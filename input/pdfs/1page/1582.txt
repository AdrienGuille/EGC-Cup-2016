Apprentissage de structure des reseaux bayesiens et
donnees incompletes
Olivier Francois et Philippe Leray
INSA Rouen - Laboratoire PSI - FRE CNRS 2645
BP 08 - Av. de l'Universite, 76801 St-Etienne du Rouvray Cedex
fOlivier.Francois, Philippe.Lerayg@insa-rouen.fr
http://bnt.insa-rouen.fr
Resume. Le formalisme des modeles graphiques connait actuellement un essor dans
les domaines du machine learning. En particulier, les reseaux bayesiens sont capables
d'eectuer des raisonnements probabilistes a partir de donnees incompletes alors
que peu de methodes sont actuellement capables d'utiliser les bases d'exemples in-
completes pour leur apprentissage. En s'inpirant du principe de ams-em propose par
(Friedman, 1997) et des travaux de(Chow & Liu, 1968), nous proposons une methode
permettant de faire l'apprentissage de reseaux bayesiens particuliers, de structure ar-
borescente, a partir de donnees incompletes. Une etude experimentale expose ensuite
des resultats preliminaires qu'il est possible d'attendre d'une telle methode, puis
montre le gain potentiel apporte lorsque nous utilisons les arbres obtenus comme
initialisation d'une methode de recherche gloutonne comme ams-em.
1 Introduction
La determination d'un reseau bayesien B = (G; ) necessite la denition d'un graphe acy-
clique dirige (dag) G dont les sommets representent un ensemble de variables aleatoires X =
fX1;    ; Xng (la structure), et de matrices de probabilites conditionnelles du nud i connaissant
l'etat de ses parents Pa(Xi) dans G, i = [P(Xi=XPa(Xi))] (les parametres).
De nombreuses methodes d'apprentissage de structure de reseaux bayesiens ont vu le jour ces
dernieres annees. Alors qu'il est possible de faire de l'apprentissage de parametres de reseaux
bayesiens a partir de donnees incompletes et que l'inference dans les reseaux bayesiens est pos-
sible me^me lorsque peu d'attributs sont observes (Jensen, 1996, Pearl, 1998, Nam et al., 2004),
les algorithmes d'apprentissage de structure avec des donnees incompletes restent rares.
Il est possible de dierencier trois types de donnees manquantes selon le mecanisme qui les
a generees. Le premier type represente les donnees manquantes au hasard (mar, missing at ran-
dom). Dans ce cas, la probabilite qu'une variable ne soit pas mesuree ne depend que de l'etat
de certaines autres variables observees. Lorsque cette probabilite ne depend plus des variables
observees, les donnees manquantes sont dites mcar (missing completely at random). Par contre
lorsque la probabilite qu'une variable soit manquante depend a la fois de l'etat de certaines autres
variables observees mais egalement de phenomenes exterieurs, les donnees sont dites nmar.
Par la suite, nous supposerons que nous sommes en presence d'une base de donnees incompletes
suivant un mecanisme mar ou mcar. Ainsi, nous possedons toute l'information necessaire pour
estimer la distribution des donnees manquantes dans la base d'exemples.
Lorsque les donnees sont incompletes, il est possible de determiner les parametres et la structure
du reseau bayesien a partir des entrees completes de la base. Comme les donnees manquantes sont
supposees l'e^tre aleatoirement, nous construisons ainsi un estimateur sans biais. Neanmoins, dans
l'exemple d'une base de 2000 cas sur 20 attributs, avec une probabilite de 20% qu'une mesure soit
manquante, nous ne disposerons en moyenne que de 23 cas complets. Les autres donnees a notre
disposition ne sont donc pas negligeables et il serait donc preferable de faire l'apprentissage en
utilisant toute l'information a laquelle nous avons acces.
Un avantage des reseaux bayesiens est qu'il sut que seules les variables Xi et Pa(Xi) soient
observees pour estimer la table de probabilite conditionnelle correspondante. Dans ce cas, il est
alors possible d'utiliser tous les exemples (me^me incomplets) ou ces variables sont observees (dans
RNTI-E-3127
