Apprentissage Statistique de la Topologie d’un Ensemble de
DonnØes EtiquetØes
Pierre Gaillard , Michaºl Aupetit , GØrard Govaert 
 Commisariat à l’Energie Atomique
BP 12 - 91680 BruyŁres-le-Châtel, France
pierre.gaillard@cea.fr, michael.aupetit@cea.fr
 UniversitØ de Technologie de CompiŁgne
BP 60319 - 60203 CompiŁgne Cedex, France
gerard.govaert@utc.fr
Résumé. DØcouvrir la topologie d’un ensemble de donnØes ØtiquetØes dans un
espace Euclidien peut aider à construire un meilleur systŁme de dØcision. Dans
ce papier, nous proposons un modŁle gØnØratif basØ sur le graphe de Delaunay
de plusieurs prototypes reprØsentant les donnØes ØtiquetØes dans le but d’extraire
de ce graphe la topologie des classes.
1 Introduction : extraction de la topologie et discrimination
GØnØralement, les problŁmes d’apprentissage supervisØ impliquent un ensemble deN don-
nØes ØtiquetØes fxi; ciji = 1; :::;Mg, oø xi est un vecteur de dimension D et ci 2 f1; :::;Kg
est le label de la classe associØe à ce vecteur. L’objectif ultime des mØthodes d’apprentissage
supervisØ est de construire un classieur dans le but de prØdire la classe de nouveaux vecteurs
avec un minimum d’erreur. Cependant, la discrimination est seulement la derniŁre Øtape du
processus d’apprentissage qui peut Œtre enrichie à travers une phase d’exploration des don-
nØes. En effet, plusieurs caractØristiques topologiques des classes peuvent Œtre utiles, parmi
lesquelles : (1) leur connexitØ, pour Øvaluer la complexitØ du problŁme de classication ; (2)
leur dimension intrinsŁque pour selectionner les variables les plus discriminantes.
Un moyen de capturer la structure des donnØes est de modØliser leur distribution en terme
de variables cachØes ou latentes. Les principaux modŁles gØnØratifs traitant de l’apprentissage
non-supervisØ de variØtØs sont le "Generative Topographic Mapping" (Bishop et al., 1998) et
les "Probabilistic Principal Component Analyzers" (Tipping et Bishop, 1999). Dans la pre-
miŁre approche, la dimension intrinsŁque est xØe a priori pour permettre la visualisation,
tandis que dans la seconde approche, la dimension intrinsŁque est capturØe mais la connexitØ
est perdue. Dans le but de dØpasser ces limites, un autre modŁle gØnØratif basØ sur le Graphe de
Delaunay (DG) de prototypes reprØsentant les donnØes est proposØ. Ce modŁle, appelØ Graphe
GØnØratif Gaussien (GGG) (Aupetit, 2006), n’assume aucun a priori sur la topologie et permet
d’apprendre la connexitØ d’un ensemble de donnØes. Nous proposons d’Øtendre le GGG au
cas supervisØ, dans le but d’extraire la topologie des classes. Observant que le GGG peut Œtre
vu comme une gØnØralisation des modŁles de MØlange Gaussien (GM) et que les GM ont ØtØ
