Inférence dans les HMM hiérarchiques et factorisés :
changement de représentation vers le formalisme des
Réseaux Bayésiens.
Sylvain Gelly∗, Nicolas Bredeche∗, Michèle Sebag∗
∗Equipe Inference&Apprentissage - Projet TAO (INRIA futurs),
LRI, Université Paris-Sud, 91504 Orsay Cedex
(gelly,bredeche,sebag)@lri.fr
1 Présentation du problème
Une limite essentielle des HMM, et plus généralement des modèles de Markov,
concerne le passage à l’échelle, l’impossibilité de la prise en compte efficace de l’influence
de phénomènes indépendants et la difficulté de généralisation.
Pour répondre à ces problèmes, plusieurs extensions existent. En particulier, nous
nous intéresserons dans ce qui suit à la hiérarchisation (Theocharous et al. 2001, 2004)
et à la factorisation (Ghahramani 1996).
La hiérarchisation permet de réduire le nombre de liens entre états nécessaires dans
un HMM et par là même de réduire la complexité algorithmique de l’apprentissage ainsi
que l’imprécision. Quant à la factorisation, le principe est d’expliquer les observations
par plusieurs causes plutôt qu’une seule. C’est à dire qu’on remplace le P (Y |X) des
HMM par P (Y |X1, X2, ..., Xn). Les X i sont des variables cachées pouvant être gérées
indépendamment. Les P (X it+1|X
i
t) sont alors différents pour chaque i.
– L’existence de dépendances multiples dans les FHHMM entraîne à priori une
explosion combinatoire du nombre de paramètres à apprendre, ce qui est d’autant
plus problématique lorsque peu d’exemples sont à notre disposition (ceci est une
propriété inhérente à la robotique) ;
– La présence de circuits dans les dépendances conditionnelles entre les variables
d’un FHHMM empêchent la modélisation directe par un réseau bayesien. Il est
à noter que ces dépendances ne concernent les variables qu’à un même pas de
temps (synchrones).
Dans la suite de cet article, nous ne ferons pas de différence entre les dépendances
synchrones et les transitions temporelles, les deux types étant des dépendances condi-
tionnelles entre deux variables.
On ne peut ainsi pas adapter directement les algorithmes existants dans le cas des
HMM factorisés, ou hiérarchiques.
Un aspect important du problème est que notre système apprend à partir de don-
nées éparses car nous faisons l’hypothèse que nous ne disposons que d’un petit nombre
d’exemples pour apprendre. Ceci se justifie par le domaine d’application (la robotique
située), où le processus d’échantillonnage des données est contrôlé par un compor-
tement dépendant entre autres de l’environnement et des capacités du robot qui ne
permet pas d’obtenir beaucoup d’exemples. Par conséquent, nous souhaitons exprimer
un compromis entre précision et vitesse de l’apprentissage.
- 57 - RNTI-E-5
