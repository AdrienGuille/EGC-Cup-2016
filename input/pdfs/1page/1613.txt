Inte´gration efficace des arbres de de´cision dans les
SGBD : utilisation des index bitmap
Ce´cile Favre, Fadila Bentayeb
Laboratoire ERIC, Lyon 2
5 Avenue Pierre Mende`s France
69676 Bron CEDEX
{cfavre,bentayeb}@eric.univ-lyon2.fr,
Re´sume´. Nous pre´sentons dans cet article une nouvelle approche de
fouille qui permet d’appliquer des algorithmes de construction d’arbres
de de´cision en re´pondant a` deux objectifs : (1) traiter des bases volumi-
neuses, (2) en des temps de traitement acceptables. Le premier objectif
est atteint en inte´grant ces algorithmes au cœur des SGBD, en utilisant
uniquement les outils fournis par ces derniers. Toutefois, les temps de
traitement demeurent longs, en raison des nombreuses lectures de la base.
Nous montrons que, graˆce aux index bitmap, nous re´duisons a` la fois la
taille de la base d’apprentissage et les temps de traitements. Pour valider
notre approche, nous avons imple´mente´ la me´thode ID3 sous forme d’une
proce´dure stocke´e dans le SGBD Oracle.
Mots cle´s : Index bitmap, bases de donne´es, fouille de donne´es, arbres
de de´cision, performance, complexite´.
1 Introduction
L’application efficace de me´thodes de fouille sur des bases de donne´es volumineuses
devient un enjeu de recherche de plus en plus important. Les algorithmes traditionnels
de fouille de donne´es s’appliquent sur des tableaux attributs/valeurs (Zighed et Rako-
tomalala 2000). La volume´trie des bases e´tant croissante, les algorithmes classiques se
heurtent au proble`me de la limitation de la taille de la me´moire centrale dans laquelle
les donne´es sont traite´es. La ”scalabilite´” (capacite´ de maintenir des performances
malgre´ un accroissement du volume de donne´es), peut alors eˆtre assure´e en optimisant
soit les algorithmes (Agrawal et al. 1996, Gehrke et al. 1998), soit l’acce`s aux donne´es
(Ramesh et al. 2001, Dunkel et Soparkar 1999). Une autre issue au proble`me consiste a`
re´duire la volume´trie des donne´es a` traiter. Pour cela, une phase de pre´traitement est
ge´ne´ralement applique´e sur les donne´es : l’e´chantillonnage (Ttoivonen 1996, Chauchat
et Rakotomalala 2000) ou la se´lection d’attributs (Lia et Motoda 1998).
Re´cemment, une nouvelle approche de fouille de donne´es est apparue pour pallier
au proble`me de limitation de la taille de la me´moire. Il s’agit d’inte´grer les me´thodes
de fouille de donne´es au cœur des Syste`mes de Gestion de Bases de Donne´es (SGBD)
(Chaudhuri 1998). Ainsi, le volume des donne´es traite´es n’est plus limite´ par la taille
de la me´moire. Cette piste de recherche est conjointement lie´e a` l’ave`nement des en-
trepoˆts de donne´es et de l’analyse en ligne (OLAP) plus particulie`rement (Codd 1993).
RNTI-E-3319
