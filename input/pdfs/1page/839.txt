Se´lection rapide en apprentissage supervise´
Pierre-Emmanuel JOUVE ∗, Gae¨lle LEGRAND∗, Nicolas NICOLOYANNIS ∗
∗LABORATOIRE ERIC, Universite´ Lumie`re - Lyon2
Baˆtiment L, 5 av. Pierre Mende`s-France
69 676 BRON cedex FRANCE
{pierre.jouve, gaelle.legrand}@eric.univ-lyon2.fr, nicolas.nicoloyannis@univ-lyon2.fr
http://eric.univ-lyon2.fr
Re´sume´. La se´lection de variables (SdV) permet de re´duire l’espace de
repre´sentation des donne´es. Ce processus est de plus en plus critique en
raison de l’augmentation de la taille des bases de donne´es. Traditionnelle-
ment, les me´thodes de SdV ne´cessitent plusieurs acce`s au jeu de donne´es,
ce qui peut repre´senter une part relativement importante du temps d’exe-
cution de ces algorithmes. Nous proposons une nouvelle me´thode efficiente
et rapide (ne ne´cessitant qu’un unique acce`s aux donne´es). Cette me´thode
utilise les algorithmes ge´ne´tiques ainsi que des mesures de validite´ de clas-
sification non supervise´e (cns).
1 Introduction
La taille des bases de donne´es e´tant de plus en plus importante, l’ame´lioration de la
qualite´ de l’espace de repre´sentation des donne´es (ERD) est devenue un proble`me ma-
jeur de l’ECD. L’une des difficulte´s majeures lie´e a` l’ERD est la dimension des donne´es
(le nombre de variables descriptives caracte´risant chacun des objets). Ce proble`me
peut se re´sumer par la phrase de Liu et Motoda [Liu et Motoda, 1998] ”Less is more.”
qui signifie que si l’on de´sire extraire de l’information utile et compre´hensible a` partir
de nos donne´es, il convient en premier lieu de retirer les parties non pertinentes. La
se´lection de variables (SdV) permet de re´soudre ce proble`me. C’est un processus choi-
sissant un sous-ensemble optimal de variables selon un crite`re particulier. Il permet
l’e´limination de variables inutiles et/ou redondantes, autorisant ainsi l’acce´le´ration et
l’ame´lioration de la pre´cision pre´dictive des processus d’apprentissage. Il existe deux fa-
milles d’algorithmes de SdV : les me´thodes ”Enveloppe” [Kohavi et John, 1997] et les
me´thodes ”Filtre”[Kira et Rendell, 1992]. La diffe´rence fondamentale entre ces deux
familles re´side dans le fait que la premie`re est lie´e a` l’algorithme d’induction utilise´ (ce
qui lui confe`re un couˆt calculatoire bien souvent trop important) alors que la seconde
est totalement inde´pendante.
Les approches filtre sont de 4 types : exhaustive, heuristique, probabiliste et se´lection
en un seul parcours de base. Les me´thodes exhaustives(MDLM [Sheinvald et al., 1990],
FOCUS [Almuallim et Dietterich, 1991]...) testent tous les sous-ensembles possibles de
variables, ces algorithmes sont donc le plus souvent impossible a` appliquer du fait de
leur couˆt calculatoire trop e´leve´. Les me´thodes heuristiques sont tre`s nombreuses,
la plus connue est RELIEF[Kira et Rendell, 1992]. Sa complexite´ est line´aire selon le
nombre d’objets et le nombre d’ite´rations effectue´es. Il existe e´galement des me´thodes
