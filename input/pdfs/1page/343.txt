Evaluating Bayesian Networks by Sampling with Simplified
Assumptions
Saaid Baraty∗, Dan A. Simovici∗
∗University of Massachusetts Boston
Computer Science Department,
Boston, Massachusetts 02125
e-mail{sbaraty,dsim}@cs.umb.edu,
Abstract. The most common fitness evaluation for Bayesian networks in the
presence of data is the Cooper-Herskovitz criterion. This technique involves
massive amounts of data and, therefore, expansive computations. We propose a
cheaper alternative evaluation method using simplified assumptions which pro-
duces evaluations that are strongly correlated with the Cooper-Herskovitz crite-
rion.
1 Introduction
We investigate the problem of constructing a Bayesian network for a composite phe-
nomenon U = {u1, u2, . . . , un} where ui for 1 ≤ i ≤ n are discrete random variables
representing the state assignment of the attributes of U. To accomplish this, we start from
a data multiset D = {t1, t2, . . . , tm} where an n-ary tuple ti is an instance of the event U. We
refer to this multiset as evidence data set (data set for short).
A number of assumptions are necessary for deriving a measure for evaluating the fitness
of a Bayesian network structure (BNS) for a training data set. Stronger hypotheses make the
evaluationmoremanageable. On the other hand, the model obtained under weaker assumptions
is better capable to be conforming with the underlying true distribution of the problem.
Let G = (U, E) be a directed acyclic graph having U as its set of vertices and E as its set
of edges, which captures the direct probabilistic dependencies among these variables. LetΘ be
the collection of parameters which quantifies the joint probability distribution of U as specified
by G. We denote the set of possible assignments of a random variable ui by Dom(ui) =
{u1i , . . . , urii }. The notion of domain can be extended to sets of variables V using Cartesian
product. If the set of parent nodes of ui is ParG(ui), then Dom(ParG(ui) = {U1i , . . . , U qii }.
The set of non-descendants of ui, ndG(ui) is the set of all nodes in U excluding ui and all its
descendants. When it is clear from the context we drop the subscript G. The pair B = (G,Θ)
satisfies the local Markov condition if PB(ui|nd(ui)) = PB(ui|Par(ui)) for 1 ≤ i ≤ n, where
PB is the probability distribution on U specified by B. The model B is a Bayesian network
if it satisfies the local Markov condition. By the chain rule we have: PB(u1, u2, . . . , un) =∏n
i=1 PB(ui|Par(ui)). Therefore if we let θijk = P (ui = uki |Par(ui) = U ji ) and θij· =
(θij1, . . . , θijri) for 1 ≤ i ≤ n, 1 ≤ k ≤ ri and 1 ≤ j ≤ qi, then the joint probability
distribution on U is specified by Θ = {θij·|1 ≤ i ≤ n and 1 ≤ j ≤ qi}.
- 11 -
