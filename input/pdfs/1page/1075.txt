Structure Inference of Bayesian Networks from Data: A New
Approach Based on Generalized Conditional Entropy
Dan A. Simovici∗, Saaid Baraty∗
∗Univ. of Massachusetts Boston, Massachusetts 02125, USA
{dsim,sbaraty}@cs.umb.edu
Abstract. We propose a novel algorithm for extracting the structure of a Bayesian
network from a dataset. Our approach is based on generalized conditional en-
tropies, a parametric family of entropies that extends the usual Shannon condi-
tional entropy. Our results indicate that with an appropriate choice of a general-
ized conditional entropy we obtain Bayesian networks that have superior scores
compared to similar structures obtained by classical inference methods.
1 Introduction
A Bayesian Belief Network (BBN) structure is a directed acyclic graph which represents
probabilistic dependencies among a set of random variables.
Inducing a BBN structure for the set of attributes of a dataset is a well known problem and
a challenging one due to enormity of the search space. The number of possible BBN structures
grows super-exponentially with respect to the number of the nodes.
In Cooper and Herskovits (1993), where the K2 heuristic algorithm is introduced, a mea-
sure of the quality of the structure is derived based on its posterior probability in presence of
a dataset. An alternative approach to compute a BBN structure is based on the Minimum De-
scription Length principle (MDL) first introduced in Rissanen (1978). The algorithms of Lam
and Bacchus (1994) and Suzuki (1999) are derived from this principle.
We propose a new approach to inducing BBN structures from datasets based on the notion
of β-generalized entropy (β-GE) and its corresponding β-generalized conditional entropy (β-
GCE) introduced in Havrda and Charvat (1967) and axiomatized in Simovici and Jaroszewicz
(2002) as a one-parameter family of functions defined on partitions (or probability distribu-
tions). The flexibility that ensues allows us to generate BBNs with better scores than published
results.
One important advantage of our approach is that, unlike Cooper and Herskovits (1993) it
is not based on any distributional assumption for developing the formula.
2 Generalized Entropy and Structure Inference
The set of partitions of a set S is denoted by PART(S). The trace of a partition pi on a
subset T of S is the partition piT = {T ∩ Bi | i ∈ I and T ∩ Bi 6= ∅} of T . The usual order
between set partitions is denoted by “≤”. It is well-known that (PART(S),≤) is a bounded
