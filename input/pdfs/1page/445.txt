Définition d’une stratégie de résolution de problèmes pour 
un robot humanoïde 
Yves Kodratoff, Mary Felkin 
Équipe Inférence et Apprentissage, LRI, Bât. 490, 91405 Orsay, France 
mary.felkin@lri.fr, yk@lri.fr 
Résumé. Nous avons développé un système dont le but est d’obtenir le logiciel 
de commande d’un robot capable de simuler le comportement d’un humain 
placé en situation de résolution de problèmes. Nous avons résolu ce problème 
dans un environnement psychologique particulier où les comportements hu-
mains peuvent être interprétés comme des ‘observables’ de leurs stratégies de 
résolution de problèmes. Notre solution contient de plus celle d’un autre pro-
blème, celui de construire une boucle complète commençant avec le compor-
tement d’un groupe d’humains, son analyse et son interprétation en termes 
d’observables humaines, la définition des stratégies utilisées par les humains (y 
compris celles qui sont inefficaces), l’interprétation des observables humaines 
en terme de mouvements du robot, la définition de ce qu’est une “stratégie de 
robot ” en terme de stratégies humaines. La boucle est bouclée avec un langage 
de programmation capable de programmer ces stratégies robotiques, qui de-
viennent ainsi à leur tour des observables, tout comme l’ont été les stratégies 
humaines du début de la boucle. Nous expliquons comment nous avons été ca-
pables définir de façon objective ce que nous appelons une stratégie de robot. 
Notre solution assemble deux facteurs différents. L’un permet d’éviter les 
comportements ‘inhumains’ et se fonde sur la moyenne des comportements 
des humains que nous avons observés. L’autre fournit une sorte ‘d’humanité’ 
au robot en lui permettant de dévier de cette moyenne par n fois l’écart type 
observé chez les humains qu’il doit simuler. Il devient alors possible de pro-
grammer des comportements complètements humains.  
1 Introduction et Motivations 
Dans une série d’expériences menées par des psychologues (Tijus et al., 2007), des volontai-
res humains aux yeux bandés ont exploré un labyrinthe pour découvrir un ‘trésor’ et leur 
comportement au cours de cette recherche c’est exprimé en suites de paires perception-
actions qui ont été filmées.  Les actions possibles se limitaient à leur déplacements dans le 
labyrinthe et à saisir le trésor. Toutes ces actions ont été observées.
Le fossé entre des stratégies humaines et des paires perception-action est trop large pour 
être franchi d’un seul pas d’apprentissage. Nous avons utilisé des modèles architecturaux 
issus des sciences cognitives pour augmenter progressivement la complexité de ce qui devait 
être appris. Nous sommes ainsi passés de nos données brutes constituées par les ‘observa-
bles’, c'est-à-dire des paires perception-action, à des primitives, c. à d. des suites signifiantes 
