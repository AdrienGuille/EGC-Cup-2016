Arbre BIC optimal et taux d’erreur
Gilbert Ritschard
De´partement d’e´conome´trie, Universite´ de Gene`ve
gilbert.ritschard@themes.unige.ch
Re´sume´. Nous reconside´rons dans cet article le crite`re BIC pour arbres d’induc-
tion propose´ dans Ritschard et Zighed (2003, 2004) et discutons deux aspects lie´s
a` sa porte´e. Le premier concerne les possibilite´s de le calculer. Nous montrons
comment il s’obtient a` partir des statistiques du rapport vraisemblance utilise´es
pour tester l’inde´pendance ligne-colonne de tables de contingence. Le second
point porte sur son inte´reˆt dans une optique de classification. Nous illustrons sur
l’exemple du Titanic la relation entre le BIC et le taux d’erreur en ge´ne´ralisation
lorsqu’on regarde leur e´volution selon la complexite´ de l’arbre. Nous esquissons
un plan d’expe´rimentation en vue de ve´rifier la conjecture selon laquelle le BIC
minimum assurerait en moyenne le meilleur taux d’erreur en ge´ne´ralisation.
1 Introduction
La qualite´ des arbres de classification, comme pour d’autres classifieurs, est le plus souvent
e´tablie sur la base du taux d’erreur de classement en ge´ne´ralisation. Si l’on examine l’e´volution
de ce taux en fonction de la complexite´ du classifieur, il est connu qu’il passe par un minimum
au dela` duquel on parle de sur-apprentissage (overfitting). Intuitivement, l’explication de ce
phe´nome`ne tient au fait qu’au dela` d’un certain seuil, plus on augmente la complexite´, plus
l’arbre devient de´pendant de l’e´chantillon d’apprentissage utilise´, au sens ou` il devient de plus
en plus probable que de petites perturbations de l’e´chantillon entraıˆneront des modifications
des re`gles de classification. Lorsqu’il s’agit d’utiliser l’arbre pour la classification, il semble
de`s lors naturel de retenir celui qui minimise le taux d’erreur en ge´ne´ralisation.
Mais comment s’assurer a priori que l’arbre induit sera celui qui minimisera le taux en
ge´ne´ralisation ? Il s’agit de disposer d’un crite`re qui, tout en se calculant sur l’e´chantillon
d’apprentissage, nous assure que le taux d’erreur sera en moyenne minimum pour tout en-
semble de donne´es supple´mentaires. A de´faut de pouvoir mesurer a priori le taux d’erreur en
ge´ne´ralisation, on s’inte´resse a` la complexite´ qu’il s’agit de minimiser et l’on tentera de retenir
le meilleur compromis entre qualite´ d’information sur donne´es d’apprentissage et complexite´.
Le crite`re BIC (Bayesian Information Criteria) pour arbre que nous avons introduit dans Rit-
schard et Zighed (2003, 2004) pour comparer la qualite´ de la description des donne´es fournies
par diffe´rents arbres nous semble pouvoir eˆtre une solution de ce point de vue puisqu’il com-
bine un crite`re d’ajustement (la de´viance) avec une pe´nalisation pour la complexite´ (le nombre
de parame`tres). D’autres crite`res, dont la description minimale de donne´es (Rissanen, 1983) et
le message de longueur minimal, MML, (Wallace et Freeman, 1987) qui combinent e´galement
une qualite´ d’information et une pe´nalisation pour la complexite´ pourraient e´galement s’ave´rer
- 403 - RNTI-E-5
