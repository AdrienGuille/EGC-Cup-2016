Acce´le´ration de EM pour donne´es qualitatives :
e´tude comparative de diffe´rentes versions
Mohamed Nadif, Franc¸ois-Xavier Jollois
LITA - IUT de METZ, Universite´ de Metz,
Ile du Saulcy, 57045 METZ Cedex, France
{jollois,nadif}@iut.univ-metz.fr,
Re´sume´. L’algorithme EM est tre`s populaire et tre`s efficace pour l’esti-
mation de parame`tres d’un mode`le de me´lange. L’inconve´nient majeur de
cet algorithme est la lenteur de sa convergence. Son application sur des
tableaux de grande taille pourrait ainsi prendre e´norme´ment de temps.
Afin de reme´dier a` ce proble`me, nous e´tudions ici le comportement de
plusieurs variantes connus de EM, ainsi qu’une nouvelle me´thode. Celles-
ci permettent d’acce´le´rer la convergence de l’algorithme, tout en obtenant
des re´sultats similaires a` celui-ci. Dans ce travail, nous nous concentrons
sur l’aspect classification. Nous re´alisons une e´tude comparative entre les
diffe´rentes variantes sur des donne´es simule´es et re´elles et proposons une
strate´gie d’utilisation de notre me´thode qui s’ave`re tre`s efficace.
1 Introduction
L’utilisation des mode`les de me´lange dans la classification est devenue une ap-
proche classique et tre`s puissante (voir par exemple [Banfield et Raftery, 1993], et
[Celeux et Govaert, 1995]). En traitant la classification sous cette approche, l’algo-
rithme EM [Dempster et al., 1977] compose´ de deux e´tapes : Estimation et Maximi-
sation, est devenu quasiment incontournable. Celui-ci est tre`s populaire pour l’estima-
tion de parame`tres. Ainsi, de nombreux logiciels sont base´s sur cette approche, comme
Mclust-EMclust [Fraley et Raftery, 1999], EMmix [McLachlan et Peel, 1998] ou MIX-
MOD [Biernacki et al., 2001]. Ce succe`s tient a` sa simplicite´, a` ses proprie´te´s the´oriques
et a` son bon comportement pratique. De plus, un inte´reˆt grandissant se fait ressen-
tir actuellement pour les donne´es qualitatives. On peut citer le logiciel AutoClass
[Cheeseman et Stutz, 1996], tre`s utilise´ dans la communaute´ Fouille des Donne´es.
Malheureusement, son principal inconve´nient re´side dans sa lenteur due au nombre
e´leve´ d’ite´rations parfois ne´cessaire pour la convergence, ce qui rend son utilisation
inapproprie´e pour les donne´es de grande taille. Plusieurs versions ont e´te´ faites pour
acce´le´rer cet algorithme et beaucoup d’entres elles agissent sur l’e´tape maximisation.
Ici, comme nous nous inte´ressons au mode`le des classes latentes, l’e´tape de maximi-
sation ne pre´sente aucune difficulte´ pour le calcul des parame`tres. Nous avons donc
choisi d’e´tudier des versions particulie`rement adapte´e aux donne´es de grande taille et
qui utilisent une e´tape partielle d’estimation au lieu d’une e´tape Estimation comple`te.
Cette version semble tre`s efficace pour des me´langes Gaussiens, nous proposons ici de
l’appliquer sur le mode`le de me´lange des classes latentes et de discuter son comporte-
ment.
