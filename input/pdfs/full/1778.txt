Extension de l’algorithme Apriori et des re`gles
d’association au cas des donne´es symboliques
diagrammes et se´lection des meilleures re`gles par la
re´gression line´aire symbolique
Filipe Afonso
Lamsade et Ceremade-Unversite´ Paris 9 Dauphine/ Place du Mare´chal de Lattre de
Tassigny, 75775 Paris Cedex 16, France
afonso@ceremade.dauphine.fr
Re´sume´. Cet article pre´sente l’extension de l’algorithme Apriori et des
re`gles d’association au cas des donne´es symboliques diagrammes. La me´thode
propose´e nous permet de de´couvrir des re`gles au niveau des concepts.
Notamment, plutoˆt que d’extraire des re`gles entre diffe´rents articles ap-
partenant a` des meˆmes transactions enregistre´es dans un magasin comme
dans le cas classique, nous extrayons des re`gles d’association au niveau
des clients afin d’e´tudier leurs comportements d’achat. Enfin, nous pro-
posons une me´thode de se´lection des meilleures re`gles d’association selon
la re´gression line´aire symbolique.
1 Introduction
L’algorithme Apriori de´fini par [Agrawal et Srikant, 1994] a pour but de de´couvrir
des re`gles d’association a` partir de donne´es nominales issues du panier de la me´nage`re.
Les re`gles extraites sont du type lait→beurre traduisant le fait que si du lait est pre´sent
dans le panier de la me´nage`re alors il y a aussi du beurre. A partir de la`, des travaux
ont voulu exploiter la complexite´ des donne´es afin d’acce´le´rer l’exe´cution de l’algo-
rithme Apriori ou d’enrichir les re`gles d’association. Ainsi, [Wang et al., 2000] et [Cai
et al., 1998] de´couvrent des re`gles ponde´re´es par l’importance d’un meˆme article pre´sent
dans le panier de la me´nage`re alors que [Srikant et al., 1997] et [Han et Fu, 1995] ex-
ploitent les relations de taxonomie dans les donne´es. De plus, les re`gles d’association
sont e´tendues aux donne´es quantitatives et intervalles, notamment [Srikant et Agra-
wal, 1996] et [Miller et Yang, 1997]. [Kuok et al., 1998] font de meˆme en exploitant les
ensembles flous. Ainsi, cet article s’inscrit dans le prolongement de ces travaux. Nous
traitons la de´couverte de re`gles d’association et l’extension de l’algorithme Apriori au
cas des variables symboliques diagrammes afin d’extraire des re`gles non plus au ni-
veau des individus mais au niveau des concepts. Ainsi, apre`s avoir rappele´ certaines
de´finitions a` propos des donne´es symboliques, nous pre´sentons l’algorithme Apriori et
son extension aux cas des donne´es diagrammes, c’est-a`-dire lorsque chaque case de
notre matrice de donne´es contient plusieurs modalite´s ponde´re´es telles que la somme
des poids soit e´gale a` un. Par la suite, nous e´tendons les re`gles d’association au cas de
ces donne´es et nous utilisons la re´gression line´aire afin d’e´tudier la qualite´ des re`gles
d’association symboliques. Finalement, nous terminons par un exemple d’application
ou` nous e´tudions les comportements d’achat dans des magasins non plus au niveau
Extension des re`gles d’association aux donne´es symboliques diagrammes
des transactions comme dans le cas classique mais au niveau des clients. Pour chaque
client, nous agre´geons tous les articles achete´s graˆce a` un diagramme construit avec la
proportion de chaque article par rapport aux achats totaux du client.
1.1 Donne´es en entre´e de l’analyse des donne´es symboliques
L’inte´reˆt principal de l’analyse des donne´es symboliques (ADS) est de passer de
l’e´tude des individus a` l’e´tude des concepts. Par exemple, si les habitants d’un pays
sont de´crits par la re´gion, le sexe et la classe d’aˆges alors nous avons la table 1 classique.
Supposons que nous de´sirons e´tudier chaque re´gion. Nous supprimons alors la premie`re
colonne de la table 1 et nous de´crivons, table 2, chaque re´gion par des diagrammes
construits avec les cate´gories de chaque variable et non plus par une valeur unique.
Ainsi, les habitants sont des individus de premier niveau et les re´gions sont des indivi-
dus de deuxie`me niveau appele´s concepts. L’ADS s’e´tend non seulement aux variables
diagrammes mais aussi aux variables intervalles, multi-value´es, et histogrammes pour
lesquelles les ope´rateurs nume´riques standards ×, + ,− ne peuvent eˆtre applique´s di-
rectement (voir [Bock et Diday, 2000]). Nous obtenons alors une matrice symbolique
ou` chaque ligne de´finit la ”description ” d’une re´gion et chaque colonne est associe´e a`
une variable symbolique. Afin de construire et d’e´tudier les concepts, le logiciel SODAS
d’analyse de donne´es symboliques a e´te´ de´veloppe´. Ce logiciel est disponible a` l’adresse
http://www.ceremade.dauphine.fr/%7Etouati/sodas-pagegarde.htm
1.2 Concepts, objets symboliques et assertions
Un objet symbolique (OS) mode´lise des concepts. Un concept est ge´ne´ralement
de´fini par un ensemble de proprie´te´s appele´ intension et un ensemble d’individus satis-
faisant ces proprie´te´s appele´ extension (voir [Bock et Diday, 2000]).
De´finition 1 Un OS est un triplet s=(a,R,d) ou` R est une relation entre descrip-
tions, d est une description et ”a”, allant de Ω (ensemble des individus) dans L, de´pend
de R et d.
Nous avons deux sortes d’OS pour deux ensembles L diffe´rents. Les OS boole´ens
sont tels que [y(w)Rd] ∈ L = {vrai,faux}. Exemple: a(w)=[couleur(w)⊆{noir, bleu}]
∨ [poids(w)⊆[60,75]] = (vrai∨faux) = vrai ou` w²Ω, couleur et poids sont deux va-
riables qui de´crivent w. Les OS modaux sont tels que [y(w)Rd] ∈ L=[0,1]. Nous
n’utilisons pas ce type d’OS par la suite. Une assertion est alors un OS de´fini par
[d′Rd] = ∧i=1,p[d′iRidi], p ≥ 1. Nous donnons, par exemple, l’assertion boole´enne:
a(w)=[aˆge(w)⊆ {20,30,35}] ∧ [CSP (w) ⊆ {cadre,ouvrier}] ou` aˆge et CSP sont deux
variables qui de´crivent w. Finalement, l’extension d’un OS est donne´ par Ext(s) =
{w ∈ Ω/a(w) = vrai} dans le cas boole´en.
2 Algorithme Apriori et re`gles d’association
Depuis [Agrawal et al., 1993], la recherche d’algorithmes capables d’extraire des
re`gles d’association dans de grandes bases de donne´es a e´te´ un the`me tre`s e´tudie´. La
de´couverte de re`gles d’association entre diffe´rents produits pre´sents dans le panier de
RNTI - C - 1
Afonso
N◦ re´sident Re´gion Sexe Age N◦ re´sident Re´gion Sexe Age
10001 Picardie H [0,20] 15001 Alsace F [60,80]
10002 Picardie H [0,20] 15002 Alsace H [20,40]
10003 Picardie F [60,80]
Tab. 1 – Donne´es classiques de´crivant les habitants d’une re´gion
Re´gion sexe Age
Picardie (2/3) H, (1/3) F (2/3) [0,20], (1/3) [60,80]
Alsace (1/2) F, (1/2) H (1/2) [60,80], (1/2) [20,40]
Tab. 2 – Matrice de donne´es symboliques ou` chaque case contient un diagramme
la me´nage`re a e´te´ un exemple d’application particulie`rement exploite´. Par la suite, les
articles du panier de la me´nage`re sont appele´s items alors que les sous-ensembles d’items
sont appele´s itemsets. Une transaction est un sous-ensemble d’items enregistre´ a` la
caisse d’un supermarche´. Ainsi, en entre´e de ces algorithmes, nous avons un ensemble
de n items I = {i1,...,in} et un ensemble de m transactions T = {t1,...,tm} avec
ti ∈ P (I)−® (voir table 3). Une re`gle d’association est alors de´finie par deux itemsetsX
et Y tels que X → Y avec X ⊂ I, Y ⊂ I et X∩Y = ®. Dans [Agrawal et Srikant, 1994],
les auteurs sugge`rent l’algorithme Apriori. L’ide´e est de ge´ne´rer les re`gles d’association
ayant un support sup et une confiance conf supe´rieurs a` deux seuils minimum minsup
et minconf respectivement ou`: sup(X → Y ) = card(t∈T/X∪Y⊆t)card(T ) ,conf(X → Y ) =
card(t∈T/X∪Y⊆t)
card(t∈T/X⊆t) =
sup(X∪Y )
sup(X) .
L’algorithme Apriori recherche les sous-ensembles ayant un support supe´rieur a`
minsup appele´s itemsets fre´quents. Cette recherche a tout de meˆme une complexite´
forte, de l’ordre de 2n, ou` n est le nombre d’items. En fait, dans la pratique, nous
avons beaucoup moins de n items par transaction et par conse´quent, la complexite´
re´elle est bien moindre. De plus, graˆce a` la proprie´te´ 2 suivante et a` la de´termination
d’un support minimum nous supprimons les itemsets non-fre´quents avant la ge´ne´ration
de plus grands itemsets.
Proprie´te´ 2 [Agrawal et al., 1993]: Tout itemset inclus dans un itemset fre´quent
est lui-meˆme fre´quent.
Nous rappelons les diffe´rentes e´tapes de l’algorithme Apriori:
1. Apriori recherche tous les 1-itemsets (itemsets compose´s d’un item) fre´quents
Lk=1. Les supports sont calcule´s avec un passage dans la base de donne´es.
2. Tant que Lk 6= ® (Lk: ensemble des k-itemsets, itemsets de k items, fre´quents):
(a) L’algorithme ge´ne`re les k+1-itemsets ”candidats” en faisant le produit carte´sien
entre les itemsets de Lk. L’ensemble des candidats Ck+1 est ge´ne´re´. Graˆce
a` la proprie´te´ 2, Apriori supprime tout itemset I ∈ Ck+1 tel qu’il existe un
k-itemset non-fre´quent J ⊂ I. Par exemple, avec (1,2), (1,3), (1,4), (2,3),
(3,4) fre´quents, l’algorithme ge´ne`re (1,2,3), (1,2,4) et (1,3,4). (1,2,4) est alors
supprime´ car (2,4) est non fre´quent.
RNTI - C - 1
Extension des re`gles d’association aux donne´es symboliques diagrammes
Transaction Client X=items Transaction Client X=items
t1 1 v t7 2 v
t2 1 v,p,c t8 3 v,p
t3 1 v,p,c t9 3 v
t4 1 v t10 4 p,c
t5 2 v,p t11 4 p
t6 2 v,p,c
Tab. 3 – Matrice de transactions pour l’algorithme Apriori classique
(b) Pour tout c ∈ Ck+1, le support est calcule´ avec un passage dans la base.
(c) les k+1-itemsets fre´quents de Ck+1 sont ajoute´s a` Lk+1.
3 Algorithme Apriori e´tendu aux donne´es diagrammes
Nous e´tendons l’algorithme Apriori au cas des donne´es diagrammes. Concre`tement,
au lieu d’avoir une valeur unique par case dans notre matrice de donne´es ou bien un en-
semble d’items par transaction comme dans le cas classique, nous avons un diagramme
dans chaque case, i.e. des valeurs multiples ponde´re´es telles que la somme des poids
soit e´gale a` un. Cet ”Apriori Diagramme” va nous permettre d’e´tudier des concepts.
Par exemple, dans l’Apriori classique, les unite´s statistiques sont des transactions. Par
opposition, avec notre me´thode nous sommes capables d’e´tudier les clients plutoˆt que
les transactions.
Ainsi, nous conside´rons la matrice classique, table 3, avec 11 transactions re´pertorie´es
dans un supermarche´. Ces onze transactions proviennent de quatre clients diffe´rents.
Dans ces transactions, nous nous inte´ressons aux associations entre 3 cate´gories d’items
v = viande, p = poissons, c = paˆtes et ce´re´ales. Pour appliquer l’analyse symbolique sur
les concepts clients nous cre´ons ces concepts (table 4). Pour chaque client, cette matrice
agre`ge tous les items achete´s sous forme d’un diagramme. Ainsi, chaque diagramme est
construit avec la proportion de chaque article par rapport aux achats totaux du client.
Remarque: Nous pouvons si nous le de´sirons prendre en compte la quantite´ de
chaque item dans une meˆme transaction alors que dans le cas classique on regarde
simplement si un item a e´te´ achete´ ou pas. Par exemple, si nous avons, pour un meˆme
client, deux transactions (a,a,b,c) et (a,b,b,b) ou` a, b, c sont trois items alors le cas
classique conside`re deux transactions (a,b,c) et (a,b) alors que la me´thode symbolique
conside`re le diagramme {3/8a, 4/8b, 1/8c}.
Par la suite, nous alons donc utiliser l’exemple table 4 avec quatre concepts et une
seule variable diagramme X. Cependant, l’algorithme que nous pre´sentons se ge´ne´ralise
en pre´sence de plusieurs variables. Nous explicitons les e´tapes ne´cessaires a` l’obtention
des re`gles table 5 ou` par exemple la re`gle 1, 1/3 < Pv ≤ 2/3 → 0 < Pp ≤ 1/3 se
lit: ”Si pour le concept client, la proportion d’achats de viandes est comprise entre 1
produit sur 3 et 2 produits sur 3 alors la proportion d’achats de poissons est strictement
positive et infe´rieure a` 1 produit sur 3”.
RNTI - C - 1
Afonso
Concepts=Clients X=items Concepts=Clients X=items
1 1/2v, 1/4p, 1/4c 3 2/3v, 1/3p
2 1/2v, 1/3p, 1/6c 4 2/3p,1/3c
Tab. 4 – Matrice de donne´es symboliques compose´e d’une variable diagramme
N◦ Re`gles Sup % Conf % CD %
1 1/3 < Pv ≤ 2/3 → 0 < Pp ≤ 1/3 75 100 75
2 0 < Pp ≤ 1/3 → 1/3 < Pv ≤ 2/3 75 100 75
3 0 < Pc ≤ 1/3 → 0 < Pp ≤ 2/3 75 100 60
4 0 < Pp ≤ 2/3 → 1/3 < Pv ≤ 2/3 75 75 56
5 0 < Pp ≤ 2/3 → 0 < Pc ≤ 1/3 75 75 56
Tab. 5 – Re`gles d’association symboliques
3.1 Principe de la me´thode
Pour e´tendre l’algorithme Apriori, nous ”discre´tisons” les fre´quences de chaque
cate´gorie des diagrammes. Nous de´coupons en intervalles les fre´quences PXi,c pour
chaque cate´gorie c de chaque variable Xi. Ainsi, nous regardons les supports des in-
tervalles de fre´quences 0 < PXi,c ≤ 1/h,1/h < PXi,c ≤ 2/h,2/h < PXi,c ≤ 3/h,...,(h−
1)/h < PXi,c ≤ 1 ou` h de´termine la pre´cision du de´coupage. Dans un deuxie`me temps,
nous faisons l’union 2 a` 2 des intervalles de poids contigus ayant des supports stricte-
ment positifs 0 < PXi,c ≤ 2/h,1/h < PXi,c ≤ 3/h,...,(h−2) < PXi,c ≤ 1. Nous re´pe´tons
l’ope´ration jusqu’a` obtenir un unique intervalle 0 < PXi,c ≤ 1. Par la suite, toute cette
taxonomie d’intervalles sera conside´re´e. Ainsi, nous travaillons avec des objets symbo-
liques (OS) boole´ens et non plus avec des itemsets ou` les intervalles de fre´quences sont
les proprie´te´s des OS qui ont donc pour intensions a(w)=[ ah < PXi,c(w) ≤ bh ] (a=0..h-1,
b=1..h, a<b). Finalement, un k-OS est une assertion boole´enne de´finie a` partir de k pro-
prie´te´s. Par exemple, si a et a’ sont deux cate´gories de deux variables diagrammes X et
X ′ avec PXa et PX′
a′
leurs fre´quences respectives alors [ 13 < PXa ≤ 23 ]∧ [0 < PX′a′ ≤
1
3 ]
sera un 2-OS. Ces k-OS ne seront pas totalement traite´s comme des cate´gories de l’al-
gorithme classique. Il ne faut pas croiser des intervalles de meˆme cate´gorie et nous
devons a` chaque fois utiliser les plus petits intervalles de fre´quences possibles pour un
meˆme support.
3.2 Choix de la pre´cision du de´coupage h
L’utilisateur peut choisir une valeur de h en fonction du nombre de modalite´s des
variables a` e´tudier et de son besoin de re´sultats plus ou moins pre´cis. Bien e´videmment,
plus la pre´cision est grande plus le nombre de 1-OS sera grand par rapport au nombre
d’items dans le cas classique. En contrepartie, la transformation de la matrice des
donne´es classiques en donne´es symboliques aura re´duit le nombre d’individus a` e´tudier.
Dans notre exemple, table 4, nous pouvons utiliser une pre´cision h e´gale au nombre
RNTI - C - 1
Extension des re`gles d’association aux donne´es symboliques diagrammes
moyen (h=2.5) ou au nombre maximum (h=3) de cate´gories par concept dans nos
donne´es ou toute autre pre´cision juge´e conforme au besoin de l’e´tude.
3.3 De´finitions du support, de la confiance, de la ”confiance
diagramme” (CD) dans le cas de donne´es diagrammes.
Soient Ω un ensemble d’individus (concepts), X et Y deux OS ayant pour intensions
ax(w) =
∧
i,u[
ai,u
h < PXi,u(w) ≤ bi,uh ] et ay(w) =
∧
j,v[
cj,v
h < PY j,v(w) ≤ dj,vh ] avec∀i,u,j,v Xi,u 6= Yj,v ou` Pxi,u (Pyj,v ) est la fre´quence de la cate´gorie u (v) de la variable
diagramme Xi (Yj),
ai,u
h et
bi,u
h (
cj,v
h et
dj,v
h ) les bornes des intervalles de fre´quences.
De´finitions 3
A) Support. Sup(X → Y ) = card(ext(X∧Y )={w∈Ω/ax(w)=vrai,ay(w)=vrai}card(Ω)
B) Confiance. Conf(X → Y )= card(ext(X∧Y )={w∈Ω/ax(w)=vrai,ay(w)=vrai}card(ext(X)={w∈Ω/ax(w)=vrai} =
sup(X→Y )
sup(X)
C) CD. De plus, dans le cas de variables diagrammes, il est inte´ressant de de´finir
un nouvel indicateur de qualite´ (confiance diagramme ou CD) pe´nalisant les re`gles
ayant les plus grands intervalles de fre´quences et donc la plus grande impre´cision en
conclusion: CD(X → Y ) = conf(X → Y )/(1+
∑
j,v
(dj,v−cj,v)
nv×h ) ou` nv est le nombre de
proprie´te´s en conclusion.
Ce coefficient CD est tel que : 12Conf(X→Y)≤CD(X→Y)≤ hh+1Conf(X→ Y). Nous
de´finissons alors un CD minimum minCD pour la ge´ne´ration des re`gles.
3.4 Algorithme Apriori Diagramme
Dans ce paragraphe, nous de´taillons les diffe´rentes e´tapes de l’algorithme ”Apriori
diagramme” a` l’aide de l’exemple table 4. Nous donnons alors une pre´cision h=3 (=
nombre maximum de cate´gories pour un concept), un support miminum minsup =
35% (i.e. 2 unite´s):
1. Discre´tiser les fre´quences de chaque cate´gorie (voir section 3.1). Nous donnons
aux intervalles de fre´quences les codes 1, 2, 3, 4... afin de faciliter l’e´criture.
Pour la matrice, table 4, nous conside´rons les poids Pv, Pp et Pc des cate´gories
v, p et c. Ces poids sont discre´tise´s table 6 colonnes C1 (OS 1 a` 9).
2. Calculer les supports des intervalles de poids pre´ce´dents avec un passage dans la
matrice des donne´es. Nous faisons alors l’union 2 a` 2 des intervalles contigus de
supports strictement positifs (voir section 3.1). Nous re´pe´tons les unions 2 a` 2 de
nos nouveaux intervalles jusqu’a` obtenir un unique intervalle 0 < PXi,c ≤ 1. Les
supports de ces intervalles sont calcule´s sans passage dans la matrice des donne´es
car si A et B sont des intervalles contigus alors Sup(A∪B) = Sup(A)+Sup(B).
Nous ajoutons a` Lk=1 les 1-OS de support supe´rieur au seuil minsup.
Dans notre exemple, les supports des intervalles du point 1. sont calcule´s (table
6 colonne sup). Nous remarquons que 0 < Pp ≤ 1/3 et 1/3 < Pp ≤ 2/3 ont
un support supe´rieur a` 0. Par conse´quent, 0 < Pp ≤ 2/3 devient candidat (OS
nume´ro 10) et il est fre´quent car son support est e´gal a` la somme des supports
RNTI - C - 1
Afonso
OS C1 Sup OS C1 Sup OS C2 Sup OS C3 Sup
1 0<Pv≤ 13 0 6 23<Pp≤1 0 11 2∧4 3 16 2∧4∧7 2
2 13<Pv≤ 23 3 7 0<Pc≤ 13 3 12 2∧7 2
3 23<Pv≤1 0 8 13<Pc≤ 23 0 13 2∧10 3
4 0<Pp≤ 13 3 9 23<Pc≤1 0 14 4∧7 2
5 13<Pp≤ 23 1 10 0<Pp≤ 23 4 15 7∧10 3
Tab. 6 – k-Objets Symboliques fre´quents
des intervalles pre´ce´dents, soit 3+1=4. Finalement, nous ajoutons a` l’ensemble
L1 les intervalles fre´quents 2, 4, 7 et 10.
3. Faire tant que l’ensemble des k-OS (assertion de´finie avec la conjonction de k
intervalles de fre´quences) fre´quents Lk 6= ® (k ≥ 1):
(a) Ge´ne´rer les k+1-OS candidats en calculant le produit carte´sien entre les
k-OS de Lk. Dans le cas des diagrammes, nous ge´ne´rons les k+1-OS entre
intervalles de cate´gories diffe´rentes (et ”non marque´s” voir point (c)). Ainsi,
l’ensemble des candidats Ck+1 est ge´ne´re´. Du fait de la proprie´te´ 2, nous
supprimons de Ck+1 tout k+1-OS I tel qu’il existe un k-OS J ⊂ I n’appar-
tenant pas a` Lk.
Pour notre exemple, nous calculons le produit Carte´sien entre les OS de L1
pour des intervalles de cate´gories diffe´rentes. Ainsi, l’algorithme ge´ne`re les
candidats C2: (2∧4), (2∧7), (2∧10), (4∧7) et (7∧10) (voir table 6, OS=11
a` 15). (4∧10) n’est pas ge´ne´re´ car 4 et 10 sont des intervalles de la meˆme
cate´gorie.
(b) Pour tout c ∈ Ck+1, calculer le support avec un passage dans la matrice de
donne´es. Tout k+1-OS I ∈ Ck+1 fre´quent est ajoute´ a` Lk+1.
(2∧4), (2∧7), (2∧10), (4∧7) et (7∧10) sont fre´quents.
(c) Marquer tout k+1-OS I ∈ Lk+1/∃J ∈ Lk+1 avec J ⊂ I et sup(I) = sup(J).
Il s’agit de k+1-OS de´finis avec les meˆmes cate´gories mais avec des intervalles
de poids diffe´rents et nous conservons uniquement les plus petits intervalles
pour un meˆme support. Nous les marquons au lieu de les supprimer car
ces k+1-OS ne sont pas utilise´s pour la ge´ne´ration de k+2-OS mais ils sont
utilise´s pour la ge´ne´ration de re`gles.
Dans notre exemple, (2∧10) ne sera pas utilise´ pour la ge´ne´ration de 3-OS
car (2∧10) ⊃ (2∧4) et sup(2∧10) = sup(2∧4). Par contre, les re`gles 2→10
et 10→2 seront conside´re´es.
(d) Ge´ne´rer les re`gles avec un CD supe´rieur a` minCD, voir section 4.
Finalement, a` l’ite´ration suivante, le 3-OS fre´quent (2∧4∧7) (voir table 6, OS=16)
est ge´ne´re´ a` partir des 2-OS (2∧4) et (2∧7) et l’algorithme s’arreˆte. Nous remarquons
que (4∧7) et (7∧10) ne ge´ne`rent pas (4∧7∧10) car (4∧10) n’est pas fre´quent.
RNTI - C - 1
Extension des re`gles d’association aux donne´es symboliques diagrammes
4 Re`gles d’association symboliques et e´tude de ces
re`gles a` l’aide de la re´gression line´aire
4.1 Base de re`gles symboliques
Dans le cas classique, pour tous les itemsets fre´quents X et Y ⊂ X, nous ge´ne´rons
la re`gle Y → X − Y . L’algorithme classique ge´ne`re uniquement les re`gles ayant une
confiance supe´rieure a` un seuil minimumminconf. Dans le cas diagramme, nous ge´ne´rons
les re`gles ayant un CD supe´rieur a` minCD. Aussi, nous ge´ne´rons des re`gles avec une
unique proprie´te´ en conclusion:
∧
i,u[
ai,u
h < PXi,u ≤ bi,uh ] → [ cj,vh < PY j,v ≤ dj,vh ] ou`∀i,u Xi,u 6= Yj,v.
Nous ge´ne´rons des re`gles sans pre´misses redondantes, soient X → Y telles que:
1. ∀ Z ⊂ X avec Z → Y , conf(X → Y )>conf(Z → Y ) ou sup(X)>sup(Z).
Nous remarquons qu’il peut exister des OS Z ⊂ X avec sup(X) > sup(Z) car
nous avons plusieurs intervalles de fre´quences pour une meˆme cate´gorie. Dans
l’exemple table 6, nous avons 4 ⊂ 10 et sup(4) < sup(10);
2. ∀W 1-OS,W ⊂ Y , conf(X →W ) < conf(X → Y ). LorsqueW et Y sont deux 1-
OS, W ⊂ Y signifie que W et Y sont deux intervalles de la meˆme cate´gorie. Nous
cherchons alors le plus petit intervalle en conclusion pour une meˆme confiance.
Ainsi, la base de re`gles R est alors de´finie comme suit:
De´finition 4 R={(r,sup(r),conf(r),CD(r)): r=X − Y → Y / X k-OS (k > 1), Y
1-OS, Y ⊂ X; (∀Z ⊂ X−Y , conf(Z → Y ) < conf(r) ou sup(Z) < sup(X−Y )); (∀W
1-OS, W ⊂ Y , conf(X − Y →W ) < conf(r)); sup(r) ≥ minsup; CD(r) ≥ minCD}.
Nous ge´ne´rons les k-re`gles (re`gles avec k-1 pre´misses et une conclusion, k ≥ 2)
imme´diatement apre`s la ge´ne´ration des k-OS (voir l’algorithme pre´ce´dent section 3.4):
1. Pour chaque k-OS fre´quent X, calculer l’indicateur CD de toute re`gle X−Y → Y
ou` Y 1-OS, Y ⊂ X;
2. Pour chaque re`gle ayant un CD supe´rieur a` minCD :
(a) Ve´rifier qu’il n’existe pas une J-re`gle (j < k), Z → Y avec Z ⊂ X − Y et
conf(Z → Y )=conf(X − Y → Y ) (sup(Z)≥sup(X-Y) toujours vrai graˆce au
point 3(c) de l’algorithme Apriori diagramme),
(b) Ve´rifier qu’il n’existe pas une k-re`gle X−Y →W avec W ⊂ Y et conf(X−
Y →W ) = conf(X − Y → Y ),
(c) Si (a) et (b) sont ve´rifie´es: ajouter X − Y → Y a` la base de re`gles R.
Dans notre exemple, en choisissant un minCD e´gal a` 55%, nous obtenons les cinq
2-re`gles (une pre´misse et une conclusion) de la table 5. La re`gle 2 → 10 n’est pas
ge´ne´re´e car conf(2 → 10)=conf(2 → 4) et 4 ⊂ 10. De plus, malgre´ la de´couverte
d’un 3-OS fre´quent (2∧4∧7) (table 6, OS=16), l’algorithme ne ge´ne`re pas de 3-re`gles
(2 pre´misses, 1 conclusion) car aucune 3-re`gle n’ame´liore la confiance par rapport
aux 2-re`gles : conf(4∧7→2) = conf(4→2), conf(2∧7→4) = conf(2→4), conf(2∧4→7)
= conf(4→7).
RNTI - C - 1
Afonso
X1 X2 X3 X1 X2 X3
individus de la re´gression Pv Pp Pc individus Pv Pp Pc
1 1/2 1/4 1/4 3 2/3 1/3 0
2 1/2 1/3 1/6 4 0 2/3 1/3
Tab. 7 – De la matrice diagramme vers une matrice classique
4.2 Discrimination des re`gles d’association symboliques a` l’aide
de la re´gression line´aire symbolique
Les re`gles symboliques obtenues comprennent de la variation puisqu’elles sont de´finies
avec des intervalles de fre´quences en pre´misses et en conclusion. Ceci engendre de
l’impre´cision dans nos re`gles. Par exemple, si nous regardons la premie`re re`gle (1/3 <
Pv ≤ 2/3→ 0 < Pp ≤ 1/3) table 5, nous ne pouvons pas savoir si lorsque Pv est proche
de 1/3 alors Pp est plutoˆt proche de 0, ou proche de 1/3 ou bien varie dans l’inter-
valle ]0,1/3] sans distinction. Par la suite, pour e´tudier ces variations, nous utilisons la
re´gression line´aire symbolique.
[Afonso et al., 2004], [Afonso et al., 2003] et [Billard et Diday, 2002] e´tendent la
re´gression line´aire aux cas des donne´es symboliques et notamment au cas des variables
a` valeurs diagrammes. Nous expliquons brie`vement les points de la re´gression line´aire
symbolique importants pour notre e´tude. Pour plus d’informations, le lecteur pourra se
re´fe´rer aux articles cite´s ci-dessus. En fait, pour le cas des donne´es diagrammes, nous
faisons une re´gression classique en conside´rant les cate´gories de nos diagrammes comme
les variables de la re´gression. Par exemple, nous pouvons partir de la variable X de la
table 4. Il faut transformer cette matrice en matrice a` valeur unique par case afin de
pouvoir faire la re´gression. Ainsi, nous construisons une matrice ou` les poids de chaque
cate´gorie de la variable (ou des variables) deviennent des variables classiques. Ceci nous
donne la table 7 ou` les poids Pv, Pp et Pc de chaque cate´gorie deviennent 3 variables
classiques prenant, par exemple, pour valeurs 1/2, 1/4 et 1/4 respectivement pour le
premier concept. Cette me´thode est e´tendue au cas de plusieurs variables diagrammes
auxquelles nous pouvons adjoindre d’autres variables classiques et symboliques. Nous
pouvons alors choisir les variables explicatives et la variable de´pendante et faire une
re´gression normalement. Il faut cependant veiller a` ne pas faire la re´gression avec toutes
les cate´gories d’une meˆme variable diagramme, car ces cate´gories sont line´airement
de´pendantes et par conse´quent la matrice ne serait pas inversible.
Ainsi, en addition aux indicateurs de´finis section 3.3, nous pouvons discriminer les
re`gles symboliques de la forme
∧
i,u[
ai,u
h < PXi,u ≤ bi,uh ]→ [ cj,vh < PY j,v ≤ dj,vh ] a` l’aide
de la re´gression line´aire symbolique. En effet, pour des re`gles avec une seule proprie´te´ en
conclusion (une seule cate´gorie), nous calculons la re´gression des fre´quences en pre´misse
sur la fre´quence en conclusion en ne conservant uniquement que les individus dans
l’extension de l’OS. Nous obtenons alors une e´quation line´aire:
PYj,v = β0 +
∑
i,u βi,uPXi,u + ε
Dans la boule:
(
∧
i,u[
ai,u
h < PXi,u ≤ bi,uh ])
∧
([ cj,vh < PY j,v ≤ dj,vh ])
RNTI - C - 1
Extension des re`gles d’association aux donne´es symboliques diagrammes
Re`gle Equation R2 F -test Re`gle Equation R2 F -test
1 Pp=0.16+0.25Pv 0.25 0.33 4 Pv=0.25+Pp 0.25 0.33
2 Pv=0.25+Pp 0.25 0.33 5 Pc=0.13+0.3Pp 0.57 1.33
3 Pp=-0.1+2Pc 0.57 1.33
Tab. 8 – Etude des re`gles d’association symboliques a` l’aide de la re´gression symbolique
ou` ε de´signe le re´sidu de la re´gression, β0 la constante et les βi,u de´signent les coefficients
des variables PXi,u de la re´gression.
Nous sommes alors capables de mesurer la qualite´ des re`gles graˆce aux indicateurs
classiques de la re´gression line´aire:
1. Le coefficient de de´termination R2 =
∑
i=1..n
(y∗i−ym)2∑
i
(yi−ym)2 =
SSE
SST (ou` n est le nombre
d’individus dans la re´gression, les yi sont les valeurs de la variable de´pendante
Y , les y∗i les pre´dictions de Y a` partir de l’e´quation line´aire et ym la moyenne
des yi). R2 nous donne la part de la variation de Y explique´e par les variables
explicatives de la re´gression. Plus la part de variation de Y explique´e est forte
plus le R2 est proche de 1.
2. Le test de Fisher-Snedecor (F -test) de validite´ de la re´gression.
Nous donnons table 8, les e´quations, les coefficients de de´termination R2, et les
F -tests des re`gles de´couvertes table 5. Pour la re`gle 1 (1/3 < Pv ≤ 2/3 → 0 < Pp ≤
1/3), nous faisons la re´gression des poids Pv sur les poids Pp en conservant unique-
ment les individus avec un poids Pv dans l’intervalle ]1/3,2/3] et un poids Pp dans
l’intervalle ]0,1/3], c’est-a`-dire les individus 1, 2 et 3 (voir table 7). Nous obtenons
Pp = 0.16+0.25Pv lorsque Pv est dans l’intervalle ]1/3,2/3] avec une part de variation
de Pp explique´e par Pv de R2 = 0.25%. Ces re´sultats sont donne´s a` titre d’exemple
e´tant donne´ que le nombre d’individus est ici trop faible pour obtenir des re´sultats
significatifs (les R2 sont faibles et les F -tests rejettent les re´gressions).
5 Applications
5.1 Re`gles d’association classiques versus symboliques
Nous comparons les re`gles ge´ne´re´es a` partir des itemsets fre´quents issus de l’al-
gorithme classique applique´ a` la matrice table 3 et les re`gles ge´ne´re´es a` partir des
objets symboliques issus de l’algorithme ”diagramme” applique´ a` la matrice table 4.
Nous donnons les re`gles obtenues table 9 pour le cas classique avec minsup = 35% et
minconf = 55%. Pour le cas diagramme, nous rentrons comme parame`tres a` l’algo-
rithme, la pre´cision h=3 (correspondant au plus grand nombre d’items pour un meˆme
client), le support minimum minsup = 35% (i.e. 2 clients). Les OS fre´quents sont
donne´s table 6 ou` Pv, Pp et Pc sont les poids de v = viande, p = poissons, c = paˆtes
et ce´re´ales. Nous donnons table 5 les re`gles symboliques pour minDC = 55%.
Dans les deux cas, nous remarquons que l’achat de paˆtes et ce´re´ales implique, avec
une confiance de 100%, l’achat de poissons. Toutefois, la me´thode diagramme nous
RNTI - C - 1
Afonso
N◦ Re`gle Support % Confiance % N◦ Re`gle Support % Confiance %
1 c → p 36 100 3 p → c 36 57
2 p → v 45 71 4 v → p 45 55
Tab. 9 – Re`gles d’association classiques
fournit plus d’informations que la me´thode classique. En effet, nous savons en plus que
les clients de paˆtes et ce´re´ales ache`tent plus de poissons que de paˆtes : 0 < Pc ≤ 1/3→
0 < Pp ≤ 2/3 avec un support de 75%, une confiance de 100% et une DC de 60%.
Nous pouvons alors calculer une relation line´aire entre les pre´misses et la conclusion
afin d’e´tudier les variations a` l’inte´rieur de la re`gle (voir table 8). Nous obtenons que
les clients de paˆtes et ce´re´ales ache`tent environ deux fois plus de poissons que de paˆtes
puisque nous avons l’e´quation Pp=-0.1+2Pc. En fait, le test de Fisher de validite´ de
la re´gression rejette cette e´quation du fait du nombre trop faible d’individus dans le
calcul de la re´gression.
Deuxie`mement, avec l’e´tude classique, nous obtenons les re`gles v → p avec conf(v →
p) = 55% et p → v avec conf(p → v) = 71%. Par conse´quent, la meilleure re`gle,
selon la confiance, serait p → v alors que dans le cas symbolique nous obtenons ”l’in-
verse”. En effet, la re`gle 1/3 < Pv ≤ 2/3 → 0 < Pp ≤ 2/3 est meilleure que la re`gle
0 < Pp ≤ 2/3 → 1/3 < Pv ≤ 2/3 selon la confiance (100%, 75% resp.). Ainsi, nous
voyons que si le ”degre´ d’inclusion” de l’achat de poissons dans l’achat de viandes dans
les transactions est grand, l’analyse symbolique nous montre qu’en fait ce sont plutoˆt
les clients de viandes qui sont aussi clients de poissons et non l’inverse. Et comme
le montre la re`gle 1, les clients de viandes sont aussi clients de poissons bien qu’ils
ache`tent plus de viandes que de poissons. Si nous prenons un autre exemple, dans un
tabac la vente de cigarettes est tre`s importante et par conse´quent le ”degre´ d’inclusion”
de l’achat de jeux a` gratter dans l’achat de cigarettes dans les transactions est grand
mais, en fait, ce sont les clients de cigarettes qui pourront eˆtre amene´s a` acheter des
jeux et non l’inverse comme l’aurait sugge´re´ le cas classique.
6 Conclusions et perspectives
Nous avons e´tendu l’algorithme Apriori au cas des variables symboliques diagrammes
dans le but d’extraire des re`gles d’association a` partir d’une matrice de concepts. Nous
avons pris comme exemple des clients de magasins quelconque ou` nous trouvons des
re`gles entre les articles achete´s au niveau des clients et non plus au niveau des tran-
sactions. Nous avons constate´ que nous de´couvrions des informations supple´mentaires
par rapport aux re`gles classiques. De plus, nous avons propose´ une manie`re d’e´tudier
la variation a` l’inte´rieur de ces re`gles d’association a` l’aide de la re´gression line´aire
symbolique. Il serait alors inte´ressant d’e´tendre cette me´thode a` d’autres variables
symboliques afin d’extraire des re`gles d’association plus riches.
RNTI - C - 1
Extension des re`gles d’association aux donne´es symboliques diagrammes
Re´fe´rences
[Afonso et al., 2004] F. Afonso, L. Billard et E. Diday. Re´gression Line´aire Sym-
bolique avec Variables Taxonomiques. Actes des 4e`mes journe´es d’Extraction et de
Gestion des Connaissances, EGC’04, Clermont-Ferrand, Ce´padues, 2004.
[Afonso et al., 2003] F. Afonso, L. Billard et E. Diday. Extension des Me´thodes de
Re´gression Line´aire aux cas des Variables Symboliques Taxonomiques et Hie´rarchiques.
Actes des XXXVe`mes journe´es de Statistiques, SFDS-03, Lyon,Vol. 1, 89-92, 2003.
[Agrawal et Srikant, 1994] R. Agrawal et R. Srikant. Fast Algorithms for Mining
Association Rules. Proc. of the 20th Int’l Conf. on Very Large Databases, 1994.
[Agrawal et al., 1993] R. Agrawal, T. Imielinski et A. Swami. Mining Association
Rules between Sets of Items in Large Databases. ACM SIGMOD Records, 1993.
[Billard et Diday, 2002] L. Billard et E. Diday. Symbolic Regression Analysis. Clas-
sification, Clustering, and Data Analysis, K. Jajuga, A. Sokolowski, et H.H. Bock eds.,
Berlin, Springer-Verlag, 281-288, 2002.
[Bock et Diday, 2000] H-H. Bock et E. Diday. Analysis of Symbolic Data. Explora-
tory methods for extracting statistical information from complex data, Springer Verlag,
Heidelberg, 2000.
[Cai et al., 1998] C.H. Cai, A.W.C. Fu, C.H. Cheng et W.W. Kwong. Mining Asso-
ciation Rules With Weighted Items. Proc. of the 1998 Int’l Database Engineering and
Applications Symposium (IDEAS’98), 68-77, 1998.
[Han et Fu, 1995] J. Han et Y. Fu. Discovery of Multiple-Level Association Rules
from Large Databases. Proc. of the 21th Int’l Conf. on Very Large Data Bases, 1995.
[Kuok et al., 1998] C.M. Kuok, A. Fu et M.H. Wong. Mining Fuzzy Association
Rules in Databases. ACM SIGMOD Record, Vol. 27, 41-46, 1998.
[Miller et Yang, 1997] R.J. Miller et Y. Yang. Association Rules over Interval Data.
Proc. of the 1997 ACM SIGMOD int’l conf. on Management of data, 452-461, 1997.
[Srikant et al., 1997] R. Srikant, Q. Vu et R. Agrawal. Mining Association Rules with
Item Constraints. Proc. of the 3rd Int’l Conf. on Knowledge Discovery in Databases
and Data Mining, 1997.
[Srikant et Agrawal, 1996] R. Srikant et R. Agrawal. Mining Quantitative Asso-
ciation Rules in Large Relational Tables. Proc. of the ACM-SIGMOD 1996 Conf. on
Management of Data, 1996.
[Wang et al., 2000] W. Wang, J. Yang et P. Yu. Efficient Mining of Weighted
Association Rules (WAR). Proc. of the sixth ACM SIGKDD int’l conf. on Knowledge
discovery and data mining , 270-274, 2000.
Summary
This paper deals with the extension of the Apriori algorithm and of the association
rules to the symbolic histogram-valued data. We suggest a method that will enable
us to discover rules at the level of the concepts. For example, instead of mining rules
between different items of some transactions recorded in a retail organization like in
the classical case, we will mine rules at the level of the customers in order to study
their purchase behavior. Finally, we suggest a method in order to evaluate the quality
of the association rules according to the symbolic linear regression.
RNTI - C - 1
