Arbre BIC optimal et taux d’erreur
Gilbert Ritschard
De´partement d’e´conome´trie, Universite´ de Gene`ve
gilbert.ritschard@themes.unige.ch
Re´sume´. Nous reconside´rons dans cet article le crite`re BIC pour arbres d’induc-
tion propose´ dans Ritschard et Zighed (2003, 2004) et discutons deux aspects lie´s
a` sa porte´e. Le premier concerne les possibilite´s de le calculer. Nous montrons
comment il s’obtient a` partir des statistiques du rapport vraisemblance utilise´es
pour tester l’inde´pendance ligne-colonne de tables de contingence. Le second
point porte sur son inte´reˆt dans une optique de classification. Nous illustrons sur
l’exemple du Titanic la relation entre le BIC et le taux d’erreur en ge´ne´ralisation
lorsqu’on regarde leur e´volution selon la complexite´ de l’arbre. Nous esquissons
un plan d’expe´rimentation en vue de ve´rifier la conjecture selon laquelle le BIC
minimum assurerait en moyenne le meilleur taux d’erreur en ge´ne´ralisation.
1 Introduction
La qualite´ des arbres de classification, comme pour d’autres classifieurs, est le plus souvent
e´tablie sur la base du taux d’erreur de classement en ge´ne´ralisation. Si l’on examine l’e´volution
de ce taux en fonction de la complexite´ du classifieur, il est connu qu’il passe par un minimum
au dela` duquel on parle de sur-apprentissage (overfitting). Intuitivement, l’explication de ce
phe´nome`ne tient au fait qu’au dela` d’un certain seuil, plus on augmente la complexite´, plus
l’arbre devient de´pendant de l’e´chantillon d’apprentissage utilise´, au sens ou` il devient de plus
en plus probable que de petites perturbations de l’e´chantillon entraıˆneront des modifications
des re`gles de classification. Lorsqu’il s’agit d’utiliser l’arbre pour la classification, il semble
de`s lors naturel de retenir celui qui minimise le taux d’erreur en ge´ne´ralisation.
Mais comment s’assurer a priori que l’arbre induit sera celui qui minimisera le taux en
ge´ne´ralisation ? Il s’agit de disposer d’un crite`re qui, tout en se calculant sur l’e´chantillon
d’apprentissage, nous assure que le taux d’erreur sera en moyenne minimum pour tout en-
semble de donne´es supple´mentaires. A de´faut de pouvoir mesurer a priori le taux d’erreur en
ge´ne´ralisation, on s’inte´resse a` la complexite´ qu’il s’agit de minimiser et l’on tentera de retenir
le meilleur compromis entre qualite´ d’information sur donne´es d’apprentissage et complexite´.
Le crite`re BIC (Bayesian Information Criteria) pour arbre que nous avons introduit dans Rit-
schard et Zighed (2003, 2004) pour comparer la qualite´ de la description des donne´es fournies
par diffe´rents arbres nous semble pouvoir eˆtre une solution de ce point de vue puisqu’il com-
bine un crite`re d’ajustement (la de´viance) avec une pe´nalisation pour la complexite´ (le nombre
de parame`tres). D’autres crite`res, dont la description minimale de donne´es (Rissanen, 1983) et
le message de longueur minimal, MML, (Wallace et Freeman, 1987) qui combinent e´galement
une qualite´ d’information et une pe´nalisation pour la complexite´ pourraient e´galement s’ave´rer
- 403 - RNTI-E-5
Arbre BIC optimal et taux d’erreur
inte´ressants de ce point de vue. Le crite`re BIC conside´re´ ici re´sulte d’une logique baye´sienne
(Raftery, 1995) tout comme le crite`re que Wehenkel (1993) utilise pour l’e´lagage.
Avant d’examiner le lien du BIC avec le taux d’erreur en ge´ne´ralisation, nous rappelons a`
la section 2 sa de´finition et en particulier celle de la de´viance sur la laquelle il se fonde. Nous
montrons que la de´viance se de´duit directement de la valeur de la statistique du rapport de
vraisemblance de deux tests d’inde´pendance, ce qui permet en particulier a` tout un chacun de
calculer le BIC d’un arbre en utilisant n’importe quel logiciel, SPSS par exemple, qui donne
ces statistiques. Nous illustrons ensuite a` la section 3 le lien entre le crite`re BIC et le taux d’er-
reur et discutons brie`vement d’un protocole d’expe´rimentation en vue de ve´rifier la conjecture
selon laquelle la minimisation du BIC assurerait la minimisation du taux moyen d’erreur en
ge´ne´ralisation.
2 Le crite`re BIC pour arbre d’induction
Pour illustrer notre discussion nous utilisons les donne´es du Titanic ou` il s’agit de pre´dire
pour chaque passager s’il survit ou pas selon trois attributs, soit le sexe (F,M), l’aˆge (A=adulte,
C=enfant) et la classe (c1, c2, c3 et c4=e´quipage). On conside`re l’arbre induit avec la me´thode
Exhaustive CHAID de Answer Tree 3.1 (SPSS, 2001) en utilisant le khi-deux du rapport de
vraisemblance, un seuil de signification de 5% et les contraintes minimales sur la taille des
nœuds. L’arbre a
Avant de de´finir le crite`re BIC, nous devons expliquer la de´viance que nous notons D(m)
pour un arbre m. Conside´rons pour cela la table de contingence cible dont les ` lignes sont
de´finies par la variable a` pre´dire (“survit ou pas” dans notre cas) et dont les c colonnes cor-
respondent a` l’ensemble des profils diffe´rents que l’on peut de´finir avec les attributs pre´dictifs.
Dans notre cas on a 14 profils diffe´rents, soit 2 × 2 × 4 moins 2 puisqu’il n’y a pas d’enfant,
ni fille ni garc¸on parmi l’e´quipage. La de´viance mesure la divergence entre la table cible et sa
pre´diction a` partir de l’arbre induit. Son expression formelle est
D(m) = −2
∑`
i=1
c∑
j=1
nij ln(nˆij/nij) ,
ou` l’on conside`re les termes nij ln(nˆij/nij) comme nuls lorsque nij = 0.
Les pre´dictions nˆij s’obtiennent en ventilant le total des cas avec profil j selon la distri-
bution observe´e dans la feuille de l’arbre induit qui comprend le profil j. Le tableau 1 donne
par exemple (sous forme transpose´e pour des raisons de pre´sentation) la table cible et la table
pre´dite avec l’arbre induit. Avec la formule ci-dessus on e´tablit que la de´viance vaut ici 6.93.
Le crite`re BIC pour un arbre induit m qui donne lieu a` q ≤ c feuilles pour une variable a`
pre´dire avec ` classes est alors de´fini, a` une constante additive pre`s, par BIC(m) = D(m) +
p ln(n), ou` n est la taille de l’e´chantillon d’apprentissage, p = (` − 1)q + c le nombre de
parame`tres de l’arbre et D(m) la de´viance.
En pre´sence d’un grand nombre d’attributs, le nombre de profils diffe´rents possibles peut
e´videmment rapidement devenir trop grand pour envisager un calcul manuel de la de´viance. On
peut dans ce cas exploiter les logiciels qui calculent la statistique du rapport de vraisemblance
pour le test d’inde´pendance sur table de contingence. Notons T la table cible et Tm la table
de contingence qui croise la variable a` pre´dire avec les feuilles de l’arbre induit. Pour notre
- 404 -RNTI-E-5
Ritschard
table cible (nij) table pre´dite (nˆij)
yes no yes no total
1 MAc1 45 88 45 88 133
2 MAc2 10 114 10 114 124
3 MAc3 59 289 67.6175 280.3825 348
4 MAc4 132 503 123.3825 511.6175 635
5 MCc1 4 0 4 0 4
6 MCc2 8 0 8 0 8
7 MCc3 10 23 10 23 33
8 FAc1 112 4 112.0342 3.9658 116
9 FAc2 66 11 67.375 9.625 77
10 FAc3 62 71 59.5 73.5 133
11 FAc4 15 2 15 2 17
12 FCc1 1 0 0.9658 0.0342 1
13 FCc2 11 0 9.625 1.375 11
14 FCc3 6 13 8.5 10.5 19
total 541 1118 541 1118 1659
TAB. 1 – Table cible et effectifs pre´dits.
exemple, on trouve T au tableau 1 tandis que Tm est donne´ au tableau 2. En raison des pro-
prie´te´s d’additivite´ de la de´viance, on aD(m0) = D(m)+D(m0|m) ou`m0 repre´sente le nœud
initial qui correspond a` l’inde´pendance. La divergence D(m0) entre ce nœud initial et la table
cible est pre´cise´ment la statistique du rapport de vraisemblance pour le test d’inde´pendance
sur le tableau T . De meˆme la divergence D(m0|m) entre m0 et m est le khi-deux du rapport
de vraisemblance pour le test d’inde´pendance sur la table Tm.
La statistique du rapport de vraisemblance vaut respectivement 531.04 pour T et 524.11
pour Tm. On trouve donc D(m) = 531.04 − 524.11 = 6.93 ce qui correspond a` la valeur
trouve´e pre´ce´demment. On en de´duit la valeur du BIC, soit BIC(m) = 6.93 + 24 ln(1659) =
184.87.
table Tm
yes no total
1 MAc1 45 88 133
2 MAc2 10 114 124
3 MAc3,c4 191 792 983
4 MCc1 4 0 4
5 MCc2 8 0 8
6 MCc3 10 23 33
7 F{A,C}c1 113 4 117
8 F{A,C}c2 77 11 88
9 F{A,C}c3 68 84 152
10 FAc4 15 2 17
total 541 1118 1659
TAB. 2 – Table croisant la variable a` pre´dire avec les feuilles.
- 405 - RNTI-E-5
Arbre BIC optimal et taux d’erreur
Notons que le BIC est de´fini a` une constante additive pre`s. Comme a` chaque fois que le
nombre de parame`tres augmente d’une unite´ le nombre d de degre´s de liberte´ associe´ a` la
de´viance diminue d’une unite´, on peut e´galement conside´rer la de´finition BIC(m) = D(m)−
d ln(n). C’est, avec une translation de 100, la de´finition utilise´e pour les BIC illustre´s a` la
figure 1.
3 BIC et le taux d’erreur en ge´ne´ralisation
On se propose a` pre´sent de discuter le lien entre le crite`re BIC et le taux d’erreur en
ge´ne´ralisation. Notre conjecture est que l’arbre BIC optimal devrait plus ou moins assurer
le plus petit taux d’erreur en ge´ne´ralisation. Nous avons calcule´ la valeur du crite`re BIC et
le taux d’erreur pour diffe´rents arbres obtenus en e´laguant successivement les branches les
moins pertinente de l’arbre sature´ ge´ne´re´ sur les 1659 cas de l’e´chantillon d’apprentissage.
L’e´chantillon test compte 542 cas. On notera que sur cet exemple tre`s simple, le taux d’erreur
en ge´ne´ralisation, bien que supe´rieur au taux d’erreur en substitution, ne remonte pas pour les
arbres les plus complexes. La figure 1 fait apparaıˆtre que le BIC correspond au mode`le le plus
simple pour lequel on a le taux d’erreur minimal. Ceci semble plutoˆt conforter notre conjecture.
Nous n’avons ici bien e´videmment conside´re´ qu’un seul ensemble test qui ne saurait suf-
fire a` de´montrer notre conjecture. Notre intention est de proce´der a` une expe´rimentation plus
comple`te. Le protocole envisage´ est de postuler successivement plusieurs structures et de
ge´ne´rer pour chacune d’entre elle un e´chantillon d’apprentissage et un ensemble de disons
100 e´chantillons tests. Comme dans l’exemple ci-dessus, nous conside´rerons plusieurs arbres
de complexite´ variable pour lesquels nous calculerons le crite`re BIC. Chaque arbre sera ensuite
applique´ sur chacun des e´chantillons test, et nous compareront la moyenne des taux d’erreur
obtenus avec le crite`re BIC. Plus pre´cise´ment nous comparerons l’e´volution avec la complexite´
de ces deux indicateurs.
0
20
40
60
80
100
120
140
0 5 10 15
Complexity (nbr of parameters)
B
IC
0.2
0.21
0.22
0.23
0.24
0.25
er
ro
r r
at
e min
BIC
test sple err
train sple err
FIG. 1 – BIC sur e´chantillon d’apprentissage et taux d’erreur.
- 406 -RNTI-E-5
Ritschard
4 Conclusion
Le crite`re BIC pour arbres a e´te´ introduit dans Ritschard et Zighed (2003, 2004) comme
crite`re pour de´terminer l’arbre le plus ade´quat du point de vue de la description de donne´es.
Nous pensons que ce crite`re peut e´galement s’ave´rer utile pour la classification. L’illustra-
tion conside´re´e semble confirmer la conjecture selon laquelle le crite`re BIC permettrait de
de´terminer l’arbre le mieux adapte´ a` une utilisation pre´dictive en dehors de l’e´chantillon d’ap-
prentissage. Une expe´rimentation comple`te s’ave`re cependant ne´cessaire pour donner une as-
sise empirique mieux fonde´e a` cette conjecture.
Re´fe´rences
Raftery, A. E. (1995). Bayesian model selection in social research. In P. Marsden (Ed.),
Sociological Methodology, pp. 111–163. Washington, DC : The American Sociological As-
sociation.
Rissanen, J. (1983). A universal prior for integers and estimation by minimum description
length. The Annals of Statistics 11(2), 416–431.
Ritschard, G. et D. A. Zighed (2003). Goodness-of-fit measures for induction trees. In
N. Zhong, Z. Ras, S. Tsumo, et E. Suzuki (Eds.), Foundations of Intelligent Systems, IS-
MIS03, Volume LNAI 2871, pp. 57–64. Berlin : Springer.
Ritschard, G. et D. A. Zighed (2004). Qualite´ d’ajustement d’arbres d’induction. Revue des
nouvelles technologies de l’information E-1, 45–67.
SPSS (Ed.) (2001). Answer Tree 3.0 User’s Guide. Chicago : SPSS Inc.
Wallace, C. S. et P. R. Freeman (1987). Estimation and inference by compact coding. Journal
of the Royal Statistical Society, Series B (Methodological) 49(3), 240–265.
Wehenkel, L. (1993). Decision tree pruning using an additive information quality measure.
In B. Bouchon-Meunier, L. Valverde, et R. Yager (Eds.), Uncertainty in Intelligent Systems,
pp. 397–411. Amsterdam : Elsevier - North Holland.
Summary
We discuss two aspects related to the scope of the BIC index for induction trees proposed in
Ritschard et Zighed (2003, 2004). The first point is about how to compute it. We show that the
BIC can easily be derived from the Likelihood Ratio Chi-square statistics used for testing the
row-column independence of contingency tables. The second aspect is related to its interest
for classification purposes. We illustrate, by means of the Titanic example, the expected link
between the BIC and the generalization error rate in terms of their evolution with respect to
the tree complexity. Finally, we sketch an experiment design for checking empirically the
conjecture that the minimal BIC ensures on average the best generalization error rate.
- 407 - RNTI-E-5
- 408 -RNTI-E-5
