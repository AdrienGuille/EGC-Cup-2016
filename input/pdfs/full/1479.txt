© Revue MODULAD, 2005 - 29 - Numéro 32 
ESTIMATION ET COMPARAISON DE NIVEAUX DE RETOUR POUR LES 
VITESSES EXTREMES DES VENTS 
 
Henri Klajnmic 
 
EDF R & D 
Département ICAME 
Groupe Statistique et Outils d’Aide à la Décision 
1, avenue du Général de Gaulle 
92141 Clamart Cedex 
Henri.Klajnmic@edf.fr 
 
Résumé 
Plusieurs modélisations des valeurs extrêmes (ici la vitesse maximum journalière du vent) sont 
possibles :  
• par les lois des valeurs extrêmes généralisées (Fréchet, Gumbel et Weibull) dont on peut estimer 
les paramètres par maximum de vraisemblance ou par moments pondérés. Les hypothèses 
d’application de ces modèles ne sont pas toujours vérifiées. En dehors de la loi de Weibull, 
estimer des niveaux de retour à plus de 50 ans donne des valeurs et des intervalles de confiance 
inexploitables. Selon les stations météo, les lois obtenues peuvent être différentes. 
• par la méthode des dépassements de seuil (POT) et la loi de Pareto généralisée. Le choix du 
seuil n’est pas simple et les hypothèses contraignantes. 
On a pu constater des résultats différents selon les méthodes employées pour le même phénomène. 
Cela montre que cette modélisation, nécessaire en raison du faible nombre de données extrêmes, 
implique une mise en oeuvre délicate et une grande prudence dans l’exploitation des résultats, une 
validation exacte ne semblant pas possible. 
 
Mots-clés : valeurs extrêmes, lois de Fréchet, Gumbel, Weibull, maximum de vraisemblance, 
moments pondérés, dépassement de seuil, loi de Pareto généralisée, vraisemblance profil, méthode 
delta. 
 
Abstract 
Several modelling of extreme values (here maximum daily wind speed) are possible:  
• Generalized Extreme Value Distributions (Fréchet, Gumbel or Weibull) whose parameters can 
be estimated either by maximum likelihood or by probability weighted moments. Hypotheses 
required for this model are not always verified. Except for the Weibull distribution, the 
estimation of return levels above 50 years gives unexploitable confidence intervals. Depending 
on the meteorological stations, the distributions may be different. 
• Peak Over Threshold method and Generalized Pareto Distribution. But to determine the 
threshold is not so easy and the required hypotheses restricting. 
Depending on the methods different results are noticed for the same phenomenon. This shows that 
this modelling, imperative due to very little extreme data, implies delicate statistical investigations 
and to be careful when using the results, an exact validation seeming not possible. 
 
Keywords: extreme values, Fréchet distribution, Gumbel distribution, Weibull distribution, 
Maximum Likelihood, Probability Weighted Moments, Peak Over Threshold, Generalized Pareto 
Distribution, profile likelihood, delta method 
© Revue MODULAD, 2005 - 30 - Numéro 32 
Introduction 
La théorie moderne des valeurs extrêmes est apparue entre 1920 et 1940, due à M. Fréchet (1927), 
R. A. Fisher et L. H. C. Tippett (1928), E. J. Gumbel (1935) et enfin B. V. Gnedenko (1943). On 
peut citer aussi les travaux antérieurs de W. E. Fuller (1914), A. A. Griffiths (1920) et L. von 
Bortkiewicz (1922). Les problèmes de valeurs extrêmes ont d’abord concerné les hauteurs des crues 
ainsi que le génie civil. 
 
On notera : 
 
 { }XXM nn ,,max 1 L=  
 
 ( )X i Ii∈ sont des variables aléatoires indépendantes et identiquement distribuées 
 
La vitesse maximum du vent est déterminée sur un petit intervalle de temps et on en recueille le 
maximum journalier, donc peut être considérée comme « un maximum de quelque chose ». 
 
On peut établir le théorème (fondamental, dû à Gnedenko) suivant : 
 
S’il existe des suites de constantes { }0>an  et { }bn  telles que ( ){ } ( )zGzabM nnn →≤−Pr , G  
étant une fonction de répartition non dégénérée, alors G  ne peut appartenir qu’à l’une des trois lois 
(dites GEV) : Weibull (à support borné supérieurement), Gumbel et Fréchet (à support non borné). 
 
Les lois de Weibull, Gumbel et Fréchet ont respectivement pour fonctions de répartition,   
 
 
 +∞<<−∞>> ba ,0,0 α  
 
 ( ) ( )
⎪⎩
⎪⎨
⎧
≥
<
⎪⎭
⎪⎬
⎫
⎪⎩
⎪⎨
⎧
⎥⎦
⎤⎢⎣
⎡ −−−=
bz
bz
a
bz
zG
,1
,exp
α
 
 
 ( ) ( ) +∞<<−∞⎭⎬
⎫
⎩⎨
⎧
⎥⎦
⎤⎢⎣
⎡ −−−= z
a
bzzG ,expexp  
 
 ( ) ( )
⎪⎩
⎪⎨
⎧
≥
⎪⎭
⎪⎬
⎫
⎪⎩
⎪⎨
⎧
⎥⎦
⎤⎢⎣
⎡ −−
<
= − bz
a
bz
bz
zG ,exp
,0
α  
 
Le premier objectif, lorsque l’on étudie une série de maximums, est de déterminer la loi et d’en 
estimer les paramètres. On se pose alors la question suivante : quelle vitesse de vent revient tous les 
dix (décennale), vingt (vicennale), cinquante ans (« cinquantennale »), cent ans (centennale) …? Ou 
bien, ayant observé xm/s, une telle vitesse revient tous les … ? 
 
Le niveau de retour zp d’un phénomène extrême est défini comme le quantile de la distribution ( ) { } pzZPzG pp −=≤= 1 . Cette valeur est donc dépassée lors d’une année quelconque avec une 
(petite) probabilité p . En utilisant la loi géométrique (voir annexe), ceci s’interprète comme la 
© Revue MODULAD, 2005 - 31 - Numéro 32 
valeur d’une variable (hauteur d’une crue, vitesse de vent ...), qui revient en moyenne tous les 
px 1=  années, par exemple le niveau de retour à 50 ans que nous utiliserons dans cet article. 
 
Nous avons étudié la vitesse maximale journalière du vent entre 1981 et 2000 sur 32 stations 
synoptiques de Météo-France. 
 
En utilisant les lois des valeurs extrêmes, on peut estimer les paramètres de ces lois soit par 
maximum de vraisemblance (Coles (2001)), soit par les moments pondérés (Hosking (1985)). Les 
estimations obtenues sont voisines. Il est plus facile de calculer les intervalles de confiance sur les 
paramètres et sur les niveaux de retour avec le maximum de vraisemblance (méthode delta) qu’avec 
les moments pondérés. On peut utiliser de plus la vraisemblance profil, qui donne des intervalles 
non symétriques. 
 
Avec nos 32 stations météo, on a constaté que l’on obtenait les trois types de lois. Lorsque l’on a 
une loi de Gumbel et surtout de Fréchet, les niveaux de retour à horizon supérieur à 50 ans 
deviennent très grands et inexploitables. La méthode est acceptable avec la loi de Weibull à support 
borné supérieurement. Une autre méthode de modélisation est possible : le dépassement de seuil. 
 
Cette dernière technique a été développée par J. Pickands, et A.C. Davison et R. L. Smith (Coles 
(2001), Davison (2003), Embrechts (2001)) : pour un seuil assez grand, la loi conditionnelle des 
dépassements du seuil sachant que l’on est au-dessus du seuil est une loi de Pareto généralisée 
(GPD), toujours en supposant des hypothèses d’indépendance. On a le résultat suivant : 
 
Pour un seuil u assez grand, sous les hypothèses du théorème sur les lois de valeurs extrêmes, alors 
la fonction de répartition de uX − sachant uX >  (loi conditionnelle) est approximativement : 
( ) ( ) ( ){ }0~1,0:,~,~11
1
>+>−+=⎟⎠
⎞⎜⎝
⎛ +−=
−
σξµξσσσ
ξ ξ yyyuyyH  
 
Le paramètre ξ  est le même que celui de la modélisation par les lois des valeurs extrêmes. Le 
principal problème est de choisir le seuil et les méthodes proposées (Coles (2001)) ne sont pas 
simples à mettre en oeuvre. On a constaté que les niveaux de retour obtenus ne sont pas les mêmes 
selon la modélisation employée (GEV ou GPD), et que la vraisemblance profil n’est pas toujours 
applicable. 
 
Enfin, tout ce que nous utilisons pour des maximums pourrait être appliqué de manière similaire 
pour des minimums (températures, sécheresse …). 
 
Les données 
Nous disposons de vingt ans de vitesses maximales journalières de vent (du 1er janvier 1981 au 31 
décembre 2000) sur 32 stations synoptiques de Météo-France ne constituant pas un échantillon 
ressemblant à l’ensemble des stations. Il y a une grande diversité de situations : on sait que selon les 
régions les conditions de vent et les vitesses peuvent être très différentes. Les vitesses maximales 
peuvent varier du simple au double (60 m/s à la Pointe du Raz, 55 m/s à la Pointe de Chassiron, 
contre 29 m/s à Ambérieu, 31 m/s à Besançon). 60 m/s représente 60x3.6=216 km/h ( !) et 29 m/s 
104.4 km/h. Il y a peu de valeurs manquantes (de 0 à 5 % des données). Il y a rarement des vitesses 
journalières nulles, ce qui aurait pu être une erreur de mesure. Les coefficients d’asymétrie sont 
tous positifs de 0.55 à 2.25. Les coefficients d’aplatissement sont positifs et vont de 0.32 à plus de 
7... Enfin, la tempête de fin décembre 1999 ne correspond pas nécessairement à la plus forte valeur 
observée : il y a eu des événements plus extrêmes en 1987 et 1990 et les résultats varient selon la 
© Revue MODULAD, 2005 - 32 - Numéro 32 
région. Dans la suite, nous nous limiterons à trois stations que nous appellerons A, C1 et C2. 
Logiciels utilisés 
Il existe quelques logiciels pour pouvoir travailler sur les valeurs extrêmes sans tout programmer 
soi-même. Nous avons utilisé les fonctions proposées par S. Coles (2001) (ismev) et celles très 
voisines proposées par A. McNeil (evis4). Ces fonctions, initialement écrites en S (S-Plus est un 
produit industriel diffusé par Insightful, dont nous avons utilisé la version 6.2), ont été portées sous 
R (logiciel libre ressemblant beaucoup à S : http://www.r-project.org/) par A. Stephenson (evir et 
ismev). Les documentations sont assez succinctes et il faut parfois regarder le code pour bien les 
utiliser, mais il ne semble pas y avoir pour l’instant de solution plus commode. SAS, par exemple, 
ne fournit pas de procédure pour travailler sur les valeurs extrêmes. 
 
Modélisation par les valeurs extrêmes 
Loi des valeurs extrêmes 
Soit { }XXM nn ,,max 1 L= , ensemble de n  variables aléatoires indépendantes de même fonction 
de répartition F  et cherchons la distribution de probabilité de ce maximum. Le théorème suivant 
constitue la base de la modélisation :  
S’il existe deux suites de constantes réelles ( )0>an  et ( )bn  telles que : 
( )zGz
a
bMP
n
nn →
⎭⎬
⎫
⎩⎨
⎧ ≤− , (convergence faible),G étant une fonction de répartition non 
dégénérée, alors G ne peut appartenir qu’à l’une des trois lois suivantes : Weibull, Gumbel ou 
Fréchet. Ces lois peuvent s’exprimer sous une forme unifiée (dite de von Mises-Jenkinson) : 
( )
⎪⎭
⎪⎬
⎫
⎪⎩
⎪⎨
⎧
⎥⎦
⎤⎢⎣
⎡ ⎟⎠
⎞⎜⎝
⎛ −+−=
−
σ
µξ
ξzzG 1exp
1
 pour 
⎭⎬
⎫
⎩⎨
⎧ >⎟⎠
⎞⎜⎝
⎛ −+ 01: σ
µξ zz avec ξ  (paramètre de forme), 
0>σ (paramètre d’échelle) et µ  réel (paramètre de position). La loi de Gumbel s’obtient en 
faisant 0→ξ . 
L’inconvénient pour nos données est qu’il peut y avoir des épisodes venteux (donc l’indépendance 
n’est pas vraiment justifiée), présence de saisonnalité (mauvais temps en hiver par exemple et les 
vitesses ne suivraient pas la même loi). Regrouper par semaine, mois, trimestre ou année fait perdre 
de l’information. Dans le cas des vitesses de vent, c’est la répétition de vents forts qui peut causer 
des dégâts aux bâtiments et le maximum dans la semaine ou le mois fait perdre cette notion.  
© Revue MODULAD, 2005 - 33 - Numéro 32 
Niveau de retour 
On définit le niveau de retour z p  par : ( ) ⎪⎭
⎪⎬
⎫
⎪⎩
⎪⎨
⎧
⎥⎥⎦
⎤
⎢⎢⎣
⎡
⎟⎟⎠
⎞
⎜⎜⎝
⎛ −+−=−=
−
σ
µξ
ξ
z
pzG
p
p 1exp1
1
  
ce qui nous donne, en inversant G  : ( ){ }[ ]( ){ }⎪⎩
⎪⎨
⎧
=−−−
≠−−−−=
−
0,1loglog
0,1log1
ξσµ
ξξ
σµ ξ
p
p
z p .  
L’estimateur au maximum de vraisemblance de z p  est obtenu en substituant dans la formule les 
estimateurs au maximum de vraisemblance des trois paramètres des lois ξ , µ et σ (propriété 
d’invariance du maximum de vraisemblance). 
Intervalle de confiance par la méthode delta 
Le niveau de retour est une fonction (réelle) des trois variables ξ ,µ et σ . On note z p∇  le vecteur 
(gradient) des dérivées partielles de z p  par rapport à ξ ,µ  etσ  : 
=⎥⎦
⎤⎢⎣
⎡
∂
∂
∂
∂
∂
∂
ξσµ
zzz ppp
T
,, ( ) ( )[ ]yyyy pppp log1,1,1 121 ξξξ ξσξσξ −−−−−− −−−− , 
 en posant ( )py p −−= 1log . 
Alors on a une expression approchée pour la variance du niveau de retour : 
 ( ) zVzzVar pTpp ∇∇≈ˆ , V  étant la matrice des variances-covariances des paramètres. On utilise 
ensuite la loi normale pour avoir un intervalle de confiance, par exemple ( )[ ]zVarz pp ˆ96.1ˆ ± . 
Intervalle de confiance par vraisemblance profil 
Cette méthode consiste à choisir un des paramètres (ici z p ) et à considérer les autres comme des 
paramètres de nuisance. Considérons un ensemble de valeurs du paramètre d’intérêt (le niveau de 
retour). Pour chacune de ces valeurs, fixée, on calcule le maximum de vraisemblance (par rapport 
aux autres paramètres) et on trace la courbe obtenue. L’horizontale située en dessous du maximum 
de cette courbe à une distance de ( )αχ −15.0 21  (quantile à ( )α−1 % du χ 2  à un degré de liberté 
pour un paramètre à une dimension) coupe la courbe en deux points qui sont les extrémités de 
l’intervalle recherché. On peut obtenir des intervalles de confiance non symétriques, contrairement 
à la méthode delta. 
Moments pondérés 
Il y a une alternative au maximum de vraisemblance : les moments pondérés. S’ils permettent 
l’estimation des paramètres, avoir des intervalles de confiance exige des calculs compliqués. 
Pour L,2,1,0=r , définissons ( ){ }( )XFXE rr =β . Si 0=r , c’est la moyenne de la variable 
aléatoire X de fonction de répartition ( )xF . En utilisant l’échantillon x  trié par ordre croissant, on 
montre que ( )( ) ( )( )( ) ( )∑ −−−
−−−=
=
− n
j
jr xrnnn
rjjj
nb
1
1
21
21
L
L est un estimateur sans biais de β r . 
Si la fonction de répartition est une loi GEV de la forme : 
( ) ( ){ }[ ]σµξ ξ−+−= −xxF 1exp 1  si 0≠ξ et ( ) ( ){ }[ ]σµ−−−= xxF expexp si 0=ξ , on démontre 
© Revue MODULAD, 2005 - 34 - Numéro 32 
que l’on peut estimer les paramètres de cette loi par les formules suivantes (Hosking (1985)) : 
3log
2log
3
2
02
01 −−
−=
bb
bbc , ( )cc 29554.28590.7ˆ +−=ξ , 
( )( )( )21ˆ1 ˆ2ˆ ˆ01 ξξ ξσ −−Γ −−= bb , ( ){ }ξξσµ ˆ 1ˆ1ˆˆ 0 −−Γ−= b . 
Γ  est la fonction gamma d’Euler ( ) 0,0 1 >∫=Γ −+∞ − xdtetx tx . 
Le niveau de retour à N  années s’écrit : ⎥⎥⎦
⎤
⎢⎢⎣
⎡
⎟⎟⎠
⎞⎜⎜⎝
⎛ ⎟⎠
⎞⎜⎝
⎛ −−−−=
−
NzN 365
11log1ˆ
ˆˆˆ
ξˆ
ξ
σµ .  
Nous prendrons 50=N . Les résultats sont proches de ceux au maximum de vraisemblance. 
 
Résultats obtenus 
 
Comme les vitesses de vent sont exprimées en nombres entiers de m/s, elles ont été « jittérisées » en 
ajoutant un nombre aléatoire suivant une loi uniforme sur [-0.5 +0.5]. Cette petite perturbation évite 
les nombreux ex æquo lorsque l’on utilisera les méthodes à dépassement de seuil. La nature de la 
loi change selon les stations. Les intervalles de confiance seront toujours à 95%. 
 
Dans la démonstration du théorème sur la loi des valeurs extrêmes, on découpe les données en blocs 
de longueur fixe, c’est cette idée que nous retenons en ajustant les modèles sur les maximums 
mensuels, trimestriels ou en blocs de longueur quelconque. Nous allons voir que l’on obtient parfois 
des résultats assez surprenants. 
Station C1 
On obtient la loi de Weibull, la plus intéressante car elle suppose l’existence d’une vitesse limite 
ξσµ −=z0 que l’on ne peut dépasser. Pour la série initiale (une seule valeur manquante, avant 
jittérisation) : ( )118.0,74.3,18.12 −=== ξσµ . Les niveaux de retour à 50 ans sont : 33.3 
[32.3 34.3] par la méthode delta et par vraisemblance profil : [33.1 35]. 
 
Considérons maintenant la série jittérisée. On obtient : ( )119.0,76.3,18.12 −=== ξσµ . Le niveau 
de retour à 50 ans est 33.9 et l’intervalle de confiance par la méthode delta [33 34.8]. La vitesse 
limite est estimée à 43.6. Il y a peu de différence avec la série initiale. 
 
Considérons maintenant la série des maximums mensuels (20 ans : 240 mois). On obtient ( )031.0,81.2,45.21 −=== ξσµ , ξ n’est pas significativement différent de zéro. Avec la série 
trimestrielle ( )065.0,86.2,43.24 −=== ξσµ , ξ  n’est pas significativement différent de zéro. 
 
En utilisant la loi de Gumbel, on obtient pour la série mensuelle ( )78.2,40.21 == σµ  avec pour 
niveau de retour à 50 ans 39.2 (intervalle de confiance par la méthode delta : [37.2 41.1]. Pour la 
série trimestrielle ( )82.2,33.24 == σµ  avec pour niveau de retour à 50 ans 39.3 (intervalle de 
confiance par la méthode delta : [36.5 42.1]). La modélisation de la série annuelle donne la loi de 
Gumbel ( )02.2,57.28 == σµ  avec pour niveau de retour à 50 ans 36.5 (intervalle de confiance par 
la méthode delta : [33.1 39.8]). 
 
On notera que le niveau de retour obtenu avec la série journalière est très différent des niveaux de 
retour obtenus avec les séries mensuelle et trimestrielle. La série annuelle donne encore un résultat 
© Revue MODULAD, 2005 - 35 - Numéro 32 
différent. 
Station A 
Si l’on modélise la série journalière jittérisée (une seule valeur manquante), on trouve : ( )227.0,00.2,43.7 === ξσµ , c’est une loi de Fréchet (donc à support non borné vers les valeurs 
positives) car ξ  est significativement différent de zéro. Le niveau de retour à 50 ans est 80.2 et 
l’intervalle de confiance par la méthode delta [71.7 88.7], ce qui paraît très élevé et peu réaliste. La 
cause de la loi de Fréchet est la présence de quelques vitesses journalières (moins de 10) très au-
dessus des autres. La queue de distribution s’aplatit donc très lentement, les dix valeurs les plus 
élevées étant 28.45, 28.52, 28.67, 29.25, 29.78, 29.93, 30.95, 30.98, 31, 34.32. 
 
Modélisons la série des maximums mensuels. On trouve ( )162.0,51.4,20.17 −=== ξσµ , on a une 
loi de Weibull et le niveau de retour à 50 ans devient 35.16 et l’intervalle de confiance par la 
méthode delta [31.3 39]. En utilisant la vraisemblance profil : [32.5 40.7]. Par la méthode des 
moments pondérés ( )155.0,60.4,16.17 −=== ξσµ  et le niveau de retour à 50 ans : 35.8. On peut 
voir en annexe la vraisemblance profil. 
 
Modélisons la série des maximums trimestriels. On trouve ( )225.0,90.3,79.21 −=== ξσµ , on a 
une loi de Weibull et le niveau de retour à 50 ans devient 33.85 et l’intervalle de confiance par la 
méthode delta [31.3 36.6]. En utilisant la vraisemblance profil : [32.1 38.6]. Par la méthode des 
moments pondérés ( )238.0,99.3,80.21 −=== ξσµ  et le niveau de retour à 50 ans : 33.80. 
 
Si maintenant, on utilise la série des 20 maximums annuels, on trouve la loi de Gumbel : ( )2.54  ,26.50 == σµ  et le niveau de retour à 50 ans est 36.4 et un intervalle de confiance par la 
méthode delta [32.5 40.2]. 
 
On doit noter le changement de nature de la loi (on peut vérifier qu’il se produit avec une taille de 
bloc de l’ordre de 20) dû sans doute au manque de robustesse du modèle aux hypothèses. Les 
valeurs des niveaux de retour selon le degré d’agrégation sont voisines, mais il n’est pas sûr que 
l’on réponde vraiment à la question du niveau de retour à 50 ans d’un maximum journalier.  
Station C2 
La série comporte huit valeurs manquantes alors qu’il n’y en avait qu’une pour A et C1. Avec 7305 
valeurs, 1% de valeurs manquantes représente 73 jours. Cela peut poser problème s’il manque un 
mois ou plus. C’est pour cette raison que nous exposons seulement le traitement sur trois stations. 
La vitesse maximum observée pour C2 est 43.89 m/s. 
 
La modélisation de la série journalière jittérisée donne la loi de Gumbel ( )3.12  ,32.8 == σµ , le 
niveau de retour à 50 ans est 38.92 (intervalle de confiance par la méthode delta [38.3 39.5]). 
 
Pour la série mensuelle, on a également la loi de Gumbel ( )3.82  ,11.17 == σµ , le niveau de retour 
à 50 ans passe à 41.5 (intervalle de confiance par la méthode delta [38.9 44.2]). 
 
Avec la série trimestrielle, on a la loi de Gumbel ( )4.22  ,53.20 == σµ , le niveau de retour à 50 ans 
passe à 42.9 (intervalle de confiance par la méthode delta [38.6 47.2]). 
 
Enfin, avec la série annuelle, on a la loi de Gumbel ( )4.13  ,92.26 == σµ , le niveau de retour à 50 
ans passe à 43 (intervalle de confiance par la méthode delta [38.7 49.3]). 
 
© Revue MODULAD, 2005 - 36 - Numéro 32 
Conclusions 
La modélisation donne des résultats pas toujours cohérents et on obtient des niveaux de retour 
parfois plutôt différents. On se rend compte également que selon les stations (et les régions), les 
situations météorologiques peuvent être différentes en raison d’une part des épisodes venteux et 
d’autre part du caractère « très extrême » de certaines tempêtes. Le fait d’agréger par mois 
etc...change la nature de l’estimation : estimer à partir d’observations journalières des niveaux de 
retour à 50 ans. Le maximum de vraisemblance semble plus commode d’application que les 
moments pondérés. Il serait plus judicieux d’utiliser la vraisemblance profil, les intervalles de 
confiance semblant asymétriques. Dans la suite, nous allons utilser les techniques plus récentes de 
dépassement de seuil et de processus ponctuel. 
 
Résumé 
Station C1, niveau de retour à 50 ans 
33.3 (série initiale journalière, loi de Weibull), 33.9 (série journalière jittérisée, loi de Weibull), 
39.2 (série mensuelle, loi de Gumbel) 39.3 (série trimestrielle, loi de Gumbel).  
Station A, niveau de retour à 50 ans 
80.2 (série journalière jittérisée, loi de Fréchet), 35.16 (série mensuelle, loi de Weibull, maximum 
de vraisemblance), 35.8 (série mensuelle, loi de Weibull, moments pondérés), 33.85 (série 
trimestrielle, loi de Weibull, maximum de vraisemblance), 33.8 (série trimestrielle, loi de Weibull, 
moments pondérés), 36.4 (série annuelle, loi de Gumbel, maximum de vraisemeblance). 
Station C2, niveau de retour à 50 ans 
38.92 (série journalière jittérisée, loi de Gumbel), 41.5 (série mensuelle, loi de Gumbel), 42.9 (série 
trimestrielle, loi de Gumbel), 43 (série annuelle, loi de Gumbel). 
Méthode de dépassement de seuil 
Introduction 
Cette méthode, basée sur les travaux de J. Pickands, A.C. Davison et R. L. Smith est plus récente. 
Elle va impliquer le choix d’un seuil au-delà duquel le modèle peut être appliqué. Elle est sensible 
aux perturbations sur les données et aux hypothèses d’indépendance. 
On montre que la loi conditionnelle de uX −  sachant que uX >  est approximativement : 
( ) ⎟⎠
⎞⎜⎝
⎛ +−=
−
σ
ξ ξ
~11
1yyH  sur ( ){ }0~1,0: >+> σξyyy , uxy −= et ( )µξσσ −+= u~  si 0≠ξ . 
Dans le cas où 0=ξ , on a ( ) ⎟⎠
⎞⎜⎝
⎛−−= σ~exp1
yyH avec 0>y . Le paramètre de forme ξ  est le même 
que celui des lois GEV du paragraphe précédent. Cette famille de lois constitue les lois de Pareto 
généralisées (GPD en anglais). 
 
Comment estimer des niveaux de retour ? 
 
Supposons que le modèle de dépassement au-dessus d’un seuil u  soit de ce type, alors on a la 
relation : 
© Revue MODULAD, 2005 - 37 - Numéro 32 
{ } ⎥⎦
⎤⎢⎣
⎡ ⎟⎠
⎞⎜⎝
⎛ −+=>>
−
σξ
ξuxuXxXP 1
1
. D’où { } { } ⎥⎦
⎤⎢⎣
⎡ ⎟⎠
⎞⎜⎝
⎛ −+>=>
−
σξ
ξuxuXPxXP 1
1
. Et on estime 
{ } ς uuxp =>  par la fréquence relative des observations au-dessus de u . Ce modèle est sensible 
aux perturbations des observations, car un certain nombre de celles-ci peuvent passer de part et 
d’autre du seuil, modifiant ς u . Observer un phénomène pendant 50 ans avec des observations 
journalières représente 1825050365 =×=m mesures. 
 
La « clustérisation » exprime le fait que des phénomènes extrêmes se produisent souvent de 
manière non indépendantes et forment des agrégats (clusters). Pour le dépassement de seuil, 
l’hypothèse d’indépendance est contraignante. Il faut donc envisager la « déclustérisation » : 
lorsque l’on dépasse le seuil, on va exiger un certain intervalle de temps (i.e. un certain nombre de 
valeurs dans la série) en-dessous du seuil pour dire que les dépassements sont indépendants. Sinon, 
ils seront regroupés au sein du même agrégat et on prendra le maximum de l’agrégat. 
 
Niveau de retour 
 
Le niveau de retour z N dépassé en moyenne toutes les N années (m observations) est donné par la 
relation : 
m
uzN
u
11
1
=⎥⎦
⎤⎢⎣
⎡ ⎟⎠
⎞⎜⎝
⎛ −+
−
σξς
ξ
. 
Selon les valeurs de ξ  on a les formules : 
( )
( )[ ]⎪⎩⎪⎨
⎧
≠−+=
=+=
0,1
0,log
ξςξ
σ
ξςσ
ξ
uN
uN
muz
muz
 
Résultats 
Station A 
Tout d’abord, nous allons modéliser la série mensuelle avec un modèle à seuil. On va admettre qu’il 
y a indépendance entre les maximums mensuels, mais il faudrait vérifier qu’il n’y a pas d’épisodes 
venteux à cheval sur deux mois consécutifs. 
 
Rappelons que nous avons légèrement perturbé les données (nombres entiers de m/s) de façon à 
éviter les problèmes d’ex æquo. Comment déterminer un seuil ? On peut démontrer (Coles, 2001) 
que : 
 
Si u0 est une valeur au delà de laquelle le modèle Pareto s’applique, alors, pour uu> 0 , ( )uXuXE >− est une fonction linéaire de u . 
 On tracera donc ( )( ) ⎪⎭
⎪⎬
⎫
⎪⎩
⎪⎨
⎧ <⎟⎟⎠
⎞
⎜⎜⎝
⎛ ∑ −
=
xuux
n
u
n
i
i
u
u
max
1
:1, avec ( )Xx imaxmax =  et ( ) ( ),,,1 xx nuL les 
observations qui dépassent u . Il faut faire un compromis sur la valeur du seuil, trop bas, les 
hypothèses asymptotiques ne sont pas valides, trop élevé, il n’y a pas assez de valeurs pour une 
estimation fiable. 
 
Avec la série mensuelle, on va choisir un seuil de 25 m/s (voir figure 2 en annexe) et on obtient ( )89.2~,194.0 =−= σξ , le niveau de retour à 50 ans est alors 33.7 et comme intervalle de confiance 
par la méthode delta [31.1 36.3]. Avec un seuil de 26, on a un niveau de retour de 33.8 avec un 
© Revue MODULAD, 2005 - 38 - Numéro 32 
intervalle de confiance [30.6 37] . Les résultats sont proches, mais on n’a pas pu utiliser la 
vraisemblance profil et le paramètre ξ n’est pas significativement différent de zéro. 
Station C1 
Pour C1, sur la série mensuelle, avec un seuil de 26 m/s, on trouve ( )07.2~,098.0 == σξ , ξ n’est 
pas significativement différent de zéro et le niveau de retour à 50 ans en imposant ce paramètre à 
zéro est de 35.8 [31.5 40.1] par la méthode delta. On peut voir en annexe (figure 3) la forme 
curieuse de la vraisemblance profil, très plate et l’intervalle de confiance qui « s’allonge vers les 
fortes valeurs ». 
Station C2 
Avec un seuil de 25 m/s, on trouve ( ) 2.72~,0.192 == σξ , mais ξ n’est pas significativement 
différent de zéro. Le niveau de retour en imposant ce coefficient à zéro est 37.1 avec un intervalle 
de confiance [30.8 43.3]. La vraisemblance profil ne semble pas applicable. 
 
Déclustérisation 
 
Pour finir, nous allons modéliser la série journalière pour la station A avec la méthode de 
dépassement de seuil, mais en prenant en compte la présence d’agrégats. 
 
Si on fixe un seuil à 25 et on impose deux journées en-dessous du seuil pour séparer les clusters, on 
trouve ( )14.025.0−=ξ  et 25.3~ =σ  et avec un seuil de 26 et deux journées en-dessous du seuil : 
( )20.014.0−=ξ  et 48.2~ =σ . Si on utilise le modèle sans déclustériser la série, on trouve 
( )14.019.0−=ξ  et 89.2~ =σ  avec 37 dépassements au lieu de 33 en déclustérisant. 
Résumé 
Station C1, niveau de retour à 50 ans 
35.8 (série mensuelle, seuil 26, paramètre ξ  contraint à zéro) 
Station A, niveau de retour à 50 ans 
33.7 (série mensuelle, seuil 25), 33.8 (série mensuelle, seuil 26) ; vraisemblance profil non 
utilisable. 
Station C2, niveau de retour à 50 ans 
37.1 (série mensuelle, seuil 25, paramètre ξ  contraint à zéro) ;  vraisemblance profil non utilisable. 
Conclusions 
On constate que les phénomènes de vents extrêmes ne se modélisent pas de la même façon selon les 
stations. On peut remarquer des valeurs un peu détachées de l’ensemble des observations. On peut 
se poser la question de les retirer. Mais il y a un paradoxe à retirer des valeurs atypiques lorsque 
l’on cherche justement à les modéliser, on doit donc tout prendre en compte, en espérant que la 
mesure reste valide. 
 
Travailler sur les valeurs extrêmes nécessite l’emploi de modèles car on va procéder à une 
extrapolation. Les conditions d’application de ces modèles paraissent bien plus contraignantes 
qu’on ne le pense (indépendance, loi asymptotique …). Ces techniques paraissent peu robustes. 
© Revue MODULAD, 2005 - 39 - Numéro 32 
Selon le niveau d’agrégation, les résultats peuvent varier. Le maximum de vraisemblance semble 
plus commode d’emploi. 
 
Nous avons disposé de deux logiciels libres dédiés à ces méthodes. Ceux-ci sont parfois peu 
documentés et il faut donc regarder de près la théorie tout en dépouillant les résultats. L’usage de la 
vraisemblance profil reste délicat si l’on ne dispose pas de fonctions déjà écrites.  
 
Des idées à envisager seraient l’étude et l’estimation de l’indice extrémal et la prise en compte de 
connaissances a priori (techniques bayésiennes). 
Bibliographie 
 
[1] Coles S. (2001), An Introduction to Statistical Modeling of Extreme Values, Editions Springer 
[2] A. C. Davison (2003) Statistical Models, Cambridge University Press  
[3] Embrechts P., Klüppelberg C., Mikosch T., (2001) Modelling Extremal Events for Insurance 
and Finance, Editions Springer 
[4] E. J. Gumbel (1958), Statistics of extremes, Columbia University Press 
[5] Hosking J. R. M., Wallis J. R., Wood E. F. (1985), Estimation of the generalized extreme-value 
distribution by the method of probability-weighted moments, Technometrics, vol. 27, no. 3, 
pages 251-261 
 [6] Resnick S. I. (1987), Extreme Values, Regular Variation, and Point Processes, Editions 
Springer 
Annexes 
Loi géométrique 
Considérons une suite d’essais indépendants où à chaque essai, un événement a une probabilité 
donnée constante 10 << p de se produire. Le numéro de l’essai où cet événement se produit pour la 
première fois suit une loi géométrique : { } ( )ppxXP x−== −1 1pour L,3,2,1=x . On démontre 
que ( ) ( ) pppxXE
x
x 11
1
1 =∑ −= ∞
=
− (dériver la série ( )∑ −= +∞
=0
1)(
x
xppg ). Ce résultat est utilisé pour 
interpréter les niveaux de retour. 
© Revue MODULAD, 2005 - 40 - Numéro 32 
Figures 
 
figure 1 : exemple de vraisemblance profil 
 
figure 2 : exemple de choix du seuil 
 
 
© Revue MODULAD, 2005 - 41 - Numéro 32 
 
 
figure 3 : modèle à dépassement de seuil : vraisemblance profil 
 
 
