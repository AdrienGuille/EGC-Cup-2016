Analyse en Facteurs : pre´sentation et
comparaison des logiciels
SAS, SPAD et SPSS
Marie Chavent1, Vanessa Kuentz1, Je´roˆme Saracco1,2
1 Universite´s Bordeaux 1 et 2,
IMB, UMR CNRS 5251,
351 Cours de la Libe´ration, 33405 Talence Cedex, France
vanessa.kuentz,marie.chavent@math.u-bordeaux1.fr
2 Universite´ Montesquieu - Bordeaux 4,
GREThA, UMR CNRS 5113,
Avenue Le´on Duguit, 33608 Pessac Cedex, France
jerome.saracco@u-bordeaux4.fr
Abstract In data analysis, factorial methods are essential. These techniques can
be used as an end in themselves, seeking to highlight underlying common factors in
a group of variables. They can also be used as input to another analysis. Then, they
consist in data dimension reduction and operate by replacing the original variables,
sometimes highly correlated, by a smaller number of linearly independent variables.
Factor Analysis (F.A.) is one possible method for quantitative data. This article
aims at presenting in a synthetic way the F.A. model, rarely described in French
books, but frequent in the Anglo-Saxon literature, and often available in softwares.
The presentation of the estimation techniques for the F.A. model enables to estab-
lish the existing connection between Principal Component Analysis (P.C.A.) and
F.A. The usefulness of rotation techniques, which can facilitate the interpretation
of the results, will also be shown. An application on crime data of American cities
will be carried out and will allow to describe the results provided by three of the
most used statistical softwares : SAS, SPAD and SPSS. Then it will help to clarify
the vocabulary, sometimes confused for the user.
Keywords : Factor Analysis, Principal Component Analysis, Singular Value De-
composition, Rotation.
Re´sume´ En analyse des donne´es, les me´thodes factorielles sont fondamentales. Ces
techniques peuvent eˆtre utilise´es comme but en soi, il s’agit alors de faire ressortir des
facteurs sous-jacents communs a` un groupe de variables. Elles peuvent e´galement
constituer une e´tape pre´alable a` d’autres e´tudes. Elles consistent alors a` re´duire
la dimension des donne´es en remplac¸ant les variables d’origine, qui peuvent eˆtre
corre´le´es, par un plus petit nombre de variables line´airement inde´pendantes. Lorsque
les donne´es sont quantitatives, l’Analyse en Facteurs (A.F.) est une des me´thodes
possibles. L’objectif de cet article est de dresser une pre´sentation synthe´tique du
mode`le d’A.F., peu de´veloppe´ dans les manuels francophones, mais fre´quent dans
la litte´rature anglo-saxonne, et souvent pre´sent dans les logiciels statistiques. La
c© Revue MODULAD, 2007 -1- Nume´ro 37
pre´sentation des techniques d’estimation du mode`le d’A.F. permet d’e´tablir le lien
existant entre l’Analyse en Composantes Principales (A.C.P.) et l’A.F. Il s’agit
e´galement de montrer l’utilite´ des techniques de rotation, qui peuvent faciliter l’in-
terpre´tation des re´sultats. Un exemple d’application sur des donne´es de criminalite´
de villes ame´ricaines permet enfin de de´crire les re´sultats fournis par trois des lo-
giciels statistiques les plus utilise´s : SAS, SPAD et SPSS, et ainsi de clarifier le
vocabulaire, parfois confus pour l’utilisateur.
Mots-cle´s : Analyse en Facteurs, Analyse en Composantes Principales, De´composition
en Valeurs Singulie`res, Rotation.
1 Introduction
L’A.F. trouve son origine en psychome´trie lorsqu’en 1904, Spearman de´veloppe une
the´orie psychologique selon laquelle l’esprit humain s’explique par un facteur commun a`
tous les individus et par plusieurs facteurs spe´cifiques a` chacun. Ce mode`le est ge´ne´ralise´
pour plusieurs facteurs communs par Garnett en 1919. De nombreuses applications sont
alors re´alise´es pour de´terminer un nombre relativement faible de tests qui permettraient
de de´crire l’esprit humain de fac¸on aussi comple`te que possible.
Ainsi, l’A.F. vise a` e´crire chaque variable ale´atoire du proble`me en fonction de facteurs
sous-jacents communs a` toutes les variables, et d’un facteur spe´cifique ou unique a` la
variable ale´atoire conside´re´e. Il repose sur diffe´rentes hypothe`ses dont principalement la
non corre´lation des facteurs communs. Diffe´rentes me´thodes d’estimation existent, les
plus courantes sont l’estimation via les composantes principales, la me´thode du facteur
principal et le maximum de vraisemblance. L’estimation du mode`le d’A.F. via l’A.C.P.
ne garantit pas que les hypothe`ses du mode`le soient ve´rifie´es. Cependant cette technique
est la plus utilise´e car elle fournit souvent une approximation convenable.
Cet article met e´galement en lumie`re un point essentiel de l’A.F. : le choix du nombre q
de facteurs communs. Diffe´rents crite`res empiriques et the´oriques existent pour le choisir.
Nous insisterons sur le fait que ces re`gles sont une aide partielle qui ne doit pas se sub-
stituer a` une interpre´tation rigoureuse des re´sultats. Notons que l’enjeu de ce choix est
majeur car la qualite´ des re´sultats en de´pend.
Suite a` l’estimation du mode`le d’A.F., la lecture des re´sultats peut s’ave´rer de´licate. Les
facteurs obtenus peuvent eˆtre difficiles a` interpre´ter, sembler ne pas avoir d’inte´reˆt pour
l’e´tude, ou ne pas exliquer le phe´nome`ne conside´re´, etc. Des re´sultats sont pourtant parfois
pre´sents, mais leur lecture n’est pas directe et intuitive. L’utilisateur peut alors passer a`
coˆte´ de re´sultats importants. Une rotation orthogonale des facteurs peut aider dans cette
phase. La justification de la possibilite´ d’effectuer une rotation provient de la non-unicite´
de la solution du mode`le d’A.F. Nous verrons de plus que la rotation est possible en
A.C.P. a` condition d’effectuer convenablement la transformation. Bien que les techniques
de rotation peuvent faciliter de fac¸on significative la lecture des re´sultats, elles sont peu
pre´sente´es dans les ouvrages francophones, contrairement a` leurs voisins anglo-saxons.
L’utilite´ de la rotation des facteurs sera mise en exergue sur une application concernant la
criminalite´ de seize villes ame´ricaines (donne´es issues de U.S. Statistical Abstract, 1970).
c© Revue MODULAD, 2007 -2- Nume´ro 37
Enfin, l’estimation du mode`le peut se faire a` l’aide de logiciels statistiques, comme SAS,
SPAD et SPSS. Le vocabulaire employe´ diffe`re d’un logiciel a` l’autre et peut rapidement
devenir source de confusion. L’exemple d’application pre´cise ce vocabulaire et pourra ainsi
aider les utilisateurs dans la lecture des sorties nume´riques des logiciels.
Le pre´sent article s’articule autour de cinq parties. Le mode`le d’A.F. est pre´sente´ a` la
section 2. L’estimation des parame`tres du mode`le est ensuite de´crite a` la section 3. Les
techniques de rotation des facteurs, facilitant la de´tection de groupes de variables corre´le´es,
sont pre´sente´es a` la section 4. Enfin, a` la section 5, une application de ce mode`le d’A.F.
est re´alise´e sur des donne´es de criminalite´ dans diffe´rentes villes des Etats-Unis et permet
de comparer les re´sultats fournis par les trois logiciels statistiques SAS, SPAD et SPSS.
2 Le mode`le d’A.F.
Soit x = (x1, x2, . . . , xp)′ un vecteur ale´atoire de Rp d’espe´rance µ ∈ Rp. On note
x˜ = x− µ la version centre´e de x.
Le mode`le d’A.F. s’e´crit :
x˜ = Aqf + e
(p× 1) (p× q)(q × 1) (p× 1) (1)
ou` :
– Aq est une matrice (p×q) de coefficients aαj , j = 1, . . . , p, α = 1, . . . , q (”loadings” en
anglais). Elle est appele´e matrice de saturation (”factor loadings matrix” ou ”factor
pattern matrix”).
– f = (f 1, . . . , f q)′ est un vecteur ale´atoire de Rq, compose´ des q facteurs communs
(”common factors”) aux p variables ale´atoires x˜1, x˜2, . . . , x˜p.
– e = (e1, . . . , ep)′ est un vecteur ale´atoire centre´ de Rp, compose´ des p facteurs
spe´cifiques (ou uniques) (”unique factors”) a` chaque variable x˜j, j = 1, . . . , p.
Il de´coule de (1) et de E(e) = 0 la proprie´te´ suivante :
E(f) = 0. (2)
Pour tout j = 1, . . . , p, on a :
x˜j =
q∑
α=1
aαj f
α + ej. (3)
Chaque variable x˜j s’e´crit comme la somme d’une combinaison line´aire de facteurs f 1, . . . , f q
communs a` toutes les variables x˜1, . . . , x˜p et d’un facteur ej spe´cifique a` la variable
conside´re´e x˜j.
On insiste sur le fait que les facteurs communs f 1, . . . , f q sont ale´atoires. Ainsi, le mode`le
d’A.F. est souvent de´signe´ comme un mode`le a` effets ale´atoires ou mode`le structurel
(Baccini et Besse, 2005).
Le mode`le (1) repose sur plusieurs hypothe`ses.
(H1) : E(ff ′) = Iq, ou` Iq est la matrice identite´ (q × q).
c© Revue MODULAD, 2007 -3- Nume´ro 37
(H2) : E(ee′) = Ξ, ou` Ξ = diag(ξj, j = 1, . . . , p).
(H3) : E(ef ′) = 0.
L’hypothe`se (H1) signifie que les facteurs communs f
α, α = 1, . . . , q, sont non corre´le´s
et de variance 1. Cette hypothe`se de non corre´lation des facteurs s’explique par le fait
que l’on souhaite exprimer les variables ale´atoires x˜j en fonction du plus petit nombre de
facteurs possible, et donc e´viter des redondances.
L’hypothe`se (H2) signifie que les facteurs uniques e
j, j = 1, . . . , p, ne sont pas corre´le´s. Ils
expriment pour chaque variable la part non explique´e par les facteurs communs. Ils ont
chacun une variance spe´cifique ξj.
L’hypothe`se (H3) traduit le fait que chaque variable e
j, j = 1, . . . , p, traduit la part
spe´cifique a` la variable x˜j qui n’a pu eˆtre exprime´e par les facteurs communs fα, α =
1, . . . , q, donc les variables ej et fα, ne sont pas corre´le´es.
On note Σ la matrice de variance covariance de x. On de´duit du mode`le (1) que :
E(x˜x˜′) = AqE(ff ′)A′q + E(ee′) et donc
Σ = AqA
′
q + Ξ. (4)
L’e´quation (4) est appele´e mode`le de structure de covariance.
D’apre`s (1) ou (3), on peut e´crire pour tout j = 1, . . . , p :
V(xj) = (a1j)2 + (a2j)2 + . . .+ (a
q
j)
2 + ξj
=
q∑
α=1
(aαj )
2 + ξj
= h2j + ξ
j. (5)
De meˆme, pour j 6= k :
cov(xj, xk) =
q∑
α=1
aαj a
α
k + 0. (6)
On voit ainsi que les covariances des variables ale´atoires xj, j = 1, . . . , p, sont comple`tement
reconstitue´es par la matrice de saturation Aq tandis que les variances se de´composent en
une part due aux facteurs communs, appele´e communalite´ ou variance commune, et une
part due aux facteurs spe´cifiques, appele´e variance spe´cifique ou re´siduelle.
On remarque e´galement que Aq est la matrice des covariances entre les variables ale´atoires
xj, j = 1, . . . , p, et les facteurs communs fα, α = 1, . . . , q. En effet :
cov(x, f) = E(xf ′) = E((Aqf + e+ µ)f ′)
= AqE(ff ′) + E(ef ′) + µE(f ′)
= Aq. (7)
On travaille maintenant sur les variables standardise´es, c’est-a`-dire que x˜ correspond au
vecteur x centre´ re´duit : x˜ = Σ−1/2(x− µ).
c© Revue MODULAD, 2007 -4- Nume´ro 37
Dans ce cas, la matrice Aq devient la matrice des corre´lations line´aires entre les variables
xj et les facteurs fα, et l’e´quation (4) s’e´crit :
Υ = AqA
′
q + Ξ (8)
ou` Υ est la matrice de corre´lation line´aire de x.
De fac¸on analogue a` (5), on a :
1 = h2j + ξ
j. (9)
Dans la suite de cet article, nous conside´rons que le vecteur x˜ correspond au vecteur x
centre´ re´duit.
3 Estimation du mode`le
On veut estimer Aq et f dans le mode`le (1). Rigoureusement, on ne devrait pas parler
d’estimation pour f car il s’agit d’un vecteur ale´atoire, on va donc obtenir une re´alisation
et non une estimation de f . Nous nous conformerons cependant a` cet abus de langage,
fre´quent dans la litte´rature.
Pour cela, on dispose d’un e´chantillon {x1, . . . ,xn} de n re´alisations inde´pendantes et
identiquement distribue´es du vecteur ale´atoire x de Rp.
D’apre`s (1), on peut e´crire pour tout i = 1, . . . , n :
x˜i = Aqfi + ei. (10)
On note :
– X˜ la matrice (n× p) des donne´es centre´es re´duites.
– Fq la matrice (n× q) correspondant aux n re´alisations des q facteurs communs. Elle
est appele´e matrice des scores des facteurs communs (”factor scores matrix”).
– Eq la matrice (n× p) des erreurs spe´cifiques.
Le mode`le d’A.F. sur e´chantillon s’e´crit alors :
X˜ = FqA
′
q + Eq.
(n× p) (n× q)(q × p) (n× p) (11)
Nous pre´sentons ici trois me´thodes d’estimation de Aq et Fq. Pour toute me´thode d’es-
timation, il faut ensuite choisir le nombre q (avec q ≤ p) de facteurs communs que l’on
retient. Quelques crite`res pour le choisir sont discute´s dans la section 3.4.
3.1 Estimation du mode`le via les composantes principales
Cette technique utilise l’A.C.P. comme me´thode d’estimation du mode`le d’A.F. Nous
rappelons donc dans un premier temps le principe de l’A.C.P., puis nous expliquons com-
ment cette me´thode est utilise´e pour estimer le mode`le d’A.F.
c© Revue MODULAD, 2007 -5- Nume´ro 37
3.1.1 Pre´sentation de l’A.C.P.
L’A.C.P est propose´e pour la premie`re fois par Pearson en 1901, elle est ensuite inte´gre´e
a` la statistique mathe´matique par Hotelling en 1933. L’A.C.P. peut eˆtre conside´re´e selon
diffe´rents points de vue. La pre´sentation la plus fre´quente dans la litte´rature francophone
est ge´ome´trique. L’A.C.P est alors vue comme une technique visant a` repre´senter de
fac¸on optimale des donne´es, selon certains crite`res ge´ome´triques et alge´briques. Le lecteur
pourra se reporter a` l’ouvrage de Lebart et al. (1997). L’A.C.P peut eˆtre conside´re´e sur
un plan probabiliste, elle est alors un cas particulier du mode`le d’A.F. ou` les variances
spe´cifiques sont nulles ou e´gales, voir par exemple Tipping et Bishop (1999). Dans cet
article, nous adopterons une pre´sentation de l’A.C.P. qui nous permettra de faire le lien
avec l’A.F.
L’A.C.P pre´sente deux variantes, elle peut eˆtre re´alise´e a` partir des donne´es centre´es ou
des donne´es centre´es re´duites. Dans le premier cas, on parle d’A.C.P. non norme´e ou A.C.P
sur matrice des covariances. Dans le second cas, on parle d’A.C.P norme´e ou A.C.P. sur
matrice des corre´lations. Nous pre´sentons dans cet article l’A.C.P. norme´e, variante la
plus utilise´e.
L’objectif de l’analyse du nuage des individus {x1, . . . , xn} en A.C.P. est de de´terminer
q nouvelles variables ψ1, . . . , ψq avec q ≤ p, permettant de re´sumer ”au mieux” les p
variables x˜1, . . . , x˜p. Ces q nouvelles variables sont appele´es les composantes principales des
individus. Elles sont de´finies comme des combinaisons line´aires des p variables x˜1, . . . , x˜p.
On a donc, pour α = 1, . . . , q :
ψα = vα1 x˜
1 + . . .+ vαp x˜
p = X˜vα. (12)
On suppose que l’espace Rn est muni de la me´trique M , matrice de dimension (n × n),
avec M = diag(1/
√
m, . . . , 1/
√
m), ou` m = n ou m = n − 1 selon l’estimateur de la
variance choisi.
On veut que ces composantes soient de variance maximale et deux a` deux orthogonales.
Par construction, les colonnes de X˜ sont centre´es et donc les composantes principales le
sont aussi. On a donc :
V(ψα) = (ψα)′Mψα = (vα)′Rvα (13)
ou` R = X˜ ′MX˜ est la matrice des corre´lations empiriques entre les variables initiales
x1, . . . , xp.
En ajoutant la contrainte (vα)′(vα) = 1, on de´montre, voir par exemple Lebart et al.
(1997), que pour α = 1, . . . , q, vα est le vecteur propre associe´ a` la αe`me plus grande
valeur propre de la matrice des corre´lations R.
On construit ainsi la matrice Ψq dont les colonnes sont les composantes principales des
individus ψα, α = 1, . . . , q :
Ψq = X˜Vq (14)
ou` Vq est la matrice (p × q) dont les colonnes sont les vecteurs propres vα, α = 1, . . . , q,
associe´s aux q plus grandes valeurs propres de la matrice R.
c© Revue MODULAD, 2007 -6- Nume´ro 37
3.1.2 Estimation du mode`le d’A.F.
L’A.C.P. peut eˆtre utilise´e comme me´thode d’estimation du mode`le d’A.F. Le lien entre
l’A.C.P. et l’A.F. s’obtient facilement a` partir de la de´composition en valeurs singulie`res
(D.V.S.) de la matrice Z =MX˜.
On note r (avec r ≤ p < n) le rang de la matrice Z et on e´crit sa D.V.S. :
Z = UΛV ′ (15)
ou` :
– Λ = diag(
√
λ1, . . . ,
√
λr) des valeurs singulie`res des matrices ZZ
′ et Z ′Z range´es
par ordre de´croissant (
√
λ1 ≥
√
λ2 ≥ . . . ≥
√
λr > 0).
– U est la matrice orthonorme´e (n× r) dont les colonnes sont les vecteurs propres de
ZZ ′ associe´s aux r valeurs propres.
– V est la matrice orthonorme´e (p× r) dont les colonnes sont les vecteurs propres de
Z ′Z associe´s aux r valeurs propres.
On a donc :
X˜ =M−1Z =M−1UΛV ′. (16)
On note Uq, Λq et Vq les matrices contenant respectivement les q premie`res colonnes de
U , Λ et V .
• Avec q = r.
Pour se ramener au mode`le d’A.F. (11), on pose :
Fˆq = M
−1Uq (17)
Aˆq = VqΛq. (18)
On note que dans ce cas Eˆq = 0.
Comme U ′qUq = Ir, on montre que :
Aˆq = Z
′Uq = X˜ ′M−1Uq. (19)
Cette e´criture est utilise´e pour de´montrer que les e´le´ments de la matrice Aˆq, note´s aˆ
α
j ,
sont les corre´lations empiriques entre les variables xj et les facteurs fα (de´tails en annexe
7.1).
Comme VqV
′
q = Ip, on montre e´galement que :
Fˆq = X˜ VqΛ
−1
q︸ ︷︷ ︸
V ∗q
. (20)
Cette e´criture de Fˆq en fonction de X˜ fait ainsi apparaitre la matrice V
∗
q des coefficients
des scores des facteurs communs, calcule´e par certains logiciels statistiques.
• Avec q < r.
En ne retenant que les vecteurs propres associe´s aux q plus grandes valeurs propres, on a
l’approximation de X˜ suivante :
X˜ = FˆqAˆq + Eˆq (21)
ou` :
c© Revue MODULAD, 2007 -7- Nume´ro 37
– Fˆq contient les q premie`res colonnes de Fˆq de´finie dans (17).
– Aˆq contient les q premie`res colonnes de Aˆq de´finie dans (18).
– Eˆq est la matrice des erreurs associe´e a` cette approximation.
Avec cette me´thode d’estimation, on montre facilement (voir les de´tails en annexe 7.1)
que les facteurs communs estime´s posse`dent les bonnes proprie´te´s mais que les hypothe`ses
du mode`le ne sont pas ne´cessairement toutes ve´rifie´es.
3.1.3 Lien avec l’A.C.P.
Les facteurs communs estime´s par cette me´thode correspondent aux composantes prin-
cipales des individus (trouve´es en A.C.P.) standardise´es. En effet, d’apre`s les e´galite´s (14)
et (20), on voit que :
Fˆq = ΨqΛ
−1
q (22)
De plus, la matrice de saturations Aˆq est e´gale a` la matrice des composantes princi-
pales des variables. En effet, si on pre´sente l’A.C.P. d’un point de vue ge´ome´trique, on
re´alise ge´ne´ralement non seulement l’analyse des points-individus, comme pre´sente´ ici,
mais e´galement celle des points-variables. On montre que ces composantes correspondent
aux corre´lations entre les variables xj et les facteurs fα, et donc aux saturations (voir
l’ouvrage de Lebart et al., 1997).
3.1.4 Quelques e´le´ments de vocabulaire
On peut introduire, a` partir de ces premiers re´sultats, le vocabulaire utilise´ en A.C.P.
et en A.F. (tableau 1).
Tab. 1 – Quelques e´le´ments de vocabulaire en A.F. et A.C.P.
Matrices Franc¸ais Anglais
ACP Ψq Composantes principales Principal component scores
Vq Coefficient des composantes principales Principal component scoring coefficients
Fq Facteurs communs Factor scores
AF ou Standardized principal component scores
V ∗q Coefficients des facteurs communs Factor scoring coefficients
ou Standardized principal component scoring coefficients
3.2 Me´thode du facteur principal
A partir de l’e´chantillon {x1, . . . ,xn}, on calcule la matrice des corre´lations empiriques
de´finie par :
R = X˜ ′MX˜ (23)
L’e´quation (8) du mode`le de structure de covariance sur e´chantillon s’e´crit alors :
R = AˆqAˆ
′
q + Ξˆ (24)
Il faut donc de´terminer Aˆq et Ξˆ.
c© Revue MODULAD, 2007 -8- Nume´ro 37
Pour cela, la me´thode du facteur principal estime Ξ (en fait Υ − Ξ) et factorise R − Ξˆ
pour obtenir AˆqAˆ
′
q en utilisant les valeurs propres et vecteurs propres de R− Ξˆ.
• Estimation de Ξ.
D’apre`s l’e´quation (9), un estimateur de Υ− Ξ est donne´ par :
R− Ξˆ =

hˆ21 r12 . . . r1p
r21 hˆ
2
2 . . . r2p
...
...
...
...
rp1 rp2 . . . hˆ
2
p

ou` hˆ2j est l’estimation de la j
e`me communalite´ de´finie par : hˆ2j = 1− ξˆj.
D’apre`s (5), la communalite´ h2j traduit la part commune entre x
j et les p − 1 variables
restantes. Ainsi, une estimation courante pour la communalite´ h2j est R
2
j , le coefficient de
corre´lation multiple entre xj et les p− 1 variables restantes.
Ainsi,
hˆ2j = R
2
j = 1−
1
rjj
(25)
ou` rjj est le j e`me e´le´ment diagonal de R−1.
Pour effectuer ces estimations, R doit eˆtre re´gulie`re. Si R est singulie`re, on utilise pour
hˆ2j la valeur absolue (ou le carre´) de la plus grande corre´lation de x
j avec les p− 1 autres
variables. Un autre moyen de reme´dier a` cette singularite´ est de remarquer que, puisque
R est singulie`re, cela signifie qu’il existe des combinaisons line´aires des variables. On peut
donc supprimer les redondances et rendre ainsi R inversible.
Notons t le rang de la matrice R− Ξˆ.
• Avec q = t.
- Estimation de Aq.
On e´crit la de´composition spectrale de la matrice R− Ξˆ :
R− Ξˆ = CDC ′ = (CD1/2)(CD1/2)′ = AˆqAˆ′q (26)
ou` :
– D = diag(θ1, θ2, . . . , θt) des valeurs propres non nulles de R− Ξˆ.
– C est la matrice orthonormale dont les colonnes sont les vecteurs propres norme´s
de R− Ξˆ associe´s aux t valeurs propres non nulles.
- Estimation de Fq.
Apre`s avoir estime´ Aq, il faut ”estimer” Fq. Une me´thode possible est de choisir l’estima-
teur line´aire fˆ = Lx˜ qui minimise l’erreur quadratique moyenne :
E[‖fˆ − f‖2] = E[‖Lx˜− f‖2] = E[‖LAqf + Le− f‖2]. (27)
c© Revue MODULAD, 2007 -9- Nume´ro 37
Seber (1984) montre que (27) est e´gale a` :
trace(L′LΣ)− 2trace(LAq) + q. (28)
En diffe´renciant par rapport a` Aq, on obtient :
2LΣ− 2A′q = 0
L = A′qΣ
−1 (29)
et donc :
fˆ = A′qΣ
−1x˜. (30)
En remplac¸ant Aq par son estimateur (26), et Σ par la matrice de variance covariance
empirique S, on obtient :
Fˆq = X˜S
−1Aˆq
= X˜R−1Aˆq car on travaille avec la matrice X˜ centre´e re´duite. (31)
Remarque. En de´veloppant le calcul de Σ−1 = (AqA′q+Ξ)
−1 dans (30), on montre (voir
l’ouvrage de Seber, 1984) que fˆ est l’estimateur ”ridge” de f :
fˆ = (Iq + A
′
qΞ
−1Aq)−1A′qΞ
−1x˜. (32)
• Avec q < t.
Afin de retenir seulement q facteurs communs dans le mode`le d’A.F., on ne conserve que
les q, premie`res colonnes des matrices Aˆq et Fˆq de´finies respectivement dans (26) et (31).
• Ite´ration de la me´thode.
Cette me´thode du facteur principal peut facilement eˆtre ite´re´e afin d’ame´liorer l’estima-
tion de Aq. Apre`s avoir estime´ Aq a` partir de (26), nous pouvons obtenir une nouvelle
estimation de la communalite´ en utilisant (5) :
hˆ2j =
q∑
α=1
(aˆαj )
2.
Ces valeurs sont alors inse´re´es dans la diagonale de R−Ξˆ, ce qui nous permet d’obtenir une
nouvelle estimation de Aq a` partir de la de´composition spectrale de la nouvelle matrice R−
Ξˆ, comme dans l’e´quation (26). Ce processus est alors ite´re´ jusqu’a` ce que les estimations
de la communalite´ se stabilisent.
Cependant, un de´faut majeur de la me´thode ite´re´e est qu’elle ne converge pas toujours.
De plus, lors de ces ite´rations, hˆ2j peut devenir supe´rieur a` 1, ce qui implique ξˆ
j < 0. Or,
ceci est impossible car on ne peut pas avoir une variance spe´cifique estime´e ne´gative. Ce
proble`me est connu sous le nom de Heywood case (Heywood, 1931).
c© Revue MODULAD, 2007 -10- Nume´ro 37
3.3 Maximum de vraisemblance
On suppose que l’e´chantillon {x1, . . . ,xn} est issu d’une loi multi-normale Np(µ,Σ).
Alors (n− 1)S suit la loi de Wishart Wp(n− 1,Σ) et la log-vraisemblance de l’e´chantillon
est donne´e par :
logL(Aq,Ξ) = c− 1
2
(n− 1)(ln|Σ|+ trace(Σ−1S)) (33)
ou` c est une constante et |M | de´signe le de´terminant de M .
Les parame`tres Aq et Ξ vont alors pouvoir eˆtre estime´s en maximisant logL(Aq,Ξ), sous
la contrainte Σ = AqA
′
q + Ξ avec Ξ matrice diagonale. La condition suivante : A
′
qΞ
−1Aq
diagonale, est souvent rajoute´e afin d’avoir une solution unique.
L’e´quation du maximum de vraisemblance n’a pas de solution analytique, la re´solution se
fait donc nume´riquement par ite´rations successives. Cependant, cette me´thode ne converge
pas toujours. De plus, des cas de variances spe´cifiques estime´es ne´gatives peuvent la` encore
se produire (Heywood case).
Notons qu’avec cette me´thode, les facteurs communs obtenus fˆα ne sont pas force´ment
ordonne´s par variance explique´e de´croissante comme avec la me´thode des composantes
principales et la me´thode du facteur principal.
Apre`s avoir estime´ Aq et Ξ, il faut estimer la matrice Fq des scores des facteurs communs.
Pour cela, on utilise souvent la me´thode des moindres carre´s ge´ne´ralise´s :
Fˆq = (Aˆ
′
qΞˆ
−1Aˆq)−1Aˆ′qΞˆ
−1X˜. (34)
On ne retient ensuite que les q, avec q ≤ p, premie`res colonnes des matrices Fˆq et Aˆq.
Pour de plus amples de´tails sur cette me´thode d’estimation, le lecteur pourra se re´fe´rer a`
l’ouvrage de Seber (1984).
3.4 Choix du nombre de facteurs
Comme dans toute me´thode factorielle, une e´tape importante de l’A.F. est le choix
du nombre q de facteurs communs. La qualite´ des estimations du mode`le de´pend de q.
En effet, si q est trop grand, certains facteurs spe´cifiques vont eˆtre me´lange´s aux facteurs
communs. A l’inverse si q est trop petit, des facteurs communs importants risquent d’eˆtre
oublie´s. Diffe´rents crite`res the´oriques et empiriques peuvent eˆtre utilise´s pour choisir q.
Voici deux crite`res the´oriques reposant sur la normalite´ de l’e´chantillon :
• Crite`re 1.
Ce crite`re consiste a` de´terminer si les (p − k) dernie`res valeurs propres de la matrice de
covariance Σ sont significativement diffe´rentes entre elles. On fait pour cela l’hypothe`se
que les n observations sont les re´alisations d’un vecteur ale´atoire gaussien dont les (p−k)
dernie`res valeurs propres λk+1, . . . , λp de la matrice Σ sont e´gales. Sous cette hypothe`se,
c© Revue MODULAD, 2007 -11- Nume´ro 37
la moyenne arithme´tique ma des (p− k) dernie`res valeurs propres doit eˆtre peu diffe´rente
de la moyenne ge´ome´trique mg. On de´finit :
T1 =
(
n− 2p+ 11
6
)
(p− k)log
(
ma
mg
)
. (35)
Sous H0, on peut montrer que T1 suit une loi du Khi-deux a` v1 =
(p−k+2)(p−k−1)
2
degre´s de
liberte´.
On rejette donc H0 au seuil de signification α si l’ine´galite´ suivante est ve´rifie´e :
T1 > χ
2
v1,1−α (36)
ou` χ2v1,1−α est le fractile d’ordre (1− α) de la loi du Khi-deux a` v1 degre´s de liberte´.
Certains auteurs (voir par exemple Bouveyron, 2006) soulignent le fait que ce crite`re
surestime tre`s souvent le nombre de facteurs a` retenir.
• Crite`re 2.
Ce crite`re est utilise´ lorsque la me´thode d’estimation du mode`le d’A.F. est le maximum
de vraisemblance.
On de´sire tester l’hypothe`se que q0 est le bon nombre de facteurs communs. Les hypothe`ses
sont donc : H0 : Σ = Aq0(Aq0)
′ + Ξ, ou` Aq0 est de dimension (p × q0) contre H1 : Σ =
AqA
′
q + Ξ, ou` Aq est de dimension (p× q) avec q > q0.
La statistique de test est :
T2 =
(
n− 2p+ 4q0 + 11
6
)
log
(
|Aˆq0Aˆ′q0 + Ξˆ|
|S|
)
(37)
ou` Aˆq0 et Ξˆ sont les estimateurs du maximum de vraisemblance de Aq et Ξ, obtenus avec
q0 facteurs communs.
Sous H0, on peut montrer que T2 suit une loi du Khi-deux a` v2 =
1
2
[(p − q0)2 − p − q0]
degre´s de liberte´.
On rejette donc H0 au seuil de signification α si la condition (36) est ve´rifie´e (ou` l’on
aura pre´alablement substitue´ v2 a` v1). Si H0 est rejete´e, cela signifie que le nombre q0 de
facteurs communs est trop petit.
En pratique, on commence souvent avec q0 = 1, et on ajoute des facteurs jusqu’a` trouver
la valeur q pour laquelle H0 est ve´rifie´e. Ainsi, le risque associe´ a` la proce´dure pour trouver
le bon nombre de facteurs q0 est supe´rieur a` α, du fait de la multiplicite´ des tests.
Il faut noter que cette technique est souvent utilise´e pour fixer la borne supe´rieure du
nombre de facteurs. En effet, on peut trouver dans la litte´rature, voir par exemple Ren-
cher (2002), que lorsque le nombre d’observations est grand, cette me´thode a tendance a`
surestimer le nombre de facteurs communs.
Diffe´rentes re`gles empiriques peuvent e´galement eˆtre utilise´es pour choisir q. Dans la
de´finition des crite`res ci-dessous, λi, i = 1, . . . , p, fait re´fe´rence aux valeurs propres de R
c© Revue MODULAD, 2007 -12- Nume´ro 37
(ou S) ou bien R−Ξˆ (ou S−Ξˆ), selon que la me´thode d’estimation utilise´e est la me´thode
des composantes principales ou du facteur principal. Voici quelques exemples de crite`res
empiriques.
• Pourcentage de variance explique´e.
On choisit q tel que le pourcentage de variance explique´e par les q facteurs soit supe´rieur
ou e´gal a` un seuil fixe´ par l’utilisateur. L’appre´ciation de ce pourcentage doit tenir compte
du nombre de variables p et du nombre d’observations n. En effet, un pourcentage de 10%
peut eˆtre conside´re´ comme e´leve´ pour p = 100 variables et au contraire, faible pour p = 10.
Notre expe´rience nous a montre´ que ce crite`re a souvent tendance a` surestimer le nombre
de facteurs q.
• Le test du coude.
On utilise le test du coude de Cattell, ou scree-test, base´ sur l’analyse des diffe´rences
conse´cutives entre les valeurs propres. On calcule les diffe´rences premie`res :
i = λi − λi+1
puis les diffe´rences secondes :
δi = i − i+1.
On retient alors les valeurs propres λ1, λ2, . . . , λk, λk+1 tels que δ1, . . . , δk soient tous po-
sitifs.
Visuellement, ce crite`re revient a` de´tecter un coude dans le graphe de l’e´boulis des valeurs
propres. En pratique, la de´tection graphique de ce coude peut se re´ve´ler difficile.
• La re`gle de Kaiser.
Sachant que la variance explique´e par un facteur fˆα est λα, il s’agit de retenir les facteurs
dont la variance explique´e de´passe la moyenne de la variance totale explique´e : λ =
pP
i=1
λi
p
.
Pour la matrice de corre´lation R, on a : λ = 1. Cette valeur 1 peut aussi eˆtre vue comme
la variance de chaque variable xj et on retient donc un facteur s’il explique au moins
autant de variance qu’une variable toute seule.
On insiste sur le fait que ces crite`res ne doivent pas se substituer a` une analyse approfondie
de l’interpre´tation des facteurs. Il est indispensable d’examiner l’information apporte´e par
un facteur, et ainsi juger de sa pertinence et de son inte´reˆt quant aux objectifs de l’e´tude.
L’utilisateur retiendra, par exemple, un facteur dont la part de variance explique´e est
faible, mais dont l’inte´reˆt est significatif pour la proble´matique traite´e. Au contraire, il
pourra rejeter un facteur qui posse`de une part de variance explique´e e´leve´e, mais qui
n’aide pas a` comprendre le phe´nome`ne e´tudie´. Ainsi, on peut utiliser ces crite`res comme
valeur initiale du nombre q0 de facteurs, puis au vu de l’interpre´tation des re´sultats et
des objectifs de l’e´tude, on peut augmenter ou diminuer ce nombre q0 afin de trouver une
interpre´tation des re´sultats satisfaisante.
3.5 Choix de la me´thode d’estimation
On trouve dans la litte´rature (voir par exemple Rencher, 2002) que les solutions ob-
tenues avec la me´thode des composantes principales et la me´thode du facteur principal
(ite´re´e ou non) sont tre`s proches lorsque l’une des deux conditions suivantes est ve´rifie´e :
c© Revue MODULAD, 2007 -13- Nume´ro 37
– Les corre´lations entre les variables xj, j = 1, . . . , p, sont e´leve´es.
– Le nombre de variables p est grand.
Cependant, il est important de noter que la me´thode d’estimation la plus utilise´e est
celle des composantes principales. C’est une technique qui fournit une approximation
convenable de la solution et qui est facile a` mettre en oeuvre. Ainsi, c’est la me´thode
utilise´e par de´faut lorsqu’on estime un mode`le d’A.F. sous les logiciels SAS et SPSS.
Enfin, contrairement aux deux autres techniques, elle ne pre´sente pas le proble`me de
Heywood case.
4 La rotation des facteurs
Dans cette section, nous allons pre´senter les motivations de la rotation orthogonale
des facteurs estime´s, puis nous montrerons que cette rotation est justifie´e car elle conserve
les proprie´te´s des facteurs. Quelques crite`res permettant la mise en place d’une rotation
optimale seront ensuite discute´s. Enfin, nous montrerons brie`vement que la rotation est
possible en A.C.P., comme en A.F., a` condition d’effectuer convenablement la transfor-
mation.
4.1 Motivations
Apre`s avoir estime´ le mode`le d’A.F., on peut vouloir interpre´ter les facteurs communs
obtenus en de´tectant des groupes de variables corre´le´es aux diffe´rents facteurs. La matrice
de saturation Aq, repre´sentant les corre´lations entre les variables x
j et les facteurs com-
muns fα, il s’agit de faire apparaˆıtre des variables fortement corre´le´es a` un meˆme facteur.
Il est donc souhaitable que pour chaque colonne de Aq les valeurs soient proches soit
de 0, soit de 1 et qu’il n’y ait ainsi pas de valeur interme´diaire. Cela permet alors d’as-
socier clairement des variables a` un facteur. Il faut e´galement s’assurer que sur chaque
ligne de Aq, il n’y aura qu’une seule valeur proche de 1. En effet, si la corre´lation entre
une variable xj et un facteur fα est proche de 1, les corre´lations de cette variable avec
les facteurs restants doivent eˆtre proches de 0, car les facteurs sont orthogonaux entre
eux. Cela se traduit par la condition d’orthonormalite´ de la matrice de transformation T .
Ainsi, chaque variable xj ne pourra eˆtre parfaitement associe´e qu’a` un seul facteur fα.
Cependant, l’estimation Aˆq trouve´e ne pre´sente pas toujours une telle structure. Afin
de se rapprocher de cette situation, il est possible de re´aliser une rotation des facteurs.
La justification de la possibilite´ de faire une rotation provient de la non-unicite´ de la
solution du mode`le d’A.F. Ainsi, il s’agit de choisir la solution optimale du point de vue
de l’interpre´tation des re´sultats.
Remarque. Il existe des rotations qui ne conservent pas la proprie´te´ d’orthogonalite´
des facteurs communs. Ce type de rotation dites obliques ne sera pas aborde´ dans cet
article. Pour plus de de´tails, le lecteur pourra se reporter a` l’ouvrage de Rencher (2002).
c© Revue MODULAD, 2007 -14- Nume´ro 37
4.2 Justifications de la rotation
La solution du mode`le d’A.F. n’est pas unique. En effet, soit T une matrice orthonor-
male de dimension (q × q). On peut e´crire :
X˜ = FˆqAˆ
′
q + Eˆq
= FˆqTT
′Aˆ′q + Eˆq
= GˆqBˆ
′
q + Eˆq avec Gˆq = FˆqT et Bˆq = AˆqT. (38)
Ainsi Gˆq est l’estimation de la matrice des facteurs apre`s la rotation et Bˆq est l’estimation
de la matrice de saturation apre`s la rotation.
La transformation orthogonale entraˆıne une rotation ”rigide” des q axes de´finis par les
facteurs communs, c’est-a`-dire que les q nouveaux axes restent perpendiculaires apre`s la
rotation.
Proprie´te´ :
Les facteurs communs gα et les saturations bˆαj ve´rifient toujours les proprie´te´s et hy-
pothe`ses du mode`le d’A.F. apre`s la rotation.
La de´monstration est disponible en annexe 7.2.
On montre en particulier que les saturations apre`s rotation, bˆαj , sont toujours les corre´lations
des variables d’origine xj aux facteurs apre`s rotation, gα.
Cependant, meˆme si suite a` la rotation, les communalite´s estime´es sont inchange´es et que
l’on a :
hˆ2j =
q∑
α=1
(bˆαj )
2 =
q∑
α=1
(aˆαj )
2, (39)
la variance explique´e par chaque facteur fα change lors de la rotation. En effet :
p∑
j=1
(bˆαj )
2 =
p∑
j=1
(aˆjt
α)2 ou` tα est la αe`me colonne de T
=
p∑
j=1
(
q∑
k=1
aˆkj t
α
k )
2
6=
p∑
j=1
(aˆαj )
2. (40)
Apre`s la rotation, les facteurs ne sont donc plus force´ment range´s par ordre de variance
explique´e de´croissante.
4.3 Comment faire la rotation ?
Afin d’effectuer la rotation, il faut de´terminer la matrice T qui fournit la ”meilleure”
interpre´tation des re´sultats, c’est-a`-dire telle que les e´le´ments bˆαj de la matrice Bˆq = AˆqT
soient proches de 0 ou de 1, on parle de ”structure simple” de Bˆq. Diffe´rents crite`res
existent, le plus utilise´ est Varimax.
c© Revue MODULAD, 2007 -15- Nume´ro 37
4.3.1 Varimax
Comme toutes les variables n’ont pas la meˆme commmunalite´, le crite`re Varimax est
souvent applique´ sur les valeurs standardise´es de Bˆq, obtenues en divisant chaque ligne
de la matrice Bˆq par hˆj. On travaille avec le carre´ de ces e´le´ments, (bˆ
α
j /hˆj)
2, afin de se
ramener a` des valeurs comprises entre 0 et 1. On note Bˆ∗q cette matrice. On veut que
ses e´le´ments soient aussi proches que possible de 0 ou de 1. Pour cela, il faut maximiser
la variance empirique de chaque colonne de Bˆ∗q afin de donner plus de poids aux valeurs
extreˆmes 0 et 1.
Ceci e´quivaut a` maximiser la somme sur l’ensemble des q facteurs des variances empi-
riques de chaque colonne de Bˆ∗q , c’est-a`-dire la quantite´ :
q∑
α=1

p∑
j=1
((bˆαj )
2/hˆ2j)
2
p
−

p∑
j=1
((bˆαj )
2/hˆ2j)
p

2
 (41)
avec bˆαj = aˆjt
α, aˆj est la j
e`me ligne de la matrice Aˆq, et t
α est la αe`me colonne de la matrice
T .
La maximisation de la quantite´ (41) se fait donc de fac¸on ite´rative, par rapport a` tα, α =
1, . . . , q, sous la contrainte tα(tα)′ = 1 et tk(tl)′ = 0 pour k 6= l.
4.3.2 Quartimax
Le crite`re Quartimax maximise la somme des variances des e´le´ments (bˆαj )
2 sur toute
la matrice Bˆq, c’est-a`-dire la quantite´ :
q∑
α=1
p∑
j=1
(bˆαj )
4
pq
−

q∑
α=1
p∑
j=1
(bˆαj )
2
pq

2
. (42)
On trouve dans la litte´rature (Jobson, 1992) que ceci e´quivaut a` maximiser la quantite´
q∑
α=1
p∑
j=1
(bˆαj )
4. Il est de plus mentionne´ que cette me´thode a tendance a` produire un facteur
commun ge´ne´ral car elle maximise la variance des (bˆαj )
2 sur la totalite´ de la matrice de
saturation Bˆ∗q et non sur chaque colonne, comme le crite`re Varimax.
4.3.3 Orthomax
Le crite`re Orthomax est une ge´ne´ralisation des crite`res de rotation orthogonale. Il
s’agit de maximiser la quantite´ :
q∑
α=1

p∑
j=1
(bˆαj )
4 − δ
p
(
p∑
j=1
(bˆαj )
2
)2 (43)
c© Revue MODULAD, 2007 -16- Nume´ro 37
Pour δ = 0 et δ = 1, on retrouve respectivement le crite`re Quartimax et la version non
standardise´e de Varimax. Pour δ = 0.5, le crite`re s’appelle Biquartimax et pour δ = q
2
, ce
crite`re est connu sous le nom de Equamax.
4.4 Remarques sur la rotation et l’A.C.P.
La rotation en A.C.P est possible, comme en A.F., mais il faut eˆtre prudent et appliquer
la transformation T aux bonnes matrices.
Si on applique la rotation directement sur les composantes principales Ψq, les nouvelles
composantes apre`s rotation ΨqT ne sont pas ne´cessairement non corre´le´es. En effet :
(ΨqT )
′MΨqT = T ′Ψ′qMΨqT = T
′Λ2T. (44)
On en de´duit que (ΨqT )
′MΨqT n’est pas force´ment la matrice identite´.
Afin d’effectuer convenablement une rotation en A.C.P. il faut donc introduire la matrice
T au bon endroit dans l’e´criture de X˜.
Il ne faut pas e´crire :
X˜ =
Ψq︷ ︸︸ ︷
M−1UΛTT’V ′ (45)
mais :
X˜ =
Fˆq︷ ︸︸ ︷
M−1U TT’ΛV ′. (46)
Ainsi les composantes obtenues apre`s rotation correspondent en fait aux facteurs communs
obtenus apre`s rotation Gˆq = M
−1UT . Nous avons de´ja` ve´rifie´ en annexe 7.2 que ces
facteurs ne sont pas corre´le´s.
On comprend ainsi la raison pour laquelle les logiciels qui calculent les composantes prin-
cipales ne proposent pas de rotation des composantes, celles-ci deviendraient en effet
corre´le´es. A l’inverse, les logiciels qui construisent les facteurs communs proposent une
rotation.
5 Un exemple d’application sur des donne´es de cri-
minalite´
5.1 Proble´matique
• Donne´es.
Dans cette exemple, nous e´tudions la criminalite´ de seize villes ame´ricaines, donne´es
e´tudie´es par de nombreux auteurs dont Rencher (2002) (extraites de U.S. Statistical Abs-
tract, 1970). Pour cela, sept types d’effractions sont releve´s et un taux pour 100 000
habitants est calcule´ (tableau 2). L’objectif est de re´sumer la criminalite´ de ces villes
a` l’aide de facteurs communs. Nous allons e´tudier les re´sultats fournis par les logiciels
c© Revue MODULAD, 2007 -17- Nume´ro 37
SAS, SPAD et SPSS. Nous choisissons d’estimer le mode`le d’A.F. via les composantes
principales.
Il faut noter que le logiciel SPAD utilise la de´finition de l’estimateur biaise´ de l’e´cart-type
(m = n), les logiciels SAS et SPSS utilise au contraire la de´finition de l’estimateur non
biaise´ de l’e´cart-type (m = n − 1). Il est cependant possible de pre´ciser au logiciel SAS
d’utiliser l’estimation biaise´e de l’e´cart-type avec l’option ”vardef=n”.
Tab. 2 – Criminalite´
Ville Meurtre Viol Vol Agression Cambriolage Vol avec effraction Vol de voiture
Atlanta 16.5 24.8 106 147 1112 905 494
Boston 4.2 13.3 122 90 982 669 954
Chicago 11.6 24.7 340 242 808 609 645
Dallas 18.1 34.2 184 293 1668 901 602
Denver 6.9 41.5 173 191 1534 1368 780
Detroit 13 35.7 477 220 1566 1183 788
Hartford 2.5 8.8 68 103 1017 724 468
Honolulu 3.6 12.7 42 28 1457 1102 637
Houston 16.8 26.6 289 186 1509 787 697
Kansas City 10.8 43.2 255 226 1494 955 765
Los Angeles 9.7 51.8 286 355 1902 1386 862
New Orleans 10.3 39.7 266 283 1056 1036 776
New York 9.4 19.4 522 267 1674 1392 848
Portland 5 23 157 144 1530 1281 488
Tucson 5.1 22.9 85 148 1206 756 483
Washington 12.5 27.6 524 217 1496 1003 793
On note X = (xji ), i = 1, . . . , n, j = 1, . . . , p, la matrice des donne´es pre´sente´es dans le
tableau 2 avec n = 16 observations et p = 7 variables.
• Choix de q.
Les diffe´rents auteurs, qui ont e´tudie´s ces donne´es, ont conserve´ q = 3 facteurs communs
(voir par exemple Rencher, 2002). Nous ve´rifions, par une e´tude approfondie, que la
valeur 3 permet une bonne interpre´tation des re´sultats. Pour cela, nous comparons les
valeurs de q propose´es par les crite`res empiriques discute´s dans la section 3.4 et examinons
attentivement les valeurs propres de la matrice des corre´lations R (figure 1). Dans cette
e´tape, nous privile´gions l’interpre´tation des facteurs et leur inte´reˆt pour la proble´matique
e´tudie´e. Nous ve´rifions ainsi que la valeur 3 permet des interpre´tations inte´ressantes pour
l’e´tude mene´e. Dans la suite de cet article, la valeur q est donc choisi e´gale a` 3, pour
l’A.C.P. comme pour l’A.F.
Fig. 1 – Valeurs propres de la matrice R
c© Revue MODULAD, 2007 -18- Nume´ro 37
5.2 Logiciel SAS
La premie`re partie pre´sente la proce´dure Princomp qui re´alise une A.C.P. sur les
donne´es. Dans un second temps, nous de´crivons les re´sultats de la proce´dure Factor
avec pour me´thode d’estimation l’A.C.P. et ainsi nous comparons les re´sultats des deux
proce´dures.
5.2.1 Proce´dure PRINCOMP
Le code SAS de la proce´dure Princomp est pre´sente´ dans la figure 2. L’option ”n = 3”
permet de re´duire l’affichage des re´sultats a` 3 composantes principales.
Fig. 2 – Code SAS de la proce´dure Princomp
La proce´dure propose comme re´sultats la matrice des corre´lations empiriques R = X˜ ′MX˜,
ses valeurs propres λα et les vecteurs propres associe´s, c’est-a`-dire la matrice Vq (fi-
gure 3). Cette matrice peut e´galement eˆtre obtenue dans une table avec l’option ”outs-
tat=loadACP”. Il s’agit en fait de la matrice des coefficients des composantes principales.
Fig. 3 – Sorties nume´riques de la proce´dure Princomp
Fig. 4 – Matrice Vq des coefficients des composantes principales
L’option ”out=comp” permet d’obtenir dans une table appele´e ”comp”, la matrice Ψq des
composantes principales (figure 5).
c© Revue MODULAD, 2007 -19- Nume´ro 37
Fig. 5 – Matrice Ψq des composantes principales
5.2.2 Proce´dure FACTOR
La proce´dure SAS permettant d’estimer un mode`le d’A.F. est Factor. Cette proce´dure
nous propose diffe´rentes me´thodes d’estimation dont la me´thode des composantes princi-
pales que nous spe´cifions avec l’option ”method=prin” (figure 6). L’option ”nfactors=3”
permet de fixer q.
Fig. 6 – Code SAS de la proce´dure Factor
La proce´dure Factor fournit comme la proce´dure Princomp les valeurs propres λα de
la matrice des corre´lations empiriques R = X˜ ′MX˜.
En pre´cisant l’option ”out=fact”, le logiciel calcule la re´alisation des facteurs communs
fα, α = 1, . . . , q, sur les n observations, c’est-a`-dire la matrice Fˆq (figure 7).
Fig. 7 – Matrice Fˆq des facteurs communs
Le logiciel calcule la matrice V ∗q des coefficients des facteurs communs. Dans les sorties
du logiciel, elle est appele´e ”standardized scoring coefficents” (figure 8). Avec l’option
”outstat=loadAF”, on peut e´galement obtenir cette matrice dans la table ”loadAF”.
c© Revue MODULAD, 2007 -20- Nume´ro 37
Fig. 8 – Matrice V ∗q des coefficients des scores des facteurs communs
La matrice de saturation estime´e Aˆq est pre´sente´e sous le nom de ”factor pattern” (figure
9). Ses coefficients sont les corre´lations des variables d’origine xj aux facteurs communs
fα.
Fig. 9 – Matrice Aˆq de saturation
En rajoutant l’option ”rotate=varimax” dans le code pre´sente´ dans la figure 6, nous
demandons au logiciel d’effectuer une rotation orthogonale avec le crite`re Varimax. La
matrice T de transformation orthogonale, estime´e selon ce crite`re, est pre´sente´e dans la
figure 10.
Fig. 10 – Matrice T de transformation orthogonale
En rajoutant l’option ”out=factrotation”, on obtient la matrice Gˆq = FˆqT des facteurs
communs apre`s la rotation (figure 11).
La matrice de saturation apre`s rotation, Bˆq = AˆqT , est calcule´e et nomme´e ”rotated
factor pattern” (figure 12). Les valeurs de cette matrice sont les corre´lations des variables
d’origine xj aux facteurs communs gα apre`s la rotation, donne´s en figure 11.
On voit tre`s clairement sur cet exemple que la rotation des ”loadings” facilite la lecture des
re´sultats. Les valeurs de Aˆq (figure 9) sont tre`s disperse´es et rendent difficile la de´tection
de groupes de variables corre´le´es a` un meˆme facteur. Au contraire, la matrice Bˆq (figure
12) posse`de beaucoup plus de valeurs soit proches de 1, soit proches de 0. On peut ainsi
associer clairement chaque variable a` un facteur.
c© Revue MODULAD, 2007 -21- Nume´ro 37
Fig. 11 – Matrice Gˆq des facteurs apre`s la rotation
Fig. 12 – Matrice Bˆq de saturation apre`s la rotation
On peut alors de´crire les trois facteurs communs de la criminalite´ dans ces seize villes
ame´ricaines. Le premier facteur fait re´fe´rence aux crimes violents contre une personne :
meurtre, viol et agression. Le second facteur se rapporte aux crimes en rapport avec la
maison : cambriolage et vol avec effraction. Enfin le troisie`me facteur fait re´fe´rence aux
vols commis a` l’exte´rieur : vol et vol de voiture.
5.3 Logiciel SPSS
Avec le logiciel SPSS, dans le menu ”Analyse → Factorisation → Analyse factorielle”,
on peut choisir diffe´rentes me´thodes d’extraction des facteurs en cliquant sur le bouton
”Extraction” : Maximum de vraisemblance, Composantes principales, Factorisation en
axes principaux, etc (figure 13).
En cliquant sur le bouton ”Facteur”(figure 13), on peut demander au logiciel d’afficher
l’estimation de la matrice Fˆq des scores des facteurs communs, et l’estimation de la matrice
des coefficients des scores des facteurs communs V ∗q .
L’estimation de ces deux matrices Fˆq et V
∗
q est pre´sente´e a` la figure 14. Nous retrouvons
les re´sultats de la proce´dure Factor de SAS, pre´sente´s aux figures 7 et 8.
Le logiciel propose comme re´sultats la matrice de saturation estime´e, Aˆq, appele´e ”matrice
des composantes” (figure 15). On voit la` l’erreur commise par le logiciel car le terme
”matrice des composantes” est re´serve´ a` Ψq. Ce proble`me de vocabulaire provient peut-
eˆtre d’une mauvaise traduction franc¸aise de ce logiciel anglais.
Le logiciel nous propose e´galement diffe´rentes rotations. En choisissant le crite`re Varimax,
c© Revue MODULAD, 2007 -22- Nume´ro 37
Fig. 13 – Estimation du mode`le d’A.F. avec SPSS
Fig. 14 – Matrice Fˆq et V
∗
q
nous retrouvons les matrices Gˆq et Bˆq (figure 16) de la proce´dure Factor du logiciel SAS
(figures 11 et 12).
c© Revue MODULAD, 2007 -23- Nume´ro 37
Fig. 15 – Matrice Aˆq de saturation
Fig. 16 – Matrice Gˆq et Bˆq apre`s la rotation
5.4 Logiciel SPAD
Parmi les me´thodes d’analyse factorielle du logiciel SPAD, l’A.C.P. est propose´e mais
l’A.F. n’est pas disponible. Afin d’effectuer une A.C.P., on inse`re la me´thode des compo-
santes principales appele´e ”Copri” (figure 17).
Le logiciel re´alise alors l’analyse des points-variables (voir l’ouvrage de Lebart et al., 1997)
et propose comme re´sultats les coordonne´es des variables sur les composantes calcule´es.
Cette matrice est e´gale a` la matrice des corre´lations variable-facteur, il s’agit de l’esti-
mation de la matrice de saturation, note´e Aˆq (figure 18). Sur cette figure, on retrouve
e´galement la matrice des ”anciens axes unitaires” qui correspond en fait a` la matrice Vq
des vecteurs propres de R.
Pour obtenir la matrice des composantes principales Ψq (figure 19) , il faut demander a`
SPAD, lors du parame´trage de la filie`re, d’afficher les re´sultats pour les individus.
c© Revue MODULAD, 2007 -24- Nume´ro 37
Fig. 17 – Filie`re SPAD
Fig. 18 – Matrice Aˆq de saturation
Fig. 19 – Matrice Ψq des composantes principales
5.5 Tableau re´capitulatif des diffe´rents re´sultats
Le tableau ci-dessous re´capitule un certain nombre de re´sultats et permet de faire le
lien entre les facteurs ou composantes, obtenus avec les trois logiciels. Pour faciliter la
c© Revue MODULAD, 2007 -25- Nume´ro 37
lecture, les matrices ne sont pas indice´es par q.
Tab. 3 – Tableau comparatif des diffe´rents re´sultats
SAS SAS SPAD SPSS
Proc princomp Proc factor
(estimation par A.C.P.)
Me´thode factorielle A.C.P. A.F. A.C.P. A.F.
Estimateur de la variance non biaise´ non biaise´ biaise´ non biaise´
Facteurs/composantes Ψsas = X˜V Fsas = X˜V Λ
−1 Ψspad = X˜V Fspss = X˜V Λ−1
Norme au carre´ des facteurs (n− 1)λα n− 1 nλα n− 1
Variance des facteurs λα 1 λα 1
Matrice de saturation ? non fournie Aˆ = V Λ Aˆ = V Λ Aˆ = V Λ
Nom donne´ par le logiciel ”factor pattern” ”corre´lations variables facteurs” ”matrice des composantes”
Rotation possible ? non oui non oui
Lien ψαsas f
α
sas =
ψαsas√
λα
ψαspad =
q
n
n−1ψ
α
sas f
α
spss = f
α
sas
Pour mettre en place un mode`le d’A.F., on peut donc utiliser la proce´dure factor de
SAS ou le logiciel SPSS.
Si on utilise la proce´dure princomp de SAS ou le logiciel SPAD, la me´thode re´alise´e est
une A.C.P. et il faut standardiser les composantes principales pour obtenir l’estimation
des facteurs communs. Ceci peut se faire facilement sous le logiciel SAS, en spe´cifiant
l’option ”standard” dans le code de la proce´dure Princomp (figure 2). On obtient alors
la matrice des composantes principales standardise´es pre´sente´e dans la figure (20), qui
correspond bien a` la matrice Fˆq de la proce´dure factor (figure 7).
Fig. 20 – Matrice Ψq des composantes principales standardise´es
De plus, la proce´dure princomp de SAS ne fournit pas l’estimation de la matrice de
saturation. Il faut la calculer : Aˆq = VqΛq. Cependant, si elle contient des valeurs tre`s
disperse´es entre 0 et 1, il sera difficile d’associer des variables entre elles. Ce proble`me
peut e´galement se rencontrer avec le logiciel SPAD qui ne propose de rotation.
On peut cependant souligner deux avantages du logiciel SPAD par rapport a` SAS et
SPSS : l’interactivite´ et la possibilite´ de re´aliser facilement des graphiques.
Ainsi, on voit l’avantage d’utiliser la proce´dure factor de SAS ou le logiciel SPSS pour
estimer le mode`le d’A.F., car ils fournissent l’estimation de la matrice Aq de saturation
et proposent une rotation des facteurs.
c© Revue MODULAD, 2007 -26- Nume´ro 37
6 Conclusion
Le mode`le d’A.F. est une me´thode factorielle line´aire. Cette technique e´crit un en-
semble de p variables ale´atoires comme une combinaison line´aire de q facteurs non corre´le´s,
communs a` toutes les variables, et de p facteurs spe´cifiques a` chaque variable. L’ensemble
de ces facteurs communs et uniques reproduit les covariances des variables ale´atoires
initiales. Ainsi, le mode`le d’A.F. permet de re´sumer au ”mieux” l’information contenue
dans p variables ale´atoires, ou de de´tecter des facteurs sous-jacents communs dans une
proble´matique particulie`re. Comme toute me´thode factorielle, le point strate´gique du
mode`le d’A.F. re´side dans le choix du nombre q de facteurs communs, difficulte´ a` laquelle
nous avons souhaite´ apporter une aide. Cet aide n’est que partielle car nous avons vu
que seule une interpre´tation attentive des re´sultats et des objectifs de l’e´tude permet de
re´pondre au proble`me du choix de q.
Apre`s une pre´sentation synthe´tique du mode`le d’A.F., nous avons de´crit les techniques
d’estimation et nous avons vu que lorsqu’on estime le mode`le d’A.F. via les composantes
principales, cela revient a` faire une A.C.P.
L’accent a ensuite e´te´ mis sur les techniques de rotation des facteurs, qui peuvent s’ave´rer
tre`s utiles. Nous avons montre´ que, contrairement a` ce qu’on peut lire dans certains tra-
vaux, la rotation en A.C.P. est e´galement possible a` condition d’effectuer convenablement
la transformation.
Une application nume´rique a ensuite e´te´ mise en place sur des donne´es concernant la
criminalite´ de villes ame´ricaines. Ainsi, l’estimation du mode`le d’A.F. couple´e a` une ro-
tation de type Varimax nous a permis de re´sumer la criminalite´ des villes ame´ricaines a`
l’aide de trois facteurs communs : les crimes violents contre la personne, les crimes en
rapport avec la maison et les crimes commis a` l’exte´rieur. De plus, cette application a
permis de clarifier le vocabulaire utilise´ par les logiciels SAS, SPAD et SPSS, re´elle source
de confusion. L’exemple accompagne´ de nombreuses illustrations pourra servir de guide,
tant pour l’imple´mentation que pour la lecture des re´sultats nume´riques.
7 Annexes
7.1 Annexe 1 : Etude des proprie´te´s des facteurs communs es-
time´s par la me´thode des composantes principales
• Par construction, les facteurs communs estime´s sont centre´s.
• L’hypothe`se (H1) est ve´rifie´e car Fˆ ′qMFˆq = U ′qM−1Uq = Iq.
• L’hypothe`se (H2) n’est pas ne´cessairement ve´rifie´e. En effet, cette me´thode d’estimation
de la matrice Ξ ne garantit pas que Ξˆ = EˆqEˆ
′
q soit diagonale. Cependant, en pratique,
les termes en dehors de la diagonale de la matrice Ξˆ sont souvent ne´gligeables. Ainsi, la
solution trouve´e avec cette me´thode est souvent une approximation convenable, ce qui
explique que cette me´thode d’estimation du mode`le d’A.F. est tre`s utilise´e. On pourrait
pre´coniser a` l’utilisateur d’examiner attentivement la matrice EˆqEˆ
′
q et de recommencer
c© Revue MODULAD, 2007 -27- Nume´ro 37
l’estimation du mode`le avec une autre me´thode si les valeurs en dehors de la diagonale de
cette matrice sont trop grandes.
• L’hypothe`se (H3) est ve´rifie´e. En effet, en ne retenant que les vecteurs propres associe´s
aux q plus grandes valeurs propres, on a :
X˜ =M−1Uq︸ ︷︷ ︸
Fˆq
ΛqV
′
q︸ ︷︷ ︸
Aˆ′q
+Eˆq
ou` Eˆq = M
−1UeΛeV ′e , avec Ue, Λe et Ve les matrices contenant respectivement les r − q
dernie`res colonnes de U , Λ et V .
On a alors :
Eˆ ′qMFˆq = Eˆ
′
qUq
= VeΛeU
′
eM
−1Uq
= 0 (47)
car la matrice U est orthonorme´e.
• On peut ve´rifier que les valeurs de la matrice Aˆq, note´s aˆαj sont les corre´lations empi-
riques entre les variables xj et les facteurs fα :
aˆαj =
n∑
i=1
zji u
α
i
=
n∑
i=1
zji
1√
m
fαi
=
n∑
i=1
(
xji − xj√
msj
)(
fαi − f
α
√
m
√
var(fα)
)
= corr(xj, fα) (48)
7.2 Annexe 2 : De´monstration de la proprie´te´ des facteurs et
des ”loadings” apre`s rotation
• Les facteurs apre`s rotation sont toujours centre´s.
• L’hypothe`se (H1) est ve´rifie´e car Gˆ′qMGˆq = T ′Fˆ ′qMFˆqT = Iq.
• L’hypothe`se (H2) est ve´rifie´e car la matrice des erreurs Eˆq n’est pas modifie´e.
• L’hypothe`se (H3) est ve´rifie´e car Eˆ ′qMGˆq = Eˆ ′qMFˆqT = 0.
• Les ”loadings” apre`s rotation, note´s bˆαj , repre´sentent les corre´lations des variables xj
aux facteurs gα apre`s la rotation.
c© Revue MODULAD, 2007 -28- Nume´ro 37
On a : Bˆq = AˆqT = Z
′(UqT ) = Z ′U˘q ou` U˘q = UqT .
De plus, on a :
gˆα =
√
mu˘α
ou` gˆα est la αe`me colonne de la matrice Gˆq, et u˘
α est la αe`me colonne de la matrice U˘q.
On en de´duit :
bˆαj =
n∑
i=1
zji u˘
α
i
=
n∑
i=1
zji
1√
m
gαi
=
n∑
i=1
(
xji − xj√
msj
)(
gαi − gα√
m
√
var(gα)
)
= corr(xj, gα). (49)
• La matrice de saturation apre`s la rotation reproduit toujours le mode`le de structure
de covariance de´fini par (8) :
BˆqBˆ
′
q + Ξˆ = AˆqTT
′Aˆ′q + Ξˆ = AˆqAˆ
′
q + Ξˆ = R. (50)
• Les communalite´s sont inchange´es :
hˆ2j =
q∑
α=1
(bˆαj )
2 =
q∑
α=1
(aˆαj )
2 (51)
car BˆqBˆ
′
q = (AˆqT )(AˆqT )
′ = AˆqAˆ′q.
• La variance totale explique´e par les q facteurs communs n’est pas modifie´e :
p∑
j=1
q∑
α=1
(bˆαj )
2 =
p∑
i=1
q∑
α=1
(aˆαj )
2. (52)
Re´fe´rences
[1] Baccini A., Besse P. (2005), ”Data mining I, Exploration Statistique”
http ://www.lsp.ups-tlse.fr/Besse/pub/Explo stat.pdf.
[2] Bouveyron C., (2006),Mode´lisation et classification des donne´es de grande dimension -
Application a` l’analyse d’images, p 45-47, The`se, Universite´ Joseph Fourier - Grenoble
1.
[3] Fine J. (1993), ”Proble`mes d’inde´termination en analyse en facteurs et analyse en
composantes principales optimale”, Revue de Statistique Applique´e, tome 41, n˚ 4, p
45-72.
[4] Garnett J.-C.(1919), ”General ability, cleverness and purpose”, British Journal of
Psychiatry, 9, p 345-366.
c© Revue MODULAD, 2007 -29- Nume´ro 37
[5] Harman H. H. (1960), Modern Factor Analysis, University of Chicago Press.
[6] Heywood H.B. (1931), ”On finite sequences of real numbers”, Proceedings of the Royal
Society, Series A, 134, p 486-501.
[7] Hotelling H. (1933), ”Analysis of a complex of statistical variables into principal com-
ponents”, Journal of Educational Psychology, 24, p 417-441.
[8] Jobson J.D. (1992), Applied Multivariate Data Analysis, Volume II : Categorical and
Multivariate Methods, Springer-Verlag.
[9] Lawley D.N., Maxwell A.E. (1963), Factor Analysis as a statistical method, Butter-
worths London.
[10] Lebart L., Morineau A., Piron M. (1997), Statistique exploratoire multidimension-
nelle, 2e cycle, 2e e´dition, Editions Dunod.
[11] Pearson K. (1901), ”On lines and planes of closest fit to systems of points in space”,
Philosophical Magazine, 2, p 559-572.
[12] Rencher, A.C. (2002),Methods of Multivariate Analysis, Second Edition, Wiley Series
in Probability and Statistics.
[13] Seber G.A.F. (1984), Multivariate observations, Wiley Series in Probability and Ma-
thematical Statistics.
[14] Spearman C. (1904), ”General intelligence, objectively determined and measured”,
American Journal of Psychology, 15, p 201-293.
[15] Tipping M.E, Bishop C.M. (1999), ”Probabilistic Principal Component Analysis”,
Journal of the Royal Statistical Society, Series B, 61, Part 3, p 611-622.
c© Revue MODULAD, 2007 -30- Nume´ro 37
