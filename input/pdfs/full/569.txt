©Revue MODULAD 2010 34 Numéro 42 
 
 
 
 
 
 
‘Discussion sur les prédicteurs conformes  
proposés par Alex Gammerman et Vladimir Vovk’ 
 
Alexey Chervonenkis 
 
Research Institute of Control Problems, Russian Academy of Sciences 
Computer Learning Research Centre, 
Royal Holloway, University of London, UK 
chervnks@ipu.rssi.ru 
 
 
 
Mots clés : apprentissage automatique, prédicteurs conformes, complexité de Kolmogorov, 
approche bayésienne, étrangeté d’une prédiction 
 
 Abstract: Conformer predictors approach seems to be new and powerful. Its main advantage is 
that it is non-parametric and based only on the i.i.d. assumption. In comparison to the Bayesian 
approach, no prior distribution is used. The main theoretical result is the proof of validity of 
proposed conformal predictors. The second result is that asymptotically the relative number of cases 
when the real output value is within confidence interval converges to the average value of 
conformal predictors. The proposed technique is now applied to a large variety of practical 
problems. Two drawbacks of the approach are still mentioned in this discussion  
 
Keywords: Machine Learning, conformer predictor, Kolmogorov complexity, Bayesian approach, 
prediction strangeness 
 
Il y a aujourd’hui de nombreux algorithmes d’Apprentissage Automatique très diversifiés qui sont 
développés et appliqués dans les différents domaines scientifiques et industriels. Mais cette 
nouvelle approche comportait jusqu’à présent un certain inconvénient : on ne peut calculer un degré 
de confiance à accorder à  la prédiction d’une valeur pour les nouveaux objets.  
 
L’idée principale de l’article des professeurs Alex Gammerman et Vladimir Vovk est de considérer 
toutes les étiquettes possibles pour un nouvel élément et d’évaluer l’étrangeté de chaque appellation 
en comparaison de celles des objets de l’ensemble d’apprentissage. Tout le problème est de trouver 
une mesure intéressante pour cette ‘étrangeté’. Dans un premier temps les auteurs tentent 
d’appliquer les idées de la complexité selon Kolmogorov pour estimer l’étrangeté des étiquettes. 
Mais la complexité n’est d’une part pas calculable, de plus elle n’est définie qu’à une constante 
près, et enfin elle n’a de sens que pour l’entière séquence des objets, et non pas pour l’un d’entre 
eux en particulier.  
 
Les auteurs proposent alors une autre idée (toujours en liaison avec la complexité chez 
Kolmogorov) pour estimer cette étrangeté des étiquettes. C’est pour chaque algorithme particulier 
d’apprentissage, qu’on envisage de trouver une mesure raisonnable de l’étrangeté de l’étiquette 
attribuée à un objet. Pour la régression (ou la régression Ridge) cette mesure peut être choisie 
comme la différence absolue entre le résultat de la régression et le résultat réel : plus grande est la 
différence, plus ‘étranger’ est l’objet. Dans une approche SVM de reconnaissance de formes, cela 
 
©Revue MODULAD 2010 35 Numéro 42 
 
 peut être les poids des vecteurs de support : plus les poids sont importants, moins la confiance dans 
les étiquettes est grande ; des mesure analogues d’étrangeté peuvent être envisagées pour les autres 
algorithmes.  
 
La démarche est finalement la suivante : on parcourt tout l’éventail des étiquettes pour un nouvel 
objet. Pour chaque possibilité, on adjoint cette réalisation à l’ensemble d’apprentissage. On déroule 
ensuite l’algorithme d’apprentissage et l’on ordonne les objets par la mesure d’étrangeté choisie. On 
estime la confiance en l’étiquette par la différence à un de la proportion, dans l’ensemble 
d’apprentissage complet, d’objets plus étrangers que le nouveau.  
Cette approche  nous semble nouvelle et pleine de promesses. Son point fort est qu’il s’agit d’une 
méthode non paramétrique et la seule hypothèse que l’on fait est celle i.i.d. de distribution identique 
et indépendante des données. Par rapport à l’approche bayésienne, on n’a besoin ici d’aucune 
distribution a priori. Le résultat théorique le plus important est la démonstration de la validité des 
prédicteurs conformes. Cette validité consiste en ceci : jamais en moyenne les prédicteurs 
conformes ne surévaluent dans leur prédiction les niveaux de précision et de confiance. De plus 
l’autre résultat important est que la proportion des cas où la valeur réelle est à l’intérieur d’un 
certain intervalle de confiance converge asymptotiquement vers la valeur moyenne des prédicteurs 
conformes.  
 
On a déjà développé et implémenté différentes  versions de ces recherches pour un grand éventail 
d’applications. Je voudrais cependant  mentionner deux points de cet article qui me semblent encore 
sujets à caution: 
 
1. Il n’y pas de considération théorique sur le degré d’optimalité des intervalles de confiance 
suggérés pour chaque objet. Dans le cas général, il pourrait se produire que pour certains 
objets, l’intervalle soit trop grand, et que pour d’autres il soit par contre trop restreint, alors 
qu’en moyenne ce qu’on nomme ‘validité’ dans cet article soit bon. Pour l’approche 
bayésienne, on peut prouver l’optimalité, mais il faut une poser une distribution a priori. On 
présente justement dans le texte les résultats expérimentaux de comparaisons avec 
l’approche bayésienne, mais seulement dans des cas précis où l’on constate que les résultats 
sont très proches des résultats optimaux. Nous pensons cependant qu’une étude théorique de 
la question serait pertinente. 
 
2. Dans les problèmes de reconnaissance des formes, on propose une mesure du niveau de 
confiance par le calcul suivant : la différence à un du deuxième niveau le plus grand repéré 
par l’ordre du degré de hasard. Il nous semblerait plus judicieux d’utiliser comme formule la 
différence entre la plus grande des valeurs et la suivante. Par exemple dans la table 1, ligne 
3, on voit que la crédibilité n’est que de 1.43%, alors que le niveau de confiance est de 
98.93%. Si on considère la différence entre la première meilleure valeur et la deuxième 
meilleure, le niveau de confiance devient très faible, et effectivement, dans ce cas précis, la 
prédiction était fausse. 
