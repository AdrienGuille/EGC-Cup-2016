RÃ©sumÃ© hybride de flux de donnÃ©es par Ã©chantillonnage et
classification automatique
Nesrine Gabsiâˆ—,âˆ—âˆ—, Fabrice ClÃ©rot âˆ—âˆ—
Georges HÃ©brailâˆ—
âˆ—Institut TELECOM ; TELECOM ParisTech ; CNRS LTCI
46, rue Barrault 75013 Paris
PrÃ©nomAuteur.NomAuteur@telecom-paristech.fr,
âˆ—âˆ— France Telecom RD
2, avenue P.Marzin 22307 Lannion
PrÃ©nomAuteur.NomAuteur@orange-ftgroup.com
RÃ©sumÃ©. Face Ã  la grande volumÃ©trie des donnÃ©es gÃ©nÃ©rÃ©es par les systÃ¨mes in-
formatiques, lâ€™hypothÃ¨se de les stocker en totalitÃ© avant leur interrogation nâ€™est
plus possible. Une solution consiste Ã  conserver un rÃ©sumÃ© de lâ€™historique du
flux pour rÃ©pondre Ã  des requÃªtes et pour effectuer de la fouille de donnÃ©es.
Plusieurs techniques de rÃ©sumÃ© de flux de donnÃ©es ont Ã©tÃ© dÃ©veloppÃ©es, telles
que lâ€™Ã©chantillonnage, le clustering, etc. Selon le champ de requÃªte, ces rÃ©sumÃ©s
peuvent Ãªtre classÃ©s en deux catÃ©gories: rÃ©sumÃ©s spÃ©cialisÃ©s et rÃ©sumÃ©s gÃ©nÃ©-
ralistes. Dans ce papier, nous nous intÃ©ressons aux rÃ©sumÃ©s gÃ©nÃ©ralistes. Notre
objectif est de crÃ©er un rÃ©sumÃ© de bonne qualitÃ©, sur toute la pÃ©riode temporelle,
qui nous permet de traiter une large panoplie de requÃªtes. Nous utilisons deux
algorithmes : CluStream et StreamSamp. Lâ€™idÃ©e consiste Ã  les combiner afin de
tirer profit des avantages de chaque algorithme. Pour tester cette approche, nous
utilisons un Benchmark de donnÃ©es rÃ©elles "KDD_99". Les rÃ©sultats obtenus
sont comparÃ©s Ã  ceux obtenus sÃ©parÃ©ment par les deux algorithmes.
1 Introduction
Il existe actuellement plusieurs applications qui gÃ©nÃ¨rent des informations en trÃ¨s grande
quantitÃ©. Ces applications sont issues de domaines variÃ©s tels que la gestion du trafic dans un
rÃ©seau IP. Lorsque le volume de donnÃ©es augmente, il devient trÃ¨s coÃ»teux de stocker toutes
les donnÃ©es avant de les analyser : il est judicieux dâ€™adopter un traitement Ã  la volÃ©e pour ces
informations. Un nouveau mode de traitement de lâ€™information Ã©merge. Il sâ€™agit du traitement
de flux de donnÃ©es. Dans (Golab et Ã–zsu, 2003), les auteurs dÃ©finissent un flux de donnÃ©es
comme Ã©tant une sÃ©quence dâ€™items continue, ordonnÃ©e, arrivant en temps rÃ©el avec des dÃ©bits
importants.
Plusieurs travaux ((Babcock et al., 2002), (Golab et Ã–zsu, 2003), (Ma et al., 2007), (Towne
et al., 2007)) montrent que les SystÃ¨mes de Gestion de Base de DonnÃ©es (SGBD) sont in-
adaptÃ©s pour ce type dâ€™applications. Ceci est essentiellement dÃ» Ã  la nature continue du flux
RÃ©sumÃ© hybride de flux de donnÃ©es
ainsi que la volumÃ©trie des donnÃ©es qui transitent. En rÃ©ponse aux besoins spÃ©cifiques des
applications qui traitent des flux de donnÃ©es, plusieurs SystÃ¨mes de Gestion de Flux de Don-
nÃ©es (SGFD), acadÃ©miques et commerciaux, ont Ã©tÃ© dÃ©veloppÃ©s : Stream (Arasu et al., 2004),
Aurora (Abadi et al., 2003), etc.
Les SGFD permettent dâ€™exprimer des requÃªtes continues qui sâ€™Ã©valuent au fur et Ã  mesure
sur un flux ou sur des fenÃªtres (sous ensembles finis du flux) (Babcock et al., 2002). Ces
requÃªtes doivent Ãªtre spÃ©cifiÃ©es avant lâ€™arrivÃ©e du flux. De nouveaux besoins peuvent parfois
apparaÃ®tre aprÃ¨s le passage de lâ€™information. Dans ce cas, le systÃ¨me ne pourra pas rÃ©pondre
aux requÃªtes posÃ©es car toutes les donnÃ©es nâ€™appelant aucun traitement sont dÃ©finitivement
perdues. Il est donc nÃ©cessaire dans certains cas de conserver un rÃ©sumÃ© du flux de donnÃ©es.
Il existe dans la littÃ©rature de nombreux travaux sur des structures de rÃ©sumÃ© (Gemulla et
Lehner, 2008), (Cormode et Garofalakis, 2007), (Guha et Harb, 2005), (Guha et al., 2001),
(Flajolet et Martin, 1985), (Bloom, 1970) qui sont des structures dÃ©diÃ©es Ã  une tÃ¢che particu-
liÃ¨re. La problÃ©matique de cet article concerne les rÃ©sumÃ©s gÃ©nÃ©ralistes. Leur objectif est de
fournir un rÃ©sultat approchÃ© pour nâ€™importe quelle analyse sur les donnÃ©es dâ€™origine (requÃªte
ou fouille) posÃ©e Ã  lâ€™instant prÃ©sent sur une fenÃªtre du passÃ©. Ce domaine est encore rÃ©cent et
il nâ€™existe Ã  ce jour que peu de travaux (Csernel et al., 2006), (Aggarwal et al., 2003).
Dans ce papier, nous nous intÃ©ressons Ã  la prÃ©servation Ã  long terme des donnÃ©es du flux.
Notre objectif est dâ€™Ã©laborer un rÃ©sumÃ© Ã  la fois gÃ©nÃ©rique (opÃ©rationnel pour tout type dâ€™ap-
plication), gÃ©nÃ©raliste, Ã©volutif (adaptable aux variations des flux) et de bonne qualitÃ© (reprÃ©-
sentatif du flux dâ€™origine) sur toute la pÃ©riode temporelle. Nous utilisons deux algorithmes
StreamSamp (Csernel et al., 2006) et CluStream (Aggarwal et al., 2003) afin de tirer profit
des avantages de ces deux approches et de crÃ©er un rÃ©sumÃ© robuste qui respecte les critÃ¨res
Ã©noncÃ©s.
Nous proposons dans ce papier une mÃ©thode hybride qui permet de rÃ©sumer des grands flux
de donnÃ©es numÃ©riques. Il est possible de lancer, sur le rÃ©sumÃ© conÃ§u, des requÃªtes et dâ€™obtenir
des rÃ©ponses proches de celles quâ€™on aurait obtenues en prÃ©sence de la totalitÃ© des donnÃ©es.
2 RÃ©sumÃ©s de flux de donnÃ©es
De nombreuses structures de rÃ©sumÃ© ont Ã©tÃ© dÃ©veloppÃ©es. Certaines structures sont Ã  vo-
cation gÃ©nÃ©raliste, alors que dâ€™autres sont destinÃ©es Ã  un type particulier de traitement. Nous
nous intÃ©ressons dans ce papier aux rÃ©sumÃ©s gÃ©nÃ©ralistes.
2.1 RÃ©sumÃ© gÃ©nÃ©raliste
Dâ€™aprÃ¨s (Csernel, 2008) un rÃ©sumÃ© gÃ©nÃ©raliste doit remplir quatre conditions : rÃ©pondre
aux requÃªtes posÃ©es sur nâ€™importe quel horizon temporel fixÃ©, traiter un large champ de re-
quÃªtes (sÃ©lection, mÃ©diane, etc.), permettre des analyses supervisÃ©es des donnÃ©es (arbres de
dÃ©cision, etc.) et autoriser des tÃ¢ches dâ€™analyse exploratoire (classification, etc.).
Une autre faÃ§on de dÃ©finir un rÃ©sumÃ© gÃ©nÃ©raliste consiste Ã  rÃ©aliser une organisation tem-
porelle dâ€™une sÃ©rie dâ€™informations extraites dâ€™un flux de donnÃ©es. Ces extractions peuvent Ãªtre
rÃ©alisÃ©es par le biais de solutions mÃ©moires telles que lâ€™Ã©chantillonnage, les histogrammes, etc.
N. GABSI et al.
2.1.1 Solutions MÃ©moires
Les solutions mÃ©moires permettent de conserver des rÃ©sumÃ©s soit de la totalitÃ© des flux
de donnÃ©es, soit des rÃ©sumÃ©s qui portent sur les derniÃ¨res observations. Il existe deux grandes
opÃ©rations dâ€™extraction de lâ€™information : lâ€™Ã©chantillonnage et les histogrammes.
Lâ€™Ã©chantillonnage. Lâ€™Ã©chantillonnage est une technique directement issue des statistiques
ayant pour objectif de fournir des informations sur une large population Ã  partir dâ€™un Ã©chan-
tillon reprÃ©sentatif issu de celle-ci. Les techniques dâ€™Ã©chantillonnages classiques ne sont pas
toutes adaptÃ©es aux flux de donnÃ©es. En effet, elles nÃ©cessitent dâ€™avoir lâ€™intÃ©gralitÃ© de la base
afin de sÃ©lectionner un Ã©chantillon reprÃ©sentatif. Dans le cadre des flux de donnÃ©es, cette
contrainte ne peut Ãªtre respectÃ©e.
De nouveaux algorithmes dâ€™Ã©chantillonnage ont Ã©tÃ© dÃ©veloppÃ©s. Vitter (Vitter, 1985) a
introduit une technique dâ€™Ã©chantillonnage alÃ©atoire incrÃ©mentale. Cette technique permet de
concevoir un rÃ©sumÃ© sur la totalitÃ© du flux de donnÃ©es. Il existe des techniques plus sophisti-
quÃ©es qui permettent de maintenir un Ã©chantillon alÃ©atoire sur une fenÃªtre glissante (Babcock
et al., 2002).
Lâ€™objectif de notre approche est de permettre des interrogations sur le passÃ© lointain. Adap-
ter une technique dâ€™historisation selon le principe de Babcock serait Ã  lâ€™encontre de cet objectif.
Les histogrammes. La technique des histogrammes est trÃ¨s proche de la technique de lâ€™agrÃ©-
gat. Un histogramme permet de grouper les donnÃ©es dâ€™une variable du flux selon les valeurs
possibles. Pour chaque groupe, une surface est construite dont la base correspond aux valeurs
de ce groupe, et dont la taille est proportionnelle au nombre dâ€™observations dans le groupe.
2.1.2 Solutions temporelles
Les solutions temporelles permettent de gÃ©rer au cours du temps les flux dâ€™informations
produits par les techniques mÃ©moires. Elle permettent dâ€™archiver des rÃ©sumÃ©s qui couvrent
lâ€™intÃ©gralitÃ© du flux avec un espace bornÃ©.
Les fenÃªtres inclinÃ©es. Cette structure permet de conserver des rÃ©sumÃ©s couvrant des pÃ©-
riodes temporelles de tailles variables. Comme le montre la Figure 1, les rÃ©sumÃ©s ont une taille
constante mais sâ€™Ã©talent sur des pÃ©riodes temporelles de durÃ©es variables, plus courtes pour le
prÃ©sent et plus longues pour le passÃ© lointain.
FIG. 1 â€“ Structure des fenÃªtres inclinÃ©es.
RÃ©sumÃ© hybride de flux de donnÃ©es
Les systÃ¨mes de clichÃ©s. Tout comme les fenÃªtres inclinÃ©es, cette technique permet un trai-
tement efficace de la dimension temporelle. Lâ€™objectif est simple, il sâ€™appuie sur la sauvegarde
Ã  des instants rÃ©guliers de lâ€™Ã©tat du systÃ¨me au moment oÃ¹ un clichÃ© est pris. Le clichÃ© ainsi
obtenu fournit des informations sur le traitement du flux depuis son lancement jusquâ€™Ã  lâ€™ins-
tant de sa capture. Ces clichÃ©s sont ensuite conservÃ©s selon une structure pyramidale. Comme
le montre la Figure 2, cette structure privilÃ©gie les instants rÃ©cents par rapport aux instants les
plus anciens. Proportionnellement au temps, le nombre de clichÃ©s conservÃ©s est de plus en plus
faible.
FIG. 2 â€“ ReprÃ©sentation des clichÃ©s sur la structure pyramidale.
2.2 Clustream : approche par clustering
CluStream (Aggarwal et al., 2003) est un algorithme robuste basÃ© sur la classification au-
tomatique des donnÃ©es numÃ©riques. Lâ€™idÃ©e consiste Ã  construire un rÃ©sumÃ© du flux de donnÃ©es
sous la forme dâ€™un ensemble de micro-classes Ã©volutives dont des clichÃ©s sont mÃ©morisÃ©s rÃ©-
guliÃ¨rement. Pour dÃ©velopper cet algorithme, Aggarwal sâ€™est inspirÃ© de lâ€™algorithme BIRCH
(Zhang et al., 1996) en utilisant la structure des CFVs (Cluster Feature Vector). Cette structure
conserve des donnÃ©es statistiques qui rÃ©sument lâ€™ensemble des Ã©lÃ©ments dâ€™une micro-classe
(effectif total, somme des Ã©lÃ©ments de chaque variable et somme de leurs carrÃ©s). Dans (Aggar-
wal et al., 2003), Aggarwal ajoute aux CFVs lâ€™extension temporelle des variables. Lorsquâ€™un
nouvel Ã©lÃ©ment du flux arrive, on calcule sa distance par rapport au barycentre de chaque
micro-classe et on lâ€™ajoute Ã  la classe la plus proche. Lors de lâ€™ajout dâ€™un Ã©lÃ©ment, le CFV
de la micro-classe est automatiquement mis Ã  jour sans que lâ€™appartenance de lâ€™Ã©lÃ©ment Ã  la
classe soit mÃ©morisÃ©e.
Cet algorithme permet de mÃ©moriser, dans un clichÃ©, lâ€™Ã©tat de toutes les micro-classes. Ces
clichÃ©s sont ensuite conservÃ©s selon une structure pyramidale. GrÃ¢ce aux propriÃ©tÃ©s mathÃ©ma-
tiques des CFVs, on peut suivre lâ€™Ã©volution de ces micro-classes. On effectue des opÃ©rations
de soustractions sur les clichÃ©s afin dâ€™obtenir le contenu du flux entre deux prises de clichÃ©s.
Cette technique permet de fournir, dans la limite du nombre de clichÃ©s pris, une version du
rÃ©sumÃ© pour nâ€™importe quelle section du flux situÃ©e entre la prise de deux clichÃ©s.
En se basant sur une technique de clustering couplÃ©e avec une structure de fenÃªtre py-
ramidale, CluStream permet de conserver des clichÃ©s reprÃ©sentatifs mÃªme pour des donnÃ©es
anciennes. Ceci permet de suivre lâ€™Ã©volution du flux de donnÃ©es au cours du temps. Cependant,
son inconvÃ©nient est le traitement relativement lourd des calculs de distance lorsque le dÃ©bit
du flux est Ã©levÃ©.
2.3 StreamSamp
StreamSamp est Ã©galement un algorithme de rÃ©sumÃ© gÃ©nÃ©raliste basÃ© sur lâ€™Ã©chantillonnage
alÃ©atoire du flux de donnÃ©es. DÃ¨s leur arrivÃ©e, les donnÃ©es du flux sont Ã©chantillonnÃ©es Ã  un
N. GABSI et al.
taux Î± et placÃ©es dans des Ã©chantillons de taille T . Lorsque T est atteint, StreamSamp mÃ©mo-
rise lâ€™Ã©chantillon ainsi que sa date de dÃ©but et fin de constitution. Lâ€™ordre 0 est associÃ© Ã  cet
Ã©chantillon. Plus on avance dans le temps, plus le nombre dâ€™Ã©chantillons constituÃ©s, dâ€™ordre 0,
augmente. Il est impossible de mÃ©moriser de faÃ§on permanente tous ces Ã©chantillons.
Pour rÃ©duire lâ€™espace, lâ€™algorithme se base sur la structure des fenÃªtres inclinÃ©es. Lorsque
L (nombre maximal dâ€™Ã©chantillons par ordre) est atteint, on fusionne les deux Ã©chantillons
dâ€™ordre i les plus anciens. Un nouvel Ã©chantillon de taille T qui couvre une pÃ©riode temporelle,
deux fois plus grande, et qui sera affectÃ© Ã  lâ€™ordre i+1 est construit par rÃ©-Ã©chantillonnage alÃ©a-
toire. Par ailleurs, StreamSamp permet lâ€™exploitation et lâ€™analyse du rÃ©sumÃ© crÃ©Ã©. Pour traiter
une pÃ©riode temporelle, les Ã©chantillons qui appartiennent Ã  cette pÃ©riode sont concatÃ©nÃ©s et
pondÃ©rÃ©s de faÃ§on Ã  conserver la mÃªme reprÃ©sentativitÃ© pour chaque Ã©lÃ©ment de lâ€™Ã©chantillon
final.
Le rÃ©sumÃ© conÃ§u Ã  partir de StreamSamp a la particularitÃ© dâ€™Ãªtre petit et rapide Ã  Ã©laborer.
Il ne dÃ©pend pas de la vitesse dâ€™arrivÃ©e des Ã©lÃ©ments. Cependant la qualitÃ© du rÃ©sumÃ© produit
pour des anciennes pÃ©riodes temporelles se dÃ©grade. En effet, les anciens Ã©lÃ©ments ont un poids
croissant pour une taille dâ€™Ã©chantillon constamment fixe. Par consÃ©quent, si un Ã©chantillon
contient des Ã©lÃ©ments rÃ©cents (poids beaucoup plus faible) et des Ã©lÃ©ments anciens, ces derniers
vont considÃ©rablement augmenter les erreurs dans le rÃ©sultat des requÃªtes. Lâ€™utilisation des
fenÃªtres inclinÃ©es ne permet donc pas de privilÃ©gier (en terme de prÃ©cision) une autre pÃ©riode
que le passÃ© rÃ©cent.
3 Approche hybride de rÃ©sumÃ© gÃ©nÃ©raliste
Dans cet article nous proposons une nouvelle approche pour lâ€™amÃ©lioration des rÃ©sumÃ©s gÃ©-
nÃ©ralistes. Cette approche, intitulÃ©e "approche hybride", combine les avantages de StreamSamp
et CluStream, tout en Ã©vitant leurs inconvÃ©nients. Ã‰tant donnÃ© quâ€™on fait intervenir CluStream,
seul le cas des donnÃ©es numÃ©riques peut Ãªtre considÃ©rÃ©.
Comme le montre la Figure 3, le flux est dâ€™abord envoyÃ© dans le processus StreamSamp
qui permet de conserver des Ã©chantillons alÃ©atoires. Lorsque les Ã©chantillons ne sont plus re-
prÃ©sentatifs au sens des critÃ¨res dÃ©taillÃ©s plus bas (section 3.1), ils sont envoyÃ©s dans le pro-
cessus CluStream. Pour respecter la chronologie de CluStream il faut, avant lâ€™envoi de ces
Ã©chantillons, envoyer les Ã©chantillons des ordres supÃ©rieurs. Lâ€™insertion des Ã©chantillons se fait
Ã©lÃ©ment par Ã©lÃ©ment tout en respectant leur pondÃ©ration.
Le passage dâ€™un processus vers lâ€™autre nâ€™est pas alÃ©atoire mais doit respecter un certain
nombre de critÃ¨res. Les critÃ¨res de passage dÃ©finis ci-dessous permettent de dÃ©terminer quand
un Ã©chantillon est reprÃ©sentatif ou non.
3.1 CritÃ¨res de passage
Le choix des critÃ¨res de passage est basÃ© sur les propriÃ©tÃ©s intrinsÃ¨ques des deux tech-
niques : StreamSamp est guidÃ© par le rÃ©-Ã©chantillonnage alÃ©atoire et CluStream par la mise-Ã -
jour de micro-classes Ã©volutives. Maintenir une bonne qualitÃ© pour ces deux processus permet
de conserver un rÃ©sumÃ© prÃ©cis et de qualitÃ©. Le premier critÃ¨re (test sur la variance) surveille
le rÃ©-Ã©chantillonnage alÃ©atoire qui entraine une dÃ©gradation du rÃ©sumÃ© de StreamSamp. Le se-
cond critÃ¨re se base sur la conservation des centroides, mode de reprÃ©sentation de CluStream.
RÃ©sumÃ© hybride de flux de donnÃ©es
FIG. 3 â€“ Approche de passage de StreamSamp vers CluStream.
3.1.1 CritÃ¨re de variance
Notre objectif est de mesurer la qualitÃ© de la reprÃ©sentation par un Ã©chantillon sur chaque
variable, ce qui revient Ã  Ã©tudier une contrainte sur la variance. En effet, une fusion de deux
Ã©chantillons dâ€™une pÃ©riode donnÃ©e donne lieu Ã  deux fois moins dâ€™individus qui sâ€™Ã©talent sur
une pÃ©riode de mÃªme durÃ©e. Le mode de reprÃ©sentation utilisÃ© dans StreamSamp est ainsi de
moins en moins prÃ©cis, donc de moindre qualitÃ©.
Un Ã©chantillon est de bonne qualitÃ© sâ€™il permet de rÃ©pondre de faÃ§on suffisamment prÃ©cise
aux requÃªtes posÃ©es. Il doit pouvoir bien estimer les agrÃ©gats (nombre dâ€™individus, moyenne,
somme, etc.).
Puisquâ€™il sâ€™agit dâ€™un Ã©chantillonnage alÃ©atoire, Ã©tudier la prÃ©cision sur lâ€™estimation dâ€™un
agrÃ©gat revient Ã  calculer sa variance. Ce qui permet de quantifier lâ€™erreur relative dâ€™un estima-
teur. Lâ€™utilisation dâ€™un critÃ¨re de variance permet de fixer une borne sur lâ€™erreur relative (err)
ce qui revient Ã  fixer une borne sur la variance, calculÃ©e sur lâ€™Ã©chantillon. Dans la thÃ©orie des
sondages, lâ€™erreur relative est calculÃ©e comme suit :
err =
âˆ£âˆ£FÌ‚âˆ’F âˆ£âˆ£
FÌ‚
avec F : valeur de lâ€™agrÃ©gat et FÌ‚ : estimateur de F
La question posÃ©e concerne la prÃ©cision dâ€™un Ã©chantillon E3 issu de la fusion de deux Ã©chan-
tillons E1 et E2. Pour cela, nous cherchons Ã  estimer lâ€™erreur sur E3. Dans ce qui suit, on
prendra lâ€™exemple de la moyenne qui est estimÃ©e Ã  partir de lâ€™Ã©chantillon (E1 âˆª E2).
Vu que notre sondage est alÃ©atoire simple, nous obtenons ainsi avec une probabilitÃ© de
95% : âˆ£âˆ£âˆ£xâˆ’ xÌ‚(E3)
âˆ£âˆ£âˆ£ â‰¤ 2
âˆš
V ar(xÌ‚(E1 âˆª E2))
Avec : E1 et E2 : les deux Ã©chantillons Ã  fusionner, E3 : lâ€™Ã©chantillon rÃ©sultant de la fusion,
xÌ‚ : lâ€™estimateur de la moyenne calculÃ© sur E3 et x : la vraie moyenne.
Si on vÃ©rifie lâ€™inÃ©galitÃ© suivante : 2
âˆš
V ar(Ì‚x(E1âˆªE2))
xÌ‚(E3)
â‰¤ err alors on estime quâ€™on a conservÃ©
un Ã©chantillon de bonne qualitÃ© (erreur relative infÃ©rieure ou Ã©gale Ã  err).
N. GABSI et al.
La variance de lâ€™estimateur sur lâ€™Ã©chantillon, est calculÃ©e comme suit :
V ar(xÌ‚(E1 âˆª E2)) = (1âˆ’
2n
N
)(
1
2n
)[
1
2nâˆ’ 1
âˆ‘
kâˆˆE1âˆªE2
(xk âˆ’ x)
2]
oÃ¹ n : taille dâ€™un Ã©chantillon, N : taille de la population concernÃ©e
3.1.2 CritÃ¨re de conservation des centroÃ¯des
Dans notre approche de passage, le cycle de vie dâ€™un Ã©chantillon est composÃ© de deux
phases complÃ©mentaires. La premiÃ¨re Ã©tape est lâ€™Ã©volution de lâ€™Ã©chantillon dans StreamSamp.
La deuxiÃ¨me est lâ€™intÃ©gration de cet Ã©chantillon dans le processus de CluStream.
Il est de ce fait important de prendre en considÃ©ration les contraintes relatives Ã  chaque
processus. Nous avons Ã©tudiÃ© dans la section prÃ©cÃ©dente la contrainte sur le fondement de
StreamSamp (contrainte sur la variance). En suivant la mÃªme logique, nous Ã©tudions la conser-
vation des centroÃ¯des lors de lâ€™insertion des Ã©chantillons dans CluStream. En effet, CluStream
permet de regrouper les Ã©lÃ©ments "proches" dans une mÃªme micro-classe. Le processus de rÃ©-
Ã©chantillonnage alÃ©atoire entraÃ®ne une dÃ©gradation du rÃ©sumÃ©. ConsÃ©quence, la prÃ©cision sur
la position des centroides se dÃ©grade. Nous avons alors ajoutÃ© un second critÃ¨re qui se base sur
la conservation des centroides pour respecter CluStream.
Afin de conserver cette prÃ©cision, nous calculons lors de chaque opÃ©ration de rÃ©-Ã©chantillonnage,
la distance entre le centroÃ¯de (G) (calculÃ© Ã  partir des Ã©chantillons Ã  fusionner (E1 âˆªE2)) et le
centroÃ¯de (G) (calculÃ© Ã  partir de lâ€™Ã©chantillon estimÃ© (E3)).
La distance entre (G) et (G) doit Ãªtre infÃ©rieure Ã  un seuil fixÃ© (D). Si cette condition nâ€™est
plus respectÃ©e, le processus dâ€™Ã©chantillonnage est arrÃªtÃ© pour passer Ã  CluStream.
Comme le montre la Figure 4, nous calculons Ã  partir des individus deE1 etE2 le centroÃ¯de
(G). Nous estimons par la suite E3 Ã  partir de E1 et E2 et nous calculons (G) Ã  partir de
lâ€™Ã©chantillon E3.
Nous vÃ©rifions par la suite si d2(G,G) â‰¤ D. Avec D =  Ã—
âˆ‘
E1âˆªE2
(d2(x, xi)), lâ€™inertie
intra-classe de lâ€™Ã©chantillon constituÃ© Ã  partir de (E1 âˆª E2).
4 ExpÃ©rimentations
Toutes les expÃ©rimentations ont Ã©tÃ© lancÃ©es sur un ordinateur Ã©quipÃ© dâ€™un processeur Intel
Core 2 Duo 1.66 Ghz avec 1000 Mo de mÃ©moire. Le systÃ¨me dâ€™exploitation est Windows XP
Professionnel. Tous les algorithmes ont Ã©tÃ© codÃ©s dans le langage de programmation Java. Pour
Ã©valuer lâ€™efficacitÃ© de notre algorithme, nous lâ€™avons comparÃ© aux algorithmes CluStream et
StreamSamp. Les expÃ©riences ont Ã©tÃ© lancÃ©es sur un jeu de donnÃ©es rÃ©elles, KDD-CUPâ€™99
Network Intrusion Detection stream data set. Il sâ€™agit du mÃªme jeu de donnÃ©es prÃ©alablement
utilisÃ© pour lâ€™Ã©valuation de CluStream et StreamSamp. Ce jeu correspond Ã  lâ€™ensemble des
connexions TCP enregistrÃ©es sur une pÃ©riode de deux semaines de trafic sur le rÃ©seau LAN
gÃ©rÃ© par le MIT Lincoln Labs. Le jeu sur lequel nous avons menÃ© nos expÃ©riences contient
500000 enregistrements avec 34 variables numÃ©riques. Chaque enregistrement correspond Ã 
une connexion. Une connexion fait appel Ã  un service (http, Telnet, etc.). Les variables utilisÃ©es
dans nos expÃ©rimentations sont :
RÃ©sumÃ© hybride de flux de donnÃ©es
FIG. 4 â€“ Calcul de distance entre les centroides G et G.
â€¢ Variable 16 (Count) : Nombre de connexions Ã©mises durant les 2 derniÃ¨res secondes vers
la machine destinataire de la connexion courante ;
â€¢ Variable 24 (srv_diff_host_rate) : Pourcentage des connexions faisant appel au mÃªme
service que la connexion courante mais vers des destinataires diffÃ©rents ;
â€¢ Variable 26 (dst_host_srv_count) : Nombre de connexions ayant le mÃªme service et la
mÃªme destination que la connexion courante ;
â€¢ Variable 28 (dst_host_diff_srv_rate) : Pourcentage des connexions vers le mÃªme desti-
nataire et faisant appel Ã  des services diffÃ©rents que ceux de la connexion courante ;
â€¢ Variable 29 (dst_host_same_src_port_rate) : Pourcentage des connexions vers la mÃªme
destination que la connexion courante et utilisant le mÃªme port.
Ã‰tude de la variabilitÃ© du flux. Pour Ã©tudier la variabilitÃ© du flux, nous avons calculÃ© la
moyenne et la variance pour chaque variable sur une fenÃªtre glissante de taille 5000 et avec
un pas de 1000 Ã©lÃ©ments. Les rÃ©sultats obtenus ont permis de vÃ©rifier que le flux de donnÃ©es
utilisÃ© nâ€™est pas stationnaire pour les moments dâ€™ordre 1 et 2. De ce fait, ce jeu de donnÃ©es est
intÃ©ressant pour Ã©valuer notre approche.
DÃ©gradation des donnÃ©es dans StreamSamp. Cette expÃ©rience consiste Ã  Ã©tudier la dÃ©gra-
dation des donnÃ©es dans StreamSamp pour des pÃ©riodes temporelles anciennes. Nous avons
Ã©tudiÃ© lâ€™Ã©volution de lâ€™estimation de la moyenne sur la pÃ©riode temporelle [0-10000]. Nous
avons lancÃ© StreamSamp (Î± = 30%, L = 4, T = 50) 500 fois pour chacune des variables
Ã©tudiÃ©es. Ces paramÃ¨tres ont Ã©tÃ© choisis de faÃ§on Ã  garantir plusieurs opÃ©rations de fusions
dans StreamSamp. Nous avons calculÃ© Ã  diffÃ©rents instants dâ€™observation : (1) lâ€™erreur relative
moyenne sur les diffÃ©rents tirages oÃ¹ il existe une estimation ainsi que, (2) le pourcentage des
tirages dans lesquels des estimations peuvent Ãªtre effectuÃ©es. La Figure 5 montre les rÃ©sultats
obtenus. Nous constatons que pour chacune des variables Ã©tudiÃ©es lâ€™erreur relative moyenne
N. GABSI et al.
StreamSamp CluStream Approche Hybride
T = 50 Nb- classes = 50 err = 4.10âˆ’2
Î± = 30% k-means = 10  = 10âˆ’4
L = 4 Instant de prise de clichÃ© : T = 1
Nombre max de clichÃ©s par ordre : L = 50
TAB. 1 â€“ ParamÃ¨tres des expÃ©rimentations.
augmente avec le nombre dâ€™Ã©lÃ©ments traitÃ©s. Ce qui reprÃ©sente une dÃ©gradation des perfor-
mances de StreamSamp au cours du temps.
FIG. 5 â€“ Erreur relative moyenne sur la pÃ©riode [0-10000] Ã  diffÃ©rents instants dâ€™observation.
Performance de lâ€™approche hybride. Lâ€™objectif de cette expÃ©rience est de comparer les per-
formances de notre approche par rapport Ã  StreamSamp et CluStream. Pour cela, nous avons
traitÃ© tout le flux de donnÃ©es et Ã©valuÃ© lâ€™erreur relative moyenne de lâ€™estimation sur la pÃ©riode
temporelle [0-10000]. Nous avons rÃ©pÃ©tÃ© ce test 50 fois. Le Tableau 1 prÃ©sente les paramÃ¨tres
avec lesquels nos expÃ©rimentation ont Ã©tÃ© lancÃ©es. La Figure 6 montre que pour une pÃ©riode
temporelle assez ancienne [0-10000], Ã©valuÃ©e Ã  la fin du flux, lâ€™approche hybride estime beau-
coup mieux la moyenne que StreamSamp et ceci pour toutes les variables Ã©tudiÃ©es. Par ailleurs,
les performances en termes de qualitÃ© dâ€™estimation de notre approche sont proches de celles
calculÃ©es par CluStream qui permet de conserver la moyenne exacte des variables.
Vitesse dâ€™exÃ©cution. La Figure 7(a) montre les performances en termes de temps dâ€™exÃ©cution
(Ã©chelle logarithmique) accomplies pour les trois algorithmes. Il est clair que StreamSamp
fournit de meilleurs rÃ©sultats comparÃ© Ã  CluStream et Ã  lâ€™approche hybride. Notre approche
hybride est un peu plus lente que StreamSamp mais reste beaucoup plus rapide que CluStream.
Ordre de bascule. Comme le montre la Figure 7(b), sur les 500 000 enregistrements, lâ€™ordre
de bascule varie de 1 Ã  4. La majoritÃ© de ces enregistrements basculent vers CluStream Ã  lâ€™ordre
1. Ceci va impliquer un passage "forcÃ©" des Ã©chantillons dâ€™ordre supÃ©rieur (plus anciens).
En effet, afin de respecter la chronologie de CluStream, si un problÃ¨me de fusion est dÃ©tectÃ©
RÃ©sumÃ© hybride de flux de donnÃ©es
FIG. 6 â€“ Erreur relative moyenne sur la pÃ©riode [0-10000] observÃ©e en t = 500000.
entre deux Ã©chantillons dâ€™ordre i, alors il faut basculer les Ã©chantillons les plus anciens vers
CluStream.
FIG. 7 â€“ (a)Vitesse dâ€™exÃ©cution, (b)Taux des Ã©chantillons basculÃ©s, pour chaque ordre, vers
CluStream.
5 Conclusion et perspectives
Lâ€™objectif de cet article est de proposer une nouvelle approche pour la conception dâ€™un
rÃ©sumÃ© de flux de donnÃ©es. Il sâ€™agit de dÃ©velopper un rÃ©sumÃ© Ã  la fois gÃ©nÃ©raliste et de bonne
qualitÃ© pour toute la pÃ©riode temporelle.
Nous avons prÃ©sentÃ© une stratÃ©gie de passage de lâ€™algorithme StreamSamp vers lâ€™algo-
rithme CluStream en nous basant sur les avantages de chacune de ces mÃ©thodes. Lâ€™instant
de passage nâ€™est pas alÃ©atoire, il est basÃ© sur les propriÃ©tÃ©s intrinsÃ¨ques des deux techniques.
Si lâ€™un de ces critÃ¨res nâ€™est plus vÃ©rifiÃ©, le processus de fusion des Ã©chantillons de Stream-
Samp est arrÃªtÃ© et les Ã©chantillons sont envoyÃ©s vers CluStream. Cependant, avant dâ€™envoyer
ces Ã©chantillons, il faut tout dâ€™abord faire basculer tous les Ã©chantillons des ordres supÃ©rieurs
pour respecter la chronologie de CluStream. Lâ€™inconvÃ©nient avec cette approche est que nous
condamnons des Ã©chantillons Ã  passer tÃ´t vers ce processus alors quâ€™ils vÃ©rifient encore les
critÃ¨res de passage. Des travaux sont en cours afin de dÃ©velopper des techniques permettant
dâ€™Ã©viter cet inconvÃ©nient.
N. GABSI et al.
Une extension naturelle de ce travail concerne lâ€™intÃ©gration des donnÃ©es qualitatives. Avec
StreamSamp, le problÃ¨me dâ€™utilisation de variables catÃ©gorielles ne se pose pas. Concernant
CluStream, il existe des extensions qui traitent les variables catÃ©gorielles (HClustream (Yang
et Zhou, 2006), SCLOPE (Kok leong Ong et al., 2004)). IntÃ©grer les donnÃ©es qualitatives dans
notre approche est possible Ã  condition de redÃ©finir les paramÃ¨tres de tests pour la transition.
RÃ©fÃ©rences
Abadi, D. J., D. Carney, U. Ã‡etintemel, M. Cherniack, C. Convey, S. Lee, M. Stonebraker,
N. Tatbul, et S. Zdonik (2003). Aurora : a new model and architecture for data stream
management. The VLDB Journal 12(2), 120â€“139.
Aggarwal, C. C., J. Han, J. Wang, et P. S. Yu (2003). A framework for clustering evolving data
streams. In VLDB â€™2003 : Proceedings of the 29th international conference on Very large
data bases, pp. 81â€“92. VLDB Endowment.
Arasu, A., B. Babcock, S. Babu, J. Cieslewicz, K. Ito, R. Motwani, U. Srivastava, et J. Wi-
dom (2004). Stream : The stanford data stream management system. In In Data-Stream
Management : Processing High-Speed Data Streams. Springer-Verlag.
Babcock, B., S. Babu, M. Datar, R. Motwani, et J. Widom (2002). Models and issues in data
stream systems. In PODS â€™02 : Proceedings of the twenty-first ACM SIGMOD-SIGACT-
SIGART symposium on Principles of database systems, New York, NY, USA, pp. 1â€“16.
ACM.
Bloom, B. H. (1970). Space/time trade-offs in hash coding with allowable errors. Commun.
ACM 13(7), 422â€“426.
Cormode, G. et M. Garofalakis (2007). Sketching probabilistic data streams. In SIGMOD â€™07 :
Proceedings of the 2007 ACM SIGMOD international conference on Management of data,
New York, NY, USA, pp. 281â€“292. ACM.
Csernel, B. (2008). RÃ©sumÃ© GÃ©nÃ©raliste de flux de donnÃ©es. Ph. D. thesis, Ecole Nationale
SupÃ©rieure des TÃ©lÃ©communications.
Csernel, B., F. ClÃ©rot, et G. HÃ©brail (2006). Datastream clustering over tilted windows through
sampling. Knowledge Discovery from Data Streams Workshop (ECML/PKDD).
Flajolet, P. et G. N. Martin (1985). Probabilistic counting algorithms for data base applications.
J. Comput. Syst. Sci. 31(2), 182â€“209.
Gemulla, R. et W. Lehner (2008). Sampling time-based sliding windows in bounded space.
In SIGMOD â€™08 : Proceedings of the 2008 ACM SIGMOD international conference on
Management of data, New York, NY, USA, pp. 379â€“392. ACM.
Golab, L. et M. T. Ã–zsu (2003). Issues in data stream management. SIGMOD Rec. 32(2),
5â€“14.
Guha, S. et B. Harb (2005). Wavelet synopsis for data streams : minimizing non-euclidean
error. In KDD â€™05 : Proceedings of the eleventh ACM SIGKDD international conference on
Knowledge discovery in data mining, New York, NY, USA, pp. 88â€“97. ACM.
Guha, S., N. Koudas, et K. Shim (2001). Data-streams and histograms. In STOC â€™01 : Procee-
dings of the thirty-third annual ACM symposium on Theory of computing, New York, NY,
RÃ©sumÃ© hybride de flux de donnÃ©es
USA, pp. 471â€“475. ACM.
Kok leong Ong, W. L., W. keong Ng, et E. peng Lim (2004). Sclope : An algorithm for
clustering data streams of categorical attributes. Technical report.
Ma, L., W. Nutt, et H. Taylor (2007). Condensative stream query language for data streams. In
ADC â€™07 : Proceedings of the eighteenth conference on Australasian database, Darlinghurst,
Australia, Australia, pp. 113â€“122. Australian Computer Society, Inc.
Towne, K., Q. Zhu, C. Zuzarte, et W.-C. Hou (2007). Window query processing for joining
data streams with relations. In CASCON â€™07 : Proceedings of the 2007 conference of the
center for advanced studies on Collaborative research, New York, NY, USA, pp. 188â€“202.
ACM.
Vitter, J. S. (1985). Random sampling with a reservoir. ACM Trans. Math. Softw. 11(1), 37â€“57.
Yang, C. et J. Zhou (2006). Hclustream : A novel approach for clustering evolving heteroge-
neous data stream. In ICDMW â€™06 : Proceedings of the Sixth IEEE International Conference
on Data Mining - Workshops, Washington, DC, USA, pp. 682â€“688. IEEE Computer Society.
Zhang, T., R. Ramakrishnan, et M. Livny (1996). Birch : An efficient data clustering method
for very large databases. In H. V. Jagadish et I. S. Mumick (Eds.), Proceedings of the
1996 ACM SIGMOD International Conference on Management of Data, Montreal, Quebec,
Canada, June 4-6, 1996, pp. 103â€“114. ACM Press.
Summary
Given the large volume of data generated by computer systems, storing all data before
querying them is not possible. One solution is to keep a summary of the history of data streams.
This history can be used to answer queries and perform data mining. Many data summariz-
ing techniques have been already developed such as sampling, clustering, etc. According to
the scope of applications, these summaries are classified into two categories: specialized sum-
maries and generalist summaries. This paper focuses on generalist summaries. The objective is
to create a good quality summary which covers a long time period and allows to process a wide
range of queries. The reported work focuses on two algorithms: CluStream and StreamSamp.
In order to take advantages of the benefits of each algorithm, we suggest their integration into
one process. To test this approach, we use the "KDD_99" real Benchmark data. The results
are separately compared to those obtained by StreamSamp and Clustream.
