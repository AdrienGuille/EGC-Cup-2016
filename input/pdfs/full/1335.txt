PREMIERS PAS en REGRESSION LINEAIRE avec SAS® 
  
Josiane Confais (UPMC-ISUP) - Monique Le Guen (CNRS-CES-MATISSE-
UMR8174)  
 
e-mail : confais@ccr.jussieu.fr 
e-mail : monique.leguen@univ-paris1.fr 
 
 
 
 
 
Résumé 
 
Ce tutoriel accessible par internet montre de façon intuitive et sans formalisme excessif, les 
principales notions théoriques nécessaires à la compréhension et à l'interprétation des résultats 
d’analyses de régression linéaire, simple et multiple, produits par la procédure REG de SAS® 
et par le menu FIT de SAS/INSIGHT1 . 
 
Ce document est issu d’un cours enseigné par les auteurs dans différentes formations : ISUP, 
DEA & DESS de Paris 1, formation permanente du CNRS, au CEPE de  l’INSEE. Il fait suite 
à un premier document de travail publié à l’Unité Méthodes Statistiques de l’INSEE. 
 
Nous avons ajouté de nombreux graphiques et affichages de SAS/INSIGHT, qui par ses 
possibilités de visualisation et d’interactivité, facilitent la compréhension à la fois des données 
et des techniques. Nous avons profité des possibilités d’internet pour ajouter des liens vers des 
applets ou d’autres documents accessibles sur le web.  
Nous insistons dans ce tutoriel, sur l’importance des graphiques exploratoires, et sur les 
limites des résultats obtenus par une régression linéaire, si l’étape de vérification des 
suppositions n’est pas systématiquement entreprise. 
 
                                            
1 SAS® et SAS/INSIGHT sont les marques déposées de SAS Institute Inc., Cary, NC, USA 
 
© Revue MODULAD, 2006 - 220-               Numéro 35 
 
 
  
1. SENSIBILISATION A LA REGRESSION LINEAIRE SIMPLE ........................................................................... 224 
1.1. Où se place la régression linéaire ?............................................................................................ 224 
1.2. Ajustement affine ou Régression Simple...................................................................................... 225 
1.2.1. Comment trouver la droite qui passe « au plus près » de tous les points?............................................... 227 
1.2.2. Méthode d’estimation des paramètres β0 et β1 ...................................................................................... 228 
1.2.3. Effet d’un point observation sur la droite de régression ......................................................................... 230 
1.2.4. Décomposition de l'écart entre Yi et la moyenne de Y ........................................................................... 230 
1.2.5. Analyse de la variance ............................................................................................................................ 231 
Ce que le modèle explique et ce qu'il n'explique pas......................................................................................... 231 
Standard de présentation de l'Analyse de la Variance ....................................................................................... 232 
Comment apprécier globalement la régression.................................................................................................. 234 
Exemple : Régression de la Taille en fonction du Poids ................................................................................... 235 
1.2.6. Représentations géométriques ................................................................................................................ 238 
Régression simple de Y sur X ........................................................................................................................... 238 
Distribution en un point fixé de X..................................................................................................................... 240 
Représentation de X fixé et Y aléatoire............................................................................................................. 241 
1.3. Glissement fonctionnel de la méthode des Moindres Carrés Ordinaires à la Régression. ......... 242 
1.3.1. De l'Astronomie... ................................................................................................................................... 243 
1.3.2. … Aux Sciences Sociales ....................................................................................................................... 243 
1.3.3. Galton Diagram Regression.................................................................................................................... 243 
1.3.4. Formalisation des Suppositions .............................................................................................................. 245 
1.4. Confiance à accorder aux résultats............................................................................................. 246 
1.4.1. Test de la signification globale de la régression ..................................................................................... 246 
1.4.2. Statistiques liées au paramètre β1 ........................................................................................................... 247 
Calcul de la variance de b1................................................................................................................................ 248 
Test portant sur le paramètre β1........................................................................................................................ 249 
Calcul de l'intervalle de confiance de β1........................................................................................................... 250 
1.4.3. Statistiques liées au paramètre β0 ........................................................................................................... 250 
Calcul de la variance de b0................................................................................................................................ 250 
Test portant sur le paramètre β0........................................................................................................................ 251 
Calcul de l'intervalle de confiance de  β0.......................................................................................................... 252 
Exemple d’estimation des paramètres avec Proc REG...................................................................................... 253 
1.4.4. Précision sur l'estimation de Y................................................................................................................ 254 
Intervalle de confiance autour de l'estimation de la droite de régression........................................................... 255 
Intervalle de prévision de Y sachant X.............................................................................................................. 257 
Exemple avec les options CLI CLM  de la Proc REG....................................................................................... 258 
2. LA REGRESSION LINEAIRE MULTIPLE ..................................................................................................... 260 
2.1. Le critère des moindres carrés.................................................................................................... 260 
2.2. Formalisation de la régression linéaire multiple ........................................................................ 261 
2.3. Exemples de régression linéaire multiple avec Proc REG.......................................................... 263 
2.3.1. Présentation des données ........................................................................................................................ 263 
2.3.2. Régression linéaire multiple avec Proc REG sans options...................................................................... 264 
2.4. TYPE I SS et TYPE II SS de Proc REG ....................................................................................... 267 
2.4.1. Définition de TYPE I SS et TYPE II SS................................................................................................. 267 
2.4.2. Interprétations conjointes de TYPE I SS et TYPE II SS......................................................................... 270 
2.4.3. Options SS1 et SS2 de l’instruction model de Proc REG ....................................................................... 270 
2.4.4. Tester la nullité de r paramètres pour tester un sous modèle .................................................................. 272 
2.4.5. Exemple de test partiel avec PROC REG ............................................................................................... 273 
2.5. Ce qu'il faut retenir des 'SS' ........................................................................................................ 275 
2.6. Les résidus................................................................................................................................... 276 
Conclusion ........................................................................................................................................................ 277 
3. QUAND LES RESULTATS D'UNE REGRESSION NE SONT PAS FORCEMENT PERTINENTS.............................. 278 
3.1. Exemples en régression simple.................................................................................................... 278 
3.1.1. Une même valeur pour des situations différentes ................................................................................... 278 
3.1.2. Pondérations et régression linéaire par morceaux................................................................................... 280 
Théorie de la régression pondérée..................................................................................................................... 283 
3.1.3. Transformation des données ................................................................................................................... 283 
3.1.4. Méthode non paramètrique du LOWESS ............................................................................................... 287 
3.2. Exemples en régression multiple................................................................................................. 289 
3.2.1. Y « expliquée » par la corrélation entre deux régresseurs....................................................................... 289 
3.2.2. Instabilité des coefficients de la régression, en cas de multicolinéarité .................................................. 291 
Exemple sur données réelles ............................................................................................................................. 291 
© Revue MODULAD, 2006 - 221-               Numéro 35 
 
 
Exemple sur données avec modèle théorique connu et régresseurs corrélés ..................................................... 293 
3.3. Conditions d'utilisation de la régression, les diagnostics ........................................................... 295 
3.3.1. Modèle Inadapté ..................................................................................................................................... 296 
3.3.2. L’influence de certaines données, les données atypiques -Outliers- ....................................................... 296 
3.3.3. Corrélation et colinéarité entre les régresseurs ....................................................................................... 297 
4. VALIDATION D’UNE REGRESSION .......................................................................................................... 298 
4.1. Introduction................................................................................................................................. 298 
4.1.1. Modèle et notations................................................................................................................................. 298 
4.1.2. Problèmes à étudier................................................................................................................................. 299 
4.2. Vérification des suppositions de base sur les erreurs ................................................................. 299 
4.2.1. Espérance nulle....................................................................................................................................... 299 
4.2.2. Indépendance.......................................................................................................................................... 299 
Cas particulier où les observations sont apparentées (cas des chroniques) :...................................................... 300 
4.2.3. Egalité des variances (homoscédasticité)................................................................................................ 301 
4.2.4. Normalité des erreurs.............................................................................................................................. 303 
4.2.5. Exemple.................................................................................................................................................. 303 
Modèle .............................................................................................................................................................. 303 
Dessin des résidus contre les 4 régresseurs (avec SAS/INSIGHT) ................................................................... 304 
Test d’homoscédasticité et tracé du QQ-PLOT avec PROC REG. ................................................................... 306 
4.3. Influence d'observations.............................................................................................................. 307 
4.3.1. Hat matrice et leverages.......................................................................................................................... 307 
4.3.2. Résidus studentisés internes.................................................................................................................... 309 
4.3.3. Résidus studentisés externes................................................................................................................... 309 
4.3.4. Mesure globale de l'influence  sur le vecteur des coefficients: Distance de COOK................................ 309 
4.3.5. Influence sur chacun des coefficients : DFBETAS................................................................................. 310 
4.3.6. Précision des estimateurs : COVRATIO ................................................................................................ 310 
4.3.7. Influence sur la valeur ajustée: DFFITS ................................................................................................. 310 
4.3.8. Coefficient global PRESS....................................................................................................................... 311 
4.3.9. Comment obtenir les mesures d’influence dans SAS ............................................................................. 311 
Dans PROC REG .............................................................................................................................................. 311 
Dans SAS/INSIGHT ......................................................................................................................................... 312 
4.3.10. Tableau récapitulatif.......................................................................................................................... 312 
4.3.11. Exemple............................................................................................................................................. 314 
4.4. Colinéarité des régresseurs......................................................................................................... 318 
4.4.1. Méthodes basées sur l'étude de la matrice X'X ....................................................................................... 319 
Etude de la matrice de corrélation des régresseurs ............................................................................................ 320 
4.4.2. Variance Inflation Factor ........................................................................................................................ 320 
4.4.3. Condition index et variance proportion .................................................................................................. 321 
Les indices de colinéarité .................................................................................................................................. 322 
4.4.4. Remèdes en cas de multi-colinéarité....................................................................................................... 323 
4.4.5. Exemple.................................................................................................................................................. 324 
Regression RIDGE............................................................................................................................................ 325 
4.5. Choix des régresseurs ................................................................................................................. 326 
4.5.1. Utilisation des sommes de carrés............................................................................................................ 326 
Rappel sur les somme de carrés apportés par un régresseur .............................................................................. 327 
Tests des apports à SSModèle d’une variable ....................................................................................................... 327 
Exemple d’élimination progressive ................................................................................................................... 328 
4.5.2. Différentes méthodes basées sur les sommes de carrés .......................................................................... 330 
Méthode FORWARD (ascendante)................................................................................................................... 330 
Méthode BACKWARD (descendante) ............................................................................................................. 331 
Méthode STEPWISE (progressive)................................................................................................................... 331 
Exemples de sélection STEPWISE ................................................................................................................... 332 
4.5.3. Amélioration de R² ................................................................................................................................. 334 
Maximum R 2 Improvement (MAXR)............................................................................................................... 334 
Minimum R 2 Improvement (MINR)................................................................................................................. 335 
4.5.4. Autres méthodes basées sur R² : RSQUARE et ADJRSQ ...................................................................... 335 
4.5.5. Coefficient CP de Mallows..................................................................................................................... 335 
Sélection suivant le coefficient CP.................................................................................................................... 336 
Utilisation du coefficient CP dans une sélection de régresseurs........................................................................ 336 
4.5.6. Critères AIC et BIC ................................................................................................................................ 336 
4.5.7. Exemple de sélection RSQUARE........................................................................................................... 337 
CONCLUSION.................................................................................................................................................. 339 
ANNEXES ..................................................................................................................................................... 341 
ANNEXE 1......................................................................................................................................................... 342 
© Revue MODULAD, 2006 - 222-               Numéro 35 
 
 
SYNTAXE SIMPLIFIEE DE LA PROCEDURE REG DE SAS.................................................................. 342 
PROC REG options ;................................................................................................................................. 342 
MODEL dépendante = régresseurs / options ;.......................................................................................... 343 
Instructions BY FREQ ID WEIGHT :........................................................................................................ 344 
REWEIGHT expression / WEIGHT = valeur  ; ......................................................................................... 344 
TEST equation(s) ;..................................................................................................................................... 344 
RESTRICT equation(s);............................................................................................................................. 344 
Options RIDGE et PCOMIT des instructions  PROC REG ou MODEL ................................................... 346 
ANNEXE 2......................................................................................................................................................... 347 
MODE D’EMPLOI TRES SUCCINCT DE SAS/INSIGHT......................................................................... 347 
Le lancement de SAS/INSIGHT ................................................................................................................. 347 
Rôle statistique des variables dans SAS/INSIGHT .................................................................................... 348 
Menu principal de SAS/INSIGHT.............................................................................................................. 349 
Graphiques standard en SAS/INSIGHT..................................................................................................... 349 
Les Analyses Statistiques avec SAS/INSIGHT........................................................................................... 351 
Impression et Sauvegarde.......................................................................................................................... 352 
Pour plus d’information sur les graphiques .............................................................................................. 354 
ANNEXE 3......................................................................................................................................................... 355 
STATISTIQUES RELATIVES A L’ANALYSE DE LA VARIANCE ........................................................ 355 
STATISTIQUES SUR LES PARAMETRES .............................................................................................................. 356 
ANNEXE 4......................................................................................................................................................... 357 
RELATIONS ENTRE LA LOI NORMALE ET LES STATISTIQUES DE LOIS .................................... 357 
ANNEXE 5......................................................................................................................................................... 358 
CONSTRUCTION D’UN QQ-PLOT.............................................................................................................. 358 
PRINCIPE DE LA DROITE DE HENRY ................................................................................................................. 358 
GENERALISATION............................................................................................................................................ 359 
QQ-PLOT AVEC SAS....................................................................................................................................... 359 
  
 
© Revue MODULAD, 2006 - 223-               Numéro 35 
 
 
1. Sensibilisation à la régression linéaire simple 
Cette sensibilisation à la régression présente de manière détaillée la logique et les calculs 
permettant la compréhension de la régression simple. 
On montre tout d'abord la démarche algébrique qui conduit à un ajustement affine, puis par un 
détour obligé à l'Histoire, on « glisse » vers la modélisation en s'appuyant sur la Statistique. 
1.1. Où se place la régression linéaire ? 
La régression linéaire se classe parmi les méthodes d’analyses multivariées qui traitent des 
données quantitatives. 
 
C'est une méthode d'investigation sur données d'observations, ou d’expérimentations, où 
l'objectif principal est de rechercher une liaison linéaire entre une variable Y quantitative et 
une ou plusieurs variables X également quantitatives. 
 
C’est la méthode la plus utilisée pour deux raisons majeures : 
 
• c’est une méthode ancienne, 
• c’est l'outil de base de la plupart des modélisations plus sophistiquées comme la 
régression logistique, le modèle linéaire généralisé, les méthodes de traitement des séries 
temporelles, et surtout des modèles économétriques, etc.  
 
A l'aide du tableau 1.1, on peut repérer les méthodes les plus courantes d'analyses statistiques 
et les procédures SAS utiles pour rechercher des liaisons, selon le type (nominal, ordinal, 
intervalle, ratio) des variables Y et X. Le lecteur peu familiarisé avec la terminologie des 
variables SAS pourra voir sur le site de MODULAD, le tutoriel2 « La Proc FREQ de SAS, 
Tests d’indépendance et d’association  », de J. CONFAIS, Y. GRELET, M. LE GUEN. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                                            
2 http://www-rocq.inria.fr/axis/modulad/archives/numero-33/tutorial-confais-33/confais-33-tutorial.pdf , page 5-7. 
© Revue MODULAD, 2006 - 224-               Numéro 35 
 
 
Tableau 1.1  Procédures SAS adaptées selon le type des variables 
(nominal, ordinal, intervalle, ratio) 
 
 X intervalle/ratio X ordinale/nominale 
 
 
Y intervalle/ratio  
Régression linéaire 
 
PROC REG 
 
 
Analyse de la 
variance 
 
PROC ANOVA 
Modèles linéaires 
généralisés 
 
Õ  PROC GLM 
 
Y ordinale/nominale Si Y est ordinale ou 
égression 
ISTIC 
Analyses de 
ence 
égression 
ISTIC 
raitements des 
es  
  PROC CATMOD
à 2 modalités 
 
 
R
logistique 
PROC LOG
 
tableaux 
de conting
PROC FREQ 
 
R
logistique 
PROC LOG
T
variables 
catégoriell
 
Õ
 
our la régression linéaire la procédure REG est la plus complète. Cependant le module 
ans les exemples nous utiliserons l’une ou l’autre de ces possibilités. En annexe 2, on 
1.2. Ajustement affine ou Régression Simple 
Exemple   
 mesures de poids (variable X) et taille (variable Y) relevées sur un échantillon de 
P
SAS/INSIGHT, qui est à la fois un tableur, un grapheur et un analyseur, est particulièrement 
adapté pour étudier des données dans une problématique de régression linéaire couplée à une 
analyse exploratoire des données. 
 
D
trouvera un mode d’emploi très succinct de SAS/INSIGHT. 
Soient les 2
20 objets. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
© Revue MODULAD, 2006 - 225-               Numéro 35 
 
 
 
Tableau 1.2  Données Taille et Poids 
 
identifiant poids (X) taille (Y) 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
20 
46 
78 
85 
85 
85 
85 
95 
95 
100 
100 
100 
103 
105 
105 
115 
115 
115 
130 
135 
150 
152 
158 
160 
162 
158 
159 
165 
165 
166 
159 
166 
168 
163 
164 
168 
166 
162 
165 
167 
172 
 
e graphique du nuage de points, d’abscisse le poids et d’ordonnée la taille montre L
qu’il existe une relation linéaire entre ces deux variables. Lorsque le poids 
augmente, la taille a tendance à croître également. 
 
 
Figure 1.1 Taille*Poids 
 
es points du nuage sont approximativement alignés sur une droite  (y=ax+b) à une 
 
 
L
erreur près. 
 
Taille = β0 + β1 oids + erreur  P
 
 
a variable Taille (Y) est appelée la variable “réponse”, ou selon les domaines 
0 est l’ordonnée à l’origine.  
L
disciplinaires, variable à expliquer, ou encore variable dépendante. La variable Poids 
(X) est la variable “régresseur”, encore appelée variable explicative, ou variable 
indépendante. 
 
β
© Revue MODULAD, 2006 - 226-               Numéro 35 
 
 
β1 est la pente de la droite d’ajustement. 
te : Dans ce document nous n’utiliserons que les termes « réponse » et 
able dite expliquée n’est pas forcément expliquée par les 
 elles 
1.2.1. Comment trouver la droite qui passe « au plus près » de tous les 
Pour trouver la droite qui passe « au plus près » de tous les points il faut se donner 
 
oN
« régresseurs », pour éviter toutes confusions sémantiques très dommageables lors 
des interprétations des résultats, et particulièrement lors de la communication des 
résultats à un tiers. 
 
ar exemple, la variP
variables dénommées explicatives. Quand aux variables dites indépendantes,
sont, dans le cas de données réelles, rarement indépendantes. 
points? 
un critère d’ajustement. 
 
M1
P1
P2
M2
M3
P3
M4
P4
Y
X
droite Y= Xβ0+β1
 
 
Figure 1.2  Projection des points M1...M4  sur la droite. 
 
n pro ur la droite on obtient les 
La somme des carrés des écarts (SCE) des points observés Mi  à la droite solution 
O jette les points M1 à M4 parallèlement à l'axe des Y. S
points P1 à P4, comme le montre la figure 1.2. Le critère retenu pour déterminer la 
droite D passant au plus près de tous les points sera  tel que : 
 
soit minimum. 
 
a droite solution sera appelée droite de régression de Y sur X. 
O, Ordinary Least 
L
 
e critère est le « critère des Moindres Carrés Ordinaires » (MCL
Squares en anglais), appelé aussi par les statisticiens « critère de Norme L²». 
Les écarts sont calculés en projetant les points M parallèlement à l’axe des Y. On 
pourrait aussi projeter les points M parallèlement à l’axe des X, on aurait alors une 
autre droite solution (régression de X sur Y). Dans ces deux régressions Y et X ne 
jouent pas le même rôle. 
© Revue MODULAD, 2006 - 227-               Numéro 35 
 
 
On pourrait aussi projeter les points M perpendiculairement à la droite solution. Y et 
X joueraient dans ce cas le même rôle. C’est la situation que l'on rencontre dans une 
Analyse en Composantes Principales3, illustrée dans la figure 1.3. 
 
     
 
Y
XY O 1ββ +=
Figure 1.3 Trois projections possibles du point (Xi, Yi)  
1.2.2. Méthode d’estimation des paramètres β0 et β1 
La Somme des Carrés des Ecarts (SCE) est donnée par : 
 
2n
1i
i10i
n
1i
2
i )XY(S ∑∑
==
β−β−=ε=  
 
La valeur de cette fonction S est minimum lorsque les dérivées de S par rapport à 
 s'annulent. La solution est obtenue en résolvant le système : 1Oet ββ
 
0S
0
=∂β
∂
  et   0
S
1
=∂β
∂
 
 
Les dérivées par rapport à β0 et β1  sont : 
 
)XY(2S i1O
n
1i
i
0
β−β−−=∂β
∂ ∑
=
 
 
)XY(X2S i1O
n
1i
ii
1
β−β−−=∂β
∂ ∑
=
 
 
Ces dérivées s’annulent pour deux valeurs b0 et b1 solutions des 2 équations à 2 
inconnues : 
 
                                            
3 On pourrait encore prendre comme critère la somme des valeurs absolues des écarts des points observés à la 
droite, ce serait alors un critère de norme L1, et pourquoi pas prendre un exposant non entier appartenant à 
l’intervalle [1,2], ce serait une norme Lp.
 
e1
Yi
e2
d
0β  
XXi
© Revue MODULAD, 2006 - 228-               Numéro 35 
 
 
équation 1 :   0)XbbY( i1O
n
1i
i =−−∑
=
 
 
équation 2 :   0)XbbY(X i1O
n
1i
ii =−−∑
=
 
 
Ce système de 2 équations à 2 inconnues déterminent les  équations normales. 
 
Développons ces 2 équations normales : 
 
• l'équation 1 donne :  0XbnbY i10i =−− ∑∑  et en divisant par n  XbbY 10 += . 
 
On remarque que la droite solution passe par le centre de gravité du nuage 
⎟⎟⎠
⎞
⎜⎜⎝
⎛ ∑∑
=
n
i i
Y
,
n
i i
X
)Y,X( . 
 
• L'équation 2 donne 
 0XbXbXY 2i1i0ii =−− ∑∑∑  
dans laquelle on remplace b0 
 
0XbX)XbY(XY 2i1i1ii =−−− ∑∑∑  
Solution : 
∑ ∑
∑∑∑
−
−=
n/)X(X
n/)YX(YX
b 2
i
2
i
iiii
1  
 
en divisant numérateur et dénominateur par n on retrouve les expressions de la 
covariance et de la variance empiriques : 
 
)X(Var
)Y,X(Cov
)XX(
)YY)(XX(
b 2
i
ii
1 =−
−−= ∑
∑     formule n° 1 
 
Les points qui sont sur la droite de régression ont pour ordonnée:  XbbYˆ 10 +=  
 
Le coefficient b1 dépend au numérateur de la covariance entre X et Y, et de la 
variance de X pour le dénominateur. 
 
Terminologie 
 
Yˆ  est l’estimation de Y obtenue à partir de l’équation de régression. 
Yˆ  se prononce Y chapeau. 
b0 et b1 sont les estimateurs des moindres carrés des paramètres inconnus β0 
et β1. On appelle estimations les valeurs particulières (solutions) prises par les 
estimateurs b0 et b1.   
© Revue MODULAD, 2006 - 229-               Numéro 35 
 
 
Dans la suite du document on ne fera pas de différence de notations entre les 
estimateurs b0 ou  b1 et leurs estimations. 
1.2.3. Effet d’un point observation sur la droite de régression 
Avec cet applet java http://www.stat.sc.edu/~west/javahtml/Regression.html 
on peut voir l’effet de levier (leverage) sur le calcul de la droite de régression en 
ajoutant un point -rouge- par un simple clic de souris. Ici le point rouge est un point 
influent dans la liaison (X,Y). Plus le point est éloigné de la tendance plus son levier 
sera grand. Il peut aussi exister des points atypiques -Outliers- seulement en 
direction des X, ou dans la direction des Y (voir le chapitre 4). 
 
 
 
1.2.4. Décomposition de l'écart entre Yi et la moyenne de Y 
En un point d'observation  on décompose l'écart entre et la moyenne des 
Y en ajoutant puis retranchant  la valeur estimée de Y par la droite de régression. 
Cette procédure fait  apparaître une somme de deux écarts : 
)Y,X( ii iY
iYˆ
 
)YYˆ()YˆY()YY(
)YYˆYˆY()YY(
iiii
iiii
−+−=−
−+−=−
 
 
Ainsi l'écart total )YY( i −  peut être vu comme la somme de deux écarts : 
• un écart entre iY  observé et iYˆ  la valeur estimée par le modèle 
un écart entre • Yˆi  la valeur estimée par le modèle et la moyenne Y . 
ion géométrique de cette décomposition. 
Cet artifice de décomposition aura un intérêt fondamental dans l'analyse de la 
 
Le graphique suivant montre l'explicat
variance abordée au paragraphe suivant. 
 
© Revue MODULAD, 2006 - 230-               Numéro 35 
 
 
                   
 
Figure 1.4  Décomposition des différents écarts 
 
Ecart total  )YY( i −  = écart dû au model )YˆY( ii −   + écart résiduel )YYˆ( i −  
1.2.5. Analyse de la variance 
Ce que le modèle explique et ce qu'il n'explique pas 
A partir de l’équation de la droite de régression (modèle retenu), on peut pour tout 
point i d'abscisse  calculer son estimation (ordonnée)   iX iYˆ
i10i XbbYˆ +=   avec  XbYb 10 −=  
 
ce qui donne : 
)X(XbYYˆ i1i −+=  
 
ou encore      )X(XbYYˆ i1i −=−
    
formule n° 2 
 
En un point i l’écart ou résidu est :  )YYˆ()YY(YˆY iiii −−−=−  
 
On élève les deux membres au carré et on somme sur les observations i : 
 
)YYˆ)(YY(2)YYˆ()YY()YˆY( i
i
i
2
i
i
2
i
i
2
i
ii −−−−+−=− ∑∑∑∑  
 
En utilisant la formule n°2 : 
 
)XX(b)YY(2)YYˆ()YY()YˆY( i1
i
i
2
i
i
2
i
i
2
i
ii −⋅−−−+−=− ∑∑∑∑
 
 
En utilisant une transformation de la formule n°1 : )YY)(XX()XX(b ii
2
i1 −−=− ∑∑  
on obtient 
 
.
Y
. .
. .
)YY( i −
Yi
Y 
 
)YˆY( ii −  
)YYˆ( i −  .
iYˆ  
XbbYˆ 10 +=  
X 
Xi
© Revue MODULAD, 2006 - 231-               Numéro 35 
 
 
2i
i
2
1
2
i
i
2
i
i
2
i
ii )XX(b2)YYˆ()YY()YˆY( ∑∑∑∑ −⋅−−+−=−  
 
En utilisant la formule n° 2 : 
 
2
i
i
2
i
i
2
i
i
2
i
ii )YYˆ(2)YYˆ()YY()YˆY( ∑∑∑∑ −−−+−=−  
 
On aboutit enfin à l’égalité fondamentale : 
 
2
i
ii
2
i
i
2
i
i )YˆY()YYˆ()YY( ∑∑∑ −+−=−  
 
La SCE (Somme des Carrés des Ecarts) totale est égale à la somme des carrés des 
écarts dus au modèle augmentée de la somme des carrés des écarts dus aux 
erreurs 
 
erreurSCE+modèleSCEtotaleSCE = . 
 
Cette formule montre que : 
 
Les variations de Y autour de sa moyenne, c’est-à-dire SCE Totale (SS Total pour 
Sum of Squares en anglais) peuvent être expliquées par : 
• le modèle grâce à SCE Modèle (SS Model en anglais) ; 
• et ce qui ne peut être expliqué par le modèle, est contenu dans SCE 
 
'erreur est aussi appelée le « résidu ». 
Standard de présentation de l'Analyse de la Variance 
s forme d'un tableau, 
ose 
odèle, Erreur) correspond un nombre de 
resseurs (la variable X0 , constante égale à 
 
ous présentons le tableau général de l’analyse de variance pour p régresseurs. 
Erreur (SS Error en anglais). 
L
On a l'habitude de représenter l'analyse de la variance sou
faisant apparaître les 3 sources de variation : le total en 3ième ligne qui se décomp
en la partie modèle et la partie erreur. 
A chaque source de variation (Total, M
degrés de liberté (ddl) respectivement égal à n-1, p,  n-p-1, 
n : nombre d'observations 
p : nombre de variables rég
1, correspondant au paramètre β0, n'est pas comprise).  
N
Pour la régression simple, p=1 (une seule variable régresseur). 
 
 
 
 
 
 
 
 
© Revue MODULAD, 2006 - 232-               Numéro 35 
 
 
Tableau 1. 3 Analyse de variance (version anglaise) 
Source DF S
 
um of Squares Mean Square 
MODEL p 2i
n
1i
)YYˆ( −∑
=
 p/)YYˆ( 2i
n
1i
−∑
=
 
ERROR n-p-1 
n
2
ii
1i
)YˆY( −∑
=
 )1pn/()YˆY( 2ii
1i
−−−∑
=
n
 
TOTAL n-1 2i
1i
)YY( −∑
=
 
n
 
 
bréviations:A  
F :  Degrees of Freedom se traduit par degrés de liberté (ddl).  
S :   des Carrés des Ecarts (SCE) 
r 
 
D
 Ils vérifient : DF total=DFmodel +DF erreur
S Sum of Squares se traduit par Somme
MS :  Mean Square, est le rapport SS/DF, relatif soit au modèle soit à l'erreu
MSE : Mean Square Error = )1pn/()YˆY( 2
n
−−−∑ ii
1i=
représente le carré de l'écart 
 
 
moyen résiduel.  
ous ces « indicateurs » SS, MS, MSE, vont jouer un rôle important dans 
 
Figure 1.5  Décomposition des SS –Sums of Squares 
La figure 1.5 montre les liens entre SS total, SS model et SS error lorsque l’on 
T
l’appréciation du modèle calculé à partir des observations. 
 
 
 
somme les carrés des écarts sur tous les points i. 
 
 
 
 
 
.Y 
Y 
. .
. .
SS Total 
SS model .
X 
SS error
Yi
XbbY 10ˆ +=
© Revue MODULAD, 2006 - 233-               Numéro 35 
 
 
Il est remarquable que la formule de décomposition de l'écart total en un point i, vu 
au § 1.2.4.  
 
)YˆY()YYˆ()YY( iiii −+−=−  
 
prennela même forme pour la somme des carrés. 
 
2
i
ii
2
i
i
2
i
i )YˆY()YYˆ()YY( ∑∑∑ −+−=−  
Comment apprécier globalement la régression 
Les deux quantités SCE totale (SS total) et SCE modèle (SS model) sont des 
sommes de carrés donc toujours positives ou nulles et telles que 
. TotaleSCEModèleSCE ≤
 
Le rapport   
TotaleSCE
ModèleSCE
 est donc compris entre 0 et 1. 
 
On appelle ce rapport le coefficient de détermination  
TotalSS
elmodSS
TotaleSCE
ModèleSCER2 ==  
 
Cas particulier : 
Si tous les points Yi observés sont alignés sur la droite de régression, le modèle est 
parfaitement adapté et SCE Erreur = 0, 
 
Dans ce cas: 1TotaleESC
ModèleSCE =  
 
Interprétation de R2 
 
R2 qui varie entre 0 et 1, mesure la proportion de variation totale de Y autour de la 
moyenne expliquée par la régression, c’est-à-dire prise en compte par le modèle. 
Plus R2 se rapproche de la valeur 1, meilleure est l'adéquation du modèle aux 
données.  
 
Un R2 faible signifie que le modèle a un faible pouvoir explicatif. 
On démontre que R2 représente aussi le carré du coefficient de corrélation 
linéaire entre Y et Y estimé:  
 
)Yˆ,Y(CorrR 22 =  
 
Dans le cas de la régression simple, R est aussi la valeur absolue du coefficient de 
corrélation linéaire entre Y et X. 
)X,Y(CorrR =  
© Revue MODULAD, 2006 - 234-               Numéro 35 
 
 
Lien entre coefficient de corrélation de 2 variables et le cosinus de leur angle 
 
Soient 2 vecteurs X1 et X2 définis dans un espace Rn (espace des n observations), le 
coefficient de corrélation entre X1 et X2 est aussi le cosinus de l’angle θ  entre ces 2 
vecteurs. 
 
En utilisant les conventions de notation, le produit scalaire de 2 vecteurs X1 et X2 se 
note )(CosX*XX,X 2121 θ=><  
On a :  
)X,X(nCorrélatio
s*s
)XX)(XX(
*
n
1
)X,XX,X(
X,X)X,X(Cos 21
n,1i 21
i,1i,1
2/1
2211
21
21 =−−=>><<
><= ∑
=
 
 
21 s*s  étant le produit des écarts-type des 2 vecteurs.  
 
L’interprétation d’un coefficient de corrélation comme un cosinus est une propriété 
importante.  
 
Comme le remarque TOMASSONE (1992), les variables X n’étant pas des variables 
aléatoires, il est plus correct de parler de « cosinus » des angles formés par les 
vecteurs associés, en réservant le terme « coefficient de régression » pour sa 
similitude avec l’estimation de ce coefficient à partir d’un échantillon. 
 
Exemple : Régression de la Taille en fonction du Poids  
Sur les données du tableau 1.2, la première étape consiste à « regarder » les 
données pour vérifier qu’une liaison linéaire est envisageable (Proc GPLOT). Puis en 
deuxième étape on calcule le coefficient de corrélation (Proc CORR). Cette 
deuxième étape non indispensable en régression simple deviendra essentielle en 
régression multiple. Enfin on effectue une régression linéaire (Proc REG). 
 
Programme SAS 
 
 
Proc gplot data=libreg.tailpoid; 
 plot Y*X; 
 title ' Graphique taille en fonction du 
Poids ';  
Proc corr data=libreg.tailpoid; 
title 'Corrélation '; 
var Y X;  
Proc REG data=libreg.tailpoid; 
title 'Régression de la Taille en fonction du 
Poids '; 
model y=x;  
run; 
 
 
© Revue MODULAD, 2006 - 235-               Numéro 35 
 
 
 
 
 
 
Le coefficient de corrélation CORR entre Y et X vaut 0.83771. 
 
Sortie standard de la Proc REG sans options 
 
 
 
Dans la sortie de Proc REG on obtient d’abord le tableau d’analyse de la variance, 
puis les estimations des paramètres.  
 
 
 
 
© Revue MODULAD, 2006 - 236-               Numéro 35 
 
 
Lecture de l’Analyse de la Variance  
SS Model = 2i
n
1i
)YYˆ( −∑
=  
= 280.52918 
SS Error =  = 119.22082 2ii
n
1i
)YˆY( −∑
=
SS Total = = 399.75 
Mean Square Model = p/)YYˆ( 2i
n
1i
−∑
=
  = 280.52918  
Mean Square Error =  )1pn/()YˆY( 2ii
n
1i
−−−∑
=   
= 6.62338  
Root MSE = = 2.57359 ERRORMS
25.163Y =  Dependant Mean = 
 
R-Square = 
TotalSS
ModelSS
= 0.7018 = CORR(X,Y)2 = (0.83771)2. 
 
Autres indicateurs 
• CV =1.57647     C’est le Coefficient de Variation = 100
MeanDep
MSERoot ∗  
Le CV est un indicateur sans dimension -exprimé en %- permettant de comparer 
l'écart moyen résiduel à la moyenne de la variable dépendante Y. Ce pourcentage 
est plutôt utilisé pour comparer 2 modèles (donc 2 CV) portant sur le même jeu de 
données. 
 
• Le coefficient R2 ajusté , Adj R-sq 
Le R2 ajusté  (utilisé en régression multiple) tient compte du nombre de paramètres 
du modèle. 
 
pn
)²R1)(interceptn(1ajustéR 2 −
−−−=
 
 
Avec Intercept=0, si il n'y a pas de constante b0 à l'origine
4 sinon Intercept =1. 
 
Le reproche fait au coefficient de détermination est qu'il peut approcher la valeur 1, 
interprété comme un ajustement parfait, si on ajoute suffisamment de variables 
régresseurs. 
Le R2 ajusté tient compte du rapport p/n entre le nombre de paramètres du modèle 
et le nombre d'observations. 
Selon certains auteurs ce coefficient permet de comparer des modèles de régression 
sur différents ensembles de données, mais il ne fait pas l'unanimité. 
 
Attention : Adj R-sq peut prendre des valeurs inférieures à zéro ! 
 
                                            
4 S'il n'y a pas de constante b0 à l'origine, les statistiques relatives à l'analyse de la variance n'ont pas la même 
interprétation. 
© Revue MODULAD, 2006 - 237-               Numéro 35 
 
 
Lecture du tableau des paramètres  
Intercept =  145.98  donne la valeur de la constante à l’origine. On peut 
remarquer que dans cet exemple, cette valeur n’a pas de signification dans le monde 
physique. On ne peut concevoir qu’à un poids de valeur nulle corresponde une taille 
de 145.98. 
=0b
 
La pente de la droite (coefficient de X)  = =1b  0.1703. 
 
On l’interprète comme augmentation de la taille lorsque le poids augmente de une 
unité. 
 
Equation de la droite : Poids*0.170398.145Taille +=  
 
Là encore il faut se préserver de toute interprétation causale. Peut-on agir et 
augmenter le poids en espérant faire augmenter la taille ? 
 
Nous verrons les autres indicateurs dans la suite du chapitre. 
 
Pour mieux comprendre la technique de la régression, voyons certaines 
représentations géométriques. 
1.2.6. Représentations géométriques  
Régression simple de Y sur X 
 
Afin d'avoir une idée géométrique de la régression prenons un exemple avec  n=3 
observations (y1,x1), (y2,x2) et (y3,x3). 
 
Le vecteur réponse Y = (y1,y2,y3), et le vecteur régresseur X = (x1,x2,x3) peuvent 
se représenter dans l'espace à 3 dimensions des observations. On nomme 1,2,3 les 
axes de ce repère. 
Dans l’espace des observations représenté figure 1.6 5, la droite ∆  des constantes a 
pour vecteur directeur (1,1,1). 
 
                                            
5  La figure 1.6 est une synthèse des graphiques de DRAPER & SMITH (1966)  pp112-113 et SAPORTA  (2006)  p208  
© Revue MODULAD, 2006 - 238-               Numéro 35 
 
 
  
 
Figure 1.6  Régression de Y sur (X, ∆) dans l'espace des 3 observations. 
 
L'interprétation géométrique de la régression est la suivante :  
 
Régresser Y sur (∆ et X) consiste à projeter orthogonalement Y sur le plan (∆,X) 
ce qui donne le point P. 
Si d'autre part on projette Y sur la droite ∆, on obtient le point Q.  
Par le théorème des 3 droites perpendiculaires Q est aussi la projection orthogonale 
de P sur ∆. 
 
Dans le triangle YQP, rectangle en P, on peut appliquer le théorème de Pythagore :  
 
 
222 PQYPYQ +=  
 
2
i
i
2
i
ii
2
i
i )YYˆ()YˆY()YY( ∑∑∑ −+−=−  
 
La longueur  représente la somme des carrés corrigée SCE Totale (SS Total).  2YQ
La longueur  représente la somme des carrés  non expliquée par le régression 
SCE Erreur (SS error) .  
2YP
La longueur  représente la somme des carrés expliquée par la régression soit 
SCE Modèle (SS model).  
2PQ
 
C'est l'équation fondamentale de l'analyse de la variance vue précédemment : 
 
 Error SS  Model SS   Total SS +=
  
 
1 
Q est la 
projection 
orthogonal
e de Y sur 
∆ de 
coordonné
es  
)Y,Y,Y(  
P est la 
projection 
orthogonal
e de Y sur 
le plan 
(X,∆) et 
représente 
Yˆ,Yˆ,Yˆ(Yˆ 21=
3 
2 
0
∆ 
X 
Y
)ˆ,( YYCorr  
Résidu
P 
Q 
© Revue MODULAD, 2006 - 239-               Numéro 35 
 
 
Le coefficient de détermination R2 est le rapport  2
2
YQ
PQ  .  
R2 représente donc le carré du cosinus de l'angle (YQ, QP), c'est à dire l'angle entre 
Y et . Yˆ
 
Plus l'angle entre Y et  est faible, meilleur est le pouvoir explicatif du modèle. Yˆ
 
Et maintenant il suffit de généraliser mentalement à l'ordre n cette représentation à 3 
dimensions. 
 
Remarque en régression multiple 
Si au lieu d'avoir une seule variable régresseur X, on avait plusieurs variables 
X1,….XP, alors le plan de projection (X,∆) serait remplacé par l’hyperplan formé par 
les vecteurs X1,….Xp, ∆.  
Régresser Y sur les p variables régresseurs consisterait à projeter orthogonalement 
Y sur l'hyperplan déterminé par X1,….Xp, ∆. 
Distribution en un point fixé de X 
Jusqu'ici, on ne s'est appuyé que sur des calculs algébriques et sur des notions de 
géométrie, sans faire appel à des notions de statistique. On ne cherchait que la 
droite d'ajustement sur l'échantillon. 
Aucune supposition n'a été nécessaire dans toutes les démonstrations. 
 
Si maintenant, on souhaite utiliser les résultats obtenus à partir des observations, 
vues comme un échantillon, pour inférer sur la population, il faut faire appel à des 
notions de probabilité, et de statistique puisque dans les relevés de données 
(exemple : Poids et Taille) à notre disposition on n'a qu'un échantillon de valeurs et 
non toute la population. 
 
Sur la figure 1.7, on remarque que pour une même valeur du Poids, par exemple 85, 
il y a plusieurs valeurs possibles de la Taille  (158, 159, 160 et 162). 
 
Poids
Taille
152
154
156
158
160
162
164
166
168
170
172
0 20 40 60 80 100 120 140 160
152
158 158
159
160
162
165
159
166
162
166
168
165
167
172
163
164
168
 
 
Figure 1.7  Taille en fonction du Poids 
 
© Revue MODULAD, 2006 - 240-               Numéro 35 
 
 
Il n'y a pas de valeur unique associée à une valeur Xi mais une distribution de 
valeurs. 
 
Pour chaque valeur du poids (X) existe une distribution théorique des tailles (Y). Les 
valeurs de centrage sont les espérances des tailles de la population correspondant à 
chaque poids Xi. L’espérance (moyenne théorique µi) de chaque distribution de Y, 
est appelée « statistiquement parlant » l'espérance de Yi sachant Xi que l'on note 
E(Yi/Xi).   
L'hypothèse de la régression linéaire est que les µi sont alignés sur la vraie droite de 
régression qui est inconnue. 
 
Remarque : pour simplifier l'écriture on note E(Yi) au lieu de  E(Yi/Xi), soit : 
 
i10ii X)E(Y β+β==µ  
 
Représentation de X fixé et Y aléatoire 
 
X
Y
X1 X2 X3
µ1
Y1
µ2 µ3
ε1
X
vraie droite de régression
Droite estimée
∗
<--- observations
Y=
^
y3
b0+b1X
E(Y)= β0+β1 
∗
∗ ∗∗
∗
Y2 Y3
Distribution de Y pour X fixé
p(Yi | Xi)
 
 
Figure1.8  Distributions de Y pour X fixé 
 
Pour un même poids X1 fixé on a une distribution de taille Y1, dont on a observé une 
réalisation y1, ou plusieurs. 
 
Par exemple sur le graphique Taille*Poids de la figure 1.7, on remarque que pour 
X=46 on a une seule valeur observée Y=152, tandis que pour X=85 on observe  
plusieurs valeurs de Y (158, 159, 160 et 162). 
 
Chaque Yi est une variable aléatoire qui a une distribution de probabilité  de Yi 
sachant Xi notée  p(Yi⏐Xi). Des hypothèses sur la régularité de ces distributions 
devront être  faites :  
© Revue MODULAD, 2006 - 241-               Numéro 35 
 
 
 
 
• les distributions, pour tous les points Xi, sont supposées normales 
• stributions sont centrées sur la droite de régression  les espérances des di
• les variances de chaque Yi conditionnellement à Xi sont toutes égales. 
 
 
 plus les variables aléDe atoires Yi ne doivent pas être reliées entre elles, elles sont 
upposées  indépendantes. s
Ces suppositions se résument ainsi : 
 
Les variables aléatoires Yi sont 
indépendantes,  
 
d'espérance et de variance : 
1i X)Y( β+β= 0
2
i =)Yvariance( σ
E
 
 
Il faut avoir à l’esprit que E(Yi nelle. De même lorsque 
endu, variance conditionnellement à X. 
a figure1.8 montrant les distributions de Y pour X fixé est une illustration du modèle 
oujours en supposant que le modèle linéaire postulé est le véritable modèle, on 
) est une espérance condition
l’on parle de variance de Y, c’est sous-ent
 
« Vraie » droite de régression et droite estimée par la régression 
 
L
de régression linéaire. 
T
obtiendrait le vraie droite de régression X)Y(E 10 β+β= , si on avait à notre 
disposition toute la population. 
Comme on n'a qu'un échantillon d'observations, on n'a qu'une estimation 
XbbYˆ 10 +=  ou droite estimée par la régression. 
 
A propos des erreurs 
 
L'erreur théorique ε  représente l'écart entre Yi observé et l'espérance E(Yi) non 
ue 
i
observable. On notera q ε i  non plus n'est pas observable. Ce qui est observable 
e c'est l'erreur ei correspondant à l'écart entre Yi observé et iYˆ , son estimation par l
modèle. 
 
Le résidu observé ei est une estimation de l'erreur inobservable iε  . 
1.3. Carrés 
Ordinaires à la Régression. 
De la théorie des erreurs  en astronomie  à l'étude des moyennes en sciences 
sociales, un siècle les sépare. 
Glissement fonctionnel de la méthode des Moindre  s
© Revue MODULAD, 2006 - 242-               Numéro 35 
 
 
1.3.1. De l'Astronomie... 
hode des moindres carrés à Historiquement la mét d'abord été développée par 
"Comment combiner des observations effectuées dans des conditions différentes, 
afin d'obtenir les meilleures estimations possibles de plusieurs grandeurs 
astronomiques ou terrestres liées entre elles par une relation linéaire?". 
mesures dans 
s observations. 
rticle 
cientifique de Legendre sur les moindres carrés (Least Squares)  
LEGENDRE en 1805, pour répondre à une question posée par les astronomes et les 
spécialistes de la géodésie comme le rapporte DESROSIERES (1993) : 
 
 
Ces grandeurs sont mesurées par des instruments imparfaits, et par des 
observateurs qui ne sont pas tous identiques. Il y a des erreurs de 
le
 
De là provient le vocabulaire : observation, écart, erreur ou résidu. 
Vous pouvez trouver sur internet une traduction anglaise de ce premier a
s
http://www.stat.ucla.edu/history/legendre.pdf. 
1.3.2. … Aux Sciences Sociales 
 si la distribution 
oi normale, celle de la moyenne tend 
vers une loi normale, quand le nombre des observations s'accroît indéfiniment, 
 
2. La synthèse opérée par Laplace et Gauss vers 1810 entre: 
•  comment combiner au mieux des observations imparfaites ?   
"corrélation" 
ppliquèrent l'ajustement des moindres carrés à des données sociales dans les 
année
 
Nous r , révélateur d’une 
« Rev
http://ww ression.gif
En s'appuyant  sur : 
 
1. Le théorème central limite (LAPLACE 1810) montrant que même
de probabilité des erreurs ne suit pas une l
 
Réponse : en utilisant le milieu (la moyenne), 
•  comment estimer le degré de confiance que mérite une estimation ?  
Réponse : en terme de  probabilité, 
 
 Galton inventeur de la "régression" et PEARSON inventeur de la 
a
s 1880.  
eproduisons ci-après le graphique6 de GALTON
ersion », et accessible surinternet : 
w.stat.ucla.edu/history/reg  . 
 203 parents, en fonction de la taille moyenne de leurs parents (la 
ille de la mère étant préalablement multipliée par un coefficient 1.8). 
                                           
1.3.3. Galton Diagram Regression 
En 1885 GALTON réalisa le tableau qui croise la taille de 928 enfants (devenus 
adultes) nés de
ta
 
6 F GALTON, Regression towards mediocrity in hereditary statur", Journal of the Anthropological Institute 15 (1886), 
246-263. 
© Revue MODULAD, 2006 - 243-               Numéro 35 
 
 
 Ce n'est que vers les années 1930 que le formalisme de la méthode des moindres 
carrés associé à une interprétation probabiliste est devenu la « Régression » 
 
En présentant ce tableau sous forme d’un graphique, GALTON remarqua que l’on 
pouvait voir des ellipses de densités. Si les parents sont plus grands que la 
moyenne, les enfants seront également plus grands que la moyenne mais avec une 
taille plus proche de la moyenne que celle de leurs parents.  
 
Si les parents sont de petites tailles, leurs enfants seront également plus petits que la 
moyenne, mais avec une taille plus proche de la moyenne que celle de leurs parents. 
Il y a régression vers la moyenne.  
 
D’où le terme de « régression ». 
 
(ARMATTE (1995)). 
© Revue MODULAD, 2006 - 244-               Numéro 35 
 
 
 
Le glissement des méthodes d'analyse, des erreurs en Astronomie vers des 
stimations de moyennes en Sciences Sociales, a conduit à appeler erreur ou 
ii10i XY
e
perturbation ou encore aléa, l'écart de Y par rapport à sa moyenne. 
Le modèle s'écrit : 
 
ε+β+β=    
où les erreurs εi sont des aléas 
indépendants 
d’espérance =0 
de variance σ2 
1.3.4. Formalisation des Suppositions 
L'ensemble des suppositions nécessaires pour élaborer les tests statistiques se 
• l' erreur εi est une variable aléatoire d’espérance nulle et de variance constante σ2.  
 
résume ainsi: 
 
2
i )(E σε i )(Varet0 =ε=  
 
• l' erreur εi est non corrélée à εj.  
 
jirpou0),(Cov ji ≠=εε  
i sont normalement distribuées  
 
 
• les  erreurs ε
),0(N 2i σ≈ε  
 
 
On résume souvent ces 3 suppositions par l'expression "i i d selon une loi normale" 
oi normale 
qui signifie  
 
Indépendantes et Identiquement Distribuées selon une l
 
oires Y cIl faut de plus que les variables aléat nditionnellement à X soient 
dépendantes, et que les régresseurs Xj soient non aléatoires et non corrélés. 
(de variance minimum). En anglais on utilise l’acronyme BLUE (BEST Linear 
Unbiased Estimator)  
 
ous verrons au paragraphe suivant, comment interviennent ces suppositions sur les 
o
in
 
Lorsque ces suppositions sont vérifiées, l’e timateur MCO est non biaisé et efficace s
N
aléas dans les raisonnements statistiques. 
© Revue MODULAD, 2006 - 245-               Numéro 35 
 
 
1.4. Confiance à accorder aux résultats 
ns, la 
r 
 chercher à : 
• tester l'hypothèse nulle β1=0 et à calculer l'intervalle de confiance de  β1, 
 
 • tester l'hypothèse nulle 0 β0, 
n globale de la régression 
resssion multiple, c'est à dire avec 
ente la régression multiple, on 
p2
Pour inférer de l'échantillon à la population dont sont issues les observatio
logique statistique nous conduit à effectuer des tests d'hypothèses, et à détermine
des intervalles de confiance autour des valeurs estimées. 
 
uccessivement on vaS
 
 • tester la signification globale de la régression,  
  
β =0 et à calculer l'intervalle de confiance de  
 
 • calculer la précision de l'estimation de Y pour la moyenne et pour une observation 
individuelle. 
1.4.1. Test de la significatio
Ce test a surtout un intérêt dans le cadre de la rég
régresseurs. En anticipant sur le chapitre 2, qui présp 
généralise le modèle de régression à un régresseur au cas d'un modèle à p 
régresseurs 1 XX,X L  :  
 
pp110ii XX)E(Y β++β+β==µ L  
 
Ce test permet de connaître l'apport global de l'ensemble des variables X1,,...,Xp à la 
détermination de Y. 
On veut tester l'hypothèse nulle: 
H0: 1β
β ,,
0p =β==L   contre 
Ha: Il existe au moins un j   parmi  p1 ββ L   non égal à 0. 
On calcule la statistique de test    errorMS
modelMSF =  
 
avec p
= modelSSmodelMS  et 1p
errorSS
−= nerrorMS −  représentant  respectivement 
ne somme de carrés des écarts moyens respectivement pour le modèle et pour 
des suppositions suivantes, ce rapport F est une 
ervée d'une variable qui suit une loi de Fisher-Snedecor à p et n-p-1 
ance 
i
u
l'erreur. 
 
Si H0 est vraie et sous réserve 
valeur obs
degrés de liberté. 
 
Si les iε  sont indépendants et suivent une loi normale de même vari
),0(N 2σ≈ε  
© Revue MODULAD, 2006 - 246-               Numéro 35 
 
 
Alors la statistique F suit une loi de Fisher-Snedecor  
 
)1pn,p(F
errorMS
l ≈modeMSF −−=  
ègle de décision 
 
R
 
Si  F observé ≥ )1pn,p(F1 −−α−  
 
Alors  H : 00 p1 =β==β L  doit être rejetée au 
niveau α 
 
où )1pn,p(F1 −−α−  représente le quantile d'ordre (1− α ) de la loi de Fisher-Snedecor 
 (p) et (n-p-1
 
Note r une loi de Fisher-Snedecor 
st donnée par la fonction FINV. 
 )1pn,p,1(FINVF
à ) degrés de liberté.  
: Dans SAS, la fonction de répartition inverse pou
e
Instruction SAS   Ö  −−α−=  
vec n= nombre d'observations et p = nombre de régresseurs (non compris la 
constante). 
 
Pour éviter de rai  au F observé. La p-
value est le niveau de signific
probabilité de dépasser le F observé èse nulle est vraie. 
n p-value au risque α choisi (par exemple α=0.05). 
A
sonner sur F, SAS fournit la p-value associée
ité du test de Fisher-Snedecor, c'est-à-dire la 
 si l'hypoth
ativ
O  compare la 
 
Raisonnement sur la p-value 
 
Si p-value  ≤ α  
Alors on rejette l'hypothèse nulle 0p1 =β==β L  
 
Interprétation 
On dit que la régression est significative au niveau α. 
 ensemble, ce qui 
Le modèle retenu améliore la prévision de Y par rapport à la simple moyenne des Y. 
Pour la régresssion simple, ce test porte uniquement sur le paramètre 1β . 
 
Ce test fournit un moyen d'apprécier la régression dans son
ne signifie pas que chacun des coefficients de la régression soit 
significativement différent de 0. 
1.4.2. Statistiques liées au paramètre β1 
urer de la signific 1
nce de b1, puis en deuxième étape tester l'hypothèse nulle β1=0, en 
lle de confiance pour β1 autour 
Pour s'ass ativité du paramètre β , on va dans une première étape 
calculer la varia
troisième étape on pourra alors déterminer un interva
de b1. 
© Revue MODULAD, 2006 - 247-               Numéro 35 
 
 
Calcul de la variance de b1 
On a vu que b1 est le rapport de la covariance entre X et Y divisé par la variance de 
X : 
 
∑
∑
− 2i )XX(
−−= ii1
)YY)(XX(
b  
 
On développe le numérateur 
 
∑
∑∑ −−−= iii )XX(YY)XX(b − 2i1 )XX(  
 
Comme le 2ième terme du numérateur est nul, par définition de la moyenne 
)XX( i −∑ =0, il ne reste que le 1er terme. 
∑ −i )XX(
−++−= 2 nn111
)Y)XX(Y)XX((b L  
 
On ne peut calculer la variance de b  que si on fait des suppositions sur les Xi et sur 
s liaisons entre les Yi. 
uppositions 
 
Si les Xi sont non aléatoires 
i les Yi sont non corrélés et de même variance 2σ  
1
le
 
 pour calculer la variance de b1 S
S
Et comme par construction 0)1b,Y(Cov =  
Alors :  
)Y(Var n
2
1
2
11 ++= L a)Y(Vara)b(Var n  
 
avec   ∑ − 2ii )XX(
−= i )XX(a  assimilés à des constantes 
  
Ce qui permet d'aboutir à :  ∑ −=1 XX()b(Var
σ
2
i
2
)
 
nouveau faire une supposition. 
Si  
 
2σ  représente la variance inconnue de Y. Il faut   de
 
Supposition 
 
le modèle postulé est le modèle correct  
Alors  2σ  peut être estimé par les erreurs entre les iY  
observés et Yˆi    
© Revue MODULAD, 2006 - 248-               Numéro 35 
 
 
Mean Square Error= 
2n
)YY(
s ii2 −
−==
ˆ
MSE
2∑   
  
Note : Pour la régression multiple : 
1pn
sMSE 2 −−==
)YˆY( 2ii −∑  
Compte tenu de toutes ces suppositions, l'estimateur de l'écart-type de b1 devient : 
 
∑ − 2i1 )XX(=
s)b(s  
Remarque
• La variance de b est inversement proportionnelle à la dispersion des Xi autour 
Donc, si on veut améliorer la précision de b1 il faut, si possible, augmenter la 
variance  empirique des Xi. 
à (n-2), n étant la taille de 
l'échantillon. 
e 
l'échantillon. 
Test portant sur le paramètre 
 au test de l'hypothèse nulle: 
On
s: 
1 
de la moyenne. 
• La variance de b1 est inversement proportionnelle 
Donc, si on veut améliorer la précision de b1 il faut augmenter la taille d
β1 
On s'intéresse
H0 : paramètre  β1= 0    contre  Ha : paramètre  β1≠0  
 
 calcule la statistique de test   )b(s
bTobservé 1=
1
 
 
Si β1=0 la statistique Tobservé suit une loi de Student, sous l'hypothèse que les 
err
 
Su
eurs soient indépendantes et identiquement distribuées selon la loi Normale. 
ppositions 
Si    β1 = 0 
Si  ),0(N 2i σ≈ε  
Alors T observé suit une loi de Student à n-1 
degrés de liberté 
 
Raisonnement 
On compare la p-value associée à T observé, au risque α choisi (par ex:α=0.05). 
 
Si p-value ≤ α  
Alors on rejette l'hypothèse  β1 = 0 
 
 Conclusion : β1 est significativement différent de zéro au niveau α  
© Revue MODULAD, 2006 - 249-               Numéro 35 
 
 
Calcul de l'intervalle de confiance de β1 
On peut calculer un ur de b1, ce qui 
ermet de statuer s 1 : 
 intervalle de confiance (IC de niveau 1-α) auto
ur le paramètre βp
 [ ])b(stb;)b(stb)(IC 12/1112/1111 ⋅+⋅−=β α−α−α−  
 
où 2/1t α−  représente le quantile d'ordre 1-α/2 de la loi de Student à (n-2) degrés de 
liberté. 
      Instruction SAS      Ö   )2n,21(TINVT
 
Note 
• Dans SAS, la fonction de répartition inverse pour une loi de Student est donnée 
par la fonction TINV. 
/−= −α      avec n= nombre d'observations 
e avec p=nombre de régresseurs, la formule 
précédente devient: 
     Instruction SAS      Ö
 
• Dans le cas de la régression multipl
   )1pn,2/1(TINVT −−α−=  
 
En pratique : si α=5% et si n est assez grand (n>30), pour approcher la loi de 
Student par la loi Normale, 
   
 [ ])b(s96.1b;)b(s96.1b)(ICAlors  1111195.0 ⋅+⋅−=β  
Int
riable X dans le modèle n'apporte aucun pouvoir explicatif sur Y.  
a première étape consiste à calculer la variance de b0, puis en deuxième étape à 
 
  β0. 
 vaut : 
 
erprétation 
Si la valeur 0 est dans l'inte 1, alors l'introduction de la rvalle de confiance de β
va
1.4.3. Statistiques liées au paramètre β0 
L
tester l'hypothèse nulle β0=0, en troisième étape on pourra alors déterminer un
intervalle de confiance pour
Calcul de la variance de b0 
On a vu que b0
XbYb 10 −=  
la variance vaut: 
)XbY(Var)(bVar 10 −=  
 
Raisonnement 
cette 
i  
pour calculer la variance de b0 
 
Pour pouvoir calculer la variance il faut faire des suppositions sur les termes de 
expression. 
On suppose que les X  sont non aléatoires.
© Revue MODULAD, 2006 - 250-               Numéro 35 
 
 
Seuls la moyenne des Yi et le coefficient b1 sont des variables aléatoires. On peut 
 covariance entre montrer de plus que la Y  et le coefficient b1 est nulle
7 . 
 
Suppositions  pour calculer la variance de b
Si les Xi sont non aléatoires 
i les Yi sont non corrélés et de même variance 2σ  
0 
 
S
Et comme par construction 0)1b,Y(Cov =  
 
Alors :  
∑ −∑ −
=
2)XiX(n
2)XX(n
)1b(r
∑σ=σ+σ=
2
iX
222X
2
+= Va2X)Y(Var)0b(Var
i
  
 
2 onnue de Y. Il faut de nouveau faire une 
Si  le modèle postulé est le modèle correct  
σ  représente la variance inc
supposition. 
 
Supposition 
 
Alors  σ 2  peut être estimé par les erreurs entre les Y 
observés et Yˆ    
             
2n
)YˆY(
s
2
ii2
−
−= ∑  = MSE 
  
'estimateur de la variance  de b  devient : L 0
 
∑
∑
−= 2i
2
i
2
0
2
)XX(n
Xs
)b(s  
Remarque
La varianc  est proportionnelle à la somme des carrés des Xi. 
Si le plan el que les valeurs des Xi sont très grandes, la variance de 
b0
st portant sur le paramètre β0 
= 0    contre  Ha : paramètre  β0≠0  
On calcule la statistique de test   
 
: 
e de b0
d'expérience t tes
 sera très grande, et l'estimation de b0 n'aura aucune signification.  
Te
Test de l'hypothèse nulle H0 : paramètre  β0
 
)b(s
b
Tobservé
0
0=  
                                            
7 voir démonstration dans NETER, WASSERMAN, KUTNER pp75-77. 
© Revue MODULAD, 2006 - 251-               Numéro 35 
 
 
 
Si β0=0 la statistique Tobservé suit une loi de Student à n-2 degrés de liberté, sous 
tribuées selon 
Supposition 
l'hypothèse que les erreurs sont indépendantes et identiquement dis
la loi Normale. 
 
 
Si  )0(Ni ≈ε  , 2σ
Alors T observé suit une loi de Student 
 
 
Raisonnement 
n compare la p-value associée à T observé, c'est-à-dire la probabilité de dépasser 
Si p-value ≤ α 
O
le T observé en valeur absolue, au risque α choisi (par exemple α=0.05). 
 
Alors on rejette l'hypothèse  β0 =0 
 
 Conclusion     β  est significativement différent de zéro au niveau α  
Calcul de l'intervall
n peut assigne  un intervalle de confiance autour de b0, ce qui permet de statuer 
 β0: 
0
e de confiance de  β0 
O r
sur le paramètre
[ ])b(stb;)b(stb)(IC 02/1002/1001 ⋅+⋅−=β α−α−α−  
 
où 2/1t α−  représente le quantile d'ordre 1-α/2 de la loi de Student à n-2 degrés de 
liberté. 
 
Note 
t donnée 
par la fonction TINV. 
)2n
• Dans SAS, la fonction de répartition inverse pour une loi de Student es
Instruction SAS      Ö   ,2/1(TINVT −α−=    avec n= nombre d'observations 
 
t: 
Instruction SAS      Ö
 
• Dans le cas de la régression multiple avec p=nombre de régresseurs, la formule
précédente devien
   )1pn,2/1(TINVT −−α−=  
 
En pratique si on choisit le risque α=5% et si n est assez grand (n>30) pour 
approcher la loi de Student par la loi Normale, alors l'intervalle de confiance de β0 à 
5% est donné par : 9
 [ ])b(s96.1b;)b(s96.1b)(IC 0000095.0 ⋅+⋅−=β  
 
© Revue MODULAD, 2006 - 252-               Numéro 35 
 
 
Interprétation 
a valeur 0 est dans l'intervalle de confiance de β0, alors la dSi l roite de régression 
pas
aille en fonction du Poids  
 
se par l'origine.  
 
Exemple d’estimation des paramètres avec Proc REG 
Sur l’exemple de la T
 
Programme SAS 
 
Proc REG data=libreg.tailpoid outest=TableSortie; 
title 'Régression de la Taille en fonction du Poids '; 
model y=x ; 
proc Print;title "Table de l'option outest"; 
run; 
 
 
Sortie de Proc REG 
 
 
 
 
 
 
 
Interprétation du test de la signification globale de la régression 
 
La statistique 35.42
62.6
529.280
errorMS
modelMSF ===  indique que globalement le modèle avec le 
régresseur Poids améliore la prévision de la Taille, par rapport à la moyenne seule 
dans le modèle. 
 
 
 
 
 
© Revue MODULAD, 2006 - 253-               Numéro 35 
 
 
Interprétation des estimations des paramètres 
pour valeur 145.98994
 
L’estimateur de β0 a . Son écart type vaut 2.71384.  
 
La statistique de Test  79.53
71384.2
valuet ==  et sa p 9894.145 value associée est bien 
n rejette l’hypothèse que 0O =β  avec une grande confiance. 
ême raisonnement pour l’estimateur de β1 qui a pour valeur 0.17030. 
β1 et lié à 
inférieure au seuil 0.05. 
O
 
M
 
Note 
Dans le cas de la régression simple la statistique de test de l’estimateur de 
2F :  )valuet(F =  
 
ans laD  table en sortie par l’option outest=, SAS enregistre RMSE et les valeurs des 
ramètres.  
 standard les intervalles de confiance des paramètres mais on 
s cette table en sortie, en utilisant l’option outest= et le mot clé 
pa
SAS n’imprime pas en
eut les récupérer danp
Tableout. 
 
Programme SAS 
 
 
Proc REG data=libreg.tailpoid outest=TableSortie Tableout; 
title 'Régression de la Taille en fonction du Poids '; 
model y=x  ; 
proc PRINT data=TableSortie;  
title "Table produite par l'option outest avec le mot clé 
Tableout"; 
run; 
 
 
 
es lignes L9 intervalles de confiance à 95% des 
n a vu que pour chaque valeur iX  fixée, la vraie droite de régression était le lieu 
e l'espérance (i.e. la valeur  moyenne) de Y  et que les Y devaient théoriquement 
e distribuer selon une loi normale centrée sur cette droite avec une variance 
éorique σ2. 
 
L 5B et U95B donnent les 
paramètres. 
1.4.4. Précision sur l'estimation de Y 
O
d
s
th
© Revue MODULAD, 2006 - 254-               Numéro 35 
 
 
Pour évaluer la précision sur l'estimation de Y on aura deux optiques à considérer, 
oit on s'intéressera à l'intervalle de confiance autour de l'estimation de la droite de 
 X. 
niveau particulier de X pour lequel nous voulons estimer la 
 l'échantillon, ou une 
utre valeur de la variable régresseur non repérée dans l'échantillon. La réponse 
kYˆ  . 
 voir la distribution d'échantillonnage de kYˆ , comme la distribution que l'on 
  Calcul de l'erreur-type sur kYˆ   
 
s
régression, soit on s’intéresse à l'intervalle de prévision de Y en fonction de
 
Intervalle de confianc  la droite de régression 
Soit Xk représentant un 
e autour de l'estimation de
valeur moyenne de Y. Xk tre une valeur connue danspeut ê
a
moyenne quand X=Xk  est notée E(Yk). L'estimateur de E(Yk) est noté 
Il faut
obtiendrait si on effectuait des mesures répétées en Xk. 
 
♦
On a vu que l'estimation de E(Yk)  est donnée par : 
)X(XbYYˆ k1k −+=  
 
Plaçons-nous en un point Xk et calculons la variance de  kYˆ   : 
 
))X(XbY(Var)Yˆ(Var k1k −+=  
ette 
les Xi sont non aléatoires. 
eut 
 
s de cPour pouvoir calculer la variance il faut faire des suppositions sur les terme
expression. 
Comme précédemment on suppose que 
Seuls la moyenne des Yi et le coefficient b1 sont des variables aléatoires. On p
montrer de plus que la covariance entre Y  et le coefficient b  est nulle 8 . 1
ppositions  pour calculer la variance de kYˆ   
 les Xi
 
Su
Si  sont non aléatoires 
Si les Yi sont non corrélés et de même variance 2σ  
Et comme par construction 0)1b,Y(Cov =  
Alors :  
∑ −
σ−+σ= 22k )XX()XX(n
=−+=
i
22
1
2
kk )b(Var)XX()Y(Var)Yˆ(Var
 
 
Comm riance théorique 2σ  de Y. Il faut 
l'estimer. 
                    
e précédemment, on ne connaît pas la va
 
 
 
                        
 voir démonstration dans NETER, WASSERMAN, KUTNER pp75-77. 8
© Revue MODULAD, 2006 - 255-               Numéro 35 
 
 
Supposition 
 
Si  le modèle postulé est le modèle correct  
Alors 2σ  peut être estimé par les erreurs entre les 
Y observés et Yˆ    
             
2n
)YˆY(
s ii2 −
−= ∑  = MSE 2
 
ˆ
2/1
2
k )XX(1)ˆ ⎢
⎡ −+=L'estimateur de l'erreur-type de kY  devient : 2
i
k
)XX(n
sY(s ⎥⎦⎢⎣ −∑
⎥⎤  
  Calcul de l'intervalle de confiance de Yˆ   ♦ k
On montre que pour un modèle de régression la  statistique 
)Yˆ(s
)Y(E
k
k −Yˆ  suit  une 
distribution de Student à (n-2) degrés de liberté. 
La vraie valeur moyenne µk  a une probabilité égale à (1-α) 
’appartenir à l'intervalle de confiance :  
de Y pour un Xk
d
 [ ])Yˆ(stY;)Y(s.tY))Y(E(IC kkk21kk1 2/α−+−= −α− .ˆˆˆ /α 1  
L'intervalle de confiance de kYˆ  se matérialise par deux lignes courbes, des 
yperboles, comme le montre la figure 1.9. h
 
 
 moyenne des Tailles  
 de l'intervalle de confiance, on peut faire les remarques 
uivantes : 
 
 
Figure 1.9  Intervalle de confiance à 95% de la
selon les valeurs des Poids 
 
A propos de la largeur
s
 
 
© Revue MODULAD, 2006 - 256-               Numéro 35 
 
 
• La largeur  varie en fonction de )XX( k −  
• La largeur est minimum au point XXk =  
        C'est  gravité du nuage des  dire qu la précision est la meilleure, au centre dee 
points 
• re de gravité. La précision est la plus La largeur croît lorsqu'on s'éloigne du cent
mauva  du nuage de points. ise aux extrémités
 
Intervalle de prévision de Y sachant X 
valeur kX , de la variable X et non pas à la valeur moyenne de Y.
Dans ce cas, la variance de Y a deux composantes : 
. 
calcul réalisé au paragraphe précédent 
e sa position centrale au point 
our une explication 9
 
                             
Ici on s'intéresse à la prévision d e nouvelle'un  observation individuelle de Y pour une 
 
 
1. la variance de la position centrale de la distribution d'échantillonnage de kYˆ , cf
2. la variance 2σ  de la distribution de Y autour d
kXX = . Comme précédemment, on estime 2σ  par s2. 
 
P visuelle de cette décomposition  voir la figure 1.10. 
Yk
^
limite de prévision
Si E(Yk) est ici
limite de prévision
Si E(Yk) est ici
limite de confiance pour E(Yk)  
 
Figure 1.10  Illustration de la prédiction d'une nouvelle observation individuelle  
de Y 
 
L'estimateur de l'erreur-type de Y sachant X devient : 
 
⎥⎥⎢ ++=+ 2
k2
k
22
)
1s)Yˆ(ss
⎦
⎤⎡ − 2)XX(1
⎢⎣ −∑ i XX(n  
 
L'intervalle de confiance d'une prévision de Y sachant X se matérialise là aussi par 
deux lignes courbes décalées d'une distance "s" par rapport à l'intervalle de 
nfiance calculé pour la moyenne de Yk. 
                                         
co
   
9Source : NETER, WASSERMAN et KUTNER, p82. 
© Revue MODULAD, 2006 - 257-               Numéro 35 
 
 
 
Les remarques faites précédemment sur l'estimation de la moyenne de Yk sont les 
 mêmes que celles faites pour une observation individuelle. A savoir, la largeur de
l'intervalle de confiance varie en fonction de )XX( − , c'est au centre de gravité duk  
 de 
 
nuage de points que la précision est la meilleure, et aux extrémités du nuage
points que cette précision est la plus mauvaise. 
 
 
es Tailles 
Sur la figure 1.11 on v iduelles est 
évidemment plus grand que l’intervalle 
 
Attention 
En prévision et dans un cadr mer aux extrémités de la 
plage de variation de X, or c'
Exemple avec les options CLI CL
Les options CLI 
l’instruction model
Pour sauve Output.  
 
r
 
Figure 1.11  Intervalle de confiance à 95% des prévisions individuelles d
 
oit que l’intervalle de confiance des prévisions indiv
de confiance des moyennes théoriques. 
e temporel, on cherche à esti
est justement là que la précision est la moins bonne! 
M  de la Proc REG 
(Confidence Limit Individual) et CLM (Confidence Limit Mean) de 
 de Proc REG donnent ces intervalles de confiance. 
garder ces valeurs dans une table SAS  il faut utiliser l’instruction 
P
 
ogramme SAS 
Proc REG data=libreg.tailpoid ; 
title 'Régression de la Taille en fonction du Poids '; 
model y=x /CLI CLM  ; 
Output Out=Table2 Predicted=Pred residual=Residu  
       LCL=Borne_Inf_ind UCL=Borne_Sup_Ind 
       LCLM=Borne_Inf_Moy UCLM=Borne_Sup_Moy; 
proc PRINT data=Table2 ;title "Table produite par 
l'instruction OUTPUT"; 
run; 
 
 
 
 
© Revue MODULAD, 2006 - 258-               Numéro 35 
 
 
Sortie de PROC REG 
 
 
 
Lecture : 
 
Le
Dependant variable : Y 
 : les 2 colonnes suivantes donnent les bornes inférieure et 
s options CLM CLI donne pour chaque observation, les valeurs :  
Predicted Value : Yˆ  
Std Error mean predict : erreur-type au point Xi
95% CL Mean
supérieure de l’intervalle de prédiction à 95% de la moyenne. 
95% CL Predict : les 2 colonnes suivantes donnent les bornes inférieure et 
supérieure de l’intervalle pour une prédiction individuelle. 
Residual : résidu  
 
L’instruction Output avec les mots clés LCL UCL LCLM UCLM permettent de 
récupérer ces statistiques dans une table SAS: 
 
 
 
 
© Revue MODULAD, 2006 - 259-               Numéro 35 
 
 
2. 
Dans ce c imple pour 
les formalis
2.1. 
erche à 
La régression linéaire multiple 
hapitre nous reprenons les concepts de la régression linéaire s
er et les étendre à la régression multiple. Nous présentons les différentes 
formes de décomposition de sommes de carrés (Sum of Squares) et commentons 
les résultats obtenus avec la procédure REG. 
Le critère des moindres carrés  
Tout comme en régression linéaire simple; la régression linéaire multiple ch
approximer une relation fonctionnelle trop complexe en général, par une fonction 
mathématique simple telle qu'une équation de la forme: 
 
ε+β++β+β+β= XXXY L pp22110  
 
eprenonsR  le résumé des concepts de la régression linéaire présenté au chapitre 1. 
• Y : varia  ou variable dépendante). 
• Xj : varia
 
Cette équ ) 
1O ,,, βββ L e 
en minimi
Le critère mme des carrés 
des écarts (SC Erreur en français, SS Error en anglais) entre Y observé et Y estimé 
ar l'équation de régression. 
L'équation de régression ou modèle postulé, met en relation: 
ble réponse (à expliquer
bles régresseurs (explicatives ou variables indépendantes).  
ation est linéaire par rapport aux paramètres (coefficients de régression
p . Le modèle est dit linéaire. Ces paramètres sont inconnus, on les estim
sant le critère des moindres carrés (MCO ou Ordinary Least Squares). 
 des moindres carrés correspond à la minimisation de la so
p
Y estimé est noté 
^
Y  . 
 
ippi110i Xb...XbbYˆ +++=  
Y : variable réponse 
Xj : p variables régresseurs,  j=1,…p 
i   indice de l'observation courante, i=1,…n  
n  le nombre d'observations. 
avec:  
 
es valeurs qui minimisent ce critère sont des estimations b0,b1,....bp des paramètres 
p1O ,,, βββ L  inconnus. 
 
Estimation des paramètres du modèle  
 
Dans le cas d'un modèle à p variables régresseurs le critère des moindres carrés 
s'écrit: 
 
L
© Revue MODULAD, 2006 - 260-               Numéro 35 
 
 
2n
1i
ipi10i
n
2
i
n
2
iip0 )Xp...1XY()YˆY(),...(S ∑∑∑
=
β−β−β−=ε=−=ββ
1i1i ==
 
 
Les valeurs des β qui minimisent ce critère seront les solutions b , b , …b  du 0 1 p
système linéaire de (p+1) équations à (p+1) inconnues. 
 
pyppp22p11p SbS....bSbS =+++
y1pp1212111
....
SbS....bSbS =+++
 
Avec   
)XX)(XX(S −−= ∑ jji
n,1i
kkikj
=
  pour k,j=1,2,…p 
 
)YY)(XX(S kkiky −−= ∑ i
n,1i=
  pour k=1,2,…,p 
 
our résoudre un tel système linéaire les mathématiciens ont développé le calcul 
 
 
tte présentation cache 
ées réelles. 
P
(algèbre) matriciel qui permet une présentation et des traitements compacts de
onc devenue l'uniquegrands tableaux de données. La notation matricielle est d
moyen d'appréhender la régression multiple. Cependant ce
bien des difficultés du point de vue des résolutions numériques sur donn
 
Les estimateurs des moindres carrés estiment les paramètres inconnus p1O ,,, βββ L  
certaine précision. Sous les suppositions que les erreurs sont 
indépendantes et identiquement distribuées selon une loi normale, les estimat
avec une 
eurs 
reurs inconnues i : 
 
MCO sont centrés sur une valeur à laquelle est associé un intervalle de confiance. 
L’intervalle de confiance dépend de l'adéquation du modèle aux données, 
adéquation qui dépend des er ε
)Y(EY iii −=ε  
 Formalisation de la régression linéaire multiple 
es n observations de la variable réponse 
te en première colonne un vecteur constitué uniquement de 1. 
a matrice X est alors de dimension 
ive. 
2.2.
En notation matricielle : 
 
 Y est le vecteur colonne d•
• X(n,p) la matrice des observations des p vecteurs Xi , chacun de dimension (n,1). 
 
ice on ajouA cette matr
Ce vecteur correspond à la constante X0. L
n,p+1). (
Cette représentation permet de traiter la constante X0 comme une variable 
explicat
© Revue MODULAD, 2006 - 261-               Numéro 35 
 
 
• β
inconnus 
• ε représente le vecteur des erreurs. 
 est le vecteur colonne des (p+1) coefficients de régression ou paramètres 
βi.  
 
 
         
n
3
2
1
Y
Y
Y
Y
Y
L
=      
np2n1n XXX1 L
p11211
1
1
XXX1
X
L
L
=             
p
2
1
0
β
β
β
β
=β
L
         
        n
3
2
1
ε
ε
ε
ε
=ε
L
 
  
 
le modèle s'écrit: ε+β= XY  
 
Y estimé par le modèle de régression s'écrit: XBˆXYˆ =β=   
 
Le vecteur colonne βˆ  (noté aussi B) représente le vecteur des estimateurs bi des 
moindres carrés des paramètres inconnus β . 
es notations matricielles permettent d'écrire simplement le système à résoudre pourL
tr
 
ouver les coefficients bi qui minimisent le critère des moindres carrés: 
 
)Y'X(B)X'X( =  
X' désignant la matrice transposée de X. 
 
Le vecteur B des coefficients solution s'obtient en inversant la matrice )XX( ′ : 
 
)YX.()XX(B 1 ′′= −  
 
La résolution de ce système n'est pas toujours possible. Cette résolution est liée à la 
possibilité d'inversion de la matrice )XX( ′ . 
 
Supposons que 2 variables Xi et Xj soient corrélées entre elles c'est-à-dire qu'il 
re permettant de passer de Xi à Xj on a alors 2 lignes de la 
e 
toujours (p+1) inconnues à trouver.  
es  sont les éléments diagonaux de la matrice de 
existe une relation linéai
matrice )XX( ′  qui sont proportionnelles et lorsque l'on veut résoudre le système il n
reste plus que p équations indépendantes et 
Le système est indéterminé, il existe une infinité de solutions.  
 
 variances des estimateurs (b)L
variance-covariance des X inversée multipliés par la variance des erreurs 2σ  . 
122 )XX()b( −′σ=σ  
 
Comme pour la régression simple σ2 est estimé par   errorSS =MSE
1pn −−  
© Revue MODULAD, 2006 - 262-               Numéro 35 
 
 
Les variances des estimateurs dépendent des éléments diagonaux de la matrice 
inverser. Si des régresseurs sont corrélés, les variances des estimateurs des
ées, et les estimati
à 
 
paramètres sont élev ons sont instables (non robustes). Un 
a matrice H  
 
X)X
avec
HYYˆ
YX)XX(XYˆ
XBYˆ
1
1
′′
=
′′=
=
−
−
exemple de cette instabilité sera donné au chapitre 4. 
 
L
A partir de l'expression du vecteur B des estimateurs des coefficients on peut 
calculer l'estimation de Y: 
X(X=H
 
 
ue des données relatives 
aux variables régresseurs va jouer un rôle usage sera développé 
2.3.1. Présentation des données 
ec quelques options de Proc REG, nous 
vons repris l’exemple de la chenille processionnaire du pin traité dans l’ouvrage de 
ançaise 
(voir FOUCART, AZAIS-BARBET). On pourra ainsi, avec leurs ouvrages, poursuivre des 
analyses plus complexes de ces données. 
ettes où sont plantés des arbres 
re l’influence de certaines caractéristiques 
e peuplements forestiers (variables régresseurs X1-X10) sur le développement de 
Cette matrice H - H comme Hat matrice- qui n qe comporte 
 important, et son 
chapitre 4. 
2.3. Exemples de régression linéaire multiple avec Proc REG 
Pour présenter la régression multiple av
a
TOMASSONE & al. Cet exemple est fréquemment analysé dans la littéra frture 
Le fichier de données est composé de 33 
in
plac
fectés par des nids de chenille « procesionnaire du pin », une variable réponse 
(X11 et sa transformée en Log et dix variables régresseurs potentiels (X1-X10). 
 « Les expérimentateurs souhaitent îtconna
d
la chenille processionnaire du pin (variable réponse X11 ou son logarithme ) ». 
 
1 : Nombre de nids de processionnaires par arbre d’une X1
placette. 
Log  = Log(X11), transformation de la variable X11 par son    
logarithme 
 
X1 : Altitude (en mètre) 
X2 : pente (en degré) 
X3 : nombre de pins dans une placette de 5 ares 
X4 : hauteur de l’arbre échantillonné au centre de la placette 
X5 : diamètre de cet arbre 
© Revue MODULAD, 2006 - 263-               Numéro 35 
 
 
X6 : note de densité de peuplement 
X7 : orientation de la placette  
(1 orientation vers le sud, 2 autre) 
X8 : Hauteur (en m) des arbres dominants 
X9 : nombre de strates de végétation 
X10 : mélange du peuplement (1 pas mélangé, 0  mélangé) 
 
Données de base 
 
 
2.3.2. Régression linéaire multiple avec Proc REG sans options 
Nous étudions le modèle linéaire de la variable Log en fonction des 4 
régresseurs X1, X2, X4, X5. 
 
Etape 1 : Graphique de la matrice de diagrammes de dispersion (Scatter Plot avec 
SAS/INSIGHT)  
Etape 2 : Analyse des corrélations entre les variables 
Etape 3 : Régression multiple 
 
Nous utilisons SAS/INSIGHT qui est beaucoup plus efficace pou
 exploratoires, (voir en annexe 2 le mode d’emploi
r obtenir des 
graphiques  succinct de 
SAS/INSIG
 
Programm
 
HT). 
 SAS e
/* étape 2 */ 
proc COR lation de  X1 X2 R data=libreg.chenilles;  title 'Corré
X4 X5 avec Log'; 
var X1 X2 X4 X5 Log; 
run; 
© Revue MODULAD, 2006 - 264-               Numéro 35 
 
 
/*étape 3 */ 
proc REG data=libreg.chenilles; 
title 'Régression de LOG avec X1 X2 X4 X5 sans options'; 
model Log=X1 X2 X4 X5; 
run; 
 
 
 
Figure 2.1: Matrice des diagrammes de dispersion des variables croisées 2*2. 
Sur la diagonale sont affichées les valeurs min et max pour chaque variab
 
le. 
Sortie SAS de PROC CORR 
 
 
iagrammes de dispersion de la figure 2.1, donne une image des 
se Log est liée négativement à tous les régresseurs.  
 
Le graphique des d
liaisons entre toutes les variables X1, X2, X4, X5, Log. On voit d’un coup d’œil que 
les variables X4 et X5 sont très liées. Le coefficient de corrélation vaut 0.90466. 
D’autre part la variable répon
© Revue MODULAD, 2006 - 265-               Numéro 35 
 
 
La matrice de Scatter Plot est un complément utile à l’analyse de la matrice des 
i de repérer les points atypiques (outliers) 
s options 
coefficients de corrélation. Elle permet auss
en X et en Y. 
 
SAS de PROC REG sanSortie 
 
 
 
 
Lecture du test globa
 
 
e la variabil é de Y est expliquée par le modèle. 
 
• 
• 
• 
• 
• 
 
Toutes les
l’hypothèse
Cependant
négative.  
Log ?  
a corrélation entre X4 et X5 provoque une instabilité des valeurs des coefficients. 
Cette sortie est analogue à celle de la régression simple, on retrouve les mêmes 
informations explicitées au chapitre1. 
l dans le tableau de l’Analyse de Variance 
• F value = 12.83 avec p value <0.001 Ä  rejet de H0 tous les paramètres ne
sont pas tous nuls 
• R2 = 0.6471  Ä  64% d it
 
Lecture des paramètres 
Intercept               b0 = 7.73214  s(b0)=1.48858 
Coefficient de X1  b1=-0.00392  s(b1)=0.00115 
Coefficient de X2  b2=-0.05734 s(b2)=0.01939 
Coefficient de X4  b4= -1.35614 s(b4)=0.31983 
Coefficient de X5  b5=  0.28306 s(b5)=0.07626 
 p-value associées aux estimateurs des paramètres sont <0.05, on rejette 
 de nullité pour chacun des coefficients de la régression. 
 le coefficient de X5 est positif alors que la corrélation (X5, Log) est 
Peut-on alors parler d’un effet positif de cette variable X5 sur la variable réponse 
L
© Revue MODULAD, 2006 - 266-               Numéro 35 
 
 
2.4. TYPE I SS et TYPE II SS de Proc REG 
ous verrons N d’abord la définition des statistiques Type I SS et Type II SS relatif à 
 plusieurs paramètres.  
Reprenons
 
un paramètre puis les tests partiels relatifs à
2.4.1. Définition de TYPE I SS et TYPE II SS 
 l'équation fondamentale de l'analyse de la variance : 
SS Total = SS Model  + SS Error 
 
SS total  est 
invariant  
a 
• 
• TYPE II SS : représente la réduction de SS Error liée à la variable 
TYPE I SS 
ODEL de Proc 
REG : 
 
qui représente la somme des carrés des écarts entre Y et sa moyenne
quel que soit le nombre de variables régresseurs p dans le modèle.
Lorsqu'on introduit une nouvelle variable régresseur dans un modèle SS Model 
augmente et donc SS Error diminue de la même quantité.  
Pour juger de la contribution d'une variable régresseur à la réduction de SS Error, l
Proc REG calcule pour chaque variable du modèle, deux sortes de SS Error.  
TYPE I SS : représente la réduction de SS Error liée à la variable lorsqu'elle 
est introduite séquentiellement dans le modèle. 
lorsqu'elle est introduite la dernière dans le modèle. 
 
• 
Soit le modèle complet définit avec les p régresseurs de l'instruction M
[ ]IC )b(s96.1b;)b(s96.1b)( iiiii95.0 ⋅+⋅−=β  
 
Soit d'autre part le modèle restreint aux k premiers régresseurs :  
 
ε+β++β+β+β= kk22110 XXXY L  
 
Pou a  différence entre SSerror du 
mod e gresseurs.  
 
ttention : Le TYPE I SS d'une variable dépend de l'ordre de la variable dans 
isher-
et sa p-value, niveau de significativité du test. Le calcul de la F value et de 
Cette statistique de test vaut : 
r l  "k"ème variable, TYPE I SS correspond à la
èl  à (k-1) régresseurs et SSerror du modèle à k ré
A
l'instruction MODEL de Proc REG. 
 
A TYPE I SS peut être associée une statistique de test,  la F Value ou F de F
Snedecor, 
sa  p value associée n'est pas réalisé dans Proc REG10. 
 
• F VALUE : statistique de Fisher-Snedecor 
  
ErrorMS
SS I TYPE = VALUEF  
 
                                            
10 La statistique de Fisher-Snedecor F value et son niveau de significativité p-value pour Type I SS et TYPE II SS 
sont disponibles dans Proc GLM et dans SAS/INSIGHT. 
© Revue MODULAD, 2006 - 267-               Numéro 35 
 
 
Le r n de SS error lorsque l'on passe 
du modèle à (k-1) régresseurs -la variable étudiée étant exclue- au modèle à k 
hèse nulle de la 
kième variable.  
 
numé ateur TYPE I SS correspond à la réductio
régresseurs. 
Le dénominateur MS Error correspond au modèle complet à p régresseurs . 
La statistique de test F value ainsi définie permet de tester l'hypot
Hypothèse à tester 
n veut tester si le paramètre 0k =β .  O
H0 : 0k =β   contre 
Ha : 0k ≠β  
 
La statistique de test F value est sous H0 une valeur observée d'une variable F de 
Fisher-Snedecor à 1 et (n-p-1) degrés de liberté. L'hypothèse nulle doit être rejetée 
au niveau α lorsque : 
 
)1pn,1(FobservéF 1 −−≥ α−   
 
où 1F1 )1pn,( −−α−  représente le quantile d'ordre ( α−1 ) de la loi de Fisher-S
n-p-1) degrés de liberté.  
nedecor 
à (1) et (
ision 
 
Règle de déc
Si  )1pn,1(FvalueF 1 −−≥ α−  
Alors  H0: 0k =β  doit être rejeté au niveau α 
 
 H0 : 0k =β  est 
1 α−
variable contribue significativem duction de SS Error, lorsqu'elle est entrée 
n dernier dans le modèle à k régresseurs. 
Raisonnement  
Au seuil α% la valeur maximum atteinte par F sous l'hypothèse nulle
)1pn,1(F −− , si donc F value est supérieure on rejette l'hypothèse nulle. La 
ent à la ré
e
 
•  Prob > F  
'est la p-value associée à F value. C
On compare la p-value, au risque α choisi (par exemple α=0.05). 
 
aisonnement sur la p-value R
 
Si p-value  ≤ α  
Alors on rejette l'hypothèse nulle 0k =β  
 
Interprétation : Si la probabilité (Prob>F) est faible (<0.05) la variable contribue 
Error dans le modèle à k régresseurs. 
TYPE II SS 
Soit le modèle complet définit avec p régresseurs dans l'instruction MODEL de Proc 
REG : 
significativement à la réduction
 
 de SS 
• 
 
© Revue MODULAD, 2006 - 268-               Numéro 35 
 
 
[ ])b(s96.1b;)b(s96.1b)(IC iiiii95.0 ⋅+⋅−=β  
 
Pour la kième variable, TYPE II SS correspond à la différence entre SSerror du 
modèle à (p-1) régresseurs (le kième régresseur étant exclu) et SSerror du modèle 
complet à p régresseurs.  
 
A TYPE II SS peut ê
Snedecor, et sa p-val
tre associée une statistique de test, la F value ou F de Fisher-
ativité du test. 
Remarque : Par construction TYPE I SS et TYPE II SS de la dernière variable du 
modèle ont la même valeur. 
F VALUE : stat
Cette statistique de test vaut : 
ue, niveau de signific
 
 
Le calcul de la F value et de sa  p value associée n'est pas réalisé dans Proc REG, il 
faut faire le calcul à la main, ou utiliser l'option de Proc REG, SELECTION= 
FORWARD ou BACKWARD qui donne les F value de TYPE II à chaque pas . 
 
• istique de Fisher-Snedecor 
  
Error 
SS II TYPE = VALUEF
MS
 
ond à la réduction de SS error lorsque l'on passe 
u modèle à (p-1) régresseurs –le régresseur étudié étant exclu- au modèle complet 
Le dénominateur MS Error correspond au , avec les p régresseurs . 
La statistique de tes
partiel. 
ter 
 
Le numérateur TYPE II SS corresp
d
à p régresseurs. 
modèle complet
t F value ainsi définie permet de tester l'hypothèse nulle du 
"k"ème régresseur, lorsqu’il entre en dernier dans le modèle. C’est un F dit 
 
Hypothèse à tes
On veut tester si le paramètre 0k =β .  
0H0 : k =β   contre 
Ha : 0k ≠β  
 
La statistique de test F value est sous H0 une valeur observée d'une variable F de 
s de liberté. L'hypothèse nulle doit être rejetée Fisher-Snedecor à 1 et (n-p-1) degré
au niveau α lorsque : 
)1pn,1(FobservéF 1 −−≥ α−   
 
ù )1pn,1(F1 −−α−  représente le quantile d'ordre (o α−1 ) de la loi de Fisher-Snedecor à 
(1) et (n-p-1) degrés de liberté.  
 
ègle de décision R
 
Si  )1pn,1(FvalueF 1 −−≥ α−  
Alors  H0 : 0k =β  doit être rejetée au niveau 
α 
 
© Revue MODULAD, 2006 - 269-               Numéro 35 
 
 
Raisonnement  
u seuil α pothèse nulle H0 : 0k =β  est  
odèle. 
 α  
A % la valeur maximum atteinte par F sous l'hy
)1pn,1(F1 −−α− , si donc F value est supérieure on rejette l'hypothèse nulle. 
Le régresseur contribue significativement à la réduction de SS Error, lorsqu'il est 
entré en dernier dans le m
 
Remarque : F value = T2, avec T représentant la valeur du test de Student associé 
u paramètre. a
 
 
  Prob > F  •
C'est la p-value associée à F value. On compare la p-value, au risque α choisi (par 
ex : α=0.05). 
Raisonnement sur la p-value 
 
Si p-value  ≤
Alors on rejette l'hypothèse nulle 0k =β  
 
Interprétation : Si la probabilité (Prob>F) est faible, le régresseur contribue 
TYPE I SS = TYPE II SS = SS modèle 
e variable régresseur : 
le TYPE I SS (lié au F séquentiel) dépend de l’ordre d’apparition des variables 
on MODEL, tandis que TYPE II SS (lié au F partiel) n'en 
e dans le modèle ou 
en dernier.  
 
tre les régresseurs. 
ée par ce régresseur est redondante par rapport à l’information 
pportée par les précédents régresseurs déjà introduits dans le modèle. 
2.4.3. Options  REG 
truction model de PROC REG permettent d’obtenir 
s statistiques Type I SS et Type II SS. 
 
significativement à la réduction de SS Error, même lorsqu'il est entré en dernier 
dans le modèle complet à p régressseurs. 
2.4.2. Interprétations conjointes de TYPE I SS et TYPE II SS 
• Lorsque le modèle ne comporte qu'une seule variable régresseur : 
 
• Lorsque le modèle comporte 'unplus d
régresseurs dans l’instructi
dépend pas. 
 
Si pour un régresseur Xi, le F séquentiel et le F partiel sont plus grands que ceux 
des autres régresseurs, alors Xi a une contribution plus grande puisqu'il réduit plus 
la variation de SS Error, que la variable soit entrée en séquenc
Si pour un régresseur Xi, le F séquentiel est signi f et le F partiel ne l’est plus 
c’est qu’il y a des colinéarités en
ficati
 
L’information apport
a
 SS1 et SS2 de l’instruction model de Proc
Les options SS1 et SS2 de l’ins
le
© Revue MODULAD, 2006 - 270-               Numéro 35 
 
 
Programme SAS 
 
 
proc REG data=libreg.chenilles;  
     title 'Régression de Log avec X1 X2 X4 X5 avec Options 
SS1 SS2 '; 
     model Log=X1 X2 X4 X5/ SS1 SS2; 
run; 
 
 
Sortie de Proc REG de SAS 
 
 
Exemple pour X1 : 
• iable X1 est 
entrée la première dans le modèle (elle est alors la seule variable régresseur). 
ariable X1 est 
l à la main, car dans 
 
Lecture  
 
Type I SS = 14.12216 est la réduction de SS error lorsque la var
• Type  II SS =7.30671 est la réduction de SS error lorsque la v
entrée la dernière dans le modèle.  
 
Pour tester si cette réduction est significative il faut faire le calcu
cette sortie, Proc REG ne fournit pas les F value et les proba associées pour TYPE I 
SS et TYPE II SS :  
 
59.22
0.62512  ErrorMS
valueF === 1222.14SSITYPE  
 
69.11
0.62512  ErrorMS
valueF === 30671.7SSIITYPE  
IGHT. 
 
On peut vérifier ces F value avec les sorties de SAS/INS
 
© Revue MODULAD, 2006 - 271-               Numéro 35 
 
 
Sortie avec SAS Insight 
 
 
 
Note : SAS/ INSIGHT nomme TYPE III tests ce qu’on a appelé TYPE II SS dans la  
Proc REG 
 
On retrouve bien les calculs faits à la main (cf.  F Stat =22.59  pour la F value de 
Type I SS et F Stat=11.69 pour la F value de Type II SS).  
 
La variabl
odèle el
e X4 a un comportement bizarre, lorsqu’elle est entrée en 3ème rang dans le 
le est limite au niveau significativité (pvalue =0.0490), alors que son apport 
orsqu’elle est entrée la dernière (p value =0.0002)  
La li i
tres pour tester un sous modèle  
 
 
pécification on entend la recherche des variables-régresseurs intervenant dans la 
 
On veut tester la nullité
ypothèse nulle  
H0 : 0qk =β==β L
Ha : il y a parmi les 
m
est très significatif l
 
a son entre X4 et X5 nous joue des tours ! 
2.4.4. Tester la nullité de r paramè
Ce type d'analyse est d'usage courant en Econométrie. L'idée est de mettre à
l'épreuve une approche théorique par une validation empirique. L'intérêt porte non 
sur l'estimation des paramètres mais sur la « spécification » du modèle. Par
s
détermination de la variable «  à expliquer » Y. 
 de r (indices k à q) paramètres parmi les p, c'est à dire 
l'h
 contre  
qk ββ L  des coefficients non égaux à 0) (not all qk ββ L  equal to    
e modèle sans les r variables est appelé le modèle restreint par opposition au 
modèle complet à p variables. 
 
Ici aussi on raisonne sur les réductions de SS error. 
On note : 
RRSS (Restricted Residual Sum of Squares) = Somme des carrés des résidus du 
modèle restreint 
URSS (Unrestricted Residual Sum of Squares)=Somme des carrés des résidus du 
modèle complet. 
0). 
 
L
© Revue MODULAD, 2006 - 272-               Numéro 35 
 
 
 
'hypothèse est testée en évaluant la statistique F dite partielle11  L
 
MSE
r/)URSSRRSS(
)1pn/(URSS
r/)URSSRRSS(F −=−−
−=  
 
La statistique de test F est sous H0 une valeur observée d'une variable F de Fisher-
Snedecor à r et (n-p-1) degrés de liberté. L'hypothèse nulle doit être rejetée au 
niveau  α lorsque : 
 
)1pn,r(FobservéF 1 −−≥ α−   
 
où F r n p1 1− − −α ( , )  représente le quantile d'ordre (1− α ) de la loi de Fisher-Snedecor 
ègle de décision 
à (r) et (n-p-1) degrés de liberté.  
 
R
 
Si  )1pn,r(FvalueF 1 −−≥ α−  
Alors  H0 : 0qk =β==β L  doit être rejetée au 
niveau α 
 
L'instruction TEST de la Proc REG réalise ces tests en fournissant la statistique de 
ificativité  p-value associé, noté 
Prob>F. 
Fisher-Snedecor F value et son niveau de sign
2.4.5. Exemple de test partiel avec PROC REG 
On veut tester si les 2 coefficients de X4 et X5 sont nuls. 
 
0:H 540 =β=β          instruction SAS   Ö test X4=0, X5=0; 
 
Programme SAS  
 
proc REG data=libreg.chenilles;  
      title "Test de l'Hypothèse nulle X4=0 et X5=0"; 
      model Log=X1 X2 X4 X5;  
test X4=0, X5=0; 
 
• Pour le modèle restreint (sans X4 et X5) on a : 
 
 
                                            
11 La statistique de test F ainsi calculée est appelée F partiel  quand elle ne porte que sur un sous-ensemble de 
paramètres, pour la distinguer de la statistique F, qui porte sur l'ensemble des paramètres du modèle complet. 
© Revue MODULAD, 2006 - 273-               Numéro 35 
 
 
 
Ä 28.76434 RRSS =  
 
• Pour le modèle complet : 
 
 
Ä 
  
 17.50338URSS =   avec  DF=(n-p-1)=28 
 
d'où
 
    
01.9
62512.0
63048.5
28/80338.17
2/)50338.1776434.28(
MSE
r/)URSS
)
==RRSS(r/)URSSRRSS( −== −−F
1pn/(URSS −−=
 
 
 
Sortie SAS pour le test partiel  
 
 
 
On trouve bien la valeur 9.01  ValueF =  avec un  niveau de significativité Prob >F de 
0.05, on rejette l'hypothèse 
0.0010. 
 
Conclusion  
Le niveau de significativité (0.0010) étant bien inférieur à 
nulle 0:H =β=β 540  
Il existe au moins un effet de X4 et/ou de X5 sachant X1 et X2 introduit dans le 
modèle. 
© Revue MODULAD, 2006 - 274-               Numéro 35 
 
 
2.5. Ce qu'il faut retenir des 'SS' 
 
Décomposition des SS : Sum of Squares 
 
 
=SS Total
SS error
SS model
 
 
 
Lorsqu'on introduit une nouvelle variable dans un modèle : 
 
SS model augmente  de la même quantité que 
 
SS error décroît 
 
 
Donc le coefficient de détermination R-square augmente toujours. 
 on n'améliore pas nécessairement la précision de l'estimation de Y. 
 
Cependant
n effet SS Error décroît mais 
1pn −−E
ErrorSSMSErrors2 ==  peut croître donc 
er la largeur de l'intervalle de confiance de Y estimé qui est proportionnel à 
SE.  
'observations (n), l'équation de régression passera exactement 
as SS Error vaut 0, et le coefficient de détermination R2 vaut 1. Ce n'est 
plus de la statistique mais de la résolution d'équations ! 
 
D’autre part les colinéarités entre les régresseurs rendent les résultats instables. En 
augmentant le nombre de régresseurs on augmente les risques de colinéarités. Le 
chapitre 4 traitera de ce problème. 
 
Modèles "parcimonieux" 
Par sagesse, les statisticiens parlent de modèles « parcimonieux », pour signifier 
qu'un modèle doit comporter un nombre limité de variables par rapport au nombre 
d'observations, si on veut que le modèle ait une portée prévisionnelle et/ou 
explicative. 
augment
M
 
A la limite si le nombre de variables p + 1 (le 1 correspond à la variable constante X0) 
est ég dal au nombre 
par tous les points du nuage, l'ajustement sera parfait.  
 
Dans ce c
© Revue MODULAD, 2006 - 275-               Numéro 35 
 
 
2.6. Les résidus 
En i  observé et Y estimé par le modèle est le 
résidu au point i: 
ii YˆYe −=
 un po nt d'observation i, l'écart entre Y
i  
 
Ces résidus ie  sont vus comme les erreurs observées des vraies erreurs inconnues 
i : 
 
ε
)Y(EY iii −=ε  
Nous avons vu que les suppositions faites sur les εi pour élaborer les tests 
statistiques se résument ainsi « les erreurs doivent être indépendantes et 
 selon une loi normale ». 
Si le modèle est approprié aux données, les résidus observés e  
 
identiquement distribuées
 
i doivent refléter les 
propriétés des vraies erreurs inconnues εi.
C'est donc pa er le 
modèle de régression postulé. 
 
Pour cela on effectuera différents graphiques des résidus en fonction de: 
 
• Y la variable réponse 
• Y estimé ( Yˆ ) 
• la variable temporelle, si l'analyse statistique porte sur des séries 
• etc. 
'autre part une information concernant l'inadéquation du modèle aux données 
 
r le biais de l'analyse des résidus que l'on cherchera à valid
• Xi les variables régresseurs 
chronologiques 
 
De même on étudiera la normalité des résidus, leur indépendance.  
En effet, les résidus contiennent d'une part un aléa d’espérance nulle et de variance 
σ2, et d
(c'est-à-dire l'écart entre le modèle postulé et le modèle correct inconnu). Ce que l'on 
veut c'est que l'importance de cette deuxième partie soit moindre que celle due à 
l'aléa. 
 
Pour cela on devra rechercher si dans les résidus il n'existe pas une structure 
organisée ou un contenu informationnel qui prouverait que le modèle postulé se 
ifférencie significativement du modèle correct. d
 
Tous les tests sont faits en supposant que le modèle postulé est le modèle correct, si 
donc l'analyse des résidus prouve l'inadéquation du modèle postulé, les tests ne sont 
lus valables, ou sont biaisés. p
 
Des orientations pour l'analyse critique des résidus seront données dans le chapitre 
4. 
 
© Revue MODULAD, 2006 - 276-               Numéro 35 
 
 
Co
Au cours des chapitres 1 et 2 nous avons présenté la majeure partie des concepts 
s 
t été limitées à l'essentiel. Le lecteur se reportera à la bibliographie 
pour avoir plus de précision et de rigueur mathématique. L’ouvrage de TOMASSONE & 
l., en particulier, est vivement conseillé. 
 
difficultés de la régression linéaire lorsqu’on étudie des données réelles, qui 
 prennent un malin plaisir » à ne pas se comporter comme la théorie le suppose. 
 
our aider aux diagnostics, de nombreuses options sont disponibles dans la 
nclusion 
théoriques nécessaires à la compréhension d'un modèle de régression. Le
démonstrations on
a
 
Dans le chapitre 3, nous analyserons à partir d'exemples de la littérature, les
«
P
procédure REG, ce que nous verrons au chapitre 4. 
© Revue MODULAD, 2006 - 277-               Numéro 35 
 
 
3. Quand les résultats d'une régression ne sont pas forcément 
pertinents 
ans ce chapitre nous montrons sur queD lques exemples les difficultés rencontrées 
4.  
La majorité des résultats d’une régression sont présentés avec les sorties de 
SAS/INSIGHT, pour montrer l’apport de l’interactivité, et l’importance des graphiques  
dans la compréhension des analyses. 
3.1. Exemples en régression simple 
3.1.1. Une même valeur pour des situations différentes 
Cet exemple est deTOMASSONE & al. (1986). Dès 1973 ANSCOMBE, neveu et 
collaborateur de J.W TUKEY (1977) avait proposé un exemple similaire dans «Graphs 
in Statistical Analysis ». Soient les 5 couples de 16 observations  
(X,Ya),(X,Yb),(X,Yc),(X,Yd),(Xe,Ye) sur lesquels on effectue 5 régressions linéaires 
simples. 
 
OBS        X      Ya       Yb       Yc       Yd       Xe        Ye   
dans l’application de la régression linéaire simple et la régression linéaire multiple sur 
données réelles ou simulées, lorsque les suppositions ne sont pas vérifiées. Nous 
présentons quelques aides très utiles. Ce n’est qu’un petit survol de la littérature sur 
 sujet de la robustesse qui nécessite à lui seul plusieurs ouvrages.  le
 
Ce chapitre a pour objectif de vous sensibiliser à l’importance des diagnostics 
proposés dans Proc REG, qui seront vus au chapitre 
   1 7  5,535 0,113 7,399 3,864 13,715 5,654
   2 8  9,942 3,770 8,546 4,942 13,715 7,072
   3 9  4,249 7,426 8,468 7,504 13,715 8,491
   4 10  8,656 8,792 9,616 8,581 13,715 9,909
   5 12  10,737 12,688 10,685 12,221 13,715 9,909
   6 13  15,144 12,889 10,607 8,842 13,715 9,909
   7 14  13,939 14,253 10,529 9,919 13,715 11,327
   8 14  9,450 16,545 11,754 15,860 13,715 11,327
   9 15  7,124 15,620 11,676 13,967 13,715 12,746
  10 17  13,693 17,206 12,745 19,092 13,715 12,746
  11 18  18,100 16,281 13,893 17,198 13,715 12,746
  12 19  11,285 17,647 12,590 12,334 13,715 14,164
  13 19  21,365 14,211 15,040 19,761 13,715 15,582
  14 20  15,692 15,577 13,737 16,382 13,715 15,582
  15 21  18,977 14,652 14,884 18,945 13,715 17,001
  16 23  17,690 13,947 29,431 12,187 33,281 27,435
 
© Revue MODULAD, 2006 - 278-               Numéro 35 
 
 
Les estimations des Y sont les suivantes : 
 
OBS Ya_est Yb_est Yc_est Yd_est Ye_est 
1 6,18 6,18 6,18 6,18 11,61
2 6,99 6,99 6,99 6,99 11,61
3 7,80 7,80 7,80 7,80 11,61
4 8,61 8,61 8,61 8,61 11,61
5 10,22 10,23 10,22 10,22 11,61
6 11,03 11,03 11,03 11,03 11,61
7 11,84 11,84 11,84 11,84 11,61
8 11,84 11,84 11,84 11,84 11,61
9 12,65 12,65 12,65 12,65 11,61
10 14,27 14,27 14,27 14,27 11,61
11 15,07 15,08 15,08 15,08 11,61
12 15,88 15,89 15,89 15,89 11,61
13 15,88 15,89 15,89 15,89 11,61
14 16,69 16,69 16,69 16,69 11,61
15 17,50 17,50 17,50 17,50 11,61
16 19,12 19,12 19,12 19,12 27,43
 
Les ajustements par les 5 droites de régressions sont donnés figure 3.1 ; ils sont 
identiques, mêmes estimations, mêmes statistiques pour R²=0.617, mêmes 
coefficients b =0.520, b1=0.809, mêmes erreurs-types sur les coefficients, et 
 1er graphique on peut voir que le modèle semble bien adapté. 
le 2ième  graphique le modèle linéaire est inadapté, un modèle quadratique de 
la fo = ait
• Sur  graph e un e p e te de régression 
vers le haut.  
• Sur le 4ième grap ue l n s s  un omène 
d'hétéroscédasticité (va h o s
• Sur  grap e l leu Xe est 
particulièrement mauvais. Un seul poin  d ue se 
pass  entre X 715 n e ?
 
Un simp agramm rtési es e 
vérifier s  suppos  de i et er un 
diagnos
 
0
pourtant les situations sont bien différentes. 
 
Analyse des résultats 
 
• Sur le
• Sur 
rme Y 2Xβ  ser  préférable.  
le 3ième iqu  point st sus ect et ntraîne la droi
hiq a varia ce de  erreur  varie. Il y a  phén
riance d
 plan 
e Y sac
xpérim
ant X n
ental d
n con
fini pa
tante). 
r les vale 5ième hiqu e e é
e déte
rs de 
t extrêm rmine la roite. Q
e-t-il =13.  et X=34.281 ? La liaiso  est-elle linéair  
le di
i les
e ca
itions
en (Sca
 la régre
tter plo
ssion l
t) perme
néaire so
t dans c
nt resp
hacun d
ectées, 
 5 cas d
 de port
tic. 
© Revue MODULAD, 2006 - 279-               Numéro 35 
 
 
 
 
Figure 3.1 : 5 droites de régression 
3.1.2. Pondérations et régression linéaire par morceaux 
Cet exemple inspiré de J.P. BENZECRI & F.BENZECRI (1989), « Calculs de corrélation 
entre variables et juxtaposition de tableaux », est totalement artificiel. 
© Revue MODULAD, 2006 - 280-               Numéro 35 
 
 
L'objectif de cet exemple est double : montrer d'une part l'effet d'une pondération des
observations sur les résultats d'une analyse de régression et d'autre part de 
iliser par des graphiques, à l'usage abusif de la régression lorsque l'hypothès
de linéarité sur tout l'intervalle n'est pas valide. 
Tableau des données 
101 observations (variables X et Y) sont générées par programme de la manière 
suivante : X varie de -50 à +50 avec un pas de 1 et à chaque pas Y est calculé selon 
les formules linéaires suivantes : 
20XY alors 11X Si
X-Y alors 11<X10-Si
20+X=Y alors 10-X Si
−=≥
=≤
 
sensib e 
 
 
<
 
X est la variable régresseur, Y est la variable réponse. X et Y sont donc
rigoureusement liées par une fonction linéaire par morceaux. 
Les 3 parties ont des pentes (paramètre 1
 
 
β ) respectives de +1 pour les 40 premières
observations, -1 pour les observations 41 à 61, et +1 pour les observations 62 à 101. 
On effectue une première régression sans pondération, sur toutes les observations 
(figure 3.2), puis deux régressions pondérées, en pondérant par 100 les observations
partie centrale, les autres observations ayant une pondération de 1, puis une 
 régression avec une pondération par 1000. 
On utilise l'instruction "Weight "de la Proc Reg. 
Programme SAS de génération des observations et analyse de régression 
L’appel de Proc REG se fait par une macro. 
 
 
 
de la 
3ième
 
 
data ligne ; 
    do x=-50 to 50; 
    p1=1 ;  p100=1; pmil=1; 
    if x <-10 then  y=x+20; 
              else if x < 11 then do; y=-x ; 
                                  p100=100; pmil =1000; end; 
                             else y=x-20; 
    output;     
end; 
%macro reg(poids=); 
proc reg data=ligne; 
     model y=x ; 
     %if &poids ^=  %then weight &poids ; %str(;); 
     title " Avec ponderation &poids"; 
%mend; 
%reg(poids=p1) 
%reg(poids=p100) 
%reg(poids=p1000) 
quit; 
 
© Revue MODULAD, 2006 - 281-               Numéro 35 
 
 
 
ans aléa a) Observations (X,Y) générées s b) Régression sans pondération 
 
 Régression avec pondération de 100 c) d) Régression avec pondération de 1000 
 
Figure 3.2  Droite de régression selon les pondérations utilisées (1, 100 , 1000) 
tie centrale on obtient des F value, des 
termination, des estimations de 1
 
Analyse des résultats  
En pondérant de 3 façons différentes la par
β  droite de régression- totalement 
urs significatif (cf. Tableau 3.1) 
bleau 3.1 
n de 1β  T Student 
coefficients de dé
différents et cependant toujo
 
Ta
Pondération F value P value R2 estimatio
s
p
ans 261.433 <0.0001 0.7253 0.0255 16.169 ondération 
p -3.427 ar 100 11.740 <0.0009 0.1060 -0.2512 
par 1000 <0.0001 0.7985 -0.8580 -19.744 389.810 
 
En fonction de la pondération, la droite de régression « tourne » jusqu'à s'adapter à 
trale, comme on le voit dans les figures 3.2 (b, c, d). 
 pas de même 
e 3 études séparées sur les 3 intervalles où l'hypothèse de 
 exacte, on obtient des coefficients de détermination  R²=1  
es droites de régression totalement adaptées aux données 
r=0). 
L’exemple met en lumière les questions que l'on doit se poser avant d'effectuer une 
régression : l’hypothèse de linéarité est elle plausible sur tout l’intervalle ?. 
la pente de la partie cen
Si la modélisation devient correcte pour la partie centrale, il n'en va
pour le
 
s deux autres parties. 
Si, par contre on réalis
linéarité entre X et Y est
ion parfaite) et d(corrélat
(SS Erro
 
© Revue MODULAD, 2006 - 282-               Numéro 35 
 
 
Théorie de la régression pondérée 
 
z L'instruction Weight de Proc REG 
L'instruction Weight de Proc REG, minimise la somme des carrés résiduels 
pondérés : 
2
ii )Yˆ−
i
i Y(w∑  
iée dans l'instruction Weight,  iw  : valeur de la variable spécif
Y  : valeur observée de la variable à expliquer,  
Les équations normales utilisées sont dans ce cas : 
 
i
Yˆ  : valeur prédite pour l'observation i.  i
)WYX() 1 ′−WXX( ′=β  
 
e des erreurs n'est pas vérifiée 
rature statistique propose d'utiliser la 
 
W : matrice diagonale constituée des poids. 
z Quand utiliser l'instruction Weight ? 
Lorsque l'hypothèse de variance constant
(hétéroscédasticité des erreurs), la litté
omm  
éoriques iσ  . 
 
régression pondérée en prenant c
2
e pondération l'inverse des variances
th
2i
1w =
iσ  
onclusion 
 
p n nées  être rn  
ulier il fau lab ler s erva t homogèn -à-
ntu es port différ vent être d s. 
proche p se ées yse ire des don ut 
néce n  avec profit des marqueurs de couleurs 
AS/INSIGHT et sa boîte à outils Tools) pour repérer si une variable de groupe ne 
OUSSEEUW  
nsformer les données, pour tenter de linéariser la liaison. 
En général les variances théoriques des erreurs ne sont pas connues, elles sont 
estimées. 
 
C
L’artifice de ondératio  des don doit utilisé avec d eisc ement. En
partic
dire si d’éve
t au préa
els group
le contrô
 aux com
i les obs
ements 
tions son
ents peu
es, c'est
ifférencié
Une ap ar analy  de donn ou anal explorato nées pe
s’avérer ssaire. O  utilisera
(S
fait pas apparaître des mélanges de populations.  
 
Il existe des méthodes robustes pour pondérer les observations mais elles sortent 
du cadre de cet ouvrage. La lecture de l’ouvrage de R et al. (2003) est 
rtement recommandée. fo
3.1.3. Transformation des données 
Lorsque sur un graphique, la liaison entre X et Y n’apparaît pas linéaire, on peut 
ssayer de trae
 
 
© Revue MODULAD, 2006 - 283-               Numéro 35 
 
 
Exemple : Liaison entre Produit Nationa
La table SAS Paysniv3 porte sur 173 p
l Brut et taux d’urbanisation  
ays des 5 continents (figure 3.3). 
 
 
 
ur la Figure 3.4 a, sont représentées la variable PNB, Produit national brut en 
roite de régression, pour 173 pays.  
Bien que les résultats statistiques soient significatifs (R2=0.4358, F=122.06, p value 
< alue <0.0001) cette analyse n’est pas 
 elle augmente en fonction de URBA. Il y 
 un effet d’entonnoir caractéristique téroscédasticité des erreurs. 
 
 
Figure 3.3 Effectifs par Continent 
S
fonction du taux d’urbanisation URBA, et la d
0.0001, T de Student = 11,05, p v
satisfaisante.  
La supposition de liaison linéaire n’est pas vérifiée, confirmé par le graphique des 
résidus (figure 3.3 b).  
 
a variance des erreurs n’est pas constante,L
a de l’hé
a) 
UR
régression linéaire PNB en fonction de 
BA  
b) graphique des résidus R_PNB en 
fonction de URBA 
 
Figure 3.4 
 
Les couleurs des points observations correspondent aux couleurs des continents de 
la Figure 3.3. 
On pe  (point rouge) se différencie totalement 
de l’Europe (point bleu), on a à faire à des on. Cependant pour 
our dilater les valeurs faibles et en même temps compresser les valeurs élevées du 
NB on transforme la variable en son logarithme.  
ut noter grâce aux couleurs que l’Afrique
 mélanges de populati
notre démonstration sur les transformations on passera sous silence cette remarque. 
 
P
P
© Revue MODULAD, 2006 - 284-               Numéro 35 
 
 
En SAS/INSIGHT il suffit de cliquer sur le nom de la variable PNB sur le graphique et 
e la variable 
NB en son logarithme  Log (L_PNB). Tous les affichages sont modifiés (figures 3.5 
a et b).  
 
de demander par le menu Ä Edit # Variables # Log, la transformation d
P
b) Après transformation par le logaritha) Avant transformation  
 
me
 
Figure 3.5  Liaison entre le taux d’urbanisation et le Produit National Brut 
 
La transformation a eu un double effet (figure 3.5). D’une part elle a symétrisé la 
2=0.6468, 
 
distribution du PNB, visible sur les Box-plots, et d’autre part elle a linéarisé la liaison 
entre Log(PNB) et URBA 
es indicateurs statistiques de la régression sont nettement améliorés. (RL
F=289.39, pvalue<0.0001, T de Student = 34,05, pvalue <0.0001). 
a) régression Log(PNB) fonction de URBA b) Graphique des résidus fonction de 
URBA 
 
Figure 3.6 
 
Les résidus (figure 3.6 b) se trouvent maintenant bien repartis dans la bande (-2, +2), 
à l’exception de 2 pays atypiques, Oman et Equatorial Guinea, sur lesquels il faut 
s’interroger. 
 
© Revue MODULAD, 2006 - 285-               Numéro 35 
 
 
Echelle de Tukey – Ladder of Power 
 
Les transformations de variables occupent une place importante dans la littérature. 
On a vu précedemment, que la transformation Log du PNB, permettait de linéariser 
 liaison entre Y et X. Pour choisir une transformation appropriée, J.W. TUKEY (1977) 
 
4 4Y  
la
a proposé ce qu’on appelle maintenant l’échelle de transformation de TUKEY12. 
3 3Y  
2 2Y  
1 1Y  
1/2 Y  
0 Y(Log  )
-1/2 Y/1−  
-1 Y/1−  
-2 2Y/1−  
 
Echelle de Tukey 
l’échelle, c'est-à-dire transform
descendre l’échelle, en prenant 
 
Selon la forme des courbes définies par les points (Xi,Yi) on pourra soit monter 
er X ou Y en ses puissances ( 2Y , 3Y  etc.) soit 
Y , )Y(Log , Y/1− , Y/1−  etc. 
J. Vanpoucke et E. Horber 13
un arc, et la flèche indique selon son 
helle. 
onnées formaient une courbe d’allure n°3, 
 
Astuce de lecture proposée par 
 
La forme des courbes du tableau 3.2 dessine 
orientation s’il faut monter ou descendre l’éc
 
Ainsi pour PNB en fonction de URBA, les d
o  la 
distribution de URBA est symétrique (voir fig  a), c’est plutôt sur PNB qu’il faut 
agir (distribution non symétrique, voir le Box plot de PNB). 
 
ette procédure raisonnée permet d’éviter d’agir complètement par « essais-
                                         
il faut donc soit monter l’échelle en X, s it descendre l’échelle en Y. Comme
ure 3.5
C
erreurs », cependant pour trouver le bon choix on n’évite pas de faire quelques 
essais, grandement facilités par l’interactivité de SAS/INSIGHT.  
 
   
12 TUKEY utilise le mot « re-expression » et non le mot « transformation » d’une variable. 
13 JACQUES VANPOUCKE de l’Université Sabatier de Toulouse et EUGENE HORBER de l’Université de Genève, sont 
les fondateurs de l’Association MIRAGE, Mouvement International pour le développement de la recherche en 
Analyse Graphique et Exploratoire, http://www.unige.ch/ses/sococ/mirage/assoc.htm 
brut 
Monter l’échelle 
Descendre l’échelle 
© Revue MODULAD, 2006 - 286-               Numéro 35 
 
 
Tableau 3.2  Transformations appropriées selon la forme des courbes 
 
Forme de Courbes Description de l’action 
Transformation 
sur X 
Transformation 
sur Y 
 
ou 
Monter l’échelle  
en Y 
Descendre 
l’échelle en X X , )X(Log , 
X/1−  etc. 
2Y , 3Y  etc. 
 
Descendre 
ou 
Descendre 
l’échelle en Y 
l’échelle en X X , )X(Log , 
X/1−  etc. 
Y , )Y(Log , 
Y/1−  etc. 
 
onter l’échel
en X 
ou 
Descendre 
2X , 3X  etc. 
M le  
l’échelle en Y 
Y , )Y(Log , 
Y/1−  etc. 
 
Monter l’échelle  
en X 
ou  
nter l’éch
en Y 
2X , 3X  etc. 2Y , 3Y  etc. 
Mo elle  
 
Pour vous familiariser avec les ller voir cet applet sur internet 
http://noppa5.pc.helsinki.fi/opetus/sd/sdt0.html
 transformations a
. Développé par JUHA PURANEN de 
Université de Helsinski, cet applet montre l’
olynomiale locale avec la flexibilité 
nêtre. Chaque point du 
era lissée. Pour la 
nction de poids, on utilise généralement la fonction tri-cube. 
l’ effet de différentes transformations sur la 
liaison entre 2 variables, Y= Distance de freinage et X=Vitesse du véhicule, dont tout 
conducteur sait que la liaison n’est pas linéaire. 
Il montre également la technique de lissage de courbes par LOWESS. 
3.1.4. Méthode non paramètrique du LOWESS  
La méthode non paramétrique du LOWESS - Locally WEighted Smoothing Scatter- 
de Cleveland (1979, 1993, 1994) permet de lisser une courbe. Cette technique 
ombine une technique de régression linéaire ou pc
de la régression non linéaire. Le lissage obtenu permet à l’œil de repérer des points 
atypiques, de voir d’éventuelles structures, de détecter des non linéarités etc.  
Le principe repose sur des régressions locales définies sur des fenêtres glissantes. 
Chaque point observation est estimé, par une droite éventuellement un polynome, à 
artir des points de son voisinage, situés dans une fep
voisinage est pondéré en fonction de sa distance au point estimé.  
Les paramètres sur lesquels on peut agir sont la largeur de la fenêtre (Bandwith) et la 
fonction de pondération des points. Le principe est analogue à celui des moyennes 
obiles, plus la largeur de la fenêtre est grande plus la série sm
fo
 
© Revue MODULAD, 2006 - 287-               Numéro 35 
 
 
1xpour)x1()x(W 33 <−=
1xr >=pou0)x(W =  
et d tte technique. L’exemple14 porte sur les 
températures quotidienn e Me e 
 
’utiliser ce
es maximum d lbourne de janvier 1981 à décembr
SAS/INSIGHT perm
1990 (Source : Australian Bureau of Meteorology ,3650 observations). 
 
Dans le menu Fit de la régression, on demande une régression simple de la variable 
 en Y en fonction de la variable Date en X. Lorsque l’analyse de 
régression est affichée, on choisit le menu Ä  
 
Température
Curves # Loess
 
 
Figure 3.6 Technique du LOWESS appliquée à des données de températures 
 
La droite de régression est strictement horizontale avec une tempéra
de 21°04 sur les 10 années (figure 3.6). 
ture moyenne 
 
 
 
La technique du LOWESS (parfois dénommée LOESS) permet le lissage de la série. 
Elle nécessite beaucoup de calculs, ce qui ne pose plus de problèmes avec les 
ordinateurs actuels si la technique est bien programmée. C’est une des techniques 
                                           
modernes les plus attractives puisqu’elle ne nécessite pas de préciser la forme d’un 
modèle, elle laisse « parler les données » Cette technique est très utile dans la 
phase exploratoire des données mais elle a son revers, elle ne fournit pas de 
fonction analytique comme la régression linéaire. 
 
 
14 Les données proviennent de la banque de données de Rob  J ; Hyndman sur des séries temporelles  
http://www-personal.buseco.monash.edu.au/~hyndman/TSDL/ 
© Revue MODULAD, 2006 - 288-               Numéro 35 
 
 
Tableau 3.3 
 
 
En cliquant sur le curseur Alpha (paramètre du LOWESS lié à la largeur de bande - 
bandwith) on peut agir sur la largeur de la fenêtre et voir l’effet sur le filtrage. Avec un 
coefficient Alpha de 0.005, on fait apparaître un lissage moins régulier. 
 
 
 
Il existe aussi dans SAS une procédure LOESS dans le module SAS/ETS. 
3.2.1. 
Cet exem que les 
gresseurs sont corrélés. Les données sont issues du cours de Georges Monette de 
 
Figure 3.7 après modification du paràmètre de filtarge Alpha 
 
Pour connaître la technique du LOWESS programmée dans SAS, il suffit de cliquer
sur un mot clé (par exemple Alpha –voir Tableau 3.3) et de demander l’aide en ligne 
par le menu  
Ä Help # Help on Selection.  
 
3.2. Exemples en régression multiple 
Y « expliquée » par la corrélation entre deux régresseurs 
ple, montre l’influence sur le coefficient de détermination lors
ré
York University. 
 
Data HWH; 
input Weight Height Health; 
cards; 
68 94 120 
137 114 60 
94 104 123 
121 107 94 
100 118 104 
93 91 117 
76 123 139 
102 73 100 
122 112 91 
© Revue MODULAD, 2006 - 289-               Numéro 35 
 
 
89 78 91 
69 61 103 
123 150 131 
33 60 128 
207 193 107 
135 153 141 
; 
proc reg ; 
 ModHW: model health=weight; 
 ModHH: model health=Height; 
 ModHWH: model health=weight Height;  
run ; 
 
• Pour le  premier modèle, régression simple de HEALTH en fonction de WEIGHT, 
le coefficient de détermination vaut 0.0738. Aucune liaison entre santé et poids. 
• Pour le  deuxième modèle, régression simple de HEALTH en fonction de 
HEIGHT, le coefficient de détermination vaut 0.0367. Aucune liaison entre santé 
et taille. 
• Pour le  troisième modèle du tableau 3.4, donnant les résultats de la régression 
multiple de HEALT
déterminati
H en fonction de WEIGHT et HEIGHT, le coefficient de 
on vaut 0.6551. La statistique F et les T de student sont tous 
ssion de Health en fonction de WEIGHT et HEIGHT 
significatifs. Si on s’arrête à ces seules indications le modèle explique 65 % de la 
variation de Health, voir le tableau 3.4. 
 
Tableau 3.4  Régre
 
 
xplication de la santé par le Poids et le Taille est due à la corrélation 
est visible sur la matrice de corrélation et sur 
 
Cette fausse e
entre les régresseurs (0.8357). Ce qui 
 de scatter plot. la matrice
 
© Revue MODULAD, 2006 - 290-               Numéro 35 
 
 
Matrice de corrélation et Scatter Plot 
 
 
 
 
 
3.2.2. Instabilité des coefficients de la régression, en cas de 
multicolinéarité 
E
C
e
ré
 
  OBS URBA CCR_CAL 
xemple sur données réelles  
et exemple est de D. LADIRAY 15. On dispose de 44 observations et on cherche à 
xpliquer le taux d'urbanisation, variable URBA, en fonction de 10 variables 
gresseurs, POP87 à ESPER. 
 
Tableau 3.5  Tableau des données 
  POP87 NAT MORT ACCR DOUB FERTI MORTI AGE15 AGE65 ESPER 
   1   81    0.4  32   5   2.8   25  4.6   32.0   41     2    67     2.7 
   2   53    0.7  20   9   1.1   63  2.5   12.0   25    11    74     1.1 
   3   79    0.6  47   8   4.0   18  7.4   59.0   50     3    64     3.9 
   4   68   17.0  46  13   3.3   21  7.2   80.0   49     4    62     3.3 
   5   90    4.4  23   7   1.7   41  3.1   12.3   33     9    75     1.6 
   6   60    3.7  45   8   3.7   19  7.4   54.0   51     3    67     3.7 
   7   80    1.9  34   3   3.2   22  4.4   19.0   40     1    72     3.1 
   8   80    3.3  30   8   2.2   32  3.8   52.0   38     5    65     2.2 
   9    9    1.3  47  14   3.3   21  7.1  117.0   44     3    52     3.3 
  10   86    0.3  34   4   3.0   23  5.6   42.0   34     2    69     3.0 
  11   72   14.8  39   7   3.1   22  6.9   79.0   37     2    63     3.2 
  12   49   11.3  47   9   3.8   18  7.2   59.0   49     4    63     3.8 
  13   46   51.4  30   9   2.1   33  4.0   92.0   36     4    62     2.1 
  14   81    1.4  30   4   2.6   27  5.9   38.0   30     1    68     2.6 
  15   15    6.5  53  19   3.4   20  7.8  137.0   49     3    47     3.4 
  16   40    2.4  47  17   3.0   23  7.3  135.0   48     3    48     3.0 
  17   16   14.2  48  22   2.6   27  7.6  182.0   46     4    39     2.6 
  18   13  107.1  44  17   2.7   26  6.2  140.0   44     4    50     2.7 
  19    5    1.5  38  18   2.0   34  5.5  142.0   40     3    46     2.0 
  20   25  800.3  33  12   2.1   33  4.3  101.0   38     4    55     2.1 
  21   51   50.4  45  13   3.2   21  6.3  113.0   44     3    57     3.2 
  22   26    0.2  48  10   3.8   18  7.1   68.0   45     2    51     3.8 
  23    7   17.8  42  17   2.5   28  6.1  112.0   41     3    52     2.5 
  24   28  104.6  44  15   2.9   24  6.6  125.0   45     4    50     2.9 
  25   22   16.3  25   7   1.8   38  3.7   29.8   35     4    70     1.8 
  26   64    0.2  30   4   2.6   26  3.6   12.0   38     3    62     2.6 
                                            
15 Ladiray D.(1990) Autopsie d'un résultat: L'exemple des procédures Forecast, X11, Cluster. Club SAS 1990 
© Revue MODULAD, 2006 - 291-               Numéro 35 
 
 
  OBS URBA  POP87 NA E65 ESPER CCR_CAL T MORT ACCR DOUB FERTI MORTI AGE15 AG
  27   24   38.8  34  13   2.1   33  4.4  103.0   39     4    53     2.1 
  28   12    0.7  48  23   2.5   28  5.8  183.0   35     3    40     2.5 
  29   22  174.9  31  10   2.1   33  4.2   88.0   40     3    58     2.1 
  30   11    6.5  39  18   2.1   33  4.7  160.0   35     3    43     2.1 
  31   16    3.8  41  16   2.5   28  5.8  122.0   43     3    50     2.5 
  32   32   16.1  31   7   2.4   28  3.9   30.0   39     4    67     2.4 
  33   40   61.5  35   7   2.8   25  4.7   50.0   41     3    65     2.8 
  34  100    2.6  17   5   1.1   61  1.6    9.3   24     5    71     1.2 
  35   17   53.6  29   8   2.1   33  3.5   57.0   36     3    63     2.1 
  36   19   62.2  34   8   2.6   27  4.5   55.0   40     4    63     2.6 
  37   32 1062.0  21   8   1.3   53  2.4   61.0   28     5    66     1.3 
  38   92    5.6  14   5   0.9   77  1.6    7.5   24     7    75     0.9 
  39   76  122.2  12   6   0.6  124  1.8    5.5   22    10    77     0.6 
  40   64   21.4  30   5   2.5   28  4.0   33.0   39     4    65     2.5 
  41   65   42.1  20   6   1.4   51  2.1   30.0   31     4    67     1.4 
  42   97    0.4  23   6   1.7   41  3.7   12.0   34     8    68     1.7 
  43   51    2.0  37  11   2.6   26  5.1   53.0   42     3    62     2.6 
  44   67   19.6  17   5   1.2   59  1.8    8.9   30     5    73     1.2 
 
Dans le tableau 3.5, deux valeurs de la variable NAT (taux de natalité) pour OBS=11 
nt et après modifications donnent les résultats 
Tableau 3.6 
 
Résultat 1 (vale
Avant 
t 2  (valeur 40) 
Après 
et OBS=30 sont légèrement modifiées (39 est remplacé par 40 ) 
Les régressions effectuées ava
suivants pour les coefficients de régression : 
 
ur 39)  Résulta
URBA = URBA= 
25.541    20.689    
-0.026   POP87 -0.026   POP87 
  
-6.661   NAT -4.047   NAT 
+2.681   MORT -0.005   MORT 
+64.506 +39.832   ACCR   ACCR 
  
+0.019   DOUB +0.015   DOUB 
+7.834   FERTI +7.307   FERTI 
+0.101   MORTI 
-1.132   AGE15 -1.157   AGE15 
+0.128   MORTI 
+2.709   AGE65 +2.848   AGE65 
+0.910   ESPER +0.969   ESPER 
 
 
Les résultats "Avant" et "Après"  (tableau 3.6) sont particulièrement instables pour les 
 estimations des coefficients des 3 variables, NAT (taux de natalité), MORT (taux de
mortalité)  et ACCR (taux d'accroissement de la population). 
 
© Revue MODULAD, 2006 - 292-               Numéro 35 
 
 
Explication 
Ces 3 variables ne sont pas indépendantes, elles sont liées entre elles par une 
ut 
 la 
le. 
ts 
es 
00 
relation quasi-linéaire ACCR= (NAT-MORT)/10. Dans le tableau 3.5, on pe
comparer ACCR avec la variable ACCR_CAL, en dernière colonne, calculée avec
formule exacte. 
Lors de l'inversion de la matrice X'X, il y a une valeur propre qui est presque nul
Conséquence une légère perturbation des données entraîne de grands changemen
dans les estimations des paramètres. 
Exemple sur données avec modèle théorique connu et régresseurs corrélés 
Cet exemple est de T. Foucart (2007). Pour étudier l’effet des corrélations entre l
régresseurs sur les estimations des paramètres, T. Foucart a généré 1
observations d’un vrai modèle théorique :  
 
ε+β+β+β+β+β= XXXXY 443322110  
 
Les vraies valeurs des paramètres du modèle théorique sont : 
 
01=β     5.021 =β=β     5.043 −=β=β  
 
Les 4 régresseurs X1 à X4 suivent des lois normales centrées et réduites. 
L’erreur ε suit une loi normale ,0(N 2σ
On impose de plus des la matrice des corrélations entre les 
régresseu
ableau 3.7 Corrélations imposées
 
1 X2 X3
) ,  
 contraintes sur 
rs.  
T  
 X X4
X1 1    
X2 0.5 1   
X3 0.5 0.5 1  
X4 -0.5 0.4 0.3 1 
 
Et on impose la valeur R2 du coefficient de détermination 5.0= .  
 
Les données générées RIDGE1 sont disponibles sur le si 6. 
 
Résultats avec SAS/INSIGHT   
 
• la mat
te de T. Foucart1
rice de corrélation  
•  
enu Ä Analyze # Mutivariate avec les 5 variables X1, X2, X3, X4, Y dans le rôle 
 
 
                                           
M
Y  
 
On la trouve dans le (tableau 3.8) ci-dessous. 
 
 
16 http://foucart.thierry.free.fr/StatPC/. 
 
© Revue MODULAD, 2006 - 293-               Numéro 35 
 
 
Tableau 3.8 Statistiques univariées et matrice de corrélation 
 
 
 les valeurs imposées 
• la matrice de scatter plot 
 
On vérifie sur le tableau 3.8 que la matrice de corrélation a bien
u Tableau 3.7. d
 
 
 
Menu Ä Analyze# Scatter Plot avec les 5 variables (X1, X2, X3, X4, Y) dans le rôle 
X et les mêmes dans le rôle Y 
 
X1
-2.9987
2.8081
X2
-2.9509
2.7650
2.6579
X3
-2.6484
2.
X4
-2.9459
0666
Y
-4.1021
3.4373
 
 
matrice de diagrammes de dispersion permet de repérer les liaisons entre les 
, avec un coefficient positif, et Y est lié 
• La régression linéaire
Figure 3.6  Matrice de diagrammes de dispersion 
 
a L
régresseurs et la variable Y. Y est lié à X1, X2
 X3, X4 avec un coeffcient négatif. à
 
 
 
Menu Ä Analyze#Fit  avec les 4 variables X1, X2, X3, X4, dans le rôle de X et Y 
ans le rôle de Y  d
© Revue MODULAD, 2006 - 294-               Numéro 35 
 
 
  
 
 
 
Avec la méthode des moindres carrés, le coefficient de détermination R2=0.4907 est 
bien calculé (le théorique vaut 0.50), par contre les coefficients sont très différents de 
ceux du modèle théorique. 
 
Les es ations MCO sont  respectivement : 1.6339, -0.1482, -1.0375, 0.4439 au lieu 
des vraies valeurs : 0.5, 0.5, -0.5, -0.5. Mêmes les signes ne sont pas respectés. 
Conclusion 
tim
 
suivantes : 
• 
•  
• Les varianc
 
 
e 
4 (§4.4.5). L’  régression bornée »17, 
montre que là encore on ne onnaître 
3.3. 
es différents exemples présentés dans ce chapitre montrent l'importance des 
correct, que les suppositions, a priori sur les 
ariables et sur les erreurs, sont vraies. Ces suppositions sont nécessaires pour 
 
Les conséquences des colinéarités entre les variables régresseurs sont les
Les coefficients de régression sont instables ; 
Leur signe peuvent changer (positif ³´ négatif) rendant les interprétations
fausses, ce qui a de graves conséquences lors de la recherche des effets 
d’une variable régresseur ; 
es des estimateurs sont élevées. 
La technique de la régression bornée (Ridge Regression) a été proposée dans les
années 1970, pour pallier ces inconvénients. On en trouvera un exemple au chapitr
article de T. FOUCART (2007) « Evaluation de la
peut systématiquement y recourir. Il faut bien c
les données et le domaine pour en faire bon usage.  
Conditions d'utilisation de la régression, les diagnostics 
L
analyses et diagnostics effectués avant et après les premiers traitements. 
 Pour réaliser les tests d’hypothèses de la régression on a supposé, en pure théorie, 
que le modèle linéaire postulé est 
v
                                            
17 Site http://foucart.thierry.free.fr/colreglin/Regression_bornee.pdf,  
 
© Revue MODULAD, 2006 - 295-               Numéro 35 
 
 
© Revue MODULAD, 2006 - 296-               Numéro 35 
 
 
 
 
•
• 
 
• les erreurs sont d’espérance nulle ce qu  
• 
• 
• 
 
 
orrect.  
. Ce qui ne signifie pas que les suppositions soient 
orrectes. Cela veut dire que sur la base des données que l'on a étudiée, on n'a 
Modèle Inadapté 
lement correct, ou s'il est inadapté. 
Les é  mesure et des erreurs de 
spé ic
On pe
param t inadapté à l’étude. 
 
n dehors de certaines visualisations il n'y a que le bon sens et la pré-
Certaines données atypiques peuvent fausser les résultats. Les visualisations 
graphiques permettent parfois de les identifier.  
 
Le livre de BELSLEY, KUH et WELSH (BKW) a popularisé une méthode rigoureuse de 
définir les tests comme on l’a vu au Chapitre 1, car on ne peut calculer les variances
que dans des cas gaussiens et sous certaines conditions. 
Suppositions sur les variables  
 Les observations Yi sont supposées indépendantes  
Les variables Xj sont non aléatoires. 
Suppositions sur les erreurs  
i est vérifié par construction si la
constante β0 existe dans le modèle. 
les erreurs sont de variance constante 
les erreurs suivent une distribution normale  
les erreurs sont indépendantes 
Les erreurs sont inconnues, elles sont approchées par les résidus, si le modèle est
c
 
Après examen des résidus, on peut conclure: les suppositions semblent ou ne 
semblent pas être violées
c
aucune raison de dire que les suppositions sont fausses. 
3.3.1. 
C'est par l'examen des résidus que l'on peut voir si le modèle postulé est 
vraisemblab
 r sidus contiennent à la fois des erreurs de
cif ation du modèle, comme des variables omises, ou des liaisons non linéaires. 
ut avoir des tests satisfaisants, de bonnes précisions sur les estimateurs des 
ètres, alors que le modèle es
E
connaissance du problème qui permettent de repérer l'inadéquation du modèle aux 
données. 
3.3.2. L’influence de certaines données, les données atypiques -Outliers-  
recherche des observations influentes. L’option INFLUENCE de Proc REG permet 
cette analyse.  
On peut alors être amené à retirer ces points atypiques des analyses, ou à procéder 
à des techniques « robustes » (voir ROUSSEEUW et al. (2003)). La procédure 
ROBUSTREG de SAS disponible en V9 reprend ces techniques. 
3.3.3. Corrélation et colinéarité entre les régresseurs 
a colinéarité est un  lot quotidien du statistiL gros problème, cien praticien lorsqu’il 
ipalement en sciences économiques et sociales. 
ateurs de détection de 
colin
es options TOL, VIF t COLLIN, COLLINOINT de Proc REG sont des aides aux 
Tous c
tech q e appel aux nombreuses options de 
Proc E dation d’une régression ». 
analyse des données réelles, princ
C’es ét galement le trio "BKW" qui a proposé des indic
éarités. 
eL
diagnostics de colinéarité. 
 
es compléments à la régression, représentations graphiques, indicateurs 
ni ues de BKW, etc., nécessitent de fair
R G, qui seront présentées au chapitre 4 « Vali
© Revue MODULAD, 2006 - 297-               Numéro 35 
 
 
4. Validation d’une régression 
Dans ce chapitre, on présente les différents éléments nécessaires à la validation 
u niveau des observations (détection des observations 
fluentes et atypiques) et au niveau des variables (colinéarités, choix d’un sous-
exemple que pour le chapitre 2 (§2.3.1), issu du livre de Tomassone et al. (1992). 
4.1. Introduction 
Un principe de base doit être appliqué : explorer les données par des graphiques 
et/ou des calculs numériques. 
 
Les calculs préalables des caractéristiques des variables Y et des Xj, ainsi que des 
histogrammes et des tracés Box-Plot de ces différentes variables permettent en 
effet de mettre en évidence des problèmes. Bien sûr le calcul des corrélations 
entre Y et les Xj est nécessaire.  
 
Il faut étudier les variables, et donc en particulier faire des graphiques, par 
exemple de Y contre les régresseurs Xj pour contrôler la linéarité des liaisons.  
Pour cela, on utilisera la procédure GPLOT, ou le menu « Scatter-Plot » de 
SAS/INSIGHT. 
Dans PROC REG, l’instruction PLOT permet de faire des graphiques des variables 
entrant dans la régression, mais aussi des variables créées comme les valeurs 
résiduelles et ajustées. 
 
De plus, une Analyse en Composantes Principales des régresseurs, avec Y en 
variable supplémentaire, peut aussi être utile pour visualiser comment Y se 
reconstruit à partir de l’ensemble des X. 
4.1.1. Modèle et notations 
Si on postule un modèle avec n observations (i) et p variables régresseurs (j) et 
une constante, on note : 
• Y réponse ou variable dépendante 
• X matrice des variables régresseurs 
• β coefficients de régression  
• ε erreurs. 
 
Le modèle linéaire s’écrit : iipp3i32i21i10i X...XXXY ε
d’une régression, c’est-à-dire la vérification des suppositions de base du modèle, 
l’étude de la robustesse a
in
ensemble de régresseurs). 
 
Les sorties de SAS-version 9  illustrant ce chapitre sont réalisés avec le même 
+β++β+β+β+β=  . 
 
D’où l’ajustement: 
© Revue MODULAD, 2006 - 298-               Numéro 35 
 
 
ipp2i21i10i Xb....XbXbbYˆ ++++=  et les résidus iii YˆYe −= . 
t des aléas, indépendants, d’espérance nulle, 
de variance constante, et de même loi  (cf. chapitre 1). 
 sur les erreurs ;  
 
Choix d'  de régresseurs. 
vecteur des résidus forme un échantillon tiré de n variables 
léatoires indépendantes  
composants du vecteur e des résidus, 
iii YˆYe −= , sont reliés par des relations ainsi que le montre la figure 4.1 :  
 
 
Suppositions sur les erreurs : εi son
Æon dit «  IID  avec loi normale N(0,σ²)». 
4.1.2. Problèmes à étudier 
érification des suppositionsV
 
Robustesse de la régression : détection des observations influentes, et de la 
colinéarité des régresseurs ;  
un sous-ensemble
4.2. Vérification des suppositions de base sur les erreurs 
Les suppositions sur les erreurs (inconnues) doivent être vérifiées à partir de leurs 
observations (les résidus). 
4.2.1. Espérance nulle 
Il faut vérifier que les résidus sont de moyenne nulle. Or les résidus construits par 
les moindres carrés sont centrés par construction, si la constante est dans le 
modèle (ce que l'on suppose ici). 
4.2.2. Indépendance 
Il faudrait vérifier que le 
a
 
On obtient Yˆ  par projection du vecteur Y sur le sous-espace engendré par les 
régresseurs : il en résulte que les n 
© Revue MODULAD, 2006 - 299-               Numéro 35 
 
 
 
Figure 4.1 : Projection de Y dans l’espace des régresseurs 
 
Dans la représentation géométrique dans l’espace Rn, le vecteur des n résidus est 
ur des résidus est alors situé dans un espace de 
dimension (n-(p+1)). 
L’indépendance n’a donc de sens que si n est grand par rapport à p. 
 
cessives (ei+1 - ei), ou séquence des 
signes des différences à la médiane (ei - Mediane).  
 
lors le test de Durbin-Watson permet de vérifier si le résidu en i est non-corrélé au 
 
iii Yˆ− ,  
situé dans le sous-espace orthogonal à celui des régresseurs ; celui-ci étant de 
dimension (p+1), le vecte
Remarque :  
De façon générale, pour tester l’indépendance, on met en œuvre des tests non 
paramétriques (qui ne sont proposés dans SAS) basés sur des séquences : 
séquence des signes des différences suc
Cas particulier où les observations sont apparentées (cas des chroniques) : 
A
résidu en (i+1) : on parle d’auto-corrélation d’ordre 1. Il est obtenu par l’option DW de
l’instruction MODEL de Proc REG. 
 
si le coefficient de Durbin-Watson à partir des résidus Ye =On calcule ain
( )2
i
2
i
i
i1i
e
ee
DW ∑
∑ −
=
+
 
 
 
En notant ⎟⎟⎠
⎞
⎜⎜⎝
⎛=ρ ∑
∑ +
2
i
i1i
e
e.e
, si les résidus forment un processus autorégressif d’ordre 
1, 
c'est-à-dire suivent le modèle ii1i e.e η+ρ=+ , alors DW vaut à peu près ( )ρ−12 ,  
© Revue MODULAD, 2006 - 300-               Numéro 35 
 
 
où ⎟⎟⎠
⎞
⎜⎜⎝
⎛ −≅ ∑
∑ +
2
i
i1i
e
e.e
1.2DW  . 
Liens entre les valeurs ρ et DW: 
ρ < 1  ⇒  DW compris entre 0 et 2 
ρ > -1 ⇒DW compris entre 2 et 4 
S’il n’y a pas d’auto-corrélation d’ordre 1 
 
 
 
Si 0 < 
Si 0 > 
 
⇔ρ proche de 0, donc DW proche de 2. 
Il existe des tables dites de Durbin-Watson permettant de tester l’absence d'
corrélation d'ordre 1 en fonction du niveau de confiance α, et de n (
d'observations) et  p (nombre de variables). On y lit deux valeurs d1 et d2: 
 
auto-
nombre 
Les causes de l'auto-corrélation sont une mauvaise spécification du modèle, ou 
ailler sur les 
ifférences premières en Y c'est-à-dire (Yi - Yi-1), soit d'appliquer la méthode de 
tt (voir les livres spécialisés en Econométrie). PROC AUTOREG, du 
tiquement cette statistique DW, 
ais interpréter  le test de Durbin-Watson sur les résidus n’a aucun sens si les 
données ne sont pas apparentées.  
 les différents régresseurs Xj, permettent de 
isualiser si les résidus sont répartis dans une bande de valeurs horizontale autour 
t 
 
l'absence d'une variable importante. Les remèdes sont soit de trav
d
Cochran-Orcu
module SAS/ETS, réalise des régressions où le problème de l’auto-corrélation des 
résidus est résolu. 
 
Remarque : Beaucoup de logiciels donnent systéma
m
4.2.3. Egalité des variances (homoscédasticité) 
Les graphiques des résidus contre
v
de 0, c’est à dire s’il y a homoscédasticité. Sinon on peut alors déte es
la variable responsable de l'hétéroscédasticité.  
cter quelle 
.
.
.
.
. ..
.. .
.
e
O Xj
Var(e) grandit
avec Xj..
.
.
. .
 
 
« typique » des résidus contre Xj  Figure 4.2 : Graphique 
révélant une hétéroscédasticité 
© Revue MODULAD, 2006 - 301-               Numéro 35 
 
 
 
ent être tracés par la procédure GPLOT si on a stocké les 
i être faits à l’intérieur de la procédure 
EG, à l’aide de l'instruction PLOT, avec «R. » comme nom de variable en 
rdonnée car le résidu est stocké en interne dans la variable ayant le nom R. 
des résidus (dénommé R_Y) contre X est tracé 
g à un régresseur ; sinon c’est le tracé de R_Y 
) qui est tracé par défaut. Ces deux 
ans la table SAS active. Il est possible de 
aliser les autres graphiques à l’aide de la variable R_Y. 
’instruction MODEL de Proc REG possède une option SPEC pour tester s'il y a un 
à 
t 
suite on partage le vecteur des résidus triés en 2 paquets 
Quelques remèdes en cas d'hétéroscédasticité : 
 
− transformer Y ou Xj par une fonction racine carrée, ou Log, ou carré, etc. 
prenant comme poids 
Ces graphiques peuv
résidus dans une table, mais peuvent auss
R
o
Dans SAS/INSIGHT, un graphique 
i le modèle est une ré ression s
contre l’estimation Yˆ  (dénommée P_Y
variables sont automatiquement créées d
ré
 
L
problème d'hétéroscédasticité : l'hypothèse nulle « homoscédasticité » est testée 
l'aide d'une statistique suivant une loi du Chi2 (cf. White H., (1980)). Le test es
global, et donc en cas de rejet de H0, on ne sait pas quelle est la variable 
responsable de l'hétéroscédasticité. 
 
D'autres tests, comme ceux de Goldfeldt et Quandt, ou de Breush et Pagan (voir les 
publications spécialisées en Econométrie, par exemple Green (2005)), permettent de 
mettre en évidence l'hétéroscédasticité dûe aux  différentes variables. Mais ils sont 
assez lourds à mettre en œuvre, et ne sont pas faits par des procédures SAS. 
 
Une méthode plus simple peut permettre d'avoir une idée préalable sur l'existence 
d'un problème. Celle-ci s’apparente au test de Chow(1960) pour une série 
chronologique, où on teste l’égalité des variances des résidus de 2 sous périodes 
de la chronique. 
Ici, on trie les résidus selon les valeurs croissantes de la variable Xj suspecte (par 
PROC SORT), en
(premiers, derniers) dont on calcule les variances. Puis on teste l'hypothèse nulle 
d'égalité de ces 2 variances c'est à dire la possibilité d'homoscédasticité, à l'aide 
de la procédure TTEST de SAS. 
 
pour « aplatir » les variances : l’échelle de Tukey donnée au chapitre 3 
(§3.1.3), peut aider au choix de la transformation ; 
− mettre en œuvre une régression pondérée avec l’instruction WEIGHT, en 
( )jXf
1 si la variance σ² est une fonction connue f de 
Xj ; 
− mettre en œuvre  les moindres carrés généralisés, ce qui peut se faire par 
PROC GLM . 
© Revue MODULAD, 2006 - 302-               Numéro 35 
 
 
4.2.4. Normalité des erreurs 
Supposition : Les εi sont indépendant, et suivent une loi N(0,σ²). 
 
Cette supposition de normalité est nécessaire pour effectuer les tests sur les 
coefficients  et les tests sur les sommes de carrés  à l'aide des statistiques de 
Student ou de Fisher vues aux chapitres 1 et 2. 
 
omme tout test, le test d’adéquation à une loi nécessiteC  l’indépendance. Or les 
s la procédure REG avec l’instruction PLOT : on 
t 
 
t 
variables. 
résidus sont liés. Donc réaliser un test de normalité à une loi N(0, σ²) sur ces 
résidus n’a pas de sens. 
 
Dans SAS, un tracé « QQ-Plot »18 pour les résidus permet de vérifier graphiquement 
l’adéquation à la loi normale (0,s²) ou s² est estimé par MSE (Mean  Square Error du 
odèle). Le QQ-Plot est obtenu danm
demande le tracé de R (variable interne des résidus) contre NQQ (variable interne 
contenant les quantiles de la loi normale) : voir l’exemple ci-dessous (§4.2.5). Dans 
SAS/INSIGHT, une fois que l’on a exécuté le modèle, on peut ajouter aux sorties 
standards un graphique QQ-Plot appelé « Residual Normal QQ » dans le menu 
raphs (penser à cocher « Reference lines »dans le menu contextuel du graphique G
pour tracer la droite). 
4.2.5. Exemple 
On utilise les données « Processionnaire du pin » issu du livre de Tomassone e
al..(1983), déjà traitées au chapitre 2. On se limite dans ce paragraphe au modèle Y
= log = f(X1 X2 X4 X5), dont on verra que c’est  un « bon » modèle. 
On trouvera au §2.3.2 les caractéristiques des variables, la matrice de corrélation e
les graphiques de dispersion des 
Modèle  
 
proc reg data=libreg.chenilles; title 'Modèle Y = X1 X2 X4 X5 
'; 
LOG : model LOG=X1 X2 X4 X5 ; 
run ; 
quit; 
 
 
                                            
18 On trouvera en annexe 5 le principe de construction des QQ-Plot pour l’adéquation à certaines lois. 
© Revue MODULAD, 2006 - 303-               Numéro 35 
 
 
 Dessin des résidus contre les 4 régresseurs (avec SAS/INSIGHT) 
On y affiche le numéro de certaines observations, qui ont des résidus un peu grands, 
ou qui seront détectés plus loin comme « atypiques » (§4.3.11)  
 
© Revue MODULAD, 2006 - 304-               Numéro 35 
 
 
 
 
Remarque : instruction de tracé des résidus dans PROC REG  
 
 /* dessin des residus contre les X dans PROC REG */ 
plot R.*X1='1' R.*X2='2' R.*X4='4' R.*X5='5' / vref = 0 ;  
 
QQ-Plot (avec SAS/INSIHT) 
 
 
 
Le tracé QQ-Plot montre un assez bon ajustement à la loi normale. 
 
© Revue MODULAD, 2006 - 305-               Numéro 35 
 
 
Test d’homoscédasticité et tracé du QQ-PLOT avec PROC REG. 
 
 
/*option SPEC + dessin QQ_Plot */ 
proc reg data=libreg.chenilles; title 'Modèle Y = X1 X2 X4 X5 
'; 
LOG : model LOG=X1 X2 X4 X5 / SPEC ; 
run ; 
/* QQ Plot */ 
plot R.* NQQ. ; 
quit; 
 
 
 
’homoscédasticité des résidus n’est pas rejetée. 
 
L
 
 
 
© Revue MODULAD, 2006 - 306-               Numéro 35 
 
 
4.3. Influence d'observations 
Dans le but d'avoir une régression plus robuste, il faut détecter les observations 
ar des graphiques soit de Y contre 
 la figure 4.3, e  est nul car l’observation i est influente à cause de son caractère 
influentes, détection qui commence là-aussi p
les Xj, soit des résidus contre les Xj. 
Dans i
ique. atyp
 
Y
. .
.
.
.
. .
.
..
. .
.
..
. .
X
ei = 0 !
 
 
 Figure 4.3 : Exemple d’observation à fort effet de levier 
 
SAS calcule une série d'indicateurs par les 2 options R et INFLUENCE de 
l'instruction MODEL. L'ouvrage « Regression Diagnostics » de Belsley D.A., Kuh 
K. et Welsh R.E. (1980) en est la référence de base. 
 
Ces indicateurs sont basés sur des détections de l’influence selon des mesures 
ature différente : on distinguera 
donc des observations influentes sur la régression, ou suspectes, ou atypiques, ce 
dernier terme étant 
 
 
• 
leverage
 
• 
 
• 
précision. 
4.3.1. 
différentes, donc détecteront des influences de n
plutôt recommandé. 
Les mesures peuvent être classées en 3 groupes : 
détection d’un effet de levier de l’observation, donnant un résidu petit : 
 ; 
détection de résidu grand donc observation atypique ; 
détection d’un grand effet sur l’ajustement, ou les coefficients, ou la 
Hat matrice et leverages 
On utilise ici le modèle sous sa forme matricielle :  
n
3
2
1
Y
Y
Y
Y
Y
L
=
 np2n1n
p11211
XXX1
1
1
XXX1
X
L
L
L
=   
p
2
1
0
β
β
β
β
=β
L
 
n
3
2
1
ε
ε
ε
ε
=ε
L
 
© Revue MODULAD, 2006 - 307-               Numéro 35 
 
 
L’estimation des moindres carrés est le vecteur ( ) YXXXB 1 ′′= − . 
D’où l'ajustement  ( ) YXXXXYˆ 1 ′′= −  
En notant ( ) XXXXH 1 ′′= −  , on obtient HYYˆ =  et ( )YHIe −=  
 
Cette matrice est nommée H pour Hat matrice car hat se traduit par chapeau, et Yˆ  
se dit Y chapeau. 
 
Dans l’espace Rn pace engendré par 
les variables régresseurs X (es : c’est donc la matrice 
 
H est une matrice carrée (n,n), dont porte les n coefficients hii .De 
l’expression matric
, H est la  matrice de la projection de Y sur l'es
pace de dimension (p+1)) 
d’un projecteur, dont deux  propriétés sont : H' = H, et  trace(H) = p+1. 
la diagonale com
ielle de H, on déduit ( ) i1iii xXXxh −′′= . 
  ne comportent donc que des données relativLes coefficients hii es aux variables 
explicatives Xj . 
 
Les « leverages » (leviers) des observatio s sont ces n valeurs ii.  
 
Un levier représente l'influence de l'observation i sur la valeur ajustée Yˆ , à cause 
n h
i
des valeurs xi  prises par les variables en i.  
On  peut montrer que ( ) ( ) ( ) ( )1cccin1ii xxXXxxh −′ ci′−+= − , où (x  - x ) est la i c
ifférence entre le vecteur des valeurs des variables pour l'observation i,  et le 
 entre les valeurs des X prises en i et les 
aleurs moyennes calculées sur les n observations  
es différentes propriétés de H, on déduit:  
 
d
vecteur des valeurs moyennes, et  Xc la matrice de taille (n,p) des valeurs 
centrées. 
 
Le levier en i est donc une « distance »
v
 
D
( )
1hiin1
1i
≤≤⇒
1ph1pHtrace
p
+=⇒+= ∑
hhhh
ii
n,1j ij
ijiiijii +== ∑ 222 ∑
=
= ≠
 
 
et aussi des formules concernant les variances : var( iYˆ ) = σ²hii  et var(ei) = σ²(1-
hii).  
ii à 1. 
 
Règle 
n empirique, un levier supérieur à 2(p+1)/n est suspect. 
 
 
On en conclut que h  est toujours plus petit ou égal 
(colonne Hat Diag H): Si les leviers  étaient tous égaux, la valeur commune 
serait (p+1)/n. De faço
© Revue MODULAD, 2006 - 308-               Numéro 35 
 
 
4.3.2. Résidus studentisés internes 
Ils sont appelés en anglais Standardized Residuals ou STUDENT. 
n connaît la variance de chaque résidu : 
 ( ) ( )2 h1−σ= iiievar . Dans cette formule, 
( )
O
1pn
i
+−=  = MSE; donc le résidu standardisé est : 
e
s
2
i
2
∑
on estime σ² par 
ii
i
i h1s
er −=  . 
 
Bien que numérateur et dénominateur ne soient pas indépendants, on considère 
que cette quantité ri suit une loi de Student à (n-1-(p+1)) = (n-p-2) ddl, d’où le nom 
STUDENT. 
 
Règle (colonne Student) : ri sera suspect si |ri| > 2 (quantile de la loi de Student (1-
/2), pour le seuil α=5%, avec l’approximation par une loi normale si n grand). 
4.3.3. Résidus studentisés externes 
uals ou RSTUDENT. 
α
Ils sont appelés en anglais Studentized Resid
 
On remplace dans l'expres i est l’estimation de s 
obtenue en refaisant l'ajustement du modèle sans l'observation i, ce qui rend e
sion de ri l'estimation s par s(-i) qu
i 
indépendant de s(-i) : ceci donne 
ii)i(−
i
)i( h1s
er −=−  
(-i)  Student à (n-1-(p+1)) ddl et 
ertains auteurs préconisent d'autres 
(-i) α/2n plutôt que 1-α/2 .  
4.3.4. ce  sur le vecteur des coefficients: 
Distance de COOK  
Pour chaque observation i, » entre le vecteur B des 
coefficients de la régression et faisant la régression sans 
observation i : la distance se mesure à l’aide de (X’X) et est normée par s², 
 
ègle (colonne RStudent) : r  suit aussi une loi deR
sera donc aussi suspecte si |r(-i)| > 2.  C
uantiles à un seuil fixé α  pour r  : quantile 1-q
Mesure globale de l'influen
on calcule une « distance 
 le vecteur B(-i) obtenu en re
l’
estimation de σ². 
 
( ) ( ) ( ) ( )( ) ( )( )ii
ii
2
i
h11p
hr
s1p −++ 2i
iBBXXiBB
COOKD =−−′
′−−=  
leur 
upérieure à 1 est suspecte .  
                                           
 
Règle : (colonne Cook's D) : La distance de COOK étant normée, une va
19s
 
19 Certains auteurs suggèrent une limite de 4/(n-p-1), la calibration à 1 pouvant laisser passer des 
valeurs influentes 
© Revue MODULAD, 2006 - 309-               Numéro 35 
 
 
4.3.5. Influence sur chacun des coefficients : DFBETAS  
timé bj et celui 
btenu avec l'estimation sans l'observation i, bj(-i). 
Pour chaque variable, on calcule la différence entre le coefficient es
o
Avec standardisation, on obtient pour chaqu ive j : 
 
e variable explicat
( ) ( )( )( ) ( ) 1
jjj
i
ibb
ETAS −
j,jXXis
DFB
′−
−−=  
 
: Empiriquement, un DFBETAS dont la valeur absolue est plus grande que Règle 
n   est suspect. 
 
Utilisation co
2
njointe COOKD et DFBETAS : S'il y a beaucoup de variables, on 
garde d'abord les observations globalement influentes (COOKD élevé), puis pour 
4.3.6. Précision des estimateurs : COVRATIO 
La quantité Mean Square Error (MSE) mesure la précision globale de l’estimation : 
es résidus. 
re
cette observation quelle(s) variable(s) cause(nt) cette influence (DFBETAS). 
MSE petit indique une bonne précision. MSE est aussi la variance d
 
Ici, on mesure la précision en utilisant une variance « généralisée », évaluée par :  
s²|| (X'X)-1 || calculée avec et sans l'observation i ((la notation || (..)|| désigne le 
déterminant de la matrice) : 
( ) ( ) ( )( ) 1
1
)i(Xis
COVRATIO −
−
−−=
2
2
i
X'Xs
X'
 
e diminution 
de la précision. 
 
Règle )/n 
est grand. 
rvation i, (DFFITS)i donne la différence entre la valeur ajustée pour 
bservation i et la valeur prédite de Y pour i dans le modèle estimé sans cette 
la valeur ajustée 
par le modèle quand l'
Avec une standardisat
 
Donc (COVRATIO)i plus grand que 1 indique que le fait de mettre l'observation i 
augmente la précision, alors qu'une valeur plus petite que 1 indique un
 : Belsley, Kuh et Welsh suggèrent qu'un écart à l'unité  dépassant 3(p+1
4.3.7. Influence sur la valeur ajustée: DFFITS  
Pour chaque obse
l'o
observation i. Un grand écart indiquera une forte modification dans 
observation i est retirée.  
ion à s(-i): 
 
( ) ( )( ) ( ) iiiii h1his −−
iiii hiriYˆYˆDFFITS −=−−=  
: DFFITS est déclaré suspect s'il est en valeur absolue plus grand que Règle 
( )
n
1p2 + . 
© Revue MODULAD, 2006 - 310-               Numéro 35 
 
 
4.3.8. Coefficient global PRESS  
Predicted Residuals Sum of Squares = PRESS= ( )( )∑ −− 2iYˆY  
=
ii
n,1i
Ce coefficient (unique) est calculé en faisant n estimations ( )iYˆ −i  obtenues en 
a  être égal à la somme des carrés des 
résidus du modèle avec toutes les observations (SSResidus) si aucune 
observation ne pose problème. 
enlevant une observ tion. Il devrait donc
 
Des coefficients PRESS individuels ( )( )2ii iYˆY −−  peuvent être obtenus uniquement 
dans la table SAS créé par l'instruction OUTPUT. Ces coefficients peuvent être 
comparés aux coefficients DFFITS, comme le montre la figure 4.4 ci-dessous : 
 
 
Figure 4.4 : Illustration de PRESS et DFFITS 
ans PROC REG 
n R Æ pour toutes les observations, le résidu et son écart-type, les 
résidus standardisés STUDENT, la distance de COOK et un dessin indiquant 
2] ; 
− Option INFLUENCE Æ pour toutes les observations, levier, résidu studentisé 
ns une table de sortie SAS (table 
 à l’aide de l’instruction OUTPUT : on crée des 
ariables en utilisant le UDENT, RSTUDENT, H, COOKD, DFFITS 
et PRESS. 
L’option PRESS de l’i oefficient PRESS 
 
 
4.3.9. Comment obtenir les mesures d’influence dans SAS 
D
Elles sont affichées en sortie par des options de l’instruction MODEL. 
− Optio
la position du résidu par rapport à l’intervalle [-2 ; +
externe RSTUDENT, COVRATIO, DFFITS et DFBETAS de chaque 
coefficient. 
 
Certaines  mesures peuvent être stockées da
possédant  n lignes au moins),
v s mots-clefs R, ST
nstruction MODEL permet d’obtenir le c
« global », qui sera affiché en sortie, et stocké dans la table de l’instruction OUTPUT
si cette instruction existe. 
© Revue MODULAD, 2006 - 311-               Numéro 35 
 
 
Dans 
Une fois que l’on a exécuté le modèle, on peut  SAS sur laquelle on 
 variables ajoutées ont alors le nom 
indiqué entre parenthèses ci-dessous (où Y est le nom de la v riable réponse du 
(R_Y) 
− Standardized residual  (RS_Y) 
 Covratio    (C_Y) 
− 
Hat Diag H 
SAS/INSIGHT 
ajouter à la table
travaille, des variables à l’aide du menu Vars. Les
a
modèle) : 
 
− Hat Diag,    (H_Y) 
− Residual    
− Studentized residual  (RT
− Cook’s D    (D_Y) 
− Dffits     (F_Y) 
−
_Y) 
Dfbetas    (BY_Intercept, BY_X1, BY_X2, etc.) 
4.3.10. Tableau récapitulatif  
 Std Err 
Residual Student Residual Rstudent 
signifiant levier de l'obs. i  
estimateur de 
l'erreur-type du  
résidu i 
résidus 
studentisés 
internes, appelés 
standardized 
residual  dans 
SAS-Insight 
résidus 
studentisés 
externes, appelés 
studentized 
residual dans 
SAS- Insight 
objet confiance autour 
du r
test de 
signific é 
à comparer avec 
Student  Residual 
écart-type calculé 
obs. i 
mesure l'influence 
de l'obs.i à cause 
des valeurs xi   
permet de calculer 
l'intervalle de 
ésidu i du résidu i en retirant l’
ativit
valeurs 
critiqu  es 2 2 n
)1p(2 +  
2>residual Student
alors le résidu i 
2> RStudent  
n
)1p(2hii
+>  
 
 
Règle de 
décision  
alors l'observation est nécessite une
investigation
i nécessite une 
investigation ! significativement ≠ 0 
Opti
de
REG
on 
 PROC 
 
R R Influence Influence 
 
 
 
 
 
 
 
 
 
 
© Revue MODULAD, 2006 - 312-               Numéro 35 
 
 
 Cook's D Df betas Cov Ratio Dffits 
signifiant distance de Cook 
DFBETAS relatif à  
chaque coefficient 
jβ  
Ratio de MSE 
sans et avec 
l'observation i 
statistique 
DFFITS 
o
mesure le 
changement en 
t bs. i, ur 
mesure 
normalisée de 
e l'obs. i 
n, 
aque  
t j
bjet les estimations de sur l'estimatio
retiran l'o  s l'effet d
l’ensemble des pour ch
coefficients coefficien β  
mesure l'effet de 
l'obs. i sur la 
précision 
mesure 
normalisée 
du changement 
dans la valeur 
prédite, avec et 
sans l'obs. i 
va
cri
leurs 
tiques 
1 ou 
)1pn( −−  
4
 n
2  
n
)1p(3 +  
n
)1p(2 +  
Règle
i est influente 
globalement 
2
 de 
1CookD >  
alors l'observation 
décision 
n
indique une 
Dfbetas >  
influence de l'obs. 
n
)1p(31Covratio +>−
nécessite une 
investigation 
n
)1p(2Dffits +>
indique une 
infl s. 
i sur iY  
uence de l'ob
ˆi sur l'estimation de jβ  
Option 
de PROC 
REG 
R, Influence Influence R R 
 
On trouvera dans le programme SA  une m UE  
(avec comm mbre ations e
ind r de l ne co
pe nt d s cr fére u
S ci-dessous acro CRITIQ
e paramètres : n no
a présence d’u
’afficher les valeur
 d’observ
nstante)  
it if
, p nombre de régr sseurs, et b0 
ence. 
icateu
rmetta iques des d ntes mesures d’infl
© Revue MODULAD, 2006 - 313-               Numéro 35 
 
 
 
%MACRO CRITIQUE (n= o vati ,   /* n mbre d'obser ons*/ 
                   p= om resse ,   /* n bre de rég ur */ 
                   b0=1  /* bo=1 si constante  
(intercept) */ 
                ); 
data seuil; 
n= =&&n; p p; b0=&b0; 
dcook=4/(&n-&p-&b0); 
hat_diag=2 &n;*(&p+&b0) /  
covratio=3*  &n;(&p+&b0) /  
dffits=2*sqrt((&p+&b0) / &n); 
dfbetas=2/sqrt(&n); 
proc print data=seuil; 
%mend; 
/*_________________________________________________________*/ 
*exemple  appel de la macro ; 
%critique b0=(n= 44 ,p= 4 , 1); 
run; 
4.3.11. Exemple 
On utilise l
(1983)
es ocessio pin » issu du livre de Tomassone et 
al.  et on se limite de nouveau au modèle Y = log = f(X1 X2 X4 X5). 
données « Pr nnaire du 
 
/* appel de la macro */ 
Title 'Valeurs critiques pour n = 33 et p = 4'; 
%critique(n= 33 ,p= 4 ,b0=1); 
run; 
 
title ' influence des observations '; 
proc reg data=libreg.chenilles;; 
LOG : model LOG=X1 X2 X4 X5 /R influence ; 
run; 
/* exemple de stockage des criteres */ 
output out=influence H=levier COOKD=dcook STUDENT = rsi 
RSTUDENT = rse ; 
quit; 
 
Voici les valeurs limites pour les coefficients d’influence :  
 
 
 
La table des valeurs des coefficients d’influence de toutes les observations est 
donnée ci-après. Mais plutôt que de rechercher les valeurs limites dans cette table, 
de simples Box-Plot permettent de les repérer rapidement. 
© Revue MODULAD, 2006 - 314-               Numéro 35 
 
 
 e d’une variable, et 
 
Des
Ce type
sins BOX-PLOT des coefficients d’influence :  
 de représentation est très riche en information sur la form
l’existence de valeurs différentes des autres (outliers). On en trouvera l’explication 
détaillée dans Le Guen (2001) 20. 
                                            
20 http://matisse.univ-paris1.fr/leguen/leguen2001b.pdf 
 
© Revue MODULAD, 2006 - 315-               Numéro 35 
 
 
 
 
 
Résidus standardisés  
Internes                         Externes 
 
 
Leviers 
 
 
 
 
CovRatio 
 
 
Dffits 
 
 
 
 
DCook 
 
 
© Revue MODULAD, 2006 - 316-               Numéro 35 
 
 
 
 
 
Dfbetas 
 
 
 révèle pas d’outl
constate que quelques observations ont 
0.23) : 8, 10, 12, 21 et 32.  
Les observations  20 et 33 ont des résidus | 
> 2) et donc un grand effet sur la précis  
enlève de la régression, SSE diminue fortement.  
Et elles influent également sur |DFFITS| >>
forte incidence sur l’ensemble des coefficien
coefficients (DFBETAS > 0.30), ceux  X  et X2 pour les 2 observations, celui de 
X4 pour l’observation 10. 
 
Pour résumer, les observations 10 20 21 et 33 seraient atypique
on peut penser qu’il n’est pas judicieux 
 
Le dessin humoristique de la figure 4 .5 ci
OSIRIS, mais l’auteur nous est inconnu) illu
le statisticien au vu de données atypiques ! 
La distribution des leviers ne iers, mais au vu des valeurs, on 
cependant un levier un peu trop grand (> 
« grands » (|STUDENT| et |RDSTUDENT
ion (COVRATIO -1) > 0.34 car quand on les
 0.67. Les observations 10 et 21 ont une 
ts (DCOOK > 0.10) et donc sur certains 
de 1
s. Cependant, au vu 
des données, où ces observations sont des placettes issues d’un plan d’expérience, 
de les retirer de la régression. 
-dessous (publié dans le manuel du logiciel 
stre le mauvais réflexe que pourrait avoir 
© Revue MODULAD, 2006 - 317-               Numéro 35 
 
 
 
 
Figure 4.5 : Que faire en présence de données atypiques ? 
Différents symptômes sont révélateurs de problèmes de colinéarité : 
− De grandes corrélations entre les régresseurs ; 
− Un grand changement dans les coefficients quand on ajoute ou enlève un 
régresseur ; 
− Des coefficients non significatifs alors que le test global d’analyse de 
variance sur tous les coefficients est significatif ; 
− La non significativité et/ou une très grande variance pour le coefficient d’un 
régresseur théoriquement important dans le modèle ;  
− Un coefficient de signe opposé à celui auquel on s’attendait. 
 
Ce sont  des problèmes d'inversion de X'X, qui entrainent une augmentation des 
variances des coefficients, et donc leur instabilité car 12 )X'X()(Var −σ=β . Et la non-
inversion de X’X se rencontre quand il existe des combinaisons linéaires entre les 
colonnes de X. 
 
4.4. Colinéarité des régresseurs 
© Revue MODULAD, 2006 - 318-               Numéro 35 
 
 
L’exemple simple de la figur nstabilité dû à la liaison 
entre deux régresseurs. 
 
e 4.6 illustre le phénomène d’i
O
Y
X2
X1
Y^
 
s 
 
Dans l’espace Rn es sont les corrélations (voir 
chapitre 1, §1.2.5): Ici X1 et s est 
petit, ce qui rend le sous-espace (X1, 21. 
4.4.1. Méthodes basées su
La matrice X possède n lignes et (p+1) colonnes : 
 
⎥⎥
⎥⎥
⎤
⎢⎢
⎢⎢
⎡
== p22221
p11211
ij
xx1
.
xxx1
xxx1
xX MMMM  
 
La matrice (X'X) est une matrice carrée (p+1), symétrique, dont les éléments sont 
cal  a
 
Figure 4.6 : Projection de Y dans l’espace de 2 régresseurs corrélé
, les cosinus d’angle entre variabl
 X2 étant très corrélées, l’angle entre les 2 vecteur
X2), et donc la projection, instables
r l'étude de la matrice X'X 
( )
⎥⎦⎢⎣ np2n1nx
culés insi : ( ) nXX =′
( ) 1k,xXX ikkk ≠∀=′ ∑
=
( )
n,1i
′
( ) ( ) 1k,Xmoyenne.nxXX k
n,1i
ik1k ≠∀==′ ∑
=
1h,k,xxXX
n,1i
ihikkh ≠∀= ∑
=
2
11
 
 
En
Si o  
en covariance des 
                                         
  étudiant les leviers au §4.3.1, on a utilisé les variables régresseurs centrées.  
onsidère la matrice X  de taille (n,p ) ayant en colonnesn c c  les p régresseurs 
trés, alors (Xc'Xc) = n . COV où COV est la matrice de variance-c
variables Xj. Quand les variables sont non-corrélées, alors (X'c Xc) est une matrice 
diagonale puisque toutes les covariances sont nulles. 
   
  Le site de Chong Ho Yu illustre de façon très amusante ce problème d’instabilité  
http://creative-wisdom.com/computer/sas/collinear_subject_space.html
21
 
© Revue MODULAD, 2006 - 319-               Numéro 35 
 
 
Donc X’X est égal à n.R si on travaille sur des régresseurs centrés et réduits, où R
est la matrice carrée 
 
symétrique des coefficients de corrélation entre les p 
gresseurs. 
 
− Si les régr trice, notée R, n’a 
 
−  
e 
vaut p (trace de R). Quand il n’y a aucune liaison entre les rég esseurs, elles 
s s valeurs 
propres plus petites et  
 effet on 
peut montrer que ses éléments diagonaux 
ré
Etude de la matrice de corrélation des régresseurs 
Cette étude se révèle intéressante.  
esseurs ne sont pas corrélés entre eux, cette ma
que des 1 sur sa diagonale, et 0 ailleurs : c’est la matrice identité. 
La matrice R est symétrique définie et positive, et de rang p. Les valeurs
propres de R sont donc en nombre de p, elles sont positives et leur somm
r
ont toutes égales à 1 car R est la matrice identité. Sinon, on aura de
mêmes proches de 0 : l’examen des valeurs propres
révèlera donc les problèmes de liaison entre les régresseurs. 
 
− R(-1), matrice inverse de R, est également riche en informations. En( ))1(−jR  sont égaux à  1/(1 - R²j) où 
ec constante de 
− Si on définit un modèle av et réduits, en remplaçant 
l’express  carrés, on montre (cf. 
Woolridge (2000)) que le ve c de ce modèle est  
R²j est le coefficient de corrélation multiple de la régression av
Xj sur les (p-1) autres variables. 
 
ec les régresseurs centrés 
ion de (X’X) dans l’estimateur des moindres
cteur des coefficients B
YXR
n
1B 1c ′= −  , et la matrice de variance-covariance vaut 1
2
c Rn
)B(Var −σ= . 
t 
liser le
REG possède des options TOL, VIF et 
SAS/ INSIGHT donn  table COLLIN 
uniquement. 
4.4.2. 
n a vu au §4.4.1 que la matrice de variance –covariance des coefficients du 
 
e 
Variance Inflation Factor  
 
Une étude préalable de la matrice de corrélation des régresseurs, complétée 
éventuellement par une Analyse en Composantes Principales, s’impose donc e
permet de visua s liaisons entre variables.  
COLLIN, COLLINOINT pour détecter des 
problèmes de colinéarité  selon deux optiques différentes. 
e les indices TOL et VIF par défaut, et affiche la
Variance Inflation Factor 
O
modèle où les régresseurs sont centrés et réduits est R-1, à un facteur près. Donc
l’élément diagonal j de cette matrice mesure comment la variance du coefficient d
Xj sera augmentée par la colinéarité. 
 
Pour chaque variable Xj , on nomme cet élément VIFj ( ou
inflation de variance) : VIFj = 1/(1 - R²j) où R²j est le coefficient de corrélation 
multiple de la régression avec constante de Xj  sur les (p-1) autres variables. 
 
© Revue MODULAD, 2006 - 320-               Numéro 35 
 
 
S'il  y a colinéarité, alors R²j est proche de 1, donc VIFj  est grand. Comme la loi de 
ce coefficient n’est pas connue, Belsley et al. ont défini un seuil limite de façon 
empirique. 
 
Règle : une valeur de VIF plus grande que 10 révèle un problème. 
omassone (1983) propose de calculer un indice global de colinéarité défini 
 
T
comme la somme des VIF de tous les régresseurs : ⎟⎟⎠
⎞
⎜⎜⎝
⎛= ∑
=
p
1j
jVIFp
1I  
 
Rem r
inflatio
TOLj =
 
4.4.3. Condition index et variance proportion 
On a s
révèle
 
en composantes principales (ACP), qui 
on t
qui
princip
 
Plus  
réduites , on const gonales  avec  
lation W = Z U. En ACP, on démontre que la matrice U est la matrice des 
tre les variables Z entraine une 
 est égale à λ .  
it le modèle avec les variables W 22, on trouve donc la solution des 
moindres carrés ecWY +=
a que: la tolérance (option TOL) est définie comme l'inverse de la variance 
n  
 1/VIFj 
ignalé au §4.4.1 que l’étude les valeurs propres de la matrice de corrélations 
 les problèmes de liaisons entre les régresseurs. 
Cette étude se fait aussi par l’analyse 
c sis e à transformer des variables pour obtenir d’autres variables orthogonales, 
 sont des  combinaisons linéaires des premières, appelées composantes 
ales (cf. Saporta (2006) ou Tenenhaus (1994)). 
i Z est la matrice (n,p) des variables init
ruit la matrice W (n,p) des variables ortho la
précisément s iales centrées et
re
vecteurs propres normés de R, associés aux p valeurs propres )p,...,2,1k,( k =λ , 
qui sont positives car R est symétrique définie positive. On les ordonne de la plus 
grande à la plus petite : une liaison parfaite en
nullité des dernières valeurs propres.   
On montre également que la variance d’une composante W k k
 
Si on constru )
, avec Y'W)W'W(c 1−=) .  
Et la m coefficients est ( ) ( ) 12 W'WcVar −σ=)  ; pour atrice de variance-covariance des 
un coefficient : ( )
k
2
k n
cvar λ
σ=) . 
Comme les variables sont orthogonales et de variance égale à la valeur propre, on 
en déduit Y'WecWY 1−Ω=+= ) , avec ⎥⎦⎢⎣ ⎟⎠⎜⎝ λn k
diagonale.  
 
⎤⎡ =⎟⎞⎜⎛=Ω− p,..,1k,1Diag1  matrice 
                                            
22 On trouvera dans le chapitre 6 du livre Tomassone et al (1992), le principe de cette méthode qu’il 
appelle « régression orthogonalisée » 
© Revue MODULAD, 2006 - 321-               Numéro 35 
 
 
On passe facilement de c
)
 à α)  car eZecZUecWY +α=+=+= ))) , et donc cU)) =α . 
La matrice de variance-covariance est ( ) 'U)c(VarUVar )) =α  ; pour le coefficient du 
régresseur j, ( ) ∑
=
σ=α
p 2
jk
2 U
var )  : des valeurs propres faibles entrainent donc de 
randes variances des coefficients. 
Les indices de colinéarité 
ions sur 
existence de colinéarité. 
 transformée pour avoir uniquement la valeur 1 sur les éléments 
 a donc (p+1) valeurs propres : c’est l’option COLLIN. 
i on travaille sur un modèle avec les régresseurs centrés comme ci-dessus, il y 
aura p valeurs propres : c’est l’option COLLINOINT. 
 
On édite ces valeurs propres de la plus grande  à la plus petite λ , (L=p ou p+1). 
λ1k kj n
g
A - Tout d’abord, l’édition des valeurs propres donner ta des informa
l’
 
De façon générale, on calcule les valeurs propres de la  matrice (X’X) du modèle, 
préalablement
diagonaux. Il y
S
λ1 L
Une valeur propre nulle révèle l’existence d’une dépendance linéaire entre les 
colonnes de X,  donc une colinéarité. 
 
On nomme « Condition Index » le rapport 
k
1CI λ
λ= ,  appelé aussi  « indice de 
conditionnement ». Le dernier de ces rapports 
L
λ
« Condition Number ». 
 
Comme la loi de ce coefficient n’est pas connue, Belsley et al. ont défini un seuil 
limite de façon empirique : 
 
Règle (colonne Condition Index) : une valeur grande met en évidence un 
1CI =  (L=p ou p+1) est nommé 
avec 
  
 de multicolinéarité 
erses des  propres e 
λ
problème ;  empiriquement  CI > 30 avec l'option COLLINOINT, ou CI  > 100 
OLLIN.C
 
Remarque : On r une » en calculant la 
moyenne des inv valeurs
peut défini « indice
(cf. Foucart 2006, 2007) : Cet indic
serait calculé comme ⎟⎟⎠
⎜ λ= ∑ kpI  si on considère que les régresseurs sont 
centrés et réduits (p valeurs propres). 
leur propre et donc
ROPortions », qui indiquent quelles variables sont respon
eur propre.  
a vu que la matrice de variance-covariance des coefficients α
⎞
⎜⎝
⎛
k
11
 
B – Ensuite, pour chaque v  
« VARiance P sables de 
la colinéarité révélée par cette val
En effet, on 
a  chaque CI, sont données des
)  de la 
gression sur les variables centrées et réduites est ( ) 'U)c(VarUVar )) =α  et que  ré
pour un coefficient j, ( ) ∑
=
σ p 2jk2 U)
λ=α 1k kj n
var .  
© Revue MODULAD, 2006 - 322-               Numéro 35 
 
 
La colonne « proportion e riancd va e » pour le coefficient d’une variable j est le 
vecteur ⎟⎟⎠
⎜⎛ == p(oup,..,1k,U.PropVar.
2
jk ⎞
⎜⎝
+λ )1k , normé pour que la somme de ses
composantes soit égale à 1. 
Règle : d'après Belsley, Kuh et Welsh, si les proportions de variance de plusieurs 
s que 0.50 pour un « condition index » grand, les 
 constante des estimateurs de 
COLLIN que si la 
tor ». On trouvera dans l’article d’Hélène 
ousse-Erkel (1990) des précisions et ents aux travaux de Belsley 
− Retirer certains régresseurs, princi  » de la colinéarité ; 
ar des ratios si on identifie le facteur commun de liaison ; 
− Augmenter la taille n de l'échantillon avec le recueil d'autres observations ; 
ression 23 (transformer (X'X) en (X'X + kI)) (Hoerl et 
er les méthodes de type « LASSO » de Tibshirani
 
 
variables sont plus grande
variables correspondantes ont un problème de colinéarité entre elles.  
 
emarque : l'option COLLINOINT exclut laR
coefficients; les p variables sont centrées et réduites et (X'X) est donc, à un 
coefficient près, la matrice de corrélation entre les p variables explicatives. 
L'option COLLIN inclut  la  constante dans les estimations de coefficients. X 
contient donc la variable constante égale à 1. La matrice X'X, de taille (p+1), est 
normée pour avoir 1 sur la diagonale, mais les variables ne sont pas centrées. 
elsley, Kuh et Welsh recommandent  de n'utiliser l'option B
constante a une interprétation physique. Centrer les variables (option 
COLLINOINT) consiste à supposer que la constante n'a pas d'effet sur la 
colinéarité des autres variables régresseurs. De plus, ceci est cohérent avec les 
alculs du « Variance Inflation Facc
R  des prolongem
et al. sur la colinéarité. 
4.4.4. Remèdes en cas de multi-coliné
− Les transformer p
arité 
paux « responsables
− Sélectionner les régresseurs, si p est trop grand par rapport à n ; 
− Faire une Ridge-Reg
Kennard (1970)) ; 
− Travailler sur les composantes principales issues des régresseurs 24 ; 
− Faire une régression PLS ; 
− Utilis  (1996) ; 
e). 
emarques :  
mble une méthode plus efficace que 
− Etc. . 
 
La régression RIDGE et la régression sur composantes principales peuvent être 
réalisées à l’aide des op E et PCOMIT de l’instruction Proc REG (voir 
l’annexe 1 pour la syntax
 
tions RIDG
R
- Quelques unes de ces méthodes sont décrites dans les articles de la R.S.A. de 
P.Cazes (1975) ou de R. Palm et A.F.Iemma (1995). 
- La régression PLS (Partial Least Square) se
la régression Ridge ou la régression sur composantes principales en cas de 
                                            
23 Voir l’exemple au §4.4.5. 
24 C’est la « régression orthogonalisée » de Tomassone ( §4.4.3.) 
© Revue MODULAD, 2006 - 323-               Numéro 35 
 
 
colinéarité, et s'applique aussi au cas où p est très grand par rapport à n (voir les 
 
régression sur données « ma
publications de Tenenhaus (1995,1998)). 
PROC ORTHOREG de SAS propose d’autres solutions pour réaliser une 
l conditionnées », c’est à dire en cas de colinéarités 
es variables. 
n utilise les données « Processionnaire du pin » issu du livre de Tomassone et 
d
4.4.5. Exemple 
O
al.(1983), avec le modèle Y = log = f(X1 X2 X4 X5). 
 
proc reg data=libreg.chenilles ; title 'option TOL VIF'; 
LOG : model log=X1 X2 X4 X5 /tol vif collinoint; 
run; 
quit; 
 
 
 
Au t 
signific
 
cune des valeurs VIF ne sont trop grandes, et tous les coefficients son
atifs. 
 
 
Dans la colonne « condition Index » (traduit dans la version française de SAS pa
« Index de condition ») il n’y a  pas de grandes valeurs. Sur la 4
r 
 
(c’est celle de « condition number »), en regardant les proportions de variance, on 
constate que les 2 variables X4 et X5 sont les « responsables » de la faiblesse de la 
n avait vu au chapitre 2 (§2.3.2) que c’est le couple de 
ième et dernière ligne
4ième valeur propre : o
régresseurs le plus corrélé.  
© Revue MODULAD, 2006 - 324-               Numéro 35 
 
 
Regression RIDGE 
ette méthode, due à Hoerl et Kennard (C 1970), consiste à modifier (X’X) pour la 
: c’est la « Ridge Trace ». On 
détermine la valeur de k à partir de laquelle les coefficients  se stabilisent : ce sera 
la vale
rendre inversible. Pour cela on ajoute un terme constant k à la diagonale 
)1k0( ≤≤ . La solution des moindres carrés sera donc obtenue en inversant (X'X + 
kI) : les coefficients obtenus sont appelés « coefficients ridge ». On trace ensuite la 
variation des coefficients ridge en fonction de k 
ur choisie. 
 
title 'Ridge-regression sur le modele a 4 variables' ; 
proc reg data=libreg.chenilles ridge = 0 to 1 by 0.05 outest = 
coeff_ridge ; 
LOG: model log=X1 X2 X4 X5 ; 
plot / ridgeplot ; 
run; 
quit;  
proc print data = coeff_ridge ; 
run ; 
 
 
 
Ici les coefficients ridge se stabilisent pour k ≅ 0.3. 
Les valeurs des coefficients sont alors lus dans la table coeff_ridge. Dans cette table, 
la première ligne est le modèle habituel, et la deuxièm correspond à k=0, ce qui est e 
le même modèle. 
 
Pour _RIDGE_ = 0.3 ,  
b1 = -0.003281930, b2 = -0.047532; b4 = -0.40556 ; b5 =0.05207. 
© Revue MODULAD, 2006 - 325-               Numéro 35 
 
 
 4.5. 
Ce choix s'
 
 cas 
 
1. 
2. 
3. choix d’un modèle plus simple pour  prévision (principe de PARCIMONIE). 
s de sélection dans SAS/INSIGHT. 
Choix des régresseurs 
avère nécessaire en particulier si le nombre d'observations est petit par 
rapport au nombre de régresseurs, à cause du rang de X'X qui peut devenir plus petit 
que p. Ceci peut entrainer une instabilité des coefficients comme on l’a vu au 
paragraphe précédent. 
Soit un modèle avec n observations et p régresseurs ; on sélectionne dans les
suivants (cette liste est non exhaustive) : 
n petit par rapport à p ;  
colinéarité des régresseurs ; 
la
(1 et 2 entraînent des problèmes d’inversion de X’X). 
 
Proc REG permet ce choix par l'option « SELECTION = method », de l'instruction 
MODEL. Il n’y a pa
4.5.1. Utilisation des sommes de carrés 
La formule de base est : SSTotale = SSModèle + SSErreurs
© Revue MODULAD, 2006 - 326-               Numéro 35 
 
 
Rappel sur les somme de carrés apportés par un régresseur 
Les sommes de carrés apportés par les régresseurs peuvent être obtenues par les
options SS1 SS2 de l'instruction MODEL de REG, ce qui a déjà été vu dans le 
chapitre 2 (§2.4.1), ou bien par les « Type III Tests » dans SAS/INSIGHT. 
 SS1(Xj) = somme des carrés apportée par la variable Xj introduite en 
séquence dans la régression, la régression contenant uniquement  les
variables qui la précèdent dans la liste de variables explicatives de 
 
 
−
 
 
  
− SS2(Xj) = somme des carrés apportée par la variable Xj, lorsque l'ensemble 
des (p-1) autres régresseurs est déjà dans la régression. Ce sont les 
sommes de carrés données par la table « Type III Tests » de 
SAS/INSIGHT. 
 
SS2(Xj) correspond au calcul du carré de la différence entre la valeur de Y estimée 
par la régression avec les p variables et celle estimée dans la régression à (p-1) 
variables, sans Xj.  Pour le choix de régresseurs, le deuxième calcul d’apport de 
somme de carrés est le plus intéressant, car il ne dépend pas de l’ordre 
d’introduction des variables dans le modèle. On notera « SSapporté par j » cette 
quantité SS2(Xj). 
 
Tests des apports à SSModèle d’une variable  
Les tests décrits dans le chapitre 2 (§2.4.3), ne sont pas faits par l'option SS2 de 
l'instruction MODEL de REG, mais sont donnés dans la table «Type III Tests » de 
SA I
Plus généralement, comme on l’a vu au §2.4.4, un modèle sans r variables est 
ed Residual Sum of Squares)=somme des carrés des 
résidus du modèle complet. 
l'instruction MODEL. 
−
S/INS GHT.  
appelé modèle restreint  par opposition au modèle complet à p variables. 
− RRSS (Restricted Residual Sum of Squares) =  Somme des carrés des 
résidus du modèle restreint 
− URSS (Unrestrict
La valeur de la statistique du test est 
© Revue MODULAD, 2006 - 327-               Numéro 35 
 
 
)1pn/(URSS −−
r/)URSSRRSS(F −= .  
Dan le e, r vaut 1, et donc en passant aux sommes de carrés 
du 
 
s  cas d’une seule variabl
modèle : 
MSE)1pn/(URSS
1/)URSSRRSS(F completModèle=−−
−= SSSS jsansModèle− . 
MSE
F = SS jparapporté  
 
uantité MSE (Mean Square 
Error) du modèle avec constante contenant tous les régresseurs. De plus, la valeur 
Les tests de significativité de ces sommes de carrés sont donc réalisés à l’aide 
d’une statistique F, obtenue en divisant SS par la q
de F associé à SS est aussi le carré du t de Student du coefficient de la variable j 
ssone et 
l..(1983). On va calculer les apports de sommes de carrés pour éliminer 
pro
les so
tester 
 
Modèle à 10 variables 
 
dans la régression à p régresseurs.  
 
Exemple d’élimination progressive 
On analyse les données « Processionnaire du pin » issu du livre de Toma
a
gressivement les variables à partir du modèle complet à 10 variables. On utilise 
rties de SAS/INSIGHT, qui permet dans le tableau « Type III Tests » de 
la validité de l’apport des sommes de carrés. 
Model  Equat i on
 = 10. 9984
 -   1. 2936
l og  -   0. 0044 X1  -   0. 0538 X2  +  0. 0679 X3
    X4  +  0. 2316 X5  -   0. 3568 X6  -   0. 2375 X7
     +  0. 1811 X8  -   1. 2853 X9  -   0. 4331 X10             
Anal ysi s of  Var i ance
Source
Model
Error
DF
   
    2
Sum of  Squares Mean Square F St at Pr  > F
C Tot al
 10
2
    32
   34. 4662
   15. 1299
   49. 5960
    3. 4466
    0. 6877
    5. 01   0. 0008
 
Paramet er  Est i mat es
Var i abl e
I nt ercept
X1
DF
     1
     
Est i mat e
   10. 9984
St d Error
    3. 0603
t  St at
      3. 59
Pr  >| t |
  0. 0016
Tol erance
     .     
Var  I nf l at i on
         0
X2
X3
X4
X5
     1
     1
     1
     1
   -0. 0538
    0. 0679
   -1. 2936
    0. 2316
    0. 0219
    0. 0995
    0. 5638
    0. 1044
     -2. 46
      0. 68
     -2. 29
      2. 22
  0. 0223
  0. 5017
  0. 0317
  0. 0371
    0. 8400
    0. 0239
    0. 0624
    0. 1066
    1. 1904
   41. 8708
   16. 0219
   
X6
X7
     1
     1
     1
     1
   -0. 3568
   -0. 2375
    0. 1811
   -1. 2853
    1. 5665
    1. 0060
    0. 23
    0. 86
     -0. 23
     -0. 24
  0. 8219
  0. 8156
    0. 0170
    0. 6064
   58. 755
    1. 649
X8
X9
1    -0. 0044     0. 0016
67
     -2. 85
      0. 76
  0. 0094
  0. 4525
    0. 5327
    0. 0693
    1. 8774
 9. 3845
8
1
   14. 4226
X10      1    -0. 4331
48
    0. 7349
     -1. 49
     -0. 59
  0. 1514
  0. 5616
    0. 0895
    0. 6057
   11. 1686
    1. 6509
 
 
 
C’est un modèle globalement bon (F d’analyse de variance significatif), mais les 
coefficients des régresseurs X3 X6 X7 X8 X9 et X10 sont non significatifs . De 
lus, l’inflatiop
e
n de variance est plus grande que 10 pour les régresseurs X3 X4 X6 
t X9. Le mod : il faut éliminer des 
régresseurs.  Pour cel
èle n’est donc pas un « bon modèle » 
a on effectue les tests sur les apports de sommes de carrés 
© Revue MODULAD, 2006 - 328-               Numéro 35 
 
 
Type I I I  Test s
Source DF Sum of  Squares
    0. 2389
Mean Square
    5. 5717
    0. 2389
F St at
      8. 10
      0. 59
      2. 21
      0. 35
Pr > F
  0. 0094
  0. 4525
  0. 1514
  0. 5616
X1      1     5. 5717
X2
X3
X4
X5
X6
X7
X8
X9
     1
     1
     1
     1
     1
     1
     1
     1
    4. 1551
    0. 3208
    3. 6205
    3. 3869
    0. 0357
    0. 0383
    0. 4023
    1. 5190
    4. 1551
    0. 3208
    3. 6205
    3. 3869
    0. 0357
    0. 0383
    0. 4023
    1. 5190
      6. 04
      0. 47
      5. 26
      4. 92
      0. 05
      0. 06
  0. 0223
  0. 5017
  0. 0317
  0. 0371
  0. 8219
  0. 8156
X10      1
 
 
Les variables X3, X6, X7, X8, X9, et X10 ont un apport non significatif : on élimine 
la variable X6 dont l’apport est le plus petit. 
Remarque : on peut vérifier ici que F(X6) = t²(X6) Æ 0.0529 = (-0.23)²  (cf. chapitre 
1, §1.3.4) 
 
Type I I I  Test s
Source
X1
X2
X3
X4
X5
X7
X8
X9
X10
DF
     1
     1
     1
     1
     1
     1
Sum of  Squares
    5. 5373
    4. 1218
    0. 9909
    4. 0339
    3. 5100
    0. 0871
Mean Square
    5. 5373
    4. 1218
    0. 9909
    4. 0339
    3. 5100
    0. 0871
F St at
      8. 40
      6. 25
      1. 50
      6. 12
      5. 32
      0. 13
Pr > F
  0. 0081
  0. 0200
  0. 2327
  0. 0212
  0. 0304
  0. 7196
     1
     1
     1
    0. 3742
    1. 8513
    0. 2063
    0. 3742
    1. 8513
    0. 2063
      0. 57
      2. 81
      0. 31
  0. 4589
  0. 1074
  0. 5813
 
Æ On élimine X7  
Type I I I  Test s
Source
X1
X2
X3
X4
X5
X8
DF
     1
     1
     1
     1
     1
     1
Sum of  Squares
    6. 3925
    4. 0447
    0. 9455
    4. 9416
    4. 7047
    0. 3782
Mean Square
    6. 3925
    4. 0447
    0. 9455
   4. 9416
7047
    0. 3782
F St at
     10. 06
      6. 36
      1. 49
      7. 78
      7. 40
      0. 60
Pr > F
  0. 0041
  0. 0187
  0. 2344
  0. 0102
  0. 0119
  0. 4480
 
    4.
X9
X10
     1
     1
    1. 7752
    0. 2984
    1. 7752
    0. 2984
      2. 79
      0. 47
  0. 1076
  0. 4997
 
Æ On élimine X8  
Type I I I  Test s
Source
X1
X2
X3
X4
X5
X9
X10
DF
     1
     1
     1
     1
     1
     1
     1
Sum of  Squares
    7. 0905
    4. 1181
    1. 1435
    5. 0418
    4. 5410
    1. 4670
    0. 4195
Mean Square
    7. 0905
    4. 1181
    1. 1435
    5. 0418
    4. 5410
    1. 4670
    0. 4195
F St at
     11. 34
      6. 59
      1. 83
      8. 06
      7. 26
      2. 35
      0. 67
Pr > F
  0. 0025
  0. 0166
  0. 1884
  0. 0088
  0. 0124
  0. 1381
  0. 4205
 
Æ On élimine X10  
© Revue MODULAD, 2006 - 329-               Numéro 35 
 
 
 Type I I I  Test s
Source
X1
X2
X3
X4
X5
X9
DF
     1
     1
     1
     1
     1
     1
Sum of  Squares
    6. 6711
    4. 2645
    0. 9272
    4. 7457
    4. 3079
    4. 7457
    4. 3079
      7. 69
      6. 98
  0. 0101
  0. 0138
    1. 4451
Mean Square
    6. 6711
    4. 2645
    0. 9272
    1. 4451
F St at
     10. 81
      6. 91
      1. 50
      2. 34
Pr > F
  0. 0029
  0. 0142
  0. 2314
  0. 1381
 
Æ On élimine X3  
Type I I I  Test s
X9
     1
     1
     1
    6. 2247
    5. 6406
    0. 5259
  5. 8582
    6. 2247
    5. 6406
    0. 5259
      9. 32
      9. 90
      8. 97
      0. 84
  0. 0051
  0. 0040
  0. 0058
  0. 3685
Source
X1
DF
     1
Sum of  Squares
    5. 8582
Mean Square
  
F St at Pr  > F
X2
X4
X5
     1     4. 0243     4. 0243       6. 40   0. 0176
 
Æ On élimine X9 
Type I I I  Test s
Source
X1
X2
X4
X5
DF
     1
     1
     1
     1
Sum of  Squares
    7. 3067
    5. 4683
   11. 2389
    8. 6123
Mean Square
    7. 3067
    5. 4683
   11. 2389
    8. 6123
F St at
     11. 69
      8. 75
     17. 98
     13. 78
Pr > F
  0. 0019
  0. 0062
  0. 0002
  0. 0009
 
 
On a obtenu un modèle dont les apports de toutes les variables sont tous 
significatifs : on arrête donc le processus. 
La procédure réalisée donne donc comme modèle final Y = f(X1 X2 X4 X5); qui es
le modèle déjà étudié et qui s’est révélé être un modèle « correct », vérifiant les
suppositions de base sur les erreurs (§4.2.5), où 4 observations sont atypiques
(§4.3.11), et dans lequel les 4 régresseurs n’ont pas de problème de colinéarité 
(§4.4.5). 
4.5.2. Différentes méthodes basées sur les sommes de carrés 
t 
 
 
 
 
Méthode FORWARD (ascendante) 
On introduit les variables une par une : on commence par un modèle à une variable,
et on ajoute à chaque étape une variable. Les SSModèle augmentent  forcément (gain) 
et le principe est de faire entrer à chaque pas la variable qui apportera 
l'augmentation la plus significative de la somme des carrés du modèle. Donc, la 
variable qui est introduite est celle qui a SSapporté par j maximum, donc qui possède le 
F le plus grand, et significatif avec une probabilité par défaut associée au F de 0.5 :
ce seuil s'appelle le seuil «pour entrer» SLE de REG. 
Il y a au plus p modèles sélectionnés, qui sont affichés par ordre croissant de k (k=1 
à L, L ≤  p.  
© Revue MODULAD, 2006 - 330-               Numéro 35 
 
 
Méthode BACKWARD (descendante)25
j 
 
M
ison FORWARD/BACKWARD : on effectue une sélection 
 
 
 
On part de la régression à p régresseurs, et on élimine à chaque pas la variable la 
moins significative, c'est-à-dire qu'on élimine la variable ayant SSapporté par 
minimum, c'est-à-dire le F ou le t de Student le plus petit (probabilité par défaut
associée au F de 0.10 : seuil «pour sortir» SLS de REG). 
Il y a au plus p modèles sélectionnés, qui sont affichés par ordre décroissant de k 
(k=p à L, L ≥  1.  
éthode STEPWISE (progressive) 
C’st une combina
FORWARD, en laissant la possibilité de faire sortir du modèle à chaque pas une 
des variables devenue non significative (seuils de probabilité «pour entrer» 0.15, 
«pour sortir» 0.15 par défaut dans REG). 
Remarque : les méthodes FORWARD, BACKWARD et STEPWISE ne donnent
pas forcément le meilleur sous-ensemble à k variables. On peut le voir sur 
l’exemple ci-dessous, extrait de Brenot, Cazes et Lacourly (1975). On considère un 
modèle à 3 régresseurs. La figure 4.6 illustre graphiquement les liaisons dans Rn : 
 
 
Figure 4.6 : représentation géométrique dans Rn de y et x1 x2 x3 
res, et x1, qui n’appartient pas au plan, est 
Les méthodes de sélection donneront les choix successifs : 
BACK
FORW  
1,x 2) ou (x1, x3) Æ (x1, x2, x3) Æ 
   
 
Dans l’espace Rn, y, x1 et x3 sont coplanai
telle que son coefficient de corrélation avec y est le plus fort des coefficients de 
corrélations de y avec les 3 régresseurs.  
La meilleure régression avec 2 variables est donc y=f(x1). La meilleure régression à 
2 variables est donc y=f(x2, x3). 
 
WARD :  (x1, x2, x3)  Æ          (x2, x3)   Æ x2 ou x3 
ARD :         x1  Æ (x1, x2) ou (x1, x3)  Æ (x1, x2, x3) 
STEPWISE :         x1  Æ (x
(x2, x3) 
 
Les modèles à 1 ou à 2 variables trouvés par ces méthodes sont différents, et ne 
sont pas forcément les meilleurs : BACKWARD trouve le meilleur modèle  à 2 
variables, mais pas celui à 1 ; FORWARD et STEPWISE trouvent le meilleur modèle 
à 1 variable mais pas celui à 2 ; la méthode STEPWISE effectue un pas de plus que 
FORWARD. 
 
                                         
25 C’est la méthode réalisée au §4.5.1. 
© Revue MODULAD, 2006 - 331-               Numéro 35 
 
 
Exemples de sélection STEPWISE  
On sélectionne parmi les 10 variables candidates dans les données 
« Processionnaire du pin » issu du livre de Tomassone et al.(1983). 
 
 Tout d’abord, on conserve les seuils par défaut SLE = SLS = 0.15 de la 
méthode. 
 
title 'regression STEPWISE  '; 
proc reg data =libreg.chenilles  ;  
log10 : model log = x1--x10 / selection = stepwise; 
run ; 
quit; 
 
 
© Revue MODULAD, 2006 - 332-               Numéro 35 
 
 
  
 
Résultats : 
La sélection se fait en 4 étapes. A chaque ét
sont données (R², CP, analyse de variance). P
de colinéarité « pathologique », le «Condition Number 
exemple au 4ième pas, Condition Number a une bor
donc on peut soupçonner l’existence d’une co
 
ape, des résultats globaux sur le modèle 
our vérifier si les régresseurs n’ont pas 
» (cf. 4.4.3) est borné : ici par 
ne supérieure très grande (52.20) 
linéarité entre les 4 régresseurs. 
 
 
Le modèle trouvé en 4 étapes est le modèle LOG=f(X9, X1, X2, X3). 
© Revue MODULAD, 2006 - 333-               Numéro 35 
 
 
 
 SLE et SLS à 5% par les options
0.05. 
 
 Puis on fixe les seuils  SLE= 0.05 et SLS = 
title 'regression STEPWISE avec seuils à 0.05  '; 
proc reg data =libreg.chenilles  ;  
log10 : model log = x1--X10 / selection = stepwise SLE = 0.05 
SLS = 0.05; 
run ; 
quit; 
 
Dans ce cas, 2 pas seulement sont effect
 
ués et le modèle est LOG= f(X9, X1). 
 
 
Remarque  
On peut raisonner soit
§4.5.1 et 4.5.2,
 avec les sommes de carrés comme on vient de le faire aux 
 soit avec 
Total
Modèle
SS
SS
²R = , ce qui est équivalent compte-tenu de 
l’équation d’analyse de variance : SSTotale = SSModèle + SSErreurs  
les autres méthodes présentées ci-dessous. 
Amélioration de R² 
 
D’où 
4.5.3. 
 
 2
trouver le meilleur modèle au sens du R² pour chaque valeur k du nombre de 
régresseurs.  
La méthode MAXR commence par choisir la variable donnant le plus grand R² (c’est 
à dire celle qui est la plus corrélée avec Y).  
Puis est ajoutée celle qui provoque la plus grande augmentation du R².  
Une fois ce modèle à 2 variables obtenu, tous les échanges possibles entre une des 
2 variables présentes dans le modèle et une variable extérieure sont examinés, c'est-
Maximum R  Improvement (MAXR) 
C’est une méthode qui procède par étape comme les précédentes. Elle tente de 
© Revue MODULAD, 2006 - 334-               Numéro 35 
 
 
à-dire que le R² de la régression est calculé, et l’échange qui est fait est celui qui 
fou t
La comparaison recommence alors avec 3 variables dans le modèle.  
e processus continue jusqu’à ce qu’aucune permutation n’augmente R². 
que toutes les 
 
 
» variable. En contre partie, MAXR demande évidemment 
p plus de calculs. 
 2
 s’agit du même processus que le précédent sauf que la procédure d’´echange fait 
appel au c
k, le m u 
MAXR
Elles  
 
 
, les modèles sont affichés dans l’ordre décroissant de R² (ou R²adj).  
 
ont pas forcément au 
iveau des données. Aussi il est recommandé d’afficher des critères supplémentaires 
s ci-dessous.  
Il faudra aussi valider les modèles, comme on l’a vu dans ce chapitre aux §4.2, §4.3, 
§4.4. 
4.5.5. Coefficient CP de Mallows 
en 1973, est basé sur la recherche des 
bre de régresseurs et la précision atteinte. 
variances des estimations et «l'erreur 
 variables 
 
rni  l’accroissement maximum de R².   
C
 
E et MAXR est La différence entre les méthodes STEPWIS
permutations possibles sont évaluées dans MAXR avant le changement. Dans
STEPWISE, seul le « moins bon » régresseur est retiré, sans vérifier si on pourrait
a « meilleure ajouter l
beaucou
Minimum R  Improvement (MINR) 
Il
ouple de variables associé au plus petit accroissement du R². L’objectif est 
ainsi d’explorer plus de modèles que dans le cas MAXR et donc, éventuellement, de 
tomber sur un meilleur optimum. 
4.5.4. Autres méthodes basées sur R² : RSQUARE et ADJRSQ 
Ces méthodes ne fonctionnent pas par étapes. Elles affichent pour toute valeur de 
eilleur sous-ensemble de k régresseurs au sens de R² ou R²adj (défini a
chapitre 1 §1.2.5), ce que n'assurent pas les méthodes STEPWISE ou 
/MINR.  
 demandent beaucoup plus de calculs car il faut examiner toutes les
régressions possibles, mais les puissants moyens informatiques actuels rendent
ces méthodes très rapides. 
Pour k=1 à p
Pour limiter le volume des sorties quand le nombre de variables est grand, l’option 
BEST = q limite l’affichage aux q premiers modèles pour chaque valeur de k. 
 
Ceci permet d’explorer rapidement les sous-ensembles de variables, mais les
modèles sélectionnés, optimaux au sens R² (ou R²adj.), ne le s
n
de qualité comme les critères CP, AIC et BIC présenté
Ce coefficient proposé par Mallows 
régresseurs ayant le meilleur pouvoir prédictif, c’est à dire l’erreur totale moyenne 
la plus petite. Il permet ainsi de choisir entre plusieurs régressions différant à la 
fois par le nom
En effet, si on ajoute des régresseurs on diminue, en général, le biais des 
estimations mais on risque d'augmenter les 
totale» moyenne, car on a pu ajouter des variables très liées aux
initialement introduites. 
 
© Revue MODULAD, 2006 - 335-               Numéro 35 
 
 
La précision étant mesurée par MSE ou bien SSE, on calculera le coefficient ainsi : 
 
- Si q < p , CP(q) =[ SSE(q)/MSE] - [n - 2(q + 1)] 
− où SSE(q) = somme des carrés des erreurs de la  régresssion avec q 
régresseurs et constante, 
choisi, l’estimation est sans biais, et alors CP(q) est 
dans  Daniel et Wood (1980). 
 même précision que la régression globale. 
ous-ensembles de régresseurs par ordre croissant 
de CP. 
A par ont le CP 
approche la valeur (p+1): c'est le « me
eurs, il est conseillé de choisir le sous-ensemble de k 
ariables ayant une valeur de CP la plus grande. 
 Information Criterion (1969) :  k2)L(Log2AIC
− et MSE = précision s² calculée avec les p régresseurs (soit  SSE(p)/(n-
(p+1)). 
- Si q = p, alors CP(p) = p+1. 
 
Si le « bon » modèle est 
proche de (q+1) : voir plus de détails 
Dans le cas où CP vaut (p+1), on a la
 
Sélection suivant le coefficient CP 
En plus du R², REG affiche les s
tir du modèle complet, on choisit le premier sous-ensemble d
illeur » sous-ensemble de régresseurs.  
On peut aussi faire le graphique de CP(q) en fonction de q (q=1 à p) et regarder la 
position de l'optimum ainsi que Mallows recommande: 
Utilisation du coefficient CP dans une sélection de régresseurs 
On demande à afficher le coefficient de chaque modèle obtenu par la méthode de 
sélection choisie, en ajoutant l’option CP à l’instruction MODEL de REG. Pour un 
nombre k donné de régress
v
4.5.6. Critères AIC et BIC 
Ces critères ne sont pas des critères de sélection des régresseurs, mais des 
indicateurs de la qualité du modèle. 
De manière générale, ces critères mesurent la qualité d’un modèle statistique bâti sur  
k paramètres sur un échantillon de taille n, à partir de la fonction de vraisemblance L. 
Akaike +−=  
Sawa' 8) : )n(Logk)L(Log2BIC +−=  s Bayesian information criterion (197
Le critère BIC est d’un autre critère utilisé nommé « critère de Schwartz ». 
Dans le cas d’un modèle de régression à p régresseurs avec constante :  
SSE
²snqavecq)3p(2
n
SSELognBIC =++⎟⎠
⎞⎜⎝
⎛=
)1p(2
n
SSELognAIC ++⎟⎠
⎞⎜⎝
⎛=
 
© Revue MODULAD, 2006 - 336-               Numéro 35 
 
 
Ces indicateurs sont utilisés comme la règle habituelle consistant à choisir le modèle 
yant la meilleure précision (SSE petit). 
On
« Processionnaire du pin » issu du livre de Tomassone et al.(1983). On demande 
èles pour chaque nombre de régresseurs par l’option 
EST = 2. 
a
4.5.7. Exemple de sélection RSQUARE 
 sélectionne parmi les 10 variables candidates dans les données 
l’affichage des 2 meilleurs mod
B
 
title 'regression RSQUARE  '; 
proc reg data =libreg.chenilles ;  
log10 : model log = X1--X10 / selection = RSQUARE AIC BIC CP 
BEST = 2 ; 
run ; 
quit; 
 
 
 
© Revue MODULAD, 2006 - 337-               Numéro 35 
 
 
Dans le tableau des modèles, on constate que, parmi les modèles à 4 variables, celui 
qui a le meilleur R², et les plus petites valeurs de AIC et BIC est  Y = f(X1 X2 X4 X5), 
qui est le modèle étudié aux paragraphes §4.2.5, §4.3.11 et §4.4.5. Par contre le 
critère électionné Y = f(X1 X2 X3 X9), qui 
pourra ier : c’est d’ailleurs le modèle final 
 de15 %. 
 CP est plus petit que celui 2ième modèle s
it donc être également un modèle à étud
trouvé par la méthode STEPWISE (§4.5.2) avec les seuils par défaut
© Revue MODULAD, 2006 - 338-               Numéro 35 
 
 
 Conclusion 
Arrivé au terme de ce tutoriel nous voulons insister sur deux points non abordés par 
la technique de la régression : la qualité des données et les difficultés 
d’interprétation. Ces deux points sont du ressort du spécialiste du domaine d’études 
sur lequel le statisticien applique la régression. 
 
La qualité de l'information apportée par les données (observations) intervient dans 
la validité et la robustesse d'un modèle de régression. Mais cette qualité n’est pas 
appréhendable par le statisticien-praticien. 
Ce sont des connaissances externes à la statistique mais internes à l’étude qui 
doivent intervenir. Ces connaissances sont aussi indispensables pour déterminer le 
plan d'échantillonnage. Cette étape qui se situe au niveau de la collecte des données 
et donc en amont de l'analyse statistique des données mériterait à elle seule un long 
développement. 
 
Une fois réglées toutes les difficultés reste un dernier point et non des moindres, 
l’interprétation. Prenons un exemple concret : parmi des enfants, on effectue une 
enquête permettant de mesurer l’étendue du vocabulaire et la taille de leurs pieds. 
La corrélation entre ces deux variables est nettement significative ! Le bon sens 
permet d’éviter d’en tirer des conclusions aberrantes. Sous cette corrélation se cache 
l’influence de la variable âge.  
Autre exemple, dans un état des U.S.A on a corrélé sur les 20 dernières années, le 
taux de criminalité et le taux de fréquentation dans les églises. Là aussi la corrélation 
obtenue est très élevée, mais le bon sens ne vient que peu en aide. La variable 
cachée est l’immigration italienne et irlandaise. 
 
A la lumière de ces deux exemples, gardons-nous de toutes interprétations hâtives. 
 
Avoir toujours à l’esprit que sous une corrélation peut se cacher 
l’effet d’une autre variable, ou d’un autre facteur. 
 
On peut cependant utiliser le modèle identifié, s'il est correct, dans un but de 
prévision mais surtout pas dans un but de "contrôle" (action sur les variables 
explicatives dans l'espoir d'agir sur Y) ou d’explication. Sinon, on pourrait augmenter 
l’intelligence de nos enfants en augmentant la taille de leurs pieds! 
 
L’erreur qui perdure dans la littérature, est de donner le nom de variable dépendante 
ou variable expliquée à Y et de variables indépendantes ou variables explicatives à 
X, ce qui amène à déduire logiquement qu’il existe une idée de cause à effet entre X 
et Y.  « Mécaniquement », ce n’est pas l’objet de la régression. 
 
La régression sur données d’observations ne permet  pas de déduire une 
quelconque relation de cause à effet de X sur Y et/ou de Y sur X. Il faut d’autres 
pratiques méthodologiques pour expliquer la causalité qui peut avoir des formes 
multiples. 
© Revue MODULAD, 2006 - 339-               Numéro 35 
 
 
La liaison entre 2 variables X et Y peut se rencontrer dans 5 situations: 
• X cause Y 
• Y cause X 
• X et Y inter-agissent , problème de circularité, ou de 
rétro-action 
C'est un débat historique qui est de 
l'une sur l'autre
•  X et Y évoluent ensemble sous l'effet d'une même variable 
•  X et Y sont liées par hasard 
 
La causalité peut être validée par “l’outil” régression que si on peut faire des 
omparaisons sur des groupes comparables. c
plus en plus d'actualité. Les économètres tentent de pallier la faiblesse des 
techniques de régression appliquées à des données d’observations, en essayant de 
se rapprocher des techniques expérimentales. Ils ont introduit la méthode des 
variables instrumentales, avec l’idée de pouvoir comparer des individus qui ne 
diffèrent que sur une seule dimension : le traitement. Ils ont également proposé de 
traiter des données issues « d’expériences naturelles » et « d’expériences 
contrôlées », c’est un premier pas vers des interprétations causales (voir BEHAGHEL 
(2006).  
 
Terminons sur ce constat, les méthodes de régression sont des méthodes très 
puissantes, mais qui doivent être utilisées avec beaucoup de discernement et de 
prudence. En toute honnêteté il ne faut pas se contenter d'un seul modèle et d'une 
seule procédure REG, il faut en tester plusieurs.  
 
C'est un travail d'explorateur et de détective. C’est ce que nous avons tenté de 
mettre en lumière. 
 
© Revue MODULAD, 2006 - 340-               Numéro 35 
 
 
ANNEXES 
ANNEXE 1.. .................... 342 
SYNTAXE S 342 
PROC REG options ;................................................................................................................................. 342 
 principal de SAS/INSIGHT.............................................................................................................. 349 
Graphiques standard en SAS/INSIGHT..................................................................................................... 349 
.................................................................... 355 
 
NNEXE 4......................................................................................................................................................... 357 
RELATIONS ENTRE LA LOI NORMALE ET LES STATISTIQUES DE LOIS .................................... 357 
ANNEXE 5......................................................................................................................................................... 358 
CONSTRUCTION D’UN QQ-PLOT.............................................................................................................. 358 
PRINCIPE DE LA DROITE DE HENRY ................................................................................................................. 358 
GENERALISATION............................................................................................................................................ 359 
QQ-PLOT AVEC SAS....................................................................................................................................... 359 
 
...................................................................................................................................
G DE SAS..................................................................IMPLIFIEE DE LA PROCEDURE RE
MODEL dépendante = régresseurs / options ;.......................................................................................... 343 
Instructions BY FREQ ID WEIGHT :........................................................................................................ 344 
REWEIGHT expression / WEIGHT = valeur  ; ......................................................................................... 344 
TEST equation(s) ;..................................................................................................................................... 344 
RESTRICT equation(s);............................................................................................................................. 344 
Options RIDGE et PCOMIT des instructions  PROC REG ou MODEL ................................................... 346 
ANNEXE 2......................................................................................................................................................... 347 
MODE D’EMPLOI TRES SUCCINCT DE SAS/INSIGHT......................................................................... 347 
Le lancement de SAS/INSIGHT ................................................................................................................. 347 
Rôle statistique des variables dans SAS/INSIGHT .................................................................................... 348 
Menu
Les Analyses Statistiques avec SAS/INSIGHT........................................................................................... 351 
Impression et Sauvegarde.......................................................................................................................... 352 
Pour plus d’information sur les graphiques .............................................................................................. 354 
ANNEXE 3.....................................................................................
STATISTIQUES RELATIVES A L’ANALYSE DE LA VARIANCE ........................................................ 355
STATISTIQUES SUR LES PARAMETRES .............................................................................................................. 356 
A
© Revue MODULAD, 2006 - 341-               Numéro 35 
 
 
Annexe 1 
La p
mod
l’étu
 
 
 
 
 
 
 
 
O
Autres options : ALL CORR NOPRINT SIMPLE USSCP 
 
ALL Demande beaucoup d'impressions (induit l'option SIMPLE, USSCP, et 
CORR). 
CORR  Imprime la matrice de corrélation de toutes les variables du modèle.  
NOPRINT Supprime les impressions. 
SIMPLE  Imprime somme, moyenne, variance, écart-type et somme des carrés 
non corrigée pour les variables utilisées dans REG. 
USSCP  Imprime les sommes de carrés non corrigées et la matrice des produits 
croisés pour toutes les variables utilisées dans REG. 
 
PRESS  Permet d’obtenir dans la table OUTEST le coefficient PRESS  
 
RIDGE et PCOMIT  pour les régressions Ridge et sur composantes principales (voir 
à la fin de cette annexe). 
Syntaxe simplifiée de la Procédure REG de SAS 
rocédure REG est une procédure « interactive » permettant d’étudier plusieurs 
èles en un seul appel de PROC REG. On donne ici son utilisation pour 
de d’un seul modèle. 
PROC REG options ; 
  MODEL dépendante = régresseurs / options ; 
  BY nom_var ; 
  FREQ nom_var ; 
 ID nom_var ; 
 WEIGHT nom_var ; 
 REWEIGHT expression / option ; 
RUN ; 
 TEST équation(s) ; 
 RESTRICT équation(s) ; 
  OUTPUT OUT = data_sas mot_clef = nom_var ; 
  PLOT yvar*xvar='symbol' / options ; 
 QUIT ; 
PROC REG options ; 
DATA=NOMTAB  data_set_option  option commune à toutes les procédures 
 
UT   permet de créer des tableaux de résultats utiles, comme les EST = TAB
coefficients estimés, et des résultats créés dans des options. 
 
© Revue MODULAD, 2006 - 342-               Numéro 35 
 
 
MODEL dépendante = régresseurs / options ; 
 : nom de la variable dépendante 
 
régresseurs : liste des noms des p variables régresseurs 
 
Remarque : on peut donner un label à l’instruction MODEL, label qui sera alors 
dépendante
affiché dans les sorties. 
 
Quelques options de l’instruction MODEL: 
 
Sélection de régresseurs 
Option sous la forme  SELECTION =  nom  (où nom est un des mots-clefs de la liste 
ction (choix par défaut) 
ndante  
scendante 
e sur gain maximum/minimum en R² 
r sous-ensemble au sens de R², R² 
P  
iées à SELECTION : 
INCLUDE = n   inclure les n premières variables explicatives dans les modèles 
il de significativité pour entrer  
SLS = valeur  seuil de significativité pour rester 
on a
  (avec s < p); STOP = p par défaut. 
 
ttention aux valeurs par défaut des seuils :  
LS = 0.10 en BACKWARD  et SLS = 0.15 en STEPWISE 
Remarque : les différentes valeurs du critère de sélection choisi sont stockées dans 
ante  
 
ci-après) : 
 
séleNONE     pas de 
FORWARD    sélection asce
BACKWARD   sélection descendante 
 sélection progressive aSTEPWISE   
MAXR, MINR  sélection basé
RSQUARE, ADJRSQ  sélection du meilleu
justé a
 Mallows C    sélection basée sur CP de
 
Autres options assoc
explorés (n<p) 
SLE = valeur  seu
STOP = s    arrête l'explorati u meilleur sous-ensemble de s variables 
 
BEST = k  arrête l'exploration après k modèles. 
A
SLE = 0.50 en FORWARD et SLE = 0.15 en STEPWISE 
S
 
la table OUTEST, où on trouve aussi les  2 variables :   
_IN_  nombre de régresseurs hors const
_P_  nombre de régresseurs y compris la constante si elle existe dans le modèle 
Autres options de l'instruction MODEL: 
 
éfinir un modèle sans constante : NOINT  
fficher: 
D
 
A
− des résultats complémentaires pour les observations : 
© Revue MODULAD, 2006 - 343-               Numéro 35 
 
 
− P (prévisions) CLI CLM (intervalles de prévision à 95 % individuels et sur la 
moyenne) R(résidus) INFLUENCE (indices de détection des observations 
CP (Cp de Mallows), BIC, AIC, etc.; 
 II) 
:  SPEC (et ACOV) 
− colinéarité:     TOL VIF et COLLIN COLLINOINT 
 WEIGHT :  
s instructions communes à toutes les procédures. En particulier, WEIGHT 
e dé nir un  régre
ne 
tion de la régression. 
xpression  est une comparaison sur une variable (on peut utiliser la variable 
méro de l'observation), 
r  
l'expression . 
 on écrit  
 sur les estimations des 
). Chaque équation 
TEST X3-X4 = 0 ;                     tester (β3= β4) 
, avec des équations 
ide
 
 
influentes) 
− des coefficients: DW (Durbin-Watson), 
− les sommes de carrés SS1 SS2 (carrés de type I ou
  
Diagnostiquer des problèmes particuliers: 
− heteroscédasticité
Instructions BY FREQ ID
Ce sont de
permet d fi e ssion pondérée. 
REWEIGHT expression / WEIGHT = valeur  ;  
Cette instruction permet de redéfinir les poids, et en particulier d'omettre u
observa
 
e
OBS.  qui contient le nu
WEIGHT = valeu donne cette valeur de poids aux observations vérifiant 
 
Exemple :   pour supprimer l'observation numéro 20,
      REWEIGHT obs. = 20 / WEIGHT = 0 ; 
TEST equation(s) ; 
Cette instruction permet de tester une ou des hypothèses
aramètres (les équations doivent être séparées par des virgulesp
est une fonction linéaire formée de coefficients et de noms de variables (ici, 
INTERCEPT est le nom de la constante).  
 
Exemples:  TEST X1 = 0 , INTERCEPT = 0 ;  tester (β1=0) et (β0=0) 
RESTRICT equation(s); 
Elle permet de fixer des contraintes sur les coefficients
ntiques à TEST. 
© Revue MODULAD, 2006 - 344-               Numéro 35 
 
 
Exe p
 
OU
Ce S contenant certaines 
s variables créées par la régression. Ce tableau contiendra aussi les variables du 
 
Lis d  pou ssion  
(ces mots_clefs sont utilisables aussi pour les instructions PLOT et PRINT, sauf 
PRESS): 
e prédite  
STDI   écart-type de la valeur prédite 
 
STDR  écart-type du résidu 
levier 
O
Cette instruction permet de tracer des graphiques en désignant les variables 
ordonnée Yvar et abscisse Xvar, et le symbole associé. 
nt possibles pour définir les caractéristiques des graphiques 
(cf. la documentation SAS). 
le  P. ou  R. 
n peut aussi utiliser la variable OBS. pour désigner le numéro de l’observation. 
Remarque : l’option RIDGEPLOT permet de tr cer le fficients RIDGE 
(voir plus loin la description de l’option RIDGE). 
 
m le: RESTRICT X1-X3 = 0 ;    modèle avec contrainte (β1= β3) 
TPUT OUT = nomtab mot_clef = nom_var ; 
tte instruction permet de créer un tableau de données SA
de
modèle (réponse et régresseurs). 
te es mots_clefs r les variables créées par la régre
 
PREDICTED (ou P) valeur prédite 
L95M U95M limites des intervalles à 95% sur la moyenne des valeurs prédites 
L95 U95  limites des intervalles à 95% sur une valeur prédite 
STDP  écart-type de la valeur moyenn
RESIDUAL (ou R) résidu 
NQQ  quantile normal (pour le dessin QQPLOT) 
STUDENT   résidu studentisé interne  
STUDENT  résidu studentisé externe R
 
H   
PRESS  coefficient Press (individuel) 
COOKD DFFITS C VRATIO   mesures d'influence des observations 
 
PLOT  Yvar1*Xvar1='s'  Yvar2*Xvar2='s'  / options ; 
 
Différentes options so
 
Attention : on peut utiliser une des variables créées par la régression, définies plus 
haut dans la liste des mots-clefs de l’instruction OUTPUT, à condition de faire 
suivre son nom par un point : par exemp
O
 
a  dessin des coe
PRINT mots-clefs; 
Cette instruction permet d'imprimer certaines des variables créées avec la liste des 
mots-clefs vue plus haut. 
© Revue MODULAD, 2006 - 345-               Numéro 35 
 
 
Options RIDGE et PCOMIT des instructions  PROC REG ou MODEL 
On peut effectuer une régression Ridge ou 
principales, par une option de PROC REG ou d
une régression sur composantes 
e MODEL. La procédure travaille 
te de valeurs qui peut être définie par la syntaxe  
kd to kf by p, où l’intervalle de variation du coefficient ridge est 
leur donne une estimation des coefficients Ridge, qui est placée dans une  
ble SAS à définir avec l’option OUTEST = table de PROC REG. La colonne 
e on a employé : pour la méthode Ridge, 
riable 
Ridge de chaque 
ur. 
  k est un entier positif ou nul.  
édur aramètres estimés en utilisant les composantes 
 des coefficients est placée 
on OUTEST = table  de PROC REG, avec ici  
ar ue : k peut aussi être une liste d’entiers non négatifs, pour permettre de faire 
utres options de PROC REG tilisables en association avec les options RIDGE 
 RIDGE 
UTVIF pour avoir les Variance Inflation Factor des coefficients.  
par 
option RIDGE = liste) est obtenu par l’instruction PLOT avec l’option RIDGEPLOT, à 
PLOT / RIDGEPLOT ; 
alors sur les données centrées (l’option NOINT est ignorée).  
 
RIDGE = liste  liste est une lis
[kd,kf], la variation se faisant par pas de p.  
 
Chaque va
ta
_TYPE_ indique quelle méthod
_TYPE_=RIDGE, et les valeurs de la liste sont stockées sous le nom de va
_RIDGE_. On trouve ensuite les valeurs des coefficients 
régresse
 
PCOMIT = k 
 
La proc e calcule alors les p
principa  l’exclusion des k dernières ; L’estimationles à
dans une table SAS à définir avec l’opti
_TYPE_ =  IPC. 
 
Rem q
plusieurs ais d’élimination de composaness tes. 
 
A
et PCOMIT : 
 
OUTSTB pour avoir les estimations standardisés des coefficients estimés par
ou IPC ; 
 
OUTSEB pour avoir les erreurs standardisées des coefficients ; 
 
O
 
Dessin « Ridge Trace » 
 
Le dessin des coefficients Ridge en fonction des valeurs du paramètre (définies 
l’
condition que les coefficients soient stockés dans une table par l’option OUTEST. On 
écrit alors simplement  l’instruction : 
© Revue MODULAD, 2006 - 346-               Numéro 35 
 
 
Annexe 2 
Mode d’emploi très succinct de SAS/INSIGHT 
Le module de SAS  Il 
ermet de faire de nalyse confirmatoire 
/Insight est à la fois un tableur un grapheur et un analyseur.
l’Analyse Exploratoire des Données et de l’ap
dans l’esprit de TUKEY. Il est particulièrement bien adapté à la régression linéaire 
couplée à l’AED, grâce à ses possibilités de visualisation et d’interactivité. 
 
Tableau des Grandes Fonctions de SAS/INSIGHT 
 
 
Nous ne présentons que quelques manipulations essentielles de SAS/INSIGHT. 
U S. & LE GUEN M.. 
e lancement de SAS/INSIGHT 
Pour une présentation plus complète voir l’ouvrage de DESTANDA
L
Î dans la barre de commande de SAS, taper : INSIGHT puis entrée  
 
 
 
1. Si la table de données n’existe pas encore  
Dans la boîte de dialogue, cliquer sur le bouton-poussoir New 
 
© Revue MODULAD, 2006 - 347-               Numéro 35 
 
 
 
Boîte de dialogue de SAS/INSIGHT 
 
Un tableau de données vide s’ouvre. Saisissez vos données. 
 
 
 Si la table existe 
te de dialogue sélectionner la bibliothèque : « Library » et la table SAS 
 », et cliquer sur le bouton Open. 
Affichage de la table SAS dans un tableur (cf. ci-dessous écran à gauche) et menu 
déroulant (cf. écran à droite). 
 
2. 
Dans la boî
« Data set
 
 
 
 
 
et 20 observations indiqué par La Table TAILPOID a 3 variables . 
En cliquant sur la petit flèche en haut à gauche le menu déroulant –pop menu ou 
eur. 
Rôle statis
ans SAS/INSIGHT toute variable SAS définit en caractère est forcément une 
ar ique n’est pas nominale, elle est 
chelles de mesures 
dessus du nom de la 
ariable  
 
encore menu contextuel- s’affiche avec les actions possibles sur le tabl
tique des variables dans SAS/INSIGHT 
D
v iable nominale. Par défaut une variable numér
d’intervalle. C’est à l’utilisateur de choisir le type d’é
Interval/Nominal) souhaité, en cliquant et cochant la zone au (
v
© Revue MODULAD, 2006 - 348-               Numéro 35 
 
 
 
 
e rôle statistique déterminera les types de graphiques à 1 dimension, 2 dimensions 
Menu prin
C
ou 3 dimensions et les types d’analyses.  
cipal de SAS/INSIGHT 
 
• Graphiques pour les variable nominales : Bar Chart (1D) , Mosaic Plot (1D)  
• Graphiques pour les variables d’intervalle 
 ou 
C’est un principe général dans SAS/INSIGHT.  
 
Graphiques standard en SAS/INSIGHT 
: Histogram (1D) , Box Plot (1D) , 
Line Plot(2D), Scatter Plot (2D) , Contour Plot (3D), Rotating Plot (3D). 
 
Pour réaliser un graphique il y a 2 possibilités : en utilisant les options par défaut,
en passant par une boîte de dialogue pour modifier les options par défaut.  
Choix 1 – avec options par défaut 
 
L’affichage est immédiat  avec les options par défaut. 
 
Dans le tableur :  
Î Cliquer sur le nom de la variable d’intervalle Y 
Î menu : Analyze# Box Plot/Mosaic Plot(Y) 
 
© Revue MODULAD, 2006 - 349-               Numéro 35 
 
 
 
 
Sur le graphique, en c  
Means, 
ajouter les valeurs des
 
Choix 2 – avec options
liquant sur la flèche en bas à gauche un menu déroulant
s’affiche pour modifier les options. Par exemple, ajouter la moyenne avec 
 quantiles avec Values etc.  
 modifiables 
: Analyze# Box Plot/Mosaic Plot(Y) 
 
Î menu 
 
 
ffiche sélectionner la variable Y (dans la liste à 
gauche) puis cliquer sur le bouton-poussoir Y, pour que la variable choisie Y soit 
sélectionnée. Les boutons poussoirs Method et Output permettent de modifier les 
option
 
 
Dans la boîte de dialogue qui s’a
s par défaut. 
© Revue MODULAD, 2006 - 350-               Numéro 35 
 
 
Pour plus d’information sur les graphiques voir les articles en ligne 
sites internet donnés en fin de cette annexe (page 354) 
yses Statistiques avec SAS/INSIGHT 
yze # Distribution 
Etude d’une distribution (équivalent à Proc Univariate) 
yze # Fit Ä Analyse de régression linéaire, GLM , Régression 
logistique, Probit, Logit, ANOVA 
yze # Multivariate Ä Analyse en Composantes Principales, Analyse 
 Analyse discriminante. 
Même principe que pour les graphiques : 
Soit on sélectionne la ou les variables puis le menu Analyze #.
ont réalisées avec les options par défaut, 
Soit on choisit le menu Analyze #.... , une boîte de dialogue s’affiche pour 
sélectionner la ou les variables, et choisir les nouvelles options. 
sur les 
Les Anal
Î menu : Anal
    
 
Î menu : Anal
 
Î menu : Anal
canonique,
 
- .... Les 
analyses s
- 
 
 
 
 
 
Exemple de Régressi
du pin du §2.3.1.) 
 
 
 
 
 
 
 
 
on linéaire sur la Table SAS : Chenille (processionnaire 
 
 
© Revue MODULAD, 2006 - 351-               Numéro 35 
 
 
Ä Sélectionner dans la liste de gauche la variable Réponse (Log) puis cliquer sur le 
bouton de rôle Y, idem pour les variables régresseurs (X4,X2,X4,X5), en cliquant sur 
le bouton de rôle X. Si on veut la constante 1 (0) dans le modèle, cocher Intercept. 
 
ÄCliquer sur le bouton poussoir Method : 
 
 
Pou  la
 
• 
• Link Function
• Scale : MLE 
pression et Sauvegarde  
ous présentons seulement quelques possibilités, pour imprimer un ou des éléments 
ffichés, puis les sauvegarder dans un fichier externe, et enfin les insérer dans un 
ocument Word. 
our imprimer 
Sélectionner avec la souris, le graphique ou le tableau à imprimer, ou choisir  
our sauvegarder les résultats graphiques ou tableaux dans un fichier 
Ä
ou choisir  
Menu : 
Î 
 exemple le format .bmp et en 
 
 
r  régression linéaire les options à cocher sont : 
Response Dist : Normal 
 : Canonical 
Im
N
a
d
P
Ä
Menu : Edit# Windows # Select all pour sélectionner tous les éléments affichés 
Ä File # Print 
P
Sélectionner avec la souris la bordure du graphique ou le tableau à sauvegarder, 
Edit# Windows # Select all pour sélectionner tous les éléments affichés 
File # save # Graphics File…  
puis renseigner la boîte de dialogue en choisissant par
suffixant le nom du fichier par .bmp (SAS ne le fait pas). 
 
 
© Revue MODULAD, 2006 - 352-               Numéro 35 
 
 
 
Le fichier sera sauvegardé dans le répertoire courant qui est affiché en bas de 
l’écran de SAS  
 
our modifier l’
répertoire (fenêtre 
 
Dans un document Word : ….. 
 
 
P emplacement, il suffit de double cliquer dessus et de changer le 
Change Folder). 
Pour insérer un fichier externe .bmp dans Word  
Î insertion # image # à partir d’un fichier
© Revue MODULAD, 2006 - 353-               Numéro 35 
 
 
Pour plus d’information s
ESTANDAU S., LADIRAY D., M. LE GUEN, (1999), « AED mode d’emploi », Courrier des 
ur les graphiques  
Consulter les articles en ligne sur les sites internet : 
 
 
D
Statistiques, INSEE, n° 90, http://www.insee.fr/fr/ffc/docs_ffc/cs90e.pdf 
 
LE GUEN M. (2001), La boîte à moustaches de Tukey, un outil pour initier à la 
Statistique, Statistiquement Vôtre, n° 4, 14 pages.   
http://matisse.univ-paris1.fr/leguen/leguen2001b.pdf 
 
LE GUEN M. (2004), « L'Analyse Exploratoire des Données et SAS/Insight, 
Visualisation Dynamiques des Données », Cahiers de la Maison des Sciences 
Economiques, Matisse, Série rouge, n°2004.01,13 pages,  
ftp://mse.univ-paris1.fr/pub/mse/cahiers2004/R04001.pdf  
 
CONFAIS J. &  LE GUEN M., (2003), Graphiques conventionnels et Graphiques moins 
conventionnels. Importance de la visualisation Interactive, Document de travail 
ISUP-MATISSE, n°2003, 21 pages. 
http://matisse.univ-paris1.fr/doc2/leguen1490.pdf 
© Revue MODULAD, 2006 - 354-               Numéro 35 
 
 
Annexe 3 
Statistiques relatives à l’analyse de la variance 
Statistique Formule Signification 
Mean 
Square 
 
  
DF 
 =MS  • pour SS error  DF=n-p-1 
La statistique Mean Square Error donne 
 
SS
C’est le rapport d’une somme des carrés des 
egrés 
). 
vraie valeur inconnue de 
la variance des erreurs σ2. 
écarts (SS) divisée par le nombre de d
de liberté (DF
• pour SS model DF=p 
l'estimation s² de la
F Value ErrorMS
ModelMSF =  Statistique de Fisher-Snedecor pour tester si 
tous les paramètres β sont nuls. 
Prob>F )ddf,ndf,Value F(Probf  
alue ou niveau de significativité du 
test,  associée à F Value. La p-value est 
calculée en utilisant la fonction SAS : Probf. 
Probf : fonction SAS de la fonction de 
répartition d'une variable de Fisher-Snedecor 
ndf : nombre de degrés de liberté du 
numérateur de F Value 
ddf : nombre de degrés de liberté du 
dénominateur de F Value. 
C'est la p-v
Root MSE ErrorMS  
Standard Deviation, soit l’écart moyen 
résiduel. 
C’est l’estimation de "s", l’écart-type des 
erreurs 
R-square 
totalSS
ErrorSSTotalSS
TotalSS
ModelSS2R
−=
==
 
F et Rsquare (R²) sont liés par la relation
 
Rsquare1
Rsquare
p
1pnF −∗
−−=
 
Dep Mean ∑== n,1i i n/YY  moyenne de la variable réponse Y 
© Revue MODULAD, 2006 - 355-               Numéro 35 
 
 
  Formule Signification Statistique
Adj R-sq 
pn −
constante
))2R1)(interceptn((1 −−−
R2 ajusté en fonction du nombre de régresseurs 
du modèle. Intercept=0 s'il n'y a pas de 
26 sinon intercept =1. 
CV 100Dep
MSERoot ∗=  Coefficient de variation exprimé en % Mean
Statistiques
Pour chaque paramètre  donne  tre avec son erreur-
type, le test de l’hypothèse nulle ( 0i
 sur les paramètres 
βj, SAS  : l’estimation du paramè
=β ) et la p-value associée. 
Remarque : La variable notée Intercep 1.  
 
Statistique Formule Signification 
t correspond à la variable constante X0 =
Estimate )Y'(b*)X'X( =
 
solution de : 
X  estimation du paramètre βj
Standard Error MSE.)XX( 1ii
−′  
erreur-type de l’estimateur du 
paramètre βj calculé à partir du jième  
élément de la diagonale de la matrice 
1)XX( −′  
T for H0 : 
Parameter=0 EstimofErrorStd
EstimateT =
ate
H
statistique T de Student pour tester 
l’hypothèse nulle: 
H0 : paramètre βj =0  contre 
a : paramètre βj ≠0 
Remarque 
partielvalueFT2 =  
 
Prob  > !T! 
La p-value est calculée en utilisant la 
fonction SAS : Probt. 
e 
)df,T(Probt  
C'est la p-value ou niveau de 
significativité du test de Student. 
Probt : fonction SAS de la fonction d
répartition d'une variable de Student à  
df (Degree of Freedom) degrés de 
liberté. 
 
                                            
26 S'il n'y a pas de constante b0 à l'origine, les statistiques relatives à l'analyse de la variance n'ont pas la même 
interprétation. 
© Revue MODULAD, 2006 - 356-               Numéro 35 
 
 
Annexe 4  
Relations entre la loi n t de lois 
d
 
 
ormale e  les statistiques 
Chi2, T de Stu ent et F de Fisher-Snedecor 
Normale     si X   ~ N(0,1) 
 
Chi2    alors 2XZ =   suit une loi de 2χ à 1 degré de liberté (ddl) 
    et  ∑= 2iXZ
= n,1i
   suit 2χ  à  n ddl, si les iX  so un  nt indépendants et  
N(0,1) 
 
T de Student à n ddl 
 
Si Z suit une loi de χ t ind2  à  n ddl  et si Z es épendant de X 
 
alors   
n
XT =
Z
 suit u t à n dne loi de Studen dl. 
 
F de Fisher-Snedecor 
 
Si  so  une une loi  Z1 et Z2 nt des variables aléatoires indépendantes suivant chac
de  
2  χ  à  ν1 et ν2  ddl  
 
 alors 
2
2
1
1
Z
Z
F
ν
ν=    suit une loi de Fisher-Snedecor à ),( 21 νν  ddl. 
 
 
© Revue MODULAD, 2006 - 357-               Numéro 35 
 
 
Annexe 5 
Construction d’un QQ-Plot 
Ce graphique perm ns le cas de la loi 
normale, il est appelé « droite de Henry » 
rincipe de la droite de Henry 
ose de n observations de X : (x i ) pour i =1 à n .  
n de répartition empirique en (x i ) : 
et une visualisation de l’adéquation à une loi. Da
P
1. Soit une variable X dont on veut vérifier l’adéquation à une loi normale 
(m,σ ) 
On disp
  
On note F(x i ) la fonctio
 
( ) ( ) ⎟⎟⎠
⎞
⎜⎝ σ
≤σ=≤= probxXprobxF ii ⎜
⎛ −− mxmX i  
Soit φ  la fonction de répartition de la loi normale (0,1) : on peut trouver une valeur ui 
de même fonction de répartition : 
 
( ) ( ) ( )( )i1iiii xFuxFuquetelu −φ=⇔=φ∃ . 
σ
 
2. Si X suit une loi normale (m, ) alors : 
( ) ( )
( )( ) σ
−=⎟⎟⎠
⎞
⎜⎜⎝
⎛ ⎟⎠
⎞⎜⎝
⎛
σ
−φφ=φ=⇒
⎟⎠
⎞⎜⎝
⎛
σ
−φ=⎟⎟⎠
⎞
⎜⎜⎝
⎛
σ≤σ
−=≤=
−− mxmxxFu
mxmxmXprobxXprobxF
ii1
i
1
i
ii
i
−
i
 
 
Donc les points (xi, ui ) sont alignés sur la droite d’équation ui  = (xi - m) / σ . 
 
En pratique, on ordonne les valeurs xi  : on note x(i)  les valeurs 
ordonnées. 
Bien sûr, on a alors F(x(i) ) = i /n . 
 
3. 
Le « nuage de points » à représenter est donc défini ainsi : [ui  = φ  -1 (i/n) ; x(i) ] 
 
Attention : pour  faire les mêmes représentations que SAS, on mettra les valeurs de X en ordonnées. 
 
© Revue MODULAD, 2006 - 358-               Numéro 35 
 
 
La droite d’équation Y = (X-m)/σ est celle dont les points du nuage doivent se 
rapprocher en cas d’adéquation à la loi normale : on la représente donc également 
e plan. 
Remarque : Proc UNIVARIATE du module SAS/Base, ainsi que le menu « Distribution » de SAS-
INSIGHT, utilise un calcul légèrement différent de celui exposé ici :  
On cherche 
sur le mêm
⎟⎟⎠
⎞
⎜⎜⎝
⎛
+
−φ= −
4
1
8
3
i1
i n
ru  n général). 
Généralisation   
n à une autre loi que la loi normale, il suffit de 
connaître la fonction de répartition G de cette loi, et que celle-ci soit inversible. 
place alors φ  par G dans les formules du §2. 
SAS permet de représent  
 
e). 
ans SAS/INSIGHT, on les trouve dans le menu « Distribution », rubrique 
roite de référence, dans le menu 
Lorsque l’on a exécuté une », on peut ajouter 
aux sorties » dans le 
menu « Graphs » dans le menu contextuel du 
graphique pour tracer
  où ri est le rang de l’observation i (ri = i  e
Ceci permet en particulier de ne pas « perdre » les points extrêmes. 
Si on veut visualiser l’adéquatio
 
On rem
QQ-Plot avec SAS 
er des QQ-Plot pour les lois suivantes :
Normale, LogNormale, Exponentielle et Weibull. 
 
Dans le module SAS/Base, la procédure UNIVARIATE possède une instruction
QQPLOT (voir la documentation SAS pour son utilisatio x
 
n un peu comple
D
« Graphs » Æ « QQ-Plot ». Pour tracer la d
« Curves » demander « QQ ref line ».  
 régression linéaire avec le menu « Fit 
 standards un graphique QQ-Plot appelé « Residual Normal QQ 
» (penser à cocher « Reference lines 
 la droite). 
© Revue MODULAD, 2006 - 359-               Numéro 35 
 
 
Bibliographie 
AKAIKE, H., (1969), « Fitting Autoregressive Models for Prediction», Annals of the 
 en Statistique 
en 1945
ANSCOMBE F., « Graphs in Statistical Analysis », The American Statistician ; February 
1973, Vol.27, n°1, p17-21. 
Lire l’économétrie, Collection Repères, Editions La Découverte. 
 
J.P., B F., (1989), « Calculs de corrélation entre variables et 
e données, 1989, n° 3, pp347-
354. 
 
 LACOURLY N. ,(1975) « Pratique de la régression : Qualité et 
protection », cahiers  du BURO n° 23, pp 1-81 
raintes linéaires 
t non linéaires » éro 3. 
rican Statistical Association, Vol. 74, pp. 829-836. 
 
CLEVELAND W. S., (1993), Visualizing Data , Hobart Press, Summit, New Jersey, USA 
1993.  
 
CLEVELAND W. S., (1994), The Elements of Graphing Data, Hobart Press, Summit, 
New Jersey, USA 1994. 
 
CONFAIS J., LE GUEN M., (2003), « La régression linéaire sous SAS », Document de 
travail n°F9605 de la Direction des Statistiques Démographiques et Sociales de 
l’INSEE  
 
CONFAIS J.,  LE GUEN M., (2003), « Graphiques conventionnels et Graphiques moins 
conventionnels. Importance de la visualisation Interactive », Document de travail 
ISUP-MATISSE, n°2003, 21 pages. 
http://matisse.univ-paris1.fr/doc2/leguen1490.pdf
Institute of Statistical Mathematics, 21, 243 - 247.  
ARMATTE M stoire du modèle linéaire, Formes et Usages
et Econométrie jusqu' », Thèse de Doctorat, EPHE le 24/01/1995 
., (1995), « Hi
 
 
BEHAGHEL L. ,(2006), 
BELSLEY D.A., KUH E., WELSH R.E,. ,(1980), Regression diagnostics, Wiley.  
 
BENZECRI  ENZECRI 
juxtaposition de tableaux », Les cahiers de l'analyse d
BRENOT J., CAZES P .,
 
CAZES P., (1975), « Protection de la régression par utilisation de cont
, Revue de Statistique Appliquée, volume XXIII, nume
 
CAZES P., (1976), « Régression par Boule et par l'Analyse des Correspondances », 
evue Statistiques Appliquées, Vol XXIV n°4, pp5-22. R
 
CHATTERJEE S., HADI A. S., (1988), Sensitivity analysis in linear regression, Wiley. 
 
CHOW, G.C., (1960), «Tests of Equality between Sets of Coefficients in Two Linear Regressions», 
Econometrica, 28, 591-605.  
 
CLEVELAND W. S., (1979), «Robust Locally Weighted Regression and Smoothing 
Scatterplots», Journal of the Ame
 
 
© Revue MODULAD, 2006 - 360-               Numéro 35 
 
 
COOK R.D., WEISBERG S., (1994) ion to Regression Graphics», Wiley 
Series in Probability and Statistics. 
 Plain Liars—New Graphical EDA 
+ (EDA Plus) Techniques for Understanding Data », SUGI 26, SAS. 
, « An Introduct
 
DESJARDINS D., (1998), « Outliers, Inliers, and Just
 http://www2.sas.com/proceedings/sugi26/p169-26.pdf 
 
DESTANDAU S., LE GUEN M., (1995), Analyse exploratoire des données avec 
ohn Wiley & Sons, Inc.  
ESROSIERES A., (1993), La politique des grands nombres, histoire de la raison 
NDAU S., LADIRAY D., M. LE GUEN, (1999), « AED mode d’emploi », Courrier des 
tatistiques, INSEE, n° 90, http://www.insee.fr/fr/ffc/docs_ffc/cs90e.pdf
SAS/INSIGHT, INSEE GUIDES N°7-8. 
 
DANIEL, C.,WOOD, F. ,(1980), Fitting Equations to Data, Revised Edition, New York: 
J
D
statistique, Editions la Découverte  
 
DESTA
S  
n analysis, Wiley. 
du département des études 
conomiques d’ensemble de l’INSEE. 
RKEL-ROUSSE H., (1995), « Détection de la multicolinéarité dans un modèle linéaire 
es Appliquées, volume XLIII, numéro 4. 
. 
tp://www.
 
DRAPER N.R., SMITH H., (1966), Applied regressio
 
ERICKSON B.H. & NOSANCHUK T.A., (1995-2d édition), Understanding Data, Open 
Université Press, 381 pages. 
 
ERKEL-ROUSSE H., (1990), «Détection et effets de la multicolinéarité dans les modèles 
linéaires ordinaires », Document de travail n° 9002 
é
 
E
ordinaire: quelques éléments pour un usage averti des indicateurs de BELSEY, KUH ET 
WELS », Revue Statistiqu
 
FOUCART F., (2006), « Colinéarité et régression linéaire », Math. & Sciences. 
Humaines, ~ Mathematics and Social Sciences, 44e année, n° 173, 2006(1), p. 5-25
ht ehess.fr/revue-msh/pdf/N173R963.pdf 
 
FOUCART F., (2007) « Evaluation de la régression bornée » en cours de publication 
ns la Revue des Nouvelles Technologies de l'Informda ation. Article consultable sur le 
site : http://foucart.thierry.free.fr/colreglin/Regression_bornee.pdf 
 
FR .J  ITTE .C., (1991), SAS System for regression, 2nd edition, SAS-
Editor. 
 
GALTON F
EUND R ., L LL R
., (1886), «Regression towards mediocrity in hereditary stature», Journal of 
e Anthr g al Inth opolo ic stitute 15 (1886), p246-263. 
 http://www.stat.ucla.edu/history/regression.gif 
 
Greene W., (2005), L’Econométrie, Pearson Education », 5ème Edition 
© Revue MODULAD, 2006 - 361-               Numéro 35 
 
 
HOERL A.E., KENNARD R.W., (1970), «Ridge Regression: (1) biased estimation for 
nonorthogonal problems ; (2) applications to nonorthogonal problems», 
echnometrics, 12, pp. 55-67; pp. 68-82. 
ADIRAY D., (1990), « Autopsie d'un résultat : L'exemple des procédures Forecast, 
ADIRAY D.,(1997 et suivantes), « Analyse Exploratoire des données », Cours 
polycopié de l’ENSAE. 
 boîte à moustaches de TUKEY, un outil pour initier à la 
Statistique », Statistiquement Vôtre, n° 4, 14 pages.   
T
 
INDJEHAGOPIAN J.P., (1993), «Cours d'économétrie», polycopié ISUP. 
 
L
X11, Cluster », Club SAS 1990  
 
L
 
LE GUEN M., (2001), « La
http://matisse.univ-paris1.fr/leguen/leguen2001b.pdf 
 
LE GUEN M., (2004), « L'Analyse Exploratoire des Données et SAS/Insight, 
p://mse.univ-paris1.fr/pub/mse/cahiers2004/R04001.pdf
Visualisation Dynamiques des Données », Cahiers de la Maison des Sciences 
Economiques, Matisse, Série rouge, n°2004.01, 13 pages,  
ft  
ALINVAUD E., (1966), Méthodes Statistiques de l'économétrie, Dunod  
s de l’imprécis, Seuil  
ALM R., IEMMA A.F., (1995), « Quelques alternatives à la régression classique dans 
ression and outlier 
etection, Wiley. 
.A.S , (1981), Technical Report A102, SAS Regression Applications 
.A.S , (1991), FREUND R.J., LITTELL R.C., SAS System for regression, (2ème édition) 
Y O., (1995), La Statistique Descriptive avec le Système SAS, INSEE 
UIDES numéros 1-2. 
ating Among Alternative 
 1282. 
ic Approach, 
Springer-Verlag 
 
 
M
 
MOLES A., (1990), Les science
 
NETER J., WASSERMAN W., KUTNER M. H., (1990), Applied Linear Statistical Models, 
Irwin 3ème Edition 
 
P
le cas de la colinéarité », Revue Statistiques Appliquées, volume XLIII, numéro 2. 
 
ROUSSEEUW P.J., LEROY A.M., (2003 -2ième edition), Robust reg
d
 
SAPORTA G., (2006), Probabilités, analyse des données et statistique, Technip. 
 
S
 
S.A.S , (1990), Stat User's Guide version 6  
 
S
 
SAUTOR
G
 
SAWA, T., (1978), «Information Criteria for Discrimin
Regression Models», Econometrica, 46, 1273 -
 
SAVILLE J.D., WOOD G. R., (1990), Statistical Methods: The Geometr
© Revue MODULAD, 2006 - 362-               Numéro 35 
 
 
SEN A., SRIVASTAVA M., (1990), Regression Analysis, Theory, Methods, and 
Applications, Springer-Verlag 
 
STIGLER S. M. ,(1986), The history of Statistics, The measurement of uncertainly 
ENENHAUS M., (1998), La  régression PLS : Théorie et pratique, Editions Technip. 
J. P., MENARDO C., (1995) «Régression PLS et applications», 
.S.A., volume XLIII, numéro 1. 
ection via the lasso», J. Royal. 
ttp://www-stat.stanford.edu/~tibs/lasso/lasso.pdf
before 1900, The Belknap Press of Harvard University Press. 
 
TENENHAUS M., (1994), Méthodes statistiques en gestion, Dunod-Entreprise.  
 
T
 
TENENHAUS M., GAUCHI 
R
 
TIBSHIRANI R., (1996), «Regression shrinkage and sel
Statist. Soc B., Vol. 58, No. 1, pages 267-288,  
h  
n, 2è édition. 
OMASSONE R., DERVIN C., MASSON J. P., (1993), Biométrie, modélisation de 
, Addison Wesley Publishing 
ompany, Reading, Massachusetts. 
onometrics, volume 48, pages 817-838 
U CH. H0, animation sur le problème des multicolinéarités, http://www.creative-
 
TOMASSONE R., ANDRAIN S., LESQUOY E., MILLIER C., (1992), La Régression Nouveaux 
regards sur une ancienne méthode statistique, INRA-Masso
 
T
phénomènes biologiques, Masson.  
 
TUKEY J.W., (1977), Exploratory Data Analysis
C
 
WHITE H., (1980), Ec
 
WOOLDRIDGE J.M., (2000), Introductory Econometrics : A Modern Approach, South 
Western 
 
WONNACOTT T.H., WONNACOTT R.J., (1991), Statistique, 4ème édition, Economica.  
 
Y
wisdom.com/multimedia/collinear.html, puis cliquer sur PC Version (17 megas) pour 
écharger la vidéo.  d
 
© Revue MODULAD, 2006 - 363-               Numéro 35 
 
 
