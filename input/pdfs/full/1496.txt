Une raison pour ne pas abandonner
les tests de signification de l’hypothe`se nulle
Bruno Lecoutre1, Jacques Poitevineau2, Marie-Paule Lecoutre3
1 ERIS, Laboratoire de Mathe´matiques Raphae¨l Salem
UMR 6085 C.N.R.S. et Universite´ de Rouen
Avenue de l’Universite´, BP 12, 76801 Saint-Etienne-du-Rouvray
bruno.lecoutre@univ-rouen.fr
Internet : http ://www.univ-rouen.fr/LMRS/Persopage/Lecoutre/Eris
2 ERIS, LAM/LCPE
UMR 7604, C.N.R.S., Universite´ de Paris 6 et Ministe`re de la Culture
11 rue de Lourmel, 75015 Paris
poitevin@ccr.jussieu.fr
3 ERIS, Laboratoire Psy.Co, E.A. 1780,
Universite´ de Rouen
UFR Psychologie, Sociologie, Sciences de l’Education
76821 Mont-Saint-Aignan Cedex
marie-paule.lecoutre@univ-rouen.fr
Re´sume´
On montre que l’on peut directement calculer un intervalle pour un contraste entre
moyennes, e´tant donne´ seulement la valeur observe´e du contraste et la statistique de
test t ou F associe´ (ou encore, de manie`re e´quivalente le seuil observe´ correspondant :
“p-value”). Cet intervalle peut eˆtre vu comme un intervalle de confiance fre´quentiste ou
comme un intervalle de cre´dibilite´ baye´sien ou comme un intervalle fiduciaire. Cela donne
aux utilisateurs des tests de signification usuels la possibilite´ d’une transition facile vers
des pratiques statistiques plus approprie´es. On met en avant les liens conceptuels entre
les tests et les intervalles de confiance ou de cre´dibilite´
1 Introduction
Un grand nombre d’articles re´cents ont mis en avant la ne´cessite´ de changements dans
la pre´sentation des re´sultats expe´rimentaux. Une opinion de plus en plus re´pandue est que
des proce´dures infe´rentielles qui fournissent une information approprie´e sur la taille des
effets (“effect size”) doivent eˆtre utilise´es en plus ou a` la place des tests de signification
de l’hypothe`se nulle. Ainsi, en psychologie, cela a e´te´ rendu officiel par l’“American Psy-
chological Association Task Force on Statistical Inference”, qui a propose´ des “guidelines”
pour une re´vision de la section statistique du manuel de l’American Psychological Associa-
tion. Ces propositions pre´conisent l’utilisation syste´matique d’estimations par intervalles :
“interval estimates should be given for any effect sizes involving principal outcomes” (Wil-
kinson et al., 1999).
Par conse´quent un projet salutaire devrait eˆtre de fournir aux utilisateurs des tests de
signification des outils qui faciliteraient une transition “en douceur” vers les intervalles
c© Revue MODULAD, 2005 -243- Nume´ro 33
d’estimation. Dans cette perspective un re´sultat e´tonnement simple et pourtant virtuel-
lement ignore´ est la facilite´ a` obtenir un intervalle d’estimation pour une diffe´rence entre
deux moyennes (et plus ge´ne´ralement pour un contraste entre moyennes) a` partir du test
t ou F qui lui est associe´.
Un tel intervalle d’estimation (“fourchette”) peut recevoir diffe´rentes justifications et
interpre´tations. Il peut eˆtre vu aussi bien comme un intervalle de confiance fre´quentiste,
comme un intervalle de cre´dibilite´ baye´sien, ou encore comme un intervalle fiduciaire
(Fisher, 1990). Les discussions the´oriques sur ces diffe´rents cadres d’infe´rence de´passent
l’objectif de cet article. Nous signalerons cependant que l’opinion des auteurs est qu’une
approche baye´sienne avec une motivation fiduciaire est ide´alement adapte´e a` l’analyse
des donne´es expe´rimentales et a` la publication scientifique. Le lecteur inte´resse´ peut se
re´fe´rer a` Lecoutre et al. (2001) et Rouanet et al. (2000). Ici nous utiliserons l’expression
“intervalle”, laissant le lecteur libre de choisir son cadre de justification et d’interpre´tation.
2 Du rapport F a` l’intervalle pour un contraste entre
moyennes
A titre d’illustration conside´rons une expe´rience avec deux facteurs croise´s Aˆge et
Traitement, chacun a` deux modalite´s. Les moyennes observe´es des quatre conditions
expe´rimentales (avec 10 sujets pour chacune) sont respectivement 5.77 (a1,t1), 5.25 (a2,t1),
4.83 (a1,t2) et 4.71 (a2,t2). On trouve dans une revue expe´rimentale internationale les
commentaires typiques suivants, base´s sur les tests F usuels de l’analyse de variance :
“the only significant effect is a main effect of treatment (F [1,36]=6.39, p=0.016),
reflecting a substantial improvement”,
et encore
“clearly, there is no evidence (F[1,36] = 0.47, p = 0.50) of an interaction”.
De tels commentaires sont fre´quents dans les publications expe´rimentales. Il est forte-
ment sugge´re´ a` un lecteur, peu au fait de la rhe´torique accompagnant l’usage des tests de
signification, que l’on a de´montre´ a` la fois l’existence d’un effet important du traitement
et l’absence d’effet d’interaction. Mais il n’en est rien !
La diffe´rence des moyennes observe´es pour les deux traitements est :
d =
1
2
(5.77 + 5.25)− 1
2
(4.83 + 4.71) = +0.74
et l’effet d’interaction peut eˆtre caracte´rise´ par la diffe´rence des diffe´rences :
d = (5.77− 4.83)− (5.25− 4.71) = +0.40
Un re´sultat simple et ge´ne´ral est que l’intervalle 100(1− α)% pour la diffe´rence vraie
δ peut eˆtre de´duite du rapport F (avec un et q degre´s de liberte´). Cet intervalle est (en
supposant d 6= 0) : [
d− (|d|/
√
F )tq;α
2
, d+ (|d|/
√
F )tq;α
2
]
ou` tq;α
2
est le (α
2
)% percentile supe´rieur de la distribution de Student a` q degre´s de li-
berte´ (rappelons que le carre´ de tq;α
2
est le α% percentile supe´rieur de la distribution
c© Revue MODULAD, 2005 -244- Nume´ro 33
F a` un et q degre´s de liberte´). En outre une bonne approximation peut eˆtre directe-
ment obtenue (c’est-a`-dire sans se re´fe´rer a` des tables statistiques) en remplac¸ant tq;α
2
par
1.96
√
q/(q − 2), ou encore plus simplement par 2 quand q est grand.
Ce re´sultat met en avant la proprie´te´ fondamentale de la statistique de test F d’eˆtre
un estimateur de la pre´cision expe´rimentale, conditionnellement a` la valeur observe´e d. De
manie`re plus explicite d2/F estime la variance d’erreur d’e´chantillonnage de d. Le meˆme
re´sultat s’applique aux tests t de Student usuel, en remplac¸ant |d|/√F par d/t.
A partir de t36;0.025 = 2.028, nous obtenons ici les intervalles 95% [+0.15 , +1.33]
pour la diffe´rence entre les deux traitements et [-0.78 , +1.58] pour l’effet d’interaction.
Cela montre clairement que l’on ne peut pas conclure a` la fois a` un effet important du
traitement et a` un effet d’interaction faible, ou du moins relativement ne´gligeable (et
encore moins a` l’absence d’interaction).
3 Seuils de signification et intervalles d’estimation
Les statistiques de test t ou F peuvent eˆtre calcule´es a` partir du seuil de signification
observe´ (“p-value”). Par conse´quent des intervalles peuvent eˆtre de´duits directement du
seuil observe´ p (suppose´ connu avec une pre´cision suffisante). Il s’ensuit que, e´tant donne´
la valeur observe´e d, le seuil p est aussi un estimateur de la pre´cision expe´rimentale. D’ou`,
intuitivement, plus le re´sultat est significatif (plus p est petit par rapport a` α), plus δ
devrait eˆtre proche de d. Il est e´clairant de remarquer que l’intervalle 100(1 − α)% peut
encore eˆtre e´crit comme
[d− dα, d+ dα]
ou` dα = (|d|/
√
F )tq;α
2
est la valeur critique (positive) de d telle que le test est de´clare´
significatif au seuil bilate´ral α si |d| est supe´rieur a` dα.
Comme autre illustration, conside´rons une e´tude planifie´e pour tester l’efficacite´ d’une
nouveau me´dicament en comparant deux groupes (nouveau me´dicament vs. placebo) de
20 sujets chacun. le nouveau me´dicament est conside´re´ comme efficace (cliniquement
inte´ressant) par les experts du domaine si la diffe´rence est supe´rieure a` +2. Quatre cas pos-
sibles de re´sultats ont e´te´ construits en croisant le re´sultat du test t (significatif, p = 0.001
vs. non significatif, p = 0.60, bilate´ral) et la diffe´rence observe´e d entre les deux moyennes
(grande, d = +4.92 vs. petite, d = +0.84).
Les intervalles 95% pour la diffe´rence vraie δ sont donne´s dans le Tableau 1. Ce tableau
illustre le passage de la connaissance de d et p (ou t) a` une conclusion sur la grandeur de
δ (l’efficacite´ du nouveau me´dicament). A partir de ce tableau, il devient facile d’e´viter
des conclusions errone´es base´es sur des interpre´tations haˆtives du test de signification. Les
re`gles ge´ne´rales suivantes peuvent s’en de´duire.
Table 1 - Intervalles 95% pour δ dans les quatre cas de re´sultats
(t38;0.025 = 2.024, d’ou` d0.05 = 2.024d/t)
cas t p d d0.05 95% intervalle conclusion
1 +3.566 0.001 +4.92 2.79 [+2.13 , +7.71] efficace
2 +3.566 0.001 +0.84 0.48 [+0.36 , +1.32] inefficace
3 +0.529 0.60 +4.92 18.83 [-13.91 , +23.75] pas de conclusion
4 +0.529 0.60 +0.84 3.22 [-2.38 , +4.06] pas de conclusion
c© Revue MODULAD, 2005 -245- Nume´ro 33
Cas 1 (test significatif, diffe´rence d positive et grande). De tels re´sultats semblent
ge´ne´ralement tre`s favorables aux utilisateurs des tests. Cela est justifie´ ici, car d−d0.05 est
supe´rieur a` +2. Cependant il faut souligner que conclure a` une diffe´rence grande (notable)
ne´cessite certaines pre´cautions. Le test doit eˆtre “suffisamment significatif”, c’est-a`-dire
p suffisamment infe´rieur a` α, afin d’impliquer une grande valeur d− dα. En effet, dans le
cas limite ou` d est positive et ou` le test est juste significatif au seuil bilate´ral α, on peut
seulement conclure que δ est positive.
Cas 2 (test significatif, diffe´rence d positive et petite). Puisque 0 < dα < d, ces
conditions impliquent que dα et d− dα sont petits. De plus, dans les re´sultats conside´re´s
ici, d + d0.05 e´galement petit (infe´rieur a` +2), de sorte que l’on peut conclure a` une
diffe´rence petite. Parce qu’il y a apparemment un conflit entre la diffe´rence observe´e
petite et le re´sultat du test statistiquement significatif, ce cas apparaˆıt ge´ne´ralement aux
utilisateurs des tests comme embarrassant. Cependant il n’y a pas de paradoxe, car cela
peut seulement se produire quand la pre´cision expe´rimentale est “tre`s bonne” (c’est-a`-
dire quand la variance d’erreur d’e´chantillonnage est faible). C’est donc en fait un cas
privile´gie´. Mais, en conse´quence le test est tre`s puissant (dα petit), de sorte que meˆme
une diffe´rence observe´e faible peut eˆtre statistiquement significative.
Cas 3 (test non significatif, diffe´rence d positive et grande). En re`gle ge´ne´rale,
on ne peut pas tirer de conclusion inductive ferme : il est bien entendu hors de question
de pouvoir conclure a` une diffe´rence faible. En fait ces re´sultats indiquent une pre´cision
expe´rimentale insuffisante et par conse´quent ne sont pas re´ellement contradictoires. (seule
une diffe´rence observe´e tre`s grande devrait eˆtre statistiquement significative). Cependant,
beaucoup d’utilisateurs des tests trouvent ce cas embarrassant parce qu’ils ne peuvent pas
ge´ne´raliser la conclusion descriptive d’une diffe´rence grande.
Cas 4 (test non significatif, diffe´rence d positive et petite). Ces conditions im-
pliquent seulement que d est plus petit que dα. Mais cela peut correspondre aussi bien a`
des valeurs d− dα et d+ dα grandes ou petites. Dans les re´sultats conside´re´s ici, d+ d0.05
est nettement supe´rieur a` +2, de sorte qu’on ne peut tirer aucune conclusion ferme.
Ne´anmoins, comme dans le premier cas, la convergence apparente entre la diffe´rence ob-
serve´e et le re´sultat du test semble souvent favorable aux utilisateurs des tests qui tendent
a` conclure a` tort que le me´dicament est inefficace.
4 Conclusion
En un sens, le seuil observe´ p ne peut pas eˆtre regarde´ comme une mesure rationnelle du
degre´ de certitude (voir notamment Hacking, 1965 ; Spielman, 1974). Il faut aussi souligner
que p en lui-meˆme ne dit rien sur la grandeur de l’effet. Cependant, il apparaˆıt que dans
beaucoup de cas usuels la statistique de test, ou de manie`re e´quivalente le seuil observe´ p,
peut eˆtre directement combine´ avec une statistique descriptive pour obtenir un intervalle
d’estimation. A la diffe´rence de la puissance cet intervalle est directement et facilement
interpre´table en termes de grandeur de l’effet. Seldmeier & Gigerenzer (1989) de´ploraient
le peu d’utilisations faites de la puissance dans les publications expe´rimentales. Face aux
mauvais usages des tests de signification, ils e´nonc¸aient que “given such misconceptions,
the calculation of power may appear obsolete because intuitively the level of significance
already seems to determine all we want to know” (page 314). Un e´nonce´ plus pertinent
c© Revue MODULAD, 2005 -246- Nume´ro 33
apparaˆıt eˆtre “given such misconceptions, the calculation of power may appear obsolete
because formally the level of significance may determine what we want to know”. Cela
confirme le constat de Goodman et Berlin (1994) que “for interpretation of observed
results, the concept of power has no place” (cela ne signifie pas que la puissance ne peut
pas eˆtre utile pour les calculs d’effectifs).
En particulier, en regard des mauvais usages re´pandus des tests de signification (voir en
particulier Lecoutre et al., 2003), il s’ensuit qu’un re´sultat “largement significatif” permet
le plus souvent de ge´ne´raliser le re´sultat descriptif. Toutefois, en fonction de la grandeur de
l’effet observe´, cela peut conduire aussi bien a` conclure a` un effet grand, moyen ou petit.
Au contraire un re´sultat “largement non significatif” ne conduira a` conclure a` un effet
petit que si l’effet observe´ est lui-meˆme tre`s petit. En pratique un tel re´sultat correspondra
le plus souvent a` une constat d’ignorance.
En conclusion, meˆme si bannir les tests de signification des publications expe´rimentales
serait sans aucun doute une the´rapie de choc (voir Shrout, 1997), les statistiques t, les
rapports F et les seuils observe´s p demeureraient utiles, au moins pour les calculs des
intervalles d’estimation et pour les re´analyses de re´sultats pre´ce´demment publie´s. Ironi-
quement, les fournir avec une pre´cision suffisante apparaˆıt alors eˆtre une bonne pratique
en vue des analyses ulte´rieures sur les tailles des effets.
Re´fe´rences
- Fisher R. A. (1990) – Statistical Methods, Experimental Design, and Scientific Infe-
rence (Re-issue). Oxford : Oxford University Press.
- Goodman, S.N. & Berlin, J.A. (1994) – The use of predicted confidence intervals when
planning experiments and the misuse of power when interpreting results. Annals of
Internal Medicine, 121, 200–206.
- Hacking, I. (1965) – The Logic of Statistical Inference. Cambridge, England : Cam-
bridge University Press.
Lecoutre, B., Lecoutre, M.-P., & Poitevineau, J. (2001) – Uses, abuses and misuses of
significance tests in the scientific community : won’t the Bayesian choice be unavoi-
dable ? International Statistical Review, 69, 399-418.
Lecoutre M.-P., Poitevineau J., & Lecoutre B. (2003) – Even statisticians are not im-
mune to misinterpretations of Null Hypothesis Significance Tests. International Jour-
nal of Psychology 38, 37-45.
Rouanet, H., Bernard, J.-M., Bert, M.-C., Lecoutre, B., Lecoutre, M.-P., & Le Roux,
B. (2000) – New Ways in Statistical Methodology : From Significance Tests to Bayesian
Inference, 2nd edition. Bern, CH : Peter Lang.
Spielman, S. (1974) – The Logic of Tests of Significance. Philosophy of Science, 41,
211–226.
Seldmeier, P. & Gigerenzer, G. (1989) – Do studies of statistical power have an effect
on the power of studies. Psychological Bulletin, 105, 309–316.
Shrout, P.E. (1997) – Should significance tests be banned ? Introduction to a special
section exploring the pros and cons. Psychological Science, 8, 1–2.
c© Revue MODULAD, 2005 -247- Nume´ro 33
Wilkinson, L. and Task Force on Statistical Inference, APA Board of Scientific Affairs
(1999) – Statistical Methods in Psychology Journals : Guidelines and Explanations.
American Psychologist, 54, 594–604.
c© Revue MODULAD, 2005 -248- Nume´ro 33
