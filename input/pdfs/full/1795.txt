Classification Non Supervise´e pour Donne´es
Cate´gorielles
Pierre-Emmanuel JOUVE ∗, Nicolas NICOLOYANNIS ∗
∗LABORATOIRE ERIC, Universite´ Lumie`re - Lyon2
Baˆtiment L, 5 av. Pierre Mende`s-France
69 676 BRON cedex FRANCE
{pierre.jouve, nicolas.nicoloyannis}@eric.univ-lyon2.fr,
http://eric.univ-lyon2.fr
Re´sume´. La classification non supervise´e (CNS) constitue l’une des pro-
ble´matiques centrales de l’Extraction de Connaissances a` partir de Donne´es
(E.C.D.). Le cadre spe´cifique de la CNS pour donne´es cate´gorielles a e´te´
l’objet de multiples travaux ces dernie`res anne´es, les principaux challenges
associe´s a` ses recherches sont d’une part la de´finition de crite`res bien
adapte´s a` ce cadre particulier et d’autre part la mise au point d’algo-
rithme au couˆt calculatoire relativement faible. Le propos de cet article
n’est pas de poursuivre dans ces directions de recherche mais plutoˆt de
s’appuyer sur ces travaux afin de proposer une me´thode efficace exhi-
bant de nombreux avantages pour l’utilisateur et utilisable par un non
spe´cialiste. Nous proposons et e´valuons donc une me´thode de CNS pour
donne´es cate´gorielles permettant la mise a` jour relativement rapide d’une
classification pertinente d’un ensemble d’objets, tout en facilitant la taˆche
de l’utilisateur : aucun parame`tre obscur ni nombre final de classes a` fixer,
description compre´hensible de la classification, possibilite´ d’intervention
de l’utilisateur dans le processus de CNS...
1 Introduction
Nous pre´sentons dans cet article une nouvelle me´thode de classification non su-
pervise´e (CNS) pour donne´es cate´gorielles dont le principal attrait re´side dans la
re´solution de plusieurs proble`mes auquel un utilisateur se trouve confronte´ en pratique
(de´termination du nombre de classes, compre´hensibilite´ de la taxonomie construite...)
tout en n’impliquant pas une perte de qualite´ dans les re´sultats fournis. L’ensemble
des terminologies et formalismes que nous utiliserons afin d’introduire le processus de
CNS pour donne´es cate´gorielles proviennent de multiples re´fe´rences de la litte´rature
que nous ne manquerons pas d’e´voquer. La forme de cette pre´sentation s’inspire quant
a` elle de [8] (ce choix est motive´ par le souci de conserver une certaine uniformite´ avec
certains travaux notoires du domaine).Afin de faciliter la pre´sentation nous nous ap-
puierons sur des exemples (note´s Exemple :) base´s sur un jeu de donne´es de´crivant un
ensemble de 3 votes de motions diffe´rentes par 9 nations lors de sessions a` l’O.N.U.(voir
Tableau 1 page suivante).
Classification Non Supervise´e pour Donne´es Cate´gorielles
Pays M1 M2 M3 Pays M1 M2 M3 Pays M1 M2 M3
USSR A A C PORT D C B FRAN C B C
POLA A A C DENM C B C SWED C B C
CUBA A D C FINL B B C NORW C B C
Tab. 1 – Votes a` l’O.N.U. pour 9 pays diffe´rents pour 3 Motions diffe´rentes
2 Donne´es Cate´gorielles
On de´finit les donne´es cate´gorielles comme les donne´es de´crivant des objets ne
posse´dant que des caracte´ristiques cate´gorielles. Les objets, par conse´quent nomme´s ob-
jets cate´goriels, ne peuvent posse´der des caracte´ristiques nume´riques (quantitatives) 1.
2.1 Domaines Et Attributs Cate´goriels
Notation 1 V1,V2,...,Vp p variables de´crivant un espace V
Exemple : V = {M1,M2,M3}.
Notation 2 Dom(V1),...,Dom(Vp) sont les domaines respectifs des variables de V .
De´finition 1 Un domaine Dom(Vj) = {vj1,...,vjk},k ∈ N∗ est de´fini comme cate´goriel
s’il est fini, et non ordonne´. Ainsi ∀a,b ∈ Dom(Vj) les seules relations pouvant exister
entre a et b sont : a = b ou a 6= b. Vj est alors appele´e variable cate´gorielle.
Exemple : Dom(M1) = {A,B,C,D},Dom(M2) = {A,B,C,D},Dom(M3) = {B,C}.
De´finition 2 V est un espace cate´goriel si ∀Vj ,j ∈ 1..p,Vj est cate´gorielle.
Notons, que les domaines cate´goriels sont de´finis par des singletons ainsi des valeurs
provenant de combinaisons ne sont pas autorise´es contrairement a` [4]. Afin de simplifier
la pre´sentation de notre me´thode nous ne conside´rerons ni les relations d’inclusions
conceptuelles entre variables contrairement a` [9], ni les valeurs manquantes (dans ce cas
nous de´finirons une valeur supple´mentaire pour les domaines des attributs pre´sentant
des valeurs manquantes, valeur qui sera conside´re´e comme une valeur classique). Il
sera cependant possible d’adapter avantageusement notre me´thode (et en particulier la
mesure de l’aspect naturel d’une partition utilise´e) au traitement de ces cas particuliers.
2.2 Objets Cate´goriels et Ensemble d’Objets Cate´goriels
Notation 3 O est l’ensemble des objets d’un jeu de donne´es.
Comme dans [4] un objet cate´goriel oi ∈ O est repre´sente´ par une conjonction
logique de paires attributs-valeurs [V1 = oi1 ]
⋂
[V2 = oi2 ]
⋂
...[Vp = oip ]. (Une paire
attribut-valeur est de´nomme´e se´lecteur dans [13].) Nous repre´senterons chaque objet
oi ∈ O par un vecteur [oi1 ,oi2 ,...,oip ] (chaque objet posse`de exactement p valeurs d’at-
tributs). (Exemple : FRAN = [C,B,C] est un objet cate´goriel.)
On a alors oi = oj si ∀k,oik = ojk . Cette dernie`re relation n’implique toutefois pas que
1. si tel est le cas on devra s’astreindre a` une phase de discre´tisation de ces caracte´ristiques afin
d’uniformiser la description de ces objets
RNTI - 1
Pierre-Emmanuel JOUVE et Nicolas NICOLOYANNIS
oi et oj repre´sentent le meˆme objet, mais elle signifie qu’ils posse`dent les meˆme valeurs
cate´gorielles pour les attributs V1,V2,...,Vp.
Exemple : ”FRAN” 6= ”DENM” mais [C,B,C] = [C,B,C].
Nous introduisons maintenant la notion de mode d’un ensemble d’objets (notion
notamment de´finie dans [8]) qui repre´sente l’objet virtuel le moins dissimilaire (ou le
plus similaire) ”en moyenne” de la totalite´ des objets de cet l’ensemble. Le mode d’un
ensemble d’objets constitue donc en quelque sorte le profil type de ses objets.
Notation 4 E = {o1,o2,...,oh} un ensemble de h objets cate´goriels et E ⊆ O
nEk,j le nombre d’objets de E ayant la valeur k pour la variable Vj ∈ V
fr(Vj = k|E) = nEk,j/card(E) la fre´quence relative de la valeur k pour Vj pour E.
De´finition 3 Le mode d’un ensemble d’objet E est l’objet virtuelmodeE = {modeEj ,j =
1..p} tel que pour toute variable Vj ∈ V la valeur d’attribut de modeE est, celle, la plus
repre´sente´e pour cette variable au sein de la classe E:
∀j = 1..p,∀oi ∈ E,fr(Vj = modeEj |E) ≥ fr(Vj = oij |E).
(Le mode d’un ensemble d’objet E n’est ni force´ment un objet de E ni force´ment unique.)
Exemple : E = {FRAN,SWED,DENM,NORW,FINL}, modeE = [C,B,C].
2.3 Voisinage d’une Partition d’un Ensemble d’Objets Cate´goriels
Notation 5 Ph = {E1,...,Eh} une partition de O en h groupes
De´finition 4 Nous dirons qu’une partition Pz appartient a` V ois(Ph) l’ensemble des
partitions voisines d’une partition Ph si
– Pz peut eˆtre obtenue a` partir de Ph par segmentation d’une classe Ej de Ph selon
une variable Vi (processus e´quivalent a` la segmentation des arbres de de´cision)
– Pz peut eˆtre obtenue a` partir de Ph par fusion de deux classes de Ph
– Pz = Ph
Exemple : Soient O = {CUBA,POLA,USSR,FRAN,SWED}, et la partition
P1 = {{CUBA,POLA,USSR},{FRAN,SWED}} on a alors V (P1) = {P1,P2,P3} avec
P2 = {{CUBA,POLA,USSR,FRAN,SWED}} obtenue par fusion des 2 classes de P1,
P3 = {{CUBA},{POLA,USSR},{FRAN,SWED}} obtenue par segmentation de la classe
{CUBA,POLA,USSR} selon la variable M2. (aucune autre segmentation n’est possible)
3 Aspect Naturel d’une Partition d’Objets :
le Nouveau Crite`re de Condorcet
Le proble`me de la CNS est, e´tant donne´ un ensemble d’objets O, de de´terminer
une partition Pnat de O que l’on de´nommera naturelle. Cette partition doit eˆtre telle
que ses classes soient constitue´es d’objets pre´sentant une relative forte similarite´ et que
les objets de classes diffe´rentes pre´sentent une relative forte dissimilarite´. Pour ce faire
on doit disposer d’un crite`re permettant de capturer l’aspect naturel d’une partition,
RNTI - 1
Classification Non Supervise´e pour Donne´es Cate´gorielles
nous pre´sentons et utilisons ici un crite`re relativement peu exploite´ dans la litte´rature :
le nouveau crite`re de Condorcet (NCC) de´fini dans [14], article auquel on se re´fe´rera
pour avoir une comparaison de ce crite`re au crite`re classique de l’inertie intra-classe.
Le principal avantage de ce crite`re est une de´termination automatique du nombre final
de classes pour la CNS. Voici sa de´finition formelle, en adoptant les notations de la
section pre´ce´dente : NCC(Ph) la mesure de l’aspect naturel d’une partition Ph
NCC(Ph) =
∑
i=1..h,j=1..h,i 6=j
Sim(Ei,Ej) + α×
h∑
i=1
Dissim(Ei) (1)
α scalaire appele´ facteur de granularite´, fixe´ par de´faut a` 1 mais modifiable (α ≥ 0)
Sim(Ei,Ej) =
∑
oa∈Ei,ob∈Ej
sim(oa,ob), Dissim(Ei) =
∑
oa∈Ei,ob∈Ei dissim(oa,ob)(2)
sim(oa,ob) =
p∑
i=1
δsim(oai ,obi), dissim(oa,ob) =
∑p
i=1 1− δdissim(oai ,obi) (3)
δsim(oai ,obi) = δdissim(oai ,obi) =
{
1 si oai = obi
0 si oai 6= obi (4)
Ainsi, NCC(Ph) mesure simultane´ment les dissimilarite´s entre objets de meˆme
classe de la partition Ph, et les similarite´s entre objets de classes diffe´rentes (on peut
donc dire que NCC(Ph) est de´finie comme une fonction de l’homoge´ne´ite´ interne des
classes et de l’he´te´roge´ne´ite´ entre classes). Donc, les partitions pre´sentant une forte ho-
moge´ne´ite´ intra-classe et une forte disparite´ inter-classes posse´deront une faible valeur
pour NCC et constitueront les partitions apparaissant comme les plus naturelles.
De´finition 5 Une partition P1 est dite plus naturelle qu’une partition P2 (ou encore
repre´sentant mieux la structure interne des donne´es) si NCC(P1) < NCC(P2).
De´finition 6 Une partition d’un ensemble d’objets O est nomme´e Partition Natu-
relle de O et est note´e Pnat si elle minimise NCC : ℘ ensemble des partitions de O,
∀Pi ∈ ℘,NCC(Pnat) ≤ NCC(Pi).
Notons le roˆle du facteur de granularite´ α (non pre´sent dans la de´finition initiale du
NCC) : celui ci permet soit de privile´gier l’influence de l’homoge´ne´ite´ intra-classe ou
de la disparite´ inter-classe pour la de´termination de l’aspect naturel d’une partition.
En effet, plus α est e´leve´ (resp. faible) plus une partition doit pre´senter une forte ho-
moge´ne´ite´ intra-classe (resp. une forte disparite´ inter-classes) pour apparaˆıtre naturelle.
4 Une Me´thode de Classification Non Supervise´e Oriente´e
Utilisateur
4.1 Travaux Lie´s et Spe´cificite´s du Travail
La CNS pour donne´es cate´gorielles a e´te´ l’objet de multiples travaux ces dernie`res
anne´es, les principaux challenges associe´s a` ses recherches sont d’une part la de´finition
RNTI - 1
Pierre-Emmanuel JOUVE et Nicolas NICOLOYANNIS
de crite`res bien adapte´s a` ce cadre particulier (dans ROCK [6] les auteurs utilisent une
mesure base´e sur le nombre de voisins communs que posse`de deux objets, [1] utilisent
quant a` eux une mesure base´e sur l’entropie ge´ne´ralise´e, enfin [14] utilise quant a` lui le
NCC) et d’autre part la mise au point d’algorithmes au couˆt calculatoire relativement
faible ([8] propose les K-Modes une adaption de la me´thode des K-Means dans le cas
de donne´es cate´gorielles, [3] utilisent les syste`mes dynamiques pour STIRR).
Notre propos n’est pas ici de poursuivre dans ces directions de recherche mais
plutoˆt de s’appuyer sur ces travaux afin de proposer une me´thode efficace exhibant de
nombreux avantages pour l’utilisateur et utilisable par un non spe´cialiste. On peut ainsi
lister un ensemble de qualite´s pratiques de´sirables par un utilisateur et qui distinguerait
largement une me´thodes les posse´dant des approches existantes :
– ge´ne´rer une description des classes de´finies aise´ment compre´hensible et ne ne´cessitant
aucun post-traitement contrairement a` [6], [3] [14]
– couˆt calculatoire relativement faible contrairement a` [6]
– ne pas ne´cessiter de fixer a priori le nombre final de classe contrairement a` [8]
mais toutefois permettre a` l’utilisateur de jouer sur la finesse de la partition s’il
conside`re que le nombre de classes obtenues est trop e´leve´ ou trop faible.
– permettre la de´couverte de structures ne pre´sentant pas une re´gularite´ dans le
nombre d’objets par classe.contrairement a` [8]
– permettre la gestion de donne´es manquantes, l’introduction de contraintes et
l’intervention de l’utilisateur au cours du processus de CNS et ce de manie`re
aise´e.
L’objectif du travail mene´ est donc la mise au point d’une me´thode de CNS per-
mettant la mise a` jour de partitions pertinentes et posse´dant ces qualite´s pratiques.
4.2 L’Algorithme de Classification Non Supervise´e
L’algorithme que nous proposons consiste en une mise en oeuvre astucieuse et
nouvelle de principes et techniques existants afin d’atteindre les objectifs de´taille´s
pre´ce´demment. Pour cela nous utilisons le crite`re NCC tre`s peu exploite´ dans la
litte´rature, et une technique de types graphes d’induction pour de´couvrir une par-
tition P∼nat proche ou e´gale a` Pnat ce qui confe´rera un aspect non hie´rarchique a` la
me´thode ([17] avaient propose´ une technique de type arbre d’induction ce qui confe´rait
un aspect hie´rarchique a` la me´thode et utilisaient un crite`re de type khi2).
Remarques :
-La de´couverte de Pnat (proble`me combinatoire) peut eˆtre re´solue par des me´thodes au couˆt
calculatoire e´leve´e : par une approche de type Programmation en nombre entier, par une ap-
proche base´e sur les me´thodes de Plans de Coupe et Branch and Bound [5].
-La de´couverte d’une partition P∼nat proche ou e´gale a` Pnat peut eˆtre effectue´e par l’in-
terme´diaire d’heuristiques de couˆt calculatoire en O(n2) : [15] a propose´ une approche ite´rative
base´e sur la pre´topologie, [16] utilisent une me´thode ite´rative utilisant le recuit-simule´ per-
mettant la de´couverte de P∼nat, [11] utilisent une approche de type programmation line´aire.
-Utiliser ces me´thodes ne permet malheureusement pas d’atteindre les objectifs vise´s.
RNTI - 1
Classification Non Supervise´e pour Donne´es Cate´gorielles
Nous avons donc adopte´ une heuristique gloutonne de type graphe d’induction (on
proce`de par segmentation/fusion successives de classes de partitions). En de´finitive, a`
partir de la partition grossie`re de O, l’algorithme va e´voluer ite´rativement de partition
en partition en suivant le principe d’e´volution suivant : on passe d’une partition Pt vers
la partition Pt+1 appartenant a` son voisinage (cf. De´finition 4) telle qu’elle re´duise au
plus le NCC. L’algorithme s’ache`ve lorsque Pt = Pt+1. Le pseudo-code de l’algorithme
est donc le suivant:
1. soit P0 la partition grossie`re de O
2. i:=0
3. De´terminer V (Pi)
4. De´terminer Pi+1 ∈ V (Pi) la meilleure partition de V (Pi) selon le NCC
5. Si Pi+1 = Pi aller en 6), sinon i:=i+1 et aller en 3)
6. P∼nat = Pi
Remarques :
Pour e´viter des minima locaux, on peut autoriser dans le cas Pi+1 = Pi, un nombre fixe´ a
priori d’e´volution vers la partition du voisinage de Pi obtenue par segmentation selon une
variable et impliquant la plus faible augmentation du NCC.
4.3 Qualite´s de la Me´thode pour l’Utilisateur
– Chacune des classes de la partition re´sultat (P∼nat) est caracte´rise´e par une re`gle
logique (re`gle forme´e de disjonctions de conjonctions de se´lecteurs) correspondant
a` la suite de me´canismes (fusion / segmentation) lui ayant donne´ le jour. Cette
re`gle correspond alors pour un objet de O a` une condition ne´cessaire et suffisante
pour appartenir a` la classe qu’elle de´crit.
– On associera e´galement a` chaque classe de P∼nat son mode, celui-ci correspondant
en de´finitive a` une sorte de profil ou individu type de la classe.
– Ces deux premiers points simplifient largement la compre´hension et l’interpre´tation
des re´sultats.
– La description de chaque classe par une re`gle logique peut e´galement permettre
l’assignation d’un nouvel objet a` l’une des classes sans pour autant connaˆıtre
l’ensemble de ses caracte´ristiques.
– le nombre de classe est de´termine´ automatiquement par la me´thode, toutefois
l’utilisateur peut influer sur la finesse de la partition finalement produite par
l’interme´diaire du facteur de granularite´. (si le nombre de classes apparaˆıt trop
faible (resp. trop fort) a` l’utilisateur, ce dernier peut proce´der a` une nouvelle
CNS en augmentant (resp. en diminuant) la valeur du facteur de granularite´).
4.4 Illustration du Fonctionnement de l’Algorithme
Conside´rons le jeu de donne´es classique : les donne´es mushrooms[12]. Ce jeu de
donne´es est compose´ de 8124 objets (en l’occurrence des champignons), chacun de´crit
par 23 variables. Chaque objet est, de plus, identifie´ par sa comestibilite´. Le jeu de
donne´es est ainsi compose´ de champignons comestibles et de champignons ve´ne´neux.
RNTI - 1
Pierre-Emmanuel JOUVE et Nicolas NICOLOYANNIS
La figure 1 pre´sente le processus de CNS sur le jeu de donne´es ”Mushrooms” pour un
facteur de granularite´ α valant 1. Elle de´taille ainsi l’ensemble des processus de segmen-
tation/fusion, permettant l’obtention de la CNS . Voici pour exemple les re`gles logiques
caracte´risant les classes C8 et C10 (rappelons que chacune de ces re`gles de´termine l’ap-
partenance ou la non appartenance de tout objet a` la classe a` laquelle elle est associe´e) :
– C8 [Ring Type = evanescent] ET [Gill Size = broad] ET [Bruises? = bruises]
– C10 [Ring Type = pendant] ET [ [Bruises? = bruises] OU [ [Bruises? = no] ET [stalk-
color-above-ring = white] ET [Gill Size = narrow] ] ]
Fig. 1 – Illustration du Fonctionnement de l’Algorithme
5 Evaluation de l’Algorithme de Classification non
Supervise´e
Classiquement, une me´thode de CNS s’e´value selon : la validite´ et la stabilite´ des
classifications qu’elle propose, et selon son efficacite´ algorithmique.
5.1 Evaluation de la Qualite´ des Classifications
L’e´valuation de la validite´ d’une CNS est ge´ne´ralement re´alise´e par utilisation de
mesures de validite´ de CNS[7] [2]. Ces mesures sont de deux types : externes et internes
(les modes d’e´valuation habituels correspondant en de´finitive a` l’utilisation implicite
d’une mesure externe). Les crite`res externes de validite´ e´valuent dans quelle mesure le
re´sultat du processus de CNS correspond a` des connaissances ave´re´es sur les donne´es.
RNTI - 1
Classification Non Supervise´e pour Donne´es Cate´gorielles
De manie`re assez ge´ne´rale, on admet que ces informations ne sont pas calculables a`
partir des donne´es. La forme la plus commune de donne´es de ce type est un ensemble
d’e´tiquettes que l’on associe a` chacun des objets (ce dernier type d’information peut
e´ventuellement eˆtre obtenu par une classification manuelle). Les crite`res internes de
validite´ consistent quant a` eux en une mesure base´e uniquement sur le traitement des
donne´es servant au processus de CNS et leur utilisation n’est que rarement envisageable.
Nous avons utilise´ ici une e´valuation de type mesure externe largement utilise´e
dans la litte´rature. Nous avons conside´re´ le jeu de donne´es mushrooms (compose´ de
champignons comestibles et de champignons ve´ne´neux) et avons re´alise´ plusieurs CNSs,
pour des valeurs de α diffe´rentes, enfin nous avons utilise´ le concept ”comestibilite´” et le
taux de correction T.C. des CNSs par rapport a` ce concept afin de caracte´riser la qualite´
de la CNS re´sultant (la variable de´finissant la ”comestibilite´” n’e´tant e´videmment pas
introduite dans le processus de CNS). Les re´sultats obtenus pour 3 valeurs diffe´rentes
de α (α = 1,2,3) pre´sente´s dans le tableau 2 montrent que les diffe´rentes classifications
re´alise´es permettent bien d’obtenir des partitions refle´tant correctement la structure
implique´e par le concept comestibilite´ ainsi que la capacite´ de l’algorithme a` de´terminer
une structure pre´sentant des irre´gularite´s dans le nombre d’objets par classe. (Notons de
plus que pour des valeurs de α supe´rieures a` 3, les classifications obtenues pre´sentaient
un nombre de classes strictement supe´rieur a` 24, chacune e´tant homoge`ne du point de
vue de la comestibilite´ des champignons la constituant.)
Nous pre´sentons e´galement une comparaison des re´sultats obtenus par notre me´thode
et ceux obtenus par les k-modes pour diffe´rentes CNSs. Nous avons, pour cela, lance´
plusieurs processus de CNS avec notre me´thode en utilisant des facteurs de granularite´
diffe´rents. Cela nous a permis d’obtenir des CNSs en 6, 10, 21, 24, 58, 141 et 276 classes.
Les taux de correction de ces CNSs par rapport au concept ”comestibilite´” sont ainsi
reporte´s sur la figure 2. Ensuite nous avons lance´ des se´ries de 10 CNSs en utilisant
les k-modes parame´tre´s de manie`re telle qu’on obtienne des CNSs en 6, 10, 21, 24, 58,
141 et 276 classes. La valeur moyenne du taux de correction par rapport au concept
”comestibilite´” de chacune de ces 7 se´ries de 10 CNSs sont ainsi reporte´es sur la figure
2. L’ensemble de ces tests montrent une qualite´ le´ge`rement supe´rieure pour les CNSs
obtenues par l’interme´diaire de notre me´thode.
Fig. 2 - Taux de Correction pour le
concept ”comestibilite´”
Des tests ont e´galement e´te´ mene´s sur le
jeu de donne´es Soybean Disease [12]. Soy-
bean Disease est un jeux de donne´es stan-
dard en apprentissage symbolique (ma-
chine learning) compose´ de 47 objets,
chacun e´tant de´crit par 35 variables
cate´gorielles. Chaque objet est caracte´rise´
par une des 4 pathologies suivantes : Dia-
porthe Stem Canker (D1), Charcoal Rot
(D2), Rhizoctonia Root Rot(D3), and Phy-
tophthora Rot(D4).A l’exception de D4 qui
est repre´sente´e par 17 objets, toutes les
autres pathologies sont repre´sente´es par 10
RNTI - 1
Pierre-Emmanuel JOUVE et Nicolas NICOLOYANNIS
α = 1 N.C. #1 #2 #3 #4 #5 #6 #7 #8
#C./#V. 0/1296 48/0 0/36 192/0 16/0 192/0 1056/0 2656/816
N.C. #9 #10
#C./#V. 48/1760 0/8
α = 2 N.C. #1 #2 #3 #4 #5 #6 #7 #8
#C./#V. 0/1728 192/0 768/0 0/1296 1728/0 512/0 288/0 192/0
N.C. #9 #10 #11 #12 #13 #14 #15 #16
#C./#V. 0/36 0/288 0/192 192/0 96/256 48/0 0/32 96/0
N.C. #17 #18 #19 #20 #21
#C./#V. 32/72 16/0 0/8 48/0 0/8
α = 3 N.C. #1 #2 #3 #4 #5 #6 #7 #8
#C./#V. 92/0 0/1296 0/864 0/864 288/0 96/0 1728/0 768/0
N.C. #9 #10 #11 #12 #13 #14 #15 #16
#C./#V. 192/0 0/72 48/0 512/0 0/192 0/32 0/36 0/288
N.C. #17 #18 #19 #20 #21 #22 #23 #24
#C./#V. 192/0 96/0 0/256 0/8 48/0 0/8 32/0 16/0
Tab. 2 – CNS sur le jeux de donne´es ”Mushrooms”, α = 1, α = 2, α = 3
Le´gende : N.C. : nume´ro de la classe, #C./#V. : nb champignons comestibles/nb champignons ve´ne´neux
objets chacune. Nous avons mene´s plusieurs CNSs pour diffe´rentes valeurs de α
et utilise´ le concept ”pathologie” pour caracte´riser la qualite´ des CNSs obtenues (la
variable ”pathologie” n’e´tant e´videmment pas introduite dans le procesus de CNS).
Les re´sultats obtenus pour 4 valeurs diffe´rentes de α (α = 1,1.5,2,3) pre´sente´s dans le
tableau 3. montrent que les CNSs obtenues refle`tent correctement le concept ”patho-
logie”.( Pour α ≥ 3, les CNSs ont un nombre de classes strictement supe´rieur a` 4, chaque
classe e´tant homoge`ne du point de vue du concept ”pathologie”. Nos re´sultats pour une CNS
en 4 classes (taux de correction est e´gal a` 100%) sont meilleurs que ceux des k-modes reporte´s
dans [8], (taux de correction a` peu pre`s e´gal a` 96% pour les k-modes.)
N.C. #1 #2 #3 #4
α = 1 #D1/#D2/#D3/#D4 10/10/10/17
α = 1.5 #D1/#D2/#D3/#D4 10/0/0/0 0/10/10/17
α = 2 #D1/#D2/#D3/#D4 10/0/0/0 0/10/0/0 0/0/10/17
α = 3 #D1/#D2/#D3/#D4 10/0/0/0 0/10/0/0 0/0/10/0 0/0/0/17
Tab. 3 – Clusterings on ”Soybean Diseases” data
5.2 Evaluation de la Stabilite´
Un autre point d’e´valuation d’un algorithme CNS, est l’e´valuation de sa stabilite´, i.e.
”aurai je obtenu une organisation des objets similaire ou tre`s proche si l’ensemble d’ob-
jets que j’avais utilise´ avait e´te´ le´ge`rement diffe´rent (quelques objets supple´mentaires
RNTI - 1
Classification Non Supervise´e pour Donne´es Cate´gorielles
ou en moins)?”. Afin, de re´pondre a` cette question des me´thodes d’e´chantillonages et
de comparaison des partitions obtenues ont e´te´ pre´sente´es, nous utiliserons ici celle
pre´sente´e dans [10], son mode de fonctionnement est le suivant :
– on conside`re le jeu de donne´es dans son inte´gralite´ et l’on re´alise une premie`re
CNS qui constituera la classification de re´fe´rence CRef (le nombre d’objets du
jeu de donne´es est note´ n).
– On re´alise ensuite un ensemble EC de p CNSs (Ci,i = 1..p) sur des e´chantillons
de taille µ× n de ce jeu de donne´es (µ ∈]0,1],µ est appele´ facteur de dilution).
– Pour chaque CNS Ci,i = 1..p on proce`de a` une comparaison avec CRef afin de
calculer la proportion de paires d’objets (note´e propi) traite´es diffe´remment par
CRef . On dit qu’une paire d’objets est traite´e diffe´remment par CRef et Ci, si
les deux objets sont pre´sents dans l’e´chantillon ayant permis de baˆtir Ci et si
ces deux objets sont regroupe´s au sein d’une meˆme classe dans Ci alors qu’ils ne
l’e´taient pas pour CRef ou si ces deux objets ne sont pas regroupe´s au sein d’une
meˆme classe dans Ci alors qu’ils l’e´taient pour CRef . propi ∈ [0,1].
– On calcule la valeur d’un indicateur de stabilite´ de la CNS Stab qui correspond
a` la moyenne des propi. Stab ∈ [0,1].
Ainsi, une valeur e´leve´ de Stab (relativement proche de 1) correspondra a` une forte
diffe´rence entre les CNSs de EC et CRef , et donc une valeur faible de Stab (proche de
0) correspondra a` une faible diffe´rence entre les CNSs de EC et CRef . La valeur de
Stab permet alors de savoir si l’algorithme de CNS peut eˆtre conside´re´ comme stable
et son utilisation valable (la non stabilite´ impliquant la non utilisabilite´ de la me´thode
ou une recherche en profondeur des causes de la non stabilite´).
Les tests de stabilite´ de l’algorithme re´alise´s sur le jeu de donne´es ”Mushrooms”
sont pre´sente´s dans la figure. Les parame`tres suivants ont e´te´ adopte´s pour cet ensemble
de tests : le nombre de CNSs re´alise´es pour chaque niveau du facteur de dilution est 100,
la valeur du facteur de granularite´ α est 3. Ces tests montrent une excellente stabilite´
des CNSs obtenus par notre me´thode, d’ailleurs, de tels re´sultats n’auraient pas e´te´
obtenus avec la plupart des me´thodes existantes.
5.3 Evaluation de l’Efficacite´ Algorithmique
Nous ne pre´sentons pas ici une e´tude pousse´e du couˆt calculatoire de la me´thode,
nous nous contentons de pre´ciser que la complexite´ algorithmique de notre me´thode
est e´quivalente a` celle des graphes d’induction largement utilise´ en E.C.D. (cela s’ex-
pliquant notamment par un couˆt calculatoire relativement peu e´leve´) et pre´sentons le
temps de calcul assoocie´ a` diffe´rentes CNSs pour le jeux de donne´es ”mushrooms”. En
fait, nous ne pre´sentons pas explicitement les temps de calculs associe´s aux CNSs mais
le rapport suivant : R = temps de calcul associe a laCNStemps de calcul associe a laCNS en 6 classes par les k−modes .
Les rapports pre´sente´s pour les k-modes sont les valeurs moyennes de chacune des se´ries
de 10 CNSs. Ces re´sultats montrent que les K-Modes (qui sont reconnus comme une
me´thode rapide et posse´dant une bonne scalabilite´) sont plus rapides pour de faibles
nombre de classes mais que les 2 me´thodes semblent se comporter de manie`re similaire
pour des nombres de classes plus e´leve´s.
RNTI - 1
Pierre-Emmanuel JOUVE et Nicolas NICOLOYANNIS
Fig. 3 - Evaluation de la stabilite´ Fig. 4 - Rapports R associe´s a` diffe´rentes CNSs
6 Conclusion
Nous venons de proce´der a` l’e´valuation de notre me´thode de CNS qui nous a permis
de mettre en avant la qualite´ des clusters produits, la tre`s bonne stabilite´ et le couˆt
calculatoire relativement faible de la me´thode. Ces diffe´rents points constituent plu-
sieurs points forts, tout comme les avantages concernant l’utilisabilite´ cite´ a` la section
4.3 nous listons maintenant un ensemble d’autres points non aborde´s qui participent
e´galement a` rendre cette me´thode tre`s attrayante du point de vue de l’utilisateur :
(1) la pre´sence de donne´es manquantes n’est pas geˆnante : leurs conse´quences sur
la classification est comple`tement parame´trable en codant l’implication particulie`re
de la pre´sence de donne´es manquantes sur l’aspect naturel d’une partition, (2) l’in-
troduction de contraintes est possible par l’interme´diaire de l’utilisation de variables
supple´mentaires sur lesquelles on n’autorisera pas de segmentation lors du processus de
recherche de la partition naturelle approche´e (Ainsi, l’interactivite´ entre utilisateur et
processus de CNS est possible, par introduction de contraintes), (3) le nombre d’objets
par classe peut varier tre`s fortement d’une classe a` l’autre, on peut ainsi de´couvrir des
structures ne pre´sentant pas une re´gularite´ dans le nombre d’objets par classe.
Re´fe´rences
[1] Cristofor D., Simovici D., An information-theoretical approach to clustering catego-
rical databases using genetic algorithms, 2nd SIAM ICDM, Workshop on clustering
high dimensional data, 2002.
[2] Dom B., An Information-Theoretic External Cluster-Validity Measure , IBM, 2001.
RNTI - 1
Classification Non Supervise´e pour Donne´es Cate´gorielles
[3] Gibson D., Kleinberg J. M., Raghavan P., Clustering Categorical Data : An Ap-
proach Based on Dynamical Systems, VLDB Journal : Very Large Data Bases, vol.
8, n◦3–4, 2000, p. 222-236.
[4] Gowda K. C., Diday E., Symbolic Clustering using a New Dissimilarity Measure,
Pattern Recognition, vol. 24, n◦6, 1991, p. 567-578.
[5] Gro¨tschel M., Wakabayashi., A Cutting Plane Algorithm for a Clustering Problem,
Mathematical Programming, vol. 45, 1989, p. 59-96.
[6] Guha S., Rastogi R., Shim K., ROCK : A Robust Clustering Algorithm for Cate-
gorical Attributes, Information Systems, vol. 25, n◦5, 2000, p. 345-366.
[7] Halkidi M., Batistakis Y., Vazirgiannis M., On Clustering Validation Techniques,
Journal of Intelligent Information System, vol. 17, n◦2-3, 2001, p. 107-145.
[8] Huang Z., A Fast Clustering Algorithm to Cluster Very Large Categorical Data
Sets in Data Mining, Research Issues on Data Mining and Knowledge Discovery,
1997.
[9] Kodratoff Y., Tecuci G., Learning Based on Conceptual Distance, IEEE Transac-
tions on Pattern Analysis and Machine Intelligence, vol. 10, n◦6, 1988, p. 897- 909.
[10] Levine E., Domany E., Resampling Method for Unsupervised Estimation of Clus-
ter Validity, Neural Computation, vol. 13, n◦ 11, 2001, p. 2573-2593.
[11] Marcotorchino F., Michaud P., Heuristic Approach to the similarity Aggregation
Problem, Methods of Operations Research, vol. 43, 1981, p. 395-404.
[12] Merz C., Murphy P., UCI repository of machine learning databases,
http://www.ics.uci.edu/#mlearn/mlrepository.html, 1996.
[13] Michalski R. S., Stepp R. E., Automated Construction of Classifications : Concep-
tual Clustering Versus Numerical Taxonomy, IEEE Transactions on Pattern Ana-
lysis and Machine Intelligence, vol. 5, n◦ 4, 1983, p. 396-410.
[14] Michaud P., Clustering techniques, Future Generation Computer Systems, vol. 13,
n◦ 2-3, 1997, p. 135 147.
[15] Nicoloyannis N., Structures Pre´topologiques et Classification Automatique, PhD
thesis, Universite´ Lyon 1, 1988.
[16] Nicoloyannis N., Terrenoire M., Tounissoux D., An Optimisation Model for Aggre-
gating Preferences : A Simulated Annealing Approach, Health and System Science,
vol. 2, n◦ 1-2, 1998, p. 33-44.
[17] Williams W., Lambert J., Multivariate Methods in Plant Ecology, Journal of Eco-
logy, vol. 47, 1959, p. 83-101.
Summary
Clustering constitutes one of the central problem in Knowledge Discovery in Data-
bases (K.D.D.). Categorical data clustering was the object of several work these last
years, main challenges associated with these researches were the definition of well adap-
ted criteria for this particular framework and the development of fast algorithms. The
subject of this article is not to continue in these directions of research but rather to
take into account those works in order to propose and evaluate an effective method
that exhibits many advantages for the user and usable by a non-specialist.
RNTI - 1
