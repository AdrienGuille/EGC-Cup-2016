Comparaison de critÃ¨res de puretÃ© pour lâ€™intÃ©gration de
connaissances en clustering semi-supervisÃ©
Germain Forestier, CÃ©dric Wemmert, Pierre GanÃ§arski
UniversitÃ© de Strasbourg - LSIIT - CNRS - UMR 7005
PÃ´le API, Bd SÃ©bastien Brant - 67412 Illkirch, France
{forestier,wemmert,gancarski}@unistra.fr
RÃ©sumÃ©. Lâ€™utilisation de connaissances pour amÃ©liorer les processus de fouille
de donnÃ©es a mobilisÃ© un important effort de recherche ces derniÃ¨res annÃ©es. Il
est cependant souvent difficile de formaliser ce type de connaissances, comme
celles-ci sont souvent dÃ©pendantes du domaine. Dans cet article, nous nous in-
tÃ©ressons Ã  lâ€™intÃ©gration de connaissances sous la forme dâ€™objets Ã©tiquetÃ©s dans
les algorithmes de clustering. Plusieurs critÃ¨res permettant dâ€™Ã©valuer la puretÃ©
des clusters sont prÃ©sentÃ©s et leur comportement est comparÃ© sur des jeux de
donnÃ©es artificiels. Les avantages et les inconvÃ©nients de chaque critÃ¨re sont
analysÃ©s pour aider lâ€™utilisateur Ã  faire un choix.
1 Introduction
Lâ€™intÃ©gration de connaissances dans les algorithmes de clustering a connu un fort intÃ©rÃªt
ces derniÃ¨res annÃ©es, des connaissances dites du domaine (background knowledge) Ã©tant sou-
vent disponibles. Celles-ci peuvent se prÃ©senter sous des formes trÃ¨s diffÃ©rentes et sont diffi-
ciles Ã  formaliser de maniÃ¨re gÃ©nÃ©rique car elles dÃ©pendent souvent du domaine dâ€™application.
Plusieurs travaux (Wagstaff et al., 2001; Bilenko et al., 2004) se sont intÃ©ressÃ©s Ã  lâ€™utilisation
de connaissances sous la forme de contraintes entre paires dâ€™objets. Ã€ lâ€™instar dâ€™un algorithme
supervisÃ© qui va apprendre une fonction de classification, cette information peut Ãªtre utilisÃ©e
pendant le processus de clustering pour guider lâ€™algorithme vers une solution en accord avec
ces connaissances.
Un concept rÃ©current dans les mÃ©thodes utilisant ce type de connaissances est la puretÃ©
des clusters qui consiste Ã  Ã©valuer la qualitÃ© des clusters par rapport Ã  ces objets Ã©tiquetÃ©s. Un
cluster pur sera un cluster dans lequel tous les objets, dont la classe est connue, appartiennent
Ã  une et une seule classe. Un cluster impur prÃ©sentera des objets de classes diffÃ©rentes.
Lâ€™objectif de cet article est de prÃ©senter et de comparer diffÃ©rentes mÃ©thodes dâ€™Ã©valuation
de la puretÃ© des clusters. Dans la section 2, nous prÃ©sentons un Ã©tat de lâ€™art de lâ€™utilisation de
connaissances en clustering. Dans la section 3, diffÃ©rentes mesures de puretÃ© sont prÃ©sentÃ©es
et comparÃ©es. Enfin, la section 4 prÃ©sente les conclusions et les futures pistes de recherche de
ces travaux.
RNTI-E-19- 127 -
Comparaison de critÃ¨res de puretÃ© pour lâ€™intÃ©gration de connaissances
2 Ã‰valuation dâ€™un clustering
Nous considÃ©rons ici que la connaissance est un ensemble dâ€™objets Ã©tiquetÃ©s. Soit N le
nombre dâ€™objets Ã©tiquetÃ©s, C = {c1, c2, . . . , cK} les clusters trouvÃ©s par lâ€™algorithme de clus-
tering, W = {w1, w2, . . . , wC} les classes des objets Ã©tiquetÃ©s, ck les objets appartenant au
cluster k et wk lâ€™ensemble des objets de la classe k, |ck| le nombre dâ€™objets du cluster k et
nij = |wi âˆ© cj | les objets Ã  la fois dans le cluster i et de la classe j.
2.1 Calcul de puretÃ©
La faÃ§on la plus simple de calculer la puretÃ© est de chercher la classe majoritaire dans
chacun des clusters et de sommer le nombre dâ€™objets de cette classe pour chacun des clusters
(Manning et al., 2008). La puretÃ© dâ€™un clustering se dÃ©finit comme :
Î simple(C,W) =
1
N
Kâˆ‘
i
argmax
j
(nij) (1)
Une autre faÃ§on de calculer la puretÃ© des clusters est proposÃ©e par Solomonoff et al. (1998)
qui le formulent comme la probabilitÃ©, Ã©tant donnÃ© un cluster, que deux objets tirÃ©s au hasard
sans remise soient de la mÃªme classe :
Î prob(C,W) =
1
N
Kâˆ‘
i
|ck|Ï€prob(ci) avec Ï€prob(ci) =
Câˆ‘
j
( nij
|ci|
)2
(2)
Cette mesure a lâ€™avantage, par rapport Ã  la puretÃ© simple (Eq. 1), de prendre en compte la
distribution des classes minoritaires dâ€™un cluster (i.e. les classes autres que la classe majori-
taire), et favorise donc les clusters prÃ©sentant un nombre limitÃ© de classes diffÃ©rentes.
Ces deux mesures de puretÃ© ont cependant un inconvÃ©nient majeur, qui est de surÃ©valuer la
qualitÃ© dâ€™un clustering avec un nombre important de clusters. DiffÃ©rentes propositions ont Ã©tÃ©
faites pour rÃ©soudre ce problÃ¨me. Par exemple, Ajmera et al. (2002) ont proposÃ© de calculer
la puretÃ© des clusters en terme de classes ainsi que la puretÃ© des classes en terme de clusters,
câ€™est Ã  dire pour chaque classe sa rÃ©partition dans les diffÃ©rents clusters. Ces deux valeurs sont
ensuite combinÃ©es pour donner une Ã©valuation globale du clustering. ConsidÃ©rer Ã©galement la
puretÃ© des classes permet de pÃ©naliser un nombre trop important de clusters. La puretÃ© des
classes se calcule de maniÃ¨re similaire Ã  la puretÃ© des clusters mais en observant la distribution
des clusters des objets dans chaque classe :
Î gprob(C,W) = 1N
Kâˆ‘
i
|ck|Ï€gprob(wi) avec Ï€gprob(wi) =
Câˆ‘
j
( nij
|wi|
)2
(3)
La puretÃ© des clusters et la puretÃ© des classes sont ensuite combinÃ©es :
Î overall(C,W) =
âˆš
Î prob(C,W)Ã—Î gprob(C,W) (4)
Une autre approche consiste Ã  considÃ©rer Ã©galement une mesure de la qualitÃ© du clustering
Ã  partir des donnÃ©es. Demiriz et al. (1999) utilisent un algorithme pour optimiser la puretÃ© des
RNTI-E-19 - 128 -
Forestier et al.
clusters appelÃ© Gini et similaire Ã  Eq. 2. Pour Ã©viter que lâ€™algorithme ne gÃ©nÃ¨re une solution
avec un nombre trop important de clusters, la fonction objective est une moyenne arithmÃ©tique
de la puretÃ© des clusters et de la qualitÃ© du clustering. La combinaison de ces deux critÃ¨res
permet dâ€™Ã©viter des solutions trop extrÃªmes.
Enfin, Eick et al. (2004) ont Ã©galement proposÃ© dâ€™introduire une notion de pÃ©nalitÃ© par
rapport au nombre de clusters de la solution proposÃ©e afin de rÃ©soudre ce problÃ¨me. Cette
mÃ©thode permet de pÃ©naliser une solution ayant un nombre de clusters trop important par
rapport au nombre de classes.
penalty(K) =
â§âªâ¨âªâ©
âˆš
Kâˆ’C
N siK â‰¥ C
0 sinon
(5)
avec K le nombre de clusters, C le nombre de classes et N le nombre dâ€™objets. Cette
pÃ©nalitÃ© est retranchÃ©e de lâ€™indice de puretÃ© choisi, pondÃ©rÃ©e par un paramÃ¨tre Î², comme suit :
Î penalty(C,W) = Î simple(C,W)âˆ’ Î²penalty(K) (6)
Une autre solution est dâ€™utiliser le cadre de la thÃ©orie de lâ€™information et dâ€™Ã©valuer lâ€™infor-
mation mutuelle normalisÃ©e entre les connaissances et le clustering :
Î nmi(C,W) =
I(C,W)
[H(C) +H(W)]/2
(7)
I est lâ€™information mutuelle :
I(C,W) =
âˆ‘
i
âˆ‘
j
nij
N
log
nij/N
|ci|/N Ã— |wj |/N (8)
=
âˆ‘
i
âˆ‘
j
nij
N
log
nij Ã—N
|ci| Ã— |wj | (9)
H est lâ€™entropie :
H(W) = âˆ’
âˆ‘
k
|wk|
N
log
|wk|
N
(10)
2.2 Comparaison de partitions
Un autre indice couramment utilisÃ© est lâ€™indice de Rand (Rand, 1971) qui permet de com-
parer des partitions. Dans notre cas, il consiste Ã  vÃ©rifier si les couples dâ€™objets de la mÃªme
classe dâ€™aprÃ¨s les connaissances disponibles, ont Ã©tÃ© placÃ©s dans un mÃªme cluster. On dit quâ€™un
couple dâ€™objets est un vrai positif (VP) si les deux objets sont de la mÃªme classe et sont placÃ©s
dans le mÃªme cluster, et un vrai nÃ©gatif (VN) quand les deux objets sont de classes diffÃ©rentes
et sont placÃ©s dans deux clusters diffÃ©rents. Un faux positif (FP) correspond Ã  deux objets de
RNTI-E-19- 129 -
Comparaison de critÃ¨res de puretÃ© pour lâ€™intÃ©gration de connaissances
 0  0.2  0.4  0.6  0.8  1
 0
 0.2
 0.4
 0.6
 0.8
 1
(a)
 0  0.2  0.4  0.6  0.8  1
 0
 0.2
 0.4
 0.6
 0.8
 1
(b)
FIG. 1 â€“ Deux jeux de donnÃ©es utilisÃ©s.
classes diffÃ©rentes placÃ©s dans le mÃªme cluster. Un faux nÃ©gatif (FN) correspond Ã  deux objets
de la mÃªme classe dans deux clusters diffÃ©rents. Il peut Ãªtre dÃ©fini de la maniÃ¨re suivante :
Î rand(C,W) =
V P + V N
V P + FP + FN + V N
(11)
(V P +FP +FN +V N) reprÃ©sentant tous les couples possibles dâ€™objets et (V P +V N)
les couples dâ€™objets correctement classÃ©s. Lâ€™indice de Rand donne cependant un poids Ã©gal
aux faux positifs et aux faux nÃ©gatifs.
La F-Mesure (van Rijsbergen, 1979) quant Ã  elle, permet de pondÃ©rer ces deux valeurs en
tenant compte de la prÃ©cision (P) et du rappel (R) :
P =
V P
V P + FP
R =
V P
V P + FN
Î fmesure(C,W) =
(Î²2 + 1)P Ã—R
Î²2P +R
(12)
Si Î² = 1, valeur retenue dans cet article, la prÃ©cision et le rappel ont alors la mÃªme im-
portance. Lâ€™avantage de ces deux indices (Î rand etÎ fmesure) est quâ€™ils intÃ¨grent implicitement
le nombre de clusters, en dÃ©favorisant naturellement les solutions avec un nombre de clusters
trop important.
2.3 Ã‰valuation des diffÃ©rents critÃ¨res de qualitÃ©
Dans cette section nous allons Ã©valuer les critÃ¨res prÃ©sentÃ©s dans la section prÃ©cÃ©dente
sur diffÃ©rents jeux de donnÃ©es de test. La figure 1 prÃ©sente trois jeux de donnÃ©es artificiels
reprÃ©sentant chacun quatre clusters dans un espace Ã  deux dimensions. Lâ€™algorithme KMEANS
a Ã©tÃ© utilisÃ© sur ces jeux de donnÃ©es avec des nombres de clusters variant de 2 Ã  8 (8 Ã©tant
deux fois le nombre de clusters attendu). Pour chaque clustering, les mesures prÃ©sentÃ©es dans
les sections prÃ©cÃ©dentes ont Ã©tÃ© calculÃ©es. Trois configurations diffÃ©rentes ont Ã©tÃ© Ã©valuÃ©es, la
premiÃ¨re avec 1% des donnÃ©es Ã©tiquetÃ©es, la seconde avec 10% des donnÃ©es Ã©tiquetÃ©es et enfin
la derniÃ¨re avec 25% des donnÃ©es Ã©tiquetÃ©es. Chaque expÃ©rience a Ã©tÃ© effectuÃ©e 100 fois avec
des initialisations alÃ©atoires de lâ€™algorithme, puis les rÃ©sultats ont Ã©tÃ© moyennÃ©s. Les figures 2
et 3 reprÃ©sentent les rÃ©sultats respectivement pour les jeux de donnÃ©es des figures 1(a) et 1(b).
RNTI-E-19 - 130 -
Forestier et al.
 
 
 
 
 

   	  
 






  
Î  
Î 	

Î 
Î 
 

Î  
Î 
 		
Î  
	
(a) 1%
 
 
 
 
 

   	  
 






  
Î  
Î 	

Î 
Î 
 

Î  
Î 
 		
Î  
	
(b) 10%
 
 
 
 
 

   	  
 






  
Î  
Î 	

Î 
Î 
 

Î  
Î 
 		
Î  
	
(c) 25%
FIG. 2 â€“ Evolution des critÃ¨res en fonction du nombre de clusters pour le jeu donnÃ© Fig. 2 (a).
 
 
 
 
 

   	  
 






  
Î  
Î 	

Î 
Î 
 

Î  
Î 
 		
Î  
	
 
 
 
 
 

   	  
 






(a) 1%
 
 
 
 
 

   	  
 






  
Î  
Î 	

Î 
Î 
 

Î  
Î 
 		
Î  
	
(b) 10%
 
 
 
 
 

   	  
 






  
Î  
Î 	

Î 
Î 
 

Î  
Î 
 		
Î  
	
(c) 25%
FIG. 3 â€“ Evolution des critÃ¨res en fonction du nombre de clusters pour le jeu donnÃ© Fig. 2 (b).
Quand le nombre dâ€™objets Ã©tiquetÃ©s disponibles est faible (1%), la majoritÃ© des critÃ¨res ont
un comportement trÃ¨s alÃ©atoire. En effet, il nâ€™est pas du tout garanti dâ€™avoir des objets pour
chacune des classes du jeu de donnÃ©es. Câ€™est pourquoi ces critÃ¨res sont difficilement utilis-
ables quand vraiment trÃ¨s peu de connaissances sont disponibles. Quand le nombre dâ€™objets
Ã©tiquetÃ©s augmente (10%), il est plus probable dâ€™avoir des objets Ã©tiquetÃ©s pour chaque classe.
Par consÃ©quent, les courbes deviennent plus caractÃ©ristiques. Le problÃ¨me prÃ©sentÃ© prÃ©cÃ©dem-
ment sur le fait que les mesures de puretÃ© simples surÃ©valuent la qualitÃ© du clustering quand le
nombre dâ€™objets augmente peut Ãªtre observÃ©. En effet, la puretÃ© simple (Î simple) ainsi que la
puretÃ© par cluster (Î prob) ne font quâ€™augmenter avec le nombre de clusters. Les autres indices
(Î rand,Î nmi,Î fmesure,Î overall,Î penalty) ont tendance Ã  diminuer avec lâ€™augmentation du nom-
bre de clusters. Les plus caractÃ©risques Ã©tantÎ fmesure,Î overall et leÎ nmi. Les critÃ¨resÎ rand et
Î penalty diminuent de faÃ§on moins caractÃ©ristique. Il est intÃ©ressant de noter quâ€™il nâ€™y a pas de
diffÃ©rence importante entre les rÃ©sultats obtenus avec 10% dâ€™objets Ã©tiquetÃ©s et 25% dâ€™objets
Ã©tiquetÃ©s.
3 Conclusion
Lâ€™intÃ©gration de connaissances dans les algorithmes de classification non supervisÃ©e reprÃ©-
sente un enjeu important. De plus en plus de connaissances implicites ou explicites sont disponibles
et il convient de dÃ©velopper des approches permettant dâ€™en tirer parti. Dans cet article, nous
avons abordÃ© lâ€™utilisation dâ€™objets Ã©tiquetÃ©s pour Ã©valuer la puretÃ© dâ€™un rÃ©sultat de clustering.
Plusieurs critÃ¨res ont Ã©tÃ© prÃ©sentÃ©s, formalisÃ©s et comparÃ©s. Il en ressort que les critÃ¨res Ã©val-
RNTI-E-19- 131 -
Comparaison de critÃ¨res de puretÃ© pour lâ€™intÃ©gration de connaissances
uant la puretÃ© sans prendre en compte le nombre de clusters peuvent rapidement surÃ©valuer
la qualitÃ© des rÃ©sultats. Pour rÃ©soudre ce problÃ¨me, il est possible de prendre en compte une
mesure qui va pÃ©naliser les rÃ©sultats avec un nombre de clusters trop important. Dâ€™autres types
de critÃ¨res qui comparent le regroupement de couples dâ€™objets prennent en compte implicite-
ment le nombre de clusters. Câ€™est notamment le cas de la F-Mesure qui a donnÃ© des rÃ©sultats
particuliÃ¨rement bons lors de nos expÃ©riences.
RÃ©fÃ©rences
Ajmera, J., H. Bourlard, I. Lapidot, et I. McCowan (2002). Unknown-multiple speaker cluster-
ing using hmm. In International Conference on Spoken Language Processing, pp. 573â€“576.
Bilenko, M., S. Basu, et R. J. Mooney (2004). Integrating constraints and metric learning in
semi-supervised clustering. In International Conference on Machine Learning, pp. 81â€“88.
Demiriz, A., K. Bennett, et M. Embrechts (1999). Semi-supervised clustering using genetic
algorithms. In Intelligent Engineering Systems Through Artificial Neural Networks, pp.
809â€“814.
Eick, C. F., N. Zeidat, , et Z. Zhao (2004). Supervised clustering - algorithms and benefits. In
International Conference on Tools with Artificial Intelligence, pp. 774â€“776.
Manning, C. D., P. Raghavan, et H. SchÃ¼tze (2008). Introduction to Information Retrieval.
Cambridge University Press.
Rand, W. M. (1971). Objective criteria for the evaluation of clustering methods. Journal of the
American Statistical Association 66, 622â€“626.
Solomonoff, A., A. Mielke, M. Schmidt, et H. Gish (1998). Clustering speakers by their
voices. In Acoustics, Speech and Signal Processing, 1998. Proceedings of the 1998 IEEE
International Conference on, Volume 2, pp. 757â€“760.
van Rijsbergen, C. J. (1979). Information Retrieval. London : Butterworths.
Wagstaff, K., C. Cardie, S. Rogers, et S. Schroedl (2001). Constrained k-means clustering with
background knowledge. In International Conference on Machine Learning, pp. 557â€“584.
Summary
In recent years, the use of background knowledge to improve the data mining process has
been intensively studied. Indeed, background knowledge along with knowledge directly or
indirectly provided by the user are often available. However, it is often difficult to formalize
this kind of knowledge, as it is often dependent of the domain. In this article, we studied the
integration of knowledge as labeled objects in clustering algorithm. Several criteria allowing
the evaluation of the purity of a clustering are presented and their behavior is compared using
artificial datasets. Advantages and drawbacks of each criteria are analyzed in order to help the
user to make a choice among them.
RNTI-E-19 - 132 -
