Analyse de la Vraisemblance des Liens Relationnels : Une
méthodologie d’analyse classificatoire des données
Israël-César Lerman
Université de Rennes 1-IRISA Projet Symbiose,
Campus Universitaire de Beaulieu, 35042 Rennes Cedex
lerman@irisa.fr
http://www.irisa.fr/symbiose/
Résumé. La méthodologie de classification des données par l’Analyse de la
Vraisemblance des Liens Relationnels a pris naissance vers la fin des années
soixante. Elle s’est très largement développée. De nombreux chercheurs et pra-
ticiens ont pris part à son développement. De nombreuses applications d’en-
vergure provenant des domaines les plus divers (Bioinformatique, Informatique,
Sciences sociales, Traitement d’images, Traitement de langues naturelles, ...) ont
validé cette méthodologie. Elle s’adresse à n’importe quel type mathématico-
logique du tableau de description des données. L’objet de notre article est de
présenter de façon illustrée les principes fondamentaux de cette approche. Ces
principes se situent d’une part au niveau de la représentation de la description et
d’autre part, au niveau de l’évaluation quantifiée des ressemblances entre les
structures mathématiques à comparer. Dans notre cas la représentation de la
description sera ensembliste et relationnelle et la ressemblance sera évaluée au
moyen d’une similarité qui se réfère à une échelle de probabilité établie par rap-
port à une hypothèse statistique d’absence de liaison. Le texte ci-dessous se veut
le reflet de ma présentation orale aux “3-èmes Journées Thématiques Apprentis-
sage Artificiel et Fouille des Données”, 8-9 avril 2008.
1 Préambule
Mon texte s’apparente à une introduction. Il se veut le reflet exact de ma présentation orale
aux “3-èmes Journées Thématiques Apprentissage Artificiel et Fouille des Données”, 8-9 avril
2008. Ce texte ne correspond pas à la forme classique d’un article.
Il s’agit pour nous de présenter une méthodologie d’analyse classificatoire des données sur
laquelle nous avons travaillé de très longues années. De nombreuses collaborations ont contri-
bué de façon importante à sa mise au point. Cette méthode n’est pas vraiment connue dans ses
différentes facettes ; alors qu’elle repose sur deux principes fondamentaux. Le premier consiste
en la représentation ensembliste et relationnelle des variables (attributs) de description de l’en-
semble des objets ou individus et le second, en l’évaluation probabiliste de la similarité entre
les structures mathématiques à comparer (Indices de la vraisemblance des liens). Ces prin-
cipes sont concrétisés quelle que soit la complexité de la description des données. Il peut s’agir
Classification par la vraisemblance des liens relationnels
d’associer des descripteurs (resp., des objets), des classes de descripteurs (resp., des classes
d’objets), il peut aussi s’agir de reconnaître des agrégats “intéressants” qui se distinguent, ...
Dans ma présentation, je chercherai autant que possible à insister sur les principes en m’ap-
puyant sur des exemples.
Il est fondamental d’avoir à l’esprit qu’une méthodologie d’Analyse des Données se conçoit
toujours par rapport à une algorithmique d’un type donné. À cet égard, les concepteurs de mé-
thodes de classification ont vite tendance à vouloir faire oublier l’algorithmique qui a servi
de nid de fécondation aux méthodes construites pour parler de “théorie générale”. Certes, il
est très important et très intéressant de vouloir transposer les acquis méthodologiques dans le
cadre d’autres algorithmiques ; et d’ailleurs, c’est une richesse de l’approche initialement pro-
posée. Dans notre cas l’algorithmique en question est fournie par la Classification Ascendante
Hiérarchique, la CAH, comme on dit.
Il sera donc juste de rappeler le principe et les ingrédients de cette algorithmique pour
montrer comment ils se déclinent dans le cadre de l’Analyse de la Vraisemblance des Liens
Relationnels AV LR. Le plan de notre présentation est :
1. Préambule
2. Introduction : principes généraux et exemples
3. Le principe algorithmique et les éléments constitutifs d’une CAH
4. La méthode de l’Analyse de la Vraisemblance des Liens Relationnels (Une présentation
à partir d’exemples)
5. Les grands types logico-mathématiques de données
6. Logiciels et Applications
7. Références
2 Introduction : principes généraux et exemples
2.1 Le paradigme de la CAH, schéma d’arbre et exemples
Le paradigme de la CAH remonte à loin ...Michel Adanson, dans son Histoire naturelle du
Sénégal (Bauche, Paris, 1757) écrivait :
“Je me contenterai de rapprocher les objets suivant le plus grand nombre de degrés de leurs
rapports et de leurs ressemblances ... Les objets ainsi réunis formeront plusieurs petites fa-
milles que je réunirai encore afin d’en faire un tout dont les parties soient unies et liées inti-
mement.”
Je pourrais peut-être ajouter : “liées intimement” sur le plan de la cohérence.
Le schéma d’arbre, tel que celui présenté ci-dessous (voir FIG. 1) sur un ensemble E de 10
éléments, donne précisément une image de la suite des rapprochements telle que décrite par
Michel Adanson ; en “petites” familles puis ces dernières en de plus “grosses”. Le processus
de rapprochement est parfaitement conforme à la construction ascendante hiérarchique d’un
RNTI - G - 2
I.C. Lerman
arbre des classifications. Le niveau 0 est celui des feuilles de l’arbre. Chaque feuille représente
- j’allais dire un élément - plus exactement, une partie comprenant exactement un élément.
Entre les niveaux 0 et 1 on a les rapprochements suivants : {g} et {h}, {f} et {i} et {c} et {e}.
Entre les niveaux 1 et 2, on a d’une part le rapprochement entre {b} et {g, h} et d’autre part,
celui entre {a}, {j} et {c, e}. Ce dernier rapprochement donne lieu au noeud {a, c, e, j}. La
racine de l’arbre correspond à l’ensemble plein E. Après une étape donnée on peut distinguer
la notion de classification (partition) produite à un niveau donné. Ainsi, en est-il de la partition
{{b, g, h}, {d}, {f, i}, {a, c, e, j}} qu’on peut noter pi2, produite au niveau 2 de l’arbre.
.    .    .    .    .    .    .    .    .    .
.       .      .       .      .       .      .
.          .       .              .
.              .                  .
.
{b} {g}{h}{d}{f}{i} {a}{c} {e}{j}
E = {a, b, c, d, e, f, g, h, i, j}
E = {a, b, c, d, e, f, g, h, i, j}
0
1
2
3
4
{a, c, e, j}
FIG. 1 – Un exemple d’arbre de classification.
Rentrons maintenant dans le vif du sujet et considérons une illustration réelle issue d’un
travail de thèse citée dans les références (M. Ouali-Allah). Il s’agit d’une partie d’une enquête
d’opinion réalisée en 1989 par l’institut d’Agoramétrie qui dépendait du consortium CEA-
EDF. L’objet de l’enquête globale portait sur les conflits qui pouvaient alors agiter l’opinion
publique. Pour la partie concernée de l’enquête où un échantillon de 500 individus ont été
intérrogés, 19 questions, chacune associée à un homme politique, de la forme suivante, ont été
introduites :
“Souhaitez-vous voir jouer un rôle important à tel homme politique”
Les codes des résultats à la question posée sont :
1. OUI
2. NON
3. SANS RÉPONSE
Chaque question définit ainsi une variable qualitative à 3 valeurs (on dit encore modalités
ou catégories). Le plus classique consiste à ne considérer aucune structure sur l’ensemble des
RNTI - G - 3
Classification par la vraisemblance des liens relationnels
R. BARRE
S. VEIL
B. LALONDE
A. WAECHTER
L. FABIUS
L. JOSPIN
J. LANG
J. M. LEPEN
G. MARCHAIS
F. MITTERAND
M. ROCCARD
P. BEREGOVOY
J. DELORS
P. MEHAIGNERIE
M. SEGUIN
J. CHIRAC
V.G. D’ESTAING
F. LEOTARD
M. NOIR
6
3
1
7
11
16
 
 
12
5
2
13
*
4
10*
9
8
14
15
17*
18
FIG. 2 – Un premier arbre organisant l’opinion politique dans la France de 1989.
valeurs de la variable. Il s’agit dans ce cas d’une variable qualitative nominale. Une interpréta-
tion plus riche résulte d’une similarité ordinale, pouvant être posée par l’expert, sur l’ensemble
des valeurs de la variable. Il s’agira alors d’une variable qualitative préordonnance. Nous avons
retenu le préordre total suivant sur l’ensemble des paires de valeurs :
{1, 2} < {2, 3} < {1, 3} < {1, 1} ∼ {2, 2} ∼ {3, 3} (1)
où les catégories “OUI” et “NON” sont les plus dissemblables et où, la ressemblance entre
une catégorie et elle même est maximale quelle que soit la catégorie. On comprendra égale-
ment la position des autres paires de catégories.
C’est la même méthode, celle précisément de l’AV LR qui a été appliquée pour chacun
des deux codages. Dans le premier résultat, où le codage classique a été utilisé, la droite et la
gauche politiques ont certes une certaine influence dans les regroupements ; mais, elles ne se
séparent pas vraiment. La tendance qui domine dans les associations ou séparations est celle
d’une certaine rigueur, voire de sectarisme, face à une certaine ouverture, autour du patrio-
tisme allant jusqu’au nationalisme, d’attachement à la terre, ... . Ainsi voit-on des associa-
tions telles que “Lepen-Marchais”, “Mitterand-Rocard”, “Méhaignerie-Séguin”, “Beregovoy-
Delors”, “Veil-Barre”, “Lalonde-Waechter”, ... .
Considérons à présent le second résultat où le codage en termes de préordonnance a été uti-
lisé. Dans ce cas la droite et la gauche se séparent clairement. D’autre part, au sein de chacune
RNTI - G - 4
I.C. Lerman
R. BARRE
S. VEIL
J. CHIRAC
V.G. D’ESTAING
F. LEOTARD
M. NOIR
P. MEHAIGNERIE
M. SEGUIN
P. BEREGOVOY
J. DELORS
F. MITTERAND
M. ROCCARD
L. FABIUS
L. JOSPIN
J. LANG
B. LALONDE
A. WAECHTER
J.M. LEPEN
G. MARCHAIS
3
5
12
1
10   *
15*
8
2
13
*
6
4
11
16
18
17
9
7
14
FIG. 3 – Un deuxième arbre organisant l’opinion politique dans la France de 1989.
de ces deux formations politiques on distingue la vieille et traditionnelle génération et celle
montante. Ainsi, pour la droite, la génération la plus classique est représentée par {J.Chirac,
V.G. D’estaing, R. Barre, S. Veil} ; celle plus jeune et avec un accent nouveau, par {F. Léotard,
M. Noir, M. Séguin, P. Méhaignerie}. Pour la gauche, la génération classique est représentée
par {F. Mitterand, M. Roccard, P. Beregovoy, J. Delors} et celle, jeune et montante par {L.
Fabius, L. Jospin, J. Lang}. Une dernière classe {J.M. Lepen, G. Marchais, B. Lalonde, J.
Waechter} regroupe les aspects les plus extrêmes du paysage politique français où le nationa-
lisme et l’attachement à la terre sont présents.
La comparaison de ces deux résultats illustre toute l’importance de la prise en compte d’une
structure relationnelle au niveau de l’ensemble des valeurs d’une même variable descriptive.
2.2 Le tableau des données et son analyse par la classification
2.2.1 Le tableau des données
Dans la très grande majorité des cas, mais pas toujours, les données peuvent être représen-
tées au moyen d’un tableau (voir FIG. 4).
La description peut concerner un ensemble O d’objets élémentaires ou bien, un ensemble
C de catégories (on dit encore “concepts”). Les colonnes du tableau des données sont indexées
par l’ensemble A des attributs (variables) de description. En supposant que le nombre d’attri-
buts est p et que le nombre d’objets (resp., catégories) est n, on peut noter :
RNTI - G - 5
Classification par la vraisemblance des liens relationnels
aj
oi/ci
A
O
C
aj(oi/ci)
Valeur observée ou résultat 
d’une connaissance d’expert
FIG. 4 – Le tableau des données.
A = {aj |1 ≤ j ≤ p}
O = {oi|1 ≤ i ≤ n} , C = {ci|1 ≤ i ≤ n}
Si la description concerne un ensemble O d’objets (resp., un ensemble C de catégories),
la i-ème ligne du tableau est indexée par l’objet élémentaire oi (resp., par la catégorie ci),
1 ≤ i ≤ n. De toute façon, la j-ème colonne du tableau est indexée par l’attribut aj , 1 ≤ j ≤ p.
D’autre part, quel que soit l’ensemble décrit (un ensemble d’objets ou un ensemble de catégo-
ries), à l’intersection de la i-ème ligne et de la j-ème colonne se trouve une valeur observée ou
une connaissance d’expert de l’attribut aj sur l’objet oi s’il s’agit d’une description d’objets,
ou sur la catégorie ci, s’il s’agit d’une description de catégories.
Dans le cas des données ci-dessus, il s’agit de la description d’un ensemble O d’objets
élémentaires qui est défini par l’échantillon formé des 500 individus. D’autre part, comme cela
a déjà été exprimé, on dispose de 19 variables qualitatives. La valeur aj(oi) est représentée
par le code de la réponse du i-ème individu à la j-ème question, 1 ≤ i ≤ 500, 1 ≤ j ≤ 19.
Comme nous l’avons vu, ce code est 1, 2 ou 3.
Il est important de noter que le tableau des données ne peut en aucun cas contenir l’in-
formation concernant la structure relationnelle dont se trouve munie l’ensemble des valeurs
d’une même variable descriptive. Ainsi dans l’exemple ci-dessus, on précise la structure pré-
ordonnance qui est supposée sur l’ensemble des valeurs d’une variable qualitative préordon-
nance donnée. D’ailleurs, même dans le cas d’une variable qualitative nominale, le calcul tient
compte de l’absence de structure sur l’ensemble des modalités de la variable.
Les données de connaissance qui sont parfois appelées “symboliques” peuvent parfaite-
ment rentrer dans le moule précédent et être traitées efficacement par l’AV LR. D’ailleurs, nous
présenterons en section 5 notre expression formelle des grands types logico-mathématiques de
données.
RNTI - G - 6
I.C. Lerman
2.2.2 Analyse et réorganisation par la classification hiérarchique du tableau des don-
nées
Les classifications proposées ci-dessus sont des classifications hiérarchiques d’ensembles
de variables. Il est clair que - pour chacun des deux codages proposés ci-dessus (qualitatif
nominal et qualitatif préordonnance) - nous aurions pu poursuivre par une classification de
l’ensemble des 500 individus. Peut-être que nous pouvons évoquer ici la réalisation de ce type
de classification dans le cas d’un codage pouvant être apparenté à celui “préordonnance”.
Il s’agissait d’un ensemble d’objets définis par des séquences protéiques. Une séquence pro-
téique est une suite d’acides aminés et peut être représentée comme un mot dans un alphabet à
20 lettres. La description relationnelle suppose précisément un graphe valué complet sur l’en-
semble des 20 lettres.
Une étape ultime - nous y reviendrons - consistera à situer des classes de variables par
rapport à des classes d’objets. En effet, la réorganisation des lignes et des colonnes d’un ta-
bleau de données conformément à un couple d’arbres de classification (issus de la CAH), le
premier sur l’ensemble des attributs descriptifs et le second sur l’ensemble des objets, est très
riche d’enseignement sur le plan de l’interprétation des tendances comportementales. Consi-
dérons à cet égard une illustration schématique très simplifiée où on considère un très petit
tableau de données de présence-absence, décrivant un ensemble de 5 objets au moyen se 4 at-
tributs booléens (voir FIG. 5). Le croisement des deux arbres de classification (sur l’ensemble
A des attributs de description et sur l’ensembleO des objets décrits) donne la partie droite de la
figure, où une case noircie indique que l’attribut est à V RAI . La reconnaissance de niveaux in-
téressants (nous disons “significatifs”) sur chacun des deux arbres permet de situer des classes
cohérentes d’objets par rapport à des classes cohérentes de variables. Nous avons repéré sur
chacun des deux arbres un niveau “significatif”. Il s’agit du deuxième (resp., troisième) niveau
pour l’arbre de classification sur A (resp., O). Ces niveaux sont indiqués sur la partie droite
de la figure. La partition déterminée sur l’ensemble A est pi = {{a1, a2}, {a3, a4}}, celle dé-
terminée sur l’ensemble O est χ = {{o1, o2, o4}, {o3, o5}}. Si la classe {o1, o2, o4} est en
correspondance avec la classe {a1, a2}, celle {o3, o5}, l’est avec la classe {a3, a4}. Pour ce
qui est de la première correspondance on constatera que l’association la plus forte est relative à
la sous classe {o1, o2}. Pour ce qui est de la deuxième correspondance, on peut aussi constater
que l’association la plus forte concerne la sous-classe {o3}.
Il y a bien sûr de nombreuses méthodes de classification conjointe des lignes et des co-
lonnes d’un tableau de données booléennes ou numériques, où on cherche à optimiser au mieux
un critère objectif. Cependant, il faut être conscient que la philosophie qui préside au croise-
ment de deux arbres condensés à leurs niveaux les plus “significatifs” n’est pas vraiment la
même. Deux questions importantes de complexité subsistent : la première de nature statistique
et la seconde de nature formelle. Pour la première, il s’agit de savoir comment gérer un tel
croisement en cas d’un “gros” tableau de données. D’autre part, comment gérer le cas où les
variables descriptives sont complexes ; par exemple le cas où l’ensemble des valeurs d’une
même variable est muni d’une structure relationnelle.
RNTI - G - 7
Classification par la vraisemblance des liens relationnels
1 1 0 0
1 1 0 0
0 0 1 1
1 0 0 0
0 0 1 0
A
O
o1
o2
o3
o4
o5
a
1
a
2
a
3
a
4
A
O
o1
o2
o3
o4
o5
a
1
a
2
a
3
a
4
FIG. 5 – La source (le tableau des données) et le but (deux arbres de classification croisés).
3 Le principe algorithmique et les éléments d’une CAH
3.1 Une expression formalisée de la démarche d’Adanson
La donnée est un couple de la forme (E, δ) où E est l’ensemble à organiser par la Classifi-
cation Ascendante Hiérarchique. Nous avons déjà vu queE peut être un ensembleA d’attributs
(de variables) de description, un ensemble O d’objets élémentaires ou un ensemble C de ca-
tégories. δ correspond à une notion de dissimilarité quantifiée numériquement entre parties
disjointes de E.
L’état initial se trouve défini par l’ensemble des parties singletons de E qu’on peut noter
P0 = {{e}|e ∈ E}. P0 détermine une partition en classes à un élément de E. La progression
de l’algorithme est définie comme suit :
D’un niveau au suivant de l’arbre agréger les paires de classes
“les plus proches” au sens de δ
Dans cette expression on ne suppose pas nécessairement qu’il y a une seule fusion bi-
naire de classes qui est opérée en passant d’un niveau de l’arbre au suivant. D’ailleurs, dans
le schéma de la figure 1, trois fusions binaires de classes sont opérées “en même temps” pour
passer du niveau 1 au niveau 2.
La condition d’arrêt est définie par l’obtention d’une seule classe qui regroupe tous les élé-
ments de E.
On comprend dans ces conditions que la question fondamentale est de savoir comment
élaborer l’indice numérique δ compte tenu de la nature de l’ensemble à organiser et de sa
description. Il est clair que la première étape doit consister en la définition d’un indice de dis-
similarité d entre éléments de E. Cette définition conduit à un tableau carré de dissimilarité de
la forme :
{d(x, y)|(x, y) ∈ E × E} (2)
RNTI - G - 8
I.C. Lerman
d est une fonction numérique à valeurs positives qui, dans le cas classique, est symétrique :
d(x, y) = d(y, x) pour tout (x, y) ∈ E ×E, pour laquelle on a : d(x, x) = 0 pour tout x ∈ E.
Maintenant, comment définir d compte tenu de la nature deE et des caractéristiques mathé-
matiques et statistiques du tableau des données (voir ci-dessus). D’autre part, comment opérer
le passage crucial entre l’indice d entre éléments de E et celui δ entre parties disjointes de E.
3.2 Une expression formelle plus générale et formule de réactualisation
La donnée est maintenant un triplet de la forme (E,µE , d) où, avec les mêmes notations
que ci-dessus, µE = {µx|x ∈ E} se trouve défini par un système de poids ponctuels affec-
tés aux éléments de E. La dissimilarité d sur E, représentée toujours au moyen du tableau
{d(x, y)|(x, y) ∈ E × E}, fait généralement intervenir ces poids.
Il s’agit maintenant pour pouvoir construire une CAH de passer du triplet précédent à un
triplet de la forme : (P(E), µP , δ) où P(E) désigne l’ensemble des parties de E et où µP
désigne l’extension additive de µE sur P(E). Plus précisément,
∀Z ∈ P(E) , µZ =
∑
z∈Z
µz (3)
Comme ci-dessus, δ définit une notion de dissimilarité sur P(E) ; mais dépendant de µP .
δ se présente sous la forme de l’application suivante :
δ :
(
P(E)× P(E) , µP
)
−→ R+ (4)
où R+ désigne l’ensemble des nombres réels positifs. Plus précisément et de façon assez
générale - pour couvrir l’ensemble de tous les critères de fusion de paires de classes qui ont pu
être proposés - la fonction δ peut s’écrire :
∀(X,Y ) ∈ P(E)× P(E) ,
δ(X,Y ) = f [{d(x, y)|(x, y) ∈ (X ∪ Y )× (X ∪ Y )} , {µz|z ∈ X ∪ Y }] (5)
où f est une fonction numérique à valeurs positives dépendant de deux arguments. Le pre-
mier est le tableau des dissimilarités sur l’union X ∪ Y des deux classes X et Y à comparer
et le second, est le système des masses ponctuelles surX ∪ Y . Cette équation exprime que les
classes formées déjà en dehors deX∪Y n’interviennent pas dans la comparaison entreX et Y .
On peut voir la construction ascendante hiérarchique d’un arbre de classification comme
l’évolution d’un système. Si k est un niveau donné de l’arbre, nous caractérisons l’état du sys-
tème par le couple (Tk, µk), où Tk est la matrice des dissimilarités δ entre classes déjà formées
au niveau k et où µk est la mesure (telle que µP ci-dessus) sur l’ensemble de ces classes.
L’état initial (T0, µ0) est défini par la matrice T0 des indices δ entre classes singletons (com-
prenant chacune exactement un élément) et par le système initial de poids µ0 où chaque classe
singleton {x} est affectée par le poids de l’élément x concerné, x ∈ E. En désignant par l
le dernier niveau de l’arbre (l = 4 dans l’exemple de la figure 1), les états du système pour
0 ≤ k ≤ l−1 ont à être considérés. Dans ces conditions, la formule suivante appelée “formule
de réactualisation” est de la première importance :
RNTI - G - 9
Classification par la vraisemblance des liens relationnels
(Tk+1, µk+1) = ϕ(Tk, µk) (6)
où ϕ est une fonction à déterminer compte tenu de l’expression spécifique de l’indice δ
choisi de comparaison entre classes (critère de fusion). Une telle équation dite aussi formule de
“récurrence” permet après la reconnaissance des paires de classes également les plus proches
- et donc à fusionner - de déterminer l’état du système au niveau k + 1, sachant son état au
niveau k, 0 ≤ k ≤ l − 1. Cette formule est très utilisée pour une forme d’implémentation de
l’algorithme de classification ascendante hiérarchique.
4 L’Analyse de la Vraisemblance des Liens Relationnels (Une
présentation à partir d’exemples)
4.1 Caractéristiques principales de la méthode et principe de l’indice de
fusion entre classes
Trois caractéristiques fondamentales conditionnent cette méthodologie :
1. Représentation ensembliste puis relationnelle des variables (attributs) de description
2. Notion très générale de similarité se référant à une échelle probabiliste établie par rap-
port à une hypothèse d’absence de liaison entre les variables (attributs) de description
“respectant” les distributions marginales observées des différentes variables
3. Guidage statistique dans l’interprétation de l’arbre de classification, conduisant à la dé-
termination - au moyen d’un critère objectif - d’agrégats “intéressants” et de partitions
(classifications) “intéressantes”
La représentation ensembliste et relationnelle des variables descriptives entraîne une ex-
trême généralité de l’approche par rapport aux structures des données les plus complexes. Nous
le mentionnerons plus explicitement dans la section traitant des grands types mathématico-
logiques de données. La notion de similarité probabiliste va rejoindre la philosophie de la
théorie de l’information ; mais où, les évènements observés sont des valeurs d’indices de simi-
larité entre les structures de données à comparer. Les partitions intéressantes vont se produire
aux niveaux que nous dirons “significatifs” - dans un sens que nous préciserons - de l’arbre de
classification. Les agrégats “intéressants” vont correspondre à des noeuds “significatifs” - dans
un sens que nous préciserons - de l’arbre de classification.
Il y a une très forte cohérence dans la suite des différentes étapes de la méthode de classifi-
cation ascendante hiérarchique de l’AVLR. Nous allons commencer par considérer une articu-
lation fondamentale concernant le critère (indice) de fusion des paires de classes. Nous allons
en donner le principe dans le cadre d’une illustration géométrique très simple alors que dans
notre cas, comme nous venons de l’exprimer, c’est une représentation ensembliste et relation-
nelle des variables descriptives qui prévaut. Il s’agit dans l’exemple, de la classification d’un
nuage de points unidimensionnel (voir FIG. 6). Ayons à l’esprit que l’exigence première d’une
CAH consiste à établir un ordre des agrégations et que c’est un critère numérique qui per-
met de sélectionner à chaque étape la “meilleure” agrégation (ou les également “meilleures”
agrégations). C’est de ce critère numérique dont il s’agit. Commençons par poser un indice δ
RNTI - G - 10
I.C. Lerman
classique et naturel ici, défini par la distance minimale et imaginons qu’à une étape donnée de
l’algorithme on ait à choisir parmi deux agrégations candidates : C1 et C2 d’une part etD1 etD2
d’autre part. En se limitant au critère défini, compte tenu de ce que δ(D1, D2) est strictement
inférieur à δ(C1, C2), la première agrégation à choisir est celle deD1 etD2. Cependant, on peut
remarquer que les classes D1 et D2 sont sensiblement plus denses que celles C1 et C2. Or, il
est “normal” que les deux extrémités mutuellement les plus voisines soient plus proches pour
deux classes fortement densesD1 etD2 que pour deux classes faiblement denses C1 et C2. Dans
ces conditions, pour le critère de l’AVLR, la fusion choisie est celle de C1 et C2. Ainsi, c’est
l’exceptionnalité de la petitesse de δ qui guide vers le “meilleur” choix. On se rend compte
qu’ainsi, nous rejoignons la philosophie de la théorie de l’information au niveau des relations
observées.
C1 C2 D1 D2
 (C1, C2)  (D1,D2)>
.  … ..   . .. .              ……. …..
FIG. 6 – Principe de l’agrégation AVL.
Considérons à présent une deuxième illustration géométrique supposant un nuage de points
planaire (voir FIG. 7). C1 et C2 sont deux classes fortement denses ; alors que D1 et D2 sont
deux classes faiblement denses. Pour le critère de la distance minimale δ on a clairement
δ(C1, C2) < δ(D1,D2). Avec le même raisonnement intuitif que ci-dessus, entre les deux
fusions ; celle de C1 et C2 ou celle de D1 et D2, AV LR choisit celle de D1 et D2.
Profitons de signaler ici que l’effet bien connu de “chaînage” du critère de la distance
minimale, disparaît dès lors qu’on lui substitue la vraisemblance de la petitesse de la valeur de
cette distance minimale. D’autre part et enfin, il est clair qu’on peut prendre d’autres indices
de base (nous disons “bruts”) que la distance minimale et suivre la même démarche.
4.2 Les comparaisons par paires dans la méthode AV LR en cas de don-
nées booléennes
4.2.1 Représentation ensembliste de l’ensemble des attributs de description
Nous noterons de façon conforme à ci-dessus par A l’ensemble des attributs booléens de
description et par O l’ensemble des objets décrits. Nous représentons un attribut booléen a
(a ∈ A) par le sous ensemble O(a) des objets où il est à V RAI (où il est présent) (voir FIG.
8). Ainsi, l’ensemble de représentation est l’ensemble des parties de l’ensemble O des objets.
C’est le cas de représentation le plus simple puisque l’attribut booléen définit une variable
relationnelle unaire. Signalons ici qu’un autre cas très important de variable relationnelle unaire
est fourni par la variable quantitative qui elle, définit une valuation sur l’ensembleO des objets.
Il est clair que s’il s’agit d’attributs de même type dont l’ensemble des valeurs peut être
structuré de façon plus ou moins complexe, la représentation fidèle d’un même attribut ne peut
plus se faire au niveau de O. Il faudra travailler à un niveau supérieur : l’ensemble des paires
RNTI - G - 11
Classification par la vraisemblance des liens relationnels
C1 C2
D1 D2
 (C1, C2)
 (D1,D2)
FIG. 7 – Comparaison entre deux dissimilarités entre classes.
O(a)
O
FIG. 8 – Représentation d’un attribut booléen.
RNTI - G - 12
I.C. Lerman
11001011
00111001
11001100
01110001
00011001
00010101
11000100
00011011
11001000
10101100
a1 a2 a3 a4 a5 a6 a7 a8
o1
o2
o3
o4
o5
o8
o6
o7
o9
o10
O(a5) = {o3, o5, o6, o7, o9}
O(a1) = {o3, o5, o6, o7, o9, o10}
O(a2) = {o3, o10}
O(a3) = {o1, o4, o5, o8}
O(a4) = {o1, o2, o3, o6, o8, o9, o10}
O(a7) = {o2, o4, o7, o8, o10}
O(a6) = {o1, o7, o9}
O(a8) = {o1, o2, o4, o8, o10}
FIG. 9 – Représentation de la description d’un tableau de données booléennes.
d’objets ou celui des couples de paires d’objets, ou ...
La figure 9 donne l’exemple de la représentation de l’ensemble des attributs de descrip-
tion dans le cas d’un petit tableau de données booléennes (10 objets et 8 attributs). Il s’agit de
façon générale d’un échantillon d’éléments dans l’ensemble des parties de O.
4.2.2 Comparaison entre attributs booléens
En vue de l’organisation par la classification de l’ensembleA des attributs booléens consi-
dérons le problème de la comparaison deux à deux de ces attributs booléens. À cet effet, com-
mençons par considérer une paire {a, b} d’attributs faisant partie de A. La représentation en-
sembliste conduit à une paire de parties de O de la forme {O(a),O(b)}. La situation relative
entreO(a) etO(b) est schématisée dans la figure 10 où on introduit les paramètres s, u, v et t.
On a avec des notations que l’on comprend :
s = n(a ∧ b) = card(O(a) ∩ O(b))
u = n(a ∧ ¬b) = card(O(a) ∩ O(¬b))
v = n(¬a ∧ b) = card(O(¬a) ∩ O(b))
t = n(¬a ∧ ¬b) = card(O(¬a) ∩ O(¬b))
On a s + u + v + t = n. De nombreux indices (nous dirons aussi “coefficients”) de
similarité (nous dirons aussi d’“association”) entre deux attributs booléens ont été proposés.
Ils se présentent tous respectivement sous la forme, de fonctions des trois paramètres s, u et v,
strictement croissantes par rapport à s, symétriques en u et v et décroissantes par rapport à u.
Dans ces fonctions on cherche d’une façon ou d’une autre et de façon implicite à neutraliser
l’influence dans la ressemblance des tailles n(a) = card(O(a)) et n(b) = card(O(b)). Ainsi
en est-il du fameux indice de Jaccard (1908) qui se met sous la forme s/(s+ u+ v) que nous
RNTI - G - 13
Classification par la vraisemblance des liens relationnels
considérerons ci-dessous pour notre illustration. Notre approche constructive est différente.
Nous commençons bien par le choix initial d’une fonction de similarité. Mais, compte tenu
de l’invariance du résultat par rapport à ce choix, nous partirons le plus “naturellement” de
l’indice “brut” de ressemblance s qui représente le nombre d’objets où les deux attributs a et b
sont à V RAI . Il s’agit alors d’évaluer la grandeur relative de s compte tenu du contexte défini
“localement” par le couple (n(a), n(b)). Cette évaluation se fera par rapport à une Hypothèse
d’Absence de Liaison (H.A.L.) où au couple de parties observées (O(a)),O(b))), on associe
un couple de parties aléatoires et indépendantes (O(a∗)),O(b∗)) “respectant” respectivement
les cardinalités n(a) et n(b). Différents modèles aléatoires peuvent être considérés. La valeur
observée s est alors située par rapport à la distribution probabiliste de l’indice brut aléatoire
S = card(O(a∗))∩O(b∗)). Dans ces conditions, la valuation de la “ressemblance” entre a et b
est d’autant plus grande que s apparaît “invraisemblablement” grand eu égard à la distribution
de S. On introduit ainsi une notion de “vraisemblance” dans la notion de “ressemblance”. Dans
la figure 11 qui schématise la construction, Pl(a, b) est l’indice probabiliste d’association.
su
v
tO(a) O(b)
O
FIG. 10 – Représentation ensembliste de la comparaison entre deux attributs booléens.
(O(a),O(b))
H.A.L.
O(a ) O(b
 )
S = card(O(a )  O(b ))
Pl(a, b) = Pr{S ! s}
FIG. 11 – Indice probabiliste local.
Signalons ici l’indice statistiquement normalisé suivant qui permet le calcul de l’indice
probabiliste via la fonction de répartition de la loi normale centrée réduite Φ :
Q(a, b) =
(
s− E(S))/√var(S)
RNTI - G - 14
I.C. Lerman
Pl(a, b) = Φ
(
Q(a, b)
)
(7)
où E(S) et var(S) désignent l’espérance mathématique et la variance de l’indice brut aléa-
toire S.
L’indice Pl(a, b) a un caractère local, circonscrit aux deux attributs à comparer. Le contexte
définitif de comparaison deux à deux pour l’établissement de l’indice probabiliste sur A sera
global.
Les coefficients d’association (indices de similarité) que nous considérons ont essentiel-
lement un caractère symétrique. Ainsi, relativement à un couple d’attributs booléens (a, b),
l’indice Pl(a, b) cherche à “mesurer” le degré d’équivalence entre a est à V RAI et b est à
V RAI . Régis Gras a eu l’idée d’adapter ce type d’indice de la Vraisemblance du Lien pour
“mesurer” une relation dissymétrique de la forme “combien a à V RAI implique b à V RAI”.
Il en est résulté un ensemble important de travaux - évoqués dans les références - autour de la
recherche dans les données de structures implicatives.
6 0.89 0.27 0.58 0.95 0.74 0.38 0.15
2 2 0.45 0.84 0.74 0.55 0.74 0.74
1 0 4 0.44 0.38 0.66 0.68 0.88
4 2 2 7 0.51 0.65 0.51 0.75
5 1 1 3 5 0.82 0.24 0.06
2 0 1 2 2 3 0.54 0.54
2 1 2 3 1 1 5 0.92
1 1 3 4 0 1 4 5
A
a
1
a
1
a
2
a
2
a
3
a
3
a
4
a
4
a
5
a
5
a
6
a
6
a
7
a
7
a
8
a
8
s Pl
FIG. 12 – Tableau des similarités pour le tableau des données booléennes ci-dessus.
Exemple du tableau précédent des données booléennes Le tableau de la figure 12 est rela-
tif aux données booléennes du tableau de la figure 9. Les valeurs de l’indice brut s se trouvent
sous la diagonale principale (au sens large). Ainsi, s(a4, a7) = 3, s(a5, a6) = 2, ... . Le j-ème
élément de la diagonale tel que s(aj , aj) n’est autre que n(aj) = card(O(aj)), 1 ≤ j ≤ 8.
Les valeurs d’un indice probabiliste local Pl - conformément à un modèle aléatoire d’ab-
sence de liaison - sont placées strictement en dessous de la diagonale principale. On a ainsi
Pl(a4, a7) = 0.51 et Pl(a5, a6) = 0.82.
RNTI - G - 15
Classification par la vraisemblance des liens relationnels
On constate qu’il peut exister des inversions entre d’une part l’indice brut s et d’autre
part, l’indice probabiliste local Pl. On a par exemple :
s(a4, a7) = 3 > s(a5, a6) = 2 et Pl(a4, a7) = 0.51 < Pl(a5, a6) = 0.82
Des inversions peuvent même avoir lieu entre l’indice de Jaccard J mentionné ci-dessus et
l’indice probabiliste local Pl. On a ainsi :
J(a1, a6) =
2
7
< J(a4, a7) =
3
9
et Pl(a1, a6) = 0.74 > Pl(a4, a7) = 0.51
Réduction globale des similarités Le contexte local permet avec Pl des comparaisons bien
différenciées pourvu que le nombre d’objets ne soit pas “trop grand”. Autrement, Pl a ten-
dance à tendre soit vers 1 (resp., 0) en cas d’association positive (resp., négative) par rapport à
l’indépendance probabiliste. C’est qu’en fait, pour l’organisation classificatoire de l’ensemble
A des attributs booléens, le problème consiste en la comparaison relative deux à deux des élé-
ments de A. C’est pour cette raison que dans le contexte global on rapporte la comparaison
entre deux attributs aux comparaisons mutuelles deux à deux entre attributs. Dans ces condi-
tions, à la suite (a1, a2, ..., aj , ..., ap) des attributs observés on associe dans une hypothèse
d’absence de liaison respectant de façon marginale la configuration du tableau des données,
une suite (a1∗, a2∗, ..., aj∗, ..., ap∗) d’attributs aléatoires mutuellement indépendants. L’indice
Q(aj , ak) (cf. (7)) entre deux attributs de A, statistiquement localement normalisé, est lui
même à nouveau globalement normalisé par rapport à sa distribution empirique sur l’ensemble
P2(A), 1 ≤ j < k ≤ p. Ainsi, on substitue à l’indice Q(aj , ak), celui Qg(aj , ak) où (voir
FIG. 13) où me(Q) et var(Q) sont respectivement la moyenne et la variance empirique de
Q(aj , ak) sur P2(A). C’est la loi asymptotiquement normale de Qg(aj∗, ak∗) qui conduit à
l’indice probabiliste global Pg(aj , ak), 1 ≤ j < k ≤ p. La figure 13 donne le schéma général
de la procédure.
(a1, a2, ..., aj , ..., ap) (a1 , a2 , ..., aj , ..., ap )
H.A.L.
P2(A) = {{a
j , ak}|1  j < k  p}
Q(aj, ak)!" Qg(a
j , ak) = (Q(aj , ak)"moye(Q))/
p
vare(Q)
Pg(a
j , ak) = Pr{Qg(a
j , ak )  Qg(a
j , ak)} =  (Qg(a
j , ak))
me(Q) et vare(Q) sur P2(A)
FIG. 13 – Similarité probabiliste globale.
RNTI - G - 16
I.C. Lerman
Cette référence à la loi normale est justifiée dans les références Daudé (1992) et Lerman
(1984) de la section 7.2. L’approximation normale devient dans la plupart des cas, très bonne
dès lors que la taille n de l’ensemble des objets dépasse l’ordre de la dizaine d’unités.
4.2.3 Comparaison entre objets décrits par des attributs
Il s’agit à présent d’adresser le problème de la classification de l’ensemble O des objets
décrits par des attributs. Pour se fixer les idées on peut imaginer que les attributs sont booléens.
Cependant, la procédure est d’une extrême généralité par rapport à la nature des attributs. Ainsi,
comment effectuer de façon cohérente les comparaisons mutuelles entre objets pour aboutir au
même type d’indice probabiliste que dans le cas de la comparaison entre attributs. La procédure
se décompose en la suite des étapes suivantes :
(i) Contribution brute d’un attribut à la comparaison de deux objets Considérons le
couple formé par un attribut aj et une paire d’objets {oi, oi′}, 1 ≤ j ≤ p, 1 ≤ i < i′ ≤ n.
On définit la contribution “brute” sj(oi, oi′) de l’attribut aj à la ressemblance entre les deux
objets oi et oi′ . Un exemple en cas d’attributs booléens - que nous ne pouvons ici justifier - est
donné par :
sj(oi, oi′) =
1
p
− 1
2
(ηji − ηji′)2 (8)
où
ηji = 
j
i/
√( ∑
1≤k≤p
ki
)
(9)
et où ji = 1(resp.,0) selon que l’attribut a
j est présent (à V RAI) (resp., absent (àFAUX))
chez l’objet oi.
(ii) Normalisation statistique de la contribution “brute” de similarité sj(oi, oi′) est nor-
malisé par rapport à la distribution statistique de la contribution “brute” du j-ème attribut sur
l’ensemble O ×O des couples d’objets. Il s’agit nommément de la distribution :
{sj(ol, ol′)|1 ≤ l, l′ ≤ n}
La contribution normalisée de l’attribut aj à la comparaison des deux objets oi et oi′ se
met dans ces conditions sous la forme :
Sj(oi, oi′) =
(
sj(oi, oi′)−me(sj)
)
/
√
vare(sj) (10)
où me(sj) et vare(sj) sont la moyenne et la variance de la précédente distribution, 1 ≤
i < i′ ≤ n.
RNTI - G - 17
Classification par la vraisemblance des liens relationnels
(iii) Somme des contributions normalisées On définit l’indice totalisant l’ensemble des
contributions normalisées sous la forme :
S(oi, oi′) =
∑
1≤j≤p
Sj(oi, oi′) (11)
1 ≤ i < i′ ≤ n. Par rapport au cas dual de la construction d’un indice d’association entre
attributs de description, on peut ici considérer qu’on se trouve au même niveau que celui de la
définition du coefficient Q (cf. (7)). Il nous reste donc à procéder à la
(iv) Normalisation statistique globale de S(oi, oi′) par rapport à l’ensemble P2(O) des
paires d’objets distincts L’indice ainsi normalisé conduit via la fonction de répartition de la
loi normale centrée et réduite, à l’indice probabiliste de vraisemblance du lien. La référence à
la loi normale dans l’hypothèse probabiliste d’absence de liaison mutuelle entre les différents
attributs de description, pour la loi de l’indice aléatoire associé à S(oi, oi′) se justifie en faisant
appel au théorème central limite. En effet, cette variable aléatoire est formée d’une somme de
contributions normalisées aléatoires et indépendantes. Il importe dans ces conditions que le
nombre p de variables de descriptions ne soit pas trop petit. Ce qui est le cas le plus souvent.
Toutefois, quelle que soit la valeur de p, il n’est pas interdit de vouloir se positionner, pour la
loi de l’indice aléatoire globalement normalisé dans l’hypothèse d’absence de liaison, relative-
ment à la loi normale centrée et réduite.
Signalons ici que l’élaboration d’une matrice de similarités probabilistes sur un ensemble
C de catégories décrits par des attributs booléens obéit à la même démarche que ci-dessus.
4.2.4 Cas général
L’établissement d’une matrice d’indices probabilistes de la vraisemblance du lien telle
qu’elle a été introduite pour la classification d’un ensemble A d’attributs, respectivement pour
la classification d’un ensemble O d’objets, dans le cas d’un tableau de données booléennes,
a été étendu dans le cas d’un tableau très général de données (voir la sous section 2.2.1 et la
section suivante). Cette généralisation mathématico-statistique a été validée sur le plan expé-
rimental par de nombreuses, difficiles et très intéressantes applications. La figure 14 donne le
schéma général. L’ensemble E à organiser par la classification peut être soit un ensemble A
de variables descriptives, soit un ensemble O d’objets décrits (resp., un ensemble C de catégo-
ries décrites). Dans l’un ou l’autre de ces deux cas duaux, on aboutit à une matrice d’indices
probabilistes {P (x, y)|{x, y} ∈ P2(E)} telle qu’elle est indiquée dans le schéma. P2(E) est
l’ensemble des paires (parties à deux éléments) de E.
Nous proposons de substituer à la table d’indices probabilistes la table suivante que nous
appelons “Matrice des dissimilarités “informationnelles”” :{
∆(x, y) = −Log2(P (x, y))|{x, y} ∈ P2(E)
}
−Log2(P (x, y)) est la quantité d’information de l’évènement dont la probabilité estP (x, y).
On remarquera que lorsque P (x, y) varie entre 1 et 0, ∆(x, y) varie entre 0 et l’infini. La ma-
trice précédente est ce que la méthode AV LR peut transmettre aux algorithmes qui travaillent
avec des dissimilarités.
RNTI - G - 18
I.C. Lerman
{P (x, y)|{x, y}  P2(E)}
O( resp., C)A
E
FIG. 14 – Table de similarités probabilistes quel que soit l’ensemble organisé.
4.3 Famille de critères de la vraisemblance du lien maximal et construc-
tion de l’arbre
Il s’agit maintenant, selon la démarche d’Adanson, de rapprocher des “petites familles” qui
représentent dans notre formalisme des parties disjointes, des classes, de l’ensemble à organi-
serE. Nous avons vu (section 3.2) que cela passait par la définition d’un indice de dissimilarité
- ou de façon équivalente - de similarité entre parties disjointes de E. E est maintenant muni
d’un indice de similarité probabiliste (section 4.2.4 ci-dessus). Dans ces conditions, soient C
et D deux parties disjointes (deux classes) de l’ensemble E. Nous allons partir d’un indice de
comparaison qui est défini par le lien “maximal” (on dit encore lien “simple” ou “single lin-
kage”) mais dans le contexte de la matrice des indices probabilistes établie. Plus précisément,
nous définissons :
p(C,D) = max{P (c, d)|(c, d) ∈ C ×D} (12)
Conformément au principe de fusion des classes dans l’AV LR (voir section 4.1), nous
associons dans une hypothèse d’absence de liaison, au couple de parties (C,D) un couple
(C∗, D∗) de parties aléatoires indépendantes et formées respectivement d’éléments mutuelle-
ment indépendants. La forme pure du critère “vraisemblance du lien maximal” prend alors la
forme :
P (C,D) = Pr{p(C∗, D∗) ≤ p(C,D)} = (p(C,D))(|C|×|D|) (13)
où |C| (resp., |D|) désigne le cardinal de C (resp.,D). Une famille plus large et paramétrée
de critères est définie par l’équation :
P(C,D) =
(
p(C,D)
)(|C|×|D|)
(14)
Pour des raisons de discrimination au niveau du calcul numérique ; mais avec un résultat
identique on utilise la fonction strictement croissante :
S(C,D) = −Log2[−Log2(P(C,D))] (15)
Nous avions introduit cette famille à l’occasion de travaux avec F. Costa Nicolaü et H.
Bacelar-Nicolaü. En effet, F. Costa Nicolaü a cherché à introduire une certaine souplesse en
RNTI - G - 19
Classification par la vraisemblance des liens relationnels
étudiant d’autres fonctions que celles associées à (12) ou (13). Remarquons que pour  = 0,
on a le lien simple et que pour  = 1 on a la forme pure du critère de la vraisemblance du lien
maximal. Signalons que dès que  se détache de la valeur 0, l’effet bien connu de “chaînage”
du “single linkage” disparaît. Une valeur très utilisée pour  est 0.5.
Signalons enfin qu’on dispose clairement d’une formule de réactualisation pour S.
4.3.1 Les deux arbres de classification issus de l’exemple
Relativement au tableau de données booléennes de la figure 9, nous avons obtenu par l’ap-
plication de la méthode les deux arbres des figures 15 et 16. Le premier (FIG. 15) porte sur
l’ensemble A des 8 attributs booléens et le second (FIG. 16) porte sur l’ensemble O des 10
objets. Dans un sens que nous préciserons ci-dessous, le niveau 5 est distingué dans le premier
arbre (sur A), comme étant un niveau “significatif”. Le niveau 6 est également intéressant.
Dans le second arbre (sur O) c’est le niveau 9 qui est distingué comme “significatif”. Nous
préciserons également bientôt la notion de noeuds “significatif”. Les noeuds significatifs sont
marqués par une étoile ∗.
 
 
 
0
1
2
3
4
5
6
7
a
1
a
5
a
6
a
2
a
4
a
7
a
3
a
8
FIG. 15 – Arbre de classification sur A ; niveaux et noeuds “significatifs”.
1
2
3
4
5
6
7
8
9
o1o2o9 o8o4o10o3o6o7o5
 
 
 
FIG. 16 – Arbre de classification sur O ; niveaux et noeuds “significatifs”.
RNTI - G - 20
I.C. Lerman
4.4 Niveaux et Noeuds les plus “significatifs” d’un arbre de classification
Commençons par donner un sens intuitif aux notions d’un niveau “significatif” et d’un
noeud “significatif” d’un arbre de classification. Reprenons ici l’image donnée au paragraphe
3.2 de la construction de l’arbre en termes d’un processus de synthèse automatique. Un niveau
donné, défini par un état du processus, détermine une partition (classification) sur l’ensemble
total E. Un niveau “significatif” correspond à un état d’équilibre dans la synthèse automa-
tique. Les classes obtenues qu’achèvent des noeuds qui sont en dessous (au sens large) du
niveau concerné, sont ces familles qui, selon l’expression d’Adanson, forment un “tout dont
les parties sont liées intimement”, sur le plan de la cohérence, avions nous précisé. La liaison
est d’autant plus intime sur le plan de la cohérence que le noeud est “significatif”.
Il y a lieu maintenant de préciser comment objectivement, nous déterminons les niveaux
et les noeuds les plus “significatifs” d’un arbre de classification. La base est un critère qui
se présente comme un coefficient d’association obéissant au principe de la démarche AV LR,
entre une partition et une similarité sur E. Ce coefficient a une nature combinatoire et non
paramétrique. Le point de départ consiste en la représentation de la partition et de la similarité
sur E. Elles seront vues comme deux relations binaires symétriques sur E. La représentation
se fait au niveau de l’ensemble F des paires ou parties à deux éléments de E :
F = P2(E) =
{{x, y}|x ∈ E, y ∈ E, x 6= y}
Pour notre problème de détection de partitions intéressantes, posons :
{pi1, pi2, ..., pik, ..., pil}
la suite des partitions produites aux différents niveaux de l’arbre des classifications. Indi-
quons pik sous la forme :
pik = {Ek1, Ek2, ..., Eki, ..., Ekck}
Nous représentons pik au niveau de F par le sous ensemble des paires qu’elle réunit ; nom-
mément :
R(pik) =
∑
1≤i≤ck
P2(Eki),
où la somme d’ensembles indique une réunion d’ensembles disjoints.
Prenons l’exemple du premier arbre de la figure 15 où E = A. On a la partition du niveau
5, pi5 =
{{1, 5, 6}, {2, 4}, {3, 7, 8}} qu’on représente comme suit :
R(pi5) =
{{1, 5}, {1, 6}, {5, 6}, {2, 4}, {3, 7}, {3, 8}, {7, 8}}
Précisons maintenant la construction du coefficient d’association entre une partition pi et
une similarité Q sur l’ensemble E. Nous proposons ici de prendre une similarité numérique.
Cependant, il existe une version du critère où une similarité ordinale (préordonnance sur E)
est prise en compte. La similarité numérique considérée dans nos programmes est celle Qg
pour la classification de l’ensembleA des variables descriptives et celle duale correspondante,
obtenue après (11), pour la classification de l’ensemble O des objets.
RNTI - G - 21
Classification par la vraisemblance des liens relationnels
Le point de départ consiste en la définition de l’indice “brut”
s(Q, pi) =
∑
{x,y}∈R(pi)
Q(x, y) (16)
qui représente la somme des similarités des paires réunies par la partition pi. Introduisons
ici l’ensemble P(n; t(pi)) qui est l’ensemble des partitions de E de même type t(pi) (i.e. ayant
la même famille de cardinaux de classes) que la partition donnée pi. L’hypothèse d’absence de
liaison associe à la partition observée pi une partition aléatoire pi∗ qui représente un élément
aléatoire dans l’ensemble P(n; t(pi)) muni d’une probabilité uniformément répartie. Dans ces
conditions, l’indice brut aléatoire s(Q, pi∗) suit asymptotiquement (l’approximation est excel-
lente) une loi normale dont la moyenneM et la variance V sont calculées mathématiquement.
Le critère (coefficient d’association) est alors calculé par la formule :
C(Q, pi) =
s(Q, pi)−M√
V
(17)
Lorsque ce critère est appliqué à la suite décroissante en finesse, de l’arbre de classifi-
cation, nous l’appelons “Statistique globale des niveaux”. Précisément, nous considérons la
distribution suivante de la Statistique globale des niveaux :{
C(Q, pii)|1 ≤ i ≤ l
}
(18)
De la sorte un niveau “significatif” correspond à un maximum local de cette distribution.
C’est de cette façon que nous avons repéré le niveau 5 de l’arbre de classification sur A de la
figure 15, ainsi que celui 9 de la figure 16 sur O. Nous avons pu exprimer que le niveau 6 du
premier arbre restait intéressant, parce que la valeur du critère C(Q, pi) gardait une certaine
force. Le graphique de gauche de la figure 17 donne dans un cas réel, le diagramme de la dis-
tribution le long de la suite des niveaux, de la Statistique globale des niveaux. Chaque bâtonnet
vertical est associé à un niveau. Sa hauteur est proportionnelle à la valeur de cette statistique.
Les niveaux “significatifs” sont marqués à la base par une ∗. Ces niveaux permettent, pour un
ordre donné du nombre de classes de faire le bon choix d’une partition de l’ensemble organisé.
Maintenant, relativement à deux niveaux consécutifs i − 1 et i, on associe le taux d’ac-
croissement Statistique globale des niveaux ; c’est-à-dire :
τ(Q, pii) = C(Q, pii)− C(Q, pii−1) , 1 ≤ i ≤ l,
τ(Q, pii) définit la Statistique locale attachée au niveau i. L’importance de ce taux témoigne
du “gain en cohérence” obtenu en passant du niveau i − 1 au niveau i. On constate d’ailleurs
dans la pratique expérimentale que ce taux augmente graduellement dès lors qu’une classe
en cours de formation se confirme. À l’achèvement à un niveau de synthèse d’une classe, la
valeur de ce taux retombe. Il est donc naturel de considérer la distribution le long de la suite
des niveaux de la Statistique locale des niveaux :{
τ(Q, pii)|1 ≤ i ≤ l
}
(19)
Dans ces conditions, un noeud “significatif” est défini par un maximum local de cette
distribution. Le graphique de droite de la figure 17 donne la dsitribution de la Statistique locale
RNTI - G - 22
I.C. Lerman
des niveaux associée à celle globale figurée à gauche. L’amplitude du bâtonnet vertical pour
le niveau i est proportionelle à la valeur τ(Q, pii). Les noeuds “significatifs” sont marqués à la
base par une ∗. Les noeuds et niveaux “significatifs” permettent une interprétation dynamique
et ascendante (des feuilles vers la racine) de l’arbre de classification.
niveau
niveau
FIG. 17 – Distributions des statistiques “globale” (en haut à gauche) et “locale” (en bas et à
droite) des niveaux.
4.5 Croisement entre deux classifications duales
Nous en sommes maintenant - dans le cadre de l’AV LR - au niveau du paragraphe 2.2.2 et
en particulier de la figure 5 de l’introduction générale. Considérons dans le cadre de l’exemple
traité le couple d’arbres de classification sur A et sur O (voir FIG. 15 et FIG. 16). Retenons la
partition la plus “significative” sur A de niveau 5. Cette dernière est en 3 classes et peut être
notée {A1, A2, A3}. De même, retenons la partition la plus “significative” sur O de niveau 9,
elle est en deux classes et peut être notée {C1, C2}. Le croisement de ces deux partitions donne
le tableau de la figure 18.
Ce tableau est obtenu par permutation des lignes et des colonnes du tableau initial des
données (voir FIG. 9), conformément au couple de classifications retenues. Les cases noircies
sont celles qui contiennent la valeur logique 1 (attribut à V RAI). On constate que la classe
C1 se réfère dans une forte mesure à la classe A3 et s’oppose à la classe A1. La référence à
la classe A2 est plus partielle. Au contraire, la classe C2 se réfère à la classe A1 et s’oppose à
la classe A3. Là encore, C2 se réfère de façon partielle mais différente de celle de C1, à A2.
On peut certes considérer la partition de niveau 6 de l’arbre sur A où la partition obtenue est
RNTI - G - 23
Classification par la vraisemblance des liens relationnels
C1
C2
A1 A2 A3
A
O
a1 a2 a3a5 a6 a4 a7 a8
o1
o2
o8
o4
o10
o6
o9
o3
o7
o5
FIG. 18 – Croisement entre deux partitions significatives duales.
{A1, A2 ∪ A3}. Dans ce cas, C1 se réfère à A2 ∪ A3 et C2 se réfère à A1 ; mais, l’opposition
de C2 par rapport à A2 ∪A3 est moins nette que celle de C2 par rapport à A3.
Reprenons une des deux questions posées à la fin du paragraphe 2.2.2 à savoir : s’il s’agit
d’un “grand” tableau de données booléennes, comment faire ? À cet égard, nous avons bien
une solution qui a été de nombreuses fois expérimentée avec beaucoup d’intérêt. Elle relève
d’un développement que nous avons effectué de la théorie du χ2 attaché à un tableau de contin-
gence. Ce développement nous permet de croiser deux classes d’attributs booléens A et B qui
sont logiquement indépendants ; mais, bien sûr, statistiquement dépendants. Plus précisément,
A ∩ B = ∅, d’autre part, dans A ∪ B, il n’y a pas un attribut et sa négation. La notion d’at-
tribut booléen à V RAI chez un objet donné x est remplacée, relativement à un ensemble A
d’attributs booléens (logiquement indépendants), par la proportion dans A d’attributs booléens
à V RAI chez x. Nous noterons ΦA(x) cette proportion. Elle s’écrit :
ΦA(x) =
1
c(A)
∑
a∈A
Φa(x)
où Φa(x) = 1( resp. 0) si l’attribut a est à V RAI (resp., FAUX) chez x. D’autre part,
c(A) désigne le cardinal de A.
Associons à l’ensemble A d’attributs l’ensemble A¯ des attributs obtenus en remplaçant
chaque attribut de A par sa négation. On a dans ces conditions :
ΦA¯(x) =
1
c(A)
∑
a∈A
Φa¯(x)
On a alors l’équation de “cohérence” :
RNTI - G - 24
I.C. Lerman
ΦA(x) + ΦA¯(x) = 1 (20)
Relativement au couple (A,B) de classes d’attributs booléens tel que nous venons de le dé-
crire, la démarche de l’AV LR est toujours la même. Nous introduisons l’indice brut ν(A,B)
suivant :
ν(A,B) = ν(A ∧B) =
∑
x∈O
ΦA(x)× ΦB(x) (21)
Maintenant, on considère l’association
(A,B) −→ (A∗, B∗)
où au couple (A,B) de classes d’attributs booléens on associe un couple (A∗, B∗) de
classes d’attributs booléens mutuellements indépendants dans une hypothèse d’absence de liai-
son adéquate. C’est l’indice centré et réduit
χ(A,B) =
1√
n− 1
(
ν(A ∧B)− E [ν(A∗ ∧B∗)])/√var[ν(A∗ ∧B∗)] (22)
qui définit l’intensité de l’association entre les deux classes d’attributs A et B.
Relativement à l’exemple ci-dessus introduisons les attributs booléens c1 et c2, où c1 (resp.,
c2) définit la fonction indicatrice de la classe C1 (rep., C2). c2 est l’attribut booléen opposé à
c1. Le tableau des coefficients
{χ(ci, Aj)|i = 1, 2, 1 ≤ j ≤ 3}
est donné dans le tableau de la figure 19. Ce tableau synthétise bien les conclusions que
nous avons déjà apportées.
De tels coefficients peuvent aisément être étendus dans le cas où les attributs sont quan-
titatifs. Cependant la méthode s’applique dans le cas très général de variables relationnelles,
conformément au schéma de la figue 20. La question se pose alors de savoir comment faire
correspondre les deux arbres de classification duaux surA etO (Croiser(CAHA,CAHB)).
D’autre part, dans la mesure où il peut être réalisé sous une certaine forme, quel type d’in-
terprétation peut-on tirer d’un tel croisement. À cet égard, des coefficients que nous avons
expérimentés avec beaucoup d’intérêt entre d’une part une variable relationnelle quelconque
et d’autre part, une classification sur O ou une classe de O, joueront certainement un rôle
important.
5 Les grands types mathématico-logiques de données
Selon notre point de vue les grands types mathématico-logiques de données se formalisent
au moyen de deux systèmes que nous noterons T et S. Nous allons les présenter ci-dessous en
cherchant à les illustrer.
RNTI - G - 25
Classification par la vraisemblance des liens relationnels
 0.833
+0.833 0.833
+0.833
+0.143
 0.143
A1 A2 A3
c1
c2
FIG. 19 – Croisement statistique entre deux partitions duales.
E  A;
CAHA E.CAH;
E  O( resp., E  C);
CAHB  E.CAH;
Croiser(CAHA,CAHB)
FIG. 20 – Schéma général de la biclassification ascendante hiérarchique.
5.1 Le système T
T est un système de Tarsky. Il se présente sous la forme :
T = (O;R1, R2, ..., Rj , ..., Rp) (23)
où O est un ensemble d’objets élémentaires et où R1, R2, ..., Rj , ..., Rp sont p relations
d’arités respectives quelconques. En analyse des données la relation Rj se trouve définie par
le j-ème attribut aj , 1 ≤ j ≤ p. Commençons par nous référer au tableau des données du
paragraphe 2.2.1 et donnons quelques exemples typiques. Dans le cas d’un attribut booléen
aj , la relation Rj est unaire et l’attribut est représenté au niveau de O de façon ensembliste
(voir paragraphe 4.2.1). Rj est toujours une relation unaire mais valuée (valuation surO) dans
le cas d’un attribut quantitatif-numérique. Dans le cas où l’attribut aj est qualitatif nominal
Rj est une relation binaire symétrique qu’on représente par un sous ensemble au niveau de
l’ensemble P2(O) des parties à deux éléments de O. Si aj est un attribut qualitatif ordinal
la représentation ensembliste est au niveau du produit cartésien O × O. Si aj est un attribut
qualitatif préordonnance, la représentation est au niveau de l’ensemble des couples de couples
(O)2 × (O)2 ou, si l’on veut, de O4. Cependant, un codage en termes d’une valuation sur O2
est le plus souvent proposé pour des raisons de simplification de la complexité. La variable
taxinomique est un cas particulier de la variable préordonnance. Une variable qualitative aj
RNTI - G - 26
I.C. Lerman
dont l’ensemble des valeurs, codé par {1, 2, ..., i, ..., vj}, est muni d’un graphe valué de si-
milarité, peut être interprétée, sous un certain point de vue, comme une généralisation d’une
variable qualitative préordonnance. Une telle variable définit un graphe valué sur l’ensemble
O des objets. Une telle variable peut être représentée par la j-ème colonne du tableau des
données. Cette dernière comprendra des codes issus de {1, 2, ..., i, ..., vj}. Il importe dans ces
conditions, d’avoir séparément la matrice donnant le graphe valué sur {1, 2, ..., i, ..., vj}.
Un cas d’importance est celui où aj définit directement un graphe valué sur l’ensemble
O des objets. Le support en termes d’une colonne du tableau des données pour représenter
aj , ne peut plus alors se conçevoir. Néanmoins, le problème bien connu de la classification
d’un ensemble de graphes valués sur un ensemble d’objets, peut être abordé, dans le cadre de
l’AV LR, comme la classification d’un ensemble de variables relationnelles.
Maintenant, il existe des situations où le tableau des données ne peut pas directement re-
présenter l’information descriptive. Il s’agit notamment des données de type “séquences” de
longueurs inégales (e.g. séquences génétiques). On ne pourra passer à la description au moyen
d’un tableau de données qu’après avoir défini le même ensemble de variables de description
pour l’ensemble des séquences. C’est ce que font la grande majorité des méthodes.
Un dernier point concerne le mélange des types de variables dans le cadre de la classi-
fication AV LR. Il s’agit plus précisément du cas où les diverses relations Rj , 1 ≤ j ≤ p ne
sont pas de même arité. La classification de l’ensemble O des objets est formellement indiffé-
rente à ce mélange. Toutefois, il importe que les différentes variables correspondent au même
ordre de finesse structurelle et statistique. Il est ainsi difficile de traiter sur le même plan un
attribut booléen et un attribut taxinomique très structuré. Pour ce qui est de la classification
AV LR des variables de description, il importe qu’elles soient toutes d’un même type. À cet
égard et dans les cas classiques et assez généralement, où les variables induisent sur O des
relations soit unaires, soit binaires, on peut de façon naturelle déterminer un codage uniforme
en termes de variables préordonnances ou graphes valués (thèse M. Ouali-Allah).
5.2 Le système S
Le système S se présente sous la forme :
S = (C; distC(R1), distC(R2), ..., distC(Rj), ..., distC(Rp)) (24)
C est un ensemble de catégories (on dit encore “concepts”). R1, R2, ..., Rj , ... et Rp sont
comme ci-dessus, p relations d’arités respectives quelconques, sur O. distC(Rj) représente la
famille des distributions statistiques de Rj sur chacune des catégories c de C.
Pour se rendre compte du degré de généralité de ce système, considérons quelques types
de données classiques qui s’y inscrivent. Un tableau de contingence constitue un cas très par-
ticulier de ce système. Il se met sous la forme :
(C; distC(R))
RNTI - G - 27
Classification par la vraisemblance des liens relationnels
où R est une relation d’équivalence associée à une variable qualitative nominale. Mainte-
nant, une juxtaposition “horizontale” de tableaux de contingence s’exprime au moyen de :(C; distC(R1), distC(R2), ..., distC(Rj), ..., distC(Rp))
où R1, R2, ..., Rj , ... et Rp sont p relations d’équivalence respectivement associées à p
variables qualitatives nominales. Plus généralement, les données de type “histogrammes” où
les pieds d’un même histogramme sont munis d’une relation, correspondent à ce système.
Signalons pour terminer que cette formalisation mathématico-logique des données en les
deux systèmes T et S - qui nous était apparue vers la fin des années 80 - intègre bien les don-
nées dites “symboliques” et que nous préférons appeler “données de connaissace” (“knowledge
data”, en anglais). AV LV R traite efficacement ces données.
6 Logiciels et Applications
6.1 Les programmes CHAVLh, AVARE et LLAhclust
Nous allons mentionner succintement les produits logiciels qui ont été élaborés pour la
mise en oeuvre de la méthodologie AV LR. Ces programmes ont été écrits en Fortran 77,
conformément aux normes rigoureuses de Modulad établies par Henri Leredde (maître de
conférences à l’Université de Paris Nord).
Le programme le plus important est CHAV Lh (Classification Hiérarchique par Analyse
de la Vraisemblance des Liens en cas de données hétérogène) (P. Peter, H. Leredde et I-C.
Lerman). La dernière version de ce programme a été déposée l’Agence de Protection des Pro-
grammes (APP) en décembre 2005. Philippe Peter (maître de conférences à l’École Polytech-
nique de l’Université de Nantes) a été l’artisan de cette dernière version. Il a été installé par le
projet Symbiose sur la plateforme logicielle de la génopole Ouest. Les structures de données
prises en compte sont les suivantes :
1. Numériques-Quantitatives
2. Booléennes
3. Qualitatives nominales
4. Qualitatives ordinales
5. Qualitatives préordonnances ou graphes valués binaires
6. Juxtaposition “horizontale” de tableaux de contingence
7. Tableau de dissimilarités fourni par l’expert
Le programme permet la classification d’un ensemble O d’objets décrits par des variables
toutes d’un même type ou par des variables pouvant être de types respectifs différents.
Par ailleurs, le programme permet la classification de l’ensemble V des variables de des-
cription, toutes d’un même type. Il peut s’agir de variables numériques, booléennes, qualita-
tives nominales ou qualitatives ordinales.
RNTI - G - 28
I.C. Lerman
Un deuxième programme important AV ARE (Association entre VAriables qualitatives
pREordonnance) a été élaboré par M. Ouali-Allah dans le cadre de sa thèse. Il permet la clas-
sification AV LR d’un ensemble de variables qualitatives de différents types codées en termes
de préordonnances. Rappelons à cet égard que la variable taxinomique représente un cas très
spécifique d’une variable préordonnance.
Signalons ici qu’une version ergonomique et donc simplifiée du programme CHAV Lh
a été implantée (juillet 2007) dans l’environnement logiciel dit R (I. Kojadinovic (École Po-
lytechnique de l’Université de Nantes), I.C. Lerman et P. Peter). Bien que ne comportant pas
certaines options de CHAV Lh, cette version reste assez riche. Le programme est intitulé
LLAhclust (Likelihood Linkage Analysis hierarchical clustering)
6.2 Quelques applications récentes d’envergure
Nous nous contenterons de mentionner les thématiques dans lesquelles s’inscrivent ces
applications et les références des travaux menés dans différents projets ; mais où, à chaque
fois, la méthode AV LR et donc le programme CHAV Lh a joué un rôle essentiel.
6.2.1 Simulation du comportement de l’exécution de “très gros” programmes à partir
d’un échantillonnage “représentatif”
T. Lafage ; “Étude, réalisation et application d’une plate-forme de collecte
de traces d’exécution de programmes”, Thèse de doctorat, Université de Rennes
1, Décembre 2000.
6.2.2 Détermination de classes sémantiques dans le Traitement Automatique de Langues
Naturelles
M. Rossignol ; “Acquisition automatique de lexiques sémantiques pour la
recherche d’information”, Thèse de doctorat, Université de Rennes 1, Octobre
2005.
6.2.3 Correspondance entre profils génotypiques et profils phénotypiques dans l’hémo-
chromatose
I.-C. Lerman ; “Coefficient numérique général de discrimination de classes
d’objets par des variables de types quelconques. Application à des données
génotypiques”, Revue de Statistique Appliquée, 2006, vol. 2, pp. 33-63.
RNTI - G - 29
Classification par la vraisemblance des liens relationnels
6.2.4 Structuration d’une famille spécifique de séquences d’ADN
S. Tempel ; “Dynamique des hélitrons dans le génôme d’Arabidopsis tha-
liana : développement de nouvelles stratégies d’analyse des éléments transpo-
sables”, Thèse de doctorat, Université de Rennes 1, juin 2007.
6.2.5 Organisation d’espèces de “phlébotomes” pour une description biologique très
complexe
I.-C. Lerman, P. Peter ; “Representation of Concept Description by Multiva-
lued Taxonomic Preordonance Variables”, in : Selected Contributions in Data
Analysis, and Knowledge organization, P. Brito, P. Bertrand, G. Cucumel, F.
de Carvalho (editors), Studies in Classification, Data Analysis, and Knowledge
organization, Springer, 2007, pp. 271-284.
6.2.6 Segmentation d’images numérisés
I.-C. Lerman, K. Bachar ; “Comparaison de deux critères en Classification
Ascendante Hiérarchique sous contrainte de contiguïté. Application en ima-
gerie numérique”, Journal de la Société Française de Statistique et Revue de
Statistique Appliquée, tome 149, n◦ 2, 2008, pp. 45-74.
7 Références importantes pour le fondement et l’élaboration
de la méthodologie
Nous organisons ces références par thèmes. À l’intérieur de chacun des
thèmes, les références seront ordonnées chronologiquement. Elles concernent
nos publications ainsi que celles de chercheurs de notre environnement le plus
immédiat.
7.1 Références générales
I.C. Lerman ;Classification et Analyse Ordinale des Données, Dunod, Paris,
1981.
I.C. Lerman ; Foundations of the Likelihood Linkage Analysis (LLA) Clas-
sification Method, Stochastic Models and Data Analysis, vol. 7, ] 1, march
1991, pp. 63-76.
I.C. Lerman ; Likelihood linkage analysis (LLA) classification method (Around
an example treated by hand) Biochimie 75, Elsevier editions, 1993, pp. 379-
397.
RNTI - G - 30
I.C. Lerman
7.2 Coefficients d’association (de similarité) entre variables relationnelles
I.C. Lerman, R. Gras, H. Rostam ; Élaboration et évaluation d’un indice
d’implication pour des données binaires I : Revue Mathématiques et Sciences
Humaines, 19ème année, n◦ 74, 1981, pp. 5-35, II : Revue Mathématiques et
Sciences Humaines, 19ème année, n◦ 75, 1981, pp. 5-47.
I.C. Lerman ; Association entre variables qualitatives ordinales nettes ou
floues, Statistique et Analyse des Données, 1983, vol. 8 n◦ 7, pp. 41-73.
I.C. Lerman ; Indices d’association partielle entre variables qualitatives no-
minales, RAIRO série verte, vol. 17, n◦ 3, août 1983, pp. 213-259.
I.C. Lerman ; Indices d’association partielle entre variables qualitatives or-
dinales, Publications Institut Statistique de Paris, XXVIII, fasc. 1, 2, 1983, pp.
7-46.
I.C. Lerman ; Justification et validité statistique d’une échelle [0,1] de fré-
quence mathématique pour une structure de proximité sur un ensemble de va-
riables observées, Publications Institut Statistique Universités de Paris, XXIX,
fasc. 3-4, 1984, pp. 27-57.
I.C. Lerman ; Comparing partitions. Mathematical and Statistical aspects,
1ère conférence internationale des fédérations des sociétés de classification.
Aix-la-Chapelle, juin 1987, in Classification and related methods of data ana-
lysis, Edited by H. H. Bock, North Holland, 1988, pp. 121-132.
M. Ouali-Allah ; Analyse en préordonnance des données qualitatives. Ap-
plication aux données numériques et symboliques, thèse de doctorat de l’Uni-
versité de Rennes 1, décembre 1991.
F. Daudé ; Analyse et justification de la notion de ressemblance entre va-
riables qualitatives dans l’optique de la classification hiérarchique par AVL,
thèse de doctorat de l’Université de Rennes 1, juin 1992.
I.C. Lerman ; Conception et analyse de la forme limite d’une famille de
coefficients statistiques d’association entre variables relationnelles, I : Mathé-
matique (, Informatique) et Sciences Humaines, 30ième année, n◦ 118, 1992,
pp. 35-52, II : Mathématique (, Informatique) et Sciences Humaines, 30ième
année, n◦ 119, 1992, pp. 75-100, Paris.
I.C. Lerman ; Comparing classification tree structures : a special case of
comparing q-ary relations, RAIRO-Operations Research, vol. 33, 1999, sept.,
pp. 339-365.
I.C. Lerman, F. Rouxel ; Comparing classification tree structures : a spe-
cial case of comparing q-ary relations II, RAIRO-Operations Research, vol. 34,
2000, pp. 251-281.
RNTI - G - 31
Classification par la vraisemblance des liens relationnels
I.C. Lerman ; Comparing taxonomic data, Revue Mathématiques et Sciences
Humaines, 38-ème année, n◦ 1510, 2000, pp. 37-51.
I.C. Lerman, J. Azé ; A New Probabilistic Measure of Interestingness for
Association Rules, Based on the Likelihood of the Link, in Quality Measures
in Data Mining. Studies in Computational Intelligence. F. Guillet and H. Ha-
milton (eds). 2006. Springer. pp. 207-236.
R. Gras, P. Kuntz ; An overview of the Statistical Implicative Analysis (SIA)
development, in R. Gras, F. Guillet, F. Spagnolo, E. Suzuki ; Statistical Impli-
cative Analysis, Studies in Computational Intelligence, n◦ 27, Springer, 2008.
7.3 Indices de similarité entre objets décrits par des variables relation-
nelles de types quelconques
I.C. Lerman et Ph. Peter ; Organisation et consultation d’une banque de pe-
tites annonces à partir d’une méthode de classification hiérarchique en paral-
lèle, Data Analysis and Informatics IV, North Holland, 1986, pp. 121-136.
Ph. Peter ;Méthodes de classification hiérarchique et problèmes de structu-
ration et de recherche d’informations assistée par ordinateur, thèse de doctorat
de l’Université de Rennes 1, mars 1987.
I.C. Lerman ; Construction d’un indice de similarité entre objets décrits par
des variables d’un type quelconque. Application au problème de consensus en
Classification, Revue de Statistique Appliquée, XXXV (2), 1987, pp. 39-60.
I.C. Lerman, Ph. Peter et J.L. Risler ; Matrices AV L pour la classification
et l’alignement de séquences protéiques, Publication Interne IRISA n◦ 866,
septembre 1994, Rapport de Recherche INRIA n◦ 2466.
I.C. Lerman, Ph. Peter ; Indice probabiliste de vraisemblance du lien entre
objets quelconques : analyse comparative entre deux approches, Revue de Sta-
tistique Appliquée, volume LI(1), 2003, pp. 5-35.
I.C. Lerman and Ph. Peter ; Representation of Concept Description by Mul-
tivalued Taxonomic Preordonance Variables, in Selected Contributions in Data
Analysis and Classification, Studies in Classification, Data Analysis, and Know-
ledge Organization, P. Brito, P. Bertrand, G. Cucumel and F. de Carvalho, edi-
tors, Springer 2007, pp. 271-284.
7.4 Tableaux de contingence
I.C. Lerman et B. Tallur ; Classification des éléments constitutifs d’une jux-
taposition de tableaux de contingence, Revue de Statistique Appliquée, n◦ 28,
3, 1980, pp. 5-28.
RNTI - G - 32
I.C. Lerman
I.C. Lerman ; Interprétation non linéaire d’un coefficient d’association entre
modalités d’une juxtaposition de tables de contingence,Mathématique et Sciences
Humaines, 21ème année, n◦ 83, 1983, pp. 5-30.
I.C. Lerman ; Analyse classificatoire d’une correspondance multiple, typo-
logie et régression, in Data Analysis and Informatics, III, E. Diday et al. (edi-
tors), North Holland, 1984, pp. 193-221.
B. Tallur ; Contribution à l’analyse exploratoire de tableaux de contingence
par la classification, thèse de doctorat ès sciences, Université de Rennes 1,
septembre 1988.
7.5 Critères de fusion entre classes
I.C. Lerman ; Formules de réactualisation en cas d’agrégations multiples,
RAIRO, série R.O. vol 23, n◦ 2, 1989, pp. 151-163.
F. Costa Nicolau and H. Bacelar-Nicolau ; Some trends in the Classification
of Variables, inData Science, Classification, and Related Methods,C. Hayashi,
N. Ohsumi, K. Yajima, Y. Tanaka, H.-H. Bock, Y. Baba Editors, 1998, pp. 89-
98.
7.6 Niveaux et noeuds “significatifs”
I.C. Lerman ; Sur la signification des classes issues d’une classification au-
tomatique, in Numerical Taxonomy, NATO ASI Series, vol. G1. Edited by J.
Felsenstein, Springer-Verlag (1983), pp. 179-198.
I.C. Lerman, N. Ghazzali ; What do we retain from a classification tree ? an
experiment in image coding, in Symbolic-Numeric data analysis and learning,
edited by E. Diday and Y. Lechevallier, Nova Science Publishers, Proceedings
of the conference of Versailles, september 18-20, 1991, pp. 27-42.
7.7 Croisement de classifications
I.C. Lerman ; Croisement de classifications “floues”, Publications de l’Ins-
titut de Statistique des Universités de Paris, 1979, XXIV, fasc. 1-2, pp. 13-46.
I.C. Lerman, M. Hardouin et T. Chantrel ; Analyse de la situation relative
entre deux classifications “floues”, Secondes Journées Internationales Analyse
des Données et Informatique, inData Analysis and Informatics, North Holland,
1980, pp. 523-533.
I.C. Lerman ; Association entre variables qualitatives ordinales “nettes” ou
“floues”, Statistique et Analyse des Données, n◦ 7, 1983, pp. 41-73.
RNTI - G - 33
Classification par la vraisemblance des liens relationnels
I-C. Lerman ; Coefficient numérique général de discrimination de classes
d’objets par des variables de types quelconques. Application à des données
génotypiques, Revue de Statistique Appliquée, 2006, LIV (2), pp. 33-63.
7.8 Logiciels
P. Peter, H. Leredde et I.C. Lerman ; Notice du programme CHAVLh (Clas-
sification Hiérarchique par Analyse de la Vraisemblance des Liens en cas de
variables hétérogènes),Dépôt APP (Agence pour la Protection des Programmes)
IDDN.FR.001.240016.000.S.P.2006.000.20700, Université de Rennes 1, Dé-
cembre 2005.
M. Ouali Allah ; Programme pour le calcul de coefficients d’association
entre variables relationnelles, La revue de modulad n◦ 25, juin 2000, pp. 63-73.
I. Kojadinovic, I.C. Lerman and P. Peter ; LLAhclust dans R :
http ://cran.rproject.org/src/contrib/Descriptions/LLAhclust.html.
Summary
The edification of the Likelihood Linkage Relational Analysis classification
method began at the end of nineteen sixties. From that period this methodology
has been extensively developed. Many researchers and practitioners have con-
tributed to its development. Many application works on a large scale, provided
by various fields (Bioinformatics, Informatics, Social sciences, Image process-
ing, Natural language processing, ...) have been performed and then, have
validated this approach. Any logical or mathematical type of data description
can be handled in an accurate fashion. The aim of this paper consists of pre-
senting in an illustrated way the fundamental principles of this methodology.
Two conception levels are associated with these principles. The first is defined
by the mathematical representation of the data description, while the second
level is concerned by the problem of measuring the resemblances between the
mathematical structures to be compared. In our case, the description repre-
sentation will have a set theoretic and relational nature. Besides, quantifying
the resemblance will be done by means of a probabilistic similarity. The lat-
ter is established with respect to a statistical hypothesis of independence. The
following text corresponds to our oral presentation at the “3-èmes Journées
Thématiques Apprentissage Artificiel et Fouille des Données”, 2008 April 8-9.
RNTI - G - 34
