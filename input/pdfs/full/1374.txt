Bordures statistiques pour la fouille incrØmentale de donnØes
dans les Data Streams
Jean-Emile Symphor, Pierre-Alain Laur
GRIMAAG-DØpt Scientique Interfacultaire,
UniversitØ des Antilles et de la Guyane, Campus de Schoelcher,
B.P. 7209, 97275 Schoelcher Cedex, Martinique, France
fje.symphor,palaurg@martinique.univ-ag.fr.
Résumé. RØcemment la communautØ Extraction de Connaissances s’est intØ-
ressØe à de nouveaux modŁles oø les donnØes arrivent sØquentiellement sous la
forme d’un ot rapide et continu, i:e: les data streams. L’une des particularitØs
importantes de ces ots est que seule une quantitØ d’information partielle est
disponible au cours du temps. Ainsi aprŁs diffØrentes mises à jour successives,
il devient indispensable de considØrer l’incertitude inhØrente à l’information re-
tenue. Dans cet article, nous introduisons une nouvelle approche statistique en
biaisant les valeurs supports pour les motifs frØquents. Cette derniŁre a l’avan-
tage de maximiser l’un des deux paramŁtres (prØcision ou rappel) dØterminØs
par l’utilisateur tout en limitant la dØgradation sur le paramŁtre non choisi. Pour
cela, nous dØnissons les notions de bordures statistiques. Celles-ci constituent
les ensembles de motifs candidats qui s’avŁrent trŁs pertinents à utiliser dans le
cas de la mise à jour incrØmentale des streams. Les diffØrentes expØrimentations
effectuØes dans le cadre de recherche de motifs sØquentiels ont montrØ l’intØrŒt
de l’approche et le potentiel des techniques utilisØes.
1 Introduction
Ces dix derniŁres annØes un grand nombre de travaux ont ØtØ proposØs pour rechercher des
motifs frØquents dans de grandes bases de donnØes. En fonction des domaines d’applications
les motifs extraits sont soit des itemsets (Srikant, 1995; Zaki, 2001; Pei et al., 2001; Ayres et al.,
2002) soit des sØquences (Agrawal et al., 1993; Han et al., 2000). RØcemment les travaux issus
de la communautØ des chercheurs en base de donnØes et en fouille de donnØes considŁrent le
cas des data streams oø l’acquisition des donnØes s’effectue de façon rØguliŁre, continue ou
incrØmentalement et cela sur une durØe longue voire Øventuellement illimitØe.
Compte tenu de la grande quantitØ d’information mise en jeu dans le cas des data streams,
le problŁme de l’extraction de motifs frØquents est toujours d’actualitØ ((Li et al., 2004; Jin
et al., 2003; Demaine et al., 2002; Manku et Motwani, 2002; Golab et Ozsu, 2003; Karp et al.,
2003)). Dans ce contexte, un motif est dit -frØquent s’il est observØ au moins une fraction ,
appelØe support du motif, sur tout le stream. Le paramŁtre theta, tel que 0 <  < 1, est xØ
par l’utilisateur.
- 615 - RNTI-E-6
Bordures statistiques pour la fouille incrØmentale dans les data streams
Dans le cas des data streams, sujets à des mises à jour rØguliŁres et frØquentes, les approches
traditionnelles ne conviennent pas car les rØsultats obtenus pour l’ancienne base ne sont que
partiellement valables pour la nouvelle et il n’est pas envisageable de relancer l’algorithme
sur la base de donnØes mise à jour. En effet, dans tous les travaux dØveloppant une approche
par mise à jour incrØmentale (Masseglia et al., 2003; Cheng et al., 2004), la problØmatique
principale d’optimisation et de performance consiste à construire et à maintenir, au fur et à
mesure des diffØrentes mises à jour successives, un ensemble de motifs candidats. Celui-ci est
utilisØ pour mettre à jour les motifs frØquents et Øviter de relancer l’algorithme depuis zØro.
Il convient Øgalement de souligner une autre caractØristique intrinsŁque des data streams
qui dØcoule du fait que la connaissance du stream n’est que partielle quel que soit l’instant
considØrØ. En consØquence, il est nØcessaire de prendre en compte l’incertitude engendrØe par
la connaissance toujours incomplŁte du data stream. PrØcisØment, cela se traduit dans le cas de
la recherche de motifs frØquents en soulignant que les motifs frØquents obtenus ne sont en fait
que des motifs frØquents observØs. En fait, à cause de cette incertitude, deux sources d’erreurs
doivent Œtre considØrØes :
 Les motifs observØs comme frØquents ne sont peut Œtre plus du tout frØquents sur une
longue pØriode d’observation du stream.
 Inversement des motifs classØs comme non frØquents peuvent le devenir sur une plus
longue pØriode d’observation du stream.
Pour Øviter ces erreurs, il est nØcessaire de dØvelopper une approche pour connaître si un motif
est frØquent sur une partie dØjà examinØe du stream. Cette approche doit de plus Œtre prØdictive
pour savoir avec quelle probabilitØ un motif est frØquent ou non sur l’ensemble du stream.
De nombreuses applications, par exemple dans le domaine de la prØvision mØtØorologique
ou encore dans l’analyse de tendance en nance nØcessitent ce type d’approche. MŒme en
disposant d’une trŁs grande partie du stream, d’un point de vue statistique, il est impossible de
s’affranchir de ces deux sources d’erreur (Vapnik, 1998). Notre objectif sera donc d’essayer
d’approcher le mieux possible une solution optimale.
Dans cet article nous proposons une approche qui permet, tout en considØrant l’incertitude
inhØrente à la connaissance des streams, de construire et de maintenir des ensembles de motifs
candidats bien choisis. Ceci constitue un prØalable fondamental et nØcessaire à toute approche
pertinente dans le cadre de la mise à jour incrØmentale des data streams.
La suite de la prØsentation est organisØe de la façon suivante. Dans le paragraphe 2, nous
introduisons les concepts qui permettent de contrôler l’incertitude dØcoulant des sources d’er-
reurs. Au paragraphe 3, nous montrons comment obtenir les ensembles de motifs pertinents
pour effectuer la mise à jour incrØmentale. Le paragraphe 4 prØsente une expØrimentation de
notre approche, suivie d’une analyse comparative avec des travaux connexes au paragraphe 5.
Nous concluerons notre Øtude au paragraphe 6.
2 Supports statistiques
2.1 Dénitions
Pour formaliser notre problØmatique, nous dØnissons les diffØrents ensembles utilisØs. Le
data stream est obtenu à partir d’un Øchantillonnage effectuØ sur un domaineX potentiellement
trŁs grand qui contient tous les motifs possibles (gure 1). Chaque motif est ØchantillonnØ in-
- 616 -RNTI-E-6
JE. Symphor et PA. Laur
S
X
Echantillonnage
X;D (non connue)
data stream (observe): S
X
FIG. 1  Le problŁme.
dØpendemment à partir d’une distributionD sur laquelle nous ne formulons aucune hypothŁse,
exceptØ celle de dire qu’il n’y a pas de biais. Nous renvoyons le lecteur intØressØ par des ap-
proches prenant en compte le biais dans les cas de fouilles de donnØes supervisØes aux travaux
de (Fan et al., 2004;Wang et al., 2003). La partie du stream observØe est reprØsentØe par S dans
la gure 1. A partir d’une valeur xØe par l’utilisateur du paramŁtre , le support thØorique,
on voudrait connaître l’ensemble des motifs vrais -frØquents deX . Cet ensemble nommØX
est reprØsentØ en grisØ sur la gure 1. Hormis l’incertitude et les aspects liØs à l’estimation
statistique, l’approximation de l’ensemble X recouvre un aspect combinatoire qui provient
de la trŁs grande taille de X mŒme si cet ensemble peut Œtre ni. Nous nommons S l’en-
semble des motifs observØs extraits du stream avec jSj = m (jSj << jX j). Nous rØduisons
cette diffØrence à l’aide d’un algorithme qui permet d’obtenir un super ensemble S de S avec
jSj = m > m. Typiquement, S contient des motifs supplØmentaires obtenus à partir d’une
gØnØralisation des ØlØments de S (Mannila et Toivonen, 1997). Ce n’est pas le propos de cet ar-
ticle de traiter l’aspect combinatoire, l’essentiel est que S ne sera jamais sufsamment grand
pour engloberX, au regard de la façon dont il est construit (voir gure 1). Ainsi l’importance
du problŁme d’estimation statistique demeure entier.
Soit l’ensemble X

(gures 1 et 2) qui reprØsente l’ensemble des motifs vrais -frØquents
de X pour l’ensemble S, nous rappelons que cet ensemble ne peut Œtre connu totalement
compte tenu non seulement du fait que jSj << jX j, mais aussi des deux sources d’erreurs
prØcØdemment indiquØes qui en dØcoulent. Nous recherchons 0 pour approcher au mieux
l’ensemble X

, en utilisant S
0
(gure 2) qui reprØsente l’ensemble des motifs observØs 0-
frØquents du stream dans S.
S

0
FP
S
FN
V P V N
X

FIG. 2  Estimation de l’erreur.
Pour apprØcier l’approximation effectuØe, consØcutivement aux deux sources d’erreurs ,
les sous-ensemblesX

et S
0
nous permettent de dØnir les quatre paramŁtres suivants (gure
2) :
- 617 - RNTI-E-6
Bordures statistiques pour la fouille incrØmentale dans les data streams
 VP (vrais positifs) : reprØsente l’ensemble des motifs, vrais -frØquents de X

et Øgale-
ment observØs 0-frØquents de S.
 FP (faux positifs) : reprØsente l’ensemble des motifs, vrais non -frØquents de X

mais
observØs 0-frØquents de S.
 FN (faux nØgatifs) : reprØsente l’ensemble des motifs, vrais -frØquents de X

mais
observØs non 0-frØquents de S.
 VN (vrais nØgatifs) : reprØsente l’ensemble des motifs, vrais non -frØquents du stream
et Øgalement observØs non 0-frØquents de S.
A partir des ensembles dØnis ci-dessus, on peut indiquer les formules de la prØcision et
du rappel qui permettent d’estimer l’approximation effectuØe.
P = V P=(V P + FP ) (1) R = V P=(V P + FN) (2)
La prØcision permet de quantier la proportion des motifs -frØquents estimØs qui sont
en fait non vrais -frØquents, en dehors de S
0
. Si on cherche à Maximiser P, cela revient
à minimiser la premiŁre source d’erreurs. SymØtriquement, le rappel permet de quantier la
proportion de motifs, vrais -frØquentsmanquant dansS
0
. Si on cherche cette fois à maximiser
R, cela revient à minimiser la seconde source d’erreurs.
2.2 Choix de 0
Dénition 1 0 est un support statistique pour , 0 < 0 < 1, s’il est utilisØ pour approcher
les motifs vrais -frØquents du stream.
Une approche naïve pour approcher au mieux l’ensembleX

consisterait à choisir 0 =  ;
autrement dit, la question que l’on pourrait se poser est de savoir si  est un support statistique
pour lui-mŒme. Malheureusement, la principale et seule propriØtØ de l’ensemble S
0
dans ce
cas, est qu’il tend à correspondre avec une probabilitØ de 1 à l’ensembleX

lorsque le cardinal
de l’ensemble S tend vers1 selon le lemme de Borel-Cantelli (Devroye et al., 1996). Cela
reviendrait à connaître tout le stream, ce qui n’est pas possible en pratique. Le thØorŁme de
Glivenko-Cantelli permet de montrer que l’on peut borner l’erreur commise sur les motifs
vrais -frØquents en fonction de divers paramŁtres parmi lesquels le cardinal de l’ensemble
S, mais on ne peut pas faire mieux. Bien souvent, en traitement de l’information ou encore en
medecine, plutôt que de simplement borner l’erreur, il est beaucoup plus important d’estimer
et de contrôler des parties de l’erreur. On peut par consØquent dØvelopper une approche qui
consiste à maximiser soit la prØcision P soit le rappel R. Le choix des valeurs aux limites de 0
pourraient convenir en ce sens oø l’on maximise la prØcision ou le rappel mais ces valeurs sont
inintØressantes pour les applications en fouille de donnØes. Par exemple, si on choisit 0 = 0,
on obtient S0 = S et ainsi R = 1. Mais, nous avons Øgalement dans ce cas P = jX j=jSj,
qui correspond à une valeur trop faible pour bien des applications, et donc tous les ØlØments
de S sont considØrØs comme des motifs vrais -frØquents du stream. On pourrait aussi choisir
0 = 1 pour Œtre sßr de maximiser P cette fois, mais il en dØcoule que R = 0 et il se pourrait
qu’aucun ØlØment de S ne soit un motif vrai -frØquent.
Ces exemples avec les valeurs aux limites de 0 nous permettent de bien cadrer les principes
de notre approche. L’idØe gØnØrale est de choisir subtilement 0 diffØrent mais sufsamment
- 618 -RNTI-E-6
JE. Symphor et PA. Laur
proche de , respectivement plus grand ou plus petit que , de sorte qu’il soit possible de
contrôler en maximisant soit la prØcision soit le rappel, pour garantir avec une trŁs forte pro-
babilitØ que P = 1 ou respectivement que R = 1 tout en limitant la dØgradation du paramŁtre
non contrôlØ. On obtient ainsi un ensemble S
0
pas trop petit contenant des informations signi-
catives. Il y a une barriŁre statistique autour de  qui empŒche que 0 ne soit ni trop proche
ni trop ØloignØ de  pour conserver la contrainte que P = 1 ou alors que R = 1, avec une forte
probabilitØ. Notre objectif pour maximiser la prØcision ou le rappel avec une forte probabilitØ
est par consØquent de rechercher les valeurs de 0 les plus proches possibles de cette barriŁre.
Le thØorŁme ci-dessous permet d’Øtablir les valeurs des supports statistiques que nous pro-
posons en calculant la valeur de " :
Théorème 1 8X; 8D; 8m > 0; 80    1; 80 <   1, on choisit " tel que :
" 
r
1
2m
ln
jSj

:
Si on xe 0 = + ", alors P = 1 avec une probabilitØ au moins de 1  . Si on xe 0 =   ",
alors R = 1 avec une probabilitØ au moins de 1   .  est le risque statistique liØ aux data
streams. Les valeurs  + ",    " sont les supports statistiques au sens de la dØnition 1.
Les supports obtenus (0 =  ") sont statistiquement presque optimaux. Faute de place, nous
renvoyons à l’article (Nock et al., 2005) 1 pour la dØmonstration complŁte. Celle-ci repose
sur l’utilisation d’inØgalitØs de concentration de variables alØatoires, qui, dans ce cas prØçis,
permettent d’obtenir des rØsultats statistiquement presque optimaux. Par optimalitØ, nous en-
tendons que toute technique d’estimation obtenant de meilleures bornes est condamnØe à se
tromper (le critŁre à maximiser n’est plus Łgal à un) quelque soit son temps de calcul.
3 Bordures statistiques pour la mise à jour incrØmentale
Dans cette section nous introduisons deux bordures statistiques (supØrieure et infØrieure)
qui vont Œtre pertinentes dans le choix des motifs frØquents à conserver lors de la mise à jour
incrØmentale. L’objectif avec la bordure statistique infØrieure est de maximiser la prØcision
P, tandis qu’avec la bordure statistique supØrieure il s’agit de maximiser le rappel R. Nous
adoptons la notation probabiliste dØnie par (McAllester, 1999).2
A partir du thØorŁme 1, nous dØnissons l’ensemble suivant : pour un risque statistique 
xØ par l’utilisteur, en choisissant 0 = + ", on construit l’ensemble S
+" tel que 8 ; S+" 
X

avec 8 ;P = 1. Ainsi, il n’y a plus la premiŁre source d’erreurs avec une forte probabilitØ.
Tous les motifs de S
+" sont des motifs, vrais -frØquents deX , mais on ne les a pas tous (voir
gure 3). S
+"
est le plus grand ensemble possible qui contient uniquement des motifs vrais
-frØquents de X

aprŁs un temps d’observation du stream. Nous dØnissons cet ensemble
comme Øtant la bordure statistique infØrieure de X

à partir de l’Øchantillon des motifs S de
X . De façon symØtrique, à partir du thØorŁme 1, nous dØnissons l’ensemble suivant : pour un
1www.pa-laur.com/LNSP_CIKM05.pdf
2Cette notation concise, s'écrivant 8P , précise que : le prédicat P est vrai à une fraction près  pour l'ensemble
S obtenu à partir de la distribution D. De façon équivalente, cela signie que le prédicat P est vrai avec une probabilité
 1   pour l'ensemble S obtenu à partir de la distribution D.
- 619 - RNTI-E-6
Bordures statistiques pour la fouille incrØmentale dans les data streams
FN
S
S
+"
VP VN
X

FIG. 3  Bordure statistique infØrieure.
S
FP
S
 "
VP
VN
X

FIG. 4  Bordure statistique supØrieure.
risque statistique  xØ par l’utilisteur, en choisissant 0 =   ", on construit l’ensemble S
 "
tel que 8 ; X

 S
 "
avec 8 ;R = 1. Ainsi, il n’y a plus la deuxiŁme source d’erreurs avec
une forte probabilitØ, c’est à dire que S
 "
contient tous les motifs, vrais -frØquents de X

,
mais il en contient d’autres (gure 4). S
 "
est le plus petit ensemble possible qui contient tous
les motifs vrais -frØquents de X

aprŁs un temps d’observation du stream. Nous dØnissons
cet ensemble comme Øtant la bordure statistique supØrieure deX

à partir de l’Øchantillon des
motifs S du streamX .
Stream
(a) (b)
(c)
         Motifs
DB db
P , R, F
S
+"
S
 "
DB [ db
S
X
0


S
0
=
FIG. 5  Bordures statistiques pour la mise à jour incrØmentale.
La gure 5 illustre l’utilisation de bordures dans un processus de mise à jour incrØmentale.
Nous recherchons les motifs -frØquents à partir des bordures statistiques (notØes (a) et (b) sur
la gure 5). Ces bordures sont construites pour le support  choisi à partir de la valeur de ",
calculØe pour S (DB). Ces bordures, nous permettent d’approcher au mieux l’ensemble de
tous les motifs vrais -frØquents pour S 0 , qui reprØsente la base DB mise à jour par l’ajout
de db, S0 = S [ db. Dans la section suivante lors de nos expØrimentations, nous comparerons
les motifs -frØquents obtenus grâce aux bordures statistiques par rapport à l’ensemble X 0

( (c) sur la gure 5). Cet ensemble reprØsente les vrais motifs -frØquents aprŁs mise à jour
incrØmentale (DB [ db).
4 ExpØrimentation
Comme nous l’avons prØcisØ dans la section prØcØdente notre objectif lors des expØrimen-
tations ne consiste pas à Øvaluer les temps de rØponse associØs à nos bordures mais plutôt
- 620 -RNTI-E-6
JE. Symphor et PA. Laur
Database  tailleDB taille db
Dragons [0.07, 0.2] / 0.03 [0.2,0.6] / 0.1 [0.1, 0.5] /0.1
BuAG [0.08, 0.2] / 0.03 [0.2,0.6] / 0.1 [0.1, 0.5] /0.1
FIG. 6  Valeurs des paramŁtres de la forme [a; b]=c, oø a est la valeur de dØpart, c est
l’incrØment, et b est la valeur nale.
d’Øvaluer leur qualitØ. Pour cela, nous utilisons les mesures de prØcision P et de rappel R dØ-
nies prØcØdemment dans les Øquations (1) et (2). Du fait de l’indØpendance de notre mØthode
vis à vis des motifs recherchØs, nous avons utilisØ un algorithme traditionnel de recherche de
motifs sØquentiels frØquents SPADE (Zaki, 2001).
Lors de cette Øvaluation, nous avons utilisØ deux jeux de donnØes issus de serveurs Web.
Le premier appelØ Dragons, est obtenu sur le site internet3. Ces donnØes reprØsentent la
navigation d’utilisateurs sur ce site. La taille du chier de log reprØsente environ 2,54Go (132k
transactions). La deuxiŁme base de donnØes, appelØe BuAG, est obtenue à partir des 3,48Go
(54k transactions) de Web log du serveur web de la bibliothŁque de l’UniversitØ4.
Pour analyser la qualitØ de nos bordures stastiques, nous Øvaluons diffØrentes situations en
faisant varier un ensemble de paramŁtres (une exception est faite pour , qui est xØ à .05).
Les variations de ces paramŁtres sont dØcrites dans la gure 6. Le premier paramŁtre dØnit
les diffØrentes valeurs de support sur lesquelles nous allons rØaliser l’expØrimentation ( ).
Le second paramŁtre, dØnit la taille de DB par rapport à la taille du stream simulØ (taille
DB). Le dernier paramŁtre, quant à lui, dØnit la taille de db par rapport à celle deDB. Dans
notre cas db reprØsentera au plus 50% de DB (taille db), ce paramŁtre permet de contrôler
la taille de l’incrØment par rapport à la partie stockØe initialement. Pour gØrer et organiser ces
expØriences un gØnØrateur est chargØ de coordonner tous les tests à effectuer.
Au lieu d’utiliser un vrai data stream, qui aurait pu limiter la qualitØ de l’Øvaluation de
nos bordures statistiques, nous avons choisi d’en simuler un à l’aide de la connaissance de
son domaine X . Plus prØcisØment, pour simuler le stream nous Øchantillonnons chaque base
de donnØes en fragments DB (S). Par exemple, nous pouvons considØrer que les donnØes ar-
rivent successivement depuis la base de donnØes Dragons et que nous ne pouvons en stocker
que 20%. Pour cela nous prenons 20% des transactions contenues dans cette base de don-
nØes et nous les conservons dans DB. Il ne reste alors plus qu’à prendre un incrØment, db par
exemple de taille 10%, de cette base. Nous construisons alors les bordures statistiques (bordure
infØrieure et bordure supØrieure) dØnies dans la section 3 pourDB.
Les gures 7 et 8 montrent les rØsultats d’expØriences obtenues, avec  = 0:05, respective-
ment sur les bases Dragons et BuAG. Pour Øvaluer la qualitØ de ces bordures pour la mise à jour,
nous reprØsentons leurs comportements pour P et R par rapport à S 0 (S0 = DB [ db). Ainsi,
les courbes P+" et P ", reprØsentent la prØcision respectivement pour la bordure statistique
infØrieure et pour la bordure statistique supØrieure. De mŒme les courbes R" reprØsentent le
rappel. Les courbes P et R correspondent au choix trivial 0 = . Nous constatons que ces
courbes ont un comportement assez similaire :
 la prØcision P vaut ou approche 1 pour la plupart des bases stockØes quand 0 =  + ",
3www.elevezundragon.com.
4www.univ-ag.fr/buag/.
- 621 - RNTI-E-6
Bordures statistiques pour la fouille incrØmentale dans les data streams
Dragons,  = 0:07, S = 60%
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 65  70  75  80  85  90
P
Taille S'(%)
(Pθ, Pθ+ε, Pθ-ε) = f(taille S')
Pθ+ε
Pθ-ε
Pθ
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 65  70  75  80  85  90
R
Taille S' (%)
(Rθ, Rθ+ε, Rθ-ε) = f(taille S')
Rθ+ε
Rθ-ε
Rθ
Dragons,  = 0:19, S = 20%
 0.65
 0.7
 0.75
 0.8
 0.85
 0.9
 0.95
 1
 32  34  36  38  40  42  44  46
P
Taille S'(%)
(Pθ, Pθ+ε, Pθ-ε) = f(taille S')
Pθ+ε
Pθ-ε
Pθ  0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 21  22  23  24  25  26  27  28  29  30
R
Taille S' (%)
(Rθ, Rθ+ε, Rθ-ε) = f(taille S')
Rθ+ε
Rθ-ε
Rθ
FIG. 7  reprØsente les courbes P (à gauche) et R (à droite) sur la base Dragons pour trois
valeurs de 0 :    ";  et  + ", deux valeurs de  et deux tailles de S (% par rapport à |X|).
 le rappel R vaut ou approche 1 pour la plupart des bases stockØes quand 0 =    ".
Ces observations sont en accords avec les rØsultats thØoriques de la section 2. Nous obser-
vons Øgalement un autre phØnomŁne : le rappel R associØ à 0 =  + " n’est pas trŁs ØloignØ
de celui associØ à 0 = . Il en est de mŒme pour la prØcision P associØe à 0 =    ". Ce qui
montre que la maximisation de la prØcision P ou du rappel R est obtenue avec un coßt rØduit au
niveau de la dØgradation de l’autre paramŁtre. Nous notons aussi que les courbes de prØcision
P ont de meilleures performances que celles du rappel R notamment sur la gure 8. Ceci n’est
pas trŁs surprenant (c:f: section 2), car la fourchette de valeur pour la prØcision P est beaucoup
plus restreinte que pour le rappel R.
La variation de la taille de S (DB) possŁde Øgalement une importance et vient conforter
un rØsultat thØorique auquel on pouvait s’attendre. En effet si on s’intØresse au rappel R, on
constate, que ce soit sur les gures 7 ou 8, que les valeurs observØes pour cette quantitØe aug-
mentent avec la taille de S. Cela traduit le fait que plus nous possØdons de donnØes observØes
plus la qualitØ de la prØdiction augmente.
Sur ces bases de donnØes un autre phØnomŁne semble apparaître. PremiŁrement, à cause
des faibles valeurs de , certains tests n’ont pas pu Œtre rØalisØs car la valeur de    " Øtait
infØrieure à 0. De plus, les diffØrences observØes entre les courbes semblent Œtre liØes aux
tailles des bases de donnØes utilisØes. La base de donnØes BuAG est plus petite que celle de
Dragons d’un facteur 2.4. Nous pensons que ceci explique la diffØrence entre les courbes : il
s’agit de phØnomŁnes liØs à des bases de donnØes de petites tailles et qui ne devraient pas Œtre
prØsents dans des bases de donnØes plus consØquentes ou dans de vrais data streams.
Sur ces courbes (gures 7 et 8), le choix de 0 =  donne de meilleurs rØsultats en ce qui
concerne la moyenne de P et R que le choix des deux valeurs de 0, sachant que ni P, ni R
ne sont trŁs proches de 1 avec une forte probabilitØ dans ce cas. Avec notre approche, on peut
efcacement optimiser le processus de mise à jour incrØmentale. Dans le cas oø on aurait un
- 622 -RNTI-E-6
JE. Symphor et PA. Laur
BuAG,  = 0:08, S = 20%
 0.55
 0.6
 0.65
 0.7
 0.75
 0.8
 0.85
 0.9
 0.95
 1
 22  23  24  25  26  27  28  29  30  31
P
Taille S'(%)
(Pθ, Pθ+ε, Pθ-ε) = f(taille S')
Pθ+ε
Pθ-ε
Pθ
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 22  23  24  25  26  27  28  29  30  31
R
Taille S' (%)
(Rθ, Rθ+ε, Rθ-ε) = f(taille S')
Rθ+ε
Rθ-ε
Rθ
BuAG,  = 0:08, S = 40%
 0.6
 0.65
 0.7
 0.75
 0.8
 0.85
 0.9
 0.95
 1
 44  46  48  50  52  54  56  58  60  62
P
Taille S'(%)
(Pθ, Pθ+ε, Pθ-ε) = f(taille S')
Pθ+ε
Pθ-ε
Pθ  0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 44  46  48  50  52  54  56  58  60  62
R
Taille S' (%)
(Rθ, Rθ+ε, Rθ-ε) = f(taille S')
Rθ+ε
Rθ-ε
Rθ
FIG. 8  reprØsente les courbes P (à gauche) et R (à droite) sur la base BuAG pour trois
valeurs de 0 :    ";  et  + ", deux valeurs de  et deux tailles de S (% par rapport à |X|).
espace sufsant de stockage, on choisirait 0 =    ", la bordure supØrieure, pour laquelle on
possŁde des garanties importantes sur la prØsence des futurs frØquents en son sein (R = 1).
Dans ce cas, le nombre de calculs supplØmentaires sera faible lors de la mise à jour. Par contre
dans le cas oø on devrait se limiter pour des raisons de taille à conserver une bordure disons
moins volumineuse, 0 =  + ", la bordure infØrieure, sera alors utilisØe car elle contient les
informations les plus pertinentes (P = 1). On peut ainsi voir les bordures statistiques comme
des outils de mise à jour incrØmentale indiquant les limites au delà desquelles : soit il est inutile
de stocker plus d’informations dans le cas de 0 =   " (valeur limite infØrieure pour 0) ; soit
la perte d’information serait trop importante 0 =  + " (valeur limite supØrieure pour 0 ).
5 Travaux connexes
Depuis 1996, de nombreux travaux de recherche se sont focalisØs sur la maintenance des
ensembles de motifs frØquents obtenus dans les bases de donnØes statiques. Dans ce para-
graphe nous regardons leur adØquation par rapport à notre problØmatique. Partition et FUP
(Fast UPdate) (Cheung et al., 1996) sont deux algorithmes oø un partitionnement de la base
de donnØes est effectuØ pour rechercher dans un premier temps les itemsets frØquents locaux
relatifs à chaque partition puis dans un second temps en dØduire les itemsets frØquents glo-
baux par validation croisØe. Cela repose sur l’hypothŁse que les itemsets frØquents de la base
doivent l’Œtre dans au moins l’une des partitions. (Parthasarathy et al., 1999) ont dØveloppØ un
algorithme de mise à jour incrØmentale ISM (Incremental Sequence Mining) en maintenant un
treillis, de motifs de la base, construit à partir de tous les motifs frØquents et de tous les motifs
de la bordure nØgative. (Zheng et al., 2002) ont dØveloppØ un algorithme IUS( Incrementally
Updating Sequence) en utilisant une valeur support pour limiter la taille de l’espace des candi-
- 623 - RNTI-E-6
Bordures statistiques pour la fouille incrØmentale dans les data streams
dats de la bordure nØgative. Ces diffØrentes approches se heurtent aux inconvØnients inhØrents
à l’utilisation de la bordure nØgative :
 l’espace des motifs candidats à maintenir est trŁs important ;
 il est nØcessaire de considØrer les relations structurelles qui existent entre les motifs
notamment dans le cas des motifs qui auraient une faible valeur de support.
Les diffØrents algorithmes utilisant la bordure nØgative sont trŁs coßteux en temps et sont
consommateurs d’espace mØmoire.
(Masseglia et al., 2003) ont dØveloppØ un algorithme de mise à jour incrØmentale ISE
utilisant une approche par gØnØration et test de candidats. Les inconvØnients sont que :
 l’espace des candidats peut Œtre trŁs grand, ce qui rend la phase de test trŁs lente ;
 l’algorithme requiert plusieurs passages sur toute la base. Cela est trŁs coßteux en temps
particuliŁrement pour les motifs sØquentiels à sØquences longues.
−−−−−−− −− −− − −− −−−−−−−−−−−−
−
+ ++ + ++ ++ + + ++++ + +
+
+ + +
+ +
+
++
+
+
+
+
++ + + + + + + + +
+ + ++
+ + + + +
+
+
+++++
+++
+
+
Bordure statistique
Bordure statistique
SFS
Vrais frequents
inferieure
Frequents observes
superieure
FIG. 9  Comparaison.
L’algorithme IncSpan (IncrementalMining of Sequential Patterns in large database) dØveloppØ
par (Cheng et al., 2004) repose sur une approche statistique oø l’on construit un ensemble de
motifs semi-frØquents (SFS) en diminuant la valeur du support à partir d’un ratio. L’idØe est
de dire qu’à partir d’un ensemble de motifs "presque frØquents" (SFS), plusieurs des motifs
frØquents de la base mise à jour proviendraient de SFS ou alors seraient dØjà observØs frØ-
quents dans la base connue prØcØdant la mise à jour. Autrement dit, SFS constituerait une
zone frontiŁre entre les motifs frØquents et non frØquents. Sur la gure 9, nous reprØsentons
un exemple d’ensemble SFS. Cette approche prØsente des insufsances majeures d’un point
de vue statistique tant pour l’estimation de l’incertitude intrinsŁque liØe aux data streams que
pour la construction de l’ensemble des motifs candidats permettant la mise à jour incrØmen-
tale. En effet, pour diminuer la valeur du support, le choix du ratio est simplement heuristique
sans justication thØorique. Ainsi, cette approche n’offre aucune certitude ni indication sur
l’erreur commise lors de la construction de l’ensemble des motifs semi-frØquents quant aux
motifs vrais -frØquents du stream (zone identiØe avec les symboles - sur la gure 9). De
plus, nous n’avons aucune garantie sur la minimalitØ de cet ensemble (zone identiØe avec les
symboles + sur la gure 9), ce qui est fortement pØnalisant pour sa rØutilisation dans l’objectif
d’optimisation de la mØthode de mise à jour incrØmentale.
6 Conclusion
Dans cet article, nous abordons la problØmatique de la mise à jour incrØmentale pour les
motifs frØquents dans le cas des grandes bases de donnØes. Dans le contexte des data streams,
- 624 -RNTI-E-6
JE. Symphor et PA. Laur
il est plus pertinent, de construire et de maintenir des ensembles de motifs vrais -frØquents et
non simplement observØs comme tels. Plusieurs travaux, (Kearns et Mansour, 1998; Nock et
Nielsen, 2004; Vapnik, 1998), ont montrØ l’intØrŒt de l’approche statistique notamment dans
la dØtermination de rŁgles de prØvision pour l’optimisation d’algorithmes. Notre contribution
majeure porte prØcisØment sur ce point par l’introduction de supports statistiques en complØ-
ment des supports classiques permettant d’obtenir des bordures statistiques qui constituent les
ensembles statistiquement presque optimaux (à une constante prŁs) à considØrer dans le cadre
de la mise à jour incrØmentale. Les expØrimentations prØsentØes montrent la robustesse de
l’approche, dans le cas des motifs sØquentiels, au regard de la taille des bases stockØes et des
diffØrentes valeurs supports testØes. Ces rØsultats encourageants sont des points positifs quant à
l’applicabilitØ et le passage à l’Øchelle de la mØthode. Plusieurs extensions de ces travaux sont
possibles dans bien des domaines de recherche en fouille de donnØes. On citera notamment les
travaux qui portent sur les structures de donnØes oø l’on cherche à maintenir des ensembles
d’items qui sont observØs frØquents avec un rappel maximum, (Jin et al., 2003). Nos prØoc-
cupations actuelles concernent la question suivante : est-il possible de construire un ensemble
intermØdiaire qui conserverait au mieux les propriØtØs de chacune de ces bordures ? Celui-ci
reprØsenterait un compromis entre une bordure statistique trop imposante à stocker et une autre
pour laquelle le nombre d’accŁs à la base de donnØes est trop important.
RØfØrences
Agrawal, R., T. Imielinski, et A.-N. Swami (1993). Mining association rules between sets of
items in large databases. In Proc. of the ACM SIGMOD ICMD’93, pp. 207216.
Ayres, J., J. Flannick, J. Gehrke, et T. Yiu (2002). Sequential pattern mining using bitmap
representation. In Proc. of KDD’02.
Cheng, X., X. Yan, et J. Han (2004). Incspan : Incremental mining of sequential patterns in
large database. In Proc. of KDD’04.
Cheung, D., J. Han, V. Ng, et C. Wong (1996). Maintenance of discovered association rules in
large databases : an incremental updating technique. In Proc. of ICDE’96, pp. 106114.
Demaine, E., A. Lopez-Ortizand, et J.-I. Munro (2002). Frequency estimation of internet pa-
cket streams with limited space. In Proc. of the 10th European Symposium on Algorithms.
Devroye, L., L. Györ, et G. Lugosi (1996). A Probabilistic Theory of Pattern Recognition.
Fan, W., Y.-A. Huang, H. Wang, et P.-S. Yu (2004). Active mining of data streams. In Proc. of
the 4th SIAM International Conference on Data Mining, pp. 457461.
Golab, L. et M. T. Ozsu (2003). Issues in data stream management. ACM SIGMOD Records 2.
Han, J., J. Pei, B. Mortazavi-asl, Q. Chen, U. Dayal, et M. Hsu (2000). Freespan : Frequent
pattern-projected sequential pattern mining. In Proc. of KDD’00.
Jin, C., W. Qian, C. Sha, J.-X. Yu, et A. Zhou (2003). Dynamically maintaining frequent items
over a data stream. In Proc. of CIKM’03, pp. 287294. ACM Press.
Karp, R.-M., S. Shenker, et C.-H. Papadimitriou (2003). A simple algorithm for nding ele-
ments in streams and bags. ACM Trans. on Database Systems 28, 5155.
- 625 - RNTI-E-6
Bordures statistiques pour la fouille incrØmentale dans les data streams
Kearns, M. J. et Y. Mansour (1998). A Fast, Bottom-up Decision Tree Pruning algorithm with
Near-Optimal generalization. In Proc. of ICML’98, pp. 269277.
Li, H.-F., S.-Y. Lee, et M.-K. Shan (2004). An efcient algorithm for mining frequent itemsets
over the entire history of data streams. In Proc. of the 1st Int. Workshop on Knowledge
Discovery in Data Streams.
Manku, G. et R. Motwani (2002). Approximate frequency counts over data streams. In Proc.
of the 28 th International Conference on Very Large Databases, pp. 346357.
Mannila, H. et H. Toivonen (1997). Levelwise search and borders of theories in knowlede
discovery. Data Mining and Knowledge Discovery 1, 241258.
Masseglia, F., P. Poncelet, et M. Teisseire (2003). Incremental mining of sequential patterns in
large databases. Data and Knowledge Engineering 46.
McAllester, D. (1999). Some PAC-Bayesian theorems. Machine Learning 37, 355363.
Nock, R., P. Laur, P. Poncelet, et J. Symphor (2005). On the estimation of frequent itemsets
for data streams : Theory and experiments. In Proc. of CIKM’05.
Nock, R. et F. Nielsen (2004). Statistical Region Merging. IEEE Trans. on Pattern Analysis
and Machine Intelligence 26, 14521458.
Parthasarathy, S., M. Zaki, M. Orihara, et S. Dwarkadas (1999). Incremental and interactive
sequence mining. In Proc. of CIKM’99.
Pei, J., J. Han, B. Mortazavi-asl, H. Pinto, Q. Chen, et U. Dayal (2001). Prexspan : Mining
sequential patterns efciently by prex-projected pattern growth. In Proc. of ICDE’01.
Srikant, R. A. R. (1995). Mining sequential patterns. In Proc. of ICDE’95 Conference.
Vapnik, V. (1998). Statistical Learning Theory. John Wiley.
Wang, H., W. Fan, P.-S. Yu, et J. Han (2003). Mining concept-drifting data streams with
ensemble classiers. In Proc. of KDD’03, pp. 226235.
Zaki, M. (2001). SPADE : An efcient algorithm for mining frequent sequences. Machine
Learning Journal 42.
Zheng, Q., K. Xu, S. Ma, et W. lv (2002). The algorithms of updating sequential patterns. In
Proc. of ICDM’02.
Summary
Recently the knowledge extraction community takes a closer look to new models where
data arrive in timely manner like a fast and continous ow, i:e: data streams. One of the most
important singularity inside streams relies on that only a part of it is available. After some
following updates, it’s necessary, to cope with uncertainty as only a part of it is available. In
this paper, we introduce a new statiscal approach which biases the initial support for sequential
patterns mining. This approach holds the advantage to maximize one of the parameters (pre-
cision or recall) chosen by the user while limiting the degradation of the other criterion. Thus,
we dene the statistical borders which are the relevant sets of frequent patterns in incremental
mining of streams. Experiments performed on sequential patterns demonstrate the interest of
this approach and the potential of such techniques.
- 626 -RNTI-E-6
