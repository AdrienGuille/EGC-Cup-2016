Bordures statistiques pour la fouille incr√òmentale de donn√òes
dans les Data Streams
Jean-Emile Symphor, Pierre-Alain Laur
GRIMAAG-D√òpt Scientique Interfacultaire,
Universit√ò des Antilles et de la Guyane, Campus de Schoelcher,
B.P. 7209, 97275 Schoelcher Cedex, Martinique, France
fje.symphor,palaurg@martinique.univ-ag.fr.
R√©sum√©. R√òcemment la communaut√ò Extraction de Connaissances s‚Äôest int√ò-
ress√òe √† de nouveaux mod≈Åles o√∏ les donn√òes arrivent s√òquentiellement sous la
forme d‚Äôun ot rapide et continu, i:e: les data streams. L‚Äôune des particularit√òs
importantes de ces ots est que seule une quantit√ò d‚Äôinformation partielle est
disponible au cours du temps. Ainsi apr≈Ås diff√òrentes mises √† jour successives,
il devient indispensable de consid√òrer l‚Äôincertitude inh√òrente √† l‚Äôinformation re-
tenue. Dans cet article, nous introduisons une nouvelle approche statistique en
biaisant les valeurs supports pour les motifs fr√òquents. Cette derni≈Åre a l‚Äôavan-
tage de maximiser l‚Äôun des deux param≈Åtres (pr√òcision ou rappel) d√òtermin√òs
par l‚Äôutilisateur tout en limitant la d√ògradation sur le param≈Åtre non choisi. Pour
cela, nous d√ònissons les notions de bordures statistiques. Celles-ci constituent
les ensembles de motifs candidats qui s‚Äôav≈Årent tr≈Ås pertinents √† utiliser dans le
cas de la mise √† jour incr√òmentale des streams. Les diff√òrentes exp√òrimentations
effectu√òes dans le cadre de recherche de motifs s√òquentiels ont montr√ò l‚Äôint√òr≈ít
de l‚Äôapproche et le potentiel des techniques utilis√òes.
1 Introduction
Ces dix derni≈Åres ann√òes un grand nombre de travaux ont √òt√ò propos√òs pour rechercher des
motifs fr√òquents dans de grandes bases de donn√òes. En fonction des domaines d‚Äôapplications
les motifs extraits sont soit des itemsets (Srikant, 1995; Zaki, 2001; Pei et al., 2001; Ayres et al.,
2002) soit des s√òquences (Agrawal et al., 1993; Han et al., 2000). R√òcemment les travaux issus
de la communaut√ò des chercheurs en base de donn√òes et en fouille de donn√òes consid≈Årent le
cas des data streams o√∏ l‚Äôacquisition des donn√òes s‚Äôeffectue de fa√ßon r√òguli≈Åre, continue ou
incr√òmentalement et cela sur une dur√òe longue voire √òventuellement illimit√òe.
Compte tenu de la grande quantit√ò d‚Äôinformation mise en jeu dans le cas des data streams,
le probl≈Åme de l‚Äôextraction de motifs fr√òquents est toujours d‚Äôactualit√ò ((Li et al., 2004; Jin
et al., 2003; Demaine et al., 2002; Manku et Motwani, 2002; Golab et Ozsu, 2003; Karp et al.,
2003)). Dans ce contexte, un motif est dit -fr√òquent s‚Äôil est observ√ò au moins une fraction ,
appel√òe support du motif, sur tout le stream. Le param≈Åtre theta, tel que 0 <  < 1, est x√ò
par l‚Äôutilisateur.
- 615 - RNTI-E-6
Bordures statistiques pour la fouille incr√òmentale dans les data streams
Dans le cas des data streams, sujets √† des mises √† jour r√òguli≈Åres et fr√òquentes, les approches
traditionnelles ne conviennent pas car les r√òsultats obtenus pour l‚Äôancienne base ne sont que
partiellement valables pour la nouvelle et il n‚Äôest pas envisageable de relancer l‚Äôalgorithme
sur la base de donn√òes mise √† jour. En effet, dans tous les travaux d√òveloppant une approche
par mise √† jour incr√òmentale (Masseglia et al., 2003; Cheng et al., 2004), la probl√òmatique
principale d‚Äôoptimisation et de performance consiste √† construire et √† maintenir, au fur et √†
mesure des diff√òrentes mises √† jour successives, un ensemble de motifs candidats. Celui-ci est
utilis√ò pour mettre √† jour les motifs fr√òquents et √òviter de relancer l‚Äôalgorithme depuis z√òro.
Il convient √ògalement de souligner une autre caract√òristique intrins≈Åque des data streams
qui d√òcoule du fait que la connaissance du stream n‚Äôest que partielle quel que soit l‚Äôinstant
consid√òr√ò. En cons√òquence, il est n√òcessaire de prendre en compte l‚Äôincertitude engendr√òe par
la connaissance toujours incompl≈Åte du data stream. Pr√òcis√òment, cela se traduit dans le cas de
la recherche de motifs fr√òquents en soulignant que les motifs fr√òquents obtenus ne sont en fait
que des motifs fr√òquents observ√òs. En fait, √† cause de cette incertitude, deux sources d‚Äôerreurs
doivent ≈ítre consid√òr√òes :
¬ñ Les motifs observ√òs comme fr√òquents ne sont peut ≈ítre plus du tout fr√òquents sur une
longue p√òriode d‚Äôobservation du stream.
¬ñ Inversement des motifs class√òs comme non fr√òquents peuvent le devenir sur une plus
longue p√òriode d‚Äôobservation du stream.
Pour √òviter ces erreurs, il est n√òcessaire de d√òvelopper une approche pour conna√Ætre si un motif
est fr√òquent sur une partie d√òj√† examin√òe du stream. Cette approche doit de plus ≈ítre pr√òdictive
pour savoir avec quelle probabilit√ò un motif est fr√òquent ou non sur l‚Äôensemble du stream.
De nombreuses applications, par exemple dans le domaine de la pr√òvision m√òt√òorologique
ou encore dans l‚Äôanalyse de tendance en nance n√òcessitent ce type d‚Äôapproche. M≈íme en
disposant d‚Äôune tr≈Ås grande partie du stream, d‚Äôun point de vue statistique, il est impossible de
s‚Äôaffranchir de ces deux sources d‚Äôerreur (Vapnik, 1998). Notre objectif sera donc d‚Äôessayer
d‚Äôapprocher le mieux possible une solution optimale.
Dans cet article nous proposons une approche qui permet, tout en consid√òrant l‚Äôincertitude
inh√òrente √† la connaissance des streams, de construire et de maintenir des ensembles de motifs
candidats bien choisis. Ceci constitue un pr√òalable fondamental et n√òcessaire √† toute approche
pertinente dans le cadre de la mise √† jour incr√òmentale des data streams.
La suite de la pr√òsentation est organis√òe de la fa√ßon suivante. Dans le paragraphe 2, nous
introduisons les concepts qui permettent de contr√¥ler l‚Äôincertitude d√òcoulant des sources d‚Äôer-
reurs. Au paragraphe 3, nous montrons comment obtenir les ensembles de motifs pertinents
pour effectuer la mise √† jour incr√òmentale. Le paragraphe 4 pr√òsente une exp√òrimentation de
notre approche, suivie d‚Äôune analyse comparative avec des travaux connexes au paragraphe 5.
Nous concluerons notre √òtude au paragraphe 6.
2 Supports statistiques
2.1 D√©nitions
Pour formaliser notre probl√òmatique, nous d√ònissons les diff√òrents ensembles utilis√òs. Le
data stream est obtenu √† partir d‚Äôun √òchantillonnage effectu√ò sur un domaineX potentiellement
tr≈Ås grand qui contient tous les motifs possibles (gure 1). Chaque motif est √òchantillonn√ò in-
- 616 -RNTI-E-6
JE. Symphor et PA. Laur
S
X
Echantillonnage
X;D (non connue)
data stream (observe): S
X
FIG. 1 ¬ñ Le probl≈Åme.
d√òpendemment √† partir d‚Äôune distributionD sur laquelle nous ne formulons aucune hypoth≈Åse,
except√ò celle de dire qu‚Äôil n‚Äôy a pas de biais. Nous renvoyons le lecteur int√òress√ò par des ap-
proches prenant en compte le biais dans les cas de fouilles de donn√òes supervis√òes aux travaux
de (Fan et al., 2004;Wang et al., 2003). La partie du stream observ√òe est repr√òsent√òe par S dans
la gure 1. A partir d‚Äôune valeur x√òe par l‚Äôutilisateur du param≈Åtre , le support th√òorique,
on voudrait conna√Ætre l‚Äôensemble des motifs vrais -fr√òquents deX . Cet ensemble nomm√òX
est repr√òsent√ò en gris√ò sur la gure 1. Hormis l‚Äôincertitude et les aspects li√òs √† l‚Äôestimation
statistique, l‚Äôapproximation de l‚Äôensemble X recouvre un aspect combinatoire qui provient
de la tr≈Ås grande taille de X m≈íme si cet ensemble peut ≈ítre ni. Nous nommons S l‚Äôen-
semble des motifs observ√òs extraits du stream avec jSj = m (jSj << jX j). Nous r√òduisons
cette diff√òrence √† l‚Äôaide d‚Äôun algorithme qui permet d‚Äôobtenir un super ensemble S de S avec
jSj = m > m. Typiquement, S contient des motifs suppl√òmentaires obtenus √† partir d‚Äôune
g√òn√òralisation des √òl√òments de S (Mannila et Toivonen, 1997). Ce n‚Äôest pas le propos de cet ar-
ticle de traiter l‚Äôaspect combinatoire, l‚Äôessentiel est que S ne sera jamais sufsamment grand
pour engloberX, au regard de la fa√ßon dont il est construit (voir gure 1). Ainsi l‚Äôimportance
du probl≈Åme d‚Äôestimation statistique demeure entier.
Soit l‚Äôensemble X

(gures 1 et 2) qui repr√òsente l‚Äôensemble des motifs vrais -fr√òquents
de X pour l‚Äôensemble S, nous rappelons que cet ensemble ne peut ≈ítre connu totalement
compte tenu non seulement du fait que jSj << jX j, mais aussi des deux sources d‚Äôerreurs
pr√òc√òdemment indiqu√òes qui en d√òcoulent. Nous recherchons 0 pour approcher au mieux
l‚Äôensemble X

, en utilisant S
0
(gure 2) qui repr√òsente l‚Äôensemble des motifs observ√òs 0-
fr√òquents du stream dans S.
S

0
FP
S
FN
V P V N
X

FIG. 2 ¬ñ Estimation de l‚Äôerreur.
Pour appr√òcier l‚Äôapproximation effectu√òe, cons√òcutivement aux deux sources d‚Äôerreurs ,
les sous-ensemblesX

et S
0
nous permettent de d√ònir les quatre param≈Åtres suivants (gure
2) :
- 617 - RNTI-E-6
Bordures statistiques pour la fouille incr√òmentale dans les data streams
¬ñ VP (vrais positifs) : repr√òsente l‚Äôensemble des motifs, vrais -fr√òquents de X

et √ògale-
ment observ√òs 0-fr√òquents de S.
¬ñ FP (faux positifs) : repr√òsente l‚Äôensemble des motifs, vrais non -fr√òquents de X

mais
observ√òs 0-fr√òquents de S.
¬ñ FN (faux n√ògatifs) : repr√òsente l‚Äôensemble des motifs, vrais -fr√òquents de X

mais
observ√òs non 0-fr√òquents de S.
¬ñ VN (vrais n√ògatifs) : repr√òsente l‚Äôensemble des motifs, vrais non -fr√òquents du stream
et √ògalement observ√òs non 0-fr√òquents de S.
A partir des ensembles d√ònis ci-dessus, on peut indiquer les formules de la pr√òcision et
du rappel qui permettent d‚Äôestimer l‚Äôapproximation effectu√òe.
P = V P=(V P + FP ) (1) R = V P=(V P + FN) (2)
La pr√òcision permet de quantier la proportion des motifs -fr√òquents estim√òs qui sont
en fait non vrais -fr√òquents, en dehors de S
0
. Si on cherche √† Maximiser P, cela revient
√† minimiser la premi≈Åre source d‚Äôerreurs. Sym√òtriquement, le rappel permet de quantier la
proportion de motifs, vrais -fr√òquentsmanquant dansS
0
. Si on cherche cette fois √† maximiser
R, cela revient √† minimiser la seconde source d‚Äôerreurs.
2.2 Choix de 0
D√©nition 1 0 est un support statistique pour , 0 < 0 < 1, s‚Äôil est utilis√ò pour approcher
les motifs vrais -fr√òquents du stream.
Une approche na√Øve pour approcher au mieux l‚ÄôensembleX

consisterait √† choisir 0 =  ;
autrement dit, la question que l‚Äôon pourrait se poser est de savoir si  est un support statistique
pour lui-m≈íme. Malheureusement, la principale et seule propri√òt√ò de l‚Äôensemble S
0
dans ce
cas, est qu‚Äôil tend √† correspondre avec une probabilit√ò de 1 √† l‚ÄôensembleX

lorsque le cardinal
de l‚Äôensemble S tend vers1 selon le lemme de Borel-Cantelli (Devroye et al., 1996). Cela
reviendrait √† conna√Ætre tout le stream, ce qui n‚Äôest pas possible en pratique. Le th√òor≈Åme de
Glivenko-Cantelli permet de montrer que l‚Äôon peut borner l‚Äôerreur commise sur les motifs
vrais -fr√òquents en fonction de divers param≈Åtres parmi lesquels le cardinal de l‚Äôensemble
S, mais on ne peut pas faire mieux. Bien souvent, en traitement de l‚Äôinformation ou encore en
medecine, plut√¥t que de simplement borner l‚Äôerreur, il est beaucoup plus important d‚Äôestimer
et de contr√¥ler des parties de l‚Äôerreur. On peut par cons√òquent d√òvelopper une approche qui
consiste √† maximiser soit la pr√òcision P soit le rappel R. Le choix des valeurs aux limites de 0
pourraient convenir en ce sens o√∏ l‚Äôon maximise la pr√òcision ou le rappel mais ces valeurs sont
inint√òressantes pour les applications en fouille de donn√òes. Par exemple, si on choisit 0 = 0,
on obtient S0 = S et ainsi R = 1. Mais, nous avons √ògalement dans ce cas P = jX j=jSj,
qui correspond √† une valeur trop faible pour bien des applications, et donc tous les √òl√òments
de S sont consid√òr√òs comme des motifs vrais -fr√òquents du stream. On pourrait aussi choisir
0 = 1 pour ≈ítre s√ür de maximiser P cette fois, mais il en d√òcoule que R = 0 et il se pourrait
qu‚Äôaucun √òl√òment de S ne soit un motif vrai -fr√òquent.
Ces exemples avec les valeurs aux limites de 0 nous permettent de bien cadrer les principes
de notre approche. L‚Äôid√òe g√òn√òrale est de choisir subtilement 0 diff√òrent mais sufsamment
- 618 -RNTI-E-6
JE. Symphor et PA. Laur
proche de , respectivement plus grand ou plus petit que , de sorte qu‚Äôil soit possible de
contr√¥ler en maximisant soit la pr√òcision soit le rappel, pour garantir avec une tr≈Ås forte pro-
babilit√ò que P = 1 ou respectivement que R = 1 tout en limitant la d√ògradation du param≈Åtre
non contr√¥l√ò. On obtient ainsi un ensemble S
0
pas trop petit contenant des informations signi-
catives. Il y a une barri≈Åre statistique autour de  qui emp≈íche que 0 ne soit ni trop proche
ni trop √òloign√ò de  pour conserver la contrainte que P = 1 ou alors que R = 1, avec une forte
probabilit√ò. Notre objectif pour maximiser la pr√òcision ou le rappel avec une forte probabilit√ò
est par cons√òquent de rechercher les valeurs de 0 les plus proches possibles de cette barri≈Åre.
Le th√òor≈Åme ci-dessous permet d‚Äô√òtablir les valeurs des supports statistiques que nous pro-
posons en calculant la valeur de " :
Th√©or√®me 1 8X; 8D; 8m > 0; 80    1; 80 <   1, on choisit " tel que :
" 
r
1
2m
ln
jSj

:
Si on xe 0 = + ", alors P = 1 avec une probabilit√ò au moins de 1  . Si on xe 0 =   ",
alors R = 1 avec une probabilit√ò au moins de 1   .  est le risque statistique li√ò aux data
streams. Les valeurs  + ",    " sont les supports statistiques au sens de la d√ònition 1.
Les supports obtenus (0 =  ") sont statistiquement presque optimaux. Faute de place, nous
renvoyons √† l‚Äôarticle (Nock et al., 2005) 1 pour la d√òmonstration compl≈Åte. Celle-ci repose
sur l‚Äôutilisation d‚Äôin√ògalit√òs de concentration de variables al√òatoires, qui, dans ce cas pr√ò√ßis,
permettent d‚Äôobtenir des r√òsultats statistiquement presque optimaux. Par optimalit√ò, nous en-
tendons que toute technique d‚Äôestimation obtenant de meilleures bornes est condamn√òe √† se
tromper (le crit≈Åre √† maximiser n‚Äôest plus ≈Ågal √† un) quelque soit son temps de calcul.
3 Bordures statistiques pour la mise √† jour incr√òmentale
Dans cette section nous introduisons deux bordures statistiques (sup√òrieure et inf√òrieure)
qui vont ≈ítre pertinentes dans le choix des motifs fr√òquents √† conserver lors de la mise √† jour
incr√òmentale. L‚Äôobjectif avec la bordure statistique inf√òrieure est de maximiser la pr√òcision
P, tandis qu‚Äôavec la bordure statistique sup√òrieure il s‚Äôagit de maximiser le rappel R. Nous
adoptons la notation probabiliste d√ònie par (McAllester, 1999).2
A partir du th√òor≈Åme 1, nous d√ònissons l‚Äôensemble suivant : pour un risque statistique 
x√ò par l‚Äôutilisteur, en choisissant 0 = + ", on construit l‚Äôensemble S
+" tel que 8 ; S+" 
X

avec 8 ;P = 1. Ainsi, il n‚Äôy a plus la premi≈Åre source d‚Äôerreurs avec une forte probabilit√ò.
Tous les motifs de S
+" sont des motifs, vrais -fr√òquents deX , mais on ne les a pas tous (voir
gure 3). S
+"
est le plus grand ensemble possible qui contient uniquement des motifs vrais
-fr√òquents de X

apr≈Ås un temps d‚Äôobservation du stream. Nous d√ònissons cet ensemble
comme √òtant la bordure statistique inf√òrieure de X

√† partir de l‚Äô√òchantillon des motifs S de
X . De fa√ßon sym√òtrique, √† partir du th√òor≈Åme 1, nous d√ònissons l‚Äôensemble suivant : pour un
1www.pa-laur.com/LNSP_CIKM05.pdf
2Cette notation concise, s'√©crivant 8P , pr√©cise que : le pr√©dicat P est vrai √† une fraction pr√®s  pour l'ensemble
S obtenu √† partir de la distribution D. De fa√ßon √©quivalente, cela signie que le pr√©dicat P est vrai avec une probabilit√©
 1   pour l'ensemble S obtenu √† partir de la distribution D.
- 619 - RNTI-E-6
Bordures statistiques pour la fouille incr√òmentale dans les data streams
FN
S
S
+"
VP VN
X

FIG. 3 ¬ñ Bordure statistique inf√òrieure.
S
FP
S
 "
VP
VN
X

FIG. 4 ¬ñ Bordure statistique sup√òrieure.
risque statistique  x√ò par l‚Äôutilisteur, en choisissant 0 =   ", on construit l‚Äôensemble S
 "
tel que 8 ; X

 S
 "
avec 8 ;R = 1. Ainsi, il n‚Äôy a plus la deuxi≈Åme source d‚Äôerreurs avec
une forte probabilit√ò, c‚Äôest √† dire que S
 "
contient tous les motifs, vrais -fr√òquents de X

,
mais il en contient d‚Äôautres (gure 4). S
 "
est le plus petit ensemble possible qui contient tous
les motifs vrais -fr√òquents de X

apr≈Ås un temps d‚Äôobservation du stream. Nous d√ònissons
cet ensemble comme √òtant la bordure statistique sup√òrieure deX

√† partir de l‚Äô√òchantillon des
motifs S du streamX .
Stream
(a) (b)
(c)
         Motifs
DB db
P , R, F
S
+"
S
 "
DB [ db
S
X
0


S
0
=
FIG. 5 ¬ñ Bordures statistiques pour la mise √† jour incr√òmentale.
La gure 5 illustre l‚Äôutilisation de bordures dans un processus de mise √† jour incr√òmentale.
Nous recherchons les motifs -fr√òquents √† partir des bordures statistiques (not√òes (a) et (b) sur
la gure 5). Ces bordures sont construites pour le support  choisi √† partir de la valeur de ",
calcul√òe pour S (DB). Ces bordures, nous permettent d‚Äôapprocher au mieux l‚Äôensemble de
tous les motifs vrais -fr√òquents pour S 0 , qui repr√òsente la base DB mise √† jour par l‚Äôajout
de db, S0 = S [ db. Dans la section suivante lors de nos exp√òrimentations, nous comparerons
les motifs -fr√òquents obtenus gr√¢ce aux bordures statistiques par rapport √† l‚Äôensemble X 0

( (c) sur la gure 5). Cet ensemble repr√òsente les vrais motifs -fr√òquents apr≈Ås mise √† jour
incr√òmentale (DB [ db).
4 Exp√òrimentation
Comme nous l‚Äôavons pr√òcis√ò dans la section pr√òc√òdente notre objectif lors des exp√òrimen-
tations ne consiste pas √† √òvaluer les temps de r√òponse associ√òs √† nos bordures mais plut√¥t
- 620 -RNTI-E-6
JE. Symphor et PA. Laur
Database  tailleDB taille db
Dragons [0.07, 0.2] / 0.03 [0.2,0.6] / 0.1 [0.1, 0.5] /0.1
BuAG [0.08, 0.2] / 0.03 [0.2,0.6] / 0.1 [0.1, 0.5] /0.1
FIG. 6 ¬ñ Valeurs des param≈Åtres de la forme [a; b]=c, o√∏ a est la valeur de d√òpart, c est
l‚Äôincr√òment, et b est la valeur nale.
d‚Äô√òvaluer leur qualit√ò. Pour cela, nous utilisons les mesures de pr√òcision P et de rappel R d√ò-
nies pr√òc√òdemment dans les √òquations (1) et (2). Du fait de l‚Äôind√òpendance de notre m√òthode
vis √† vis des motifs recherch√òs, nous avons utilis√ò un algorithme traditionnel de recherche de
motifs s√òquentiels fr√òquents SPADE (Zaki, 2001).
Lors de cette √òvaluation, nous avons utilis√ò deux jeux de donn√òes issus de serveurs Web.
Le premier appel√ò ¬ìDragons¬î, est obtenu sur le site internet3. Ces donn√òes repr√òsentent la
navigation d‚Äôutilisateurs sur ce site. La taille du chier de log repr√òsente environ 2,54Go (132k
transactions). La deuxi≈Åme base de donn√òes, appel√òe ¬ìBuAG¬î, est obtenue √† partir des 3,48Go
(54k transactions) de Web log du serveur web de la biblioth≈Åque de l‚ÄôUniversit√ò4.
Pour analyser la qualit√ò de nos bordures stastiques, nous √òvaluons diff√òrentes situations en
faisant varier un ensemble de param≈Åtres (une exception est faite pour , qui est x√ò √† .05).
Les variations de ces param≈Åtres sont d√òcrites dans la gure 6. Le premier param≈Åtre d√ònit
les diff√òrentes valeurs de support sur lesquelles nous allons r√òaliser l‚Äôexp√òrimentation (¬ì¬î ).
Le second param≈Åtre, d√ònit la taille de DB par rapport √† la taille du stream simul√ò (¬ìtaille
DB¬î). Le dernier param≈Åtre, quant √† lui, d√ònit la taille de db par rapport √† celle deDB. Dans
notre cas db repr√òsentera au plus 50% de DB (¬ìtaille db¬î), ce param≈Åtre permet de contr√¥ler
la taille de l‚Äôincr√òment par rapport √† la partie stock√òe initialement. Pour g√òrer et organiser ces
exp√òriences un g√òn√òrateur est charg√ò de coordonner tous les tests √† effectuer.
Au lieu d‚Äôutiliser un vrai data stream, qui aurait pu limiter la qualit√ò de l‚Äô√òvaluation de
nos bordures statistiques, nous avons choisi d‚Äôen simuler un √† l‚Äôaide de la connaissance de
son domaine X . Plus pr√òcis√òment, pour simuler le stream nous √òchantillonnons chaque base
de donn√òes en fragments DB (S). Par exemple, nous pouvons consid√òrer que les donn√òes ar-
rivent successivement depuis la base de donn√òes ¬ìDragons¬î et que nous ne pouvons en stocker
que 20%. Pour cela nous prenons 20% des transactions contenues dans cette base de don-
n√òes et nous les conservons dans DB. Il ne reste alors plus qu‚Äô√† prendre un incr√òment, db par
exemple de taille 10%, de cette base. Nous construisons alors les bordures statistiques (bordure
inf√òrieure et bordure sup√òrieure) d√ònies dans la section 3 pourDB.
Les gures 7 et 8 montrent les r√òsultats d‚Äôexp√òriences obtenues, avec  = 0:05, respective-
ment sur les bases Dragons et BuAG. Pour √òvaluer la qualit√ò de ces bordures pour la mise √† jour,
nous repr√òsentons leurs comportements pour P et R par rapport √† S 0 (S0 = DB [ db). Ainsi,
les courbes P+" et P ", repr√òsentent la pr√òcision respectivement pour la bordure statistique
inf√òrieure et pour la bordure statistique sup√òrieure. De m≈íme les courbes R" repr√òsentent le
rappel. Les courbes P et R correspondent au choix trivial 0 = . Nous constatons que ces
courbes ont un comportement assez similaire :
¬ñ la pr√òcision P vaut ou approche 1 pour la plupart des bases stock√òes quand 0 =  + ",
3www.elevezundragon.com.
4www.univ-ag.fr/buag/.
- 621 - RNTI-E-6
Bordures statistiques pour la fouille incr√òmentale dans les data streams
Dragons,  = 0:07, S = 60%
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 65  70  75  80  85  90
P
Taille S'(%)
(PŒ∏, PŒ∏+Œµ, PŒ∏-Œµ) = f(taille S')
PŒ∏+Œµ
PŒ∏-Œµ
PŒ∏
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 65  70  75  80  85  90
R
Taille S' (%)
(RŒ∏, RŒ∏+Œµ, RŒ∏-Œµ) = f(taille S')
RŒ∏+Œµ
RŒ∏-Œµ
RŒ∏
Dragons,  = 0:19, S = 20%
 0.65
 0.7
 0.75
 0.8
 0.85
 0.9
 0.95
 1
 32  34  36  38  40  42  44  46
P
Taille S'(%)
(PŒ∏, PŒ∏+Œµ, PŒ∏-Œµ) = f(taille S')
PŒ∏+Œµ
PŒ∏-Œµ
PŒ∏  0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 21  22  23  24  25  26  27  28  29  30
R
Taille S' (%)
(RŒ∏, RŒ∏+Œµ, RŒ∏-Œµ) = f(taille S')
RŒ∏+Œµ
RŒ∏-Œµ
RŒ∏
FIG. 7 ¬ñ repr√òsente les courbes P (√† gauche) et R (√† droite) sur la base Dragons pour trois
valeurs de 0 :    ";  et  + ", deux valeurs de  et deux tailles de S (% par rapport √† |X|).
¬ñ le rappel R vaut ou approche 1 pour la plupart des bases stock√òes quand 0 =    ".
Ces observations sont en accords avec les r√òsultats th√òoriques de la section 2. Nous obser-
vons √ògalement un autre ph√ònom≈Åne : le rappel R associ√ò √† 0 =  + " n‚Äôest pas tr≈Ås √òloign√ò
de celui associ√ò √† 0 = . Il en est de m≈íme pour la pr√òcision P associ√òe √† 0 =    ". Ce qui
montre que la maximisation de la pr√òcision P ou du rappel R est obtenue avec un co√üt r√òduit au
niveau de la d√ògradation de l‚Äôautre param≈Åtre. Nous notons aussi que les courbes de pr√òcision
P ont de meilleures performances que celles du rappel R notamment sur la gure 8. Ceci n‚Äôest
pas tr≈Ås surprenant (c:f: section 2), car la fourchette de valeur pour la pr√òcision P est beaucoup
plus restreinte que pour le rappel R.
La variation de la taille de S (DB) poss≈Åde √ògalement une importance et vient conforter
un r√òsultat th√òorique auquel on pouvait s‚Äôattendre. En effet si on s‚Äôint√òresse au rappel R, on
constate, que ce soit sur les gures 7 ou 8, que les valeurs observ√òes pour cette quantit√òe aug-
mentent avec la taille de S. Cela traduit le fait que plus nous poss√òdons de donn√òes observ√òes
plus la qualit√ò de la pr√òdiction augmente.
Sur ces bases de donn√òes un autre ph√ònom≈Åne semble appara√Ætre. Premi≈Årement, √† cause
des faibles valeurs de , certains tests n‚Äôont pas pu ≈ítre r√òalis√òs car la valeur de    " √òtait
inf√òrieure √† 0. De plus, les diff√òrences observ√òes entre les courbes semblent ≈ítre li√òes aux
tailles des bases de donn√òes utilis√òes. La base de donn√òes BuAG est plus petite que celle de
Dragons d‚Äôun facteur 2.4. Nous pensons que ceci explique la diff√òrence entre les courbes : il
s‚Äôagit de ph√ònom≈Ånes li√òs √† des bases de donn√òes de petites tailles et qui ne devraient pas ≈ítre
pr√òsents dans des bases de donn√òes plus cons√òquentes ou dans de vrais data streams.
Sur ces courbes (gures 7 et 8), le choix de 0 =  donne de meilleurs r√òsultats en ce qui
concerne la moyenne de P et R que le choix des deux valeurs de 0, sachant que ni P, ni R
ne sont tr≈Ås proches de 1 avec une forte probabilit√ò dans ce cas. Avec notre approche, on peut
efcacement optimiser le processus de mise √† jour incr√òmentale. Dans le cas o√∏ on aurait un
- 622 -RNTI-E-6
JE. Symphor et PA. Laur
BuAG,  = 0:08, S = 20%
 0.55
 0.6
 0.65
 0.7
 0.75
 0.8
 0.85
 0.9
 0.95
 1
 22  23  24  25  26  27  28  29  30  31
P
Taille S'(%)
(PŒ∏, PŒ∏+Œµ, PŒ∏-Œµ) = f(taille S')
PŒ∏+Œµ
PŒ∏-Œµ
PŒ∏
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 22  23  24  25  26  27  28  29  30  31
R
Taille S' (%)
(RŒ∏, RŒ∏+Œµ, RŒ∏-Œµ) = f(taille S')
RŒ∏+Œµ
RŒ∏-Œµ
RŒ∏
BuAG,  = 0:08, S = 40%
 0.6
 0.65
 0.7
 0.75
 0.8
 0.85
 0.9
 0.95
 1
 44  46  48  50  52  54  56  58  60  62
P
Taille S'(%)
(PŒ∏, PŒ∏+Œµ, PŒ∏-Œµ) = f(taille S')
PŒ∏+Œµ
PŒ∏-Œµ
PŒ∏  0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 44  46  48  50  52  54  56  58  60  62
R
Taille S' (%)
(RŒ∏, RŒ∏+Œµ, RŒ∏-Œµ) = f(taille S')
RŒ∏+Œµ
RŒ∏-Œµ
RŒ∏
FIG. 8 ¬ñ repr√òsente les courbes P (√† gauche) et R (√† droite) sur la base BuAG pour trois
valeurs de 0 :    ";  et  + ", deux valeurs de  et deux tailles de S (% par rapport √† |X|).
espace sufsant de stockage, on choisirait 0 =    ", la bordure sup√òrieure, pour laquelle on
poss≈Åde des garanties importantes sur la pr√òsence des futurs fr√òquents en son sein (R = 1).
Dans ce cas, le nombre de calculs suppl√òmentaires sera faible lors de la mise √† jour. Par contre
dans le cas o√∏ on devrait se limiter pour des raisons de taille √† conserver une bordure disons
moins volumineuse, 0 =  + ", la bordure inf√òrieure, sera alors utilis√òe car elle contient les
informations les plus pertinentes (P = 1). On peut ainsi voir les bordures statistiques comme
des outils de mise √† jour incr√òmentale indiquant les limites au del√† desquelles : soit il est inutile
de stocker plus d‚Äôinformations dans le cas de 0 =   " (valeur limite inf√òrieure pour 0) ; soit
la perte d‚Äôinformation serait trop importante 0 =  + " (valeur limite sup√òrieure pour 0 ).
5 Travaux connexes
Depuis 1996, de nombreux travaux de recherche se sont focalis√òs sur la maintenance des
ensembles de motifs fr√òquents obtenus dans les bases de donn√òes statiques. Dans ce para-
graphe nous regardons leur ad√òquation par rapport √† notre probl√òmatique. Partition et FUP
(Fast UPdate) (Cheung et al., 1996) sont deux algorithmes o√∏ un partitionnement de la base
de donn√òes est effectu√ò pour rechercher dans un premier temps les itemsets fr√òquents locaux
relatifs √† chaque partition puis dans un second temps en d√òduire les itemsets fr√òquents glo-
baux par validation crois√òe. Cela repose sur l‚Äôhypoth≈Åse que les itemsets fr√òquents de la base
doivent l‚Äô≈ítre dans au moins l‚Äôune des partitions. (Parthasarathy et al., 1999) ont d√òvelopp√ò un
algorithme de mise √† jour incr√òmentale ISM (Incremental Sequence Mining) en maintenant un
treillis, de motifs de la base, construit √† partir de tous les motifs fr√òquents et de tous les motifs
de la bordure n√ògative. (Zheng et al., 2002) ont d√òvelopp√ò un algorithme IUS( Incrementally
Updating Sequence) en utilisant une valeur support pour limiter la taille de l‚Äôespace des candi-
- 623 - RNTI-E-6
Bordures statistiques pour la fouille incr√òmentale dans les data streams
dats de la bordure n√ògative. Ces diff√òrentes approches se heurtent aux inconv√ònients inh√òrents
√† l‚Äôutilisation de la bordure n√ògative :
¬ñ l‚Äôespace des motifs candidats √† maintenir est tr≈Ås important ;
¬ñ il est n√òcessaire de consid√òrer les relations structurelles qui existent entre les motifs
notamment dans le cas des motifs qui auraient une faible valeur de support.
Les diff√òrents algorithmes utilisant la bordure n√ògative sont tr≈Ås co√üteux en temps et sont
consommateurs d‚Äôespace m√òmoire.
(Masseglia et al., 2003) ont d√òvelopp√ò un algorithme de mise √† jour incr√òmentale ISE
utilisant une approche par g√òn√òration et test de candidats. Les inconv√ònients sont que :
¬ñ l‚Äôespace des candidats peut ≈ítre tr≈Ås grand, ce qui rend la phase de test tr≈Ås lente ;
¬ñ l‚Äôalgorithme requiert plusieurs passages sur toute la base. Cela est tr≈Ås co√üteux en temps
particuli≈Årement pour les motifs s√òquentiels √† s√òquences longues.
‚àí‚àí‚àí‚àí‚àí‚àí‚àí ‚àí‚àí ‚àí‚àí ‚àí ‚àí‚àí ‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí
‚àí
+ ++ + ++ ++ + + ++++ + +
+
+ + +
+ +
+
++
+
+
+
+
++ + + + + + + + +
+ + ++
+ + + + +
+
+
+++++
+++
+
+
Bordure statistique
Bordure statistique
SFS
Vrais frequents
inferieure
Frequents observes
superieure
FIG. 9 ¬ñ Comparaison.
L‚Äôalgorithme IncSpan (IncrementalMining of Sequential Patterns in large database) d√òvelopp√ò
par (Cheng et al., 2004) repose sur une approche statistique o√∏ l‚Äôon construit un ensemble de
motifs semi-fr√òquents (SFS) en diminuant la valeur du support √† partir d‚Äôun ratio. L‚Äôid√òe est
de dire qu‚Äô√† partir d‚Äôun ensemble de motifs "presque fr√òquents" (SFS), plusieurs des motifs
fr√òquents de la base mise √† jour proviendraient de SFS ou alors seraient d√òj√† observ√òs fr√ò-
quents dans la base connue pr√òc√òdant la mise √† jour. Autrement dit, SFS constituerait une
zone fronti≈Åre entre les motifs fr√òquents et non fr√òquents. Sur la gure 9, nous repr√òsentons
un exemple d‚Äôensemble SFS. Cette approche pr√òsente des insufsances majeures d‚Äôun point
de vue statistique tant pour l‚Äôestimation de l‚Äôincertitude intrins≈Åque li√òe aux data streams que
pour la construction de l‚Äôensemble des motifs candidats permettant la mise √† jour incr√òmen-
tale. En effet, pour diminuer la valeur du support, le choix du ratio est simplement heuristique
sans justication th√òorique. Ainsi, cette approche n‚Äôoffre aucune certitude ni indication sur
l‚Äôerreur commise lors de la construction de l‚Äôensemble des motifs semi-fr√òquents quant aux
motifs vrais -fr√òquents du stream (zone identi√òe avec les symboles - sur la gure 9). De
plus, nous n‚Äôavons aucune garantie sur la minimalit√ò de cet ensemble (zone identi√òe avec les
symboles + sur la gure 9), ce qui est fortement p√ònalisant pour sa r√òutilisation dans l‚Äôobjectif
d‚Äôoptimisation de la m√òthode de mise √† jour incr√òmentale.
6 Conclusion
Dans cet article, nous abordons la probl√òmatique de la mise √† jour incr√òmentale pour les
motifs fr√òquents dans le cas des grandes bases de donn√òes. Dans le contexte des data streams,
- 624 -RNTI-E-6
JE. Symphor et PA. Laur
il est plus pertinent, de construire et de maintenir des ensembles de motifs vrais -fr√òquents et
non simplement observ√òs comme tels. Plusieurs travaux, (Kearns et Mansour, 1998; Nock et
Nielsen, 2004; Vapnik, 1998), ont montr√ò l‚Äôint√òr≈ít de l‚Äôapproche statistique notamment dans
la d√òtermination de r≈Ågles de pr√òvision pour l‚Äôoptimisation d‚Äôalgorithmes. Notre contribution
majeure porte pr√òcis√òment sur ce point par l‚Äôintroduction de supports statistiques en compl√ò-
ment des supports classiques permettant d‚Äôobtenir des bordures statistiques qui constituent les
ensembles statistiquement presque optimaux (√† une constante pr≈Ås) √† consid√òrer dans le cadre
de la mise √† jour incr√òmentale. Les exp√òrimentations pr√òsent√òes montrent la robustesse de
l‚Äôapproche, dans le cas des motifs s√òquentiels, au regard de la taille des bases stock√òes et des
diff√òrentes valeurs supports test√òes. Ces r√òsultats encourageants sont des points positifs quant √†
l‚Äôapplicabilit√ò et le passage √† l‚Äô√òchelle de la m√òthode. Plusieurs extensions de ces travaux sont
possibles dans bien des domaines de recherche en fouille de donn√òes. On citera notamment les
travaux qui portent sur les structures de donn√òes o√∏ l‚Äôon cherche √† maintenir des ensembles
d‚Äôitems qui sont observ√òs fr√òquents avec un rappel maximum, (Jin et al., 2003). Nos pr√òoc-
cupations actuelles concernent la question suivante : est-il possible de construire un ensemble
interm√òdiaire qui conserverait au mieux les propri√òt√òs de chacune de ces bordures ? Celui-ci
repr√òsenterait un compromis entre une bordure statistique trop imposante √† stocker et une autre
pour laquelle le nombre d‚Äôacc≈Ås √† la base de donn√òes est trop important.
R√òf√òrences
Agrawal, R., T. Imielinski, et A.-N. Swami (1993). Mining association rules between sets of
items in large databases. In Proc. of the ACM SIGMOD ICMD‚Äô93, pp. 207¬ñ216.
Ayres, J., J. Flannick, J. Gehrke, et T. Yiu (2002). Sequential pattern mining using bitmap
representation. In Proc. of KDD‚Äô02.
Cheng, X., X. Yan, et J. Han (2004). Incspan : Incremental mining of sequential patterns in
large database. In Proc. of KDD‚Äô04.
Cheung, D., J. Han, V. Ng, et C. Wong (1996). Maintenance of discovered association rules in
large databases : an incremental updating technique. In Proc. of ICDE‚Äô96, pp. 106¬ñ114.
Demaine, E., A. Lopez-Ortizand, et J.-I. Munro (2002). Frequency estimation of internet pa-
cket streams with limited space. In Proc. of the 10th European Symposium on Algorithms.
Devroye, L., L. Gy√∂r, et G. Lugosi (1996). A Probabilistic Theory of Pattern Recognition.
Fan, W., Y.-A. Huang, H. Wang, et P.-S. Yu (2004). Active mining of data streams. In Proc. of
the 4th SIAM International Conference on Data Mining, pp. 457¬ñ461.
Golab, L. et M. T. Ozsu (2003). Issues in data stream management. ACM SIGMOD Records 2.
Han, J., J. Pei, B. Mortazavi-asl, Q. Chen, U. Dayal, et M. Hsu (2000). Freespan : Frequent
pattern-projected sequential pattern mining. In Proc. of KDD‚Äô00.
Jin, C., W. Qian, C. Sha, J.-X. Yu, et A. Zhou (2003). Dynamically maintaining frequent items
over a data stream. In Proc. of CIKM‚Äô03, pp. 287¬ñ294. ACM Press.
Karp, R.-M., S. Shenker, et C.-H. Papadimitriou (2003). A simple algorithm for nding ele-
ments in streams and bags. ACM Trans. on Database Systems 28, 51¬ñ55.
- 625 - RNTI-E-6
Bordures statistiques pour la fouille incr√òmentale dans les data streams
Kearns, M. J. et Y. Mansour (1998). A Fast, Bottom-up Decision Tree Pruning algorithm with
Near-Optimal generalization. In Proc. of ICML‚Äô98, pp. 269¬ñ277.
Li, H.-F., S.-Y. Lee, et M.-K. Shan (2004). An efcient algorithm for mining frequent itemsets
over the entire history of data streams. In Proc. of the 1st Int. Workshop on Knowledge
Discovery in Data Streams.
Manku, G. et R. Motwani (2002). Approximate frequency counts over data streams. In Proc.
of the 28 th International Conference on Very Large Databases, pp. 346¬ñ357.
Mannila, H. et H. Toivonen (1997). Levelwise search and borders of theories in knowlede
discovery. Data Mining and Knowledge Discovery 1, 241¬ñ258.
Masseglia, F., P. Poncelet, et M. Teisseire (2003). Incremental mining of sequential patterns in
large databases. Data and Knowledge Engineering 46.
McAllester, D. (1999). Some PAC-Bayesian theorems. Machine Learning 37, 355¬ñ363.
Nock, R., P. Laur, P. Poncelet, et J. Symphor (2005). On the estimation of frequent itemsets
for data streams : Theory and experiments. In Proc. of CIKM‚Äô05.
Nock, R. et F. Nielsen (2004). Statistical Region Merging. IEEE Trans. on Pattern Analysis
and Machine Intelligence 26, 1452¬ñ1458.
Parthasarathy, S., M. Zaki, M. Orihara, et S. Dwarkadas (1999). Incremental and interactive
sequence mining. In Proc. of CIKM‚Äô99.
Pei, J., J. Han, B. Mortazavi-asl, H. Pinto, Q. Chen, et U. Dayal (2001). Prexspan : Mining
sequential patterns efciently by prex-projected pattern growth. In Proc. of ICDE‚Äô01.
Srikant, R. A. R. (1995). Mining sequential patterns. In Proc. of ICDE‚Äô95 Conference.
Vapnik, V. (1998). Statistical Learning Theory. John Wiley.
Wang, H., W. Fan, P.-S. Yu, et J. Han (2003). Mining concept-drifting data streams with
ensemble classiers. In Proc. of KDD‚Äô03, pp. 226¬ñ235.
Zaki, M. (2001). SPADE : An efcient algorithm for mining frequent sequences. Machine
Learning Journal 42.
Zheng, Q., K. Xu, S. Ma, et W. lv (2002). The algorithms of updating sequential patterns. In
Proc. of ICDM‚Äô02.
Summary
Recently the knowledge extraction community takes a closer look to new models where
data arrive in timely manner like a fast and continous ow, i:e: data streams. One of the most
important singularity inside streams relies on that only a part of it is available. After some
following updates, it‚Äôs necessary, to cope with uncertainty as only a part of it is available. In
this paper, we introduce a new statiscal approach which biases the initial support for sequential
patterns mining. This approach holds the advantage to maximize one of the parameters (pre-
cision or recall) chosen by the user while limiting the degradation of the other criterion. Thus,
we dene the statistical borders which are the relevant sets of frequent patterns in incremental
mining of streams. Experiments performed on sequential patterns demonstrate the interest of
this approach and the potential of such techniques.
- 626 -RNTI-E-6
