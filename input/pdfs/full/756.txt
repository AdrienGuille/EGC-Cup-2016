Essai de Typologie Structurelle des Indices de SimilaritÃ© Vec-
toriels par Unification Relationnelle 
 
 FranÃ§ois Marcotorchino  
 
Thales Communications : 160, boulevard de Valmy â€“ BP 82 
92704 Colombes Cedex et Laboratoire de Statistique ThÃ©orique et AppliquÃ©e (Paris VI) 
jeanfrancois.marcotorchino@fr.thalesgroup.com 
 
RÃ©sumÃ© : Cet article a  pour but de proposer un regard nouveau et unificateur 
Ã  la problÃ©matique des Indices de SimilaritÃ© et des CritÃ¨res de structuration ou 
de partitionnement. Une catÃ©gorisation des indices, des propriÃ©tÃ©s non con-
nues   ainsi quâ€™une prÃ©sentation dans diffÃ©rents axes de structuration seront 
suggÃ©rÃ©es.  La recherche des significations et des filiations associÃ©es sera 
donnÃ©e comme rÃ©sultat dÃ©rivÃ© de ce travail. 
 
 
1 Introduction 
La recherche sur les indices de similaritÃ© a, depuis longtemps, donnÃ© lieu Ã  une abon-
dante littÃ©rature, les rÃ©fÃ©rences aux indices ayant Ã©tÃ© faites souvent, mÃªme dans les meil-
leurs articles, sous forme de listes   (type inventaire) sans quâ€™une rÃ©elle structuration nâ€™ait 
Ã©tÃ© proposÃ©e. Nombre de ces  indices  ont Ã©tÃ© introduits  et donnÃ©s dans diffÃ©rents articles 
et dans diffÃ©rents domaines  fondamentaux ou dâ€™application, au fur et Ã  mesure de leur 
utilisation potentielle. Ainsi nâ€™est-il pas Ã©tonnant de trouver ces indices proposÃ©s et intro-
duits dans des domaines  aussi variÃ©s que:  les Sciences Humaines et plus particuliÃ¨rement 
la Sociologie et lâ€™Ethnologie et ses dÃ©rivÃ©es : Ethnopsychologie, EthnogÃ©nÃ©tique,  etc.., la 
Linguistique proprement dite, dont: Lexicologie, LexicomÃ©trie, Ethnolinguistique,  Text 
Mining,  les MathÃ©matiques: Analyse des donnÃ©es, Classification et Â« Clustering Â», les 
Sciences du vivants : la Biologie, la BiomÃ©trie, la  Physiologie, la   PhylogÃ©nie, la  Zoolo-
gie, la MÃ©decine, les Sciences organiques : la  Chimie molÃ©culaire,    la Biochimie et enfin 
de nombreux domaines plus Â« business Â», comme : le Â« Customer Relationship Manage-
ment Â», le Â« Business Intelligence Â», la Â« GÃ©o-cartographie Â»,  le Â«Profiling Â» etc..  
    Presque tous les indices courants  ont Ã©tÃ© introduits Ã  des pÃ©riodes et Ã  des dates diffÃ©-
rentes, pour des buts  et motifs variÃ©s sans structuration et explication claire du rÃ´le de 
chacun  et sans aucun regard sur une filiation ou une hÃ©rÃ©ditÃ© sous jacentes permettant de 
mieux les comprendre ou de les interprÃ©ter (ceci Ã©tant sans doute dÃ» Ã  la provenance trÃ¨s 
diffÃ©renciÃ©e des inventeurs). Ce phÃ©nomÃ¨ne sâ€™est traduit,  de fait,  soit par une impression 
de fouillis, soit, et on le verra plus loin dans ce document, par des successions de redÃ©cou-
vertes  (parfois trÃ¨s rÃ©centes) dâ€™indices existants  depuis fort longtemps, ou de mises en 
Ã©vidence de propriÃ©tÃ©s connues depuis trÃ¨s longtemps  par des chercheurs de disciplines 
diffÃ©rentes.  
Preuve que le sujet est toujours dâ€™actualitÃ©,  un article vraiment trÃ¨s rÃ©cent de  Matthijs J. 
Warrens (2009) vient de paraÃ®tre dans  la Revue Journal of Classification, au moment 
RNTI-A-3- 203 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
mÃªme oÃ¹ nous envoyons le notre pour publication. Il aborde   quelques uns des points 
exposÃ©s dans cet article, en particulier lâ€™ordonnancement de certains des indices prÃ©sentÃ©s 
dans notre document, en cherchant une unification des bornes par moyennage (Harmo-
nique, GÃ©omÃ©trique et ArithmÃ©tique), sans exploiter pourtant  dâ€™autres considÃ©rations 
comme les structures homographiques associÃ©es.    
   MÃªme des articles synthÃ©tiques et plus thÃ©oriques, extraits dâ€™ouvrages plus mathÃ©ma-
tiques nâ€™ont pas couvert  complÃ¨tement cette problÃ©matique. Ainsi lâ€™article de F.B. Bau-
lieu (1989)  dans la Revue Â« Journal of Classification Â» (Springer Verlag), qui reprÃ©sente 
lâ€™un des meilleurs  survols du sujet, propose une liste trÃ¨s abondante dâ€™indices, sans 
quâ€™elle soit,  Ã  son tour, ni complÃ¨te ni exhaustive. Cette liste est dâ€™ailleurs prÃ©sentÃ©e, en 
vrac, sans organisation aucune (sans citer le nom des Â« inventeurs Â»), le but Ã©tant de noti-
fier un certain nombre de propriÃ©tÃ©s possÃ©dÃ©es  ou non par ces indices; aucune mention 
nâ€™est faite Ã  propos de leurs filiations, de leurs ressemblances ou de leur hÃ©rÃ©ditÃ©, en un 
mot de leur structuration ou unification rÃ©ciproque. Parmi les auteurs qui se sont,  en 
France,  intÃ©ressÃ©s le plus en profondeur Ã  ce domaine, qui semble simple (uniquement en 
apparence),  mais qui est en fait   difficile, on pourra consulter utilement les travaux de S. 
Joly  et  G.  Le CalvÃ© (1986) et (1994) ainsi que ceux de  B. Fichet (1994) dans le livre 
Ã©ditÃ© par  B. Van Cutsem (ouvrage dâ€™ensemble, excellent et de rÃ©fÃ©rence  publiÃ© chez 
Springer Verlag en (1994), ceux de IC Lerman (1970), (1981), (1987), de G. Bisson  
(2000) auxquels  on rajoutera,  toujours  dans le livre sus-citÃ© de  B. Van Cutsem (1994), 
les  contributions   additionnelles de B. Van Cutsem et F. Critchley .    
    Nous avions dÃ©jÃ  prÃ©sentÃ©, il y a quelque temps,  dans un article  la Revue de Statistique 
AppliquÃ©e titrÃ© Â« AgrÃ©gation des SimilaritÃ©s Â», F. Marcotorchino et P. Michaud (1981) , un 
essai de catÃ©gorisation des indices de similaritÃ© les plus courants. Bien que certains rÃ©sultats 
originaux aient Ã©tÃ© prÃ©sentÃ©s dans cet article, nous nâ€™avions pas vu  Ã  cette Ã©poque, tout 
lâ€™intÃ©rÃªt de cette restructuration et surtout, nous ne lâ€™avions pas appliquÃ©e Ã  un ensemble 
Ã©tendu dâ€™indices, nous nous Ã©tions contentÃ©s des plus connus et des plus reprÃ©sentatifs.  
   Câ€™est Ã  cette tÃ¢che que nous nous attelons dans cet article, et ce sont certaines des conclu-
sions associÃ©es qui peuvent soulever  un intÃ©rÃªt Ã  la fois dâ€™un point de vue thÃ©orique et 
pratique. Les diffÃ©rents axes de structuration des Indices de SimilaritÃ© que nous allons pro-
poser, donneront  une vue dâ€™ensemble et permettront dâ€™en dÃ©duire des propriÃ©tÃ©s, qui, bien 
que souvent naturelles,  ont Ã©tÃ© peu proposÃ©es sous cette forme dans la littÃ©rature.  Nous 
revendiquons le fait que nous ne sous sommes pas  intÃ©ressÃ© en profondeur ici aux  propriÃ©-
tÃ©s  trÃ¨s importantes de Â« mÃ©tricitÃ© Â» et de Â« semi-definie positivitÃ© Â» des matrices de simila-
ritÃ© associÃ©es, du fait quâ€™elles avaient  dÃ©jÃ  Ã©tÃ© amplement Ã©tudiÃ©es, en particulier on trou-
vera de larges dÃ©veloppements sur ce domaine dans lâ€™ouvrage prÃ©-citÃ© de B. Van Cutsem 
(1994), mais Ã©galement dans lâ€™article de J. Gower et P. Legendre (1986), oÃ¹ dans celui de 
G. Le CalvÃ© (1994) Ã©galement.   
Cela peut paraÃ®tre lÃ©gÃ¨rement  prÃ©somptueux de rÃ©diger un Â« niÃ¨me Â» article sur le sujet, Ã  
la date dâ€™aujourdâ€™hui, vu le nombre incroyable dâ€™articles ayant de prÃ¨s ou de loin traitÃ© de 
ce problÃ¨me, nous pensons, nÃ©anmoins, quâ€™un certain nombre des rÃ©sultats qui sont donnÃ©s 
dans cet article sont originaux ou du moins peu connus, mÃªme de spÃ©cialistes de lâ€™analyse 
des donnÃ©es. Câ€™est dâ€™ailleurs essentiellement la raison qui nous a fait reprendre un article 
dÃ©jÃ  publiÃ© en interne  Thales en 2002, en lui rajoutant un certain nombre de concepts et de 
rÃ©sultats et dont ce nouvel  article est une substantielle amÃ©lioration. Bien que nous abor-
dions en fin dâ€™article les  indices calculÃ©s sur Â« matrices dâ€™abondance Â», lâ€™essentiel de ce 
travail a trait aux indices de similaritÃ©s calculÃ©s sur variables ou entitÃ©s binaires. Compte 
RNTI-A-3 - 204 -
                                                                                                    F. Marcotorchino 
tenu de la difficultÃ© gÃ©nÃ©rale du sujet liÃ© Ã  la Â« similaritÃ© Â», il semble que des articles du 
mÃªme type que celui ci devraient Ãªtre consacrÃ©s Ã  lâ€™Ã©tude des indices de similaritÃ©s entre 
structures plus complexes  que les structures de listes ou vectorielles (similaritÃ©s entre 
graphes , similaritÃ©s profondes entre textes, similaritÃ©s topologiques entre objets ou entre 
structures diverses..etc..). MalgrÃ© le nombre trÃ¨s important dâ€™articles sur ces thÃ©matiques, il 
semble quâ€™une synthÃ¨se globale  reste nÃ©anmoins Ã  faire.  
 
1.1 ConsidÃ©rations Axiomatiques GÃ©nÃ©rales 
   Lâ€™axiomatique relative aux principes  structurants le domaine des  indices de similaritÃ©s 
est, somme toute, assez pauvre,  non seulement au niveau mathÃ©matique mais Ã©galement au 
niveau philosophique. Nous avions signalÃ© ce fait dans un article Ã©crit conjointement avec 
H. Benhadda, H. Benhadda et F. Marcotorchino  (1996), suivant  en cela les traces dâ€™une 
rÃ©flexion du philosophe D. Parrochia (1992) sur le sujet. De mÃªme on trouve chez les philo-
sophes logiciens  Willard van Orman  Quine, en particulier dans lâ€™un de ses derniers ar-
ticles, voir  W.V. O. Quine (1998) et Rudolf. Carnap (1928) , comme lâ€™avait  Ã©galement fait 
en son temps le philosophe Ã©pistÃ©mologiste  L. Brunchwicg (1921), quelques rÃ©flexions 
intÃ©ressantes sur la notion de Â« similaritÃ© Â» ainsi que sur les structures ontologiques et les 
principes descriptifs associÃ©s. Mais ceci aboutit a une axiomatique relativement faible dont 
nous donnons ci-dessous quelques principes de base et auxquels nous ferons parfois rÃ©fÃ©-
rence dans la suite. 
 
a) Axiome nÂ°1 : PositivitÃ© 
Un indice de similaritÃ© S,  est une fonction prenant ses valeurs dans I x I, oÃ¹ I est un En-
semble fini  dâ€™objets, Ã   valeur dans  â„œ+ (ensemble des rÃ©els positifs ou nuls), donc S est 
une fonction positive1, dâ€™oÃ¹ : 
                                                  IxI  )y,x(        0)y,x(S âˆˆâˆ€â‰¥   
x, peut reprÃ©senter un vecteur dans un espace Ã  plusieurs dimensions (disons Rm, ou appar-
tenir  Ã  R, tout simplement) . Sauf cas particulier, nous identifierons : 
{ } xÃ ....xx,x,xx m321= ,    et    { } yÃ ....yy,y,yy m321= ,    pour Ã©viter les 
notations vectorielles. 
 
b) Axiome nÂ°2 : SymÃ©trie 
Un indice de similaritÃ© S,  est une fonction prenant ses valeurs dans I x I Ã  valeur dans  â„œ+ 
(ensemble des rÃ©els positifs ou nuls) et telle que, pour  deux objets x et y appartenant Ã  un 
ensemble fini I ,  S doit vÃ©rifier lâ€™axiome ou le principe de symÃ©trie : 
                                                 IxI  )y,x(         )x,y(S)y,x(S âˆˆâˆ€=   
                                                 
1
 La positivitÃ© est un axiome non totalement obligatoire, car certains indices notÃ©s Â«  xy Â» (comme on le verra) 
varient de -1 Ã  +1 et ont des comportements de coefficients de corrÃ©lation. Ceci Ã©tant dit, il suffit  de remplacer  xy 
par S(x,y)=1/2(xy+1), pour se trouver titulaire dâ€™un indice Â« S Â», vÃ©rifiant alors tous les Â« bons Â» axiomes. De la 
mÃªme faÃ§on , on passe dâ€™un Â« indice de distance Â»  dxy   ou dâ€™une Â« distance vraie Â» Ã  un indice de similaritÃ© en  
posant 
xyd1
1)y,x(S
+
=
, ou  S(x,y)=1-d(x,y) , ou bien encore S(x,y)=1-Â½ dÂ²(x,y)  (on abordera ce point dans le 
texte )  
 
RNTI-A-3- 205 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
 
c) Axiome nÂ°3 : Auto-similaritÃ© maximale  (ou Axiome de Â« propretÃ© Â») 
Un indice de similaritÃ© S,  est  dit Â« propre Â», on dit aussi   quâ€™il vÃ©rifie  lâ€™axiome dâ€™  Â« au-
to-similaritÃ© maximale Â» si :  
 S  vÃ©rifie lâ€™inÃ©galitÃ© : 
                                          I  y    ,xy         )y,x(S)x,x(S âˆˆâ‰ âˆ€â‰¥  
Puisque on a de mÃªme :  
                                  I  y    ,xy         )y,x(S)y,y(S âˆˆâ‰ âˆ€â‰¥    
on en dÃ©duit que lâ€™axiome dâ€™auto-similaritÃ© maximale induit la propriÃ©tÃ© : 
 
                                          ( ) IxI  y,x        y)S(y,x),S(x, Min)y,x(S âˆˆâˆ€â‰¤  
 
 
d) Axiome nÂ°4 :  TransitivitÃ© GÃ©nÃ©ralisÃ©e Indicielle et dÃ©rivÃ©s 
Dans le cas oÃ¹ un indice de similaritÃ© vÃ©rifie       0 â‰¤ S(x,y) â‰¤ 1 
1. et que son auto-similaritÃ© maximale  implique  S(x,x)= 1  (lâ€™indice est alors dit :  
Â« normÃ© Â») 
(si ce nâ€™est pas  le cas il suffit simplement dâ€™effectuer la transformation sui-
vante :      
y)S(x,Max
y)S(x,y)(x,S'y)S(x,                  
yx,
=â†’
 
         pour se trouver titulaire dâ€™un indice variant de 0 Ã  1. On dit alors que lâ€™indice est 
Â« re-normÃ© Â» 
 
2. et quâ€™il vÃ©rifie  la propriÃ©tÃ© suivante dite de  Â« TransitivitÃ© GÃ©nÃ©ralisÃ©e Indi-
cielle Â» :   
 
(f 1)                           S(x,y) + S(y,z)- S(x,z)   1     âˆ€ (x,y,z) 
 
Alors, la quantitÃ© d(x,y)=1 â€“ S(x,y) vÃ©rifie lâ€™inÃ©galitÃ© triangulaire : 
En effet : 
               Lâ€™inÃ©galitÃ© prÃ©cÃ©dente sur  S(x,y) en posant  S(x,y) = 1 â€“ d(x,y), implique : 
        (1-d(x,y)) + (1-d(y,z)) - (1-d(x,z)) â‰¤ 1      d(x,z) â‰¤  d(x,y) + d(y,z)  (inÃ©galitÃ© triangulaire) 
 
De plus  du fait que  S(x,x)=1 on a : d(x,x)=0  (dans ce cas d(x,y) est une Â« semi-distance Â») 
Si en   plus on a : S(x,y)=1   x = y alors d(x,y)=0   x = y  et d(x,y) est une Â« distance Â»  vraie. 
 
Par ailleurs, J.C. Gower (1966) a gÃ©nÃ©ralisÃ© un rÃ©sultat de I. Schoenberg  datant de (1938) 
I. Schoenberg (1938) Ã  propos du fait que si la matrice {S(x,y)} est dÃ©finie non nÃ©gative  
(NND)  et que  S(x,x) =1, âˆ€ x ,   alors la quantitÃ© :                                        
 y)]S(x,-2[1y)d(x, =     
 reprÃ©sente une distance euclidienne.   
 
La Â« TransitivitÃ© GÃ©nÃ©ralisÃ©e Indicielle Â» (TGI) est,  pour un indice de similaritÃ©,  la 
propriÃ©tÃ© Â« duale Â» de lâ€™ Â« InÃ©galitÃ© Triangulaire Â» pour une distance ou une dissimilari-
tÃ©.   
RNTI-A-3 - 206 -
                                                                                                    F. Marcotorchino 
 
En particulier si  S(x,y) est un indice de similaritÃ© vÃ©rifiant les trois premiers axiomes et 
quâ€™il est construit Ã  partir dâ€™un indice de distance sous la forme : 
y)(x,d1y)S(x,ou  y)d(x,1y)S(x, 221âˆ’=âˆ’=   , on dira que lâ€™indice de similaritÃ© est Â« mÃ©-
trisable Â»  (premier cas) ou  Â«mÃ©trisable euclidien Â» (deuxiÃ¨me cas) . 
 
 
e) ThÃ©orÃ¨me nÂ°1 : (GÃ©nÃ©ralisation homographique de la TGI) 
 
Si  Sd(x,y) est un indice de similaritÃ© normÃ©,  câ€™est Ã  dire dont la valeur maximale est Ã©gale 
Ã  1 et vÃ©rifiant  la propriÃ©tÃ© dâ€™auto-similaritÃ© maximale , alors tout indice Su(x,y),  vÃ©rifiant 
lâ€™auto-similaritÃ© maximale  de la forme :  
 
                            â‡”
âˆ’
=
y))(x,S(
y)(x,Sy)(x,S
d
d
u
   
1y)(x,S
y)(x,S
y)(x,S
u
u
d
+
=
 
vÃ©rifiera la propriÃ©tÃ© de Â« TransitivitÃ© GÃ©nÃ©ralisÃ©e Indiciale Â» et sera donc mÃ©trisable si les 
coefficients  Î± et Î²  de la fonction homographique prÃ©cÃ©dente, liant lâ€™indice Sd(x,y) Ã  Su(x,y) 
vÃ©rifient eux â€“mÃªmes des propriÃ©tÃ©s particuliÃ¨res  que nous allons expliciter. 
 
Tout dâ€™abord la fonction homographique associÃ©e Su(x,y) doit vÃ©rifier : 
1:siobtenueseraimalemaxritÃ©autosimila'l1
-
1
x)(x,S
x)(x,S
x)(x,S
d
d
u +===
âˆ’
=
  
et elle doit  sâ€™annuler si Sd (x,y)=0  le numÃ©rateur du rapport est forcÃ©ment de la forme : 
Î±Su(x,y), car sinon on ne peut annuler la fonction homographique associÃ©e. 
Dâ€™autre part  si lâ€™indice Su(x,y) est mÃ©trisable, il doit pouvoir vÃ©rifier  une inÃ©galitÃ© de la 
forme  donnÃ©e ci dessous, (en effet il suffit de remplacer Sd(x,y) par sa valeur en fonction 
de Su(x,y) dans lâ€™inÃ©galitÃ© TGI, pour obtenir :  
[ ][ ][ ] zy,x,   z)(x,S z)(y,S1 y)(x,S1

1
 -  1z)(x,Sz)(y,Sy)(x,S uuuuuu âˆ€+âˆ’âˆ’â‰¤âˆ’+  
la quantitÃ© :    
[ ][ ][ ]
 1 Ã  infÃ©rieureet   positive Ãªtre devant   zy,x,   z)(x,S z)(y,S1 y)(x,S1

1
 uuu âˆ€+âˆ’âˆ’
 
ce qui est vrai car  (1-Su(x,y))â‰¤ 1 idem pour (1-Su(y,z))â‰¤ 1, ce qui implique donc que les 
coefficients : Î´, Î», Î¼  soient positifs.  
Ceci induit, aprÃ¨s calculs dâ€™identification des coefficients des formes monomiales asso-
ciÃ©es,  les relations suivantes entre les diffÃ©rents coefficients :  
(i) Î±=Î²+1 (dÃ©jÃ  vue) 
(ii) Î¼=Î±2 
(iii) Î´=Î²2                                            
(iv) Î»=Î±2-1 
On voit que ces diffÃ©rentes valeurs sont  paramÃ©trables par rapport Ã  un seul paramÃ¨tre :  Î± 
ou Î², de ce fait, cette   inÃ©galitÃ© se rÃ©Ã©crit en fonction dâ€™un seul paramÃ¨tre  par exemple 
Â« Î² Â», selon lâ€™expression : 
 
(f2)   [ ][ ] zy,x,   
1)(
2)(
z)(x,S
1

 z)(y,S1 y)(x,S1 -  1z)(x,Sz)(y,Sy)(x,S 2u
2
uuuuu âˆ€








+
+
+		






+
âˆ’âˆ’â‰¤âˆ’+
 
RNTI-A-3- 207 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
soit Ã©galement sous la forme Ã©quivalente: 
[ ][ ] [ ] zy,x,   2)(z)(x,S z)(y,S1 y)(x,S1
1)(

 -  1z)(x,Sz)(y,Sy)(x,S uuu2uuu âˆ€++âˆ’âˆ’+â‰¤âˆ’+
 
 Comme la quantitÃ© :       [ ][ ] [ ] zy,x,   2)(z)(x,S z)(y,S1 y)(x,S1
1)(

 uuu2 âˆ€++âˆ’âˆ’+
 
est positive si Î²â‰¥0 ,  lâ€™indice Su(x,y)  vÃ©rifie bien : 
                                       zy,x,     1z)(x,Sz)(y,Sy)(x,S uuu âˆ€â‰¤âˆ’+     
câ€™est Ã  dire lâ€™inÃ©galitÃ© TGI, il  est  donc mÃ©trisable. (cqfd) 
    
En remplaÃ§ant Su(x,y) par (1-du(x,y)) (son indice de distance) associÃ©, lâ€™inÃ©galitÃ©  (f 2) se 
transforme en :  
 [ ] [ ] [ ] [ ] zy,x,   
1)(
2)(
z)(x,d1
1

 z)(y,d y)(x,d -  1z)(x,d1z)(y,d1y)(x,d-1 2u
2
uuuuu âˆ€








+
+
+âˆ’		






+
â‰¤âˆ’âˆ’âˆ’+
  
soit :                
zy,x,
z)(y,dy)(x,d
1
1
   z)(y,d y)(x,d
1
2
 - z)(y,dy)(x,d
z)(x,d
uu
2
uuuu
u âˆ€
		






+
âˆ’
+
+
â‰¤
 
ThÃ©orÃ¨me nÂ°1 :  Tout indice de similaritÃ© Su(x,y),  fonction homographique dâ€™un indice 
Sd(x,y) vÃ©rifiant lâ€™inÃ©galitÃ© TGI, normÃ© et exprimable sous  la forme :  
1y)](x,S[1
y)(x,S
y)(x,S
d
d
u +âˆ’
=
,  vÃ©rifie Ã  son tour lâ€™inÃ©galitÃ© TGI et est  donc  mÃ©trisable.   
 
ThÃ©orÃ¨me nÂ°1 (bis) : Dâ€™autre part, si lâ€™indice Sd(x,y)= 1-1/2d2(x,y), alors lâ€™indice  
1y)](x,S[1
y)(x,S
y)(x,S
d
d
u
+âˆ’
=
 est exprimable suivant la formule Su(x,y)=1-1/2dâ€™2(x,y) et est alors 
mÃ©trisable Euclidien .  
 
En effet si Su(x,y) est bien exprimable suivant la formule prÃ©cÃ©dente alors il existe une 
mÃ©trique Euclidienne dâ€™2(x,y) telle que :  
1y)(x,d
y)(x,d1
y)(x,d'1 2
2

2
2
1
2
2
1
+
âˆ’
=âˆ’
,   montrons que  ceci implique que dâ€™2(x ,y)=2(1-Sâ€™(x,y)), donc 
que dâ€™2(x,y) vÃ©rifie le thÃ©orÃ¨me de Gower-Schoenberg .  
 
De lâ€™Ã©galitÃ© prÃ©cÃ©dente on tire : 
2y)(x,d
y)(x,d1)2( y)(x,d' 2
2
2
+
+
=
 soit : 






+
âˆ’=
2y)(x,d
y)(x,d-212y)(x,d' 2
2
2  
En remplaÃ§ant d2(x,y) par 2(1-Sd(x,y)) dans la formule ci-dessus, il vient : 






+âˆ’
âˆ’=
1y)](x,S[1
y)(x,S
12y)(x,d'
d
d2  
soit  dâ€™2(x,y) = 2(1-Sâ€™(x,y)) puisque lâ€™on reconnaÃ®t dans Sâ€™(x,y) la quantitÃ© Su(x,y) (indice de 
similaritÃ© normÃ©) que nous avions dÃ©finie prÃ©cÃ©demment. dâ€™2(x,y) vÃ©rifiant le ThÃ©orÃ¨me 
RNTI-A-3 - 208 -
                                                                                                    F. Marcotorchino 
de Gower Schoenberg est donc une distance Euclidienne. Et lâ€™indice Su(x,y) est bien mÃ©tri-
sable Euclidien.(cqfd) 
 
De la mÃªme faÃ§on,  si un indice de similaritÃ©  normÃ©, est construit Ã  partir dâ€™une expres-
sion comme :  S(x,y) = 1 â€“ d(x,y) et si d(x,y) vÃ©rifie lâ€™inÃ©galitÃ© Â« ultramÃ©trique Â» suivante :  
 
                            d(x,z)  Max (d(x,y), d(y,z))  âˆ€ x, y,z 
 
Alors lâ€™indice de similaritÃ© associÃ© vÃ©rifiera lâ€™inÃ©galitÃ©  de TransitivitÃ© UltramÃ©trique 
Indicielle   suivante :  
            
(f 3)                                    S(x,z)  â‰¥ Min (S(x,y), S(y,z)) 
 
Ce rÃ©sultat sâ€™obtient en remplaÃ§ant d(x,y) par 1-S(x,y) dans lâ€™inÃ©galitÃ© ultramÃ©trique sur 
d(x,y) prÃ©cÃ©dente. Cette inÃ©galitÃ© implique la TransitivitÃ© GÃ©nÃ©ralisÃ©e Indicielle, en effet 
comme S(x,z)  â‰¥ Min (S(x,y), S(y,z))  on a : 
                               S(x,y) + S(y,z) - S(x,z) â‰¤ S(x,y)+S(y,z)- Min (S(x,y), S(y,z)) 
Soit donc : 
S(x,y) + S (y,z) - S(x,z) â‰¤ S(x,y)+ S(y,z)- [ 1/2(S(x,y)+ S(y,z)) - 1/2  âS(x,y)-S(y,z)â) 
Et donc finalement : 
.                              S(x,y) + S(y,z) - S(x,z) â‰¤   Max (S(x,y),S(y,z))  â‰¤ 1 
(cqfd) 
 
 
f) Pseudo Axiome nÂ°5 : Axiome dit du  Â« typage de Carnap Â» 
 
   On pourrait rajouter Ã  cette liste un Â« pseudo Â» axiome Â« logique Â»  associÃ© Ã  lâ€™axiome 3,  
celui dit Â« du typage Â» dÃ» au philosophe logicien Autrichien  Rudolf Carnap (1928)qui 
peut se traduire par : 
 Un Â« type TY Â»  Ã©tant dÃ©fini par lâ€™ensemble des individus vÃ©rifiant un ensemble fini de  
propriÃ©tÃ©s :  
                         TY(x) ={x	x,   vÃ©rifie les propriÃ©tÃ©s (p1,p2,â€¦pu)} 
 alors pour tout individu Â« w Â»  tel que TYw âˆ‰ , on doit avoir : 
                                                      w)S(x,y)S(x,Min
TYTYy)(x,
â‰¥
Ã—âˆˆ
.  
En dâ€™autres termes tous les objets vÃ©rifiant un type TY donnÃ© doivent Ãªtre plus semblables 
entre eux quâ€™ils ne le sont Ã  tout objet quelconque extÃ©rieur Ã  lâ€™ensemble caractÃ©risÃ© par ce 
Type . Attention, ce Â« pseudo Â» axiome est tout Ã  fait caractÃ©ristique des classes ou types 
Â« monothÃ©tiques Â» , mais peut ne pas Ãªtre systÃ©matiquement vÃ©rifiÃ© par les  classes ou 
types Â« polythÃ©tiques Â». 
 
 
g) RÃ¨gle et borne dites de Â« Solomon et Fortier Â»  
 
   Dans leur article datant de 1966,  H. Solomon et  J. Fortier  (1966) dÃ©finissent,  pour tout 
indice de similaritÃ©  S(x,y) variant de 0 Ã  1,   une rÃ¨gle,   que lâ€™on peut appliquer de faÃ§on 
gÃ©nÃ©rale  et qui stipule que dÃ¨s lors que la valeur dâ€™un indice  est supÃ©rieure Ã   une borne 
RNTI-A-3- 209 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
correspondant au Â« milieu Â» de son intervalle de variation, on considÃ©rera que x et y seront 
Â« plus semblables Â» que Â« dissemblables Â», en un mot on pourra parler de similaritÃ© (par 
rapport Ã  cet indice)  entre x et y. Cette rÃ¨gle sâ€™Ã©crit donc : 
                 
2
1y)S(x, â‰¥  
 On peut Ã©tendre cette rÃ¨gle au cas oÃ¹ lâ€™intervalle de variation nâ€™est plus (0-1), on Ã©crira 
alors cette rÃ¨gle Â« Ã©tendue Â»  sous la forme : 
                                        
2
y)S(x,Maxy)S(x,Min
y)S(x, yx,yx,
+
â‰¥  
 
La borne de Solomon-Fortier est intÃ©ressante au sens quâ€™elle permet dâ€™Ã©talonner un indice 
au milieu de son intervalle de variation (disons un point de passage obligÃ©) et ainsi 
dâ€™autoriser  des comparaisons structurelles entre indices. Nous Ã©talonnerons surtout, pour 
un indice donnÃ©,  la valeur des Â« matchings Â» entre les profils de Â« x Â» et Â« y Â» en comparant 
cette valeur au  nombre de variables dans le contexte spÃ©cifique et particulier de la Â« dis-
jonction complÃ¨te Â» (voir Â§ 2.2.2.1) . Câ€™est le processus complet dÃ©rivÃ© de lâ€™application de 
cette rÃ¨gle qui sera utilisÃ© comme critÃ¨re de valorisation dâ€™un indice dans les paragraphes 
suivants. 
1.2 Quelques DÃ©finitions de Base  
    Dans le suite du texte nous parlerons de Â« Descripteurs Â» ou dâ€™ Â« Attributs Â» ou de 
Â« propriÃ©tÃ©s Â» quand nous aurons affaire  Ã  des variables de Â« PrÃ©sence - Absence Â», nous 
noterons :  J  cet ensemble, et  nous poserons : 
P = J   le cardinal de cet ensemble J (indice dâ€™un attribut = j ).  
 Dâ€™autre part,  nous parlerons de  Â« Variables Â»  ou de variables Â« vraies Â» au sens statis-
tique du terme lorsque nous aurons affaire  Ã   des colonnes de  tableaux de donnÃ©es, que 
ces variables soient nominales (catÃ©gorielles), hiÃ©rarchisÃ©es (notes, rang, frÃ©quences etc..), 
ou continues, nous  appellerons :  M cet ensemble  et : 
       m= M  le cardinal de cet ensemble (indice dâ€™une variable = k ). 
Enfin, et trÃ¨s classiquement cette fois, nous appellerons : I, lâ€™ensemble des individus ou 
sujets Ã©tudiÃ©s, entre  lesquels, on calculera des indices de similaritÃ©.  Nous poserons, ce 
qui est un classique de lâ€™analyse des donnÃ©es : I = {ensemble des individus} et : 
       N=  Î™  = le cardinal  de  cet ensemble (indice dâ€™un individu = i). 
 
 
 
RNTI-A-3 - 210 -
                                                                                                    F. Marcotorchino 
2 Les ReprÃ©sentations possibles et les  diffÃ©rences entre 
lâ€™Espace IxJ, lâ€™Espace IxM et lâ€™Espace Relationnel : IxI. 
2.1 Les Tableaux K=IxJ et T=IxM  
    ConsidÃ©rons maintenant les tableaux  suivants : Tableau 1, Ã  valeurs {0-1} , de dimen-
sions   (N,P)  (croisant des  individus notÃ©s {Oi }avec des variables binaires ou des modali-
tÃ©s {mj }, et le Tableau 2, de dimensions (N,m), (croisant les mÃªmes individus  {Oi}avec des 
variables catÃ©gorielles ou hiÃ©rarchisÃ©es, ou numÃ©riques  {Vk}), on a :      
 
Tableau 1                        Tableau 2 
 
 
          
  
 
 
 
 
 
 
 
 
Dans le cas du  Tableau IxJ, simple, de dimensions (N,P),   cas des donnÃ©es de Â« PrÃ©sence â€“ 
Absence Â», il apparaÃ®t  que toutes les donnÃ©es sont 0 ou 1,  (lâ€™individu possÃ¨de = 1, ou ne 
possÃ¨de  pas = 0, une propriÃ©tÃ© j (Attribut j)). 
Dans le cas du Tableau T = IxM,  de dimensions (N,m) - cas de variables vraies - les quanti-
tÃ©s donnÃ©es Ã  lâ€™intersection dâ€™une ligne i et dâ€™une colonne k peuvent prendre des valeurs 
quelconques.  Dans le cas dâ€™une  variable catÃ©gorielle ou hiÃ©rarchisÃ©e, le nombre de va-
leurs (finies et assez peu nombreuses) en gÃ©nÃ©ral prises par la variable Vk, donnera    le 
nombre total de modalitÃ©s ( les diffÃ©rentes valeurs possibles) de cette variable.   
           Soit pk  ce  nombre, pk = (Ensemble des valeurs diffÃ©rentes de Vk) et lâ€™on a : 
 
=
=
m
1k
kpP  , k âˆˆ {1,2â€¦..m},  est le nombre total de modalitÃ©s du Tableau, (Ã  ne pas  con-
fondre avec Â« m Â»,  qui lui est le nombre total de variables). 
 
En effet, si lâ€™on prend par exemple  lâ€™individu NÂ° 2 du tableau  (NÃ— m) prÃ©cÃ©dent , on voit 
que le profil de i2, est donnÃ© par:  
 
            i2  =  
     
 V
1
V
2
V
k
V
m
O1 1 3 2 5 
O2 4 3 1 4 
O3 5 4 3 5 
Oi 0 1 2 5 
Oiâ€™ 5 3 1 1 
 
    
ON 4 4 1 2 
 m1 m mj mjâ€™  mP 
O1 1 0 1 0 0 1 
O2 0 1 0 1 0 1 
O3 1 0 1 0 1 0 
Oi       
Oiâ€™       
 
      
ON 1 0 0 1 1 1 
4 3 1 4 
RNTI-A-3- 211 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
la dÃ©composition en profil disjonctif complet de lâ€™individu i2 du fait que V1 a 5 modalitÃ©s, 
V2 a 4 modalitÃ©s, V3 a 3 modalitÃ©s, enfin V4 a 5 modalitÃ©s sâ€™Ã©crit : 
 
 
    
Sur ce tableau disjonctif on a bien m (Nombre de variables ) = 4,    N = I   
 
  P, la dimension la plus large = Nombre total de modalitÃ©s =  5+ 4 +3 + 5 =  17, dans le cas 
prÃ©sent,  donc : 
=
=
m
1k
kpP , k âˆˆ{ 1,2â€¦..4};  vaut ici:  P = 17.   
Donc, il y a Ã©quivalence au niveau de lâ€™information apportÃ©e entre le tableau Nxm et le 
Tableau NxP, quâ€™on appellera Tableau Disjonctif Complet  dans ce cas, et on le notera K,  
son terme gÃ©nÃ©ral est donnÃ© par : 
 



sinon 0
j modalitÃ© la possÃ¨de iobjet l' si 1 
=k ij  
seuls le nombre de colonnes (P au lieu de m) et les valeurs  dans les cases ont changÃ© : {0,1} 
dans le tableau NxP, valeurs quelconques dans le tableau Nxm. 
Posons maintenant:   
=
=
m
1k
kp
m
1p  alors  mpP =  , si  en particulier, toutes les variables 
ont le mÃªme nombre de modalitÃ©s soit Â« Î¼ Â» ce nombre, alors  P = Î¼ m.  
 
Remarque nÂ°1: on peut considÃ©rer que le tableau de Â«prÃ©sence - absenceÂ» est  un   tableau disjonc-
tif  particulier lorsque lâ€™on dÃ©coupe une variable de  Â«prÃ©sence â€“ absence Â» en deux variables dis-
jonctives,  lâ€™une de Â« prÃ©sence Â» et lâ€™autre dâ€™ Â« absence Â» dâ€™une propriÃ©tÃ©. On respecte dÃ¨s lors les 
contraintes dâ€™un tableau disjonctif complet avec comme changement majeur, le fait que lâ€™on double 
le nombre de colonnes de la matrice de Â« prÃ©sence absence Â»  avec un nombre de variables initial  
Ã©gal Ã  m dâ€™oÃ¹   P=2m  est le nombre des modalitÃ©s .  Nous verrons ultÃ©rieurement que, de ce fait, le 
modÃ¨le particulier  de Â« prÃ©sence â€“ absence Â» disparaÃ®t au profit dâ€™un modÃ¨le disjonctif particulier 
oÃ¹ toutes les variables ont deux modalitÃ©s.  
 
2.2 Cas des Tableaux Relationnels C=IxI et B=JxJ 
    Une derniÃ¨re notation trÃ¨s utile,  et particuliÃ¨re,  est Ã  retenir et Ã  rajouter Ã  la liste prÃ©-
cÃ©dente. Lorsquâ€™on a affaire Ã  des donnÃ©es reprÃ©sentables sous forme vectorielle (cas des 
Â« m Â» variables) ou dans un cas plus complexe encore: le cas de donnÃ©es non reprÃ©sen-
tables sous forme vectorielle, mais sous forme de graphe, il existe une autre reprÃ©sentation 
appelÃ©e, reprÃ©sentation relationnelle qui permet de dÃ©ployer une ThÃ©orie qui lui est consa-
crÃ©e, Ã  savoir :   Â« lâ€™Analyse Relationnelle ou lâ€™Analyse des  ReprÃ©sentations  Relation-
nelles Â» . Une abondante littÃ©rature existe sur ce domaine que nous donnons en bibliogra-
phie (voir en particulier J. Ah-Pine (2007), H.Benhadda et F.Marcotorchino (1998) et 
(1996), F. Marcotorchino (1984), (1989), (1991), F.Marcotorchino et P.Michaud (1981), 
F. Marcotorchino et N. El Ayoubi (1991) en tant quâ€™Ã©chantillon de cette approche). Mais 
V1 V2 V3 V4 
0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 
RNTI-A-3 - 212 -
                                                                                                    F. Marcotorchino 
 
pour la suite de lâ€™exposÃ©, il nous paraÃ®t important dâ€™en donner quelques dÃ©finitions ba-
siques, (voir les explications ci-aprÃ¨s) :   
 
2.2.1 Tableau Relationnel de Â« Condorcet Â» C, croisant IxI de Taille (NxN)  
    Le modÃ¨le mathÃ©matique  sur lequel est basÃ©e lâ€™Analyse Relationnelle des DonnÃ©es est 
liÃ© Ã  une faÃ§on particuliÃ¨re de prendre en compte  des variables, quel quâ€™en soit le type. En 
fait, il sâ€™agit de prendre en compte les donnÃ©es individuelles sous forme de Relation Bi-
naire (ceci permet de croiser des clients par rapport Ã  une variable en Marketing , des 
textes en linguistique, des  Patients en MÃ©decine etc..). A titre dâ€™illustration, considÃ©rons le 
cas suivant oÃ¹ est reprÃ©sentÃ©e une variable catÃ©gorielle (nominale) Ã  savoir la Â« nationali-
tÃ© Â»  appliquÃ©e Ã  un petit  ensemble  de 5 personnes notÃ©es { A, B, C, D, E} ayant 3 Nationa-
litÃ©s. La variable V â€œnationalitÃ©â€, est codÃ©e 1 pour les citoyens FranÃ§ais:  {A et B}, 2  pour 
lâ€™Espagnol {C}, 3 pour les Anglais : {D et E}. Dans ce cas, deux individus sont en relation 
sâ€™ils ont la Â« mÃªme NationalitÃ© Â». Câ€™est bien entendu une relation  binaire, dont le graphe 
de reprÃ©sentation sous forme matricielle  C est donnÃ© ci â€“ aprÃ¨s: 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
Remarque nÂ°2: Si nous avions changÃ© le codage   1 en 2 , 2 en 7 et 3 en 13  (par exemple), il est 
Ã©vident que la matrice Relationnelle  C nâ€™aurait pas Ã©tÃ© affectÃ©e par ce  changement, (en fait en cas 
de variables catÃ©gorielles, les codages nâ€™ont pas de signification particuliÃ¨re, seule lâ€™appartenance Ã  
des classes de valeurs de modalitÃ©s diffÃ©rentes,  compte). En fait la reprÃ©sentation de C  sous forme 
matricielle sâ€™obtient en posant  la valeur Â« 1 Â» Ã  lâ€™intersection de la Ligne A et de la Colonne B si:  
lâ€™Â« Objet A Â» a  Â« la mÃªme modalitÃ©  Â»  que  lâ€™ Â« Objet B Â» et   Â« 0 Â» sinon. Ceci est fait sans tenir 
compte explicitement de la valeur de la catÃ©gorie mais seulement de faÃ§on implicite.  En fait dans ce 
cas, nous sommes dans une situation oÃ¹ la Relation  est une pure   Â« Relation dâ€™Equivalence Â».  Il 
existe une correspondance claire entre la reprÃ©sentation codÃ©e de V, et sa reprÃ©sentation associÃ©e C 
en termes de graphe ou de matrice (NxN) binaire, mais comme nous lâ€™avons vu prÃ©cÃ©demment cette 
correspondance nâ€™est pas biunivoque.   NÃ©anmoins, la matrice  C  reprÃ©sentant la variable  V est une 
Matrice  {0-1}, contenant la mÃªme  information que celle apportÃ©e par la variable catÃ©gorielle  V. En 
gÃ©nÃ©ral, une  Matrice Binaire  contient au minimum, la mÃªme information que celle contenue dans sa 
 
 A B C D E 
1 A 1 1 0 0 0 
1 B 1 1 0 0 0 
2 C 0 0 1 0 0 
3 D 0 0 0 1 1 
3 E 0 0 0 1 1 
V  C 
RNTI-A-3- 213 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
variable nominale associÃ©e, codÃ©e sous forme Â« vecteur linÃ©aire Â». Mais bien plus,  si nous considÃ©-
rons le cas, oÃ¹, dans notre premier exemple, on suppose Ã  titre illustratif que lâ€™Individu C a la triple 
â€œNationalitÃ©â€ : (multi-appartenance : Passeports FranÃ§ais, Espagnol et Anglais). Il est dÃ¨s lors  
impossible de coder cette nouvelle  information dans la variable  V, telle quâ€™elle est. Mais ceci ne 
pose aucun problÃ¨me en environnement relationnel, voir la nouvelle reprÃ©sentation Câ€™ de C ci-
aprÃ¨s : 
 
 
 
 
 
 
 
 
 
 
 
On voit sur le tableau prÃ©cÃ©dent, quâ€™il est impossible de tenir compte de la triple apparte-
nance dans le codage de V, alors que dans le codage relationnel, il suffit de rajouter des 
Â« 1 Â»  (en gras sur la figure) Ã  lâ€™intersection des lignes et des colonnes de lâ€™individu C Ã  
lâ€™intersection des lignes et des colonnes des autres individus de dÃ©part. 
Dans le cas de cette configuration relationnelle, on peut crÃ©er des critÃ¨res de classification  
sur lâ€™ensemble des individus ou sur lâ€™ensemble des variables (voir lâ€™article sur Analyse 
Factorielle Relationnelle dans  F.Marcotorchino (1989) et (1991)) ou  des indices de com-
paraisons entre deux tableaux (matrices) relationnels, câ€™est-Ã -dire entredeux variables  V 
et Vâ€™, ou plus gÃ©nÃ©ralement entre deux matrices C et Câ€™.  Des rÃ©sultats fondamentaux rÃ©-
sultent de cette notation relationnelle . 
 
2.2.2 AdditivitÃ© des Matrices  Relationnelles  de type  Â« CondorcÃ©en Â» 
  Quelle que soit  une matrice relationnelle Ck, reprÃ©sentant une relation binaire associÃ©e Ã  
une  variable Vk quelconque, elle sâ€™Ã©crit de la faÃ§on suivante :  
a) Si la variable, Vk,  est une variable purement qualitative, on a le codage suivant : 
 
)'i(V)i(V 
onsin
si
0
1
C
kk
k
'ii
=



=
 
b) Dans le cas dâ€™une variable quantitative le codage associÃ© peut prendre plusieurs formes 
possibles dont une assez simple,(mais non optimale), dÃ©crite ci-dessous : 
  A B C D E 
1 A 1 1 1 0 0 
1 B 1 1 1 0 0 
2 C 1 1 1 1 1 
3 D 0 0 1 1 1 
3 E 0 0 1 1 1 
V  Câ€™=Nouveau C 
RNTI-A-3 - 214 -
                                                                                                    F. Marcotorchino 
 
        
s)'i(V)i(V 
onsin
si
0
1
C
kk
k
'ii
â‰¤
âˆ’



=
 
 OÃ¹ Â« s Â» est un seuil donnÃ©. 
Alors, posons  : 
 (f 4)                                             
=
=
m
1k
k
ii'ii' CC
 
oÃ¹ Â« m Â» est le nombre de variables de dÃ©part, et oÃ¹ le nombre total dâ€™objets {Oi}, on lâ€™a 
vu, est posÃ© Ã©gal Ã  Â« N Â» par la suite. (N pouvant atteindre des valeurs Ã©gales Ã  plusieurs 
millions dans les problÃ©matiques rÃ©elles, CRM et Marketing bancaires par exemple)). 
Cette matrice est la matrice dite de Â« Condorcet Â» de lâ€™Analyse Relationnelle. La mÃ©tho-
dologie relationnelle sâ€™appuie sur la dÃ©finition de cette matrice globale de similaritÃ©s qui 
dans les cas les plus usuels de similaritÃ© sâ€™exprime comme un produit scalaire (Ã©quivalent 
Ã  un Â« noyau Â» (Â« Kernel de la thÃ©orie de lâ€™apprentissage ).:  
 (f 5)                                             
=
=
P
1j
j'iij'ii kkC
2
 
(oÃ¹ kij reprÃ©sente le codage disjonctif (vu au Â§ prÃ©cÃ©dent) pour lâ€™ensemble des modalitÃ©s 
de lâ€™individu Oi), câ€™est Ã  dire dans le cas ou les valeurs {0 ou 1} sont obtenues par disjonc-
tion du Tableau 2, du  prÃ©cÃ©dent  paragraphe. 
Cette matrice traduit le degrÃ© de ressemblance entre deux objets i et iâ€™.   
A  partir de cette matrice de ressemblance, on peut construire une matrice Â« duale Â» de 
celle de Condorcet dite matrice des Â« dissemblances Â» ou dissimilaritÃ©s   soit  ii'C ,  le-
terme gÃ©nÃ©ral de cette matrice alors on a :       
                                             
ii'ii' CmC âˆ’=   (si pas de donnÃ©es manquantes) 
 
                            mCC ii'ii' â‰¤+    (si donnÃ©es manquantes) 
  
Tout tableau de Condorcet  de terme gÃ©nÃ©ral Ciiâ€™, vÃ©rifie (voir  F.Marcotorchino et 
P.Michaud (1981)), la condition de Â« transitivitÃ© gÃ©nÃ©rale Â» : 
 
(f 6)                                           )"i,'i,i(mCCC
"ii"i'i'ii âˆ€â‰¤âˆ’+  
Cette condition de transitivitÃ© gÃ©nÃ©rale provient  du fait que le tableau  
=
=
m
1k
k
ii'ii' CC   (voir 
formule (f 4) ), est la somme de Â« m Â» relations dâ€™Equivalence, qui vÃ©rifient chacune  (par 
dÃ©finition dâ€™une relation dâ€™Ã©quivalence) la condition de transitivitÃ©, câ€™est Ã  dire : 
                                                 
2
 Lâ€™analyse relationnelle a Ã©tÃ© le cadre de dÃ©veloppement de nombreuses mesures de similaritÃ©s dites rÃ©gularisÃ©es 
qui permettent de tenir compte de la structure interne des unitÃ©s lexicales dans le calcul de similaritÃ© entre deux 
documents. Cette approche consiste Ã  donner un poids, calculÃ© de maniÃ¨re empirique, Ã  chaque unitÃ© lexicale qui 
permet de mettre en avant son caractÃ¨re discriminant. Nous renvoyons le lecteur intÃ©ressÃ© aux travaux de 
H.Benhadda  et F.Marcotorchino (1998) et H.Benhadda ( 1996). 
 
 
RNTI-A-3- 215 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
(f  7)                                        ( ) k ,i",i'i,    1CCC k
"ii
k
"i'i
k
'ii âˆ€âˆ€â‰¤âˆ’+   
qui sâ€™interprÃ¨te en disant que si  Â«  i Â» est en relation avec Â« iâ€™ Â» (soit  ( ) k ,i'i,    1C kii' âˆ€âˆ€= )  
et si Â«  iâ€™ Â» est  en relation avec Â« iâ€³ Â» soit ( ) k  ,i",i'    1C ki"i' âˆ€âˆ€=  alors on doit avoir Â« i Â» en 
relation avec Â« iâ€³ Â»  câ€™est Ã  dire que ( ) k  ,i"i,    1C kii" âˆ€âˆ€= , câ€™est justement ce que traduit 
la formule (f 7) 
 
En sommant pour toutes les Â« m Â» valeurs de Â« k Â» , lâ€™inÃ©galitÃ© (f 7), on trouve lâ€™inÃ©galitÃ© 
proposÃ©e dans la formule (f 6), la condition Â« duale Â» sur la matrice de Condorcet ii'C , est 
une condition dâ€™Â« inÃ©galitÃ© triangulaire Â» : 
(f 8)                                           i"i'ii'ii" CCC +â‰¤  
Comme nous lâ€™avons vu ces deux relations sont souvent Â« duales Â» lâ€™une de lâ€™autre. La 
relation dâ€™  Â« inÃ©galitÃ© triangulaire Â», relation liÃ©e Ã  des approches Â« mÃ©triques Â» de dis-
tances, correspond Ã  la relation de Â« transitivitÃ©  gÃ©nÃ©ralisÃ©eÂ» pour les structures de Â« simi-
laritÃ© Â» vue sous lâ€™angle relationnel. 
Dans le cas gÃ©nÃ©ral , dire quâ€™il y a plus de variables pour lesquelles les objets Â« i et iâ€™ Â» 
sont en relation, que de variables pour lesquelles ils ne le sont pas, se traduit par la rÃ¨gle 
suivante  : 
                                
'ii'ii CC â‰¤  
        
Quand il nâ€™y a pas de donnÃ©es manquantes , du fait que  mCC
'ii'ii =+  dans ce cas , il 
vient  la condition dite de majoritÃ© par paires :  
(f 9)                               
2
1
m
C
2
mC 'ii
'ii â‰¥â‰¥
    
(ceci est une reprÃ©sentation de la rÃ¨gle majoritaire des comparaisons par paires de Condor-
cet (1785), qui, dans le cas oÃ¹ lâ€™on  considÃ¨re le tableau de Condorcet comme un indice de 
similaritÃ© est Ã©quivalente Ã  une borne de Solomon Fortier, il suffit de diviser le tableau C 
par Â« m Â», pour  voir ce fait immÃ©diatement).  
Cette dÃ©finition est trÃ¨s gÃ©nÃ©rale car elle permet dâ€™additionner tous types de relations bi-
naires quelconques  en allant bien au delÃ  des structures vectorielles dont nous avons parlÃ© 
ici. Ainsi la dÃ©finition de la matrice de Condorcet  ( que nous avons donnÃ©e en (f 5)) est 
moins gÃ©nÃ©rale, elle ne sâ€™applique seulement que dans le cas oÃ¹ lâ€™on considÃ¨re des va-
riables linÃ©aires, telle que la variable V dÃ©finie prÃ©cÃ©demment (exemple des nationalitÃ©s 
cas 1) ou en cas de variable reprÃ©sentable sous forme de vecteur colonne (linÃ©aire). 
 
2.2.3 AdditivitÃ© longitudinale modalitaire  
   Cette additivitÃ©  est valable dans le cas de variables linÃ©aires transformables en variables 
disjonctives (formule moins gÃ©nÃ©rale mais utilisÃ©e souvent en Analyse des DonnÃ©es)  
Dans ce cas, comme nous lâ€™avons vu,  si K reprÃ©sente la matrice de terme {kij}  reprÃ©senta-
tive dâ€™une variable  V  quelconque (appelÃ©e Ã©galement matrice disjonctive de V), on a, si 
pk  reprÃ©sente le nombre de modalitÃ©s de la variable Vk : 
RNTI-A-3 - 216 -
                                                                                                    F. Marcotorchino 
 
                              
                                        ki j =  1 si  i possÃ¨de la modalitÃ© j de V 
ki j =  0 si  i  ne possÃ¨de  pas la modalitÃ© j de V 
dans ce cas particulier , la matrice relationnelle reprÃ©sentative de V (numÃ©ro k) sâ€™Ã©crit : 
                  
=
=
kp
1j
j'iijk'ii kkC  et  
=== ==
====

=
P
1j
j'iij
p
1j
j'iij
m
1k
p
1j
j'iij
m
1k
k
'ii'ii kkkkkkCC
m
1k
k
k
 
On retrouve ici la  justification de la formule (f 5)
 
 
Les rÃ©sultats obtenus dans le cas gÃ©nÃ©ral   restent valables,  avec nÃ©anmoins pour  la forme 
duale  k'iiC   de  
=
=
kp
1j
j'iijk'ii kkC ,  une nouvelle forme donnÃ©e par :                                               
( )
=
âˆ’=
kp
1j
2
j'iij
k
'ii kk
2
1C , 
soit pour la sommation longitudinale : 
 (f 10)                                  ( )
==
âˆ’==
P
1j
2
j'iij
k
'ii
m
1k
'ii kk
2
1CC  
 On vÃ©rifie Ã©galement les formules  prÃ©cÃ©dentes dans ce cas disjonctif :  
( )i'i,    1CC kii'kii' âˆ€=+       et     ( )i'i,    mCC 'ii'ii âˆ€=+    
 
En effet, comme dans le cas dâ€™un tableau K (disjonctif complet) on a :    
                                                   i    ,  mk
P
1j
ij âˆ€=
=
 , il vient : 
     ( ) mkk
2
1kk
2
1kk
2
1kkCC
P
1j
P
1j
j'iij
P
1j
P
1j
2
j'i
2
ij
P
1j
2j'iijj'i
P
1j
ij'ii'ii =		
	








+=
	
	
	








+=âˆ’+=+   
= == ===
 
            
Ce qui se traduit au niveau des tableaux de Condorcet associÃ©s par la dÃ©finition littÃ©rale  
suivante:  
 
Â« Dans le cas oÃ¹  il nâ€™y a pas de donnÃ©es manquantes, dire que le nombre de modalitÃ©s 
(des variables) que i et iâ€™ partagent  est plus grand que le nombre de modalitÃ©s  quâ€™ils ne 
partagent pas, se traduit par 3Â» :  
                        ii'ii' CC â‰¥   ce qui implique   lÃ  encore  que :   Ciiâ€™  â‰¥  m/2     
                                                 
3
 il est Ã  noter ici que la phrase est  diffÃ©rente de celle prÃ©sentÃ©e au cas prÃ©cÃ©dent, on parle ici de Â« modalitÃ©s Â» et 
non de Â« variables Â»  
 
RNTI-A-3- 217 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
2.2.4 ReprÃ©sentation sous forme Vectorielle de la Matrice  Ck 
    Si lâ€™on reprÃ©sente en extension vectorielle  (vecteur de longueur NÂ²), la matrice reprÃ©-
sentative  de la variable C, et celle de la matrice Câ€™ (nouveau C), donnÃ©es  dans lâ€™exemple 
prÃ©cÃ©dent ( nationalitÃ©) , on obtient : 
 
On voit bien, que nous avons rajoutÃ© 8 valeurs Â« 1 Â» dans le vecteur reprÃ©sentatif  de Câ€™, les 
huit cases en Â« 1 Â» gras de la matrice (Nouveau C) prÃ©sentÃ©e auparavant. Chacun  des vec-
teurs associÃ©s Ã  C et Câ€™, se compose  donc de 25 (NÂ²) Ã©lÃ©ments, en 5 blocs de 5  juxtaposÃ©s, 
chaque bloc reprÃ©sentant une ligne  de la matrice C ou  de la matrice Câ€™.  Ainsi sur les 
mÃªmes donnÃ©es on peut avoir 4 reprÃ©sentations diffÃ©rentes :    Ã  savoir: des tableaux NÃ—P, 
des tableaux NÃ—m , des tableaux NÃ—N et des vecteurs N2. 
a) Bref aperÃ§u sur la rÃ©Ã©criture du Tableau Relationnel Ck sous forme vectorielle.  
Pour toute matrice relationnelle Ck, on dÃ©finira son Extension Vectorielle Î³k comme un 
vecteur de longueur N2   tel que :  
),....
,...

,
,(

 k
N
k
s
k
3
k
2
k
1
k
2=

,  oÃ¹ si k
'iiC  est le terme gÃ©nÃ©ral de la matrice C
k
, alors : 
 
(f 11)   kskii' 
C = ,  si et seulement si  lâ€™indice courant Â« s Â» vÃ©rifie:   
                                          i'et    i        'iN)1i(s âˆ€+âˆ’=   
(donc Ã  tout couple (i,iâ€™) correspond une valeur de lâ€™indice Â« s Â» et une seule). 
Inversement connaissant Â« s Â» et bien sÃ»r la dimension N, pour avoir la valeur de i et iâ€™, il 
suffit  de procÃ©der trivialement de la faÃ§on suivante :  
a) On divise s par N  s=a N+b,  
b) si a=0 alors :     i=1      et iâ€™=b 
c) si a â‰ 0 alors      i= a+1 et iâ€™=b 
Exemple pour N=5 , que valent les indices i et iâ€™ de la matrice relationnelle Ck , pour s=18 ?              
On divise 18 par 5 soit 18=3x5+3, on a donc i=4 et iâ€™=3 
 
b) PropriÃ©tÃ©s hÃ©ritÃ©es au niveau vectoriel 
Un bon nombre  de propriÃ©tÃ©s relatives aux notations relationnelles se retrouvent, de faÃ§on  
quasi hÃ©rÃ©ditaire, vÃ©rifiÃ©es au niveau des notations vectorielles, mais avec nÃ©anmoins 
quelques prÃ©cautions Ã  prendre, comme le montre lâ€™induction de la propriÃ©tÃ© de transitivi-
tÃ©.   
En effet, pour toute variable Ck, relation  dâ€™Ã©quivalence, on a vu en  (f  7) que lâ€™on avait 
lâ€™inÃ©galitÃ© : 
                                     ( ) k ,i",i'i,    1CCC kii"ki"i'kii' âˆ€âˆ€â‰¤âˆ’+   
C 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 
Câ€™ 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 
RNTI-A-3 - 218 -
                                                                                                    F. Marcotorchino 
 
En utilisant maintenant la convention dâ€™extension vectorielle (f 11),   cette inÃ©galitÃ© prÃ©cÃ©-
dente induit au niveau du vecteur  ),....
,...

,
,(

 k
N
k
s
k
3
k
2
k
1
k
2=

 les contraintes sui-
vantes :   
 (f 12)                              k       1   
-     
  
 k
s"
k
s'
k
s âˆ€â‰¤+  
Cependant les indices s, sâ€™ et sâ€™â€™ , ne sont pas quelconques, car ils sont liÃ©s par les trois 
Ã©galitÃ©s suivantes, impliquÃ©es par les  formules (f 11) et (f 7) : 
 
                                 
"iN )1i("s
"iN )1'i(  's
'iN )1i(  s
+âˆ’=
+âˆ’=
+âˆ’=
       avec i <iâ€™<iâ€™â€™ 
PropriÃ©tÃ© nÂ°1 : InÃ©galitÃ© sur les indices reprÃ©sentant une relation dâ€™Ã©quivalence  
En Ã©liminant deux Ã  deux les indices  ou quantitÃ©s prÃ©sentes  dans  2 des  Ã©galitÃ©s  ci-
dessus,  et en tenant compte que si N=âI â est donnÃ©,  alors chacun des  indices :  i,,iâ€™, iâ€™â€™  
tels que i < iâ€™<iâ€™â€™ vÃ©rifie : i â‰¤ N , iâ€™â‰¤N, iâ€™â€™â‰¤ N, on peut montrer que les indices  s, sâ€™ et sâ€™â€™ vÃ©ri-
fient alors  lâ€™inÃ©galitÃ© non triviale suivante :  
(f 13)                                     
N
'sNs  "s âˆ’+â‰¤  
 
2.2.5 Tableau Relationnel croisant JxJ de taille (PxP) ou Â« Matrice de Burt Â»  
     De la mÃªme faÃ§on que nous avons dÃ©fini le tableau de Condorcet C du paragraphe 
prÃ©cÃ©dent, nous pouvons dÃ©finir , dans le cas oÃ¹ les modalitÃ©s j de lâ€™espace J sont les mo-
dalitÃ©s de variables discrÃ¨tes ou catÃ©gorielles une matrice dite Â« Matrice de Burt Â», notÃ©e 
B,  qui se calcule Ã©galement Ã  partir des valeurs  du tableau Disjonctif  Complet K :  
 



sinon 0
j modalitÃ© la possÃ¨de iobjet l' si 1 
=kij  
Ce tableau B a pour terme gÃ©nÃ©ral la valeur Bjjâ€™, donnÃ©e par :  
 (f 14)                                          
=
=
N
1i
ij'ijjj' kkB  
 
Ce tableau trÃ¨s utilisÃ© en Analyse Factorielle des Correspondances Multiples (voir G. 
Saporta (1990) , F.Caillez et JP.Pages (1976) ou F.Marcotorchino (1991))  a de nom-
breuses propriÃ©tÃ©s structurelles dont on donne ci dessous les principales : 
 
           )B,B(MinB
'j'jjj'jj â‰¤  
 
            2
N
1i
'ijij
P
1j
P
1'j
'jj
P
1j
P
1'j
m.NkkB == 
== == =
 
RNTI-A-3- 219 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
Dans le cas ou les variables  Vk de dÃ©part sont des variables catÃ©gorielles, il existe une 
Â« dualitÃ© Â» Ã©vidente  entre les Tableaux de Â« Burt Â» et de Â« Condorcet Â» (voir 
F.Marcotorchino (1989), (1991)). En effet  on a: 

=
=
P
1j
j'iij'ii kkC ,  
=
=
N
1i
'ijij'jj kkB  , soit en notations matricielles : C= K 
tK et B= tK K 
 
PropriÃ©tÃ© nÂ°2 : EgalitÃ© des Normes de Frobenius des matrices de  Condorcet et de  Burt 
        De ces relations prÃ©cÃ©dentes on tire  la relation Â« unificatrice Â» suivante : 
 
  
= === = === = == =
=
















=




















=
P
1j
P
1'j
2
'jj
N
1'i
'j'ij'i
P
1j
P
1'j
N
1i
'ijij
P
1'j
'j'i'ij
N
1i
N
1'i
P
1j
j'iij2'ii
N
1i
N
1'i
BkkkkkkkkC  
 soit :  
(f 15)                                                 

= == =
=
P
1j
P
1'j
2
'jj
2
'ii
N
1i
N
1'i
BC
 ,  
En dâ€™autres termes la somme des carrÃ©s des termes gÃ©nÃ©raux des deux tableaux sont 
Ã©gales. Ce qui,  en termes matriciels,  est Ã©quivalent Ã  lâ€™Ã©galitÃ© du carrÃ© des normes de 
Frobenius associÃ©es : 
                                                               
2
F
2
F
CB =    
 
 
 
 
 
 
 
 
 
3 Les QuantitÃ©s de Base du Calcul des SimilaritÃ©s 
   Quelle que soit la faÃ§on dont les donnÃ©es sont prises en compte ou mises en matrices 
adÃ©quates : (NxP, Nxm, NxN), lâ€™information de base, quand on travaille  sur les similaritÃ©s 
entre deux  Â« objets Â» x et y, revient  Ã  calculer les 4 quantitÃ©s suivantes : reprÃ©sentables 
dans un tableau de contingence (2x2) : 
Si lâ€™on note les deux vecteurs de reprÃ©sentation dâ€™un objet x  et dâ€™un objet y  : 
( ) PÃ 1devariantj.,.,...x,..xx,xx Pj21= ,  ( ) PÃ 1devariantj.,.,...y,..yy,yy Pj21=  
En posant Â« xj  Â» le fait que pour la modalitÃ© Â« j Â», x  vaut 1, et (1-xj ) le fait que x vaut 0  
alors les quantitÃ©s suivantes caractÃ©risent lâ€™ensemble de tous les cas possibles de combi-
naisons vectorielles associÃ©es:   
 
 
 
 
RNTI-A-3 - 220 -
                                                                                                    F. Marcotorchino 
 
  
 
1. Nombre de Â«matchings Â» de x sur  y   =>         
j
P
1j
jyxy)11(x, 
=
=
 
oÃ¹  11(x,y)4 reprÃ©sente les configurations oÃ¹  x et y valent 1 simultanÃ©ment 
2. Nombre de Â«non matchings Â» de x sur y =>     )y)(1x(1y)00(x,
P
1j
jj
=
âˆ’âˆ’=
 
oÃ¹  00(x,y) reprÃ©sente les configurations ou x et y  valent simultanÃ©ment 0 
3. Nombre dâ€™erreurs en y de x sur y     =>           )y(1xy)10(x,
P
1j
jj
=
âˆ’=
 
oÃ¹  10(x,y) reprÃ©sente le nombre de configurations oÃ¹   x  vaut 1 et y vaut  0 
4. Nombre dâ€™erreurs en x  de x sur y     =>     
=
âˆ’=
P
1j
jj )yx(1y)01(x,
 
oÃ¹  01(x,y) reprÃ©sente le nombre de configurations oÃ¹   x  vaut 1 et y vaut  0 
5. De la mÃªme faÃ§on , on voit que : 

===
=âˆ’+=+=
P
1j
jj
P
1j
jj
P
1j
j x)y(1xyxy)10(x,y)11(x,x)11(x,   
cette somme reprÃ©sente le nombre de valeurs pour lesquelles x =1, on note par convention 
11(x,x) cette quantitÃ©. 
6. A lâ€™identique, on a :                       

===
=âˆ’+=+=
P
1j
jj
P
1j
jj
P
1j
j yy)x(1yxy)01(x,y)11(x,y)11(y,   
 qui reprÃ©sente le nombre de valeurs pour lesquelles y =1, on note par convention 11(y,y) 
cette quantitÃ©. 
 
Ceci Ã©tant reprÃ©sentable sous la forme du  tableau de contingence, dit :Â« Tetrachorique Â» 
suivant : 
 
 
 
 
 
 
 
 
 
                                                 
4
 Par la suite pour allÃ©ger les notations,  on identifiera le vecteur )...x,..xx,(xx Pj21=

 Ã  x, puis, au lieu de noter, 
)y,x11(  , le nombre de matchings on se contentera de la forme 11(x,y), par extension on identifiera x et son profil 
vectoriel, sous la lettre gÃ©nÃ©rique Â« x Â». Enfin pour lier les deux notations vues prÃ©cÃ©demment,  on aurait pu Ã©crire 
en identifiant  x Ã  Â« i Â» et Â« xj Â» Ã  Â« kij Â» :          
==
==
P
1j
yjxj
P
1j
ji'ij kkkky)11(x,
  
 
y = 1 y = 0 
x = 1 11(x,y) 10(x,y) 
x = 0 01(x,y) 00(x,y) 
RNTI-A-3- 221 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
4 Processus  de Structuration des Indices  
       Dans la forme calculable des indices de similaritÃ©, le fait avÃ©rÃ© est que toutes les quan-
titÃ©s du tableau de contingence  (Tetrachorique) prÃ©cÃ©dent, ne jouent pas un rÃ´le Ã©quiva-
lent, et que suivant le poids accordÃ© Ã  lâ€™une ou lâ€™autre de ces quantitÃ©s, on tombe sur des 
formes diffÃ©rentes et des constructions diffÃ©rentes dâ€™indices. Nous insisterons de faÃ§on 
rÃ©pÃ©tÃ©e sur la valeur et les propriÃ©tÃ©s de ces indices dans le cas de recodage sous forme 
disjonctive complÃ¨te entre les profils dâ€™ individus  {Oi} mesurÃ©s sur des  variables catÃ©go-
rielles. Les Groupe I  et Groupe II dont il va Ãªtre question dans les pages qui suivent se 
distinguent par le fait quâ€™ils font ou  ne font pas jouer un rÃ´le Ã  la quantitÃ© 00(x,y).  
 
4.1 Indices du Groupe I, donnant prioritÃ© aux structures 11(x,y) et ne 
faisant jouer aucun rÃ´le Ã  00(x,y) 
4.1.1 Indices du Groupe I, Type I (indices obtenus par ratios directs)  
4.1.1.1 Indice de Dice â€“Czekanowski (1945-1913) 
    Cet indice, bien quâ€™introduit initialement par Czekanowski en 1913 dans la thÃ©orie des 
matrices de confusions,  puis redÃ©couvert en 1920 par H.A. Gleason (dans le domaine de 
la botanique), a surtout Ã©tÃ© Ã©tudiÃ©  par L.R. Dice (1945) (utilisÃ© par lui en botanique et en 
phylogÃ©nie, en tout cas câ€™est sous son nom quâ€™il est prÃ©sentÃ© aujourdâ€™hui). Quoique ces 
auteurs lâ€™aient introduit sÃ©parÃ©ment, et pour des besoins justifiÃ©s dans leur discipline de 
spÃ©cialitÃ© respective,  aucun dâ€™eux  nâ€™a explicitÃ©  et compris le rÃ´le central et globalisant 
de cet indice dont on verra par la suite le caractÃ¨re fondamental dans la structuration des 
indices de similaritÃ©, dâ€™autre part nous montrerons que sous certaines conditions il est 
Ã©quivalent Ã  la notion de mesure majoritaire de comparaisons (due Ã  A. de Condorcet en 
1785). Il sâ€™exprime au travers de la  formule :   
 
(f 16)                
[ ] y)01(x,y)10(x,y)2.11(x,
y)2.11(x,
y)01(x,y)10(x,
2
1y)11(x,
y)11(x,y)(x,Sd
++
=
++
=
 
En fonction des quantitÃ©s introduites au Â§ 3, il sâ€™Ã©crit Ã©galement du fait que:  
11(x,x)=11(x,y)+10(x,y) et  11(y,y)=11(x,y)+01(x,y), 
 dâ€™oÃ¹            11(x,x)+11(y,y) = 2.11(x,y)+ 10(x,y)+ 01(x,y): 
 
 (f 16â€™)           
 

= =
=
+
=
+
= P
1j
P
1j
jj
P
1j
jj
d
yx
yx2
y)11(y,x)11(x,
y)2.11(x,y)(x,S
 
De ce fait ,  la quantitÃ© dd (x,y)=1-Sd (x,y) sâ€™Ã©crit: 
                  
 

= =
=
+
== P
1j
P
1j
jj
P
1j
2
jj
dd
yx
)y-(x
y)(x,S-1y)(x,d
 
on voit  que dans le cas oÃ¹  : âˆ€ x, 11(x,x)= 11(y,y)= Constante =Î¼,   lâ€™indice de Dice sâ€™Ã©crit:  
RNTI-A-3 - 222 -
                                                                                                    F. Marcotorchino 
 
(f 16â€)            
y)(x,
2
11

y

x
2
11
2.
)y-(x
1y)(x,S 2
2
P
1j
jj
P
1j
2
jj
d âˆ’=








âˆ’âˆ’=âˆ’= 

=
=
 
 
Il apparaÃ®t clairement que dans cette configuration oÃ¹ la somme en ligne des â€œ1â€ de tous 
les vecteurs x,y,z... est une constante, lâ€™indice de Dice sâ€™exprime bien sous la forme  
S=1- (Â½) Î´2, oÃ¹ Î´2 est le carrÃ© dâ€™une distance euclidienne, dâ€™aprÃ¨s le ThÃ©orÃ¨me de Schoen-
berg-Gower  (voir axiome nÂ°4, Â§  1.1), Sd(x,y) est donc un indice mÃ©trisable euclidien. 
4.1.1.2 Indice de Jaccard (1908) 
     Cet indice, lâ€™un  des tous premiers  indices Ã  avoir Ã©tÃ© dÃ©crit dans la littÃ©rature scienti-
fique par Paul Jaccard (1908) (ressortissant suisse du canton de Vaud, spÃ©cialiste de la 
phylogÃ©nie des plantes), est une variante du prÃ©cÃ©dent, bien que dÃ©couvert auparavant, il 
sâ€™Ã©crit : 
 
 (f 17)          [ ])y,x(01)y,x(10)y,x(11
)y,x(11)y,x(Sj
++
=
 
Il sâ€™Ã©crit aussi sous une forme trÃ¨s connue des spÃ©cialistes du traitement du langage natu-
rel: 
 
  (f 17â€™)        
)y,x(11)y,y(11)x,x(11
)y,x(11)y,x(Sj
âˆ’+
=    
En effet, comme nous lâ€™avons vu au Â§ 3:  11(x,x)=11(x,y)+10(x,y) et  11(y,y)=11(x,y)+01(x,y), 
dâ€™oÃ¹ 11(x,x)+11(y,y)=2.11(x,y)+10(x,y)+01(x,y),  dâ€™oÃ¹ lâ€™obligation de soustraire 11(x,y) au 
dÃ©nominateur.  
 
Si nous explicitons cet indice grÃ¢ce aux expressions dÃ©veloppÃ©es du Â§.3. nous obtenons:         
  

= = =
=
âˆ’+
=
+
= P
1j
P
1j
P
1j
jjjj
P
1j
jj
j
yxyx
yx
y)11(x,-y)11(y,x)11(x,
y)11(x,y)(x,S
 
et lâ€™indice de distance associÃ© sâ€™Ã©crit: 
  

= = =
=
âˆ’+
== P
1j
P
1j
P
1j
jjjj
P
1j
2
jj
jj
yxyx
)y-(x
y)(x,S-1y)(x, d
 
 
4.1.1.3 Indice dâ€™ Anderberg (1961) 
      Cet indice est lâ€™un  des plus rÃ©cents de la famille des indices de Type I, puisquâ€™il a Ã©tÃ© 
introduit dâ€™abord en 1958 par  R.R. Sokal et P.H.A. Sneath, (Ã  qui nous attribuerons un 
indice du Groupe II (voir Â§ ultÃ©rieurs),   puis redÃ©couvert ensuite par  M. R. Anderberg en 
1961, voir Anderberg (1961).  Il a Ã©tÃ© introduit  beaucoup  plus tard  que les deux prÃ©cÃ©-
dents (lesquels Ã©taient plus intuitifs et correspondaient Ã  des rÃ¨gles de similaritÃ© plus lo-
giques et plus simples),  ce nâ€™est, lui aussi, quâ€™une variante de celui de Dice, lorsque lâ€™on 
donne plus de poids aux situations de non concordance. 
RNTI-A-3- 223 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
Il sâ€™Ã©crit :                                                                                  
         
 (f 18)            [ ])y,x(01)y,x(102)y,x(11
)y,x(11)y,x(San
++
= 
4.1.1.4 Indice de SÃ¸rensen (1960) 
      Cet indice a Ã©tÃ© introduit par Thorvald  SÃ¸rensen, ce dernier, souvent citÃ© comme co-
inventeur en (1948) avec Dice de lâ€™indice qui porte son nom est Ã©galement lâ€™auteur en 
1960 dâ€™une variante, donnÃ©e ci dessous,  variante des  indices de Type I,  avec une dÃ©fini-
tion trÃ¨s voisine de celle de lâ€™indice de Dice, mais en donnant moins de poids   aux situa-
tions de Â« non concordance Â». Il sâ€™Ã©crit :  
                                                                             
(f19)             
[ ])y,x(01)y,x(10
4
1)y,x(11
)y,x(11)y,x(Sso
++
=

cet indice  semble un peu   â€œ tirÃ© par les cheveuxâ€  Ã  premiÃ¨re  vue, mais rÃ©Ã©crit comme 
celui de Jaccard en fonction des quantitÃ©s 11(x,x) et 11(y,y)  il gagne en signification en 
effet on a  :    
 
(f 19â€™) 
                     
[ ] [ ])y,x(11.2)y,y(11)x,x(11
)y,x(11.4)y,x(Sso
++
=
    
               
Tous ces indices  sont des variantes par rapport au poids donnÃ©s aux structures 
(10(x,y)+01(x,y)), en effet :  Dice = Â½,   Jaccard = 1, Anderberg =  2 ; SÃ¸rensen = Â¼ , il 
manque par symÃ©trie Ã  celui de Dice,  un indice dont les le poids serait de 1/8 pour  la 
configuration  globale de non concordances : Nous appellerons cet indice, lâ€™indice dâ€™  
Â« Anderberg ComplÃ©mentaire Â»  Sac, il sera dÃ©fini par :   
4.1.1.5 Indice dâ€™ Â« Anderberg ComplÃ©mentaire Â» 
      Cet indice est introduit Â« artificiellement Â» ici,  comme indice complÃ©mentaire et sy-
mÃ©trique de celui quâ€™ avait proposÃ© en 1961, M. Anderberg (1961), , dâ€™oÃ¹ le nom que nous 
lui donnons,  pour des raisons dâ€™Ã©quilibrage. 
(f20)              
[ ])y,x(01)y,x(10
8
1)y,x(11
)y,x(11)y,x(Sac
++
=
 
4.1.2 Unification Homographique des Indices de Type I 
      Lâ€™ensemble des  diffÃ©rents indices connus,  appartenant au Groupe I :Type I, peut se 
dÃ©finir   Ã  partir de fonctions homographiques de lâ€™indice de Dice  (câ€™est cette propriÃ©tÃ© 
que nous avions dÃ©jÃ  dÃ©crite dans F. Marcotorchino , P. Michaud (1981), Ã©tudiÃ©e et reprise 
dans lâ€™article fort structurÃ© de S Joly et G. Le CalvÃ© (1994), publiÃ© chez Springer-Verlag  
dans le livre  complet sur  la Â« Dissimilarity Analysis Â», Ã©ditÃ© par B. Van Cutsem (1994).  
En effet en exprimant la quantitÃ© (10(x,y)+01(x,y)) par rapport Ã  11(x,y) et Ã  lâ€™indice de Dice 
on trouve :    
RNTI-A-3 - 224 -
                                                                                                    F. Marcotorchino 
 
           
( )[ ]
)y,x(S
)y,xS1)y,x(11.2)]y,x(01)y,x(10[
d
dâˆ’
=+
 
En remplaÃ§ant la quantitÃ© de Â« non concordance Â»,  prÃ©cÃ©dente par son expression en fonc-
tion de Sd(x,y) dans les formules relatives Ã  chaque indice, la quantitÃ© 11(x,y) disparaÃ®t et 
lâ€™on obtient des expressions ne dÃ©pendant que de Sd(x,y):  
 
 
 
 
(f 21)               
)y,x(S2
)y,x(S)y,x(S
d
dj
âˆ’
=
           et rÃ©ciproquement        
)y,x(S1
)y,x(S.2)y,x(S
j
j
d
+
=
 
De la mÃªme faÃ§on on a pour Anderberg: 
(f 22)                  
)y,x(S.34
)y,x(S)y,x(S
d
d
an
âˆ’
=
            et rÃ©ciproquement         
)y,x(S.31
)y,x(S.4)y,x(S
an
an
d
+
=
 
 
De mÃªme, il vient pour lâ€™indice de SÃ¸rensen : 
(f 23)                  
1)y,x(S
)y,x(S.2)y,x(S
d
d
so
+
=
             et rÃ©ciproquement          
)y,x(S2
)y,x(S)y,x(S
so
so
d
âˆ’
=
 
 
Enfin pour lâ€™indice dâ€™Anderberg Â«  ComplÃ©mentaire Â», on obtient:  
 
(f 24)           
1)y,x(S.3
)y,x(S.4)y,x(S
d
d
ac
+
=               et rÃ©ciproquement                 
)y,x(S.34
)y,x(S)y,x(S
ac
ac
d
âˆ’
=
 
 
 
  Du fait que ces indices du Groupe I,  Type I, soient tous fonction homographique de 
lâ€™indice de Dice, nous permet de les reprÃ©senter sur un diagramme unique, oÃ¹ lâ€™on peut 
voir de faÃ§on simple comment ils se comportent et comment ils varient les uns par rapport 
aux autres. Par ailleurs bien Ã©videmment tous ces indices varient de 0 Ã  1, ce que nous 
constatons sur le graphique :  
 
 
 
                                                                     0 â‰¤ SÎ±(x,y) â‰¤ 1 
       
                     
 Ces indices valent 0 si le nombre de  concordances (Â« matchings Â») entre  x et y 
est Ã©gal Ã  0  11(x,y)=0 
 Ils valent 1 si la quantitÃ© 10(x,y)+01(x,y) = 0  x et y ont le mÃªme profil de 1 et de 
0   
 Ils ne sont pas dÃ©finis (division par zÃ©ro) si 11(x,y)=10(x,y)=01(x,y) =0, câ€™est Ã  
dire si 00(x,y) = P . On peut par extension proposer des valeurs dâ€™extension aux 
diffÃ©rents indices citÃ©s,  dans ce cas, pour Ã©viter ces situations dâ€™indÃ©termination 
ou dâ€™ambiguÃ¯tÃ©.  Les situations oÃ¹ le profil de deux individus Â« i Â» et Â« iâ€™ Â» nâ€™ont 
aucune valeur Â« 1 Â» prÃ©sentes dans leur profil sont  exceptionnelles.  Câ€™est Ã  cette 
RNTI-A-3- 225 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
problÃ©matique rare mais  nÃ©anmoins possible que Mattijs J. Warrens (2008) 
sâ€™attaque dans un article trÃ¨s rÃ©cent Mars 2008,  de la Revue Â« Journal of Classi-
fication Â».       
 
0,0
0,2
0,3
0,5
0,7
0,8
1,0
0,0
0
0,0
5
0,1
0
0,1
8
0,2
5
0,3
3
0,4
2
0,5
0
0,5
8
0,6
6
0,7
5
0,8
2
0,9
0
0,9
5
1,0
0
Anderberg
Jaccard
Dice
Sorensen
AnderCom
         Figure 1: Graphique de variation des indices du Groupe I,  Type I 
 
On constate sur ce graphique que la courbe de lâ€™indice de Dice est la bissectrice du gra-
phique, lâ€™indice dâ€™Anderberg  est le symÃ©trique, par rapport Ã  la bissectrice (indice de 
Dice), de lâ€™indice dâ€™ Â« Anderberg ComplÃ©mentaire Â», lâ€™indice de SÃ¸rensen est le symÃ©-
trique de lâ€™indice de Jaccard par rapport Ã  cette mÃªme bissectrice. 
Dâ€™autre part, dans le cas oÃ¹ les donnÃ©es de similaritÃ©s sont calculÃ©es sur des tableaux dis-
jonctifs complets (câ€™est ce qui se produit en AFCM (Analyse factorielle des correspon-
dances multiples), ou en AFR (Analyse Factorielle Relationnelle)), on a de plus, les pro-
priÃ©tÃ©s supplÃ©mentaires suivantes:  
 
 
PropriÃ©tÃ©  3 : Relation avec la Valeur Disjonctive de la Distribution 11(x,y) 
     Dans le cas oÃ¹ les donnÃ©es (0-1) sont issues de tableaux disjonctifs complets ou de 
tableaux de Â« prÃ©sence-absence Â»  dÃ©doublÃ©s, voir remarque du Â§ 2-2,   on a la propriÃ©tÃ© 
suivante : 
(i)  10(x,y) = 01(x,y) 
(ii) (10(x,y) +  01(x,y))  =   2m â€“ 2.11(x,y)  (cas des variables disjonctives) 
(iiâ€™) dâ€™oÃ¹ compte tenu de (i) 10(x,y)=01(x,y)=m-11(x,y)  
(iii) (10(x,y) +  01(x,y))  =  P â€“ 2.11(x,y) (cas des variables Â« prÃ©sence - absence Â»  dÃ©-
doublÃ©es) (avec 2m=  P) 
La dÃ©monstration est trÃ¨s simple, en effet, on sait que sur un tableau disjonctif complet le 
nombre de 1 par ligne est une constante, il  est Ã©gal Ã  Â« m Â», nombre de variables initiales.   
DÃ¨s lors  Ã  toute prÃ©sence de 1 dans le vecteur de x,  correspond un 1 ou un 0 dans le profil 
de y . 
â€¢ Si Ã  1 de x correspond un 1 de y, cette concordance est comptÃ©e dans 11 (x,y) 
RNTI-A-3 - 226 -
                                                                                                    F. Marcotorchino 
 
â€¢ Si Ã  1 de x correspond un 0 de y, cette concordance est comptÃ©e dans 10 (x,y) 
â€¢ Si Ã  0 de x correspond un 1 de y, cette concordance est comptÃ©e dans 01 (x,y)   
 
A toute Â« non concordance Â» de x sur y, correspond par symÃ©trie une Â« non concordance de y sur x.  
Du fait que la somme des Â« 1 Â» pour chaque individu est une constante m, le nombre  de non con-
cordances, soit (10(x,y)+01(x,y))  est comptÃ© deux fois dans la somme totale m, dâ€™oÃ¹ le rÃ©sultat : 
            (iv)  [ ] m)y,x(01)y,x(10
2
1)y,x(11 =++  
dâ€™oÃ¹  Ã©videmment les formules (i) et (ii) 
De ce fait lâ€™indice de Dice  se simplifie en :                                                   
 
(f 25)                           
m
)y,x(11)y,x(Sd = 
En utilisant les formules  (i) et (iii), il vient pour les autres indices   aprÃ¨s simplification et 
division du numÃ©rateur et dÃ©nominateur par m   et application de (iii) :  
 
         
(f 26)                             
)y,x(11m.2
)y,x(11)y,x(Sj
âˆ’
=                                                     
        
de la mÃªme faÃ§on on a: 
 
(f 27)                          
)y,x(11.3m.4
)y,x(11)y,x(S. an
âˆ’
= 
                                    
De mÃªme, il vient pour les indices de SÃ¸rensen  et dâ€™ Â« Anderberg ComplÃ©mentaire Â»: 
 
 
(f 28)                        
)y,x(11m
)y,x( 11.2)y,x(Sso
+
=  
                                       
                               
(f 29)                       
)y,x(11.3m
)y,x(11.4)y,x(Sac
+
=

                             
 
            
PropriÃ©tÃ© 4 : Comparaison  des Indices prÃ©cÃ©dents par Rapport Ã  la RÃ¨gle Majoritaire de 
Condorcet 
Si nous utilisons la formule  donnant la dÃ©finition dâ€™un tableau de Condorcet, dans le cas 
de la somme de la reprÃ©sentation de variables Â« linÃ©aires Â» (approche disjonctive),  on 
constate que la  rÃ¨gle majoritaire,  donnÃ©e  par : 
2
mC
'ii â‰¥  est Ã©quivalente Ã  :    2
1)'i,i(Sd â‰¥                  
RNTI-A-3- 227 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
En effet   puisque, dâ€™aprÃ¨s la formule (f 25)    
m
)'i,i(11)'i,i(Sd = en remplaÃ§ant x par i , et y par 
iâ€™  car 11(i,iâ€™) nâ€™est rien dâ€™autre que :  
                                 
=
=
P
1j
j'iij'ii kkC  (vue prÃ©cÃ©demment (f 5))  
si lâ€™on remplace dans les notations du Â§2.2,  xj  par kij   et yj  par kiâ€™j ,  dÃ¨s lors :   Sd (i,iâ€™) =
m
C
'ii 
   
(cqfd).  
 
 
 
 
 
Remarque nÂ°3 : Application directe de la RÃ¨gle de Â« Solomon-Fortier Â» (dÃ©finie au Â§1.1-5) : Au 
niveau indiciel si lâ€™on applique la rÃ¨gle de  Solomon et Fortier ,(voir Solomon et Fortier  (1966)),  
de faÃ§on formelle, cette rÃ¨gle stipule simplement que : quelque soit lâ€™indice de similaritÃ© S(x,y) ou 
S(i,iâ€™) considÃ©rÃ©, on dira que deux objets Â« x et y Â» ou Â« i et iâ€™ Â» sont en relation de Â« similaritÃ© au 
sens de Solomon - Fortier Â» si :    
2
1)'i,i(S â‰¥   , ou plus gÃ©nÃ©ralement si un indice S varie de Â« a Â» Ã   
Â« b Â»  b)'i,i(Sa â‰¤â‰¤ ,  la rÃ¨gle dit que i et iâ€™ seront en relation de Â« similaritÃ© Â» si : 
2
ba)'i,i(S +â‰¥ , 
oÃ¹ 
2
ba +
 est le Â« milieu Â» de lâ€™intervalle de variation. La borne Ã  Â½   prÃ©cÃ©dente est due au fait que 
a = 0 et b=1, puisque le milieu de lâ€™intervalle de variation correspondant est dâ€™Ã©vidence Ã©gal Ã   Â½. 
Ainsi si : 
                
2
mCalors
2
1)'i,i(S
'iid â‰¥â‰¥
  (rÃ¨gle de la majoritÃ© usuelle5, ou CondorcÃ©enne) 
 
 
 
Ceci sâ€™interprÃ¨te en disant que pour que deux objets Â« i et iâ€™ Â» soient considÃ©rÃ©s comme 
semblables au sens de la rÃ¨gle de Solomon et Fortier, il faut quâ€™ils soient semblables  pour 
une majoritÃ© de variables. 
 
 
                                                 
5
 Il est dâ€™ailleurs intÃ©ressant Ã  ce propos de voir que lâ€™Indice de SimilaritÃ© de Gower (que ce dernier a introduit en 
1971 ,J. C.  Gower (1971)) qui sâ€™Ã©crit : k
xy
k
k
k
k
G Sw
w
1y)(x,S 
=
est une variante pondÃ©rÃ©e de lâ€™approche 
CondorcÃ©enne. 
RNTI-A-3 - 228 -
                                                                                                    F. Marcotorchino 
 
 
 
 
Si nous  interprÃ©tons ce rÃ©sultat sur une Ã©chelle Â« peu sÃ©vÃ¨re Â» <==> Â« sÃ©vÃ¨re Â», par rap-
port Ã  la rÃ¨gle de Solomon et Fortier, il vient : 
 
 
Peu SÃ©vÃ¨re   =======================Medium===========================SÃ©vÃ¨re  
 Ander Compâ€¦..         SÃ¸rensen      â€¦â€¦â€¦   â€¦...Diceâ€¦â€¦â€¦        ..  .Jaccardâ€¦â€¦â€¦â€¦         Anderberg 
 
 
 
Pour le lecteur intÃ©ressÃ©, on trouvera dans S. Joly et G. Le CalvÃ© (1994), dans lâ€™article de 
B.G. Baulieu (1989), ainsi que dans le livre de I. C. Lerman (1981), une prÃ©sentation  des 
propriÃ©tÃ©s de mÃ©tricitÃ©,  de monotonie ou  dâ€™autres encore  que vÃ©rifient ces indices. Notre 
propos Ã©tant ici plus de structurer et classifier lâ€™ensemble des indices que de lister  leurs 
propriÃ©tÃ©s, nous renvoyons le lecteur Ã  ces auteurs et Ã  leurs articles pour de plus amples 
informations .  
 
4.1.3 Un cadre unificateur pour les indices du Groupe I-Type I : le ModÃ¨le de 
Tversky 
      Une approche unificatrice a Ã©tÃ© proposÃ©e par Amos Tversky  dans son article de fond A. 
Tversky (1977), ayant pour consÃ©quence une formulation un peu plus complexe que celles 
des indices prÃ©sentÃ©s prÃ©cÃ©demment, en particulier il permet dans sa formulation une in-
fluence non systÃ©matiquement Ã©quilibrÃ©e des quantitÃ©s 10(x,y) et 01(x,y).  
 
 
De mÃªme on aura pour lâ€™indice de Jaccard: 
2
1)'i,i(S j â‰¥        implique    =>     3
m.2C
'ii â‰¥   (rÃ¨gle de la majoritÃ© aux  Â« deux tiers Â») 
Pour lâ€™indice dâ€™ Anderberg:  
2
1)'i,i(San â‰¥       implique    =>     5
m.4C
'ii â‰¥   (rÃ¨gle de la majoritÃ© aux Â« quatre cin-
quiÃ¨mes Â») 
Pour lâ€™indice de SÃ¸rensen:  
2
1)'i,i(Sso â‰¥        implique    =>     3
mC
'ii â‰¥   (rÃ¨gle de la majoritÃ© au Â« tiers Â») 
Pour lâ€™indice de Andersen ComplÃ©mentaire  
2
1)i'(i,Sac â‰¥     implique     =>     5
mC
'ii â‰¥   (rÃ¨gle Ã  la majoritÃ© au Â« cinquiÃ¨me Â») 
RNTI-A-3- 229 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
Lâ€™indice gÃ©nÃ©ralisÃ© de Tversky sâ€™Ã©crit :  
 (f 30)                         
y)01(x,y)10(x,y)11(x,
y)11(x,)y,x(S Ty
++
=
 
        avec :                                          Î± et  Î² â‰¥0 
On a bien :                                     0 â‰¤ STy (x,y) â‰¤1  
Cet indice varie de 0 Ã  1 est est donc un indice Â« normÃ© Â», en effet il vaut 1 si 
10(x,y)=01(x,y)=0 et il vaut 0 si 11(x,y)=0. Il nâ€™est pas dÃ©fini si 11(x,y)=10(x,y)=01(x,y)=0 (voir la 
remarque citÃ©e page 23 sur les travaux de Mattijs Warrens(W2008))  
ll semble que la non symÃ©trie de lâ€™influence  des quantitÃ©s 01(x,y) et 10(x,y) trouve un do-
maine particuliÃ¨rement intÃ©ressant dâ€™applications en recherche de Â« similaritÃ© molÃ©culaire Â» 
en pharmacodynamique, et peut-Ãªtre dans les essais cliniques, voir Ã  ce propos le rapport de 
John Bradshaw de la SociÃ©tÃ© Pharmaceutique  â€˜Glaxo Wellcomeâ€™, J. Bradshaw (1997).  En 
effet la question Ã  poser peut  prendre  deux formes  diffÃ©rentes, nous citons ici son rapport :  
   â€œThere are two forms of question which we can ask, 
1. Assess the degree to which object x  and object y are similar to each other.  
2. Assess the degree to which object y  is similar to object xâ€.  
Ã€ la question de type 1., correspond un Ã©quilibre de lâ€™influence , de ce fait :  =  , Ã  la ques-
tion 2. peut correspondre un dÃ©sÃ©quilibre de x vers y dâ€™oÃ¹ :    , voici dâ€™ailleurs le texte 
complet de J. Bradshaw : â€œIn this case the query is directional and we are more interested in 
the features in molecule x than we are in the features unique to molecule y,  and  , do not 
need to be equal. Molecule x may be regarded as the prototype and molecule y as the vari-
antâ€. Cependant  comme il est dâ€™ailleurs remarquÃ© dans le texte de J. Bradshaw,  plus expÃ©-
rimental que thÃ©orique, on se retrouve facilement, mÃªme dans ce contexte Ã©largi, Ã  utiliser 
lâ€™indice de Dice ou celui de Jaccard, sans oublier bien entendu les indices extrÃªmement con-
nus que lâ€™on dÃ©couvrira, prÃ©sentÃ©s  et Ã©tudiÃ©s en dÃ©tail au Â§ 4.1.3. et qui sont dissymÃ©triques 
par essence, Ã  savoir :  les indices de Â« PrÃ©cision  P Â» et de Â« Rappel :R Â», donnÃ©s par : 
)y,x(10)y,x(11
)y,x(11P
+
=
  et   
)y,x(01)y,x(11
)y,x(11R
+
=
 
PropriÃ©tÃ© nÂ°5 : Equivalence de lâ€™ Â« Indice de Tversky Â» et de lâ€™  Â« Indice de Van Rijsbergen Â»  
Ace propos, il est intÃ©ressant de noter que dans le cas particulier oÃ¹  Î± + Î² = 1 dans la formule 
(f 30), un indice citÃ© dans lâ€™article de C. Michel (2000) et connu sous le nom dâ€™ Â« Indice de 
Van Rijsbergen Â», introduit par ce dernier  dans un livre faisant rÃ©fÃ©rence chez les spÃ©cia-
RNTI-A-3 - 230 -
                                                                                                    F. Marcotorchino 
 
listes de lâ€™analyse documentaire Van Rijsbergen (1979)  et qui sâ€™exprime par rapport aux 
indices de Rappels et de PrÃ©cision  sous la forme : 
 (f 30â€™)                        1avec
RP
P.Ry)(x,S vr =+
+
=
 
est totalement Ã©quivalent  en remplaÃ§ant P et R par leur valeurs donnÃ©es prÃ©cÃ©demment, Ã  
lâ€™indice de Tversky, puisque aprÃ¨s simplifications on a :   
  1avec
y)01(x,y)10(x,y)11(x,)(
y)11(x,
RP
P.Ry)(x,S vr =+
+++
=
+
=
 
et comme Î±+Î²=1 , on retrouve6 bien lâ€™expression de lâ€™Indice de Tversky. Conclusion si  
lâ€™initiative de Tversky est intÃ©ressante pour avoir permis une justification de la dissymÃ©trie 
dâ€™influence, on connaÃ®t peu dâ€™indices dissymÃ©triques ayant eu une utilisation gÃ©nÃ©raliste 
suffisante  pour figurer comme des indices standard. En effet peu  (voire pas) dâ€™indices de 
type I (modÃ¨le de Tversky)  avec   ,  autres que ceux qui ont Ã©tÃ© crÃ©Ã©s pour des applica-
tions  particuliÃ¨res  et spÃ©cifiques ont obtenu un statut dâ€™indices  Â« connus Â» gÃ©nÃ©ralisables  
dans la littÃ©rature scientifique.   
Le cas des indices SMax (x,y) (Indice de Simpson (1943)) et  SMin (x,y) (Indice de Braun-
Blanquet (1932)) rentrent Ã©galement comme cas particuliers du modÃ¨le de Tversky, au 
sens que, par exemple, lâ€™indice de Simpson qui sâ€™Ã©crit : 
y))y),01(x,Min(10(x,y)11(x,
y)11(x,
y))01(x,y)y),11(x,10(x,y)Min(11(x,
y)11(x,R)Max(P,y)(x,SSimpson +=++==
est Ã©quivalent Ã  lâ€™Indice de  PrÃ©cision  si 10(x,y) â‰¤ 01(x,y) 
est Ã©quivalent Ã  lâ€™indice de  Rappel     si 01(x,y) â‰¤ 10(x,y) 
On peut tabuler par rapport aux diffÃ©rentes valeurs   de Î± et Î² , les indices qui relÃ¨vent de lâ€™approche 
Â« Tverskienne Â», on obtient :  
                    
                              Î² 0 1/2 1 2 
0 Pas de sens Comparaison Ã   y 
Indice de 
Â« Rappel Â» ? 
1/2 Comparaison Ã  
x 
Dice On prÃ©dit* plus y que x ? 
1 Indice
7
 de 
Â« PrÃ©cision Â» 
On prÃ©dit plus 
x que y Jaccard  
                                                 
6
 On remarque une fois encore ici,  que des indices ont Ã©tÃ© redÃ©couverts par des auteurs diffÃ©rents au fil du temps, 
sans quâ€™aucune tentative de rapprochements avec des formalismes prÃ© existants  nâ€™ait Ã©tÃ© proposÃ©e.    
7
 Les indices de Rappel et de PrÃ©cision sont dÃ©finis explicitement et en extension au Â§ 4-2. 
 
 
RNTI-A-3- 231 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
(*) exemple dâ€™un tel indice : le ratio suivant :      
                                      
[ ] y)01(x,
2
1y)01(x,y)10(x,
2
1y)11(x,
y)11(x,y)(x,S
+++
=
 
dont le dÃ©nominateur est voisin de celui de Dice,  mais pondÃ¨re davantage que dans Dice les 
situations dâ€™erreurs 01(x,y) . En cas de disjonction complÃ¨te, cet indice particulier de la fami-
lle Tversky vaut:  
                                                   
y)11(x,3.m
y)2.11(x,y)S(x,
âˆ’
=
 
Ce qui montre  quâ€™il  est bien intermÃ©diaire entre lâ€™indice  de Jaccard et celui de Rappel, par 
ailleurs sa borne de Solomon-Fortier donne une majoritÃ© au 3/5 Ã¨me: 
                                                   
m
5
3y)11(x,
2
1
y)11(x,3.m
y)2.11(x,y)S(x, â‰¥â‰¥
âˆ’
=
 
4.1.4 PropriÃ©tÃ©s des Indices du Type I dans les cas de Disjonction des Variables 
     Il est important de comprendre Ã  ce moment prÃ©cis du discours que la disjonction com-
plÃ¨te permet des simplifications considÃ©rables des propriÃ©tÃ©s des indices. En effet dans un 
souci de gÃ©nÃ©ralitÃ©, rappelons que le seul cas qui nâ€™entre pas dans la catÃ©gorie de situations Ã  
Â« disjonction complÃ¨te Â», est le cas de donnÃ©es de Â« prÃ©sence-absence Â» pures. Cependant, 
nous avons vu que, dans ce cas, par un artifice logique qui consiste Ã  dÃ©doubler chaque pa-
ramÃ¨tre de description par son inverse (oÃ¹ Ã  1 pour le dit paramÃ¨tre correspond 0 de lâ€™inverse, 
et vice versa), on se ramÃ¨ne Ã  une situation de disjonction complÃ¨te, avec P nombre total de 
descripteurs,  donnÃ© par P=2m (oÃ¹ m est le nombre de descripteurs initiaux et P le nombre 
nouveau de descripteurs aprÃ¨s lâ€™action de dÃ©doublage. De ce fait le recours aux propriÃ©tÃ©s 
engendrÃ©es par la structure de disjonction complÃ¨te devient un passage obligÃ© qui prend toute 
son importance.   
Ainsi les propriÃ©tÃ©s que nous allons proposer sont-elles quasi gÃ©nÃ©rales . 
4.1.4.1 Liste de propriÃ©tÃ©s des Indices du Type I  dans les Cas de Disjonction  des Va-
riables 
Dans le cas particulier de tableaux disjonctifs complets, lâ€™indice de Dice (du fait de son 
entiÃ¨re similitude Ã  la constante Â« m Â» prÃ¨s, avec le tableau de Condorcet) vÃ©rifie la pro-
priÃ©tÃ© de Â« transitivitÃ©  gÃ©nÃ©ralisÃ©eÂ» suivante (voir Â§ 1.1 sur lâ€™axiomatique) : 
 
PropriÃ©tÃ© nÂ°6 : Lâ€™Indice de Dice vÃ©rifie la propriÃ©tÃ© de Â« TransitivitÃ© GÃ©nÃ©ralisÃ©e Indicielle Â»  
 
(f 31)                        zy,  x,   1z)(x,Sz)(y,Sy)(x,S ddd âˆ€â‰¤âˆ’+   
Il suffit pour cela de diviser la formule (f 6) relative au tableau de Condorcet par  Â«mÂ» . 
Par ailleurs, nous avions vu ( voir formule (f 16â€³) que lorsque le nombre de Â« 1 Â» du profil 
de x,  âˆ€ x , Ã©tait une constante, alors: 
                                     Sd(x,y)= 1-1/2d2(x,y) (oÃ¹ d2 (x,y) est une mÃ©trique euclidienne) 
Comme dans le cas de la disjonction complÃ¨te, nous avons 11(x,x)=m,  âˆ€ x, nous sommes 
tout Ã  fait dans un cas dâ€™application de cette formule (f 16â€³). Nous venons de montrer en 
RNTI-A-3 - 232 -
                                                                                                    F. Marcotorchino 
 
utilisant le recours Ã  lâ€™Ã©criture CondorcÃ©enne une autre faÃ§on de voir que   lâ€™indice de Dice  
Ã©tait mÃ©trisable car il vÃ©rifie la TGI (TransitivitÃ© GÃ©nÃ©ralisÃ©e Indicielle)  
 
PropriÃ©tÃ© nÂ°7 : Lâ€™Indice de Jaccard vÃ©rifie la propriÃ©tÃ© de Â« TransitivitÃ© GÃ©nÃ©ralisÃ©e Indi-
cielle Â»  
De la  mÃªme faÃ§on en remplaÃ§ant la valeur de lâ€™indice de Dice par son expression homo-
graphique en fonction des autres indices, il vient  par exemple la relation suivante pour 
lâ€™indice de Jaccard :  
(f 32)        [ ][ ][ ] zy,x,   3z)(x,S z)(y,S1 y)(x,S1
4
1
 -  1z)(x, Sz)(y,Sy)(x,S jjjjjj âˆ€+âˆ’âˆ’â‰¤âˆ’+    
En fait lâ€™indice Sj vÃ©rifie bien la Â« transitivitÃ© gÃ©nÃ©ralisÃ©e indicielle Â» (donc est mÃ©trisable) 
car Â« 1 Â» est bien une borne du premier membre de (f 32) , en effet  la quantitÃ© 
 Â¼(1- Sj (x,y))(1- Sj(y,z))( Sj(x, z)+3)  est toujours positive du fait que Sj(x,y) â‰¤ 1 âˆ€  Â« x et y Â» .  
 
En fait pour dÃ©montrer ce rÃ©sultat de faÃ§on directe  et trÃ¨s facilement, il suffisait  dâ€™utiliser 
le  ThÃ©orÃ¨me nÂ°1 qui stipule que  si un indice Su(x,y)  sâ€™exprime sous la forme :  
                                                     
1y)](x,S[1
y)(x,S
y)(x,S
d
d
u
+âˆ’
=
  
par rapport Ã  un indice mÃ©trisable  Sd (x,y),  alors  il est lui mÃªme Â« mÃ©trisable Â» .   
En fait lâ€™indice de Dice Ã©tant mÃ©trisable, comme lâ€™indice de Jaccard sâ€™Ã©crit (voir formule  
(f 21)) 
)y,x(S2
)y,x(S)y,x(S
d
dj
âˆ’
=
 , il vÃ©rifie les conditions  dâ€™applications du ThÃ©orÃ¨me nÂ°1, avec 
Î²=1  dans ce cas,  (cqfd) .  
Donc  Sj(x,y)  est  mÃ©trisable.  
Quoiquâ€™on puisse se passer dâ€™utiliser lâ€™inÃ©galitÃ© (f 32) pour obtenir ce rÃ©sultat, lâ€™inÃ©galitÃ© 
(f 32) nous permet  nÃ©anmoins de dÃ©duire  une relation trÃ¨s surprenante sur lâ€™indice de 
distance dj(x,y)=1-Sj(x,y)  associÃ©, en effet en remplaÃ§ant :  Sj(x,y) par 1-dj(x,y) , il vient : 
 
(f32â€™)          
zy,x, z)(x,z).d(y,y).d(x,d
4
1
  z)(y,y).d(x,d - z)](y,dy)(x,d [z)(x,d jjjjjjjj âˆ€++â‰¤  
soit encore:  
(f 33)                            
zy,x,
z)(y,y)d(x,d
4
11
 z)(y,y).d(x,d - z)](y,dy)(x,d [
z)(x,d
jj
jjjj
j âˆ€
âˆ’
+
â‰¤
                         
 Sous cette forme, on voit que le deuxiÃ¨me membre de cette inÃ©galitÃ© est indÃ©pendant de 
dj(x,z). En effet comme chacune des valeurs d(x,y) et d(x,z) â‰¤ 1,  de fait  la division par  
 (1-1/4dj(x,y)dj(y,z)) qui est une valeur > 0, donc diffÃ©rente de 0, est possible. Ceci permet 
dâ€™avoir une borne meilleure que celle de lâ€™inÃ©galitÃ© triangulaire  usuelle.  
  
La soustraction par une quantitÃ© positive permet dans les formules (f 32), (f32â€™) et (f33)  
dâ€™avoir une borne plus fine permettant souvent lâ€™obtention dâ€™une Ã©galitÃ© comme le montre 
le petit exemple suivant : 
 
 
 
 
 
RNTI-A-3- 233 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
 
x 1 0 0 0 1 0 1 0 0 0 1 
y 1 0 0 0 0 1 1 0 0 0 1 
z 0 1 0 0 0 1 0 1 0 0 1 
 
 
Ici on a affaire Ã  4 variables  disjonctivÃ©es (ayant respectivement : 3; 3; 3; et 2 modalitÃ©s), dâ€™oÃ¹ m=4 
Lâ€™indice de Jaccard entre les diffÃ©rents individus vaut : 
Sj(x,y) = 3/5 ;  Sj(y,z) =  2/6;  Sj(x,z) =1/7 
Le premier membre de lâ€™inÃ©galitÃ© vaut : 3/5 +2/6 -1/7 = 166/210 
Le deuxiÃ¨me membre de lâ€™inÃ©galitÃ© vaut 1 â€“ Â¼( 2/5.4/6. 22/7)= 1-44/210= 166/210 
De mÃªme au niveau de la formule (f 29â€³) il vient : 
                                      7
6
28
24
6
4
5
2
4
1
6
4
5
2
6
4
5
2
7
6
1
==
Ã—Ã—âˆ’
Ã—âˆ’+
â‰¤   
Ce qui montre que dans ce cas, les inÃ©galitÃ©s prÃ©cÃ©dentes deviennent des  Ã©galitÃ©s.  
Nous avions dâ€™ailleurs  une Ã©galitÃ© dans le cas de la formule valable pour lâ€™indice de Dice puisque 
pour cet exemple :  
Sd (x,y) = Â¾ ;  Sd(y,z) = Â½;  Sd(x, z) = Â¼ , dâ€™oÃ¹ puisque Â¾+Â½ -Â¼ =1, 
on a bien :  
   1z)(x,Sz)(y,Sy)(x,S ddd =âˆ’+   
En fait on peut dÃ©montrer que si lâ€™inÃ©galitÃ© (f 31) est une Ã©galitÃ© alors lâ€™inÃ©galitÃ© (f 33) sera Ã©gale-
ment une Ã©galitÃ© . 
  
Comme prÃ©cÃ©demment  pour lâ€™indice de  Jaccard , en jetant un oeil Ã  la formule  (f 21) on 
voit que lâ€™Indice dâ€™Anderberg sâ€™Ã©crit comme une fonction homographique particuliÃ¨re de 
lâ€™indice de Dice, Ã  savoir : 
)y,x(S.34
)y,x(S)y,x(S
d
d
an
âˆ’
=
, dans ce cas,  en appliquant de nouveau  le 
ThÃ©orÃ¨me nÂ°1  (page 3)  on voit que cet indice  vÃ©rifie les conditions dâ€™applications du 
ThÃ©orÃ¨me nÂ°1, avec une valeur de Î²=3. . De ce fait lâ€™Indice dâ€™Anderberg vÃ©rifie la propriÃ©-
tÃ© 8 : 
PropriÃ©tÃ© nÂ°8  :  Lâ€™indice dâ€™Anderberg  est un indice Â« mÃ©trisable Â».   
De plus si le terme 11(x,x)=11(y,y) est constant (exemple sâ€™il est issu de tableaux disjonctifs 
complets), les indices de Jaccard et dâ€™Anderberg sont mÃ©trisables euclidiens .    
 
4.2 Indices du Groupe I, Type II (indices obtenus comme fonction des 
ratios de Â« Rappel Â» et de Â« PrÃ©cision Â») 
      Par analogie  avec la Â« recherche documentaire Â», et en droite ligne avec les remarques 
liÃ©es Ã  la prÃ©sentation de lâ€™indice gÃ©nÃ©ral de Tversky  (dissymÃ©trie des influences),  on 
dÃ©finit les ratios dits de Â« PrÃ©cision Â» Â« P Â»et de Â« Rappel Â» Â« R Â» , respectivement,  
comme les quantitÃ©s: 
 
RNTI-A-3 - 234 -
                                                                                                    F. Marcotorchino 
 
  (f 34)                    
)y,x(10)y,x(11
)y,x(11P
+
=
     et
)y,x(01)y,x(11
)y,x(11R
+
=
 
En effet  supposons que nous obtenions : x comme rÃ©sultat dâ€™une recherche sur un do-
maine y,  la quantitÃ© : 10(x,y) peut Ãªtre considÃ©rÃ©e comme un facteur de Â« bruit Â»,   on 
gÃ©nÃ¨re dans x des Â« items Â» (des valeurs 1 de x qui ne correspondent pas Ã  ce quâ€™on aurait 
du  sâ€™attendre par rapport Ã    y ( 0 de y correspondant Ã  des 1 de x)), ces items parasites de x 
qui nâ€™ont pas de correspondants dans y peuvent Ãªtre considÃ©rÃ©s comme du Â« bruit Â» que  
lâ€™on  a gÃ©nÃ©rÃ©  Ã  tort, lors dâ€™un processus de recherche documentaire. Inversement la quan-
titÃ© 01 (x,y) peut Ãªtre considÃ©rÃ©e comme du Â« silence Â», on Â« rate Â» par x de lâ€™existant sur y 
câ€™est la raison du mot Â« silence Â». La prÃ©cision est dâ€™autant plus forte quâ€™on ne crÃ©e pas de 
bruit  en effet si 10(x,y)=0 la prÃ©cision est maximale, inversement si le silence est Ã©gal Ã  0, 
si 01(x,y)=0,  le rappel est alors Ã©gal Ã  1, on rÃ©cupÃ¨re donc par les Â« matchings Â» de x 
lâ€™ensemble de ce que lâ€™on devait trouver sans oubli sur y. 
Bien que cette prÃ©sentation des ratios P et R ne soit quâ€™analogique, la rÃ©fÃ©rence au domaine 
de la recherche documentaire, (on dirait de nos jours Â« recherche  Internet Â»), permet de se 
faire une idÃ©e concrÃ¨te de la signification intuitive de ces ratios. Ayant intuitivement la 
connaissance dâ€™une Â« signification Â» de ces ratios, nous allons voir quâ€™ils jouent un rÃ´le 
important dans un certain nombre dâ€™indices du Groupe I en particulier leurs diffÃ©rentes 
moyennes. On appellera Groupe I, Type II , le regroupement des indices appartenant Ã  
cette famille trÃ¨s Â« structurÃ©e Â» dâ€™indices. 
4.2.1 Indices de Type II-A (Indices obtenus comme diffÃ©rentes Â« moyennes Â» des 
ratios de Â« rappel Â» et de Â« prÃ©cision Â») 
4.2.1.1 Indice de Kulczynski (1923) 
Lâ€™indice de Kulczynski a Ã©tÃ© dÃ©fini par lâ€™auteur (voir  Kulczynski (1927)) comme la 
Â« moyenne arithmÃ©tique Â» des quantitÃ©s P et R. Il sâ€™Ã©crit donc:    
                                                                    
(f 35)            [ ] 





+
+
+
=+= )y,x(01)y,x(11
)y,x(11
)y,x(10)y,x(11
)y,x(11
2
1RP
2
1)y,x(S k  
 
A   cette occasion, on voit que si lâ€™on note: 
 11(x,x)=Somme des valeurs â€œ1â€ du profil de x   
 11(y,y)=la somme des valeurs â€œ1â€ du profil de y, 
alors :  
                           [ ] 





+=+= )y,y(11
)y,x(11
)x,x(11
)y,x(11
2
1RP
2
1)y,x(S k  
 
soit encore:        [ ] 





+=+= )y,y(11
1
)x,x(11
1
2
)y,x(11RP
2
1)y,x(S k                
En posant : 
y)]11(y, x),[11(x,MH
1
y)11(y,
1
x)11(x,
1
2
1
=





+
 (moyenne harmonique des 1 de x et 
des 1 de y) 
Lâ€™indice de Kulczynski sâ€™Ã©crit Ã©galement sous la forme suivante, sous laquelle il est Ã©ga-
lement connu:  
RNTI-A-3- 235 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
        
(f 36)                                  
)]y,y(11 ),x,x(11[MH
)y,x(11)y,x(Sk =  
Cet indice varie de 0 Ã  1, il vaut: 
â€¢ 1 si  10(x,y)=01(x,y)=0 
â€¢ 0 si  11(x,y)=0 
 
PropriÃ©tÃ© NÂ°9: PropriÃ©tÃ© de lâ€™indice de Kulczynski en cas de Disjonction complÃ¨te 
Comme nous lâ€™avons vu pour les indices du Groupe I -Type I, lâ€™Ã©talonnage dâ€™un indice par 
rapport Ã  ses valeurs en cas de disjonction complÃ¨te est un moyen efficace de mesurer la 
â€œvaleur intrinsÃ¨queâ€ du dit indice par rapport Ã  son pouvoir de discrimination . En effet en 
utilisant le processus suivant dans lâ€™ordre prÃ©cis  indiquÃ©: 
a) Donner lâ€™expression de lâ€™indice en cas de disjonction complÃ¨te, 
b) Calculer la borne induite sur la quantitÃ© 11(x,y), (seule quantitÃ© rÃ©ellement variable 
du tableau de contingence dans les conditions de disjonction complÃ¨te) par rapport  
Ã  la rÃ¨gle de Solomon-Fortier, que nous avons indiquÃ©e prÃ©cÃ©demment 
c) Evaluer cette borne qui permet une sorte dâ€™Ã©talonnage pour un indice par rapport 
aux autres.   
 
Appliquons le principe:a)bc sur lâ€™indice de Kulczynski, il vient: 
Tout dâ€™abord rappelons les conditions que vÃ©rifient les cases du tableau de contingence Te-
trachorique si il y a â€œDisjonction complÃ¨teâ€: En cas de disjonction complÃ¨te on a vu en effet 
que le nombre de variables Â« m Â»  Ã©tait tel que  :   
                            [ ] m)y,x(01)y,x(10
2
1)y,x(11 =++  
dâ€™autre part on a  par dÃ©finition :            P)y,x(01)y,x(10)y,x(00)y,x(11 =+++  
et bien sÃ»r et de faÃ§on Ã©vidente :             10(x,y)=01(x,y) =m-11(x,y) 
Dâ€™oÃ¹ lâ€™expression nouvelle de lâ€™indice de Kulczynski: 
 
                         [ ] )y,x(S
m
)y,x(11
m
)y,x(11
m
)y,x(11
2
1RP
2
1)y,x(S dk ==



+=+=  
 
On reverra les consÃ©quences quâ€™impliquent ce rÃ©sultat au paragraphe Â§4.2.3.2.   
4.2.1.2 Indice dâ€™OchiaÃ¯ (1957) 
Lâ€™indice dâ€™Ochiai8 se dÃ©finit comme la  Â« moyenne gÃ©omÃ©trique Â» des indices P et R, sa 
paternitÃ© est attribuÃ©e par Sokal et Sneath au zoologue Japonais Ochiai (1957), qui lâ€™aurait 
introduit, comme un Â« cosinus Â» entre profils binaires  de description dichotomique en 
classification dâ€™espÃ¨ces  de poissons   dÃ¨s 1957,  il sâ€™Ã©crit donc :  
                                                 
8
 Lâ€™indice connu sous le nom dâ€™indice de Sorgenfrei , introduit un an plus tard que celui de OchiaÃ¯, par T. Sorgen-
frei (1958) nâ€™est en fait que le carrÃ© de lâ€™indice dâ€™OchiaÃ¯. 2
O
2
Sorg )]y,x(S[)y,y(11)x,x(11
)y,x(11S =
+
=
 et nâ€™a pas dâ€™intÃ©rÃªt 
particulier, sinon dâ€™Ãªtre infÃ©rieur Ã  celui de Jaccard, et bien entendu Ã  celui dâ€™OchiaÃ¯. Par ailleurs, mÃªme si lâ€™indice 
dit Â«  dâ€™Ochiai Â»  ait Ã©tÃ© atribuÃ© Ã  Ochiai, il semble quâ€™il ait Ã©tÃ© introduit antÃ©rieurement   par H. Driver  et A. 
Kroeber , voir H. Driver et A. Kroeber  (1932)  
RNTI-A-3 - 236 -
                                                                                                    F. Marcotorchino 
 
 
(f 37)                               
            
)]y,x(01)y,x(11)][(y,x(10)y,x(11[
)y,x(11R.P)y,x(So
++
==
  
 
Dâ€™autre part en utilisant  la dÃ©finition des â€œ1â€ de x et des â€œ1â€ de y, lâ€™indice dâ€™Ochiai   sâ€™Ã©crit 
Ã©galement:  
 (f 38)                    
y)]x),11(y,[11(x,MG
y)11(x,
y)x)11(y,11(x,
y)11(x,y)(x,S o ==
 
Sous cette forme, il peut sâ€™interprÃªter comme un â€œcosinusâ€ entre les profils de x et de y 
 
(sous cette forme, Ã©galement, on voit quâ€™il ne diffÃ©re formellement de lâ€™indice de Kulc-
zynski, que par le choix dâ€™une moyenne gÃ©omÃ©trique9 plutÃ´t que dâ€™une moyenne harmoni-
que au dÃ©nominateur). Par ailleurs la distance dÃ©finie par: y)(x,S2(1y)(x,d oo âˆ’=   est ap-
pelÃ©e â€œdistance dâ€™Ochiaiâ€ dans la littÃ©rature10, ce qui fait de lâ€™Indice dâ€™Ochiai un indice 
mÃ©trisable   
 
PropriÃ©tÃ© NÂ°10: PropriÃ©tÃ© de lâ€™indice dâ€™Ochiai en cas de Disjonction complÃ¨te 
Comme nous lâ€™avons vu pour lâ€™indice de Kulczynski, appliquons Ã  lâ€™indice dâ€™Ochiai le 
principe a)b)c) dÃ©fini au Â§ prÃ©cÃ©dent. On obtient la nouvelle formulation de lâ€™indice 
dâ€™Ochiai: 
 
(f 38)                                 )y,x(S
m
)y,x(11
m
)y,x(11)y,x(S d2o ===
 
                                                 
9
 Il est intÃ©ressant de constater  dans ce cas particulier (nous lâ€™avions dÃ©jÃ  vu pour lâ€™indice de Van Rijsbergen), que 
la littÃ©rature scientifique produit un nombre considÃ©rable dâ€™articles retrouvant des Ã©vidences pour certains, et des 
progrÃ¨s scientifiques  pour les autres,  comme le montre la citation suivante extraite dâ€™un article de G.M. Maggira, 
J.D. Petke et J. Mestres, paru en  Avril 2002 dans la  Revue Â« Journal of Mathematical Chemistry Â», Vol 31, 
NÂ°3,(MPM 2002) â€¦  Â« A formalism is presented that incorporates the entirety of all field-based molecular similarity 
indices of general form Sij=Î©ij/h(ii,jj), where the numerator is given by the inner product or â€œoverlapâ€ of field 
functions Fi and Fj corresponding to the ith and jth molecules, respectively, and the denominator is given by a 
suitable mean function of the self-similarities ii and jj. This family of similarity indices includes the index initially 
introduced by CarbÃ³ nearly twenty years ago, where h(ii, jj) is taken to be the geometric mean of ii and jj, and the 
well-known indices due to Hodgkin and Richards, and Petke, where h(ii,jj) is taken to be the arithmetic mean 
and maximum of ii and jj, respectively. Two new indices based upon the harmonic mean and minimum of ii and jj 
are also defined, and it is demonstrated that the entire set of field-based similarity indices can be generated from a 
one-parameter family of functions, called generalized means, through proper choice of the parameter value and 
suitable limiting procedures. Ordering and rigorous bounds for all of the indices are described as well as a number of 
inter-relationships among the indices. The generalization of field-based similarity indices, coupled with the relation-
ships among indices that have been developed in the present work, place the basic theory of these indices on a more 
unified and mathematically rigorous footing that provides a foundation for a better understanding of the quantitative 
aspects of field-based molecular similarityÂ». Nous voyons que Â« nos amis chimistes Â» retrouvent des propriÃ©tÃ©s 
Â« indicielles Â» connues depuis la crÃ©ation des indices de Kulczynski ou Ochiai  (depuis 80 ans pour lâ€™un et 63 ans 
pour lâ€™autre..) 
 
 
10
 Voir en particulier page 521 du remarquable   livre de F. Caillez et J.P. Pages Â« Introduction Ã  lâ€™Analyse des 
DonnÃ©es Â» aux Ã©ditions SMASH   voir (F. Caillez et J.P. Pages (1976)) 
RNTI-A-3- 237 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
La borne Ã©tant  donnÃ©e par le milieu de lâ€™intervalle de variation qui est: (0,1), on doit com-
parer lâ€™indice dâ€™Ochiai Ã  la borne de Solomon Fortier qui vaut ici 1/2 , ceci implique : 
11(x,y) â‰¥ m/2 
On retrouve ici le fait que la borne de Solomon Fortier induit la rÃ¨gle de la majoritÃ© simple 
de Condorcet. 
   
 4.2.1.3 Indice de Moyenne Harmonique de P et R 
 
Cet indice que nous noterons Sh(x,y) correspond Ã  la moyenne harmonique du Rappel et 
de la PrÃ©cision 
Il est donc dÃ©fini par:   
(f 39)                         




+=
R
1
P
1
2
1
)y,x(S
1
h
       soit en dâ€™autres termes :  
                                                                                       
                             
y)01(x,y)11(x,
y)11(x,
y)10(x,y)11(x,
y)11(x,
y)01(x,y)11(x,
y)11(x,
x
y)10(x,y)11(x,
y)211(x,
RP
2.P.Ry)(x,S h
+
+
+
++
=
+
=
   
                            
Soit aprÃ¨s de premiÃ¨res simplifications: 
 
)]y,x(01)y,x(10)y,x(11.2)[y,x(11
)y,x(11.2
RP
R.P.2)y,x(S
2
h
++
=
+
=
 
 
 
Puis en simplifiant NumÃ©rateur et DÃ©nominateur simultanÃ©ment, et les divisant par 2,  il 
vient : 
 
    (f 40)     )y,x(S
)]y,x(01)y,x(10[
2
1)y,x(11
)y,x(11
)]y,x(01)y,x(10)y,x(11.2[
)y,x(11.2)y,x(S dh =
++
=
++
=
 
 
En fait, lâ€™indice de moyenne harmonique11 entre P et R nâ€™est autre que lâ€™indice de Dice, 
que nous avions dÃ©jÃ  dÃ©fini prÃ©cÃ©demment (voir formule( f16)) . 
En utilisant le passage aux Â« 1 Â» de x et Â« 1 Â» de y, on voit que lâ€™indice de Dice peut sâ€™Ã©crire 
Ã©galement : 
                                                 
11On  a dÃ©jÃ  vu que lâ€™on peut gÃ©nÃ©raliser lâ€™indice de Moyenne Harmonique câ€™est ce quâ€™a proposÃ© C.J. Van Rijbergen  
(1979 )  en introduisant une moyenne  pondÃ©rÃ©e du type :  1 et
RP
.P.Ry)(x,Svr =+
+
=
,  (dâ€™ailleurs on  aurait 
put le faire Ã©galement pour les autres moyennes, mais lâ€™intÃ©rÃªt est faible en particulier au niveau du concept sous-
jacent  et de la possibilitÃ© dâ€™ interprÃ©tation simple des influences rÃ©ciproques de P et R).   
 
 
RNTI-A-3 - 238 -
                                                                                                    F. Marcotorchino 
 
(f 41)                          
)]y,y(11),x,x(11[MA
)y,x(11
)]y,y(11)x,x(11[
)y,x(11)y,x(S
2
1d
=
+
=
 
(oÃ¹ MA dÃ©signe la moyenne ArithmÃ©tique des â€œ 1â€ de x et des â€œ1â€ de y) , ceci, en plus des 
remarques et des propriÃ©tÃ©s introduites aux paragraphes prÃ©cÃ©dents, montre bien le carac-
tÃ¨re Â« central Â» de lâ€™indice de Dice, puisquâ€™il Ã©tait dÃ©jÃ  membre du Groupe I, Type I.   
Comme il est connu que :  
                     Moyenne Harmonique  Moyenne GÃ©omÃ©trique  Moyenne ArithmÃ©tique, 
Nous avons donc :  
                                      ( )RP 
2
1
   R.P     
RP
R.P2
+â‰¤â‰¤
+
       :  
                                
On obtient de ce fait les inÃ©galitÃ©s suivantes entre cette sÃ©rie de 3 indices : 
                                             y x,       )y,x(S)y,x(S)y,x(S kod âˆ€â‰¤â‰¤      
 De plus, on a Ã©galement:                             
                                                     )y,x(S   )y,x(S  )y,x(S kdo =  
 
Lâ€™indice dâ€™Ochiai est la moyenne gÃ©omÃ©trique de lâ€™indice de Dice et de lâ€™indice de Kulc-
zynski. 
 
Le tableau suivant rÃ©capitule les propriÃ©tÃ©s de ces 3 indices : 
 
 
 
En fonction de P et de R En fonction de 11(x,x) et 11(y,y) 
DICE MH(P,R) 11(x,y)/MA(11(x,x),11(y,y)) 
OCHIAI MG(P,R) 11(x,y)/MG(11(x,x),11(y,y)) 
KULCZYNSKI MA(P,R) 11(x,y)/MH(11(x,x),11(y,y) 
  
Si nous regardons en dÃ©tail  et dÃ©veloppons les expressions des indices dâ€™Ochiai et de  
Kulczynski , on peut montrer que  ces deux indices peuvent sâ€™Ã©crire en fonction des quan-
titÃ©s     
                Â²  =  (11(x,y) + Â½ (10(x,y) + 01(x,y)) )Â² et  Â² = Â¼ (10(x,y)  - 01(x,y))Â² 
 
Selon les formules suivantes: 
 
                                  
22k 
y)11(x, )y,x(S
âˆ’
=
    et   
22o 
y)11(x, )y,x(S
âˆ’
=
  
 
 
RNTI-A-3- 239 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
4.2.2 PropriÃ©tÃ©s des indices du Groupe I, Type II-A, en cas de Disjonction Com-
plÃ¨te 
PropriÃ©tÃ© nÂ°11: Dans le cas particulier, oÃ¹ lâ€™on travaille sur des matrices disjonctives com-
plÃ¨tes, ces trois indices prÃ©cÃ©dents sont Ã©gaux  et en particulier leurs expressions sont Ã©quiva-
lentes Ã  celle de lâ€™indice de Dice. 
En effet du fait que (10(x,y) + 01 (x,y)) = 2(m- 11(x,y)) ( voir formule (i) Â§3.1.2.1),, et que 
dâ€™autre part, il y a autant de configurations 10(x,y) que de configurations 01(x,y),  on a 
01(x,y) = 10(x,y) ; dÃ¨s lors la quantitÃ© 2 est Ã©gale Ã  0. Comme =0, il vient:  
 
                         
k
y)11(x, )y,x(S =     et   

)y,x(11

y)11(x, )y,x(S
2o
==
   
En remplaÃ§ant  par sa valeur, on retrouve bien la dÃ©finition de lâ€™indice de Dice. 
On vÃ©rifie bien de ce fait  la PropriÃ©tÃ© sus-dite :    
                                         Sd(x,y) = So(x,y) = Sk (x,y) 
 
4.3 Indices du Groupe I, Type II-B (indices obtenus comme autres fonc-
tions des ratios de Â« Rappel Â» et de Â« PrÃ©cision Â») 
4.3.1 Indice de moyenne harmonique quadratique normÃ©e de  P, R 
Cet indice notÃ©  SN(x,y) , est dÃ©fini par :                                                                            
                                             
(f 42)     
22
22N
Q
1
P
1
2
)]y,x(01)y,x(11[)]y,x(10)y,x(11[
y).11(x,2)y,x(S
+
=
+++
=
       
 
Cet indice varie bien de 0 Ã  1, il vaut 1 si 01(x,y)=10(x,y) =0  et 0 si 11(x,y) = 0. 
En utilisant les notations en Â² et Â² dÃ©finies prÃ©cÃ©demment, on peut montrer que cet indice 
se simplifie selon la formule suivante: 
22N 
y)11(x, )y,x(S
+
=
    et  si lâ€™on compare son expression Ã  celle de lâ€™indice dâ€™Ochiai       
22
o

y)11(x, )y,x(S
âˆ’
=
  
une relation Ã©vidente est dÃ©rivable  de ce qui prÃ©cÃ¨de, il suffit de comparer les dÃ©nomi-
nateurs, puisque       22  +  22  âˆ’ on voit que : 
 
(f 43)                                    )y,x(S   )y,x(S oN â‰¤   
  
De plus , on a  de faÃ§on complÃ©mentaire le rÃ©sultat suivant :    
                                             
[ ] [ ] [ ]2
2
2
N
2
o y)11(x,
.2
)y,x(S
1
)y,x(S
1 
=+             
RNTI-A-3 - 240 -
                                                                                                    F. Marcotorchino 
 
(cette derniÃ¨re quantitÃ© Ã©tant 2 fois lâ€™inverse de lâ€™indice de Dice au carrÃ©) , on a donc la 
relation suivante liant ces trois indices :  
(f 44)                                     
[ ] [ ] [ ] 





+= 2
N
2
o
2
d )y,x(S
1
)y,x(S
1
2
1
)y,x(S
1 
  
Sous cette forme il apparaÃ®t clairement que  lâ€™indice de Dice au carrÃ© est la moyenne 
harmonique de lâ€™indice N au carrÃ©  et de lâ€™indice dâ€™Ochiai au carrÃ©. 
Dâ€™autre part  on peut montrer que lâ€™indice SN(x,y) sâ€™exprime en fonction de lâ€™indice de 
Dice, lâ€™indice de Kulczynski et de lâ€™indice dâ€™Ochiai suivant les deux formules suivantes :  
                                        
(f 45)               












âˆ’
=




âˆ’
=
2
o
d
d
k
d
d
N
)y,x(S
)y,x(S2
)y,x(S
)y,x(S
)y,x(S2
y)(x,.S)y,x(S
       
On constate, une fois encore  le rÃ´le Â« central Â» de lâ€™indice de Dice, du fait de son rÃ´le de 
Â« moyenne Harmonique  carrÃ©e Â» de SN(x,y) et  So(x,y) ,  et compte tenu  de la formule 
(f 43),  liant ces deux quantitÃ©s et du fait que So(x,y)â‰¥0 et SN(x,y)  â‰¥ 0, on tire la relation 
dâ€™inÃ©galitÃ©s  suivante :   
 
(f 46)                                             SN(x,y) â‰¤ Sd(x,y) ) â‰¤ So(x,y) 
 
comme par ailleurs , nous avons vu  au paragraphe prÃ©cÃ©dent que : 
                                                     Sd(x,y) â‰¤  So(x,y) ) â‰¤ Sk(x,y)  
ceci implique   que dans le cas gÃ©nÃ©ral: 
 
(f 47)                                       SN (x,y) â‰¤ Sd(x,y) â‰¤ So(x,y) â‰¤ Sk(x,y) 
4.3.2 Indices du Min et du Max de P et de R  
Ces indices que nous noterons SMin(x,y) et SMax(x,y) varient Ã©galement de 0 Ã  1 ils  
sâ€™Ã©crivent : 
                                                     SMin(x,y) = Min  (P,R)                                        
                                                     SMax(x,y) = Max (P,R)   
Le premier de ces deux indices est connu dans la littÃ©rature anglo-saxonne sous le nom 
dâ€™indice de Â« Braun Blanquet Â»,  (voir J. Braun-Blanquet  (1932)),  utilisÃ© par lâ€™auteur en 
phytosociologie Ã©galement, le  second dâ€™entre eux SMax(x,y) est Ã©galement connu sous le 
nom dâ€™ Â« indice de Simpson Â» dans la littÃ©rature anglo-saxonne (voir G. Simpson (1943)), 
introduit en 1943 par lâ€™auteur,  il est surtout utilisÃ© dans le domaine de la similaritÃ© molÃ©-
culaire.   
Comme les numÃ©rateurs sont Ã©gaux, et comme on a  la propriÃ©tÃ© suivante :                       
                 Min (a,b)=1/2(a + b] âˆ’1/2	a âˆ’b 	et    Max (a,b)=1/2(a + b) +1/2 	a âˆ’b 	, 
 
RNTI-A-3- 241 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
(f48) [ ])y,x(01)y,x(11),y,x(10)y,x(11Max
)y,x(11)y,x(SMin
++
=
    et         
[ ])y,x(01)y,x(11),y,x(10)y,x(11Min
)y,x(11)y,x(SMax
++
=
 
 
mais   comme : 
Max (11(x,y)+10(x,y), 11(x,y)+01(x,y))  = 1/2[2.11(x,y) + 10(x,y)+01(x,y)) +1/2	10(x,y)-01(x,y) 	 
Soit : 
Max (11(x,y)+10(x,y), 11(x,y)+01(x,y)) = Î± + Î²  oÃ¹ 
 Î± et Î²  ont Ã©tÃ© dÃ©finies prÃ©cÃ©demment :   =  (11(x,y) + Â½ (10(x,y) + 01(x,y)) ) et  
  = Â½ |10(x,y)  - 01(x,y)| 
de  mÃªme, 
Min (11(x,y) +01(x,y),11(x,y)+01(x,y)) =  Î± âˆ’ Î²   
 
DÃ¨s lors les nouvelles formulations de  SMin (x,y) et de   SMax(x,y)    sont les suivantes:  
                            

y)11(x,)y,x(SMin
+
=    et    

y)11(x,)y,x(SMax
âˆ’
=  
4.3.2.1   Quelques PropriÃ©tÃ©s des Indices du Min et du Max de P et R  
Si lâ€™on calcule les moyennes arithmÃ©tique,  gÃ©omÃ©trique et harmonique de  SMin (x,y) et de  
SMax (x,y) 
on obtient :  
[ ] )y,x(S

y)11(x,   2
2
1)y,x(S)y,x(S
2
1
k22MaxMin =







âˆ’
=+ ,  comme indiquÃ© au Â§ 4.2.1.3 
a) PremiÃ¨re PropriÃ©tÃ©:  
Lâ€™indice de Kulczynski est la Â« moyenne arithmÃ©tiqueÂ» des indices  )y,x(SMin  et 
)y,x(SMax   [ ])y,x(S)y,x(S 2
1)y,x(S MaxMink +=   
b) DeuxiÃ¨me  PropriÃ©tÃ©:  
De la  mÃªme faÃ§on , on peut montrer que lâ€™indice dâ€™Ochiai )y,x(So    est la Â« moyenne 
gÃ©omÃ©trique Â» de ces deux quantitÃ©s 
                                         )y,x(S )y,x(S)y,x(S MaxMino =  
 
En effet comme Max (P,R).Min (P,R) = PÃ—R , le rÃ©sultat prÃ©cÃ©dent sâ€™en dÃ©duit simplement. 
c) TroisiÃ¨me PropriÃ©tÃ©:  
De mÃªme on retrouve  un rÃ©sultat connu  pour la moyenne harmonique,  puisque comme 
nous lâ€™indique la formule :      
 
 (f 49)              






+=





+=



+= )y,x(S
1
)y,x(S
1
2
1
)R,P(Min
1
)R,P(Max
1
2
1
R
1
P
1
2
1
)y,x(S
1
MaxMinh
.    
On en dÃ©duit que dâ€™aprÃ¨s la formule (f 40),  lâ€™indice de Dice   est la moyenne harmonique   
des indices )y,x(SMin  et )y,x(SMax  sous la forme :   
RNTI-A-3 - 242 -
                                                                                                    F. Marcotorchino 
 
               






+= )y,x(S
1
)y,x(S
1
2
1
)y,x(S
1
MaxMind
 
4.3.2.2 Indice de Mac Connaughey (Variante CorrÃ©lative de lâ€™Indice de Kulczynski)  
   Cet indice,  qui aurait pu Ãªtre introduit plus tard  dans cet article, au Â§ 4.4, comme cas 
particulier  des indices du  Groupe  II-Type II,  car issu de valeurs calculables sur le ta-
bleau de contingence Tetrachorique, nâ€™est en fait aprÃ¨s simplification dâ€™Ã©criture quâ€™une 
variante Â« indice de corrÃ©lation Â»  de lâ€™indice de Kulczynski et , de fait, se doit dâ€™Ãªtre ratta-
chÃ© aux indices du Groupe I. En effet cet indice dont on trouvera mention dans  lâ€™article  
Boyce et Ellison  (2001) , sâ€™Ã©crit de la faÃ§on suivante :  
 (f 50)                    






++
âˆ’
=
y)]01(x,y)y)].[11(x,10(x,y)[11(x,
y)y).01(x,10(x,y)][11(x,y)(x,S
2
McC
 
 DonnÃ© sous cette forme,  lâ€™indice de Mac Connaughey semble Ãªtre un indice, nouveau   
qui varie de â€“1 Ã  +1 ( -1 si 11(x,y)=0, +1 si 10(x,y)=01(x,y)=0). En fait il nâ€™en est rien , il se 
dÃ©compose en deux  parties symÃ©triques et duales  relativement aux indices de Rappel et 
de PrÃ©cision.  En effet par un simple jeu dâ€™Ã©criture, on voit que cet indice sâ€™exprime en 
fonction de P et de R  selon la formule suivante : 
(f 51)                  [ ] 1y)(x,S21
2
RP2 1RPR)]P)(1(1RPy)(x,S kMcC âˆ’=âˆ’


 +
=âˆ’+=âˆ’âˆ’âˆ’=
 
Câ€™est donc une simple translation linÃ©aire de lâ€™indice de Kulczynski , il vaut 1 quand 
lâ€™indice de Kulczinski vaut 1 et il vaut â€“1 quand lâ€™indice de Kulczynski vaut 0.  
4.3.2.3 Indice  ou fonction F(Î³ ) de compromis P,R  
  Cette fonction,  qui est souvent utilisÃ©e par les spÃ©cialistes du TAL (Traitement et Analy-
se de la Langue) (voir J. Beney (2008)) comme â€œbonneâ€ mesure de compromis entre Rap-
pel et PrÃ©cision a Ã©tÃ© dÃ©finie,  par lâ€™expression:  
                                           
RP
1)P.R( y)(x,F 2
2

+
+
=
 
En divisant le numÃ©rateur et le dÃ©nominateur par la quantitÃ© : (Î³Â²+1), on voit que lâ€™on re-
trouve exactement lâ€™indice de Van Rijsbergen dÃ©fini en (f 30â€™) , une fois posÃ© : 
1
1et
1
 22
2
+
=
+
=
 on vÃ©rifie bien  dÃ¨s lors que  : Î±+Î²=1 et que: 
1poury)(x,Sy)(x,S
RP
P.R
RP
1)P.R( y)(x,F Tyvr2
2
 =+==
+
=
+
+
=
 
en conclusion par rapport Ã  la typologie que nous venons de faire,  cette fonction F 
nâ€™apporte rien de plus  que lâ€™Indice de Tversky Ã©crit sous la forme :  
                    
y)01(x,
1
1y)10(x,
1
y)11(x,
y)11(x,y)(x,S
22
2Ty
+
+
+
+
=
 
cependant on peut noter que:  F(1)=Indice de Dice , F(0)=PrÃ©cision, F(âˆ) =Rappel, en 
dehors de ce petit rÃ©sultat   cette Ã©criture est donc totalement Ã©quivalente Ã  celle de Tvers-
ky et nous ne conserverons pas cette fonction dans notre discussion finale.  . 
RNTI-A-3- 243 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
4.3.3 Bilan comparatif de positionnement des Indices du Groupe I 
PropriÃ©tÃ© nÂ°12: EgalitÃ© des indices en cas de disjonction complÃ¨te  
Dans le cas particulier, oÃ¹ lâ€™on travaille sur des matrices disjonctives complÃ¨tes, les trois 
indices du GROUPE I, Type II-B, auxquels on peut rajouter P et R (ils jouent en fait le 
rÃ´le de SMin(x,y) et  SMax(x,y) suivant que lâ€™un est supÃ©rieur Ã  lâ€™autre) sont Ã©gaux  et en parti-
culier leur expression est Ã©quivalente Ã  celle de lâ€™indice de Dice et vaut :  11(x,y)/Î± 
Ceci sâ€™obtient en posant Î²=0 dans chacune des formules en Î± et Î² relatives Ã  ces indices . 
Dans le cas disjonctif complet on a donc: 
               Sd(x,y)=So(x,y)=Sk (x,y) = SN(x,y) = SMax(x,y) = SMin(x,y) =P = R 
Une consÃ©quence  Ã©vidente,   est que,   de facto, tous ces indices du Groupe I Type II 
sont, en cas de disjonction complÃ¨te, de la forme:  
                                                             S=1-(1/2)d2  
 et dÃ¨s lors sont des indices de similaritÃ©s mÃ©trisables euclidiens  
 
 
PropriÃ©tÃ© nÂ°13: Ordonnance des  Indices du Groupe I au sens GÃ©nÃ©ral 
Dans le cas gÃ©nÃ©ral  nous obtenons lâ€™inÃ©galitÃ© suivante entre tous les indices du Type II: 
 
            SMin(x,y)  â‰¤  SN(x,y)  â‰¤  Sd(x,y)   â‰¤  So(x,y)  â‰¤ Sk(x,y)  â‰¤  SMax(x,y) 
Si nous rajoutons tous les indices du GROUPE I (Type I, Type II - (A et B)), les inÃ©galitÃ©s 
entre eux nous permettent dâ€™Ã©crire , pour tout couple (x,y) :  
San (x,y) â‰¤  Sj(x,y) â‰¤  SMin(x,y) â‰¤ SN(x,y) â‰¤ Sd(x,y)  â‰¤  So(x,y) â‰¤ Sk(x,y) â‰¤ SMax(x,y) 
 
Il reste Ã  positionner Sas (x,y)et Sso (x,y),    comme    Sso (x,y) â‰¤ Sas (x,y) , il reste Ã  positionner 
Sso (x,y) par rapport Ã  lâ€™Ã©chelle prÃ©cÃ©dente. 
Comme Sso (x,y) sâ€™exprime sous la forme suivante par rapport Ã  Î± : 

y)11(x,)y,x(Sso
âˆ’
=  
   oÃ¹  Î±= 11(x,y) +1/2 (10(x,y) +01(x,y)) et   Î´= Â¼ (01(x,y) +10(x,y)) 
               :  
comparons  donc   

y)11(x,)y,x(Sso
âˆ’
=    Ã   

y)11(x,)y,x(SMax
âˆ’
=   (voir prÃ©cÃ©demment) 
Pour que 

y)11(x,)y,x(SMax
âˆ’
=   soit  infÃ©rieur Ã  

y)11(x,)y,x(Sso
âˆ’
=
  
il suffit que :  

y)11(x,

y)11(x,
âˆ’
â‰¤
âˆ’
 ,  soit  donc : Î±âˆ’ Î´  â‰¤   Î±âˆ’ Î²   , câ€™est-Ã -dire : Î²  â‰¤  Î´, ce qui 
implique:  
                                                 Â½ 	01(x,y)âˆ’10(x,y)	 â‰¤  Â¼ (01(x,y) +10(x,y))  
 
Pour enlever le signe  Â«	Â», il suffit de passer au Max et Min, il vient alors : 
 
    2(Max (01(x,y),10(x,y))âˆ’Min (01(x,y),10(x,y))) â‰¤ (Max (01(x,y),10(x,y)) +Min (01(x,y),10(x,y)))  
soit: 
RNTI-A-3 - 244 -
                                                                                                    F. Marcotorchino 
 
(f 52)                                     Max [ 01(x,y), 10(x,y))  â‰¤   3 Min (01(x,y),10(x,y))  
 
Si cette condition  (f 52) est vÃ©rifiÃ©e on a donc:   SMax (x,y) â‰¤  Sso (x,y)  et de ce fait :  
 
(f 52â€™) San (x,y ) â‰¤ Sj(x,y) â‰¤ SMin(x,y) â‰¤ SN(x,y) â‰¤  Sd(x,y)  â‰¤ So(x,y) â‰¤ Sk(x,y) â‰¤ SMax(x,y) â‰¤ Sso(x,y) â‰¤ Sac(x,y)  
 
Si la condition inverse se produit: Max [01(x,y),10(x,y))  >  3 Min (01(x,y),10(x,y)), nous ne 
sommes plus assurÃ©s de la sÃ©quence prÃ©cÃ©dente, il faut alors comparer Sac(x,y)  Ã  SMax(x,y), 
nous avons  Ã  comparer Î± âˆ’Î´â€™ et Î±âˆ’ Î²   (avec Î´â€™= 3/8 (01(x,y) +10(x,y))).  
De la mÃªme faÃ§on que prÃ©cÃ©demment, il faut comparer ces quantitÃ©s  Ã  lâ€™aide des notations 
en Min et Max  et  pour que SMax(x,y) soit  infÃ©rieur Ã  Sac(x,y):   il faut et il suffit que :  
                 Î± âˆ’ Î´â€™  â‰¤   Î± âˆ’ Î²   et de ce fait, il faut que :  Î²  â‰¤  Î´â€™ , câ€™est Ã  dire : 
 
Max (01(x,y),10(x,y))âˆ’Min (01(x,y),10(x,y)) â‰¤ 3/4 (Max (01(x,y),10(x,y)) +Min (01(x,y),10(x,y)))  
soit: 
(f 53)                                 Max[01(x,y),10(x,y)) â‰¤  7 Min(01(x,y),10(x,y))  
 
dÃ¨s lors si:           3 Min(01(x,y),10(x,y))  â‰¤ Max ( 01(x,y),10(x,y))  â‰¤  7 Min (01(x,y),10(x,y)) ,  alors: 
 
(f 53â€™)   San(x,y) â‰¤ Sj(x,y)â‰¤ SMin(x,y)â‰¤ SN(x,y)â‰¤ Sd(x,y) )â‰¤ So(x,y)â‰¤ Sk(x,y)â‰¤ Sso(x,y) â‰¤  SMax(x,y) â‰¤ Sac(x,y)    
 
Si cette derniÃ¨re condition nâ€™est pas vÃ©rifiÃ©e, soit maintenant si :  
(f 54)                               7 Min (01(x,y),10(x,y)) â‰¤ Max(01(x,y),10(x,y)) 
 alors on aura: 
(f 54â€™)    San (x,y)â‰¤ Sj(x,y) â‰¤ SMin(x,y) â‰¤ SN(x,y)â‰¤ Sd(x,y) )â‰¤ So(x,y) â‰¤ Sk(x,y)â‰¤ Sso(x,y)â‰¤ Sac (x,y)â‰¤SMax(x,y) 
 
Dans le cas particulier,   oÃ¹ lâ€™on a disjonction complÃ¨te, les rÃ©sultats se simplifient en  : 
 
a) Puisque alors Î²=0, on a une premiÃ¨re sÃ©rie dâ€™Ã©galitÃ©s (pour les indices fonctions de P et 
de R),  
               SMin(x,y) = SN(x,y) = Sd(x,y)  = So(x,y) = Sk (x,y) =  
m
y)11(x,)y,x(SMax =    
b) Pour les indices classiques du Groupe I-Type I (Ratios directs), on obtient les inÃ©galitÃ©s 
suivantes:  
 
y)3.11(x,m
y)4.11(x,y)(x,S
y)11(x,m
y)2.11(x,y)(x,S
m
y)11(x,y)(x,S
y)11(x,2m
y)11(x,y)(x,S
y)3.11(x,4m
y)11(x,y)(x,S acsodjan +=â‰¤+=â‰¤=â‰¤âˆ’=â‰¤âˆ’=
 
En conclusion, dans le cas de disjonction complÃ¨te le rÃ´le central de Sd(x,y) est amplifiÃ© 
car : dans le cas du systÃ¨me dâ€™Ã©galitÃ©s (a)  tous les indices sont Ã©gaux Ã  Sd(x,y), dans le 
systÃ¨me dâ€™inÃ©galitÃ©s (b), Sd(x,y) joue le rÃ´le de Â« mÃ©diane Â» des indices,  indices  qui sont 
tous, par ailleurs, fonctions homographiques de Sd(x,y).  
 
RNTI-A-3- 245 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
4.3.4  En guise de Conclusion sur les Indices du  Groupe I 
  Commenous  venons de le voir, les indices du Groupe I se divisent en deux classes dis-
tinctes, mÃªme si nous avons vu  que cette classification nâ€™est pas une partition puisque 
lâ€™Indice de Dice, par exemple, se retrouve dans les deux Types.  Par ailleurs, le modÃ¨le de 
Tversky (1977) qui tend Ã  unifier ces deux types par une formulation unificatrice ne per-
met pas dâ€™exploiter la logique rÃ©elle de formation des indices. Nous  avons vu nÃ©anmoins 
Ã  ce propos que les  cases connues de la nomenclature rÃ©capitulative reprÃ©sentent des in-
dices dâ€™usage courant et intuitifs. Plus intÃ©ressante  est la tentative faite par Julien Ah Pine 
dans sa thÃ¨se de lâ€™universitÃ© Paris VI (voir J. Ah-ine (2007)),  sur les aspects mathÃ©ma-
tiques : algÃ©briques et combinatoires de lâ€™Analyse Relationnelle ; en effet ce dernier re-
donne (pp73 Ã  88) une interprÃ©tation Â« mÃ©trique Â» (scalaire gÃ©nÃ©ralisÃ©e) de ces indices du 
Groupe  I permettant leur extension au delÃ  du domaine des donnÃ©es Â« binaires Â» vers le  
domaine des donnÃ©es Â» continues Â».  
Pour  ce faire il introduit deux paramÃ¨tres gÃ©omÃ©triques prÃ©sents de faÃ§on sous-jacente 
dans chacun de ces indices du Groupe I, Ã  savoir : le  cosinus de lâ€™angle formÃ© par les 
vecteurs binaires Â»  dâ€™une part, le rapport de la plus grande norme des deux sur la plus 
petite. Il montre ainsi que lâ€™extension continue potentielle de certains des indices du 
Groupe I , vers un formalisme de Â« bon Â» indice totalement gÃ©nÃ©ral sâ€™applique en particu-
lier  Ã  lâ€™indice de Dice  et Ã  lâ€™indice dâ€™OchiaÃ¯ .  Outre quâ€™il retrouve par lÃ  mÃªme et dâ€™une 
faÃ§on totalement diffÃ©rente ce que nous avions mentionnÃ© prÃ©cÃ©demment sur les Â« bons Â» 
indices, il donne Ã©galement une interprÃ©tation gÃ©omÃ©trique  en terme de Â« projecteurs Â» 
aux deux indices partiels de Â« Rappel Â» et de Â« PrÃ©cision Â». Nous renvoyons le lecteur Ã  
son travail    pour de plus amples renseignements.    
 
4.4 Indices appartenant au GROUPE II, faisant jouer un rÃ´le   aux 
structures  11(x,y) et  00(x,y). 
4.4.1 Indices du Groupe II,  Type I (indices obtenus par ratios directs, faisant 
jouer un rÃ´le  linÃ©aire aux structures 00(x,y)) 
4.4.1.1 Indice de Sokal et Michener (1958),  Green-Rao (1969) 
   Cet indice (voir R. Sokal et C. Michener (1958)), qui porte Ã©galement le nom de 
Â« simple matching index Â» est lâ€™un des plus intuitifs de ceux introduits dans la littÃ©rature 
des indices de similaritÃ©, en effet si lâ€™on revient Ã  lâ€™expression du tableau contingentiel 
Â« tetrachorique Â» (2Ã—2) introduit prÃ©cÃ©demment au Â§ 3, on voit que  ce coefficient,  lâ€™un  
des premiers Ã  avoir Ã©tÃ© dÃ©crit dans la littÃ©rature, est  le rapport des cases de la diagonale 
du tableau, divisÃ© par la somme des quatre cases du tableau prÃ©cÃ©dent.  
En fait si la variante Â« similaritÃ© Â» est attribuÃ©e gÃ©nÃ©ralement  Ã   Sokal et Michener (1958), 
Green et Rao12 (1969) ayant introduit, quant Ã  eux,  la variante  Â« dissimilaritÃ© Â» de 
                                                 
12
 I.C. Lerman (1970), attribue Ã  Hamann (1961),  lâ€™indice qui est dÃ©fini 
par :
P
y)]01(x,y)[10(x,y)00(x,y)11(x,y)(x,SHa
+âˆ’+
=
 , câ€™est en fait la diffÃ©rence entre lâ€™Indice de Sokal et 
Michener et celui de Green et Rao, il varie de( â€“1Ã  +1) 
RNTI-A-3 - 246 -
                                                                                                    F. Marcotorchino 
 
lâ€™indice (qui est dâ€™ailleurs le complÃ©mentaire de celui de Sokal et Michener par rapport Ã  
la somme des cases du tableau Â« Tetrachorique Â»), il se trouve que lâ€™idÃ©e originale de ce 
concept est bien plus ancienne encore. En effet on peut la faire remonter Ã  A. de Condor-
cet (1785), voir F. Marcotorchino (1981), F. Marcotorchino et N. El Ayoubi  (1991), ce 
critÃ¨re de Condorcet , qui dans le cas de comparaisons de vecteurs relationnels est Ã©quiva-
lent au coefficient de   Rand  (voir W. Rand (1971))  lequel coefficient semble avoir Ã©tÃ© 
introduit avant Rand par H.Borko et All. (1968) (voir Ã  ce propos le livre de M. Anderberg 
(1973) page 206). En tout Ã©tat de cause câ€™est ce principe de Â« simple matching Â» qui prÃ©-
vaut dans lâ€™approche CondorcÃ©enne, introduite en 1785. Ce qui dâ€™une certaine faÃ§on met 
tout le monde dâ€™accord quant Ã  la paternitÃ© de lâ€™idÃ©e. Le critÃ¨re de Â« simple matching Â» 
sâ€™Ã©crit donc :  
 
(f 55)                
)y,x(01)y,x(10)y,x(00)y,x(11
)y,x(00)y,x(11
P
)y,x(00)y,x(11)y,x(Ssm
+++
+
=
+
=
 
 
Cet indice varie de 0 Ã  1,  
â€¢ il vaut 0 si 11(x,y)=00(x,y)=0   
â€¢ il vaut 1 si 10(x,y)=01(x,y)=0  
 
PropriÃ©tÃ© nÂ°14 :  lâ€™indice de Sokal et Michener vÃ©rifie la condition de Â« TransitivitÃ© GÃ©nÃ©rali-
sÃ©e Indicielle Â» 
 Montrons par ailleurs que  Ssm(x,y) vÃ©rifie la condition de TransitivitÃ© GÃ©nÃ©ralisÃ©e Indi-
cielle, câ€™est Ã  dire que lâ€™on a  : 
 (f 56)                                      zy,  x,   1z)(x,Sz)(y,Sy)(x,S smsmsm âˆ€â‰¤âˆ’+  
soit :                  Pz)]00(x,z)[11(x,z)00(y,z)11(y,y)00(x,y)11(x, â‰¤+âˆ’+++  
 
En remplaÃ§ant ces valeurs en fonctions des quantitÃ©s xj et yj , il vient  aprÃ¨s simplifications: 
                              0z xyzy yx j
P
1j
j
P
1j
jj
P
1j
P
1j
jjj â‰¤âˆ’âˆ’+ 


 

=== =
 
Le membre de gauche de cette inÃ©galitÃ© peut Ã©galement sâ€™Ã©crire sous la forme produit 
suivante : 
(f 57)                     )zy)(yx(z xyzy yx jjj
P
1j
jj
P
1j
j
P
1j
jj
P
1j
P
1j
jjj âˆ’âˆ’=âˆ’âˆ’+ 



 

==== =
  
Comme xj,yj et zj sont des valeurs Ã©gales Ã  0 ou 1 âˆ€j, il suffit de montrer que pour toutes les 
valeurs de lâ€™indice Â« j Â», le  produit (xj-yj)(yj-zj),  ne peut en aucun cas Ãªtre strictement posi-
tif.  Pour ce faire explorons exhaustivement les 8=23 configurations possibles des valeurs 
xj, yj, zj., on obtient le tableau suivant : 
 
xj yj zj Valeur du produit  (xj-yj) (yj-zj) 
0 0 0 0 
0 0 1 0 
0 1 0 -1 
1 0 0 0 
0 1 1 0 
1 0 1 -1 
1 1 0 0 
1 1 1 0 
RNTI-A-3- 247 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
 
On constate que le produit (xj-yj)(yj-zj) est toujours nÃ©gatif ou nul pour toutes les configura-
tions des valeurs xj, yj,,zj,  donc que la quantitÃ© somme de ces produits sera nÃ©gative, soit :  
0)z- y)(y(x jj
P
1j
jj â‰¤âˆ’

=
 
 La formule (f56) est donc vraie (cqfd) 
Conclusion : Lâ€™indice de Sokal et Michener est donc un indice de similaritÃ© Â« mÃ©trisable Â» 
lâ€™indice de distance associÃ© sâ€™Ã©crit  :  
                                             
P
)y-(x
y)(x,S-1y)(x,d
P
1j
2
jj
smsm


=
==
 
Si  P est un nombre pair on peut Ã©crire  P=2pâ€™, il vient alors: 
 (f 58)                  
y)(x,
2
11
p'
y
p'
x
2
11
p'
)y-(x
2
11y)(x,S 2
2
P
1j
jj
P
1j
2
jj
sm âˆ’=



	
	


âˆ’âˆ’=âˆ’= 



=
=
 
Lâ€™indice de Sokal et Michener est donc un indice mÃ©trisable euclidien , dâ€™aprÃ¨s le thÃ©orÃ¨-
me de Gower â€“Schoenberg. 
 
 4.4.1.2 Indice de Rogers et Tanimoto (1960) 
  Cet indice, introduit par les auteurs dans un article sur lâ€™Ã©cologie botanique (voir (D. 
Rogers et T. Tanimoto (1960)), joue,  pour les indices du Groupe II -Type I,  un rÃ´le ana-
logue Ã  celui jouÃ© par  lâ€™indice dâ€™Anderberg  pour les indices du Groupe I - Type I, en effet 
il pondÃ¨re lÃ©gÃ¨rement plus (poids =2)  les cas dâ€™Â« erreurs Â» de matching. Il est dÃ©fini par : 
 
(f 59)               
)]y,x(00)y,x(11[P.2
)y,x(00)y,x(11
)]y,x(01)y,x(10[2)y,x(00)y,x(11
)y,x(00)y,x(11)y,x(Srt
+âˆ’
+
=
+++
+
=
 
    
 
En Ã©liminant les quantitÃ©s communes : 11(x,y)+00(x,y) et (10(x,y)+01(x,y)), entre les deux 
indices prÃ©cÃ©dents on obtient la relation suivante entre lâ€™indice de Rogers et Tanimoto et 
celui de  Â« Simple Matching Â» : 
 
(f 60)              
)]y,x(S2[
)y,x(S)y,x(S
sm
sm
rt
âˆ’
=
  et rÃ©ciproquement : 
]1)y,x(S[
)y,x(S.2)y,x(S
rt
rt
sm
+
=
 
PropriÃ©tÃ© nÂ°15 :  lâ€™indice de Rogers et Tanimoto vÃ©rifie Â« la condition de TransitivitÃ© GÃ©nÃ©rali-
sÃ©e Indicielle et est mÃ©trisable Â»  
En effet en se reportant Ã  la formule (f57) ci-dessus , on voit que les conditions 
dâ€™application des ThÃ©orÃ¨me nÂ°1 et ThÃ©orÃ¨me nÂ°1 bis  sont vÃ©rifiÃ©es par lâ€™indice de Rogers 
et Tanimoto , il suffit de voir que comme  
)]y,x(S2[
)y,x(S)y,x(S
sm
sm
rt
âˆ’
=
  sâ€™Ã©crit  
1y)](x,S[1
y)(x,S
y)(x,S
sm
sm
rt
+âˆ’
=
 avec Î²=1, il est donc mÃ©trisable, 
dâ€™aprÃ¨s le ThÃ©orÃ¨me nÂ°1 et mÃ©trisable euclidien dâ€™aprÃ¨s le ThÃ©orÃ¨me nÂ°1 bis, si P est pair.   
RNTI-A-3 - 248 -
                                                                                                    F. Marcotorchino 
 
4.4.1.3 Indice de Sokal et Sneath  (1963) 
   Cet indice, introduit par les auteurs en 1963 (voir (Sokal et Sneath ( 1963)) et rejustifiÃ© 
dans leur livre de 1973 (voir Sokal et Sneath (1973)) est  une variante des  indices prÃ©cÃ©-
dents,  avec une dÃ©finition trÃ¨s voisine de celle quâ€™a lâ€™indice de Dice au regard des indices 
du Groupe I-Type I, en effet il donne moins de poids  que  les deux configurations  prÃ©cÃ©-
dentes aux situations de non concordance. Il sâ€™Ã©crit :   
 
(f 61)                
)]y,x(00)y,x(11[P
)]y,x(00)y,x(11.[2
)]y,x(01)y,x(10[)y,x(00)y,x(11
)y,x(00)y,x(11)y,x(S
2
1ss ++
+
=
+++
+
=
 
 
En Ã©liminant les quantitÃ©s communes : (11(x,y)+00(x,y)) et (10(x,y)+01(x,y)), entre lâ€™indice 
de Sokal et Sneath et celui de Â« Simple Matching Â», on obtient la relation homographique 
ci dessous :  
 
(f 62)               
]1)y,x(S[
)y,x(S.2)y,x(S
sm
sm
ss
+
=
 et rÃ©ciproquement :    
)]y,x(S2[
)y,x(S)y,x(S
ss
ss
sm
âˆ’
=
 
 
Enfin en Ã©liminant  Ssm(x,y) dans les deux formules  (f 61) et (f 62), on obtient la relation 
suivante entre les indices de Sokal- Sneath et  Rogers - Tanimoto : 
 
(f63) 
]1)y,x(S.3[
)y,x(S.4)y,x(S
rt
rt
ss
+
=
 et la formule rÃ©ciproque : 
)]y,x(S.34[
)y,x(S)y,x(S
ss
ss
rt
âˆ’
=
 
 
 
Du fait que ces 3 indices du Groupe II,  Type I, soient tous fonction homographique de 
lâ€™indice de Â« Simple Matching Â», nous permet de les reprÃ©senter sur un diagramme unique, 
oÃ¹ lâ€™on peut voir de faÃ§on simple comment ils se comportent et comment ils varient les 
uns par rapport aux autres. Par ailleurs bien Ã©videmment tous ces indices varient de 0 Ã  1, 
ce que nous constatons dâ€™ailleurs sur le graphique de la Figure NÂ°2 :  
     
1)y,x(S0  â‰¤â‰¤  
 
â€¢ Ces indices valent 0 si le nombre de  concordances (Â« matchings Â»)  positives et con-
cordances  nÃ©gatives sont nulles  entre  x et y   11(x,y)=0 et 00(x,y)=0 
â€¢  Ils valent 1 si la quantitÃ© (10(x,y)+01(x,y) = 0  x et y ont le mÃªme profil de 1 et de 0   
â€¢ Ces trois indices vÃ©rifient les inÃ©galitÃ©s suivantes âˆ€ (x,y) : 
 
(f64)                                 1)y,x(S)y,x(S)y,x(S0 sssmrt â‰¤â‰¤â‰¤â‰¤  
RNTI-A-3- 249 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
.
0,0
0,2
0,3
0,5
0,7
0,8
1,0
0,
00
0,
10
0,
20
0,
30
0,
40
0,
50
0,
60
0,
70
0,
80
0,
90
1,
00
Tanimoto
SimpMatch
Sokal-Sne
Figure 2: Graphique de variation des indices du GROUPE II,  Type I 
4.4.2 Quelques propriÃ©tÃ©s des indices du Groupe II-Type I en cas de disjonction 
complÃ¨te 
        Dans le cas ou les indices prÃ©cÃ©dents sont calculÃ©s sur les tableaux obtenus par dis-
jonction complÃ¨te, des simplifications vont se produire qui permettent des convergences.  
 
En cas de disjonction complÃ¨te on a vu en effet que le nombre de variables Â« m Â»  Ã©tait tel 
que  :   
      [ ] m)y,x(01)y,x(10
2
1)y,x(11 =++  
dâ€™autre part on a :  11(x,y)+00(x,y)+10(x,y)+01(x,y)=P  
De ce fait  la quantitÃ© [ ] )y,x(11.2m2)y,x(01)y,x(10 âˆ’=+   remplacÃ©e dans lâ€™Ã©galitÃ© sur P 
nous donne : 
 
(f 65)    m2)y,x(11P)y,x(00 âˆ’+=  
Alors en remplaÃ§ant cette valeur dans les trois indices prÃ©cÃ©dents nous obtenons  pour 
chacun dâ€™entre eux des indices qui ne dÃ©pendent que de 11(x,y) et des constantes P et m: 
 
a) Expression du coefficient de Â« Simple Matching Â» 
 Le coefficient  Ssm vaut alors : 
P
m.2
P
)y,x(11.21
P
m.2)y,x(11P)y,x(11
P
)y,x(00)y,x(11)y,x(Ssm âˆ’+=
âˆ’++
=
+
=
 
b) Expression du coefficient de Sokal et Sneath 
Le coefficient  Sss vaut dans ce cas : 
m)y,x(11P
m)y,x(111
2.m-y)2.11(x,2P
]m.2)y,x(11.2[ 2P2
)]y,x(00)y,x(11[P
)]y,x(00)y,x(11.[2)y,x(Sss
âˆ’+
âˆ’
+=
+
âˆ’+
=
++
+
=
 
RNTI-A-3 - 250 -
                                                                                                    F. Marcotorchino 
 
 
c)  Expression du coefficient de Rogers-Tanimoto 
Le coefficient  Srt  vaut dans ce cas : [ ]
)]y,x(11.2m2[P
)y,x(11.2m.221)]y,x(11.2m.2[P
)]y,x(11.2m.2[P
)]y,x(00)y,x(11[P.2
)y,x(00)y,x(11)y,x(Srt
âˆ’+
âˆ’
âˆ’=
âˆ’+
âˆ’âˆ’
=
+âˆ’
+
=
 
 
Comme dans le cas de disjonction complÃ¨te, on a toujours le rÃ©sultat suivant : 
m
)y,x(11)y,x(Sd =   (voir formule (f 25)) montrons que ces trois indices sont dans le cas de 
disjonction complÃ¨te des fonctions de lâ€™indice de Dice :  
 
Il suffit pour cela de diviser NumÃ©rateur et DÃ©nominateur des indices prÃ©cÃ©dents  par 
Â« m Â», il vient : 
 
â€¢ [ ])y,x(S1
P
m.21
P
m.2
P
)y,x(11.21)y,x(S dsm âˆ’âˆ’=âˆ’+=  ou rÃ©ciproquement : 
[ ])y,x(S1
m.2
P1)y,x(S smd âˆ’âˆ’=  
 
â€¢ 
)]y,x(S1[mP
)]y,x(S1[m1
m)y,x(11P
m)y,x(111)y,x(S
d
d
ss
âˆ’âˆ’
âˆ’
âˆ’=
âˆ’+
âˆ’
+=        ou rÃ©ciproquement : 
)]y,x(S1[
)]y,x(S1[
 
m.2
P1)y,x(S
ss2
1
ss
d
âˆ’
âˆ’
âˆ’=
 
 
â€¢ [ ]
)]y,x(S1[m2P
)]y,x(S1[m41)]y,x(11.2m2[P
)y,x(11.2m.221)y,x(S
d
d
rt
âˆ’+
âˆ’
âˆ’=
âˆ’+
âˆ’
âˆ’= ou rÃ©ciproquement : 
)]y,x(S1[
)]y,x(S1[
 
m2
P1)y,x(S
rt
rt
d
+
âˆ’
âˆ’=
 
DÃ¨s lors la comparaison de ces indices au travers de la Â« borne de Salomon -Fortier Â» que 
nous avions utilisÃ©e prÃ©cÃ©demment pour lâ€™indice de Dice  ( qui se traduisait par  la rÃ¨gle 
majoritaire de Condorcet) induit les bornes suivantes pour ces trois indices du Groupe II-
Type I : 
 [ ]
2
my)11(x,         
P
m1      y)(x,S          
2
1y)(x,S1
2.m
P1      
2
1y)(x,S smsmd â‰¥â‡”âˆ’â‰¥â‡”â‰¥âˆ’âˆ’â‡”â‰¥     
2
my)11(x,            
m-2P
m
-1    y)(x,S        
2
1
y)](x,S[1
y)](x,S[1
 
2.m
P1         
2
1y)(x,S ss
ss2
1
ss
d â‰¥â‡”â‰¥â‡”â‰¥
âˆ’
âˆ’
âˆ’â‡”â‰¥
       
2
my)11(x,              
mP
2.m1y)(x, S               
2
1
y)](x,S[1
y)](x,S[1
 
2m
P1          
2
1y)(x,S rt
rt
rt
d â‰¥â‡”
+
âˆ’â‰¥â‡”â‰¥
+
âˆ’
âˆ’â‡”â‰¥
 
 
Remarque nÂ°5 : Dans le cas particulier oÃ¹ lâ€™on se trouve dans les conditions de la Remarque nÂ°1, 
tableau de Â« prÃ©sence-absence Â» dÃ©doublÃ© , on a P=2m, de ce fait les inÃ©galitÃ©s prÃ©cÃ©dentes se 
simplifient et lâ€™on obtient :  
Dice" de Indice"l'sur      appliquÃ©e Fortier   Salomon      de rÃ¨gle lapour   Sorensen" de indice"l' avec
 Sneath"et  Sokal" de indicel' de eEquivalenc   
3
2
mm4
m1)y,x(S           
mP2
m1      )y,x(S   ssss â‡”=
âˆ’
âˆ’â‰¥â‡”
âˆ’
âˆ’â‰¥
Dice" de Indice"l'sur      appliquÃ©e Fortier   Salomon      de rÃ¨gle lapour   Jaccard" de indice"l' avec 
   Tanimoto" Rogers" de indicel' de eEquivalenc   
3
1
mm.2
m.21)y,x(S           
mP
m.21      )y,x(S   ssrt â‡”=
+
âˆ’â‰¥â‡”
+
âˆ’â‰¥  
 
RNTI-A-3- 251 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
Remarque nÂ°6 : Dans la configuration prÃ©cÃ©dente, nous avions privilÃ©giÃ© une comparaison de ces 
trois indices en rÃ©fÃ©rence au fait que lâ€™indice de Dice vÃ©rifiait lui mÃªme la condition de Salomon et 
Fortier et nous avons voulu mesurer lâ€™impact induit  au niveau de chacun dâ€™entre eux sur  les bornes 
ainsi gÃ©nÃ©rÃ©es. 
Une autre approche intÃ©ressante consiste en la dÃ©marche inverse, (comme nous lâ€™avions fait dans le 
cas des indices du Groupe I â€“Type I),  câ€™est Ã  dire Ã  exhiber  les contraintes que doit vÃ©rifier la 
quantitÃ© : 11(x,y) relativement Ã  chacun de ces indices pour que la condition de Salomon â€“Fortier 
soit vÃ©rifiÃ©e. 
 
â€¢ 
4
P
my)11(x,              
2
1
 
P
2.m
P
y)2.11(x,1            
2
1y)(x,S sm âˆ’â‰¥â‡”â‰¥âˆ’+â‡”â‰¥
 
â€¢ 
3
P
my)11(x,                  
2
1
    
my)11(x,P
my)11(x,1             
2
1y)(x,Sss âˆ’â‰¥â‡”â‰¥
âˆ’+
âˆ’
+â‡”â‰¥
 
â€¢ [ ]
6
P
-my)11(x,         
2
1
y)]2.11(x,[2mP
y)2.11(x,2.m21              
2
1y)(x,S rt â‰¥â‡”â‰¥
âˆ’+
âˆ’
âˆ’â‡”â‰¥
 
On constate immÃ©diatement Ã  lâ€™aune de ces valeurs, dÃ©pendantes de P et de m, que pour les 
tableaux disjonctifs complets Ã  grand nombre de modalitÃ©s, ces bornes ont peu de  signifi-
cation, en effet supposons que .p  soit  le  nombre de modalitÃ©s moyen de lâ€™ensemble des 
variables alors m.pP = , de ce fait les bornes prÃ©cÃ©dentes  
sâ€™Ã©crivent respectivement : )
6
p
-m(1   ),
3
p
-m(1   ),
4
p1(m âˆ’ , supposons, par exemple,  que  
5p =  (ce qui est un chiffre peu Ã©levÃ©, trÃ¨s souvent rencontrÃ©  dans applications  con-
crÃ¨tes), alors les bornes sont nÃ©gatives pour lâ€™indice de Simple Matching et  Sokal et 
Sneath,  donc la condition de Salomon-Fortier est toujours vÃ©rifiÃ©e, et il suffit  que 11(x,y) 
soit supÃ©rieur Ã  m/6 pour que  la condition de Salomon -Fortier soit vÃ©rifiÃ©e par lâ€™indice de 
Rogers et Tanimoto . Ces indices ne seront donc pas trÃ¨s utilisables dans le contexte de 
tableaux disjonctifs associÃ©s Ã  des variables qualitatives dÃ¨s lors que le nombre moyen de 
modalitÃ©s est supÃ©rieur Ã   3, on privilÃ©giera  de ce fait les indices du Groupe I-Type I dans 
ce contexte.   
 
4.4.3 Indices Â« non Classiques Â» du Groupe II - Type I (indices obtenus par ratios 
directs, faisant jouer un rÃ´le aux structures 00(x,y), au NumÃ©rateur et au 
DÃ©nominateur) 
     En plus des indices dits Â« classiques Â», en un mot les plus utilisÃ©s de ce Groupe II-Type 
I, il existe des variantes  jouant sur des pondÃ©rations Ã  la fois au numÃ©rateur pour la confi-
guration 00(x,y) et au dÃ©nominateur pour les configurations 10(x,y) et 01(x,y). En fait la 
forme13 gÃ©nÃ©rale SG(x,y) des indices du Groupe II-Type I est  donnÃ©e par :  
  
(f 66)                             
y)]01(x,y)[10(x,y)00(x,y)11(x,
y)00(x,y)11(x,)y,x(SG
+++
+
=
 
                                                 
13
 En jouant sur lâ€™intersection du modÃ¨le SG  prÃ©cÃ©dent et du ModÃ¨le de Tversky , on peut fabriquer un indice encore 
plus gÃ©nÃ©ral avec 4 paramÃ¨tres  variables, de la forme : 
y)01(x,y)10(x,y)00(x,y)11(x,
y)	00(x,y)11(x,)y,x(SGG +++
+
=
 
 
RNTI-A-3 - 252 -
                                                                                                    F. Marcotorchino 
 
On retrouve dans le tableau ci-dessous en fonction des valeurs de Î± et Î² le nom des indi-
ces dÃ©jÃ  rencontrÃ©s et nous expliciterons  dans ce paragraphe ceux qui nâ€™ont pas encore Ã©tÃ© 
dÃ©finis. 
 
 
 
                 Î²      1/2 1 2 
0 Rao2 Rao (1945)  
1/2 Marco-Michaud2 (1980) 
Marco-Michaud 
(1980) 
 
1 
Sokal- Sneath (1968) Sokal-Michener 
(1958) 
Rogers-
Tanimoto(1960) 
 
 
4.4.3.1 Indice de T.R. Rao (1945)  
  Cet indice, bien quâ€™introduit initialement par PF. Russel et T..R. Rao en 1940, redÃ©taillÃ© 
ensuite par R. Rao seul en 1945 est assez peu utilisÃ© dans la pratique car il est souvent trop 
sÃ©vÃ¨re et sâ€™Ã©loigne de structures dâ€™Ã©quilibre interprÃ©tables. Il consiste dans le simple rap-
port entre le nombre de Matching 11(x,y) divisÃ© par le nombre total dâ€™attributs descriptifs,  
quâ€™on notera, comme dÃ©fini au dÃ©but de lâ€™article , par P. Ce nombre dÃ©finissant soit le 
nombre de variables descriptives de Â« prÃ©sence-absence Â», soit le nombre de modalitÃ©s de 
lâ€™ensemble des variables, quand on travaille sur un tableau disjonctif complet. Du fait de la 
prÃ©sence des configurations 00(x,y) au dÃ©nominateur (quantitÃ©s  qui sont souvent trÃ¨s 
grandes ), les valeurs de lâ€™indice de Rao  sont souvent trÃ¨s faibles. Par ailleurs contraire-
ment aux autres indices du groupe II, il ne fait pas jouer de rÃ´le aux configurations 00(x,y) 
au numÃ©rateur  (ici Î±=0 ce qui ne permet pas  le rÃ©Ã©quilibrage). Suite Ã  ce que nous venons 
de mentionner au paragraphe prÃ©cÃ©dent, il apparaÃ®t que cet indice est  encore moins bien 
adaptÃ© que les indices  prÃ©cÃ©dents aux calculs de similaritÃ©s sur  tableaux disjonctifs com-
plets.  Sa forme est donc : 
 
  (f 67)             
)y,x(01)y,x(10)y,x(00)y,x(11
)y,x(11
P
)y,x(11)y,x(Sr
+++
==
  
Il varie bien de 0 Ã  1, il vaut: 
â€¢ 0 si 11(x,y)=0 
â€¢ 1 si simultanÃ©ment : 10(x,y)=01(x,y)=00(x,y)=0   (ce qui est une contrainte extrÃªmement  
dure Ã  obtenir ) 
 
Cet indice nâ€™a pas de propriÃ©tÃ©s particuliÃ¨res  en cas de disjonction complÃ¨te , en effet en 
remplaÃ§ant  00(x,y), 10(x,y) et 01(x,y) par leurs valeurs en fonction de 11(x,y) et de P, du fait 
que  00(x,y)=11(x,y)+P-2m, 01(x,y)=10(x,y)=m-11(x,y), on retrouve :  
P
)y,x(11)y,x(Sr =  
Lâ€™application de la rÃ¨gle de â€œSolomon Fortierâ€ en cas de disjonction complÃ¨te donne le 
rÃ©sultat â€œparadoxalâ€ suivant: 
(f 68)          
2
P)y,x(11
2
1
P
)y,x(11
2
1)y,x(Sr â‰¥â‰¥â‰¥  
RNTI-A-3- 253 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
Ce rÃ©sultat  est impossible Ã  atteindre  dans le contexte  de â€œdisjonction complÃ¨teâ€, sauf 
dans un cas . En effet, le minimum pour P par rapport Ã  m est obtenu sur les tableaux de 
â€œprÃ©sence-absence dÃ©doublÃ©sâ€ pour lesquels P=2m en remplaÃ§ant P par 2m dans lâ€™inÃ©galitÃ© 
prÃ©cÃ©dente, on obtient: 
      m)y,x(11 â‰¥   
Comme,   par dÃ©finition 11(x,y)m, le seul cas possible est 11(x,y) =m, pour toutes les autres 
valeurs de P: 3m, 4m, 5m...x.m, lâ€™inÃ©galitÃ©  (f 68) est impossible Ã  vÃ©rifier.  
Ceci montre, encore une fois, que lâ€™indice de Rao ne doit Ãªtre utilisÃ© que dans des configu-
rations spÃ©ciales et en particulier, jamais sur des problÃ¨mes disjonctivÃ©s, hormis le cas 
mentionnÃ©.                                   
4.4.3.2 Indice de Marcotorchino-Michaud (1980)  
    En 1980  (voir  F. Marcotorchino et P. Michaud (1980)), nous avions introduit lâ€™indice 
suivant : 
 (f 69)         
)y,x(01)y,x(10)y,x(00)y,x(11
)y,x(00)y,x(11
P
)y,x(00)y,x(11
)y,x(S 2
1
2
1
mm
+++
+
=
+
=
 
 
Cet indice (pour lequel Î±=1/2) â€œneutraliseâ€ la trop forte influence nÃ©gative des configura-
tions 00(x,y) au dÃ©nominateur, vue dans le cas de lâ€™indice de Rao, tout en leur donnant  un 
poids moins positif toutefois que dans le â€œsimple matching â€œ index de Sokal et Michener. 
Câ€™est un indice de compromis linÃ©aire entre lâ€™indice de Rao et lâ€™indice de â€œSimple Mat-
chingâ€, dâ€™ailleurs, il sâ€™Ã©crit: 
                                                 [ ]y)(x,Sy)(x,S
2
1y)(x,S smrmm +=  
  
Comme lâ€™indice de Rao, il varie de 0 Ã  1, il vaut:  
â€¢ 0 si 11(x,y)=00(x,y)=0. Cependant on peut se poser la question, dans ce cas, de 
lâ€™extrÃªme raretÃ© dâ€™une telle situation qui correspond au fait que les profils de x et y 
sont totalement inverses lâ€™un de lâ€™autre, cas des situations de vecteurs de prÃ©sence-
absence Ã  produit scalaire nul. Ceci dit,  dans de grands tableaux cette situation peut 
nÃ©anmoins se produire, et de ce fait,   la valeur 0 est rare, mais  potentiellement attein-
te.   
â€¢ 1 si 10(x,y)=01(x,y)=0  et 00(x,y)=0, cependant dans le cas oÃ¹ 10(x,y)=01(x,y)=0, puisque 
dans ce cas P=00(x,y)+11(x,y), il vaut: 
             
P2
)y,x(11
2
1
P
P)y,x(11
P
)]y,x(11P[)y,x(11
)y,x(S 2
12
1
mm +=


 +
=
âˆ’+
=
 
â€¢ le fait marquant ici est que si 10(x,y)= 01(x,y)=0, lâ€™indice est toujours supÃ©rieur Ã  Â½ et 
il vaut 1 si  en plus 00(x,y)=0, soit 11(x,y)=P . La remarque, faite pour le cas de 
lâ€™obtention de la valeur 0, sâ€™applique ici Ã©galement, pour une situation inverse. Cette 
situation , ne peut se produire,  en effet, que pour des tableaux de donnÃ©es de prÃ©sen-
ce-absence,  lorsque deux individus x et y possÃ¨dent lâ€™ensemble complet de toutes les 
propriÃ©tÃ©s, en dâ€™autres termes que leurs profils sont deux vecteurs composÃ©s de va-
leurs â€œ1â€.  
 
RNTI-A-3 - 254 -
                                                                                                    F. Marcotorchino 
 
Il est Ã  noter cependant, quâ€™en cas de disjonction complÃ¨te,  du fait des relations entre les 
diffÃ©rentes cases du tableau, dÃ©jÃ  prÃ©sentÃ©es auparavant,  la valeur de lâ€™indice se simplifie 
en :                 
                     
P
m
2
1
P
y)11(x,
2
3
P
m]2[Py)11(x,
y)(x,S 2
1
2
3
mm âˆ’+=
âˆ’+
=
 
Comme dans ce cas,  (disjonction complÃ¨te), on ne peut avoir  11(x,y) et 00(x,y)  simul-
tanÃ©ment nuls tous les deux,  lâ€™indice prend sa valeur minimale pour 11(x,y) = 0 et  vaut 
alors :  
P
m
2
1y)(x,Smm âˆ’=   
On voit quâ€™il ne vaudra 0 que si P=2m (cas de la disjonction  tableaux de prÃ©sence-absence, 
oÃ¹ chaque variable ne peut avoir que 2 modalitÃ©s), on se retrouve alors dans le cas , dÃ©jÃ  
discutÃ© plus haut, de la valeur 0 de lâ€™indice   (vecteurs de prÃ©sence-absence Ã  produit sca-
laire nul). 
 Il prend sa valeur maximum dans le cas oÃ¹  11(x,y)=m ,valeur pour laquelle il vaut : 
2P
m
2
1y)(x,Smm +=  
On voit quâ€™il ne prendra la valeur maximale 1 que lorsque P=m, câ€™est Ã  dire dans le cas oÃ¹ 
lâ€™on identifie un tableau  de prÃ©sence absence avec un tableau  dÃ©doublonnÃ© de prÃ©sence-
absence). Cependant cette situation nâ€™est quâ€™un artefact, on parlera en fait de tableau dis-
jonctif â€œvraiâ€, dÃ¨s lors quâ€™une variable possÃ¨de au minimum 2 modalitÃ©s. Si toutes les 
variables ont deux modalitÃ©s , on obtient la valeur maximale qui vaut : 
   
4
3
4m
m
2
1y)(x,Smm =+=  
PropriÃ©tÃ© de lâ€™ indice de Marcotorchino-Michaud  en cas de disjonction complÃ¨te 
En cas de disjonction complÃ¨te, la rÃ¨gle de Solomon-Fortier est applicable ici  Ã  une borne 
(
2
MaxSMinS+ ), (voir Â§1.1),  puisque lâ€™indice varie Â« potentiellement Â» de 0 Ã  1,  mais plus 
exactement selon des bornes dÃ©pendant du rapport m/P. Ici, compte tenu des bornes prÃ©cÃ©-
dentes, la borne de Solomon-Fortier associÃ©e sâ€™Ã©crit :  
    
4P
m
2
1
2P
m
2
1
P
m
2
1
2
1
2
MaxSMinS
âˆ’=


		





	


++


	


âˆ’=
+  
La vÃ©rification de la borne de Solomon-Fortier au sens particulier du contexte disjonctif,  
induit donc  ici :    
                                    
4P
m
2
1y)(x,Smm âˆ’â‰¥ , 
 soit: 
           
2
my)11(x,m
4
3y)11(x,
2
3
4P
m
2
1
P
m
2
1
P
y)11(x,
2
3 â‰¥â‰¥âˆ’â‰¥âˆ’+   
 
Ce rÃ©sultat est intÃ©ressant au titre quâ€™il  prouve que Smm(x,y) est lâ€™un des deux seuls,  parmi 
les indices du Groupe IIâ€“Type I, pour lequel, en cas de disjonction complÃ¨te,   lâ€™application 
de la rÃ¨gle de Solomon-Fortier fait disparaÃ®tre la rÃ©fÃ©rence Ã  la valeur de P et oÃ¹ lâ€™application 
du principe fait rÃ©apparaÃ®tre la rÃ¨gle majoritaire de Condorcet. 
RNTI-A-3- 255 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
Ce rÃ©sultat montre Ã©galement que, quand lâ€™on parle de borne de Salomon-Fortier,  câ€™est bien 
Ã  la quantitÃ©  
2
SMaxSMin +
 que lâ€™on doit faire rÃ©fÃ©rence et non simplement Ã  la valeur  Â½, qui 
suppose, elle,  une variation rÃ©elle de 0 Ã  1 (bornes atteintes ) .  
 
Une autre approche, nous montre bien la diffÃ©rence entre la borne vraie de Salomon Fortier 
et la borne thÃ©orique  Si  lâ€™on fait apparaÃ®tre le cas disjonctif en fin de calculs, on illustre 
clairement ce point. 
En effet  si lâ€™on reprend la formule  (f 69), et, puisque dans le cas gÃ©nÃ©ral, sans rÃ©fÃ©rence aux 
limitations du cas disjonctif , on a vu que lâ€™indice Smm varie de 0 Ã  1, on peut donc  lui appli-
quer la borne simple Ã  Â½.  Ceci nous donne : 
  
                      
2
y)01(x,y)10(x,
2
y)11(x,
2
1
y)01(x,y)10(x,y)00(x,y)11(x,
y)00(x,y)11(x, 21 +â‰¥â‰¥
+++
+
 
 
On voit dÃ©jÃ  Ã  ce stade  que la rÃ©fÃ©rence Ã  00(x,y)  disparaÃ®t, cette formule est gÃ©nÃ©rale.  Si 
maintenant  on revient dans un processus oÃ¹ il y a eu disjonction,  la quantitÃ© 10(x,y)+01(x,y) 
est Ã©gale Ã  2(m-1l(x,y)), soit en remplaÃ§ant cette valeur dans lâ€™inÃ©galitÃ© prÃ©cÃ©dente :  
         
3
2my)11(x,
2
y)]11(x,2[m
2
y)11(x,
â‰¥
âˆ’
â‰¥
 
On retrouve bien ici une  majoritÃ© CondorcÃ©enne des 2/3, que nous avions obtenue prÃ©cÃ©-
demment dans le cas de lâ€™Indice de Jaccard, lâ€™un des indices reprÃ©sentant le Groupe I â€“ Type 
I . 
 
On constate donc que, contrairement aux indices de Sokal et Michener, Sokal et Sneath et 
Rogers et Tanimoto, la valeur P disparaÃ®t de la borne sur 11(x,y) dâ€™une part et que lâ€™indice 
impose une Â« majoritÃ© simple Â» des variables pour la valeur des  Â« matchings Â» 11(x,y) (cas 
disjonctif particulier), dâ€™autre part  une rÃ¨gle des 2/3 dans le cas gÃ©nÃ©ral.  Cette derniÃ¨re pro-
priÃ©tÃ© fait de cet indice, une mesure  tout Ã  fait intÃ©ressante dans le cas de structures disjonc-
tivÃ©es, ou de prÃ©sence â€“absence avec beaucoup de valeurs nulles,  qui ,quoique Ã©tant diffÃ©-
rente, se comporte comme lâ€™indice de Jaccard (qui, lui, appartient au Groupe I-TypeI). Cette 
lÃ©gÃ¨re dÃ©pondÃ©ration au numÃ©rateur des configurations 00(x,y),  redresse quelque peu le dÃ©-
faut inhÃ©rent aux indices du Groupe II - Type I, Ã  savoir : ne pas Ãªtre adaptÃ©s aux traitements 
des donnÃ©es disjonctives ou Ã  valeurs nulles trÃ¨s nombreuses.   
 
4.4.3.3 Indice de Marcotorchino-Michaud-2 (1980)  
Sâ€™appuyant sur le mÃªme  principe que prÃ©cÃ©demment, un autre indice du mÃªme genre que le 
prÃ©cÃ©dent donne des rÃ©sultats Ã©galement  intÃ©ressants, il sâ€™agit de lâ€™indice suivant : 
 
(f 70)                             
[ ])y,x(01)y,x(10)y,x(00)y,x(11
)y,x(00)y,x(11
)y,x(S
2
1
2
1
2mm
+++
+
=
  
Comme le prÃ©cÃ©dent cet indice varie de 0 Ã  1, il vaut:  
â€¢ 0 si 11(x,y)=00(x,y)=0. Cependant on peut lui appliquer la mÃªme remarque que dans le 
cas prÃ©cÃ©dent , a savoir lâ€™extrÃªme raretÃ© dâ€™une telle situation qui correspond au fait 
que les profils de x et y sont totalement inverses lâ€™un de lâ€™autre.  
RNTI-A-3 - 256 -
                                                                                                    F. Marcotorchino 
 
â€¢ 1 si 10(x,y)=01(x,y)=0 et 00(x,y)=0, La remarque, faite pour le cas de lâ€™obtention de la 
valeur 0, sâ€™applique ici Ã©galement, pour une situation inverse. Cette situation , ne peut 
se produire,  en effet, que pour des tableaux de donnÃ©es de prÃ©sence-absence,  lorsque 
deux individus x et y possÃ¨dent lâ€™ensemble complet de toutes les propriÃ©tÃ©s.  
Il est Ã  noter cependant, comme dans le cas de lâ€™indice prÃ©cÃ©dent,  quâ€™en cas de disjonction 
complÃ¨te,  du fait des relations entre les diffÃ©rentes cases du tableau, dÃ©jÃ  prÃ©sentÃ©es aupa-
ravant,  la valeur de lâ€™indice se simplifie en : 
                   
2m-2Py)11(x,2
2mPy)11(x,3y)(x,Smm2 +
âˆ’+
=
 
Comme dans ce cas,  (disjonction complÃ¨te), on ne peut avoir  11(x,y) et 00(x,y)  simul-
tanÃ©ment nuls, puisque 11(x,y)+00(x,y)=P,  lâ€™indice prend sa valeur minimale pour 11(x,y) = 
0 et  vaut alors :  
                              
2m-2P
2m-Py)(x,Smm2 =
  
On voit quâ€™il ne vaudra 0 que si P=2m (cas de la disjonction  tableaux de prÃ©sence-absence, 
oÃ¹ chaque variable ne peut avoir que 2 modalitÃ©s), on se retrouve alors dans le cas , dÃ©jÃ  
discutÃ© pour lâ€™indice Smm(x,y). 
 
 Il prend sa valeur maximum dans le cas oÃ¹  11(x,y)=m ,valeur pour laquelle il vaut : 
2P
m
2
1
2P
mPy)(x,Smm2 +=
+
=
 
 
De faÃ§on surprenante, cette valeur est identique Ã  celle trouvÃ©e pour  lâ€™indice prÃ©cÃ©dent.  
On voit quâ€™il ne prendra la valeur maximale 1 que lorsque P=m, câ€™est Ã  dire dans la mÃªme 
situation que Smm(x,y). La remarque faite  pour Smm(x,y) sâ€™applique ici aussi . Le maximum 
â€œvraiâ€ (par opposition au â€œMaximum thÃ©oriqueâ€) sera obtenu si les variables ont toutes 
deux modalitÃ©s, ce qui permet dâ€™obtenir une la valeur maximale qui vaut : 
     
4
3
4m
m
2
1y)(x,Smm2 =+=  
La borne Â« gÃ©nÃ©rale de Salomon Fortier Â» sâ€™Ã©crit dans ce cas : 
                              
m)P2(P
m)m)(P(P2m)P(P
2
1
2P
mP
m)-2(P
2m-P
2
1
2
MaxSMinS
âˆ’
+âˆ’+âˆ’
=


		





	

 +
+


		


=
+  
Si lâ€™on suppose que mpP= , il vient  en remplaÃ§ant P par cette valeur: 






âˆ’
âˆ’=
+
1)p(p2
11
2
1
2
MaxSMinS  
 
Lâ€™application de la rÃ¨gle de Salomon Fortier associÃ©e au cas de cet indice en environne-
ment disjonctif, nous donne, aprÃ¨s remplacement de P par m p  : 






âˆ’
âˆ’
â‰¥





âˆ’
âˆ’â‰¥
+
âˆ’+
1p2
2p2
2
my)11(x,
1)p(p2
11
2
1
2m-p2my)11(x,2
2mpmy)11(x,3  
Contrairement au cas prÃ©cÃ©dent, qui donnait une rÃ¨gle majoritaire indÃ©pendante de p . La 
rÃ¨gle associÃ©e ici est dÃ©pendante de p , mais tend  assez vite vers une rÃ¨gle de la majoritÃ© 
CondorcÃ©enne 
2
m
 , dÃ¨s lors que  p  est suffisamment grand. 
 
 
RNTI-A-3- 257 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
 
 
PropriÃ©tÃ© de lâ€™ indice de Marcotorchino-Michaud-2  en cas de disjonction complÃ¨te thÃ©orique 
En cas de disjonction complÃ¨te, la rÃ¨gle de Solomon - Fortier , si lâ€™on revient aux bornes max 
et min Â« thÃ©oriques Â» de lâ€™indice, induit lâ€™inÃ©galitÃ© suivante, oÃ¹ lâ€™on a remplacÃ© 
Â½(10(x,y)+01(x,y)) par sa valeur en fonction de 11(x,y) Ã  savoir m-11(x,y):  
         
2
m)y,x(11)y,x(00
2
m)y,x(00)y,x(11)]y,x(11m[)y,x(00)y,x(11
)y,x(00)y,x(11
2
1)y,x(S 2
1
2
1
2
12
1
2mm â‰¥+â‰¥+â‰¥
âˆ’++
+
â‰¥   
On constate,  dans ce cas,  que lâ€™on fait  encore disparaÃ®tre les configurations 00(x,y) de 
chaque cÃ´tÃ© de lâ€™inÃ©galitÃ© de la rÃ¨gle de Solomon Fortier. Dans ce cas particulier  lâ€™indice qui 
a Ã©tÃ© doublement rÃ©Ã©quilibrÃ© , aboutit cette fois ci sur une borne pour 11(x,y), qui nâ€™est rien 
dâ€™autre que la rÃ¨gle de la Â« majoritÃ©  simple Â».  Cette derniÃ¨re propriÃ©tÃ© en fait un indice en-
core plus intÃ©ressant que le prÃ©cÃ©dent  dans le cas de structures disjonctivÃ©es ou de tableaux  
de prÃ©sence-absence Ã  grands nombre de valeurs nulles,  il se comporte comme lâ€™indice de 
Dice , quoique Ã©tant dâ€™un Groupe diffÃ©rent.  
 
 
4.4.4 Indices du GROUPE II,  Type II (indices obtenus comme  ratios de fonc-
tions non linÃ©aires   des  quantitÃ©s du tableau Â« Tetrachorique Â») 
4.4.4.1 Indice liÃ© au Coefficient de corrÃ©lation Tetrachorique 
  Cet indice calcule le coefficient de corrÃ©lation Ã  partir du tableau Tetrachorique (il est Ã©ga-
lement connu sous le nom de coefficient de Bravais-Pearson) , tel quâ€™introduit au paragraphe 
Â§.3 (page 19),  il est dÃ©fini par :  
 
(f71)      
)]y,x(01)y,x(00)][y,x(10)y,x(00)].[y,x(01)y,x(11)][y,x(10)y,x(11[
)]y,x(01).y,x(10)y,x(00).y,x(11[)y,x(ST
++++
âˆ’
=
 
Contrairement aux autres indices, rencontrÃ©s prÃ©cÃ©demment,  cet indice varie de -1 Ã  +1, 
comme tout coefficient de corrÃ©lation. En particulier : 
â€¢ Il vaut   +1 si 10(x,y)   et  01(x,y)=0 
â€¢ Il vaut    â€“1 si   11(x,y)  et  00(x,y)=0 
 
Comportement asymptotique de ce coefficient pour des situations particuliÃ¨res 
  Dans le cas oÃ¹ lâ€™on se sert de ce coefficient ou indice de similaritÃ© sur des processus de 
Â« matching Â» de listes comme dans le cas de processus de recherche sur Internet (voir Â§ 
4.2.), la quantitÃ© 10(x,y) peut Ãªtre considÃ©rÃ©e comme un facteur de Â« bruit Â»,   inversement  
la quantitÃ© 01(x,y) peut Ãªtre considÃ©rÃ©e comme du Â« silence Â», on Â« rate Â» par x de lâ€™existant 
sur y, câ€™est la raison du mot Â« silence Â».Mais quâ€™en est-il de la quantitÃ© 00(x,y) ?. Dans le 
contexte dÃ©crit ci dessus, la quantitÃ© 00(x,y) reprÃ©sente ce qui nâ€™est pas liÃ© Ã  lâ€™univers dâ€™un 
questionnement, câ€™est Ã  dire Â« tout le reste Â» hors de la recherche reprÃ©sentÃ©e par x ou de 
RNTI-A-3 - 258 -
                                                                                                    F. Marcotorchino 
 
lâ€™univers quâ€™on veut atteindre reprÃ©sentÃ© par  y. De ce fait, il arrive quâ€™on ne soit pas ca-
pable de connaÃ®tre la taille de 00(x,y), qui par ailleurs est forcÃ©ment trÃ¨s trÃ¨s grande par 
rapport Ã  11(x,y), 01(x,y) ou 10(x,y) puisquâ€™il sâ€™agit du reste de lâ€™univers. Les quantitÃ©s 
10(x,y) et 01(x,y) sont nÃ©gligeables par rapport Ã  00(x,y) et dÃ¨s lors le coefficient ST(x,y) se 
simplifie suivant la formule : 
 
 
(f 72)            
2T )]y,x(00)].[y,x(01)y,x(11)][y,x(10)y,x(11[
)]y,x(00).y,x(11[)y,x(S
++
â‰…
 
 
Cette simplification permet dâ€™Ã©liminer 00(x,y), Ã  la fois au numÃ©rateur et au dÃ©nominateur, 
ce qui aboutit Ã  : 
 
(f 73)     
.R.P)y,x(01)y,x(11
)y,x(11
)]y,x(10)y,x(11[
)y,x(11
)]y,x(01)y,x(11)][y,x(10)y,x(11[
)y,x(11)y,x(ST =
++
=
++
â‰…
 
On retrouve ainsi la moyenne gÃ©omÃ©trique des indices de Rappel et de  PrÃ©cision, en 
dâ€™autres termes lâ€™Indice dâ€™Ochiai. 
 
PropriÃ©tÃ© nÂ°17: dans le cas oÃ¹ 00(x,y) est grand par rapport Ã   10(x,y) et 01(x,y), lâ€™indice de 
similaritÃ© fondÃ© sur le coefficient de corrÃ©lation tetrachorique a un comportement trÃ¨s voisin 
de celui de lâ€™indice dâ€™Ochiai et de fait varie de 0 Ã  1 et non de â€“1 Ã  +1: 
    )y,x(S)y,x(S oT â‰…  
 
Comportement de lâ€™indice ST(x,y) en cas  de Disjonction ComplÃ¨te 
En cas de disjonction complÃ¨te, comme nous lâ€™avons vu au Â§ 4.1.2 (PropriÃ©tÃ© nÂ°3),  nous 
avons Ã  notre disposition les formules dâ€™Ã©quivalence suivantes : : 
[ ] m)y,x(01)y,x(10
2
1)y,x(11 =++  
P)y,x(01)y,x(10)y,x(00)y,x(11 =+++  
 m2)y,x(11P)y,x(00 âˆ’+=   
Nous rajoutons en plus,  une relation Ã©vidente, que nous nâ€™avions pas exploitÃ©e prÃ©cÃ©-
demment et qui va nous servir ici : 
10(x,y)=01(x,y) ce qui implique que :  )y,x(11m)y,x(01)y,x(10 âˆ’==  
 
Lâ€™indice Â« Tetrachorique Â» se reformule alors selon lâ€™expression suivante : 
(f 74)       
)mP.(m
mP).y,x(11
]mP][mP].[m][m[
)]y,x(11m[]m2)y,x(11P).[y,x(11)y,x(S
22
T
âˆ’
âˆ’
=
âˆ’âˆ’
âˆ’âˆ’âˆ’+
=
 
Sous cette nouvelle expression, on voit que lâ€™indice vaut 1 si 11(x,y)=m,  et vaut :  
)mP(
m
âˆ’
âˆ’
 si 11(x,y)=0 
Il nâ€™a donc plus un intervalle de variation symÃ©trique  puisque : 1)y,x(S)mP(
m
T â‰¤â‰¤
âˆ’
âˆ’
 
 
RNTI-A-3- 259 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
Par ailleurs si lâ€™on Ã©talonne son comportement vis Ã  vis de la Â« Borne de Solomon et For-
tier Â», on obtient un rÃ©sultat qui prouve que cet indice, outre son comportement liÃ© asymp-
totiquement Ã  lâ€™indice dâ€™Ochiai , est un Â« bon Â» indice de similaritÃ©.  
 En effet comme 1)y,x(S)mP(
m
T â‰¤â‰¤
âˆ’
âˆ’
, le vÃ©ritable milieu de lâ€™intervalle de variation  de 
lâ€™indice ST(x,y), nâ€™est plus Â½ comme pour les indices rencontrÃ©s prÃ©cÃ©demment, mais  le 
milieu de  lâ€™intervalle: 




âˆ’
âˆ’ 1   ,
mP
m
  
Câ€™est Ã  dire que la quantitÃ©: 




âˆ’
âˆ’
mP
m12/1 ,  soit: 
)mP(2
m2P
âˆ’
âˆ’
 ,     devient la â€œborne de Solo-
mon- Fortierâ€ associÃ©e.  DÃ¨s lors   on voit que  la rÃ¨gle devient:  
2
my)11(x,        
m)-2(P
2.m-P
      
m)-m(P
m-y).P11(x,
        )mP.(2
m2P.
        )y,x(S
2
T â‰¥â‰¥
âˆ’
âˆ’
â‰¥ , 
 
On voit que dans ce contexte, le critÃ¨re se comporte exactement comme lâ€™indice de Dice 
au voisinage du milieu du segment de variation et lâ€™on retrouve la â€œrÃ¨gle de la MajoritÃ© de 
Condorcetâ€ .   
4.4.4.2 Indices DÃ©rivÃ©s, variantes   du Coefficient TÃ©trachorique 
Un nombre important dâ€™indices ont Ã©tÃ© dÃ©finis par de nombreux auteurs, en tenant compte 
du mÃªme numÃ©rateur que  lâ€™indice Tetrachorique, mais en faisant varier son dÃ©nominateur. 
Dans cette famille citons en quelques uns :    
 
a) Indice de Maxwell et Pilliner (1968) 
Ce coefficient qui varie de â€“1 Ã  +1 est dÃ©fini par : 
 
)]y,x(10)y,x(00)][y,x(01)y,x(11[)]y,x(01)y,x(00)][y,x(10)y,x(11[
)]y,x(01).y,x(10)y,x(00).y,x(11[2
)]y,y(00).y,y(11[)]x,x(00).x,x(11[
)]y,x(01).y,x(10)y,x(00).y,x(11[2)y,x(SMP
+++++
âˆ’
=
+
âˆ’
=
 
On constate que si 10(x,y)=01(x,y) , alors: 
)y,x(S)]y,x(10)y,x(00)][[y,x(10.)y,x(11[2
.]))y,x(10()y,x(00).y,x(11[2)y,x(S T
2
MP =
++
âˆ’
=
 
câ€™est exactement ce que vaut le coefficient  TÃ©trachorique dans ce cas. En particulier en 
cas de disjonction complÃ¨te , on a: 
[ ] m)y,x(01)y,x(10
2
1)y,x(11 =++   
10(x,y)=01(x,y) 
P)y,x(01)y,x(10)y,x(00)y,x(11 =+++  
m2)y,x(11P)y,x(00 âˆ’+=   
En remplaÃ§ant ces quantitÃ©s dans le coefficient de Maxwell et Pilliner, on obtient sa valeur 
en cas de disjonction complÃ¨te, soit: 
 
)mP.(m
mP).y,x(11)y,x(S
2
MP
âˆ’
âˆ’
=
, câ€™est exactement la valeur  quâ€™on avait obtenue pour le coefficient 
de similaritÃ© Tetrachorique,  voir formule (f74), ce qui veut dire que le coefficient de 
Maxwell et Pilliner a le mÃªme comportement que le coefficient Tetrachorique vis Ã  vis de 
la borne de Solomon et Fortier.  
RNTI-A-3 - 260 -
                                                                                                    F. Marcotorchino 
 
 Par ailleurs comme lâ€™a montrÃ©  M.J. Warrens  (2008), en revenant sur le positionnement 
des Moyennes: Harmonique, GÃ©omÃ©trique et ArithmÃ©tique (comme nous lâ€™avons fait au Â§ 
4.2.1.3), en utilisant le recodage â€œastucieuxâ€ suivant : 
)]y,x(10)y,x(00)][y,x(01)y,x(11[
)y,x(01)y,x(10)y,x(00).y,x(11
vet)]y,x(01)y,x(00)][y,x(10)y,x(11[
)y,x(01)y,x(10)y,x(00)y,x(11
u
++
âˆ’
=
++
âˆ’
=
 
on peut exprimer les indices de Maxwell et Pilliner et TÃ©trachorique comme respective-
ment les moyennes : Harmonique des quantitÃ©s u et v et GÃ©omÃ©trique des quantitÃ©s u et v 
sous la forme: 
v.u)y,x(Set)vu(
v.u2)y,x(S TMP =+=
 
Comme ces indices varient de â€“1 Ã  +1 ceci implique la propriÃ©tÃ© suivante au niveau des 
valeurs absolues des coefficients: 
 
 
b) Indice de  Fleiss (1975) 
 
Dans le mÃªme ordre dâ€™idÃ©e, la moyenne arithmÃ©tique de â€œuâ€ et â€œvâ€   existe,  il sâ€™agit dâ€™un 
coefficient fort peu connu et signalÃ© Ã©galement  par M.J. Warrens  dans M.J. Warrens 
(2008),  sous le nom de coefficient de J.L. Fleiss (1975), qui sâ€™Ã©crit:  
)vu(
2
1)y,x(SF +=  
])]y,x(10)y,x(00)][y,x(01)y,x(11[
1
)]y,x(01)y,x(00)][y,x(10)y,x(11[
1)][y,x(01)y,x(10)y,x(00)y,x(11[
2
1)y,x(SF
++
+
++
âˆ’=
 
LÃ  encore, si 10(x,y)=01(x,y) , le coefficient de Fleiss est Ã©gal au Coefficient Tetrachorique  
(câ€™est ce qui se produit en cas de disjonction complÃ¨te).  
Dâ€™autre part comme : Moyenne gÃ©omÃ©trique (u,v) â‰¤   Moyenne ArithmÃ©tique de (u,v),  
on obtient:     
 
 
Dans cette famille dâ€™indices dÃ©rivÃ©s de lâ€™indice Tetrachorique,  il apparaÃ®t clairement que ce 
dernier du fait de sa position de Â« mÃ©diane Â» des deux autres aura la prÃ©fÃ©rence des utilisa-
teurs, dâ€™autre part nous lâ€™avons vu, il joue un rÃ´le de Â« vrai Â» coefficient de corrÃ©lation.  
 
c)   Indices dÃ©duits de lâ€™InÃ©galitÃ© Â« au Determinant Â» de J. Hadamard 
Ces indices de similaritÃ©  ne sont  pas,   Ã  proprement parler , des  indices dÃ©couverts par 
Jacques Hadamard (1865-1963), mais parmi les multiples travaux du grand mathÃ©maticien, 
une inÃ©galitÃ© cÃ©lÃ¨bre qui porte son nom va nous servir, ici, pour donner lâ€™expression dâ€™un 
indice qui peut Ãªtre considÃ©rÃ© comme un dÃ©rivÃ© de lâ€™Indice TÃ©trachorique.  
En effet lâ€™inÃ©galitÃ© dâ€™Hadamard sâ€™Ã©tablit comme suit :  
ThÃ©orÃ¨me nÂ°2 :Soit M une matrice carrÃ©e dont les vecteurs colonnes sont  { V1, V2,â€¦ Vn }, on 
note 2kV , la norme euclidienne du vecteur colonne Vk : 

=
=
n
1s
2
ks2k vV  
, alors le thÃ©orÃ¨me 
dit  de Â« lâ€™inÃ©galitÃ© dâ€™Hadamard Â» stipule que lâ€™inÃ©galitÃ© suivante est vraie :          
                             
2n2221 V...VV]Mdet[ â‰¤  
1)y,x(S)y,x(S0 TMP â‰¤â‰¤â‰¤
1)y,x(S)y,x(S)y,x(S0 FTMP â‰¤â‰¤â‰¤â‰¤
RNTI-A-3- 261 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
Dans le cas oÃ¹ aucun des Vk nâ€™est nul, on a lâ€™Ã©galitÃ© si et seulement si les vecteurs Vk sont 
orthogonaux deux Ã  deux.  
 
ConsidÃ©rons alors  le tableau tÃ©trachorique suivant : 
 
 
 
 
 
 
Posons :  
 
                  M =  
 
 
De ce fait les  vecteurs colonnes associÃ©s sont  V1={11(x,y), 01(x,y)} et V2={10(x,y), 00(x,y)} et 
lâ€™application du ThÃ©orÃ¨me NÂ°2 se fait trivialement en se rappelant que pour cette  matrice 
2x2 ,  le determinant vaut :       )]y,x(01)y,x(10)y,x(00).y,x(11[]Mdet[ âˆ’=  
Lâ€™inÃ©galitÃ© de Hadamard implique donc :  
2222 )]y,x(00[)]y,x(10[)]y,x(01[)]y,x(11[)y,x(01)y,x(10)y,x(00).y,x(11 ++â‰¤âˆ’  
DÃ¨s lors la quantitÃ© suivante dÃ©nommÃ©e  : SHad (x,y), câ€™est Ã  dire:  
2222Had )]y,x(10[)]y,x(00[)]y,x(01[)]y,x(11[
)y,x(01)y,x(10)y,x(00).y,x(11)y,x(S
++
âˆ’
=
 
varie de â€“1 Ã  +1 , câ€™est donc bien un indice de similaritÃ© dÃ©rivÃ© de lâ€™Indice TÃ©trachorique. 
Cet indice vaut 1 si 01(x,y)=10(x,y)=0 et vaut â€“1 si 11(x,y)=00(x,y)=0 (câ€™est Ã  dire lorsque 
les vecteurs colonnes V1 et V2  sont orthogonaux, comme il  en est fait mention dans 
lâ€™intitulÃ© du  ThÃ©orÃ¨me NÂ°2.  Dâ€™autre part, comme on pouvait intervertir les roles de x et y 
dans la dÃ©finition de la Matrice M, on aurait tout aussi bien pu obtenir lâ€™indice suivant Ã  
partir de lâ€™inÃ©galitÃ© de Hadamard:  
 
2222'Had )]y,x(01[)]y,x(00[)]y,x(10[)]y,x(11[
)y,x(01)y,x(10)y,x(00).y,x(11)y,x(S
++
âˆ’
=
 
 Les bornes 1 et â€“1 Ã©tant atteintes dans les mÃªmes configurations que prÃ©cÃ©demment.    
 
Ainsi lors de la mÃªme faÃ§on que dans le cas des indices de Maxwell et Pilliner ou Fleiss , en 
posant:  u = SHad (x,y)  et v = S Hadâ€™(x,y)  
 
 
y = 1 y = 0 
x = 1 11 10 
x = 0 01 00 
11(x,y) 10(x,y) 
01(x,y) 00(x,y) 
RNTI-A-3 - 262 -
                                                                                                    F. Marcotorchino 
 
On peut dÃ©finir la famille des indices (symÃ©trisÃ©s) dÃ©rivÃ©s de Hadamard  suivants:    
   )vu()y,x(Setv.u)y,x(S)vu(
v.u2)y,x(S 213HAD2HAD1HAD +==+=
 
Ainsi par exemple on a:  
22222222
2HAD
)]y,x(10[)]y,x(00[])y,x(01[)]y,x(11[)]y,x(01[)]y,x(00[)]y,x(10[)]y,x(11[
)y,x(01)y,x(10)y,x(00).y,x(11)y,x(S
++++
âˆ’
=
 
Comme   pour tout couple de nombres positifs {a,b}: on  lâ€™inÃ©galitÃ©   22 ba)ba( +â‰¥+ , il  
apparaÃ®t de faÃ§on Ã©vidente que le dÃ©nominateur de ST(x,y) est supÃ©rieur  Ã  celui de 
SHAD2(x,y) et donc que lâ€™on a la les inÃ©galitÃ©s suivante: 
 
 
 
En jouant ensuite sur lâ€™ordonnance des moyennes pour les indices de Hadamard , couplÃ©e 
aux rÃ©sultats obtenus  prÃ©cÃ©demment en  b) il  vient :   
1)y,x(S)y,x(S)y,x(S)y,x(S)y,x(S0 3HAD2HADFTMP â‰¤â‰¤â‰¤â‰¤â‰¤â‰¤  
 
4.4.4.3 Les Indices Y et Q de Yule 
   Les indices de similaritÃ© Y et Q de Yule dont une premiÃ¨re version partielle est donnÃ©e 
dans le livre de  Yule et  Kendall (voir G. Yule et M.G. Kendall (1950)), et rÃ©Ã©tudiÃ©e par la 
suite par G. Yule, seul, se calculent Ã©galement Ã  partir du tableau de contingence Tetracho-
rique, puisquâ€™ils font jouer un rÃ´le  aux quatre quantitÃ©s principales en jeu. Sur le principe,  
lâ€™indice Y est le plus connu des deux,  on parle Ã  son sujet de coefficient de Â« colliga-
tion Â», en effet il a Ã©tÃ© construit Ã  partir des notions dâ€™ Â« odd ratios Â», souvent utilisÃ©s en 
statistique des contingences  par les anglo-saxons. Il est dÃ©fini par : 
  
(f 75)              
)y,x(01).y,x(10)y,x(00).y,x(11
)y,x(01).y,x(10)y,x(00).y,x(11)y,x(SY
+
âˆ’
=
 
Comme on le voit immÃ©diatement cet indice varie de -1 Ã  +1, il vaut : 
â€¢  1  si 10(x,y) ou  01(x,y)=0 
â€¢ -1  si 11(x,y) ou  00 (x,y) =0 
Contrairement au cas du Coefficient ST(x,y), il est a noter la prÃ©sence du Â« ou Â» et non du 
Â« et Â» pour lâ€™obtention des cas +1 et â€“1 de lâ€™indice, ceci, entre autre, permet de diffÃ©rencier 
les deux  indices, qui par ailleurs ont des comportements assez voisins.  
Contrairement au cas de lâ€™indice ST(x,y), il est Ã  noter, Ã©galement ici, que cet indice est peu 
(voire pas du tout) adaptÃ© aux situations  oÃ¹   00(x,y) est trÃ¨s grand, en effet  il est prati-
quement voisin de 1 dans ces cas lÃ  et donc peu discriminant.  
 
Lâ€™indice Q de Yule est une variante de lâ€™indice prÃ©cÃ©dent, en effet il sâ€™Ã©crit : 
  
1)y,x(S)y,x(S0 2HADT â‰¤â‰¤â‰¤
RNTI-A-3- 263 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
(f 76)              
)y,x(01).y,x(10)y,x(00).y,x(11
)y,x(10).y,x(01)y,x(00).y,x(11)y,x(SQ
+
âˆ’
=  
Il varie Ã©galement de â€“1 Ã  +1 et vaut :  
â€¢  1  si 10(x,y)  ou  01(x,y)=0 
â€¢ -1  si 11(x,y) ou  00 (x,y) =0 
 
Si lâ€™on compare lâ€™indice Q de Yule et lâ€™indice Tetrachorique, il est Ã©vident que lâ€™indice Q 
de Yule a une valeur qui sera toujours supÃ©rieure Ã  lâ€™indice  de lâ€™indice Tetrachorique . En 
effet on a Ã  comparer : 
 
)]y,x(01)y,x(00)][y,x(10)y,x(00)].[y,x(01)y,x(11)][y,x(10)y,x(11[
)]y,x(01).y,x(10)y,x(00).y,x(11[)y,x(ST
++++
âˆ’
=
 et   
)y,x(01).y,x(10)y,x(00).y,x(11
)y,x(10).y,x(01)y,x(00).y,x(11)y,x(SQ
+
âˆ’
=
 
Ces deux indices ont la mÃªme valeur du numÃ©rateur  et en revanche ils ont un dÃ©nomina-
teur diffÃ©rent . 
Or si lâ€™on pose y)y).01(x,10(x,y)y).00(x,11(x,A +=   et si lâ€™on Ã©lÃ¨ve le dÃ©nominateur de 
lâ€™indice y)(x,ST  au carrÃ© , on voit que le  dÃ©nominateur concernÃ© sâ€™Ã©crit: 
          (A+11(x,y)10(x,y)+00(x,y)01(x,y)) (A+11(x,y)01(x,y)+00(x,y)10(x,y))=A2+  (oÃ¹  
  0) 
 
Or le carrÃ© du dÃ©nominateur de lâ€™indice Q de Yule  est justement Ã©gal Ã  A2 , de ce fait on a: 
 
                       DÃ©nominateur de lâ€™indice Q de Yule  DÃ©nominateur de lâ€™indice TÃ©trachorique 
Ceci implique donc la relation: 
                                                    yx,y)(x,Sy)(x,S QT âˆ€â‰¤  
(car les deux indices peuvent Ãªtre positifs ou nÃ©gatifs) 
Par ailleurs, il serait intÃ©ressant de voir comment varient SY(x,y) et SQ(x,y), lâ€™un en fonction 
de lâ€™autre, puisquâ€™ils utilisent tous les deux les mÃªmes quantitÃ©s. Pour plus de simplicitÃ©, 
on va travailler sur leurs variantes transformant leur formalisme dâ€™indices de Â« corrÃ©la-
tion Â» variant de â€“1 Ã  +1 en indices de similaritÃ© variant de 0 Ã  1 , pour ce faire , il suffit de 
reprendre la note de bas de page nÂ°1 et calculer : 
                        yx,1]y)(x,S[
2
1y)(x,S'et1]y)(x,[S
2
1
 y)(x,S' QQYY âˆ€+=+=  
Les deux nouveaux indices sâ€™Ã©crivent alors : 
y)y).01(x,10(x,y)y).00(x,11(x,
y)y).00(x,11(x,y)(x,S'et
y)y).01(x,10(x,y)y).00(x,11(x,
y))y).00(x,11(x,y)(x,S' YQ
+
=
+
=
 
Dire que : 
                 
)yy).01(x,10(x,y)y).00(x,11(x,y)y).01(x,10(x,y)y).00(x,11(x,y)(x,S'y)(x,S' YQ â‰¥â‰¥â‰¥  
 ceci implique que :  
                                              
2
1y)(x,S'y)(x,S' YQ â‰¥â‰¥
,  
 
dans le cas inverse lâ€™inÃ©galitÃ© se produira dans le sens contraire et lâ€™on aura : 
                                              
2
1y)(x,S'y)(x,S' YQ â‰¤â‰¤
 
 
RNTI-A-3 - 264 -
                                                                                                    F. Marcotorchino 
 
Comportement des indices SY(x,y) et SQ(x,y) en cas  de Disjonction ComplÃ¨te 
En utilisant la sÃ©rie de formules dÃ©jÃ  mentionnÃ©e au Â§ prÃ©cÃ©dent , on peut simplifier 
lâ€™expression de ces deux indices dans le cas de disjonction complÃ¨te et lâ€™on obtient pour 
lâ€™indice SQ (x,y), (le seul Ã  pouvoir donner des simplifications interprÃ©tables puisque ne 
faisant pas appel Ã  des racines carrÃ©es)  :  
 
 (f 77)       
22
2
2
2
Q )]y,x(11m[2)m)y,x(11.P(
m)y,x(11.P
)]y,x(11m[]m2)y,x(11P).[y,x(11
)]y,x(11m[]m2)y,x(11P).[y,x(11)y,x(S
âˆ’+âˆ’
âˆ’
=
âˆ’+âˆ’+
âˆ’âˆ’âˆ’+
=
 
Sous cette derniÃ¨re forme on voit que lâ€™indice vaut :  1 si 11(x,y) = m et  â€“1 si 11(x,y)=0 
Puisque lâ€™intervalle de variation de SQ(x,y) est ici (-1,+1) le milieu de lâ€™intervalle de varia-
tion est Ã©gal Ã  0,. et de ce fait la borne de Solomon- Fortier  pour SQ(x,y) est donnÃ©e par :  
SQ(x,y)â‰¥0, ce qui implique : 
 
(f78)          
P
m)y,x(11         0m)y,x(11.P           0
)]y,x(11m[2)m)y,x(11.P(
m)y,x(11.P)y,x(S
2
2
22
2
Q â‰¥â‰¥âˆ’â‰¥
âˆ’+âˆ’
âˆ’
=
 
 
Montrons que cette borne pour 11(x,y),  bien que non aberrante lorsque le nombre moyen 
de modalitÃ©s par variable nâ€™est pas trop fort, le devient si ce nombre augmente . En effet 
nous savons que pmP = , oÃ¹ p  est le nombre moyen de modalitÃ©s par variable, de ce fait la  
borne donnÃ©e dans lâ€™Ã©quation (f 78) devient: 
 
                                            
p
m
pm
m
P
m)y,x(11     
22
==â‰¥  
Pour p=2 on retrouve la rÃ¨gle majoritaire simple ou de Condorcet , pour p=3 , on obtient 
une rÃ¨gle au tiers etc.,  en fait on obtient une rÃ¨gle inversement proportionnelle au nombre 
de modalitÃ©s moyen.  
 
En dâ€™autre termes cet indice nâ€™aura aucun pouvoir discriminant dÃ¨s lors que le nombre 
moyen de modalitÃ©s est fort (si par exemple on travaille sur m=10 variables, chacune ayant 
10 modalitÃ©s, on voit quâ€™il suffit que 11(x,y)=1 pour que lâ€™indice atteigne la borne de simi-
laritÃ© de Solomon-Fortier). 
Le lecteur pourra vÃ©rifier facilement par lui-mÃªme  que la  borne sur 11(x,y) associÃ©e Ã  la 
rÃ¨gle de  Solomon-Fortier est exactement la mÃªme pour  lâ€™indice SY(x,y) que celle associÃ©e 
Ã  lâ€™indice SQ(x,y) et donnÃ©e par la formule (f 78).  
 
4.4.4.4 Lâ€™indice de Moyenne ArithmÃ©tique des Â« quatre ratios Â» dâ€™Anderberg (1973) 
Cet indice qui est explicitement dÃ©fini dans le livre de Michael Anderberg (1973), page 
91, a Ã©tÃ© introduit par ce dernier comme une gÃ©nÃ©ralisation de la moyenne arithmÃ©tique 
des indices de Â« Rappel Â» et Â« PrÃ©cision Â» de Kulczynski Ã  lâ€™ensemble des ratios probabi-
listes possibles, issus du tableau Tetrachorique. Certain lâ€™attribue dâ€™ailleurs Ã  Sokal et 
Sneath (1963).  Il se dÃ©finit de la faÃ§on suivante : 
 
RNTI-A-3- 265 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
(f79)      






+
+
+
+
+
+
+
= )y,x(10)y,x(00
)y,x(00
)y,x(01y,x(00
)y,x(00
)y,x(01)y,x(11
)y,x(11
)y,x(10)y,x(11
)y,x(11
4
1)y,x(S 4R  
 
Cet indice varie bien de 0 Ã  1, il vaut: 
â€¢ 1 si 10(x,y)=01(x,y)=0   
â€¢ 0 si 11(x,y)=00(x,y)=0 
En sâ€™inspirant  de la propriÃ©tÃ© du passage aux moyennes harmoniques des quantitÃ©s 
11(x,x), 11(y,y), 00(x,x), 00(y,y) ,  dÃ©jÃ  vue au sujet de lâ€™indice de Kulczynski  (voir (f 35)) 
on a une autre expression posssible et plus compacte  de cet indice : 
(f 80)              






+=
y)]x),00(y,[00(x,MH
y)00(x,
y)]x),11(y,[11(x,MH
y)11(x,
2
1y)(x,SR4
 
 
Le dÃ©veloppement de la formule (f 79) par rÃ©duction au mÃªme  dÃ©nominateur  est possible 
mais entrainerait des calculs fastidieux, le dÃ©nominateur serait identique par ailleurs au 
carrÃ© de celui de la formule (f 71) concernant le coefficient de corrÃ©lation Tetrachorique.  
 
Comportement de lâ€™indice SR4(x,y) en cas  de Disjonction ComplÃ¨te 
Comme nous lâ€™avons fait prÃ©cÃ©demment, un bon moyen de comprendre un peu plus avant 
comment se comporte cet indice revient Ã  le calculer dans le contexte particulier de la 
situation de disjonction complÃ¨te. En effet dans ce cas la formule globale se simplifie et un 
certain nombre de propriÃ©tÃ©s caractÃ©ristiques peuvent Ãªtre mises en Ã©vidence. En effet en 
cas de disjonction complÃ¨te lâ€™indice SR4 (x,y) se simplifie selon la formulation suivante : 
   
       




âˆ’
âˆ’+
+=



âˆ’
âˆ’+
+
âˆ’
âˆ’+
++=
mP
m2)y,x(11P
m
)y,x(11
2
1
mP
m2)y,x(11P
mP
m2)y,x(11P
m
)y,x(11
m
)y,x(11
4
1)y,x(S 4R
 
 
ce qui, aprÃ¨s rÃ©duction au mÃªme dÃ©nominateur et simplifications au numÃ©rateur,  nous 
donne: 
 
 (f 81)       
)mP(m.2
mP).y,x(11
2
1
)mP(m.2
)mP(mmP).y,x(11
mP
m2)y,x(11P
m
)y,x(11
2
1)y,x(S
22
4R
âˆ’
âˆ’
+=
âˆ’
âˆ’+âˆ’
=



âˆ’
âˆ’+
+=
 
Sous cette derniÃ¨re forme on voit que lâ€™indice vaut 1 si 11(x,y)=m  (sa valeur maximum) et 
vaut: 
)mP.(2
m
2
1
âˆ’
âˆ’
, soit 
)mP.(2
m.2P
âˆ’
âˆ’ si 11(x,y)=0, son intervalle de variation est donc:  
1)y,x(S)mP.(2
m.2P
4R â‰¤â‰¤
âˆ’
âˆ’
, et le milieu du segment associÃ© est donnÃ© par:  
                                 
)mP(4
P1)mP(4
m4P3
)mP.(2
m.2P1
2
1
âˆ’
âˆ’=
âˆ’
âˆ’
=








âˆ’
âˆ’
+  
Si lâ€™on applique la rÃ¨gle de Solomon-Fortier sur cette valeur prÃ©cÃ©dente comme Ã©talonna-
ge de lâ€™ indice, on obtient:   
(f 82)         
2
my)11(x,         )mP(4
P1)mP(m2
mP)y,x(11
2
1
            )mP(4
P1)y,x(S
2
4R â‰¥
âˆ’
âˆ’â‰¥
âˆ’
âˆ’
+
âˆ’
âˆ’â‰¥  
 
RNTI-A-3 - 266 -
                                                                                                    F. Marcotorchino 
 
LÃ  encore, on voit que la rÃ¨gle de Solomon Fortier  appliquÃ©e Ã  cet indice, avec  un seuil 
â€œmilieu dâ€™intervalle de variationâ€,  redonne la rÃ¨gle de la majoritÃ© simple de Condorcet au 
niveau dâ€™une borne sur 11(x,y). Cet indice bien que complexe Ã  calculer est donc plus 
cohÃ©rent que les deux indices de Yule. En particulier il semble avoir un comportement 
voisin de celui de lâ€™indice Tetrachorique Ã  une homothÃ©tie prÃ¨s. 
 
4.4.4.5  Lâ€™indice de Moyenne GÃ©omÃ©trique  des Â« quatre ratios Â» dâ€™Ochiai (1973) 
 Cet indice comme le prÃ©cÃ©dent est une gÃ©nÃ©ralisation sur les 4 cases du tableau Tetracho-
rique de lâ€™indice dâ€™Ochiai , on peut dâ€™ailleurs  lâ€™attribuer Ã©galement Ã  Anderberg, mÃªme si 
ce dernier en donne la paternitÃ© au zoologiste Japonais, par filiation. Câ€™est de faÃ§on simple 
la moyenne gÃ©omÃ©trique dâ€™ordre 4 des quatre ratios prÃ©cÃ©demment dÃ©finis pour lâ€™indice 
SR4(x,y). Cet indice est dÃ©fini par :  
 
(f83)     44o )y,x(01)y,x(00
)y,x(00
x)y,x(10)y,x(00
)y,x(00
x)y,x(01)y,x(11
)y,x(11
x)y,x(10)y,x(11
)y,x(11)y,x(S
++++
=
 
Cet indice varie de 0 Ã  1, il vaut : 
â€¢ 1 si 10(x,y)=01(x,y)=0 
â€¢ 0 si 11(x,y)=00(x,y)=0 
   
Comportement de lâ€™indice So4(x,y) en cas  de Disjonction ComplÃ¨te 
 Comme nous lâ€™avons fait pour lâ€™indice dâ€™Anderberg prÃ©cÃ©dent, pour avoir une bonne idÃ©e du 
comportement de cet indice, calculons  sa valeur  dans le contexte particulier de la situation 
de disjonction complÃ¨te. En effet dans ce cas la formule globale se simplifie, et comme dans 
le cas de SR4(x,y)  un certain nombre de propriÃ©tÃ©s caractÃ©ristiques peuvent Ãªtre mises en 
Ã©vidence. En effet en cas de disjonction complÃ¨te lâ€™indice  So4(x,y) se simplifie selon la for-
mulation suivante : 
 
(f 84)        44o
mP
m2)y,x(11P
x
mP
m2)y,x(11P
x
m
)y,x(11
x
m
)y,x(11)y,x(S
âˆ’
âˆ’+
âˆ’
âˆ’+
=
 
 
Soit aprÃ¨s simplifications :  
(f 85)        
mP
m2)y,x(11P
x
m
)y,x(11)y,x(S 4o
âˆ’
âˆ’+
=
 
 
 
Sous cette forme  simplifiÃ©e, on voit que cet indice vaut 1 si 11(x,y)=m (valeur maximum du 
Â« matching Â» en cas de disjonction complÃ¨te) et il vaut 0 si 11(x,y)=0. 
A titre de comparaison  et pour lâ€™Ã©talonner, calculons la borne induite sur 11(x,y) dÃ¨s que lâ€™on 
applique la rÃ¨gle de Solomon et Fortier. Ici lâ€™intervalle de variation, mÃªme dans ce cadre 
disjonctif est (0, 1), la borne de la rÃ¨gle de Solomon- Fortier est donc fixÃ©e Ã  Â½ , dâ€™oÃ¹ : 
 
 (f 86)                      
     
2
1
mP
m2)y,x(11P
x
m
)y,x(11
            
2
1)y,x(S 4o â‰¥
âˆ’
âˆ’+
â‰¥  
 
RNTI-A-3- 267 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
 
 
 
 
 
 
 
Le dÃ©veloppement de la formule (f 85) aboutit Ã  rÃ©soudre lâ€™inÃ©galitÃ© du second degrÃ© en 11(x,y) suivante14 : 
0   )mP.(m
4
1
-y)2m).11(x,-(P  y)(x,11 2 â‰¥âˆ’+  ,  avec  3m3mP-Pm)m(P2m)(P 222 +=âˆ’+âˆ’=  
le calcul du dÃ©terminant de cette Ã©quation et le fait que  11(x,y) varie de 0 Ã  m, donc est toujours positif, nous permet 
de dÃ©finir la racine positive de lâ€™Ã©quation qui est donnÃ©e par : 
                              [ ][ ] pmPoÃ¹1)2p)(1p(m)2p(m
2
1
z
2
1 =+âˆ’âˆ’+âˆ’âˆ’=
  
Comme : 
                         [ ][ ] 





+âˆ’+âˆ’âˆ’=+âˆ’âˆ’+âˆ’âˆ’ )1)1p((
p
1
m)2p(m
2
11)2p)(1p(m)2p(m
2
1 32 ,  
on obtient : 








âˆ’
+âˆ’âˆ’+âˆ’âˆ’= ]
)1p(
1)1p[(
p
1)1p(m)2p(m
2
1
z
21
en simplifiant lâ€™expression sous le signe Â« racine carrÃ©e Â» et en 
utilisant un dÃ©veloppement limitÃ© de la racine carrÃ©e au voisinage de 0 (ce qui a dâ€™autant plus de sens que p  est non 
nÃ©gligeable), il vient :     
                             
2
222 1)p(
1
p
1
8
1
1)p(
1
p.
1
2
11
1)p(
1
p
11 





âˆ’
âˆ’+





âˆ’
âˆ’âˆ’â‰…





âˆ’
+âˆ’
  
en remplaÃ§ant cette valeur dans lâ€™expression de z1, on obtient la une valeur trÃ¨s lÃ©gÃ¨rement supÃ©rieure pour z1,  Ã  
savoir : 









		


+
âˆ’
++âˆ’âˆ’++âˆ’â‰…














âˆ’
âˆ’âˆ’âˆ’+âˆ’âˆ’= )
p
1(O
1)p( 2
1
p 8
1
p2
111)pm(2mpm
2
1
1)p(
1
p
111)pm(2)pm(
2
1
z 32221
, 
Pour satisfaire lâ€™inÃ©galitÃ© (f 86), 11(x,y) doit Ãªtre supÃ©rieur Ã  lâ€™approximation de z1,  donnÃ©e ci-dessus . 
La borne de la rÃ¨gle de Solomon-Fortier devient alors  :   
                                                
1)p(p8
5]pm[9.
4
my)11(x,
âˆ’
âˆ’
+â‰¥      
Si le nombre moyen de modalitÃ©s est Ã©gal Ã  5 par exemple,  on voit que 11(x,y) doit vÃ©rifier approximativement  une 
rÃ¨gle de majoritÃ© CondorcÃ©enne simple (m/2). 
On voit quâ€™Ã  la limite, si  p  croÃ®t, la borne tend vers 
4
m
, câ€™est Ã  dire  vers une Â« majoritÃ© au 
quart Â».  
Dans ce cas lÃ , comme dâ€™ailleurs dans le cas dâ€™indices du Groupe I Type II auquel lâ€™indice 
dâ€™Ochiai , vrai, appartient, on voit que cet indice est plus Â« gÃ©nÃ©reux Â»  que lâ€™indice des Â« 4 
ratios dâ€™Anderberg Â» , voire trop gÃ©nÃ©reux ce qui montre quâ€™il nâ€™a que peu dâ€™intÃ©rÃªt comme 
mesure discriminante. 
                                                 
14
 Les valeurs de 11(x,y) Ã©tant entiÃ¨res, les calculs sur lâ€™inÃ©galitÃ© (f 86) se font en supposant une relaxation en 
valeurs rÃ©elles de 11(x,y) , 0 â‰¤ 11(x,y) â‰¤ m, au lieu dâ€™avoir 11(x,y) âˆˆ { 0,1,2,â€¦m } 
 
 
RNTI-A-3 - 268 -
                                                                                                    F. Marcotorchino 
 
4.4.4.6 Lâ€™indice de Moyenne Harmonique  des Â« quatre ratios Â» 
    Continuant dans le mÃªme principe de gÃ©nÃ©ralisation que prÃ©cÃ©demment, nous dÃ©finirons 
un indice de  moyenne harmonique des quatre ratios tetrachoriques, en  dÃ©finissant ce nouvel 
indice Sh4(x,y) par : 
(f 84)       





 +
+
+
+
+
+
+
= )y,x(00
)y,x(01)y,x(00
)y,x(00
)y,x(10)y,x(00
)y,x(11
)y,x(01)y,x(11
)y,x(11
)y,x(10)y,x(11
4
1
)y,x(S
1
4h
 
 
Cet indice peut Ãªtre simplifiÃ© selon la formule: 
  





 ++
+
++
= )y,x(00
)y,x(01)y,x(10)y,x(00.2
)y,x(11
)y,x(01)y,x(10)y,x(11.2
4
1
)y,x(S
1
4h
 
Comme par ailleurs : 11(x,y)+00(x,y)+10(x,y)+01(x,y)=P, il peut Ãªtre exprimÃ© uniquement en 
fonction des quantitÃ©s 00(x,y) et 11(x,y), il vient: 
 
                 





 +âˆ’
+
+âˆ’
= )y,x(00
)y,x(00.)y,x(11P
)y,x(11
)y,x(11)y,x(00P
4
1
)y,x(S
1
4h
 
 
AprÃ¨s rÃ©duction au mÃªme dÃ©nominateur et inversion de la formule il vient: 
                   








âˆ’âˆ’+
= 24h )]y,x(11y,x(00[)]y,x(00)y,x(11[P
)y,x(00).y,x(114)y,xS  
 
Sous cette derniÃ¨re formulation on voit que   cet indice vaut : 
â€¢ 1 si 10(x,y)=01(x,y)=0 , en effet dans ce cas P=00(x,y)+11(x,y) et le dÃ©nominateur revient 
Ã  : 4.11(x,y).00(x,y) 
â€¢ 0 si 11(x,y) =0  
Comportement de lâ€™indice Sh4(x,y) en cas  de Disjonction ComplÃ¨te 
Comme prÃ©cÃ©demment donnons un Ã©talonnage de cet indice par rapport Ã  la rÃ¨gle de Solo-
mon et Fortier en cas de disjonction complÃ¨te. En remplaÃ§ant 00(x,y) par P+11(x,y)-2m, et en 
revenant Ã  la formule (f74) nous avons  lâ€™expression suivante de lâ€™indice: 
 
(f88)                           






âˆ’+
âˆ’
+=
m2)y,x(11P
)mP(
)y,x(11
m
2
1
)y,x(S
1
4h
 
 
A partir de  cette expression obtenue lors dâ€™une disjonction complÃ¨te, on voit bien que cet 
indice est maximum lorsque 11(x,y)=m,  puisque quâ€™alors on trouve 2/2. 
 
Calculons maintenant la valeur de la borne sur 11(x,y), lorsquâ€™on applique la rÃ¨gle de Solo-
mon et Fortier. 
Puisque lâ€™intervalle de variation est bien: (0, 1), la borne choisie pour lâ€™indice sera Â½. 
 
La formule (f 88) induit donc lâ€™inÃ©galitÃ© fonction de 11(x,y) suivante:  
2
1
)m2P(mP).y,x(11
]m.2)y,x(11P)[y,x(11.2
              
2
1)y,xS 4h â‰¥
âˆ’+
âˆ’+
â‰¥  
 
RNTI-A-3- 269 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
Ce qui implique lâ€™inÃ©galitÃ© quadratique suivante pour 11(x,y): 
 (f 89)                 0)m2P(m]m.8P.3)[y,x(11)y,x(11.4 2 â‰¥âˆ’âˆ’âˆ’+   
 
En tenant compte de la remarque faite dans la note de bas de page nÂ°4, la borne infÃ©rieure sur 11(x,y) sera la racine 
positive de lâ€™Ã©quation du second degrÃ© prÃ©cÃ©dente. Le dÃ©terminant nâ€™est pas simple, il est Ã©gal Ã  : 
[ ] [ ] 222 Pm2P.8)m2P(m16m8P3 +âˆ’=âˆ’+âˆ’=Î”  
La racine positive z1 est donnÃ©e par : 
8
P]m.2P[8P3m8
z
22
1
+âˆ’+âˆ’
=
 en jouant sur le fait que pmP = , on obtient : 






+=





+âˆ’=





+âˆ’+âˆ’â‰…





+âˆ’+âˆ’=
+âˆ’+âˆ’
=
p9
341
3
m
p27
272
3
168
8
m]
p81
272
p9
16[1p3p38
8
m
p9
32
p9
321p3p38
8
m
8
1]
p
28[1pm)p3m(8
z 22
2
1
 
Lâ€™approximation sur la racine carrÃ©e Ã©tant dâ€™autant plus significative que p  est fort, on voit que la borne pour 
11(x,y)  se traduit ici par : 
     






+â‰¥
p
3.771
3
my)11(x, ,  
 
4.4.4.7 Indice de Baroni-Urbani  et  Buser  (1976)  
   Cet indice,  introduit en 1976 (voir Baroni, Urbani et Buser (1976)) par des spÃ©cialistes de 
systÃ©matique zoologique se distingue des prÃ©cÃ©dents en ce sens quâ€™il dissymÃ©trise lâ€™influence 
des configurations de Â« matchings Â»,  quâ€™il traite non linÃ©airement , des configurations de 
Â« non matching Â» , quâ€™il traite linÃ©airement, le  tout en pondÃ©rant lÃ©gÃ¨rement plus le Â« mat-
ching 11 Â», bref un indice pas Â« naturel  du tout Â» quant Ã  sa filiation . Cependant il semble 
donner satisfaction aux experts des  domaines de la zoologie (systÃ©maticiens, phylogÃ©nistes), 
de la biologie (spÃ©cialistes des mesures de bio-diversitÃ©)  ou de lâ€™Ã©cologie en gÃ©nÃ©ral (voir Ã  
ce propos  lâ€™article de  Richard Boyle et Paula Ellison  (2001)).  
 
 (f 90)                   








+++
+
=
y)10(x,y)01(x,y)11(x,y)y).00(x,11(x,
y)11(x,y)y).00(x,11(x,
y)(x,SBuB
 
Cet indice varie  bien de 0 Ã  1, il vaut 1 quand 10(x,y)=01(x,y)=0 et il vaut 0 quand 11(x,y)=0 . 
Pour ce faire une idÃ©e de plus prÃ©cise de cet indice on peut le comparer Ã  lâ€™indice Y de Yule, 
donnÃ© par : 
 
                                    
y)y).01(x,10(x,y)y).00(x,11(x,
y)y).01(x,10(x,y)y).00(x,11(x,
y)(x,SY
+
âˆ’
=
 
qui met en jeu des  quantitÃ©s voisines.  Mais ce dernier, on lâ€™a vu,, se comporte comme un 
indice de type indice de corrÃ©lation puisquâ€™il varie de -1 Ã  1,  mais en utilisant la remarque de 
bas de page nÂ°1, on sait que : S(x,y)=1/2(xy+1) construit Ã  partir dâ€™un indice de corrÃ©lation rede-
vient un indice de similaritÃ© variant de 0 Ã  1.  
On peut donc comparer lâ€™indice   y)(x,SBuB   
Ã  lâ€™indice       [ ]
y)y).01(x,10(x,y)y).00(x,11(x,
y)y).00(x,11(x,1y)(x,S
2
1y)(x,S YY'
+
=+=
 
Pour ce faire montrons que : 
RNTI-A-3 - 270 -
                                                                                                    F. Marcotorchino 
 
                               
y)00(x,y)10(x,y)11(x,y)y).00(x,11(x,
y)11(x,y)y).00(x,11(x,
y)y).01(x,10(x,y)y).00(x,11(x,
y)y).00(x,11(x,
+++
+
â‰¥
+
 
En effet aprÃ¨s dÃ©veloppement on obtient : 
 
         (i) y)y).01(x,10(x,y)]11(x,y)y).00(x,11(x,[y)y).00(x,11(x,y)]01(x,y)[10(x, +â‰¥+  
Or    (ii)  y)y).01(x,10(x,2y)01(x,y)10(x,]y)01(x,y)10(x,[ 2 âˆ’+=âˆ’ ,  
 
en remplaÃ§ant  lâ€™expression de 10(x,y)+01(x,y) , telle quâ€™elle apparaÃ®t dans (ii) et en la repor-
tant dans (i) , on obtient :  
        
(iii) [ ] y)y).01(x,10(x,y)]11(x,y)y).00(x,11(x,[y)y).00(x,11(x,y)y).01(x,10(x,2]y)01(x,y)10(x,[ 2 +â‰¥+âˆ’  
soit  aprÃ¨s simplification: [ ] ]y)y).00(x,11(x,y)]11(x,[y)y).01(x,10(x,[y)y).00(x,11(x,]y)01(x,y)10(x,[ 2 âˆ’â‰¥âˆ’  
Le membre de gauche de cette inÃ©galitÃ© est toujours positif , alors que le membre de droite 
est toujours nÃ©gatif , sauf en cas de disjonction bivalente, i.e ; P=2m. En effet en gÃ©nÃ©ral  
00(x,y) 11(x,y) dâ€™oÃ¹ :   y)11(x,y)y).00(x,11(x, â‰¥  
De ce calcul nous dÃ©duisons : 
                                                        yx,y)(x,Sy)(x,S' BuBY âˆ€â‰¥  
Comportement de lâ€™indice SBuB(x,y) en cas  de Disjonction ComplÃ¨te 
En cas de disjonction complÃ¨te, on dÃ©veloppe lâ€™expression prÃ©cÃ©dente  en fonction de 11(x,y), 
de P et de m  selon les formules  obtenues en remplaÃ§ant  00(x,y), 10(x,y) et 01(x,y) par leurs 
valeurs en fonction de 11(x,y) et de P, du fait que  on retrouve : 00(x,y)=11(x,y)+P-2m, 
01(x,y)=10(x,y)=m-11(x,y), 
 
       








âˆ’++
++
=
y)11(x,2m2m]-Py)y)[11(x,11(x,
y)11(x,2m]-Py)y)[11(x,11(x,
y)(x,SBuB
 
Comme la borne de  Solomon Fortier  vaut Â½ , puisque lâ€™indice varie bien de 0 Ã  1, la borne 
de rÃ©fÃ©rence sera obtenue pour la valeur  11(x,y) , telle que:     
2
1
y)11(x,2m2m]-Py)y)[11(x,11(x,
y)11(x,2m]-Py)y)[11(x,11(x,
2
1
 y)(x,SBuB â‰¥








âˆ’++
++
â‰¥
 
 
Cette inÃ©galitÃ© implique lâ€™Ã©quation  du second degrÃ© suivante: 
                           04m10]mpy)[11(x,y)(x,8.11 22 â‰¥âˆ’++âˆ’  (oÃ¹  lâ€™on  a remplacÃ© P par pm ) 
 
On  prend la racine positive z1, comme nous lâ€™avons fait prÃ©cÃ©demment en simplifiant les expressions sous  les 
racines, nous obtenons: 






âˆ’=





âˆ’=











+âˆ’âˆ’+âˆ’+â‰…





âˆ’+âˆ’+=
âˆ’+âˆ’+
=
p4
354
p
m
p
140
p
64
16
m
p
140
p
50
p
14
p
101pp10
16
m
p
28
p
20
 1pp10
16
m
16
]
p
28
p
20[1pm10]pm[
z 23222
2
1
 
                        Ceci implique donc que :     






âˆ’â‰¥
p4.
354
p
my)11(x,  
On voit par exemple que si 4p = , alors 11(x,y) doit Ãªtre supÃ©rieur Ã   0,45 m , câ€™est Ã  dire que si m=9 (par exemple)  
on doit avoir 11(x,y)4, (puisque les valeurs de 11(x,y) sont toujours des valeurs entiÃ¨res), on vÃ©rifie bien  dâ€™aprÃ¨s  
la formule(f87)  que : 
RNTI-A-3- 271 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
 
57,0
38,23
38,13
1488
488
)418()18364.(4
4)18364.(4
y)11(x,2m2m]-Py)y)[11(x,11(x,
y)11(x,2m]-Py)y)[11(x,11(x,
y)(x,SBuB ==
+
+
=
âˆ’+âˆ’+
+âˆ’+
=








âˆ’++
++
=
 
On voit dâ€™ailleurs sur cet exemple quâ€™il faut que 11(x,y) soit strictement supÃ©rieur Ã  4 , si 11(x,y) nâ€™Ã©tait Ã©gal quâ€™ Ã  3 
la valeur de lâ€™indice serait Ã©gale Ã   0,4768, ce qui ne permettrait pas de vÃ©rifier la Borne de Solomon Fortier. 
Le comportement  limite de lâ€™indice nâ€™est pas Ã©vident si   p  prend des valeurs  grandes, on 
voit que la borne implique  une majoritÃ© au 
p
4
  Ã¨mes, ce qui nâ€™en fait pas un indice de carac-
tÃ¨re gÃ©nÃ©ral utilisable dans des conditions standard.  
 
4.4.5 Indices du GROUPE II,  Type III (indices obtenus comme  ratios de fonc-
tions complexes  non standard  des  quantitÃ©s du tableau Â« Tetrachorique Â») 
     Dans ce paragraphe nous introduirons certains indices utilisÃ©s en statistique  pour mesurer 
les interactions et les associations sur tableaux de contingences,  puisque le tableau Tetracho-
rique  nâ€™est, aprÃ¨s tout, quâ€™un tableau de contingence (2x2) particulier.   
 
Dans cette configuration lâ€™utilisation des coefficients dâ€™association sur tableau de contin-
gence peut ou non (cela dÃ©pend du contexte ) servir de base Ã  des indicateurs de similaritÃ©, Ã  
condition dâ€™une part de distinguer les configurations dites de Â« matchings Â» positifs des con-
figurations  de Â« matchings Â» nÃ©gatifs, ce que ne font pas dâ€™amblÃ©e ces coefficients 
dâ€™association .   
Rappelons ici quâ€™un tableau de contingence croisant deux variables catÃ©gorielles x et y, x 
ayant p modalitÃ©s  et y ayant q modalitÃ©s se prÃ©sente sous la forme suivante :   
 
 
 
    
 
 
 
 
 
 
 
 
 
OÃ¹  







=
=
=
=
objetsd'totalNombren
ydevmodalitÃ©laayantobjetsd'Nombren
xdeumodalitÃ©laayantobjetsd'Nombren
,ydevetxdeumodalitÃ©lafoislaÃ ayantobjetsd'Nombren
..
v.
.u
vu
 
 
Nous donnerons dans les paragraphes suivants des coefficients ou indices dâ€™association que 
nous Ã©valuerons en tant quâ€™indices de similaritÃ©. Ceci se fera au travers dâ€™un processus con-
     y 
x 
1 2 v .. q 
 
1      n1. 
2      n2. 
u   vun  
  
 n
 u . 
..       
p       
 
n
.1 n.2 n. v   n.. 
RNTI-A-3 - 272 -
                                                                                                    F. Marcotorchino 
 
sistant Ã  remplacer les valeurs vun  du tableau de contingence gÃ©nÃ©ral prÃ©cÃ©dent par les 
valeurs correspondantes du tableau particulier de contingence que nous avons nommÃ© Â« Te-
trachorique Â» et qui se prÃ©sente sous la forme :  
 
  
 
 
 
 
 
Dans le cas du tableau Tetrachorique les valeurs p et q  du tableau gÃ©nÃ©ral   sont Ã©gales Ã  2 , 
la valeur Pn
..
= ,   et les diffÃ©rentes  valeurs vun sont au nombre de 4, Ã  savoir : 11(x,y), 
10(x,y , 01(x,y) et 00(x,y).   
 
4.4.5.1  Indice de similaritÃ© dÃ©duit  du Coefficient dâ€™Ecart Ã  lâ€™IndÃ©termination Contingen-
tielle, du coefficient de Janson-Vegelius et du CritÃ¨re de Rand 
 
 Rappelons que cet indice dâ€™  Â« Ecart Ã  lâ€™IndÃ©termination Â» , dont on pourra trouver les pro-
priÃ©tÃ©s dans  F. Marcotorchino (1984) et F. Marcotorchino et N. El Ayoubi (1991), se prÃ©-
sente sous la forme : 
                                           


= =









		


âˆ’+âˆ’=
p
1u
q
1v
2
..v.u.
uv pq
n
p
n
q
n
ny)Ind(x,  
Cet indice est en fait le numÃ©rateur du coefficient J(x,y) de Janson et Vegelius (voir S. Janson 
et J. Vegelius  (1982)) , coefficient spÃ©cial de corrÃ©lation,  donnÃ©  lui-mÃªme sous la forme 
dâ€™un ratio composite : 
 
(f 91)                                                  
y)D(x,
y)N(x,y)J(x, =  
Le numÃ©rateur est donnÃ© par : 
                                          
pq
n
p
n
q
n
ny)N(x,
2
..
q
1v
2
v.
p
1u
2
.up
1u
q
1v
2
vu +âˆ’âˆ’=





 ==
= =
 
le dÃ©nominateur Ã©tant donnÃ© par :  
                                          


==
+





âˆ’+





âˆ’=
q
1v
2
2
..2
v.
p
1u
2
2
..2
.u q
n
q
21n
p
n
p
21ny)(x, D   
 
Par ailleurs,  on peut montrer ( voir les articles prÃ©citÃ©s de  (1984) et (1991) ) que : 
 
 y = 1 y = 0 
x= 1 11(x,y) 10(x,y) 
x= 0 01(x,y) 00(x,y) 
RNTI-A-3- 273 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
     y)N(x,
pq
n
p
n
q
n
n
pq
n
p
n
q
n
ny)(x,Ind
2
..
q
1v
2
v.
p
1u
2
.up
1u
q
1v
p
1u
2
vu
q
1v
2
..v.u.
uv =+âˆ’âˆ’=








		


âˆ’+âˆ’=





 

 ==
= = = =
 
  
Cet indice  J(x,y) varie bien de 0 Ã  1 . 
â€¢ Il  vaut 0 en cas dâ€™IndÃ©termination totale sur toutes les cases du tableau de contingence 
voir F. Marcotorchino (1984) pour des dÃ©tails sur cette structure particuliÃ¨rement intÃ©-
ressantes  des donnÃ©es), câ€™est Ã  dire si : 
vetu
pq
n
p
n
q
n
n0
pq
n
p
n
q
n
n
..v.u.
vu
p
1u
q
1v
2
..v.u..
uv âˆ€


		


âˆ’+==











		


âˆ’+âˆ’


= =
 
â€¢ Il vaut 1 en cas dâ€™association complÃ¨te (voir (M1984)), câ€™est Ã  dire dâ€™une part si : p=q, 
dâ€™autre part si pour toute cellule (u,v) du tableau de contingence on a :  
                                                
vu0n
vunnn
vu
v.u.vu
â‰ âˆ€=
=âˆ€==
   
       dans cette configuration on voit, de faÃ§on simple, que :   
    

=
+





âˆ’==
p
1u
2
2
..2
.u p
n
p
21ny)N(x,y)(x, D    
ConsidÃ©rons alors le Coefficient dâ€™ Â« Association de Janson â€“Vegelius Â»  donnÃ© sous forme 
dÃ©veloppÃ©e  par : 
 
 
(f 92)                 








+


		


âˆ’








+


		


âˆ’









		


âˆ’+âˆ’
==






==
= =
q
1v
2
2
..2
v.
p
1u
2
2
..2
.u
p
1u
q
1v
2
..v..u
vu
q
n
q
21n
P
n
p
21n
pq
n
p
n
q
n
n
y)D(x,
y)N(x,y)J(x,
 
 
En remplaÃ§ant  dans lâ€™expression du coefficient complexe de Janson -Vegelius :   n
..  
par P, p 
et q par 2  et 
vun  par lâ€™une des valeurs  :  11(x,y), 10(x,y), 01(x,y), 00(x,y), on obtient , 
lâ€™expression trÃ¨s simplifiÃ©e suivante: 
[ ] [ ]
2
2
22
2
P
y))01(x,y)(10(x,y)00(x,y)11(x,
4
P
4
P
y))01(x,y)(10(x,y)00(x,y)11(x,
4
1
y)J(x, +âˆ’+=
+âˆ’+
=
 
DÃ¨s lors, on peut dÃ©finir Ã  partir du Coefficient de similaritÃ© de Janson-Vegelius, lâ€™ indice de 
similaritÃ©  SJV(x,y) associÃ© dÃ©fini par : 
 
(f 93)                    [ ]
P
y))01(x,y)(10(x,y)00(x,y)11(x,y)J(x,y)(x,S VJ
+âˆ’+
==
 
On constate  sous cette forme et aprÃ¨s simplification des calculs,  que lâ€™indice obtenu nâ€™est ni 
plus ni moins que la version Â« corrÃ©lative Â»  de lâ€™indice de Sokal et Michener (ou indice de 
Â« Simple Matching Â»)  (voir (f 55)), câ€™est Ã  dire quâ€™il varie de â€“1 Ã  +1.  
 
                            +1 si 10(x,y)=01(x,y)=0  et â€“1 si 11(x,y)=00(x,y)=0 
 
RNTI-A-3 - 274 -
                                                                                                    F. Marcotorchino 
 
On aurait pu Ã©galement obtenir  ce rÃ©sultat de faÃ§on encore plus simple, en se rappelant (voir 
F. Marcotorchino (1984)) que le coefficient de Janson-Vegelius dans le cas de tableaux de 
contingence (2x2), est Ã©gal Ã  :  
              2x Coefficient de contingence de Rand  -1 , 
 
 oÃ¹ le Coefficient de Rand , (voir W. Rand (1971)) est donnÃ© par :   
           
2
..
p
1u
q
1v
p
1u
q
1v
2
..
2
.v
2
.u
2
vu
n
nnnn2
y)x,(R


 
 

= = = =
+âˆ’âˆ’
=
 
On retrouve ainsi lâ€™illustration des remarques indiquÃ©es au paragraphe 4.4..1.1:  
En effet :                       
2
..
p
1u
q
1v
p
1u
q
1v
2
..
2
.v
2
.u
2
vu
n
nn2n2n4
1-y)R(x, 2 


 
 

= = = =
+âˆ’âˆ’
=
 
En remplaÃ§ant les valeurs du tableaux Tetrachorique dans lâ€™expression prÃ©cÃ©dente , on ob-
tient trivialement :  
           [ ]
2
2
2
..
p
1u
q
1v
p
1u
q
1v
2
..
2
.v
2
.u
2
vu
P
y))01(x,y)(10(x,y)00(x,y)11(x,
n
nn2n2n4
1-y)R(x, 2 +âˆ’+=
+âˆ’âˆ’
=


 
 

= = = =
 
dâ€™oÃ¹ : 
                          
[ ]
P
y))01(x,y)(10(x,y)00(x,y)11(x,1y)2.R(x,y)J(x,y)(x,S VJ
+âˆ’+
=âˆ’==
 
(cqfd) 
Sous cette derniÃ¨re forme on voit que cet indice est  strictement Ã©quivalent Ã  lâ€™Indice de 
Hamann (voir note de bas de page  nÂ°11), câ€™est Ã  dire Ã  la diffÃ©rence entrelâ€™Indice de Sokal et 
Michener et lâ€™ Indice de Green â€“Rao. 
 
4.4.5.2  Indice de similaritÃ© dÃ©duit  du Coefficient  de Light et Margolin , Haldane  et du 
Coefficient de Goodman-Kruskal 
De la mÃªme maniÃ¨re que dans le cas  du coefficient de Janson et Vegelius , on peut sâ€™inspirer 
de la littÃ©rature sur les indices dâ€™association  sur tableaux de contingence, pour  dÃ©duire et 
dÃ©finir dâ€™autres indices de similaritÃ© par un processus Ã©quivalent Ã  celui utilisÃ© dans le cas 
prÃ©cÃ©dent.  Parmi les choix possibles, une excellente famille dâ€™indices dâ€™association (non 
standard quant Ã  leur construction) est celle crÃ©Ã©e autour de la filiation des indices de Good-
man-Kruskal, Light et Margolin , Haldane. Ainsi historiquement lâ€™indice le plus complet est 
celui qui a Ã©tÃ© introduit en 1954  par Goodman Kruskal et redÃ©fini  dans leur  livre (voir  L. 
A.Goodman et W.H. Kruskal (1979) ),  sous le nom de Â« Tau Â» de Goodman- Kruskal. Il est 
donnÃ©   ci dessous  dans sa formulation  pour tableau de contingence Ã  caractÃ¨re gÃ©nÃ©ral :  
 
(f 94)                                  




 

=
= = =
âˆ’
âˆ’
= q
1v
2
v.
..
..
p
1u
q
1v
q
1v
2
v.
...u
2
vu
n
n
1
n
n
n
1
n
n
y)(x,
 
                           
On peut montrer que le Coefficient de Light et Margolin (1971) est Ã©quivalent au NumÃ©ra-
teur du Coefficient de Goodman Kruskal, et quâ€™ historiquement en (1940), Haldane avait 
RNTI-A-3- 275 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
dÃ©jÃ  proposÃ© un coefficient quasi Ã©quivalent au Coefficient de Light et Margolin (pour plus 
de dÃ©tails sur  propriÃ©tÃ©s de ces indices et sur leur filiation on consultera lâ€™article F . Marco-
torchino (1984) ). 
Quoique dissymÃ©trique, ce coefficient de Goodman-Kruskal se comporte pour ses valeurs 
maximum et minimum comme le coefficient de Tchuprow, ou comme le Coefficient du 2.  
 
â€¢ Il  vaut 0 en cas dâ€™IndÃ©pendance contingentielle sur toutes les cases du tableau de con-
tingence (voir  Goodman , Kruskal (1979) ), câ€™est Ã  dire si : 
                           
vetu
n
nn
n
..
v..u
vu âˆ€=
 
â€¢ Il vaut 1 en cas dâ€™association complÃ¨te , câ€™est Ã  dire dâ€™une part si : p=q, dâ€™autre part si 
pour toute cellule (u,v) du tableau de contingence on a :  
                                                
vu0n
vunnn
vu
v.u.vu
â‰ âˆ€=
=âˆ€==
   
        
Pour Ã©valuer la valeur du Coefficient dâ€™association de Goodman Kruskal sur le tableau de 
contingence (2x2) Tetrachorique, il suffit de remplacer :   n
..  
par P, p et q par 2  et 
vun  par 
lâ€™une des valeurs  :  11(x,y), 10(x,y), 01(x,y), 00(x,y), on obtient  aprÃ¨s les  remplacements 
proposÃ©s, lâ€™ expression  suivante: 
 
[ ]
[ ]22
22
2222
y))10(x,y)(00(x,y))01(x,y)(11(x,
P
1P
y))10(x,y)(00(x,y))01(x,y)(11(x,
P
1
y)01(x,y)00(x,
y)(x,01y)(x,00
y)10(x,y)11(x,
y)(x,10y)(x,11
y)(x,
+++âˆ’
+++âˆ’
+
+
+
+
+
=Ï„
 
qui aprÃ¨s dÃ©veloppements et nouvelles simplifications revient Ã  :                   
 
[ ]
y)]01(x,y)y)][00(x,10(x,y)y)][11(x,10(x,y)y)][00(x,01(x,y)[11(x,
y)y)10(x,01(x,y)y)00(x,11(x,y)(x,
2
++++
âˆ’
=
 
 
DÃ¨s lors, on peut dÃ©finir Ã  partir du Coefficient dâ€™association de Goodman Kruskal, un indice 
de  similaritÃ© dit de Goodman Kruskal, SGK(x,y) dÃ©fini, comme pour Janson-Vegelius, par la 
racine carrÃ© du Coefficient dâ€™association, calculÃ© sur le tableau de contingence Tetracho-
rique, qui peut comme on lâ€™a vu Ãªtre positive ou nÃ©gative ; il vient : 
 
(f95)    [ ]
y]01(x,y)y)][00(x,10(x,y)y)][00(x,01(x,y)y)][11(x,10(x,y)[11(x,
y)y)01(x,10(x,y)y)00(x,11(x,y)(x,y)(x,SGK
++++
âˆ’
==
 
 
En se rÃ©fÃ©rant au Â§ 4.4.4.1,  formule (f 71) , on voit que malgrÃ© les calculs complexes occa-
sionnÃ©s, cet indice de similaritÃ© nâ€™est rien dâ€™autre que lâ€™indice de similaritÃ© Tetrachorique 
ST(x,y) (ou de Bravais-Pearson) , dÃ©fini directement Ã  partir du tableau 2x2 associÃ©. En con-
clusion on a donc : 
 
)y(x,Sy)(x,y)(x,S TGK ==  
 
 
RNTI-A-3 - 276 -
                                                                                                    F. Marcotorchino 
 
4.4.5.3  Indice de similaritÃ© dÃ©duit  du Coefficient dâ€™ Â« Ecart carrÃ© Ã  lâ€™IndÃ©pendance Â» et 
du Coefficient Contingentiel de I.C. Lerman 
Une autre famille dâ€™indices dâ€™association est issue dâ€™une ReprÃ©sentation Relationnelle gÃ©nÃ©-
rale des indices dâ€™Association sur tableau de contingence.  Ces indices font partie de la ver-
sion la plus complÃ¨te des indices dâ€™association de types relationnels dont la formule gÃ©nÃ©rale 
(voir F. Marcotorchino (1984), F. Marcotorchino et N. El Ayoubi (1991), A. Idrissi (2000) 
sâ€™Ã©crit sous la forme : 
 
 (f 96)                              








= == =
= =
âˆ’âˆ’
âˆ’âˆ’
=
N
1i
N
1i'
2
yii'
N
1i
N
1i'
2
xii'
N
1i
N
1i'
yii'xii'
)(y)(x
)(y)(x
y)A(x,
 
 
oÃ¹ la variable  x  (catÃ©gorielle) est reprÃ©sentÃ©e, comme nous lâ€™avions   vu au Â§ 2.2.1, par son 
expression relationnelle sous forme dâ€™une matrice binaire de terme gÃ©nÃ©ral : {xiiâ€™ } , idem 
pour y, reprÃ©sentable sous forme dâ€™une matrice relationnelle binaire : {yiiâ€™ }. Et oÃ¹   x  et   y 
sont, respectivement, une moyenne dÃ©rivÃ©e de la distribution des {xiiâ€™ } et une moyenne dÃ©ri-
vÃ©e de la distribution des  {yi iâ€™ }. Comme ceci a Ã©tÃ© montrÃ© (en particulier dans la thÃ¨se de N. 
Amal Idrissi  (2000)), puis repris par A. Hicham et G.Saporta (2003)  et revu et raffinÃ©  s 
dans   le travail  de  J. Ah-Pine (2007) ),   suivant les valeurs choisies pour  x  et   y , on re-
trouve  des coefficients dâ€™association connus. Ainsi , on  a :  
â€¢ si   x =1/2     et   y =1/2  (Moyennes logiques)           1y)2.R(x,y)A(x, âˆ’= , on retrouve le 
critÃ¨re de Rand 
â€¢ si  x =1/p et  y =1/q  (Moyennes Probabilistes)         y)J(x,y)A(x, = ,  on retrouve le 
critÃ¨re Janson Vegelius 
â€¢ si   x =
2
..
n
x
 et   y = 
2
..
n
y
 (Moyennes empiriques)     y)L(x,y)A(x, = ,  on retrouve un 
critÃ¨re voisin du critÃ¨re de Â« Vraisemblance du Lien Â»  de I.C. Lerman (1987), dont la 
formulation contingentielle (adaptÃ©e Ã  notre problÃ©matique) est donnÃ©e ci dessous :   
 
 
(f 97)                          









 


 

=
=
=
=
= =
= =






	
	
	
	


âˆ’






	
	
	
	


âˆ’
âˆ’
=
q
1v
2
..
q
1v
2
v.
2
v.
p
1u
2
..
p
1u
2
.u
2
.u
p
1u
q
1v
2
..
p
1u
q
1v
2
v.
2
.u
2
vu
n
n
1n
n
n
1n
n
nn
n
y)L(x, 
 
 
Le numÃ©rateur de ce coefficient   Ã  savoir la quantitÃ© : 
                                              



 

= =
= =
âˆ’
p
1u
q
1v
2
..
p
1u
q
1v
2
v.
2
.u
2
vu
n
nn
n
  
RNTI-A-3- 277 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
est connue sous  le nom de CritÃ¨re de lâ€™ Â« Ecart CarrÃ© Ã  lâ€™IndÃ©pendance15 Â»,  critÃ¨re qui pos-
sÃ¨de de nombreuses propriÃ©tÃ©s structurelles  intÃ©ressantes  ( on trouvera dans  Marcotorchino 
(1984,) ,  une Ã©tude complÃ¨te de ce critÃ¨re,  dâ€™un point de vue formel, structurel  et applica-
tif).   
 
Ce coefficient L(x,y), dÃ©rivÃ© du Coefficient de I. C. Lerman,  possÃ¨de les propriÃ©tÃ©s suivantes 
Ã  propos de ses valeurs maximales et minimales.   
â€¢ Il  vaut 0 en cas dâ€™IndÃ©pendance contingentielle sur toutes les cases du tableau de con-
tingence,  câ€™est Ã  dire si : 
                                     
vetu
n
nn
n
..
v..u
vu âˆ€=
 
       En effet dans ce cas  le numÃ©rateur de L(x,y) sâ€™annule  de faÃ§on Ã©vidente. 
â€¢ Il vaut 0 Ã©galement dans le cas dâ€™une solution Â« parasite Â» (qui se prÃ©sente uniquement  
sur des tableaux 2x2)  (voir (F. Marcotorchino (1984 partie III) ),  et pour laquelle si le 
tableau 2x2 sâ€™ Ã©crit : 
            
 y Non y 
x a b 
Non x c d 
       
       la configuration  suivante  se produit: 
        (i)        dcbanaveccbda 2222 +++=+=+    (on identifie ici n et n.. )   
    Du fait que lâ€™Ã©quation prÃ©cÃ©dente est Ã©quivalente Ã  : 
       (ii)        2bcc)(b2add)(a 22 âˆ’+=âˆ’+  
    on a Ã©galement : 
      (iii)       bc)2(adc])[bd]([anbc)2(adc)(bd)(a 22 âˆ’=+âˆ’+âˆ’=+âˆ’+   
 
Parmi les solutions de lâ€™Ã©quation Diophantienne  ( i),  (il y en a une infinitÃ©) nous en donnons  ci dessous une famille  
paramÃ©trÃ©e (voir (F. Marcotorchino (1984)) :                 
{ } ..)0,1,2,..m,:entiÃ¨resvaleursdesprenant  (s1sd5,sc 5,2sb 7,2s a +=+=+=+=  
  Il est facile de vÃ©rifier que si s=1 par exemple,  les valeurs : a=9, b=7, c=6 , d=2 , sont telles quâ€™elles annulent  le    
coefficient    L(x,y), calculÃ© sur le tableau :   
 
 
 
 
bien que lâ€™on ne soit pas (loin de lÃ ) dans une configuration dâ€™indÃ©pendance contingentielle.  
On peut voir ,  de faÃ§on Ã©vidente, que pour cette sÃ©rie de solutions  2c])[bd]([a:aons âˆ’=+âˆ’+âˆ€ ,  de  ce  
implique que (ad â€“ bc) = - n  puisque lâ€™on travaille sur des valeurs entiÃ¨res. 
 
En effet :  
         n= (2s+7)+(s+1)+(2s+5)+(s+5)=6s+18, ad = 2 s2 + 9s + 7,  bc = 2 s2 +15s+ 25, a+d = 3s +8 , b+c = 3 s +10  
dâ€™oÃ¹ : (ad â€“ bc) = - (6s+18) =-n  et    (a+d) â€“(b+c) = (3 s +8) â€“(3s+10) = -2 
 y Non y 
x 9 7 
Non x 6 2 
                                                 
15
 A ne pas confondre avec le carrÃ© de lâ€™Ã©cart Ã  lâ€™indÃ©pendance (NumÃ©rateur du Coefficient  de Tchuprow) ou  la 
forme de base  du Coefficient du 2  qui sâ€™Ã©crit : 2p
1u
q
1v
..
.vu.
vu )
n
nn(n


= =
âˆ’
 
 
 
RNTI-A-3 - 278 -
gÃ©nÃ©rale  et  
fait   ceci 
                                                                                                    F. Marcotorchino 
 
 
â€¢ Il vaut 1 en cas dâ€™association complÃ¨te , câ€™est Ã  dire dâ€™une part si : p=q, dâ€™autre part si 
pour toute cellule (u,v) du tableau de contingence on a :  
                                                       
vu0n
vunnn
vu
v.u.vu
â‰ âˆ€=
=âˆ€==
   
       En effet dans ce cas NumÃ©rateur et DÃ©nominateur sont Ã©gaux. 
 
â€¢ Enfin le calcul de la valeur minimale de cet indice nâ€™est pas du tout Ã©vident.  Nous 
allons donner la solution dans le cas dâ€™un tableau 2x2 et montrer la difficultÃ© associÃ©e 
pour trouver la solution optimale de ce problÃ¨me.  
 
Calculons, dans un premier temps, la valeur minimale du NumÃ©rateur dans le cas du tableau  
de contingence (2x2) gÃ©nÃ©ral suivant: 
 
    
 y Non y 
x a b 
Non x c d 
 
On peut montrer, que dans le  cas dâ€™un tableau 2x2, la quantitÃ©  correspondant au numÃ©rateur  
de L(x,y)  sâ€™Ã©crit sous la forme suivante: 
2
..
222222222p
1u
q
1v
2
..
p
1u
q
1v
2
v.
2
.u
2
vu
n
]d)(bc)[(a]d)(cb)[(a]dcb[ad)cb(a
n
nn
n
++++++âˆ’++++++
=âˆ’



 

= =
= =
 
AprÃ¨s dÃ©veloppement de la formule prÃ©cÃ©dente et au bout de calculs assez  fastidieux , on 
montre   que cette quantitÃ© se factorise selon la formule suivante :  
 
(f 98)       ])c(bdbc)[a(ad
n
2
n
]d)(bc)[(a]d)(cb)[(a]dcb[ad)cb(a 2222
22
..
222222222
+âˆ’+âˆ’=
++++++âˆ’++++++  
Le Â« dÃ©nominateur du numÃ©rateur Â» en question Ã©tant la constante n2, on peut se contenter de 
travailler au niveau du Â« numÃ©rateur du numÃ©rateur Â». On voit que cette expression est posi-
tive si , Ã  la fois Â« a et d Â» sont positifs et Â« b et c Â» nuls  (ce qui correspond Ã  un cas favo-
rable) , mais il se trouve quâ€™elle est Ã©galement positive si Â« a et d Â» sont nuls et Â« b et c Â» 
positifs ( cas dâ€™une configuration non favorable).  
 
 
Il apparaÃ®t donc Ã©vident que si lâ€™on veut obtenir une configuration oÃ¹ la valeur de (f 98) soit  
nÃ©gative , il faut Minimiser la fonction des quatre inconnues   (a,b,c,d) suivante :     
 
                  
 
                                  
        
                                          ( ))c(bdabc)(ad2Min 2222
dc,b,a,
+âˆ’+âˆ’  
vÃ©rifiant les contraintes : 
RNTI-A-3- 279 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
         
nd0  n,c0n,b0n,a 0    (ii)          
constante)est n(oÃ¹ ncbda      (i)          
â‰¤â‰¤â‰¤â‰¤â‰¤â‰¤â‰¤â‰¤
=+++
 
Soit en utilisant une approche Lagrangienne :  
 
                                    n)-dcb	(a-)]c(b)d(a[bc)(ad2Min 2222
abcd
++++âˆ’+âˆ’  
        vÃ©rifiant : 
        
nd0  n,c0n,b0n,a 0    (ii)          
         
â‰¤â‰¤â‰¤â‰¤â‰¤â‰¤â‰¤â‰¤
                                                 
Un raisonnement de bon sens va nous permettre de simplifier la rÃ©solution de ce ProblÃ¨me dâ€™optimisation non 
linÃ©aire  Ã   4 variables16. En effet  on constate sur la formule (f98) que pour que cette  fonction F(a,b,c,d)  soit 
nÃ©gative, il faut que lâ€™on ait simultanÃ©ment: 
                                     0)]c(bd[a    et              0bc)(ad 2222 >+âˆ’+<âˆ’   (cas nÂ°1) 
 ou                                0)]c(bd[a  et              0bc)(ad 2222 <+âˆ’+>âˆ’   (cas nÂ°2) 
 
On voit  que lâ€™on peut   donc sÃ©parer le comportement de Â« a Â» et Â« d Â»  de celui de Â« b Â» et Â« c Â». En effet  pour 
Minimiser F(a,b,c,d)  :  
* Il faut pour le couple {a, d} que lâ€™on ait : la quantitÃ© produit Â« a.d Â» minimale et la quantitÃ© Â«a2+d2
 
Â» maxi-
male  (ou lâ€™inverse cas nÂ°2) 
*  Il faut Ã  lâ€™inverse pour  le couple {b,c} :  que la quantitÃ© produit Â« b.c Â» soit maximale et la quantitÃ© Â«b2+c2
 
Â» 
minimale (ou lâ€™inverse cas nÂ°2)   
 
Nous choisissons ici le cas nÂ°1  qui va nous garantir une solution oÃ¹ Â« d Â» sera  maximum . En supposant que 
lâ€™on ait  arbitrairement dÃ©coupÃ© n en deux parties quelconques  n1 et n2 telles que : 
 
         
nd0  n,c0n,b0n,a 0    (ii)          
constante)est n(oÃ¹ n  nn avec   (iii)          
ncb    (ii)          
nda     (i)          
21
2
1
â‰¤â‰¤â‰¤â‰¤â‰¤â‰¤â‰¤â‰¤
=+
=+
=+
 
Du fait que   (a+d)2= a2+d2-2ad   
on voit que : si   (a+d)= n1=constante,  alors il y a Ã©quivalence entre : Maximiser (a2+d2)     et     Minimiser (2ad)   
ou  de faÃ§on duale : Maximiser (2ad )    et Minimiser (a2+d2)     
On  dÃ©duit des remarques faites prÃ©cÃ©demment que :  rendre Â« ad Â» minimum rendra automatiquement Â«a2+d2 Â»     
maximum  et de mÃªme  pour le couple {b,c} rendre le couple Â« cd Â» maximum rendra la quantitÃ© Â«b2+c2
 
Â» mi-
nimale  
-Dans le cas particulier du couple {b,c} puisque lâ€™on veut rendre la quantitÃ© produit Â«bc Â» maximale, on va se 
servir dâ€™un rÃ©sultat qui dÃ©coule des remarques calculatoires faites prÃ©cÃ©demment Ã  savoir : Â« le produit de 2 
nombres dont la somme S est constante  est maximum si ces deux nombres sont Ã©gaux Â», la consÃ©quence 
pour notre problÃ¨me est que : quelle que soit la valeur n2 , on doit avoir  b = c = n2/2   Ã  lâ€™optimum.   
-De la mÃªme faÃ§on le produit de 2 nombres dont la somme S est constante  est minimum si lâ€™un des deux 
nombres est Ã©gal Ã  S et lâ€™autre est nul. Â», la consÃ©quence pour notre problÃ¨me est que : quelle que soit la valeur 
n1 , on doit avoir a ou d=0 Ã  lâ€™optimum .  On vient donc de voir quâ€™au moins lâ€™une ou lâ€™autre des valeurs Â« a Â» 
et Â« d Â» est nulle  (nous choisissons a=0) et que de plus Â« b = c Â» .  
 
Le problÃ¨me que lâ€™on veut rÃ©soudre sâ€™Ã©crit maintenant sous une forme certes non linÃ©aire mais trÃ¨s simplifiÃ©e :                  
                                                ]b2d[)b(2Min 222
ba,
âˆ’âˆ’
 
                             vÃ©rifiant les contraintes : 
                                                 
16
 On ne pose pas encore Ã  ce niveau une contrainte dâ€™intÃ©gritÃ© des quantitÃ©s {a,b,c,d}, quâ€™on suppose continues 
dans un premier temps. 
RNTI-A-3 - 280 -
                                                                                                    F. Marcotorchino 
 
 
produit)du  nÃ©gativitÃ© lagarantit  contrainte (cette b2d    (iii)         
n,b0n,d 0    (ii)          
constante)est n(oÃ¹ nb2d      (i)          
22 â‰¥
â‰¤â‰¤â‰¤â‰¤
=+
 
 
La contrainte (iii) alliÃ©e Ã  la contrainte (i)  impliquent  immÃ©diatement que : 
n 2929,0
22
nb =
+
â‰¤
      (nous nous en resservirons ultÃ©rieurement) 
 
Du fait  que lâ€™on nâ€™a pas encore introduit la contrainte dâ€™intÃ©gritÃ©, la solution du problÃ¨me  prÃ©cÃ©dent revient Ã  
rÃ©soudre un programme non linÃ©aire en (d, b)  Ã  variables continues positives. En utilisant  la contrainte (i) et 
en remplaÃ§ant Â« b par x Â»  (pour se ramener Ã  des notations familiÃ¨res et  classiques de variables continues in-
connues) , on peut ramener ce problÃ¨me Ã  un programme dâ€™optimisation non linÃ©aire (du 4Ã¨me degrÃ©) Ã  1 seule  
variable x qui sâ€™Ã©crit : 
22
n
 x0  (iii)         
         :vÃ©rifiant
] x2 2x)[(nx2F(x)Max 222
 x
+
â‰¤â‰¤
âˆ’âˆ’=
 
(On passe du Min  au Max, en enlevant le signe Â«- Â» devant la fonction )  
 
Etudions  les conditions dâ€™optimalitÃ© du premier et du deuxiÃ¨me ordre  par rapport Ã  x,  on obtient : 
 
 [ ]
 0 ] x4x n 6  -n [x2soit0 x8  xn12xn22
xd
F(x)d((i)) 22322 =+=+âˆ’=   
[ ] (iii)  condition  la  x vÃ©rifie quefait  du est vraie relation  cette024x 24nx n2
x
F(x)((ii)) 222
2
â‰¤+âˆ’=
âˆ‚
âˆ‚      
La premiÃ¨re condition  ((i)) (condition du premier ordre) signifie que le x* cherchÃ© doit annuler la premiÃ¨re dÃ©-
rivÃ©e de F(x)  par rapport Ã  x .  
La deuxiÃ¨me condition ((ii))  (condition du second ordre) signifie, du fait que  0
x
F(x)
2
2
â‰¤
âˆ‚
âˆ‚ ,  que la fonction-
nelle F(x) est concave par rapport Ã  x, donc que si x* est trouvÃ©, ce sera un maximum  unique pour F(x) (câ€™est 
justement ce que lâ€™on cherche)  et non un minimum. Puisquâ€™Ã  lâ€™optimum  on doit avoir x* vÃ©rifiant la condition 
du 1er ordre ((i)),  on est amenÃ© Ã  rÃ©soudre lâ€™Ã©quation du second degrÃ© en x suivante :  
                                                              4 x2-6 n x +n2 = 0  
  
dont la solution qui nous intÃ©resse est donnÃ©e par :  
n19098,0
4
n)53(
4
5n3n
*x
2
=âˆ’=
âˆ’
=
 
en effet la deuxiÃ¨me racine : 
                                         
n3090,1
4
n)53(
4
5n3n
*'x
2
=+=
+
=
 
ne vÃ©rifie pas la condition (iii) et est donc Ã©liminÃ©e, puisque : 
                                       
22
n
 x0          
+
â‰¤â‰¤   
 nâ€™est pas compatible avec le fait que xâ€™*est supÃ©rieur Ã  n,  x* peut Ã©galement sâ€™Ã©crire : 
61803,1
2
51Or"d' Nombre"  leest      oÃ¹   n 
2
1n
4
)5(14
x* =
+
=Î¦


 Î¦
âˆ’=
+âˆ’
=
 
Rappelons que nous voulons calculer  la valeur Minimum par rapport Ã  d, b , c  de la quantitÃ© : 
                            
                                                
ncbd     (i)         
: contrainte la sous
)]c(b)(d[bc)( 2  c)b,F(d, 222
=++
+âˆ’âˆ’=
 
RNTI-A-3- 281 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
comme nous avions vu que : b =c   et  puisque : b* = x* Ã  lâ€™optimum,  on a donc :  
 
Or"d' Nombre"  leest      oÃ¹   n 
2
1c**b               Î¦


 Î¦
âˆ’==
 
de ce fait  comme d= n - 2b , il vient :               1)n(d* âˆ’=  
On vÃ©rifie bien que : 
 21)
2
1(1puisque)
2
(12nn1)(car2(b*)(d*) 222222 +â‰¥+âˆ’â‰¥âˆ’â‰¥  
En remplaÃ§ant d*, b*,c* par leurs valeurs dans F(d,b,c) il vient : 
44422
2
n0225424859,0n1
8
52n)
2
2(11)(
2
12c*)b*,F(d*, âˆ’=



âˆ’âˆ’=



âˆ’âˆ’âˆ’


	


âˆ’âˆ’=
 
                   
 
Pour  obtenir  cette expression  simplifiÃ©e, on a  utilisÃ© les propriÃ©tÃ©s suivantes du Nombre dâ€™Or : 
                                                  





+Î¦=Î¦+Î¦=Î¦
+Î¦=Î¦+Î¦=Î¦
+Î¦=Î¦
23
12
1
234
23
2
 
Nous rappelons que la valeur trouvÃ©e ici est la valeur minimale de F(d,b,c)  pour d, b, c,  Ã  valeurs continues, 
nous nâ€™avons pas tenu compte des conditions dâ€™intÃ©gritÃ© de d, b, c .  
Ceci nous aurait obligÃ© Ã  utiliser une solution par  Programmation non linÃ©aire en nombres entiers ;  en utilisant 
par exemple un algorithme dÃ©rivÃ© des approches Â« cutting planes Â» de M. GrÃ¶tschel, M. JÃ¼nger, G. Reinelt  
(1982)Â».  
 
Outre que cette approche ne permet pas dâ€™avoir des solutions explicites et que les calculs sont trÃ¨s complexes, 
mÃªme pour des valeurs faibles du nombre de variables, elle sortirait du cadre de cet article. Une solution appro-
chÃ©e, et tout Ã  fait rÃ©aliste, pour trouver la meilleure solution en nombres entiers du problÃ¨me prÃ©cÃ©dent, vu que 
le nombre de situations possibles Ã  explorer est trÃ¨s faible puisquâ€™il nâ€™y a que deux degrÃ©s de libertÃ© ici,  con-
siste alors Ã   prendre les valeurs entiÃ¨res : 
                          minimalessoient*cc~*bb~et*d-d~ :quetellesc~,b~,d~ âˆ’=âˆ’   
et telles que : *bb~2*dd~ âˆ’+âˆ’   ait une valeur minimale sous la contrainte : nb
~2d~ =+   
n618033,0N)1( de
 entiÃ¨re  partied~pour    idemet  n19098,0n 
2
1de  entiÃ¨re   partiec~   b~oÃ¹  d'       
=âˆ’Î¦
==


 Î¦
âˆ’== on  
choisira  la  solution  pour  laquelle : 
nb~2d~  contrainte  la sous*bb~2*dd~Min ait on l' que tellessoient  b~et  d~ =+âˆ’+âˆ’      
A titre dâ€™exemple , prenons  n=24 , alors  on trouve la solution  entiÃ¨re optimale  reprÃ©sentable par le tableau 
suivant :  
 y Non y 
x 0 5 
Non x 5 14 
 
Et F(d,b,c) Â« optimale17, Â»  (valeur minimale) ,  calculÃ©e sur ce tableau est donnÃ©e par :  -7300  
Rappelons que la valeur thÃ©orique optimale  continue aurait Ã©tÃ© donnÃ©e par : - 0,0225424859 n4= - 7479, 055  ,  
lâ€™erreur dâ€™approximation est  ici de lâ€™ordre de 2,3%. 
On vÃ©rifie facilement que toute autre solution est moins bonne, en effet prenons par exemple :  
 
 y Non y 
                                                 
17
 Rappelons nous quâ€™ il faudrait pour calculer  Ã  sa juste valeur le numÃ©rateur du  coefficient  de Lerman, diviser 
cette quantitÃ© par nÂ². mais ceci a peu dâ€™importance car cette quantitÃ© nÂ², disparaÃ®tra en fait du numÃ©rateur de L(x,y)  
dÃ¨s que nous le calculerons en simultanÃ©itÃ© avec le dÃ©nominateur.  
RNTI-A-3 - 282 -
                                                                                                    F. Marcotorchino 
 
x 0 4 
Non x 4 16 
 
La valeur associÃ©e de F(a,b,c) = - 7168 dans ce cas.  
ConsidÃ©rons maintenant le tableau suivant,  lÃ©gÃ¨rement modifiÃ© par rapport au prÃ©cÃ©dent:   
 
 y Non y 
x 0 5 
Non x 3 16 
La valeur de F(d,b,c)  associÃ©e Ã  ce deuxiÃ¨me tableau   est Ã©gale Ã  : -6660  (on constate bien  sur ce petit 
exemple  que dÃ¨s que  Â« b  c Â» , la valeur Â« d Â» restant inchangÃ©e , la valeur de la fonction est infÃ©rieure en va-
leur absolue au cas oÃ¹  Â« b = c Â»). 
 
Revenons maintenant Ã  lâ€™expression du critÃ¨re L(X,Y) complet et  non plus au simple 
NumÃ©rateur qui concerne le seul Â« CritÃ¨re dâ€™Ecart carrÃ© Ã  lâ€™IndÃ©pendance Â». Pour 
Ã©valuer la valeur Minimale du Coefficient dâ€™association de Lerman  sur un tableau de 
contingence (2x2), il suffit de remplacer dans la formule (f 94) :   n
..  
par P, p et q par 2  
et 
vun  par lâ€™une des valeurs  : { a, b, c, d }.  
Le dÃ©nominateur de la formule (f94) sâ€™Ã©crit alors :   
                        d]c)(b[2(a]d)(bc)d)][(ab)(c[2(a]d)(cb)[(a 2222 ++++++++++  
Soit encore sous une forme plus symÃ©trique :   
               d)]c)(bd)(ac)(b[(a]d)(bc)][(ad)(cb)[(a2 2222 ++++++++++  
 
En  vÃ©ritÃ©, cette formule est Ã  diviser par nÂ², tout comme pour le numÃ©rateur de la for-
mule (f95), de ce fait la quantitÃ© nÂ²   disparaÃ®t au numÃ©rateur et au dÃ©nominateur, de 
mÃªme  pour la constante multiplicative 2. On obtient au final lâ€™expression  suivante 
(aprÃ¨s les  remplacements proposÃ©s, des simplifications des formules complexes obte-
nues et  enfin une factorisation ,) :  
 
                                                     
y)(x,D
y)(x,N
x
y)(x,D
y)(x,Ny)L(x,
2
2
1
1
=
 
oÃ¹ : 
                                          
d][cd][bc][ab][a
bc]-ad[
y)(x,D
y)(x,N
1
1
++++
=
 
 
             et  oÃ¹ 
                                   
)d][bc]([a)d][cb]([a
)]c(b-d[a
y)(x,D
y)(x,N
2222
2222
2
2
++++++
++
=
 
Lâ€™indice de Lerman ModifiÃ© est donc le Produit de deux indices dont lâ€™un est lâ€™indice Tetra-
chorique que nous avons dÃ©jÃ  dÃ©fini , lâ€™autre Ã©tant un indice que nous allons expliciter  dans 
les paragraphes suivants. Mais revenons au calcul du Minimum de L(x,y) 
 
 
Comme nous avons vu que dans le cas oÃ¹ le NumÃ©rateur atteint sa valeur minimale soit Â« a Â» soit Â« d Â» devait Ãªtre 
Ã©gal Ã  0 , posons  Â« a=0 Â», les valeurs prÃ©cÃ©dentes se simplifient en :    
d][cd][bbc
-bc][
y)(x,D
y)(x,N
1
1
++
=
                                
( ) ]d(bc]d)(c[b
)]c(b-[d
y)(x,D
y)(x,N
2222
222
2
2
++++
+
=
 
RNTI-A-3- 283 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
En utilisant la contrainte : d+2b=n  et en remplaÃ§ant de nouveau b=c par x ,  il vient le  problÃ¨me dâ€™optimisation 
suivant :  
  (f 99)            
[ ]
[ ][ ] ( )
 
22
n
x0     (ii)         
:vÃ©rifiant
xx)n(x)(n
] x2n x4[nx
xx)(nxx)(nxx)(n
 x2  xn4xnF(x)Max 22
22
222222
4322
x
+
â‰¤â‰¤
+âˆ’âˆ’
+âˆ’
=
+âˆ’+âˆ’âˆ’
+âˆ’
=
 
Comme nous avons affaire maintenant Ã  une fonction dâ€™une seule variable , il suffit dâ€™appliquer la condition du 
premier ordre Ã  la fonctionnelle F(x) prÃ©cÃ©dente.  
Comme F(x) se prÃ©sente comme le rapport 
v(x)
u(x) de deux fonctions de x . 
La condition de dÃ©rivation du premier ordre sâ€™Ã©crit  alors  aprÃ¨s simplifications:                            
0
]xx)[(nx)-(n
n-x8n14nx-8x
dx
dF(x)
2222
3223
=
+âˆ’
+
=
. 
Il faut donc rÃ©soudre lâ€™Ã©quation du 3Ã¨me degrÃ©18 suivante pour obtenir x* : 
)prÃ©cÃ©dente (ii) contrainte voir  vraiofficed'est  qui (cen  x: que  rÃ©serve  sous                
   0n-xn 814n x-8x      (f100) 3223
â‰ 
=+
 
On obtient  la solution optimale exacte: x*=0,171350939.n  et   de fait  a*=n-x*=0,6572982.n  Dans la formule (f 
98)  on constate nÃ©anmoins que le coefficient numÃ©rique 2,210929 est assez voisin de  5 et plus exactement :                                 




	
	








âˆ’=âˆ’â‰…
3
10
515025,05210929,0
 
Dâ€™oÃ¹ aprÃ¨s dÃ©veloppements  une deuxiÃ¨me approximation de x* fournie 
par :
n17135141,0]279[
480
n]
40
1
20
2[
12
n
 ]50,025)-  5( -[7
12
n
   x*                    102) (f
  
=Î¦+=âˆ’Î¦+=â‰…
 
On constate ici que lâ€™erreur nâ€™intervient quâ€™au bout du 6Ã¨me chiffre aprÃ¨s la virgule, ce qui  nous permettra dâ€™utiliser 
la formule (f 100) comme formule explicite pour la suite.  
En particulier, on aura  en fin de compte :                                
]2161[
240
n2b*nd*et     
480
n]2[79c*b* Î¦âˆ’=âˆ’=Î¦+==                                                                            
Comme prÃ©cÃ©demment, ces valeurs optimales ont Ã©tÃ© calculÃ©es pour un environnement de valeurs continues  et sans 
tenir compte des contraintes dâ€™intÃ©gritÃ©.                                                                                                                                 
A titre dâ€™exemple , prenons  n=24 ,  on trouve  alors : 
16d~et       4 c~b~oÃ¹  d'
7752,15
240
24]2161[ de entiÃ¨re partied~et     1124,4
480
24]2[79 de entiÃ¨re partie   c~b~
===
=Î¦âˆ’==Î¦+==              
La solution entiÃ¨re optimale  est  donc donnÃ©e par le tableau suivant :  
 
                                                 
18
 La solution de ce problÃ¨me sâ€™obtient en utilisant le procÃ©dÃ©  de Cardan- Tartaglia, pour une Ã©quation de la 
forme : 0xxx 23 =+++  avec  0,.  On sait alors que la solution Z* (rÃ©elle) de  Z3+r Z+ t est donnÃ©e 
par :
]42185898,42109294,9[
12
n)]1(249210929,27[
12
n
 ]5 2,21092949 -[7
12
n
   x*: vientil  
125 encore ici  poseon      n,
24
14
*Z   x*
Î¦âˆ’=âˆ’Î¦âˆ’==
âˆ’Î¦=+=  
 
 
RNTI-A-3 - 284 -
                                                                                                    F. Marcotorchino 
 
 
Et L(x,y) minimum absolu calculÃ© pour n=24 est donnÃ© par :     
                                                        
0,10769]420.4.[20
2.16]4.4[16)y~,x~L( 22
2
âˆ’=
+
âˆ’âˆ’
=
        
        
rappelons que la valeur thÃ©orique optimale  continue aurait Ã©tÃ© donnÃ©e en calculant L(x,y) sur un tableau thÃ©orique 
oÃ¹ au lieu de â€˜4â€™ on aurait : â€˜4,1124â€™ , et au lieu de â€˜16â€™ , on aurait â€™15,775,â€™  soit : 
                                      
 valeur cette   0,107811
33730,78
3636,50y*)L(x*, âˆ’=âˆ’=                                                                                  
on voit quâ€™elle est trÃ¨s lÃ©gÃ¨rement supÃ©rieure  Ã  la valeur prÃ©cÃ©dente  lâ€™Ã©cart   0,00011)y~,x~L(y*)L(x*, =âˆ’ ,   
nâ€™Ã©tant que de  11/10000 .                                                                                                                                             
En fait cette valeur minimale thÃ©orique L(x*,y*) est indÃ©pendante de n,  en effet : posons b*=Ï‰.n (avec 
=0,1713509 et d*=Î· n (avec = 0,6572982) (valeurs donnÃ©es en (f102) plus haut).   Il   
vient : [ ]
[ ] [ ] ])[(1)(1
]2[
nn)(nnn)(n
]n2n[n
[b*]b*][n*b*)b(n
2[b*][d*][b*]y*)L(x*, 22
222
222
222222
22
222
Ï‰+Ï‰âˆ’Ï‰Ï‰âˆ’
Ï‰âˆ’Î·Ï‰
âˆ’=
Ï‰+Ï‰âˆ’Ï‰Ï‰âˆ’
Ï‰âˆ’Î·Ï‰
âˆ’=
+âˆ’âˆ’
âˆ’âˆ’
=
 
On voit que les valeurs n disparaissent  et que dâ€™autre part  comme =(1- 2) on peut  tout exprimer en fonction de 
. 
Câ€™est dâ€™ailleurs ce que nous avions fait lors de lâ€™optimisation en jouant sur lâ€™inconnue x  (voir formule (f 96)).   
AprÃ¨s simplification  du NumÃ©rateur et du DÃ©nominateur par n et Ã©limination de  , il vient :   
]22)[1(1
]4[1y*)L(x*, 2
2
+âˆ’âˆ’
+âˆ’
âˆ’=
 
 
 
Il suffit de remplacer Â«  Â»  par sa valeur   0,1713509 dans lâ€™expression prÃ©cÃ©dente, il vient :   
1078119,0 
5933296,0
063968,0
]0,17135 . 20,171350 20,828649[1
].0,171352.0,171354-[10,17135y*)(x*,L 2
2
Min âˆ’=âˆ’=
+âˆ’
+
âˆ’=
  
Cette valeur indÃ©pendante de n est le minimum thÃ©orique de lâ€™indice de Lerman modifiÃ© sur un tableau de    
contingence (2x2) .  On voit ici la complexitÃ© de la situation, car les valeurs minimisant le NumÃ©rateur de L(x,y) 
câ€™est Ã  dire celles pour lesquelles le critÃ¨re dâ€™  Â« Ecart CarrÃ© Ã  lâ€™IndÃ©pendance Â» est minimum, ne sont pas celles qui 
minimisent L(x,y) .En effet reprenons ces valeurs , on   
avait  : 1)n-( d*et       Or"d' Nombre"  leest      oÃ¹   n 
2
1c**b               Î¦=Î¦


 Î¦
âˆ’==
.  
RemplaÃ§ons ces valeurs dans lâ€™expression de L(x*,y*) donnÃ©e  prÃ©cÃ©demment en fonction de a*,b*,c*, il vient :    
[ ]
[ ] 1055728,043
85
2
1
22
2
-12)1(
2
-1
[b*]b*][n*b*)b(n
2[b*][d*][b*]
y*)L(x*,
22
2
2
22
222
âˆ’=
âˆ’Î¦
âˆ’Î¦
âˆ’=




	
	





 Î¦
âˆ’+


Î¦Î¦




	
	





 Î¦
âˆ’âˆ’Î¦


 Î¦
âˆ’=
+âˆ’âˆ’
âˆ’âˆ’
=
 
La formule prÃ©cÃ©dente peut dâ€™ailleurs sâ€™exprimer  selon la suite de  Fibonacci  (liÃ©e elle mÃªme au Nombre dâ€™Or): en 
effet si lâ€™on pose F1=1, F2=1, F3=2, F4=3, F5=5, F6=8, F7= 13 â€¦.. on voit que la formule prÃ©cÃ©dente sâ€™Ã©crit :   
 
                                                                 
1FF
FF
4-3
85y*)L(x*,
54
65
+âˆ’Î¦
âˆ’Î¦
=
Î¦
âˆ’Î¦
âˆ’=
 
On voit que cette valeur,  mÃªme si elle est  trÃ¨s proche de la prÃ©cÃ©dente ( 0,1078118 versus 0,1055728) , nâ€™est 
pas optimale, mÃªme si elle optimisait par ailleurs le numÃ©rateur  seul. Si  on exprimait la solution Minimale to-
tale par rapport au nombre dâ€™Or on voit que seul le dÃ©nominateur serait lÃ©gÃ¨rement  modifiÃ© en effet : 
 
 
9829,0FF
FF
1078119,0y*)(x*,L
54
65
Min
+âˆ’Î¦
âˆ’Î¦
=âˆ’=
 
 y Non y 
x 0 4 
Non x 4 16 
 
RNTI-A-3- 285 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
 
Revenons maintenant au calcul de lâ€™Indice de Lerman modifiÃ© sur le vrai tableau Tetracho-
rique et non sur un tableau (2x2) quelconque, dÃ¨s lors, comme prÃ©cÃ©demment, pour Ã©valuer 
la valeur du Coefficient dâ€™association de Lerman  sur le tableau de contingence (2x2) Tetra-
chorique, il suffit de remplacer :   n
..  
par P, p et q par 2  et 
vun  par lâ€™une des valeurs  : { 
11(x,y), 10(x,y), 01(x,y), 00(x,y)}, on obtient  aprÃ¨s les  remplacements proposÃ©s, des simplifi-
cations des formules complexes obtenues et  une factorisation finale, qui se traduit par 
lâ€™expression suivante: 
 
                                                     
y)(x,D
y)(x,N
y)(x,D
y)(x,Ny)L(x,
2
2
1
1
=
 
 
oÃ¹ : 
                   
[ ]
y)]01(x,y)y)][00(x,10(x,y)y)][11(x,10(x,y)y)][00(x,01(x,y)[11(x,
y)y)10(x,01(x,y)y)00(x,11(x,
y)(x,D
y)(x,N
1
1
++++
âˆ’
=
 
 
et 
[ ]
[ ][ ]2222
2222
2
2
y)]01(x,y)[00(x,y)]10(x,y)[11(x,y)]10(x,y)[00(x,y)]01(x,y)[11(x,
y))(x,01y)(x,(10y)(x,00y)(x,11
y)(x,D
y)(x,N
++++++
+âˆ’+
=
 
 
 
On reconnaÃ®t dans le rapport :  
[ ]
y)]01(x,y)y)][00(x,10(x,y)y)][11(x,10(x,y)y)][00(x,01(x,y)[11(x,
y)y)10(x,01(x,y)y)00(x,11(x,
y)(x,D
y)(x,N
1
1
++++
âˆ’
=
 
 
lâ€™indice de similaritÃ© Tetrachorique ST(x,y), dÃ©fini par la formule (f 71).  
 
 
Mais quâ€™en est-il de lâ€™indice suivant ? : 
                      
[ ]
[ ][ ]2222
2222
L
2
2
y)]01(x,y)[00(x,y)]10(x,y)[11(x,y)]10(x,y)[00(x,y)]01(x,y)[11(x,
y))(x,01y)(x,(10y)(x,00y)(x,11y)(x,S
y)(x,D
y)(x,N
++++++
+âˆ’+
==
 
 
Câ€™est un indice (de type corrÃ©latif )  non rencontrÃ© jusquâ€™ici ,  qui est donc nouveau  et qui 
vaut : 
â€¢  1 si 10(x,y)=01(x,y)=0  (configuration oÃ¹ les deux profils sont identiques) 
â€¢ -1 si 11(x,y)=00(x,y)=0  (configuration oÃ¹ les deux profils sont systÃ©matiquement en 
opposition)  
 
Pour avoir un indice Sâ€™L (x,y) variant de 0 Ã  1, nous devons faire la translation suivante :  
                                                       






+= 1
y)(x,D
y)(x,N
2
1y)(x,S'
2
2
L
  
Ce nouvel  indice vaut donc : 
â€¢ 1 si 10(x,y)=01(x,y)=0  (configuration oÃ¹ les deux profils sont identiques) 
RNTI-A-3 - 286 -
                                                                                                    F. Marcotorchino 
 
â€¢ Â½ si  112(x,y)+002(x,y)= 012(x,y) + 102(x,y) (configuration dâ€™Ã©quilibre quadratique entre 
les configurations de Â« matching Â» et les configuration de Â« non matching Â» ) . Nous 
avons dÃ©jÃ  vu page 72 que cette  situation Ã©tait Ã©quivalente Ã  :  
                       ]y)y)10(x,01(x,y)y)00(x,2.[11(x,y)]01(x,y)(10(x,y)00(x,y)[11(x,P âˆ’=+âˆ’+      
câ€™est Ã  dire si : 
o soit les 4 valeurs sont  Ã©gales : 11(x,y)=00(x,y)=10(x,y)=01(x,y)    
o soit  Ã©galement pour toutes les   dÃ©compositions entiÃ¨res paramÃ©trÃ©es,   so-
lutions de lâ€™Ã©quation Diophantienne associÃ©e  (voir page 72 oÃ¹ une telle so-
lution paramÃ©trÃ©e est donnÃ©e ; et voir F. Marcotorchino , P. Michaud  
(1981) pour dâ€™autres solutions)  
â€¢ Il vaut : 0 si 11(x,y)=00(x,y)=0 .  
 
 
Comportement de lâ€™indice SL(x,y) en cas  de Disjonction ComplÃ¨te 
En cas de disjonction complÃ¨te on a 10(x,y)=01(x,y)=(m-11(x,y)) et 00(x,y)=P+11(x,y)-2m 
Lâ€™indice (forme corrÃ©lative) sâ€™Ã©crit alors : 
 
 
[ ]
[ ] 2222
22
22
222
L
m]-[P[m]
y)]11(x,2P[m1
m]-[P[m]
y)]11(x,2P[mmm]-[P
m]-[P[m]
y))11(x,-(m22m)y)11(x,(Py)(x,11y)(x,S
+
âˆ’
âˆ’=
+
âˆ’âˆ’+
=
+
âˆ’âˆ’++
=
 
 
et  lâ€™indice de similaritÃ© vrai, sâ€™Ã©crit alors :  
 
                        
2222L m][Pm
y)]11(x,P[m11
m]-[P[m]
y)]11(x,2P[m1
2
1y)(x,S'
âˆ’+
âˆ’
âˆ’=





+
+
âˆ’
âˆ’=
 
si lâ€™on pose P=m p  oÃ¹ p  est le nombre moyen de modalitÃ©s de lâ€™ensemble des variables  
lâ€™indice prÃ©cÃ©dent se simplifie en : 
 
              




âˆ’
âˆ’+
âˆ’=
âˆ’+
âˆ’
âˆ’=
âˆ’+
âˆ’
âˆ’=
âˆ’+
âˆ’
âˆ’=
m
y)11(x,1
1)p(1
p1]1)p(m[1
y)]11(x,[mp1
m]p[mm
y)]11(x,[mpm1
m][Pm
y)]11(x,P[m1y)(x,S' 222222L
 
 
â€¢ La valeur 1 pour Sâ€™L(x,y) est obtenue quand m=11(x,y) soit en cas de Â« matching Â» to-
tal entre les profils de x et y  
â€¢ La valeur minimale nâ€™est pas 0  dans le cas de disjonction totale car on ne peut pas 
avoir 00(x,y)=0, en fait dans ce cas 00(x,y)=P-2m  et 11(x,y)=0, ce qui donne une va-
leur minimale Ã©gale Ã  : 
                              
11)p(
2)p1)(p(
1)p(1
p1
m][Pm
Pm1y)(x,S' 2222L +âˆ’
âˆ’âˆ’
=
âˆ’+
âˆ’=
âˆ’+
âˆ’=
 
o  2ou       1p Si = ,    
on constate que lâ€™indice vaut 0 : il sâ€™annule rÃ©ellement  dans le cas oÃ¹ 
la valeur moyenne vaut 1 du fait que nous sommes alors dans la situa-
tion de tableau de Â« prÃ©sence â€“absence Â» vrai, il vaut 0 Ã©galement dans 
le cas oÃ¹ la valeur moyenne du nombre de modalitÃ©s vaut 2  (ce qui se 
RNTI-A-3- 287 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
produit dans le cas de dÃ©doublement disjonctif de variables  binaires 
pures., 
 
o 1verstendy)(x,S'fortement,croÃ®tp Si L   
 
De ce fait la borne de Solomon Fortier nâ€™est donc pas Ã©gale Ã  Â½ mais au milieu de lâ€™intervalle 
allant de la valeur minimale ci dessus Ã  la valeur  1,  soit : 
                                              
( )2222SF m][Pm2
Pm11
m][Pm
Pm1
2
1Borne
âˆ’+
âˆ’=





+
âˆ’+
âˆ’=
 
                                           
la valeur de 11(x,y) pour satisfaire cette borne doit donc vÃ©rifier lâ€™inÃ©galitÃ©  : 
 
                                   
( ) 2
my)11(x,
m][Pm2
Pm1
m][Pm
y)]11(x,P[m1y)(x,S' 2222L â‰¥
âˆ’+
âˆ’â‰¥
âˆ’+
âˆ’
âˆ’=
 
11(x,y) doit donc Ãªtre supÃ©rieur Ã  la majoritÃ© de Condorcet .  
 
Conclusion sur lâ€™Indice de Lerman modifiÃ© 
Nous venons de voir quâ€™Ã  partir de lâ€™indice dâ€™association de Lerman (version modifiÃ©e) , 
nous avons pu gÃ©nÃ©rer deux indices de similaritÃ©s diffÃ©rents  et distincts dÃ©finis Ã  partir de la 
formule : 
  
  (f103)                                      )y(x,y).S(x,Sy)L(x, LT=  
 
Le premier est lâ€™indice Tetrachorique (ou de Bravais â€“Pearson),  lâ€™autre un peu plus com-
plexe vient dâ€™Ãªtre Ã©tudiÃ© ci dessus sous le nom dâ€™Indice de similaritÃ© de Lerman modifiÃ©.  
Chacun des deux indices vÃ©rifie une condition de Solomon-Fortier  impliquant une majoritÃ© Ã  
m/2.  Chacun des deux sous leurs formes corrÃ©latives varient de â€“1Ã  +1.  
Chacun sÃ©parÃ©ment   a du sens,  en revanche, leur produit nâ€™en a pas en tant quâ€™indice de 
similaritÃ©.   
 
4.4.5.4 Indice de similaritÃ© dÃ©duit  du Coefficient Â«  Â» de Goodman-Kruskal 
   Goodman et Kruskal on proposÃ© en 1954 (voir leur livre dÃ©jÃ  citÃ© (1954)) un indice 
dâ€™association quâ€™ils ont appelÃ© Â« indice de prÃ©diction optimale symÃ©trique Â». Cet indice qui 
possÃ¨de dâ€™excellentes propriÃ©tÃ©s statistiques en structure est malheureusement formÃ© Ã  partir 
dâ€™expressions mathÃ©matiques faisant intervenir des Maxima , donc difficiles Ã  calculer dans 
un processus automatique Ã  caractÃ¨re systÃ©matique, comme câ€™est le cas dans les problÃ¨mes 
d â€˜  Â« Association  Maximale Â». Nous donnons ci-dessous son expression, calculable sur 
tableau de contingence gÃ©nÃ©ral : 
 
(f 104)                     
v
v
u
u
..
p
1u
q
1v
v
v
u
u
uv
u
uv
v
nMaxnMax2n
nMaxnMaxnMaxnMax
y)(x,
âˆ’âˆ’
âˆ’âˆ’+
=
 
= =
 
â€¢ Lâ€™indice (x,y) varie entre 0 et 1 : 
 
RNTI-A-3 - 288 -
                                                                                                    F. Marcotorchino 
 
o Il vaut 1  en cas dâ€™Association complÃ¨te  
o Il vaut 0 en cas dâ€™IndÃ©pendance statistique 
 
 
Comme prÃ©cÃ©demment, pour Ã©valuer la valeur de ce Coefficient dâ€™association  (x,y) de 
Goodman Kruskal   sur le tableau de contingence (2x2) Tetrachorique, il suffit de remplacer :   
n
..  
par P, p et q par 2  et 
vun  par lâ€™une des valeurs  : { 11(x,y), 10(x,y), 01(x,y), 00(x,y)}, on 
obtient  aprÃ¨s les  remplacements proposÃ©s, les rÃ©sultats suivants : 
 
    
 
= =




âˆ’+âˆ’+âˆ’+âˆ’+=+
p
1u
q
1v
uv
u
uv
v
y)00(x,y)10(x,y)01(x,y)11(x,y)00(x,y)01(x,y)10(x,y11(x,
2
1PnMaxnMax
           
[ ]y)]00(x,y)[10(x,y)01(x,y)11(x,y)]00(x,y)[(01(x,y)10(x,y)11(x,
2
1PnMaxnMax v.
v
.u
u
+âˆ’+++âˆ’++=+  
Mais pour nous Ã©viter des calculs fastidieux,  comme le tableau Tetrachorique est un tableau 
(2x2) particulier revenons  au cas dâ€™un tableau (2x2) gÃ©nÃ©ral sous la forme : 
 
 
y Non y  
x a b a+b 
Non x c d c+d 
 
a+c b+d N 
 
Reformulons les expressions prÃ©cÃ©dentes au moyen des quantitÃ©s {a, b , c, d }, il vient : 
 
      ( ) 
= =
âˆ’+âˆ’+âˆ’+âˆ’+=+=
p
1u
q
1v
uv
u
uv
v
dcdbcaba
2
1NnMaxnMaxA(i)  
      ( )d)(bc)(ad)(cb)(a
2
1NnMaxnMaxB(ii) v.
v
.u
u
+âˆ’+++âˆ’++=+=  
Comme il existe a priori 4 ! =24 ordres totaux possibles (il y a isomorphisme entre lâ€™ensemble 
des ordres totaux et lâ€™ensemble n={Groupe symÃ©trique des permutations de n objets} ), ceci   
sans compter les possibilitÃ©s de prÃ©ordres associÃ©es. Nous illustrerons la valeur du coefficient  
(x,y) de Goodman Kruskal  en caractÃ©risant les familles dâ€™ordres induits et en le calculant 
par rapport aux sÃ©quences des lettres {a,b,c,d}, ou ce qui est Ã©quivalent Ã  la structure des 
permutations associÃ©es.  
 
Par convention on notera  par exemple <abcd> la permutation ou lâ€™ordre total gÃ©nÃ©rÃ© par la 
sÃ©quence : a>b>c>d câ€™est Ã  dire : 11(x,y)>10(x,y)>01(x,y)>00(x,y)  
 
Etudions alors les diffÃ©rentes configurations possibles : 
 
â€¢ Cas de la FamilleI des ordres respectant la sÃ©paration des couples blocs {a,d} et {b,c}, 
elle regroupe deux sous-familles : 
o La sous famille NÂ°1, elle est constituÃ©e des ordres ou permutations : 
<ad bc>, <ad cb>,<da bc>, <da cb> 
Pour cette famille la valeur de A est identique pour tous ces ordres, car toutes les valeurs absolues 
de la quantitÃ© A sont dÃ©sambiguÃ¯sÃ©es, elle est donnÃ©e par: 
RNTI-A-3- 289 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
   c)](bd[aNA +âˆ’++=  
la valeur de B ne peut Ãªtre obtenue directement , elle nÃ©cessite des comparaisons par rapport aux 
structures induites par les valeurs absolues non dÃ©sambiguÃ¯sÃ©es . Par exemple si lâ€™on prend lâ€™ordre 
<ad bc> on voit que  
               B=N+ (a-d)  si (a+c)> (b+d)  et B=N+(b-c)  dans le cas inverse . 
En fait la construction se fait autour du principe reprÃ©sentÃ© ci-dessous caractÃ©ristique de la 
permutation <adbc> et facilement gÃ©nÃ©ralisable. 
  
 
 
 
 
 
 
 
 
      
 
 
 
 
 
 
 
 
 
  Ainsi pour la permutation  <ad cb>  B vaudra soit N+ (a-d)  soit  N+ (c-b) 
 Pour la permutation <dabc>, B vaudra : soit N+ (d -a) soit   N + (b-c)  
    Pour la permutation <dacb>, B vaudra : soit N+ (d -a) soit   N + (c-b), pour cette famille  de     
permutations on voit que le coefficient  (x,y) vaudra : 
N
c)(bd)(a
B2N
BAy)(x,
âˆ’
âˆ’+âˆ’+
=
âˆ’
âˆ’
=
 
 valant soit (a-d), soit (b-c),soit (d-a), soit (c-b) suivant les cas  avec de ce fait respectivement: 
 
 
c)(b2d
c)(b2dy)(x,
++
+âˆ’
=
 ou  
2cd)(a
2b-d)(ay)(x,
++
+
=
 ou 
c)(b2a
c)(b2ay)(x,
++
+âˆ’
=
ou 
b2da
2cday)(x,
++
âˆ’+
=
 
 
o Sous Famille NÂ°2 elle regroupe les ordres : <bcad>, <cbad>, <bcda>, <cb da> 
Pour les 4 ordres de cette famille on a :  
d)](a-c)[(bNA +++= = N+((Item rang nÂ°1+item rang nÂ°2)- (item rang nÂ°3 + item  rang 
nÂ°4))  
Ainsi pour la permutation  <bcad > : B vaudra soit N+ (a -d)  soit  N+(b -c) 
  Pour cette famille de permutations on voit que le coefficient (x,y) vaudra : 
   
N
d)(ac)(b
B2N
BAy)(x,
âˆ’
âˆ’+âˆ’+
=
âˆ’
âˆ’
=
 
 valant soit (a-d), soit (b-c),soit (d-a), soit (c-b) suivant les cas  avec de ce 
fait respectivement : 
                           
2dcb
2a-cby)(x,
++
+
=
ou 
d)(a2c
d)(a-2cy)(x,
++
+
=
 ou 
2ac)(b
2dcby)(x,
++
âˆ’+
=
 ou  
d)(a2b
d)(a-2by)(x,
++
+
=
 
 
Dâ€™une faÃ§on gÃ©nÃ©rale pour toutes les permutations { I Famille 4321 >âˆˆ< } 
A= N+((Item rang nÂ°1+item rang nÂ°2)- (item rang nÂ°3 + item  rang nÂ°4))  
                         Soit  A=N+((1+2)-(3+4 )) 
  a  d  b  c  
a+b>d+c  	   
calcul sÃ»r 
a+c ? d+b  	 comparai-
son Ã  faire 
RNTI-A-3 - 290 -
                                                                                                    F. Marcotorchino 
 
                             et B=N+(1-2) ou B=N+(3-4)  
DÃ¨s lors dâ€™une faÃ§on gÃ©nÃ©rale lâ€™indice (x,y) pour toute permutation appartenant Ã  cette Fa-
mille I  
vaudra :     
)( 2
)(2
y)(x,
432
432
++
+âˆ’
=
   ou    
421
321
2
2
y)(x,
++
âˆ’+
=
 
 
â€¢ Cas de la Famille II des ordres imbriquant les couples blocs {a,d} et {cd}, elle se 
compose de la famille  des 8 ordres suivants : 
o <abdc>,<acdb>,<dbac>,<dcab>,<bacd>, <bdca>, <cabd>, <cdba> : 
pour cette famille, on peut montrer que : 
                   A= N + (item en 1Ã¨re position - item en 4Ã¨me position)  
ainsi on aura A= N + (a â€“ c) pour la 1ere permutation <abdc> 
A= N+  (a-b)  pour la deuxiÃ¨me <acdb>,   A=N + (d-c)  pour la troisiÃ¨me etc.. 
Pour B on aura B=N+(item  en 1Ã¨me position â€“ item en 3Ã¨me) ou B=N+(item en 2Ã¨me â€“ item en 
4Ã¨me), ces deux valeurs possibles de B dÃ©pendant de la dÃ©sambiguÃ¯sation de la valeur absolue 
restante. 
Ainsi B=N+(a-d)  pour <abdc> ou B=N+(b-c) pour cette mÃªme permutation <abdc> 
De  fait pour cette permutation on a les valeurs suivantes de (x,y) : 
c)(b2d
cd
d)(aN
d)-(a-c)-(a
B2N
BAy)(x,
++
âˆ’
=
âˆ’âˆ’
=
âˆ’
âˆ’
=
ou  
d)(a2c
ba
c)-(bN
c)-(b-c)-(ay)(x,
++
âˆ’
=
âˆ’
=
 
Dâ€™une faÃ§on gÃ©nÃ©rale lâ€™indice (x,y) associÃ© Ã  une permutation :  
II Famille 4321 >âˆˆ<  
Aura deux valeurs possibles  soit: 
                                   
)( 2

y)(x,
423
43
++
âˆ’
=
   ou   
)( 2

y)(x,
314
21
++
âˆ’
=
 
 
â€¢ Cas de la Famille III des ordres tels que  les structures {a,d}et {b,c} sâ€™englobent  
ou sâ€™emboÃ®tent mutuellement , elle est composÃ©e des 8 ordres ou permutations sui-
vantes : 
o <abcd>,<acbd>,<dbca>, <dcba>, <badc>,<bdac>,<cadb>,<cdab> 
pour cette famille toutes les valeurs absolues sont dÃ©sambiguÃ¯sÃ©es et on aura uniquement une 
seule valeur pour B , en effet on peut vÃ©rifier que : 
  A=N+(item en 1Ã¨re position â€“ item en 4Ã¨me position )  
       et     B=N+(item en 1Ã¨re position â€“ item en 4Ã¨me position)  
Comme le NumÃ©rateur du coefficient (x,y) est Ã©gal Ã  A-B et quâ€™ici  A=B  
lâ€™indice (x,y) associÃ© Ã  une permutation : III Famille 4321 âˆˆ><  
aura une seule et unique valeur nulle , soit :  
 
0y)(x, =  
 
.  .  
Revenons au tableau de contingence Tetrachorique proprement dit et appliquons les rÃ©sultats 
prÃ©cÃ©dents Ã  deux configurations qui peuvent se produire frÃ©quemment (en particulier dans le 
cas  gÃ©nÃ©ral dâ€™un tableau de donnÃ©es de type Â« prÃ©sence-absence Â» pour lequel il nâ€™y a pas a 
priori de structure sur les Ã©lÃ©ments qui permettent dâ€™Ã©liminer des configurations). Choisis-
sons par exemples les 3 configurations dâ€™ordres totaux suivants : 
NÂ°1= 00(x,y)>11(x,y)>01(x,y)> 10(x,y)  
NÂ°2= 11(x,y)>10(x,y)>00(x,y)> 01(x,y) 
NÂ°3= 11(x,y)>10(x,y)>01(x,y)> 00(x,y) 
 
RNTI-A-3- 291 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
â€¢ Lâ€™ordre  NÂ°1 appartient de faÃ§on Ã©vidente Ã  la Famille I, il est Ã©quivalent Ã  <dacb> 
avec les notations prÃ©cÃ©dentes. DÃ¨s lors les valeurs possibles de lâ€™indices sont don-
nÃ©es par :   
     
)( 2
)(2
y)(x,
432
432
++
+âˆ’
=
        ou          
421
321
2
2
y)(x,
++
âˆ’+
=
 
aprÃ¨s identification de 1, 2, 3, 4 respectivement Ã   00(x,y), 11(x,y), 01(x,y), 10(x,y)  
il vient : 
 
o )y01(x,y)11(x,y)10(x,y)00(x,     si    
y)(x,01y)(x,10y)2.11(x,
y](x,01y)[01(x,y)2.11(x,y)(x, +>+
++
+âˆ’
=
 
(On retrouve ici un indice connu puisque lâ€™indice de Dice est Ã©gal Ã  :                     
   
y)(x,01y)(x,10y)2.11(x,
y)]2.11(x,y)(x,Sd
++
=
) 
                dâ€™oÃ¹                                      
       1y)(x,S2y)(x, d âˆ’=  
o )y01(x,y)11(x,y)10(x,y)00(x,     si      
y)2.10(x,y)00(x,y)11(x,
y)2.01(x,y)00(x,y)11(x,y)(x, +<+
++
âˆ’+
=
 
 
Compte tenu de lâ€™ordre induit , on voit que dans les deux cas de figure : (x,y)  0 
                                                                    
 
â€¢ Lâ€™ordre NÂ°2 appartient, lui, Ã  la Famille II des ordres Ã  imbrication, il est Ã©quiva-
lent Ã  <abdc> . Les valeurs possibles de lâ€™indice (si lâ€™on identifie 1, 2, 3, 4 respec-
tivement Ã   11(x,y), 10(x,y), 00(x,y), 01(x,y) ) sont donnÃ©es de faÃ§on gÃ©nÃ©rale par : 
 
)( 2

y)(x,
423
43
++
âˆ’
=
    ou     
)( 2

y)(x,
314
21
++
âˆ’
=
 
 
on aura donc : 
 
o y)01(x,y)11(x,y)10(x,y)00(x,    si     
y)01(x,y)10(x,y)2.00(x,
y)(x,10y)00(x,y)(x, +>+
++
âˆ’
=
  
o y)01(x,y)11(x,y)10(x,y)00(x,    si     
y)(x,00y)(x,11y)2.01(x,
y)(x,10y)11(x,y)(x, +<+
++
âˆ’
=
 
 On voit ici encore que dans les deux cas de figure prÃ©cÃ©dents , compte tenu de 
lâ€™ordre induit : 
 3 > 4  et 1 >2 , on a :          (x,y)  0 
 
â€¢ Lâ€™ordre NÂ°3 appartient Ã  la Famille III des ordres Ã  emboÃ®tement , il est Ã©quivalent 
Ã  <abcd>,  de facto  
on aura donc :          (x,y) = 0 dans cette configuration 
 
 
Comportement de lâ€™indice  (x,y)  de Goodman-Kruskal  en cas  de Disjonction Com-
plÃ¨te 
RNTI-A-3 - 292 -
                                                                                                    F. Marcotorchino 
 
En cas de disjonction complÃ¨te , le tableau  Tetrachorique se ramÃ¨ne Ã  : 
 
 y Non y  
x 11(x,y) m-11(x,y) m 
Non x m-11(x,y) P+11(x,y)-2m P-m 
 m P-m N 
   
  Les formules suivantes : 
               ( ) 
= =
âˆ’+âˆ’+âˆ’+âˆ’+=+=
p
1u
q
1v
uv
u
uv
v
dbcbcaba
2
1NnMaxnMaxA(i)  
              [ ]d)(bcad)(cba
2
1NB(ii) +âˆ’+++âˆ’++=  
se simplifient, puisquâ€™ici N=P, en:  
 
        (i)             A= P+|m-2.11(x,y)|+ |P+2.11(x,y)-3m|      
(ii) B= P+ | P-2m| 
(iii) En cas de disjonction complÃ¨te :00(x,y)>11(x,y)  (sauf pour P=2m), 10(x,y)=01(x,y)=m-11(x,y)  
seule reste posÃ©e la question du positionnement de 11(x,y) par rapport Ã  10(x,y) .  
Si 11(x,y)>10(x,y)=01(x,y) alors 11(x,y)>m-11(x,y) => 11(x,y)>m/2 (majoritÃ© de Condorcet) et  
lâ€™ordre associÃ© est : 00(x,y)>11(x,y)>10(x,y)=01(x,y)  (cas des ordres Ã  sÃ©paration vus prÃ©cÃ©dem-
ment) 
Si 11(x,y)<10(x,y)=01(x,y) alors  11(x,y) <m-11(x,y)    =>  11(x,y)m/2 lâ€™ordre associÃ© est lâ€™ ordre 
Ã  emboÃ®tement : 00(x,y)>10(x,y)=01(x,y)>11(x,y)  
 
â€¢ Si P=2m alors B=P=2m et : 
                              si 11(x,y) > m/2   alors   1y)(x,2S
m
my)2.11(x,y)(x, d âˆ’=
âˆ’
=
  
                              si  11(x,y) < m/2   alors   (x,y) =0    
 
â€¢ Si P 3m  alors B=2P-2m et A= 2P +211(x,y) â€“3m + |211(x,y)-m|b 
             
                              si 11(x,y)>m/2   alors   1y)(x,2S
2m
m2y)4.11(x,y)(x, d âˆ’=
âˆ’
=
 
  
                     si 11(x,y)  m/2   alors (x,y) =0 
               (en effet dans ce cas on se retrouve comme prÃ©cÃ©demment  dans une situation dâ€™emboÃ®tement  avec              
00(x,y)>01(x,y)=10(x,y)>11(x,y)) 
 
 En conclusion lâ€™indice de Goodman Kruskal calculÃ© sur Tableau Tetrachorique en cas de 
disjonction complÃ¨te se prÃ©sente comme un indice de similaritÃ© Ã  Â« cliquet Â» ou Ã  seuil, qui, 
suivant la valeur de 11(x,y), est nul ou Ã©quivalent  Ã   2 Sd(x,y)-1  (HomothÃ©tie sur lâ€™indice de 
Dice)  ce qui veut dire par ailleurs que  dans le cas de disjonction complÃ¨te lâ€™indice:  
 
                                   S(x,y) =1/2 ((x,y)+1)  est Ã©quivalent Ã   Sd (x,y) si  11(x,y) > m/2 
La condition de Solomon Fortier appliquÃ©e Ã  cet indice comme il varie de 0 Ã  1 si 11(x,y)>m/2 
se traduira par lâ€™inÃ©galitÃ© : 
   (x,y)   1/2  2 Sd(x,y)-1  1/2  2 Sd(x,y)   3/22.11(x,y)  3/2.m  11(x,y)   3/4 m  (ma-
joritÃ© au Â¾)  
RNTI-A-3- 293 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
On a tracÃ© ci-dessous le graphe le lâ€™indice Lambda de Goodman Kruskal   (x,y) en fonction 
de lâ€™indice de Dice ou de faÃ§on Ã©quivalente du rapport 11(x,y)/m dans le contexte de disjonc-
tion complÃ¨te. 
 
0
0,2
0,4
0,6
0,8
1
1,2
0 0,2 0,333 0,5 0,625 0,76 0,9 1
Lambda
Dice
 
 
 
4.4.5.5. Indice de similaritÃ© dÃ©duit  du Coefficient Â« Îº Â» de Cohen 
 
  Comme le souligne G. Saporta dans son livre de  (2006) (rÃ©Ã©dition de son premier ouvrage 
de 1990), ce coefficient de contingence est destinÃ© Ã  mesurer lâ€™accord entre deux variables 
qualitatives (partitions) ayant le mÃªme nombre de modalitÃ©s p. ;  n
..
 unitÃ©s statistiques sont 
rÃ©parties suivant ces  p catagories pour les deux partitions. Il y aura accord total entre ces 
deux partitions si les termes diagonaux sont les seuls termes  non nuls du tableau de contin-
gence suivant. (La premiÃ¨re rÃ©fÃ©rence Ã  ce coefficient est donnÃ©e dans un article du biostatis-
tien et psychomÃ©tricien  Jacob Cohen datant de 1960 (1960)).  
 
 
 
 
 
 
 
 
 
 
 
 
 
Lâ€™indice sâ€™Ã©crit alors :  
 
(f 105) 
 
     y 
x 
1 2 v .. p 
 
1      n1. 
2      n2. 
u 
  
vun  
  
 n
 u . 
..       
p       
 n
.1 n.2 n. v   n..

 
=
= =
âˆ’
âˆ’
= p
1u
u.u.2
..
p
1u
p
1u
u.u.2
..
uu
..
nn
n
11
nn
n
1
n
n
1
y)(x,
RNTI-A-3 - 294 -
                                                                                                    F. Marcotorchino 
 
 
 
        Cet indice vaut : 
 1 en cas dâ€™association complÃ¨te et totale   
-1 en cas oÃ¹ tous les termes de la diagonales sont nuls et les termes hors diagonales sont 
Ã©gaux 
Dans le cas qui nous concerne nous travaillons sur un tableau (2x2), vÃ©rifiant donc p= q =2 
(les deux variables ont mÃªme nombre de classes). Ce tableau est du type suivant : 
 
 
 y Non y  
x a b a+b 
Non x c d c+d 
 a+c b+d N 
 
 
De ce fait nous pouvons  calculer  le coefficient Îº(x,y) sur le tableau  prÃ©cÃ©dent, il vient  
 
 
(f 106) 
 
 
 
AprÃ¨s simplification on obtient:  
(f 107):  
 
 
Cet indice possÃ¨de une autre expression Ã©quivalente en effet il sâ€™Ã©crit :  
 
(f 107â€™)                    
)dc)(ca()db)(ba(
]bcad[2)y,x(
+++++
âˆ’
=
 
En effet les dÃ©nominateurs de (f 107)  et (f 107â€™)  sont Ã©gaux aprÃ¨s dÃ©veloppement, nÃ©anmoins 
grÃ¢ce Ã  lâ€™expression (f 107â€™) , on voit que,  en posant : 
)dc)(ca(
)bcad(
vet)db)(ba(
)bcad(
u
++
âˆ’
=
++
âˆ’
=
 
 
)vu(
v.u2)v,u(HarmoniqueMoyenne)y,x(
+
==
 
et  
vu)v,u(eGÃ©omÃ©triquMoyenne)y,x(ST ==  
 
On en dÃ©duit que :    
 
 
Le coefficient de Cohen vaut : 
 
â€¢  +1, en cas dâ€™association complÃ¨te et totale  b=c=0  et  a et d â‰ 0 
d)]d)(c(bc)b)(a[(a
N
11
d)]d)(c(bc)b)(a[(a
N
1d)(a
N
1
y)(x,
2
2
+++++âˆ’
+++++âˆ’+
=
)d(a)c(bd)N(a
)d(a)c(bc)](bd)N[(a
bc]2[adc)(bN
bc]2[ady)(x, 2222
2222
+âˆ’+++
+âˆ’+++âˆ’+
=
âˆ’++
âˆ’
=
1)y,x(S)y,x(0 T â‰¤â‰¤â‰¤
RNTI-A-3- 295 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
â€¢ -1, au cas oÃ¹ tous les termes de la diagonales sont nuls et les termes hors diagonale 
sont Ã©gaux 
 
En effet, on  voit  grÃ¢ce Ã  la formule (f 106) que quand a+d=N (câ€™est Ã  dire b=c=0),  alors : 
                                                         
1
)d(a
N
11
)d(a
N
11
y)(x,
22
2
22
2
=
+âˆ’
+âˆ’
=
  
grÃ¢ce Ã  la deuxiÃ¨me formulation  on voit que quand a=d=0, alors b+c=N  et  Îº(x,y) devient : 
 
 
 
 
ce coefficient est minimal lorque Â« bc Â»  est maximum et  Â« b2+c2 Â» minimum , or nous avons 
vu au Â§4.4.5.3 que ceci se produisait quand les deux nombres sont Ã©gaux en effet : Â« le pro-
duit de 2 nombres dont la somme S est constante (ici Ã©gale Ã  N)  est maximum si ces deux 
nombres sont Ã©gaux Â», la consÃ©quence pour notre problÃ¨me est que : quelle que soit la valeur 
N , on doit avoir  b = c = N/2   Ã  lâ€™optimum.  Dâ€™oÃ¹ le fait signalÃ© que lâ€™indice de Cohen  Kap-
pa est Ã©gal Ã  â€“1 dans ce cas . 
 
Comme lâ€™indice Kappa  de Cohen varie de â€“1 Ã  +1, il Ã©voque un indice corrÃ©latif, pour en 
faire un indice de similaritÃ© vrai, variant de 0 Ã  1,  il suffit de construire lâ€™indice de similaritÃ© 
Â« affine Â» associÃ© au Kappa de Cohen en remplaÃ§ant dans les formulation prÃ©cÃ©dentes Â« a par 
11(x,y) Â», Â« b par 10(x,y) Â», Â« c par 01(x,y) Â»,  Â« d par 11(x,y) Â», et N par P et en calculant la quanti-
tÃ© Â½(Îº(x,y)+1), il vient: 
 
y)]01(x,y)P[10(x,y)]01(x,y)10(x,y)00(x,y)2[11(x,
y)]01(x,y)[10(x,
2
Py)]01(x,y)10(x,y)00(x,y)2[11(x,
c)N(bbc)ad2(
c)(b
2
Nbc)ad2(
1]y)(x,[
2
1
 y)(x,S
++âˆ’
++âˆ’
=
++âˆ’
++âˆ’
=+=
 
 
sous cette forme on  voit que lâ€™indice de similaritÃ© vaut :  
â€¢ SÎº(x,y) =0  si 11(x,y)=00(x,y)=0 avec la condition supplÃ©mentaire :  10x,y)=01(x,y)=N/2 
â€¢ SÎº(x,y) =1/2  si 11(x,y).00(x,y)= 10(x,y).01(x,y) (condition dâ€™indÃ©pendance) 
â€¢ SÎº(x,y) =1  si  10(x,y)=01(x,y)=0 
 
Si lâ€™on compare le coefficient Kappa de Cohen et le coefficient Q de Yule on voit quâ€™ils ont 
des points communs  puisquâ€™ils quâ€™ils utilisent les mÃªmes quantitÃ©s,  mais pas de la mÃªme 
maniÃ¨re.  
y)y).01(x,10(x,y)y).00(x,11(x,
y)y).10(x,01(x,y)y).00(x,11(x,
bc)(ad
bc)(ady)(x,SQ
+
âˆ’
=
+
âˆ’
=
 
 
 
Comportement de lâ€™indice S(x,y) en cas  de Disjonction ComplÃ¨te 
En cas de disjonction complÃ¨te lâ€™indice Kappa prÃ©cÃ©dent du fait des symÃ©tries entre valeurs 
se simplifie  selon la formule : 
2222 cb
2bc
2bcc)(b
2bc
2bcN
2bc-y)(x,
+
âˆ’
=
âˆ’+
âˆ’
=
âˆ’
=
RNTI-A-3 - 296 -
                                                                                                    F. Marcotorchino 
 
 
                     
y)]11(x,-2P[m]y)]11(x,[m2m)y)11(x,(Py)2[11(x,
y)]11(x,-P.[m]y)]11(x,[m2m)y)11(x,(Py)2[11(x,
 y)(x,S 2
2

+âˆ’âˆ’âˆ’+
+âˆ’âˆ’âˆ’+
=
 
Dire que S(x,y)  1/2 implique que : 
        
2
1
y)]11(x,-2P[m]y)]11(x,[m2m)y)11(x,(Py)2[11(x,
y)]11(x,-P.[m]y)]11(x,[m2m)y)11(x,(Py)2[11(x,
 y)(x,S 2
2
 â‰¥
+âˆ’âˆ’âˆ’+
+âˆ’âˆ’âˆ’+
=
 
 
câ€™est Ã  dire : 
                             11(x,y)(P+11(x,y)-2m)  (m-11(x,y))2 
soit : 
                        )y(x,11y)2m11(x,my)2m11(x,y)(x,11y)P11(x, 222 +âˆ’â‰¥âˆ’+  
ce qui implique :   
p
my)11(x,   m,pP    poseon      l'  si
P
my)11(x,
2
â‰¥=â‰¥
 
On retrouve ici une borne Ã©quivalente Ã  celle obtenue pour lâ€™indice de similaritÃ© dÃ©rivÃ© du 
Coefficient de contingence SQ de Yule (voir Â§ 4.4.4.2). 
 
 
4.5  Indices Ã  Â« valuations Â», ou  Â« pseudo-indices de similaritÃ©s Â» 
   Nous appelerons indices de similaritÃ©  Ã  Â« valuations Â» ou Â« indices dâ€™abondance Â», les 
indices que nous allons prÃ©senter maintenant. En fait ces indices nâ€™ont pas Ã©tÃ© dÃ©finis a 
priori pour des tableaux de donnÃ©es binaires de prÃ©senceâ€“absence mais pour des tableaux 
de donnÃ©es du type du tableau nÂ°1, introduit au Â§ 2.1, mais oÃ¹ les valeurs ne sont plus {0 
ou 1} mais  des Â« comptages Â» dâ€™occurrences (ce que les anglo-saxons appelent Â« abon-
dance matrices Â» de terme gÃ©nÃ©ral {tij }.    
 
  
  
  
  
  
  
   
  
                                        
En fait les matrices de Â« prÃ©sence-absence Â» sont des cas particuliers de Â« matrices 
dâ€™abondance Â»,  mais bien entendu les indices associÃ©s, sont a priori diffÃ©rents de ceux que 
nous avons  prÃ©sentÃ©s jusquâ€™ici. Il est intÃ©ressant de noter par ailleurs que la plupart des 
indices introduits dans ce contexte lâ€™ont Ã©tÃ© par des spÃ©cialistes de lâ€™Ã©tude des plantes et 
 m1 m2 mj mjâ€™  mP 
O1 t11 t12 t1j    
O2 
      
O3 t31 t32     
Oi 
  tij    
 Oiâ€™ 
      
 
      
ON tN1  tNj   tNP 
RNTI-A-3- 297 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
principalement des Â« phytosociologues Â» ou des spÃ©cialistes de ce que les anglo-saxons 
appellent Â« plant ecology Â».  
Notre propos,  dans ce paragraphe, est de voir si certains de  ces indices, dÃ©diÃ©s aux ma-
trices dâ€™abondance,  vont gÃ©nÃ©rer  dans leur restriction aux cas de tableaux de Â« prÃ©sence-
absence Â», des indices diffÃ©rents de ceux  qui auraient dÃ©jÃ  Ã©tÃ© prÃ©sentÃ©s.  MÃªme dans le 
cas oÃ¹ nous retrouverons  des indices de similaritÃ© dÃ©jÃ  Ã©tudiÃ©s prÃ©cÃ©demment (câ€™est ce qui 
va se produire), la structure intrinsÃ©que de  ces indices est diffÃ©rente de celle que nous 
avons rencontrÃ©e  jusquâ€™Ã  maintenant. Ceci est  riche dâ€™enseignements sur la faÃ§on dont les 
phytosociologues les ont imaginÃ©s et pensÃ©s.   
Par convention,  ici,  les individus x et y seront dÃ©crits par leurs profils vectoriels: 
  
x = {tx1, tx2, tx3,â€¦â€¦txj..txP} et  y = {ty1, ty2, ty3,â€¦â€¦tyj..tyP} 
 
4.5.1 Indices dâ€™abondance  (ou Ã  valuations) fonction de la diffÃ©rence  (t ij -t iâ€™j) 
4.5.1.1 Indice de Lance et Williams (1966) 
   Cet  Â« indice dâ€™abondance Â» est dÃ©fini par :  
(f108)                         
=
+
âˆ’
=
P
1j jyjx
jyjx
LW )t(t
tt
P
1y)(x,I  
On voit de faÃ§on Ã©vidente  quâ€™il varie de 0 Ã  1 ,  
Il vaut en effet  0 si tx j = ty j  âˆ€j,  et il vaut 1 si âˆ€j , txjâ‰ 0  ty j=0  et rÃ©ciproquement  si  ty j â‰ 0   . 
tx j = 0, en effet dans ce dernier cas on obtient un ratio concernant lâ€™indice Â« j Â» qui vaut 
toujours 1. Si cette situation se produit P fois, la division par P ramÃ¨ne la valeur de lâ€™Indice  
ILW(x,y) Ã  1. La faÃ§on de transformer   un indice dâ€™abondance  en un indice de similaritÃ© 
normÃ© paraÃ®t donc ici Ã©vidente,  il suffit de poser : 
                                                    SLW(x,y) = 1- ILW (x,y) 
Lâ€™indice SLW(x,y) varie bien maintenant de 0 Ã  1 , il vaut 1 si x et y ont un profil identique,   
et 0 sâ€™ils sont totalement en opposition.  
IntÃ©ressons nous maintenant Ã  la restriction de cet indice dans le cas oÃ¹ les valeurs {tij} en 
lâ€™occurrence t x j et t y j  sont des valeurs {0 ou 1},  
(Attention : on suppose par convention  ici que les configurations oÃ¹ txj=tyj=0  qui a priori 
impliquent  une division par 0) se traduisent par un ratio Ã©gal Ã  1  :  
Dans ce cas,  âˆ€ j , le ratio :   
yjxj
yjxj
tt
tt
+
âˆ’
 vaut 0 ou 1, il vaut 0 si la valeur tij est identique pour x et 
y et il vaut 1 en cas contraire.    
RNTI-A-3 - 298 -
                                                                                                    F. Marcotorchino 
 
 De ce fait :              ]y)01(x,y)[10(x,
P
1
)t(t
tt
P
1y)(x,I
P
1j jyjx
jyjx
LW +=
+
âˆ’
= 
=
 
On a alors la propriÃ©tÃ© suivante:  
 
 
PropriÃ©tÃ© nÂ°18 : Lâ€™Indice de SimilaritÃ©  de Lance Willliams dans sa restriction 0-1 avec la con-
vention prÃ©cÃ©dente (pour les cas 0-0)  nâ€™est rien dâ€™autre que le critÃ¨re de Sokal et Michener 
(Simple Matching)  
En effet on a:  
               y)(x,S
P
y)00(x,y)11(x,y)]01(x,y)[10(x,
P
11)t(t
tt
P
11y)(x,S SM
P
1j jyjx
jyjx
LW =
+
=+âˆ’=
+
âˆ’
âˆ’= 
=
 
 
4.5.1.2 Indice de Odum (1950),  plus connu sous le nom dâ€™Indice de  Â« Bray-Curtis Â» 
(1957) 
 
Cet indice est dÃ©fini par :  
(f109)                         


=
=
+
âˆ’
= P
1j
yjxj
P
1j
yjxj
BC
)t(t
tt
y)(x,I
 
Ici on nâ€™a pas besoin (et câ€™est un avantage), comme dans le cas prÃ©cÃ©dent,  de convention 
particuliÃ¨re pour les cas (0-0). Cet indice vaut 0 si tx j=ty j âˆ€ j , et il vaut 1 si âˆ€j , txjâ‰ 0  ty j=0  et 
rÃ©ciproquement  si  ty j â‰ 0   . tx j = 0, 
Dans le cas oÃ¹ lâ€™on se restreint Ã  des valeurs tij âˆˆ{0,1}, le numÃ©rateur de lâ€™indice nâ€™est rien 
dâ€™autre que la quantitÃ©  
                                           y)01(x,y)10(x,tt
P
1j
jyjx +=âˆ’
=
 
Le dÃ©nominateur est Ã©gal Ã  : 
                                     y)01(x,y)10(x,y)11(x,.2y)11(y,x)11(x,)t(t
P
1j
yjxj ++=+=+
=
 
Lâ€™indice de similaritÃ© associÃ© dÃ©fini par   SBC(x,y)= 1- IBC(x,y)  est donc Ã©gal Ã  :  
                
)y(x,S
y)]01(x,y)[10(x,
2
1y)11(x,
y)11(x,
y)01(x,y)10(x,y)211(x,
y)2.11(x,y)(x,S dBC =
++
=
++
=
 
 
PropriÃ©tÃ© nÂ°19 : Lâ€™Indice de SimilaritÃ©  de Bray-Curtis (Odum), dans sa restriction 0-1, est stric-
tement identique Ã  lâ€™indice de Dice  
 
4.5.2 Indices dâ€™abondance  (ou Ã  valuations) fonction de  Max(tij,tiâ€™j)  ou Min (tij, tiâ€™j)  
4.5.2.1 Indice de Kulczinski formel (1930) 
Cet indice est dÃ©fini par :  
RNTI-A-3- 299 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
(f110)                         


=
=
+
= P
1j
yjxj
P
1j
yjxj
K
)t(t
)t,(tMin
y)(x,I
 
  
Du fait que Min (a,b)=Â½ (a+b) - Â½ |a - b|, il apparaÃ®t de facon Ã©vidente que cet indice est Ã©gal Ã  :  
 
                                 
y)(x,I
2
1
2
1
)t(t
)t,(tMin
y)(x,I BCP
1j
yjxj
P
1j
yjxj
K âˆ’=
+
=


=
=
 
Cet indice vaut Â½  si tx j=ty j âˆ€ j , et il vaut 0  si âˆ€j , txjâ‰ 0  ty j=0  et rÃ©ciproquement  si  ty j â‰ 0   . tx j 
= 0, 
 
Dans le cas oÃ¹ lâ€™on se restreint Ã  des valeurs tij âˆˆ{0,1}, on a vu que : SBC(x,y)= 1- IBC(x,y)    
Dâ€™oÃ¹ comme  IBC(x,y)= 1-2 IK(x,y) , il vient alors : 
                                       SBC(x,y)=1-(1-2IK(x,y))= 2 IK(x,y)  
en posant              SK(x,y)=2IK(x,y) , il apparaÃ®t que cet indicedâ€™abondance  induit au coeffi-
cient 2 prÃ¨s ,  un indice de similaritÃ©  Ã©gal Ã  lâ€™indice de Â« Dice Â». 
4.5.2.2 Indice de Marczewski et Steinhaus (1937) 
Cet indice est dÃ©fini par :  
 
(f111)                         


=
=
âˆ’
= P
1j
yjxj
P
1j
yjxj
SM
)t,(tMax
tt
y)(x,I
 
 
Dans ce cas encore, en jouant sur le fait que Max(a,b) =Â½ (a+b) + Â½ |a - b| , on voit que la quan-
titÃ© 1/IMS(x,y)   peut se simplifier, en effet on obtient :  
1y)(x,I
y)(x,2Iy)(x,I
y)(x,I
1
x
2
1
2
1
t-t
)t(ttt
y)(x,I
1
BC
BC
MS
BC
P
1j
jyjx
P
1j
P
1j
yjxj2
1
yjxj2
1
MS +
=+=
++âˆ’
=

 
=
= =
 
Sous cette forme, il apparaÃ®t de faÃ§on Ã©vidente que IMS(x,y) varie de 0 Ã  1 , puisque IBC (x,y) 
varie de 0 Ã  1 lui-mÃªme.  
Maintenant dÃ©finissons lâ€™Â« indice de similaritÃ© de Marczewski et Steinhaus Â» comme la 
quantitÃ© : 
                                                       SMS (X,Y)=1-IMS (X,Y) 
DÃ¨s lors,  dans le cas oÃ¹ lâ€™on se restreint Ã  des valeurs tij binaires on peut montrer que 
lâ€™indice prÃ©cÃ©dent sâ€™Ã©crit :  
                              
y)(x,S2
y)(x,S
y)(x,I1
y)(x,I1y)x,S
d
d
BC
BC
MS(
âˆ’
=
+
âˆ’
=
 
oÃ¹ Sd(x,y) est lâ€™indice de Dice (voir 4.1.1.1) .  La fonction homographique prÃ©cÃ©dente nâ€™est 
autre que la formule (f17) caractÃ©ristique de lâ€™indice de Jaccard.  
Donc en conclusion , on a la propriÃ©tÃ© nÂ°20 suivante : 
 
RNTI-A-3 - 300 -
                                                                                                    F. Marcotorchino 
PropriÃ©tÃ©nÂ°20 : Lâ€™indice de similaritÃ© dÃ©duit de lâ€™indice dâ€™abondance de Marczewski â€“Steinhaus 
nâ€™est rien dâ€™autre dans sa restriction boolÃ©enne que lâ€™indice de Jaccard 
 
 
 
 
 
 
En guise de conclusion sur les indice du type Â« indices Ã  valuations Â».  
Dans la liste prÃ©cÃ©dente il nâ€™a pas Ã©tÃ© fait mention (et dâ€™aucuns pourraient sâ€™en Ã©tonner) des 
indices qui se calculent Ã  partir de donnÃ©es de frÃ©quences ou  dâ€™occurrences de phÃ©nomÃ¨nes 
(comme par exemple le comptage de termes apparaissant dans des textes).  
Outre les indices de contingences dont nous avons vu quelques exemplaires au Â§ 4.4.,  qui 
peuvent Ãªtre utilisÃ©s dans ce contexte, comme Ã©galement pourrait lâ€™Ãªtre le classique  CritÃ¨re 
du 2;  il se trouve quâ€™un certain nombre dâ€™auteurs provenant de la Linguistique computa-
tionnelle ou de la recherche documentaire  ont Ã©laborÃ©  des coefficients beaucoup plus adap-
tÃ©s au  domaine de la Â« comparaison documentaire Â» ou  totalement en adaquation avec  la 
recherche sur Internet. Câ€™est le cas de lâ€™amÃ©ricain Gerard Salton  (voir G. Salton (1968)  et 
(1983)) qui a proposÃ©  avec son Ã©quipe,  tout dâ€™abord son Â« Cosinus simple de profils frÃ©-
quentiels  pondÃ©rÃ©sÂ»,  puis son fameux Â«  TF-IDF Cosine Â»,  (Â« Term Frequency â€“Inverse 
Document Frequency Â»,  coefficient quâ€™il a dâ€™ailleurs appellÃ© le Â« best fully weighted sys-
tem Â» ). Lui et lâ€™anglaise Karen Sparck Jones (1971), ont Ã©tÃ© les pionniers de ces recherches 
sur les mesures de matching entre documents. On trouvera dans lâ€™article simple et bien struc-
turÃ© de A. Lelu (2002) un essai de comparaison des mesures de Salton avec  dâ€™autres ap-
proches issues de mÃ©thodologies Â« neuronales Â» ou Â« factorialistes Â».  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
RNTI-A-3- 301 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
 
100
Indices Groupe Type Formule Borne S.F. Variation 
Dice Group I Typ1 y)01(x,y)10(x,y)211(x,
y)2.11(x,y)(x,Sd ++=
 
m/2 0 S  1 
Jaccard Group I Typ1 [ ])y,x(01)y,x(10)y,x(11
)y,x(11)y,x(Sj ++=
 2m/3 0 S  1 
Anderberg Group I Typ1 [ ])y,x(01)y,x(102)y,x(11
)y,x(11)y,x(San
++
=
 4m/5 0 S  1 
Sorensen Group I Typ1 [ ])y,x(01)y,x(10
4
1)y,x(11
)y,x(11)y,x(Sso
++
=
 
m/3 0 S  1 
Anderberg 2 Group I Typ1 [ ])y,x(01)y,x(10
8
1)y,x(11
)y,x(11)y,x(Sac
++
=
 
m/5 0 S  1 
Kulczynski Group I Typ 2A 




	
+
+
+ y)01(x,y)11(x,
y)11(x,
y)10(x,y)11(x,
y)11(x,
2
1
y)(x,Sk
 
m/2 0 S  1 
OchiaÃ¯ Group I Typ 2A )]y,x(01)y,x(11)][(y,x(10)y,x(11[
)y,x(11)y,x(So
++
=
 
m/2 0 S 1 
Rappel Group  I Typ 2A y)10(x,y)11(x,
y)11(x,y)(x,SR
+
=
 
m/2 0 S  1 
PrÃ©cision Group  I Typ 2A y)(x,01y)11(x,
y)11(x,y)(x,SP
+
=
 
m/2 0 S  1 
Quadra/ Norm Group  I Typ 2B 22N y)]01(x,y)[11(x,y)]10(x,y)[11(x,
y).11(x,2y)(x,S
+++
= m/2 0 S  1 
Braun Blanquet Group I Typ 2B [ ])y,x(01)y,x(11),y,x(10)y,x(11Max
)y,x(11)y,x(SMin ++=
 
m/2 0 S  1 
Simpson Group I Typ 2B [ ])y,x(01)y,x(11),y,x(10)y,x(11Min
)y,x(11)y,x(SMax ++=
 
m/2 0 S  1 
McConaughey Group I Typ 2B 




	
++
âˆ’
=
y)]01(x,y)y)].[11(x,10(x,y)[11(x,
y)y).01(x,10(x,y)][11(x,y)(x,S
2
McC
 
m/2 -1 S +1 
Sokal- Michen Group II Typ 2B y)01(x,y)10(x,y)00(x,y)11(x,
y)00(x,y)11(x,y)(x,Ssm
+++
+
=
 
m-P/4 0 S  1 
Sokal-Sneath Group II Typ I y)]00(x,y)[11(x,P
y)]00(x,y)2.[11(x,y)(x,Sss ++
+
=
 
m-P/3 0 S  1 
Rogers-Tanim Group II Typ I y)]00(x,y)[11(x,2.P
y)00(x,y)11(x,y)(x,Srt +âˆ’
+
=
 
m-P/6 0 S) 1 
Rao Group II Typ I y)01(x,y)10(x,y)00(x,y)11(x,
y)11(x,y)(x,S r
+++
 
P/2 0 S  1 
Marco/ Mich1 Group II Typ I y)01(x,y)10(x,y)00(x,y)11(x,
y)00(x,y)11(x,
y)(x,S 2
1
mm
+++
+
=
 
2m/3 0 S  1 
Marco/ Mich2 Group II Typ I [ ])y,x(01)y,x(10)y,x(00)y,x(11
)y,x(00)y,x(11
)y,x(S
2
1
2
1
2mm
+++
+
=
 
m/2 0 S  1 
Tetrachorique Group II Typ II 
)]y,x(01)y,x(00)][y,x(10)y,x(00)].[y,x(01)y,x(11)][y,x(10)y,x(11[
)]y,x(01).y,x(10)y,x(00).y,x(11[)y,x(ST
++++
âˆ’
=
 
m/2 -1 S +1 
Yule Y Group II Typ II 
)y,x(01).y,x(10)y,x(00).y,x(11
)y,x(01).y,x(10)y,x(00).y,x(11)y,x(SY
+
âˆ’
=
 
m2/P -1 S +1 
Yule Q Group II Typ II 
)y,x(01).y,x(10)y,x(00).y,x(11
)y,x(10).y,x(01)y,x(00).y,x(11)y,x(SQ
+
âˆ’
=
 
m2/P -1 S +1 
MA4  Ratios Group II Typ II 




	
+
+
+
+
+
+
+
= )y,x(10)y,x(00
)y,x(00
)y,x(01y,x(00
)y,x(00
)y,x(01)y,x(11
)y,x(11
)y,x(10)y,x(11
)y,x(11
4
1)y,x(S 4R
 
m/2 0 S  1 
MG4 Ratios Group II Typ II 44o )y,x(01)y,x(00
)y,x(00
x)y,x(10)y,x(00
)y,x(00
x)y,x(01)y,x(11
)y,x(11
x)y,x(10)y,x(11
)y,x(11)y,x(S
++++
=
 4/mâ‰… 0 S  1 
MH4 Ratios Group II Typ II 





	 +
+
+
+
+
+
+
= )y,x(00
)y,x(01)y,x(00
)y,x(00
)y,x(10)y,x(00
)y,x(11
)y,x(01)y,x(11
)y,x(11
)y,x(10)y,x(11
4
1
)y,x(S
1
4h
 





	
+
p9
341
3
m
 
0 S  1 
Urbani-Buser Group II Typ II 







	
+++
+
=
y)10(x,y)01(x,y)11(x,y)y).00(x,11(x,
y)11(x,y)y).00(x,11(x,y)(x,SBuB
 





	
âˆ’
p4.
354
p
m
 
0 S  1 
Lerman mod Group II Typ III [ ]
[ ][ ]2222
2222
L
y)]01(x,y)[00(x,y)]10(x,y)[11(x,y)]10(x,y)[00(x,y)]01(x,y)[11(x,
y))(x,01y)(x,(10y)(x,00y)(x,11y)(x,S
++++++
+âˆ’+
=
 
m/2    -1 S+1 
Kappa-Cohen Group II Typ III 
y)]01(x,y)P[10(x,y)]01(x,y)10(x,y)00(x,y)2[11(x,
y)]01(x,y),(P/2)[10(xy)]01(x,y)10(x,y)00(x,y)2[11(x,
 y)(x,S
++âˆ’
++âˆ’
=
 
m/2 0S 1 
RNTI-A-3 - 302 -
                                                                                                    F. Marcotorchino 
5. Liaison Â« Indices de SimilaritÃ© Â» - Â« CritÃ¨res de Contin-
gence Â», vers un bouclage du processus typologique 
De mÃªme que nous avions utilisÃ© au Â§4.4.5, les expressions de certains critÃ¨res ou coeffi-
cients de contingence pour retrouver ou dÃ©finir de nouveaux indices de similaritÃ© (par 
exemple lâ€™indice de similaritÃ© de Â« Lerman modifiÃ© Â»), nous allons tenter lâ€™inverse dans ce 
paragraphe en  partant de la notion de codage vectoriel de matrices relationnelles tel que 
nous lâ€™avons introduit au Â§ 2.4.4 .  
En dâ€™autres termes, et pour boucler la boucle, nous allons nous servir des dÃ©finitions 
dâ€™indices de similaritÃ© sur vecteurs binaires, pour retrouver ou Ã©ventuellement redÃ©couvrir 
des coefficients dâ€™association sur tableaux de contingence au sens statistique usuel. Rappe-
lons que le codage vectoriel de matrices relationnelles se dÃ©finit selon le principe : 
Pour toute matrice relationnelle Ck, on   dÃ©finit  son Extension Vectorielle Î³k comme un 
vecteur de longueur N2   tel que :  
),....,...,,( k
N
k
s
k
3
k
2
k
1
k
2=

,  oÃ¹ si k
'iiC  est le terme gÃ©nÃ©ral de la matrice C
k
, alors : 
 
k
s
k
ii' C = ,  si et seulement si  lâ€™indice courant Â« s Â» vÃ©rifie:   
                                          i'et    i        'iN)1i(s âˆ€+âˆ’=   
Partant de ce principe en posant : 
),....,...,,( k
N
k
s
k
3
k
2
k
1
k
2=

 et ),....,...,,( k'Nk'sk'3k'2k'1k' 2=

 
On peut utiliser,  comme pour nâ€™importe quel tableau binaire, la prÃ©sentation des donnÃ©es 
sous forme dâ€™un tableau de contingence Tetrachorique , en remplaÃ§ant x et y par k  et 
k' , il vient : 
 
 
 
 
 k'  = 1 k'  = 0 
k = 1 11( k , k' ) 10( k , k' ) 
k = 0 01( k , k' ) 00( k , k' ) 
RNTI-A-3- 303 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
 
De ce fait, certains des indices de similaritÃ© dÃ©finis prÃ©cÃ©demment peuvent Ãªtre utilisÃ©s 
comme indices sur les linÃ©arisations vectorielles  relationnelles, une fois retraduites en 
termes des Ã©galitÃ©s : kskii' C =  . Donnons quelques exemples, choisis  parmi les indices les 
plus connus:  
5.1 Indices du Groupe  I  
5.1.1 Indice de Dice (Morey-Agresti) 
Lâ€™indice de Dice dÃ©fini par : 
[ ] y)01(x,y)10(x,y)2.11(x,
y)2.11(x,
y)01(x,y)10(x,
2
1y)11(x,
y)11(x,y)(x,Sd
++
=
++
=
 se transforme dans cette configura-
tion en : 
[ ] 

= == =
= =
+
=
Î³Î³+Î³Î³+Î³Î³
Î³Î³
=Î³Î³ N
1i
N
1'i
'k
'ii
N
1i
N
1'i
k
'ii
N
1i
N
1i'
'k
'ii
k
ii'
'kk'kkk'k
'kk
'kk
d
CC
CC2.
),01(),10(
2
1),11(
),11(),(S
 
et du fait des liaisons entre â€œexpressions relationnellesâ€ et â€œnotations contingentiellesâ€ (voir 
F. Marcotorchino (1984)), on peut  dans ce cas rÃ©Ã©crire lâ€™indice de Dice,  (sous rÃ©serve que 
Ck et Ckâ€™ reprÃ©sentent des variables nominales ayant respectivement â€œpâ€ et â€œqâ€ modalitÃ©s) sous 
forme dâ€™un coefficient de contingence: 
(f112)                  
 



= =
= =
= == =
= =
+
=
+
=Î³Î³ p
1u
q
1v
2
v.
2
.u
p
1u
q
1v
2
vu
N
1i
N
1'i
'k
'ii
N
1i
N
1'i
k
'ii
N
1i
N
1i'
'k
'ii
k
ii'
'kk
d
nn
n2
CC
CC2.
),(S
 
On retrouve dans ce cas un indice de contingence connu sous le nom de Morey-Agresti , 
dâ€™oÃ¹:     
Indice de Dice (sur matrice relationnelle vectorielle)  Coefficient  dâ€™association de Morey-
Agresti (sur tableau de contingence) 
 
5.1.2 Indice dâ€™OchiaÃ¯ (Fowlkes-Mallows) 
De la mÃªme faÃ§on que dans le cas de lâ€™Indice de Dice, lâ€™indice dâ€™OchiaÃ¯ appliquÃ© au tableau 
Tetrachorique prÃ©cÃ©dent nous redonne un Coefficient de contingence connu. En effet nous 
avons vu que lâ€™indice dâ€™OchiaÃ¯ Ã©tait dÃ©fini par :   
 
                                
)]y,x(01)y,x(11)][(y,x(10)y,x(11[
)y,x(11)y,x(So
++
=
 
 
 
Soit aprÃ¨s remplacement de x et y par k et kâ€™: 
RNTI-A-3 - 304 -
                                                                                                    F. Marcotorchino 
Il vient alors: 
            


= == =
= =
=
Î³Î³+Î³Î³Î³Î³+Î³Î³
Î³Î³
=Î³Î³
N
1i
N
1'i
'k
'ii
N
1i
N
1'i
k
'ii
N
1i
N
1i'
'k
'ii
k
ii'
'kk'kk'kkk'k
'kk
'kk
o
CC
CC.
),(01),(11),(10),11(
),11(),(S
 
et de faÃ§on identique au cas de lâ€™indice de Dice, en utilisant Ã©galement les liaisons entre 
â€œexpressions relationnellesâ€ et â€œnotations contingentiellesâ€ (voir F. Marcotorchino (1984)), 
on peut  dans ce cas rÃ©Ã©crire lâ€™indice dâ€™OchiaÃ¯,  (sous rÃ©serve que Ck et Ckâ€™ reprÃ©sentent des 
variables nominales ayant respectivement â€œpâ€ et â€œqâ€ modalitÃ©s) sous forme dâ€™un coefficient 
de contingence: 
(f113)                      




==
= =
= == =
= =
==Î³Î³
q
1u
2
v.
p
1u
2
.u
p
1u
q
1v
2
vu
N
1i
N
1'i
'k
'ii
N
1i
N
1'i
k
'ii
N
1i
N
1i'
'k
'ii
k
ii'
'kk
o
nn
n
CC
CC.
),(S
 
Quiconque , familier des statistiques contingentielle peut reconnaÃ®tre dans la formule (f113) 
lâ€™expression du Coefficient de Contingence de Fowlkes et Mallows  (voir Fowlkes et Ma-
llows(1983)). On trouvera Ã©galement  une Ã©tude dÃ©taillÃ©e de ce critÃ¨re  et les bornes qui lui 
sont associÃ©es dans la thÃ¨se de H. Messatfa (1989) . 
 
Indice dâ€™OchiaÃ¯ (sur matrice relationnelle vectorielle)  Coefficient  dâ€™association de 
Fowlkes et Mallows (sur tableau de contingence) 
 
 
5.1.3 Indice de Kulczynski (Hubert, Arabie) 
Nous avons vu au Â§  4.2.1.1, que lâ€™indice de Kulczynski Ã©tait donnÃ© par :  
 





	
+
+
+
= )y,x(01)y,x(11
)y,x(11
)y,x(10)y,x(11
)y,x(11
2
1)y,x(S k
 
En appliquant le mÃªme raisonnement que pour les indices de Dice et OchiaÃ¯ , on obtient le 
rÃ©sultat suivant:  
[ ] [ ]











	
+=




	
Î³Î³+Î³Î³
Î³Î³
+
Î³Î³+Î³Î³
Î³Î³
=Î³Î³


= == =
= =
N
1i
N
1'i
'k
'ii
N
1i
N
1'i
k
'ii
N
1i
N
1i'
'k
'ii
k
ii'
'kk'kk
'kk
'kk'kk
'kk
'kk
k
C
1
C
1
2
CC
),(01),(11
),(11
),10(),(11
),11(
2
1),(S
 
soit en notations contingentielles et  en appliquant toujours les  remarques et restrictions  
dÃ©finies pour Dice et OchiaÃ¯: 
(f114)

 
 
 
 



= =
= =
= =
= = ==
= = =
= =
= == =
= =











	
+
=
+
=











	
+=Î³Î³
p
1u
q
1v
p
1u
q
1v
2
v.
2
.u
p
1u
q
1v
2
v.
2
.u
2
uvN
1i
N
1i
N
1'i
'k
'ii
k
'ii
N
1'i
N
1i
N
'i
N
1i
N
1'i
'k
'ii
k
'iiN
1i
N
1'i
'k
'ii
k
'iiN
1i
N
1'i
'k
'ii
N
1i
N
1'i
k
'ii
N
1i
N
1i'
'k
'ii
k
ii'
'kk
k
nn2
nn
n
CC2
CC
CC
C
1
C
1
2
CC
),(S
 
RNTI-A-3- 305 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
En fait les indices  ),(S 'kkd Î³Î³ , ),(S 'kko Î³Î³ , ),(S 'kkk Î³Î³  possÃ¨dent le mÃªme numÃ©rateur 

= == =
=
p
1u
q
1v
2
uv
'k
'ii
N
1i
N
1'i
k
'ii nCC et ne diffÃ©rent que par leurs dÃ©nominateurs qui jouent le rÃ´le de 
borne supÃ©rieure pour le numÃ©rateur. Les dÃ©nominateurs respectifs sont: la moyenne 
ArithmÃ©tique, la moyenne GÃ©omÃ©trique, et la moyenne Harmonique  des quantitÃ©s 
 
= =
p
1u
q
1v
2
v.
2
.u netn , qui jouent effectivement le rÃ´le de bornes de variation pour le numÃ©ra-
teur. Ceci a Ã©tÃ© Ã©tudiÃ© pour lâ€™ensemble de ces trois critÃ¨res par L. Hubert et P.Arabie 
(1985), par A. Agresti et L. Morey (1984) ainsi que par H. Messatfa  (1989).  
Ces trois critÃ¨res sont donc connus, le premier a Ã©tÃ© Ã©tudiÃ© par Agresti et Morey , le second a 
Ã©tÃ© Ã©tudiÃ© par Fowlkes et Mallows qui lui ont donnÃ© leurs noms, le dernier a Ã©tÃ© Ã©tudiÃ© par 
L.Hubert et P. Arabie ainsi par H.  Messatfa qui a fait  une Ã©tude comparative dâ€™autres bornes 
possibles au dÃ©nominateur, en plus des trois prÃ©cÃ©dentes.   
 
 
5.2 Indices du Groupe II  
5.2.1 Indice de Sokal et Michener et Green Rao  (Condorcet, Rand) 
Lâ€™indice de Sokal et Michener est dÃ©fini au Â§ 4.4.1.1 par : 
)y,x(01)y,x(10)y,x(00)y,x(11
)y,x(00)y,x(11
P
)y,x(00)y,x(11)y,x(Ssm
+++
+
=
+
=
 
il se transforme dans la  configuration en notations relationnelle vectorielles selon 
lâ€™expression  suivante: 
[ ] 2
N
1i
N
1i'
N
1i
N
1'i
'k
'ii
k
'ii
'k
'ii
k
ii'
'kk'kk'kkk'k
'kk'kk
'kk
sm N
CCCC
),01(),10(),(00),11(
),00(),11(),(S





	
+
=
Î³Î³+Î³Î³+Î³Î³+Î³Î³
Î³Î³+Î³Î³
=Î³Î³
 
= = = =  
ceci du fait des liaisons entre â€œexpressions relationnellesâ€ et â€œprofils vectorielsâ€. On recon-
naÃ®t dans le numÃ©rateur de lâ€™expression relationnelle prÃ©sentÃ©e Ã  droite de lâ€™indice de Sokal 
et Michener, la forme symÃ©trique du critÃ¨re de Condorcet valable pour le croisement entre 
deux variables qualitatives.  
De plus sous rÃ©serve que Ck et Ckâ€™ reprÃ©sentent des variables nominales ayant respectivement 
â€œpâ€ et â€œqâ€ modalitÃ©s et en utilisant les formules de passage relations contingences  (voir 
encore F. Marcotorchino (1984), on obtient la formule contingentielle suivante (en identifiant 
les notations  N et n
.. 
): 
(f115)  
2
..
p
1u
q
1v
p
1u
q
1v
2
..
2
v.
2
.u
2
uv
2
N
1i
N
1i'
N
1i
N
1'i
'k
'ii
k
'ii
'k
'ii
k
ii'
'kk
sm
n
nnnn2
N
CCCC
),(S
   
= = = == = = =
+âˆ’âˆ’
=





	
+
=Î³Î³    
On reconnaÃ®t dans lâ€™expression Ã  droite ci dessus, lâ€™une des formes possibles du critÃ¨re de 
Rand , W. Rand (1971) , en tout cas celle Ã©tudiÃ©e par F. Marcotorchino  (1984) . 
En conclusion lâ€™indice de similaritÃ© de  Sokal et Michener nous permet de retrouver en con-
sÃ©cution et dans la foulÃ©e le Coefficient de Condorcet (approche relationnelle) et celui de 
Rand (approche contingentielle).               
RNTI-A-3 - 306 -
                                                                                                    F. Marcotorchino 
 
5.2.2 Indice de SimilaritÃ© Tetrachorique (ou de Bravais â€“Pearson) (Lerman)  
De mÃªme que dans le cas de lâ€™Indice de Sokal et Michener, intÃ©ressons nous maintenant Ã  un 
autre indice de similaritÃ© du Groupe II (en lâ€™occurrence du Type II) , Ã  savoir lâ€™indice Â« Te-
trachorique Â» donnÃ©  (page 55) par :  
 
)]y,x(01)y,x(00)][y,x(10)y,x(00)].[y,x(01)y,x(11)][y,x(10)y,x(11[
)]y,x(01).y,x(10)y,x(00).y,x(11[)y,x(ST
++++
âˆ’
=
 
 
Soit en  remplaÃ§ant x et y par k et kâ€™: 
),(01),(00),(10),(00),(01),(11),(10),11(
),(01),(10),).00(,11(),(S
'kk'kk'kk'kk'kk'kk'kkk'k
'kk'kk'kk'kk
'kk
T
Î³Î³+Î³Î³Î³Î³+Î³Î³Î³Î³+Î³Î³Î³Î³+Î³Î³
Î³Î³Î³Î³âˆ’Î³Î³Î³Î³
=Î³Î³
 
en utilisant Ã©galement les liaisons entre â€œexpressions vectorielles relationnellesâ€ et â€œnotations 
relationnelles  (voir Â§2.4.4), on peut  dans ce cas rÃ©Ã©crire lâ€™indice TÃ©trachorique ou de Bra-
vais Pearson  sous forme de lâ€™expression suivante: 
                    

   
= == == == =
= = = = = = = =
âˆ’
=Î³Î³
N
1i
N
1'i
'k
'ii
N
1i
N
1'i
k
'ii
N
1i
N
1'i
'k
'ii
N
1i
N
1'i
k
'ii
N
1i
N
1i'
N
1i
N
1'i
N
1i
N
1'i
N
1i
N
1'i
'k
'ii
k
'ii
'k
'ii
k
'ii
'k
'ii
k
'ii
'k
'ii
k
ii'
'kk
T
CCCC
CCCCCC.CC.
),(S
 
En utilisant maintenant les formules de passages contingence<=> relations (voir F. Marco-
torchino  (1984) ) nous allons transformer lâ€™expression de lâ€™indice ci dessus en une forme 
contingentielle, on obtient aprÃ¨s dÃ©veloppements et simplifications (aprÃ¨s identification des 
notations  N et n
..
):  
 
(f116)           

 
====
=== =
âˆ’âˆ’
âˆ’
=Î³Î³
q
1v
2
v.
2
..
p
1u
2
.u
2
..
q
1v
2
v.
p
1u
2
.u
q
1v
2
v.
p
1u
2
.u
p
1u
q
1v
2
uv
2
..
'kk
T
nnnnnn
nnnn
),(S
 
 
Si nous divisons le numÃ©rateur et le dÃ©nominateur de la formule prÃ©cÃ©dente par n
..
,
 il est 
intÃ©ressant de constater que  lâ€™expression donnÃ©e par la formule (f116) est strictement Ã©qui-
valente Ã  la formule (f97) caractÃ©risant le coefficient de contingence de IC Lerman. Ici il 
apparaÃ®t bien que la boucle est bien bouclÃ©e, lâ€™utilisation des tableaux de contingence et des 
coefficients nous avait permis de dÃ©boucher sur un indice de similaritÃ© nouveau : lâ€™indice de  
similaritÃ© de Â« Lerman modifiÃ© Â». Le passage par les notations Â« relationnelles vectorielles en 
extension Â» nous permet rÃ©ciproquement  de retrouver le coefficient de contingence de 
Lerman comme un cas dâ€™illustration contingentielle du coefficient de similaritÃ© Tetracho-
rique ou de Bravais Pearson.   
Attention, câ€™est bien par un Â« jeu dâ€™Ã©critures Â»  que nous avons obtenu cette Ã©quivalence,  car 
nous avions vu que lâ€™indice L(x,y) Ã©tait Ã©gal au produit ST(x,y)SL(x,y),  nous ne dÃ©montrons 
pas ici que lâ€™Ã©galitÃ© ST(x,y)=L(x,y) est vraie, mais que dans lâ€™Â« espace  relationnel Â» 
lâ€™Ã©quivalence des formules existe.    
 
RNTI-A-3- 307 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
Ce que nous venons dâ€™obtenir pour quelques  indices de similaritÃ© nous permettant de redÃ©-
couvrir des coefficients de contingence connus ou moins connus, pourrait Ãªtre gÃ©nÃ©ralisÃ© Ã  
lâ€™ensemble des indices de similaritÃ© prÃ©sentÃ©s dans ce travail, nous laissons le soin au lecteur 
de voir (Ã   titre dâ€™exercice ) si certains indices ainsi listÃ©s auraient des formes contingentielles 
intÃ©ressantes ou originales ? 
 
 
 
RNTI-A-3 - 308 -
                                                                                                    F. Marcotorchino 
6. Conclusion sur les Indices de SimilaritÃ©s et leur Usage 
    Comme nous venons de le voir , nous avons  passÃ© en revue plus dâ€™une  trentaine dâ€™indices 
de similaritÃ©s diffÃ©rents (auxquels on peut ajouter ceux issus de la dÃ©finition des restrictions 
binaires des Â« indices dâ€™abondance Â»). Nous en  avons prÃ©sentÃ© plus de 35 et listÃ© 28 des 
principaux,  certains de ces indices sont dâ€™usage courant,  dâ€™autres sont plus Ã©sotÃ©riques, mais 
ils existent en tant que tels et peuvent  donc Ãªtre utilisÃ©s dans des conditions particuliÃ¨res.  
Comme nous lâ€™avons vu Ã©galement un certain nombre dâ€™entre eux ont Ã©tÃ© dÃ©finis soit explici-
tement , soit historiquement,  soit par lâ€™usage.  
Ainsi les indices de Dice, de Jaccard, de SÃ¸rensen, dâ€™Anderberg, de Rogers-Tanimoto, de 
Sokal et Sneath, de Sokal et Michener, de Simpson,   de Braun-Blanquet, dâ€™Ochiai, de Yule, 
dâ€™ Urbani-Baroni-Buser, de Kulczinski, de Mac Connaughey , de Russel-Rao,  ont Ã©tÃ© intro-
duits directement par ces auteurs, pour des usages qui se rapportaient Ã  leurs besoins. A ce 
propos un nombre important des indices citÃ©s ont Ã©tÃ© reinventÃ©s au fil du temps, aprÃ¨s la 
dÃ©couverte initiale,  par des spÃ©cialistes de disciplines diffÃ©rentes (voir Ã  ce propos la note de 
bas de page nÂ°8). Nous avons tentÃ© dans cet article dâ€™attribuer  aux indices  le nom de 
lâ€™Â« inventeur Â» le plus Â« ancien Â» ou le plus sÃ»r . Par ailleurs nous avons vu quâ€™il y a une 
deuxiÃ¨me classe dâ€™indices, ceux  qui nâ€™ont pas Ã©tÃ© introduits de faÃ§on directe,  mais qui lâ€™ont 
Ã©tÃ©  Ã  la suite de raisonnements ou de dÃ©ductions.  
Ainsi en construisant  des indices dâ€™association Ã  partir de  tableaux de contingence (2x2) 
avons nous retrouvÃ© en fin de calculs, soit des indices, dÃ©jÃ  introduits par  ailleurs, soit des 
indices originaux comme le sont  par exemple les indices dÃ©rivÃ©s  du Coefficient de Lerman 
ou  du coefficient de Goodman Kruskal, soit  enfin nous en avons obtenus par  dÃ©duction par 
rapport Ã  des propriÃ©trÃ©s mathÃ©matiques gÃ©nÃ©rales (exemple : Indices dâ€™Hadamard) . Ils 
nâ€™Ã©taient, Ã  ma connaissance  pas connus des utilisateurs dâ€™indices classiques (ce qui prouve 
quâ€™il y a de la place pour en trouver de nouveaux). Les indices bÃ¢tis autour des  Â« 4 ratios Â» 
(Ã  partir de lâ€™idÃ©e originale dâ€™Anderberg) ne sont pas, eux aussi, trÃ¨s connus, et trÃ¨s pratiquÃ©s.  
Pour sâ€™Ã©loigner des pistes usuelles des approches comme celle de Tversky sont intÃ©ressantes,   
au sens  quâ€™elle a permis dâ€™introduire de nouvelles familles dâ€™indices Ã  la suite de raisonne-
ments dâ€™ordre logique, mÃªme si les indices les plus connus de cette famille dâ€™indices 
Â« Tverskiens Â» sont les indices de Rappel et de PrÃ©cision (qui ne sont  rien dâ€™autre au fond ,  
suivant le cas,  que lâ€™indice de Simpson ou lâ€™indice de Braun â€“Blanquet). Cette approche 
fondÃ©e sur le raisonnement logique  nous avait Ã©galement permis dâ€™introduire Ã  la suite dâ€™un 
travail sur les  bornes Â« Ã  la majoritÃ© Â» de ces indices, les indices auxquels nous avons donnÃ© 
notre nom. Enfin une place particuliÃ¨re doit Ãªtre faite Ã  lâ€™indice que nous avons appellÃ© in-
dice Tetrachorique, au sens quâ€™il est au centre des convergences  des  calculs effectuÃ©s sur les 
4 quantitÃ©s du tableau de contingence du mÃªme nom.  
Dâ€™un point de vue pratique le lecteur de cet article, serait sans doute soucieux,  tout au moins 
nous le pensons,  dâ€™avoir   une clÃ© de lecture lui permettant de savoir quels sont les Â« bons 
indices de similaritÃ©s Â», en dâ€™autres termes de faire une selection des meilleurs dâ€™entre eux, 
pour un usage gÃ©nÃ©raliste.  
 Câ€™est exactement ce que nous  proposons ci aprÃ¨s.  
 
 
 
 
RNTI-A-3- 309 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
Liste dâ€™ Â« Indices Candidats Â» comme Indices validÃ©s dâ€™usage courant   
 
 Avant tout il convient de se donner des critÃ¨res permettant de dÃ©finir ce quâ€™est un Â« bon Â» 
indice.  En voici une liste possible, hiÃ©rarchisÃ©e, correspondant aux cas dâ€™usage les plus clas-
siques, dâ€™autres pourraient Ã©galement convenir dans certaines configurations particuliÃ¨res 
dâ€™utilisation ou de domaines dâ€™application : 
1. Un Â« bon Â» indice se devra de varier de 0 Ã  1 (ou du moins de valoir 1 pour 
S(x,x) ) (autosimilaritÃ© maximale Â« normÃ©e Â») 
2. Un Â« bon Â» indice devra vÃ©rifier  une borne de Solomon Fortier Ã©gale Ã  Â« m/2 Â»   
pour 11(x,y), en cas de disjonction complÃ¨te 
3. Un Â« bon Â» indice devra vÃ©rifier si possible la TransitivitÃ© Indicielle GÃ©nÃ©rali-
sÃ©e, ce qui signifie que la dissimilaritÃ© associÃ©e pourra Ãªtre  une Â« distance Â» et 
dans le cas Â« favorable Â» une  distance  euclidienne  
4. Un Â« bon Â» indice se doit dâ€™avoir une structure de calcul linÃ©aire  des valeurs 
du numÃ©rateur  et du dÃ©nominateur de lâ€™indice faisant jouer un rÃ´le aux quanti-
tÃ©s : 11(x,y), 01(x,y), 10(x,y) et 00 (x,y). ceci du fait que sinon les calculs gÃ©nÃ©rÃ©s 
sont gÃ©nants et coÃ»teux pour les applications induites.  
 
Par rapport Ã  cette liste hierarchisÃ©e, nous voyons que pour les Indices du Groupe I :  ceux 
de  Â« Dice Â»,  et dâ€™Â« Ochiai Â»,    qui satisfont aux quatre exigeances : 1, 2, 3 , 4 ,  sont donc 
les indices ayant le spectre le plus gÃ©nÃ©ral, quâ€™il faut  choisir en prioritÃ©. On choisira ensuite 
les indices de Jaccard  (1,3,4) et de Kulcsinsky (1,2,4) qui ne vÃ©rifient que 3 des propriÃ©tÃ©s 
prÃ©cÃ©dentes  Puis suivant lâ€™usage  qui peut en Ãªtre fait,  les indices de Â« Rappel Â» et de 
Â« PrÃ©cision Â» (ou indices de Simpson & Braun Blanquet) qui  sont incontournables dans le 
domaine du Text Mining , ou du moins dans le domaine de la recherche documentaire.  
  
On peut rajouter Ã  cette liste pour les  Indices du Groupe II : les indices suivants : lâ€™indice  
Â« Tetrachorique affine Â» (câ€™est Ã  dire la forme ramenÃ©e Ã  varier de 0 Ã  1 de cet indice) qui 
vÃ©rifie les points 1 et 2 , lâ€™indice de Â« Marcotorchino-Michaud2 Â»  (qui vÃ©rifie les condi-
tions 1, 2, 4),  de mÃªme pour lâ€™indice de Moyenne ArithmÃ©tique des 4 ratios dâ€™Anderberg 
(qui  vÃ©rifie  les conditions 1,  2 et  4  Ã©galement) . On rajoutera dans la mesure oÃ¹  lâ€™usage 
des configurations  00(x,y) sâ€™impose, le coefficient de  Sokal et Michener   (puisquâ€™il est une 
variante du critÃ¨re de Rand ou de Condorcet) . 
 
Dâ€™une faÃ§on plus prÃ©cise,  lâ€™utilisation et le choix dâ€™un indice peut dÃ©pendre dâ€™habitudes ou 
de normes dâ€™usage, ainsi nous avons vu quâ€™en Â« chimie molÃ©culaire Â» un certain nombre 
dâ€™indices sont souvent proposÃ©s et utilisÃ©s,  qui ne le sont par aucune autre communautÃ© 
scientifique (par exemple lâ€™indice de Mac Caunnaughey, citÃ© dans N. Jeliazkova (JN2007) 
qui est    quasiment inconnu des autres domaines dâ€™usage ).  
On voit Ã©galement que mÃªme au niveau du vocabulaire,   lâ€™usage dâ€™une communautÃ© fait 
souvent rÃ©fÃ©rence Ã  un nom dâ€™indice,  pour un usage appropriÃ©,  sans se poser la question de 
sa signification en dehors de ses propres normes. A  ce propos les remarques intÃ©ressantes 
sur lâ€™Indice de Simpson ou (de celui de Braun Blanquet)  dans   Bradshaw (1997) et Boyce et 
Ellison ( 2001) caractÃ©risant leur usage auprÃ¨s de la communautÃ© des chimistes molÃ©culaires 
est Ã  comparer aux rÃ´les jouÃ©s par les indices de Â« Rappel Â» et de Â« PrÃ©cision Â» auprÃ¨s de la 
communautÃ© des spÃ©cialistes du Traitement des langues (TAL) Parfois, on aboutit Ã  des 
RNTI-A-3 - 310 -
                                                                                                    F. Marcotorchino 
redÃ©couvertes ou Ã  des impressions de complexitÃ© apparente qui nâ€™existent pas,  en fait,   si 
lâ€™on revient Ã  lâ€™expression originelle dâ€™une mesure de similaritÃ© et bien entendu si lâ€™on sait Ã  
quelle filiation elle appartient. Ainsi dans un ouvrage trÃ¨s rÃ©cent (2008), et fort intÃ©ressant 
par ailleurs, intitulÃ© Â« Classification SupervisÃ©e de Documents Â» (2008)(Ã©ditions Hermes-
Lavoisier),  lâ€™auteur,  J. Beney  fait une digression  de trois pages sur les propriÃ©tÃ©s de la 
Fonction F(Î³) (Â« dite Fonction F Â», fonction non triviale du Rappel et de la PrÃ©cision, chÃ¨re 
aux tenants des Â« mÃ©triques Â» et des Ã©valuations dans le domaine du TAL), alors que cette 
fonction, mÃªme utile, nâ€™est que partielle et reprend des indices connus et trÃ¨s anciens (Dice 
ou  Ochiai .. Kulczinski etc..) amplement Ã©tudiÃ©s et validÃ©s par dâ€™autres19.  Ce qui est dit ici Ã  
propos des communautÃ©s du TAL ou de la Chimie MolÃ©culaire aurait pu Ãªtre Ã©tendu tout 
aussi bien aux communautÃ©s de la zoologie, de la biomÃ©trie, de la phylogÃ©nie, de la phytoso-
ciologie  etcâ€¦ 
Il existe encore beaucoup de choses Ã  dire sur les Indices de SimilaritÃ©, nous arrÃªtons ici ce 
long descriptif , mais dâ€™autres analyses complÃ©mentaires et exhaustives seraient encore 
utiles. A titre dâ€™exemple, les rÃ©flexions autour dâ€™approches logiques simples ou logiques 
floues,  telles que celles proposÃ©es par lâ€™Ã©quipe de B. Bouchon-Meunier  du LIP6, quâ€™on 
pourra consulter  dans Bouchon Meunier-Marsala (2003) et (2000) ainsi que dans  Lesot, 
Rifqi, Benhadda (2009), dâ€™une part,  ou des approches jouant sur la pondÃ©ration de  lâ€™ordre 
dâ€™apparition des Â« matchings Â»,  comme celles exposÃ©es  dans les articles de C. Michel 
(2001) ou L. Egghe (2006), dâ€™autre part, permettraient dâ€™organiser les familles dâ€™indices 
suivant des axes de nature, certes diffÃ©rente,  mais  de fait  complÃ©mentaire  Ã  celle dont la 
structure  a Ã©tÃ© proposÃ©e dans ce texte.  
 
 
 
 
 
 
7. RÃ©fÃ©rences 
Anderberg M.(1973) :  Â« Cluster Analysis for Applications Â», Book nÂ°19, Probability and 
Statistics Series, Academic Press, New-York, 
Agresti A., Morey L (1984).: Â« An adjustment of the Randâ€™s Statistic for chance agreement Â», 
Journal of Educational and Psychological Measurement, Vol44, pp.33-37, 
 Ah-Pine J. (2007): Â« Sur les Aspects AlgÃ©briques et Combinatoires de lâ€™Analyse Relation-
nelle Â», ThÃ¨se de lâ€™UniversitÃ© Paris VI, (2007) 
Arabie P. , Hubert L.(1985) :Â« Comparing Partitions Â», Proceedings of the Fourth European 
Meeting of the Classifications Societies, Cambridge,  
                                                 
19
 Ainsi F(1)= Indice de Dice , F(0)= Indice de PrÃ©cision,, F(âˆ)= Indice de Rappel . Ok tout Ã§Ã  existe dÃ©jÃ  ,  mais 
quid des autres fonctions Ã©videntes de R et P appartenant au Groupe I Type II  (comme lâ€™indice dâ€™Ochiai ( qui est 
limite du ChiÂ²de contingence), oÃ¹ lâ€™indice de Tversky),  pourquoi les gens du TAL ne les considÃ¨rent-ils pas  et ont-
ils privilÃ©giÃ© la fonction F ?.  
RNTI-A-3- 311 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
Benhadda H. (1998) : Â« La SimilaritÃ© RÃ©gularisÃ©e et ses applications en Classification auto-
matique Â», ThÃ¨se de lâ€™UniversitÃ© Paris VI,   
Baulieu F. B. (1989) : Â«A classification of presence/absence based dissimilarity coeffi-
cientsÂ», Journal of Classification, Vol. 6,, pp. 233-246,Springer-Verlag, New York, Ber-
lin, Braun â€“Blanquet J. (1932) : Â« Plant Sociology, the Study of Hart Communities Â» 
Livre, Mac-Graw Hill, New York,   
Benavent  C. (2001): Â« Analyse des ProximitÃ©s Â», Rapport de lâ€™IAE des Pays de lâ€™Adour, 17 
pages,  disponible sur le site :christophe.benavent @free.fr  
Beney J. (2008):  Â« Classification SupervisÃ©e de Documents Â», livre publiÃ© aux Ã©ditions 
Hermes-Lavoisier),   
Bisson  G. (2000): Â« La similaritÃ©: une notion symbolique/numÃ©rique Â». Livre : Apprentis-
sage symbolique-numÃ©rique (tome 2). Eds Moulet Brito. Editions CAPADUES, 
Bradshaw J. (1997) : Â« Introduction to Tversky similarity measureÂ», Proceedings of MUG 
'97 - 11th Annual Daylight User Group Meeting   FÃ©vrier 1997, 
Brunchwicg L. (1921) : Â«Les Etapes de la Philosophie MathÃ©matique Â» , Livre, A. Blanchard 
Editeur, (nouvelle Edition 1981), ancienne Ã©dition 1921, 
Benhadda H.,  Marcotorchino F.(1998) : Â« Introduction Ã  la SimilaritÃ© RÃ©gularisÃ©e Â», Revue 
de Statistique AppliquÃ©e, nÂ°56,  pp. 45-69,, Dunod, Paris,  
Bouchon-Meunier B., Marsala C. (2003) : Â« Logique floue, principes, aide Ã  la dÃ©cision Â», 
livre Collection Information-Commande-Communication, Hermes-Lavoisier Editeurs , 
Paris,  
Boyce R. L., Ellison P. C.(2001): Â« Choosing the Best Similarity Index When Performing 
Fuzzy Set Ordination on Binary DataÂ»,  Journal of Vegetation Science, Vol. 12, No. 5 pp. 
711-720, 
Baroni-Urbani C., Buser M.W. (1976) : Â« Similarity of binary data Â», Journal of Syst. Zool. 
nÂ° 24 , pp: 165-178.,  
Burnaby T.P. (1970): Â«On a method for character weighting similarly coefficient, employing 
the concept of information Â»,  Journal of  Math. Geology., Vol. 2, nÂ° 1,  pp. 25-38, Car-
nap  R. (1928) : Â« Der Logische Aufbau der Welt Â», Weltkreis Verlag , Berlin , 
Caillez F., Pages J.P. (1976): : Â«Introduction Ã  lâ€™Analyse des DonnÃ©es Â», Publications de 
lâ€™ASU et du BURO, Ã©diteur la SMASH,  
Cohen J. (1960) : Â«A coefficient of agreement for nominal scales Â», Educational and Psycho-
logical Measurement Journal, Vol 20, pp37-46,  
Chandon J.L., Pinson S. (1981) : Â«  Analyse Typologique : ThÃ©orie et Applications Â», Mas-
son, Paris,  
Decaestecker C. (1992): Â« Apprentissage en Classification Conceptuelle IncrÃ©mentale Â» , 
ThÃ¨se de lâ€™UniversitÃ© Libre de Bruxelles (FacultÃ© des Sciences),  
Dice L.R. (1945): Â« Measures of the amount of ecological association between species Â», 
Ecology Journal, Vol 26, pp.297-302,   
RNTI-A-3 - 312 -
                                                                                                    F. Marcotorchino 
Deheuvels P., Marcotorchino F. (2000) : Â« Statistique et Informatique, la Nouvelle Conver-
gence Â», Revue RST de lâ€™AcadÃ©mie des Sciences  nÂ°8, Juillet  TECD , 
Driver, H. E., et Kroeber, A. L.(1932) : Â«Quantitative expression of cultural relationshipÂ». 
The University of California Publications in American Archaeologyand Ethnology, 31, 
211-256, 
Egghe L. , Rousseau R (2006).: Â«Classical retrieval and overlap measures satisfy the re-
quirements for rankings based on a Lorenz curveÂ» , in  Information Processing & Man-
agement, Vol 42, Issue 1, pp.106-120,  
Fleiss J.L.(1975): Â« Measuring Agreement between two judges in the presence or absence of 
a TraitÂ», Biometrics, NÂ°31, pp 651-659,  
Fowlkes E.B., Mallows J. (1983) : Â« A method for comparing two hierarchical clusteringsÂ», 
JASA (Journal of the American Statistical Association ), Vol 78, pp.553-584, 
Goodall  D.W.: (1966) Â« A new Similarity Index based on ProbabilityÂ» , Biometrics, nÂ° 22,  
pp. 882- 907,  
Goodman L.A., Kruskal W.H. (1979) : Â« Measures of Association for Cross Classification Â», 
Book by Springer Verlag , Berlin, New-York, 
Gower  J.C. (1966): Â« Some distance properties of latent root and vector methods used in 
multivariate analysisÂ», Biometrika, nÂ°53, pp:325-338,  
Gower  J.C. (1971): Â« A General Coefficient of Similarity and some of its PropertiesÂ», Jour-
nal of Biometrics, nÂ°27, pp:857-874,  
Gower J., Legendre P. (1986) : Â« Metric and Euclidean properties of dissimilarity coeffi-
cientsÂ», Journal of Classification,  NÂ°3, pp.5-48, North Holland,  
GrÃ¶tschel M., JÃ¼nger M., Reinelt G. (1982) : Â« A Cutting Plane Algorithm for the Linear 
Ordering ProblemÂ», Research Report  NÂ°82219 Operations Research, UniversitÃ¤t zu 
Bonn, Germany,    
Green P., Rao V.R.(1969) : Â«Note on proximity Measures and Cluster AnalysisÂ» , Journal of 
Marketing ResearchÂ» , Vol6, pp.359-364,  
Guttmann L. (1941): Â« The Quantification of a Class of Attributes , A theory and Method of 
Scales ConstructionÂ», Horst P. Editor, Social Sciences Research Council, New York , 
Hicham A.,Saporta G. (2003) : Â«Mesures de distance entre modalitÃ©s de variables qualita-
tives; application Ã  la classification Â», Revue de Statistique AppliquÃ©e, Vol 51, nÂ°2, 
pp. 75-90, 
 Idrissi Amal N. (2000): Â«Contribution Ã  l'Unification de CritÃ¨res d'Association pour Va-
riables Qualitatives Â» , ThÃ¨se de lâ€™UniversitÃ© Paris VI, 
Jaccard P. (1908): Â« Nouvelles Recherches sur la distribution florale Â» , Bulletin de la SociÃ©-
tÃ© Vaudoise des Sciences Naturelles, Vol nÂ°44, pp.223-270,  
Joly S., Le CalvÃ© G.(1986) : Â« Metric and Euclidean Properties of Dissimilarity Coeffi-
cients Â», Revue de Statistiques et Analyse des DonnÃ©es nÂ°11, pp :30-50 ) 
RNTI-A-3- 313 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
Joly S., Le CalvÃ© G. (1994) : Â« Similarity functions Â», Lecture Notes in Statistics, (In Van 
Cutsem, B. editor),  Springer-Verlag, vol. 93,  pp. 67-86,  
Jeliazkova  N. (2005): Â« Chemical Similarity Â», European Chemicals Bureau (ECB) Work-
shop on Chemical Similarity and Threshold of Toxicological Concern (TTC)  Approach-
es ,  Ispra, Italy,  
Jackson, A.A., Somers, K.M. et Harvey, H.H. (1989): Â« Similarity coefficients: measures for 
co-occurrence and association or simply measures of occurrence? Â»,  Am. Nat. Journal  
Vol:133: pp.436-453,. 
Janson S. , Vegelius J. (1982): Â«Correlation Coefficient for more than one Scale TypeÂ»,  
Multivariate Behavioral Research Journal, Vol 17, Issue 2, pp.271-284, 
Kulczinski S. (1927) : Â«Classes des Sciences MathÃ©matiques et NaturellesÂ», Bulletin Interna-
tional de lâ€™AcadÃ©mie Polonaise des Sciences et des Lettres, pp57-203, 
Lerman I.C. (1970):  Â« Les Bases de la Classification AutomatiqueÂ», Livre chez Gauthier-
Villars, Paris, 
Lerman I.C.  (1981): Â« Classification et Analyse Ordinale des DonnÃ©es Â»,  Livre, Dunod, 
Paris,  
Lerman I.C. (1987) : Â« Construction d'un indice de similaritÃ© entre objets dÃ©crits par des 
variables d'un type quelconque, application au problÃ¨me du consensus en classification Â»  
Revue de Statistique AppliquÃ©e, vol. 35, nÂ° 2,  pp :39-60, 
Lelu A. (2002):  Â«Comparaison de trois mesures de similaritÃ©s utilisÃ©es  en documentation 
automatique et analyse textuelle Â», Proceedings des 6Ã¨me JADT ( 6 Ã¨mes JournÃ©es 
dâ€™Analyse des DonnÃ©es Textuelles),  
Lesot M.J., Rifqi M. et Benhadda  H. (2009): Â« Similarity Measures for binary  and numeri-
cal Data Â» , pp 63-84 in  Journal of Knowledge Engineering and Software Data Para-
digms, Interscience Editor,  
Marcotorchino F. (1989): Â« Liaison Analyse Factorielle-Analyse Relationnelle (I) : "DualitÃ© 
Burt-CondorcetÂ», Etude du Centre Scientifique IBM France, No F142,  
Marcotorchino F. (1984) : Â« PrÃ©sentation des CritÃ¨res dâ€™Association en Analyse des DonnÃ©es 
Qualitatives Â», Publication AD0185, UniversitÃ© Libre de Bruxelles, pp :1-57, (1984). 
Marcotorchino F. (1987): Â« Block seriation problems: A unified approachÂ», Applied stochas-
tic models and Data Analysis  Journal NÂ°3, pp.73â€“91, 
Marcotorchino F.(1991) : Â« L'analyse Factorielle-Relationnelle (parties 1 et 2) Â». Etude du 
Centre Scientifique IBM France, M06 pp :1Ã  122, 
Marcotorchino F.,  Benhadda H.(1996) : Â« Introduction Ã  la SimilaritÃ© RÃ©gularisÃ©e Â», Etude 
MAP011, pp1-78 du Centre EuropÃ©en de MathÃ©matiques AppliquÃ©s, ECAM/IBM,  
Marcotorchino F., El Ayoubi N. (1991): Â«Paradigme logique des Ã©critures relationnelles de 
quelques critÃ¨res fondamentaux d'association Â»  Revue de Statistique AppliquÃ©e, Vol 39, 
nÂ°2, pp :25-46 , 
RNTI-A-3 - 314 -
                                                                                                    F. Marcotorchino 
Messatfa H. (1989) : Â« Unification Relationnelle des CritÃ¨res et des Structures de Contin-
gencesÂ», ThÃ¨se de lâ€™UniversitÃ© Paris VI, LSTA,  
Marcotorchino F., Michaud P. (1978) : Â« Optimisation en analyse ordinale des donnÃ©es Â».  
Livre Masson, Paris,   
Marcotorchino F.,  Michaud P. (1981) .: Â« AgrÃ©gation des SimilaritÃ©s en Classification Au-
tomatique Â», Revue de Statistique AppliquÃ©e, Vol 30, nÂ°2 , Paris,  
Michel C. (2000) : Â«Ordered similarity measures taking into account the rank of docu-
ments Â», Journal dâ€™ Information Processing and Management, nÂ°37, pp. 603-622 ,  
Maggira G.M., Petke J.D., Mestres J. (2002):  Â« Similarity Indexes for ChemistryÂ» in  Journal 
of Mathematical Chemistry Â», Vol 31, NÂ°3,   
 Ochiai  A. (1957): Â«Zoogeographic studies on the soleoid  fishes found in Japan and  its 
neighbouring Â»,  Bulletin of the Japanese Society for Scientific Fisheries, NÂ°22, pp.526-
530,  
Parrochia D.  (1992): Â«MathÃ©matiques & existence :Ordres Fragments, EmpiÃ¨tements Â»,  
Publication :Seyssel, Champ Vallon , Collection Milieux,  
Quine W. van O. (1998): The Pre-Established Harmony of Subjective Perceptual Similarityâ€ 
in Proceedings of the Twentieth World Congress of Philosophy, Volume 6, (Boston, Au-
gust, 1998) (reprinted in W. V. Quine.:  Confessions of a Confirmed Extensionalist ) in 
Floyd, Juliet and Shieh, Sanford (editors) (2008).  
Rand  W.H. (1971): Â«Objective Criteria for the Evaluation of Clustering Methods Â», Journal 
of the American Statistical Association, Vol. 66,  
Rifqi  M., Berger V. , Bouchon- Meunier  B. (2000): Â« Discrimination Power of Measures of 
Comparison Â»  , Fuzzy Sets and Systems, vol.110, pp. 189-196, 
Rogers D.J., Tanimoto T.T. (1960): Â« A computer program for classifying plants Â», Vol 132, 
pp 1115-1118, Science Journal ,  
Saporta G. (1990): Â«ProbabilitÃ©s Analyse des DonnÃ©es et Statistique Â», livre (2Ã¨me Ã©dition 
augmentÃ©e) , Editions Technip (2006), (1Ã¨re Ã©dition  (1990)) 
Salton G. (1968) : Â« Automatic Information Organization and Retrieval Â», book, Mac Graw 
Hill Editor,New York,  
Salton G, Mac Gill  M.J. (1983) : Â«Introduction to Modern Information Retrieval Â», Mac 
Graw Hill  Editor, New York)  
Schoenberg I.J. (1938): Â«Metric Space and Positive Definite Functions Â», Transactions of the 
American Mathematical Society, nÂ°44, PP:522-536, New York,   
Solomon H., Fortier  J. (1966): Â«Clustering Procedures Â»,  Multivariate Analysis, P. Krish-
naiah (Editor), Academic Press, New york, 
Simpson  G.G.(1943) : Â«American Journal of Science Â», NÂ°241, pp.1-31, 
Sneath, P.H.A. and Sokal, R.R. (1973). Â«Numerical Taxonomy: the PrinciplesÂ», Book Mac 
Graw Hill, 
RNTI-A-3- 315 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
Sokal R.R.,  Michener C.D.(1958) : Â«A Statistical Method for Evaluating Systematic Rela-
tionships Â», University of Kansas Science Bull., nÂ°38, pp:1409-1438,  
Sokal R.R,. Sneath P.H.A.,  (1963): Â«Principles of Numeric Taxonomy Â», livre, Freeman  
Editeur, San Francisco, 
SÃ¸rensen T. (1948) Â« A method of establishing groups of equal amplitude in plant sociology 
based on similarity of species content and its application to analyses of the vegetation on 
Danish commons Â»,. K. Dan. Vidensk. Selsk. Biol. Skr. Vol nÂ°5: pp.1-34, 
Sparck Jones K. (1971) : Â«Automatic keyword classification for retrieval Â», book by  Butter-
worth, London,  
Snijders  T.A. et al. (1990): Â«Distribution of some similarity coefficients for dyadic binary 
data in the case of associated attributes Â», Journal of Classification nÂ° 7, , pp. 5-31, 
Springer-Verlag,  
Tversky  A. (1977): Â« Features of Similarity Â» Psychological Reviews Vol 84 nÂ°4 pp:327-
352, 
Van Cutsem B. (editor) (1994) : Â«Classification and Dissimilarity Analysis Â», book by 
Springer-Verlag , Collection: Lecture Notes in Statistics nÂ°93, New-York, Berlin, 
Van Rijsbergen C.J.(1979): Â«Information RetrievalÂ», Livre PubliÃ© par Butterworth-
Heinemann ,  Newton, Massachussets, USA,  
Warrens M.J. (2008): Â«On the Indeterminacy of Resemblance Measures for Binary (Pres-
ence/Absence) DataÂ», Journal of Classification, Vol 25, Issue nÂ°1, pp.125-136, Springer 
Verlag, Berlin,  
Warrens M.J. (2009): Â«Bounds of Resemblance Measures for Binary (Presence-Absence) 
VariablesÂ», Journal of Classification, Vol 25, Issue nÂ°2, pp.195-208, Springer Verlag, 
Berlin,  
Yule G.U. , Kendall M.G  (1950).: Â«An Introduction to the Theory of Statistics Â», 14th edi-
tion, book by Hafner , New York, (1950). New published  edition  by  Arnold (1976).  
 
 
 
 
 
 
RNTI-A-3 - 316 -
                                                                                                    F. Marcotorchino 
 
 
Nom de lâ€™Indice Emplacement  de dÃ©finition ou Renvois 
1 Anderberg Simple DÃ©fini en  4.1.1.3  
2 Anderberg ComplÃ©mentaire DÃ©fini en  4.1.1.4 
3 Anderberg (4 Ratios) DÃ©fini en  4.4.4.4 
4 Baroni-Urbani -Buser DÃ©fini  en 4.4.4.7 
5 Borko  (voir  Sokal et Michener) 
6 Braun -Blanquet   DÃ©fini en 4.3.2 (voir  Min, voir  Simpson voir Max) 
7 Bravais - Pearson   DÃ©fini en 4.4.4.1 (voir Tetrachorique)  
8 Bray et Curtis DÃ©fini en 4.5.1.2  (voir Dice, voir Odum ) 
9 Carbo CitÃ© en note de bas de page nÂ°9   (Voir  Ochiai ) 
10 Cohen (Kappa) DÃ©fini  en 4.4.5.5 
11 Condorcet (voir  Rand voir Sokal et Michener)  
12 Czekanowski (voir  Dice) 
13 Dice DÃ©fini en 4.1.1.1 (voir Czekanowski) 
14 Fonction F  DÃ©fini en 4.3.2.3  (voir Van Rijbergen voir Tversky) 
15 Fleiss  DÃ©fini en 4.4.4.2.b  
16 Fowlkes-Mallows DÃ©fini en 5.1.2 
17 Goodman - Kruskal (Lambda) DÃ©fini en 4.4.5.4  (voir Dice)  
18 Goodman - Kruskal (Tau) DÃ©fini en 4.4.5.2 (voir  Tetrachorique) 
19 Gower CitÃ© en note de bas de page nÂ°5  
20 Green et Rao  (voir Sokal et Michener voir Hamann) 
21 Hadamard DÃ©fini en 4.4.4.2.c 
22 Hamann DÃ©fini en note de bas de page nÂ°12  
23 Hodgkin -Richards -Petke DÃ©fini en note de bas de page nÂ°9  (voir  Dice) 
24 Hubert-Arabie DÃ©fini en 5.1.3 (voir Kulczynski ) 
25 Indice du Max (P,R) DÃ©fini en 4.3.2  (voir  Simpson) 
26 Indice du Min (P,R) DÃ©fini en 4.3.2 (voir Braun-Blanquet) 
27 Jaccard DÃ©fini en 4.1.1.2 
28 Janson -Vegelius DÃ©fini en 4.4.5.1 (voir  Hamann, voir Sokal-Michener) 
29 Kulczynski (abondance) DÃ©fini en 4.5.2.1 (voir  Dice)  
30 Kulczynski (0-1) DÃ©fini en 4.2.1.1 
31 Kulczynski (4 Ratios)  DÃ©fini en 4.4.4.4 
32 Lance- Williams (abondance) DÃ©fini en 4.5.1.1 (voir  Sokal Michener)  
33 Lerman Â« ModifiÃ© Â» DÃ©fini en 4.4.5.3 
34 Mac Connaughey DÃ©fini en 4.3.2.2 (voir  Kulczynski) 
35 Marcotorchino-Michaud (1) DÃ©fini en 4.4.3.2 
36 Marcotorchino-Michaud (2) DÃ©fini en 4.4.3.3 
37 Marczewski- Steinhaus (abondance) DÃ©fini en 4.5.2.2 (voir  Jaccard) 
38 Maxwell-Pilliner  DÃ©fini en 4.4.4.2.a   
39 Morey-Agresti DÃ©fini en 5.1.1 
40 Ochiai DÃ©fini en 4.2.1.2 
41 Ochiai (4 Ratios)  DÃ©fini en 4.4.4.5 
42 Odum DÃ©fini en 4.5.1.2 (voir  Bray-Curtis) 
43 PrÃ©cision  (Indice de)   (voir  Rappel, voir  Tversky) 
44 Rand  DÃ©fini en 4.4.5.1  (voir Janson et Vegelius) 
45 Rao DÃ©fini en 4.4.3.1 
46 Rappel (Indice de)    (voir  PrÃ©cision, voir Tversky) 
47 Rogers et Tanimoto DÃ©fini en 4.4.1.2 
48 Sokal et Michener DÃ©fini en 4.4.1.1  (voir Green et Rao) 
49 Sokal et Sneath DÃ©fini en 4.4.1.3  
50 SÃ¸rensen DÃ©fini en 4.1.1.4 
51 Sorgenfrei CitÃ© en note de bas de page nÂ°8  
52 Tetrachorique  (Coefficient)  DÃ©fini en 4.4.4.1 (voir  Bravais Pearson)   
53 Tversky DÃ©fini en 4.1.3  
54 Van Rijsbergen  CitÃ©  en note de bas de page nÂ°11
55 Yule Q et Y  DÃ©finis en 4.4.4.3 
RNTI-A-3- 317 -
Essai de Typologie Structurelle des Indices de SimilaritÃ©s  
 
 
RNTI-A-3 - 318 -
