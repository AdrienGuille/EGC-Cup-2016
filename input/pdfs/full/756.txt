Essai de Typologie Structurelle des Indices de Similarité Vec-
toriels par Unification Relationnelle 
 
 François Marcotorchino  
 
Thales Communications : 160, boulevard de Valmy – BP 82 
92704 Colombes Cedex et Laboratoire de Statistique Théorique et Appliquée (Paris VI) 
jeanfrancois.marcotorchino@fr.thalesgroup.com 
 
Résumé : Cet article a  pour but de proposer un regard nouveau et unificateur 
à la problématique des Indices de Similarité et des Critères de structuration ou 
de partitionnement. Une catégorisation des indices, des propriétés non con-
nues   ainsi qu’une présentation dans différents axes de structuration seront 
suggérées.  La recherche des significations et des filiations associées sera 
donnée comme résultat dérivé de ce travail. 
 
 
1 Introduction 
La recherche sur les indices de similarité a, depuis longtemps, donné lieu à une abon-
dante littérature, les références aux indices ayant été faites souvent, même dans les meil-
leurs articles, sous forme de listes   (type inventaire) sans qu’une réelle structuration n’ait 
été proposée. Nombre de ces  indices  ont été introduits  et donnés dans différents articles 
et dans différents domaines  fondamentaux ou d’application, au fur et à mesure de leur 
utilisation potentielle. Ainsi n’est-il pas étonnant de trouver ces indices proposés et intro-
duits dans des domaines  aussi variés que:  les Sciences Humaines et plus particulièrement 
la Sociologie et l’Ethnologie et ses dérivées : Ethnopsychologie, Ethnogénétique,  etc.., la 
Linguistique proprement dite, dont: Lexicologie, Lexicométrie, Ethnolinguistique,  Text 
Mining,  les Mathématiques: Analyse des données, Classification et « Clustering », les 
Sciences du vivants : la Biologie, la Biométrie, la  Physiologie, la   Phylogénie, la  Zoolo-
gie, la Médecine, les Sciences organiques : la  Chimie moléculaire,    la Biochimie et enfin 
de nombreux domaines plus « business », comme : le « Customer Relationship Manage-
ment », le « Business Intelligence », la « Géo-cartographie »,  le «Profiling » etc..  
    Presque tous les indices courants  ont été introduits à des périodes et à des dates diffé-
rentes, pour des buts  et motifs variés sans structuration et explication claire du rôle de 
chacun  et sans aucun regard sur une filiation ou une hérédité sous jacentes permettant de 
mieux les comprendre ou de les interpréter (ceci étant sans doute dû à la provenance très 
différenciée des inventeurs). Ce phénomène s’est traduit,  de fait,  soit par une impression 
de fouillis, soit, et on le verra plus loin dans ce document, par des successions de redécou-
vertes  (parfois très récentes) d’indices existants  depuis fort longtemps, ou de mises en 
évidence de propriétés connues depuis très longtemps  par des chercheurs de disciplines 
différentes.  
Preuve que le sujet est toujours d’actualité,  un article vraiment très récent de  Matthijs J. 
Warrens (2009) vient de paraître dans  la Revue Journal of Classification, au moment 
RNTI-A-3- 203 -
Essai de Typologie Structurelle des Indices de Similarités  
même où nous envoyons le notre pour publication. Il aborde   quelques uns des points 
exposés dans cet article, en particulier l’ordonnancement de certains des indices présentés 
dans notre document, en cherchant une unification des bornes par moyennage (Harmo-
nique, Géométrique et Arithmétique), sans exploiter pourtant  d’autres considérations 
comme les structures homographiques associées.    
   Même des articles synthétiques et plus théoriques, extraits d’ouvrages plus mathéma-
tiques n’ont pas couvert  complètement cette problématique. Ainsi l’article de F.B. Bau-
lieu (1989)  dans la Revue « Journal of Classification » (Springer Verlag), qui représente 
l’un des meilleurs  survols du sujet, propose une liste très abondante d’indices, sans 
qu’elle soit,  à son tour, ni complète ni exhaustive. Cette liste est d’ailleurs présentée, en 
vrac, sans organisation aucune (sans citer le nom des « inventeurs »), le but étant de noti-
fier un certain nombre de propriétés possédées  ou non par ces indices; aucune mention 
n’est faite à propos de leurs filiations, de leurs ressemblances ou de leur hérédité, en un 
mot de leur structuration ou unification réciproque. Parmi les auteurs qui se sont,  en 
France,  intéressés le plus en profondeur à ce domaine, qui semble simple (uniquement en 
apparence),  mais qui est en fait   difficile, on pourra consulter utilement les travaux de S. 
Joly  et  G.  Le Calvé (1986) et (1994) ainsi que ceux de  B. Fichet (1994) dans le livre 
édité par  B. Van Cutsem (ouvrage d’ensemble, excellent et de référence  publié chez 
Springer Verlag en (1994), ceux de IC Lerman (1970), (1981), (1987), de G. Bisson  
(2000) auxquels  on rajoutera,  toujours  dans le livre sus-cité de  B. Van Cutsem (1994), 
les  contributions   additionnelles de B. Van Cutsem et F. Critchley .    
    Nous avions déjà présenté, il y a quelque temps,  dans un article  la Revue de Statistique 
Appliquée titré « Agrégation des Similarités », F. Marcotorchino et P. Michaud (1981) , un 
essai de catégorisation des indices de similarité les plus courants. Bien que certains résultats 
originaux aient été présentés dans cet article, nous n’avions pas vu  à cette époque, tout 
l’intérêt de cette restructuration et surtout, nous ne l’avions pas appliquée à un ensemble 
étendu d’indices, nous nous étions contentés des plus connus et des plus représentatifs.  
   C’est à cette tâche que nous nous attelons dans cet article, et ce sont certaines des conclu-
sions associées qui peuvent soulever  un intérêt à la fois d’un point de vue théorique et 
pratique. Les différents axes de structuration des Indices de Similarité que nous allons pro-
poser, donneront  une vue d’ensemble et permettront d’en déduire des propriétés, qui, bien 
que souvent naturelles,  ont été peu proposées sous cette forme dans la littérature.  Nous 
revendiquons le fait que nous ne sous sommes pas  intéressé en profondeur ici aux  proprié-
tés  très importantes de « métricité » et de « semi-definie positivité » des matrices de simila-
rité associées, du fait qu’elles avaient  déjà été amplement étudiées, en particulier on trou-
vera de larges développements sur ce domaine dans l’ouvrage pré-cité de B. Van Cutsem 
(1994), mais également dans l’article de J. Gower et P. Legendre (1986), où dans celui de 
G. Le Calvé (1994) également.   
Cela peut paraître légèrement  présomptueux de rédiger un « nième » article sur le sujet, à 
la date d’aujourd’hui, vu le nombre incroyable d’articles ayant de près ou de loin traité de 
ce problème, nous pensons, néanmoins, qu’un certain nombre des résultats qui sont donnés 
dans cet article sont originaux ou du moins peu connus, même de spécialistes de l’analyse 
des données. C’est d’ailleurs essentiellement la raison qui nous a fait reprendre un article 
déjà publié en interne  Thales en 2002, en lui rajoutant un certain nombre de concepts et de 
résultats et dont ce nouvel  article est une substantielle amélioration. Bien que nous abor-
dions en fin d’article les  indices calculés sur « matrices d’abondance », l’essentiel de ce 
travail a trait aux indices de similarités calculés sur variables ou entités binaires. Compte 
RNTI-A-3 - 204 -
                                                                                                    F. Marcotorchino 
tenu de la difficulté générale du sujet lié à la « similarité », il semble que des articles du 
même type que celui ci devraient être consacrés à l’étude des indices de similarités entre 
structures plus complexes  que les structures de listes ou vectorielles (similarités entre 
graphes , similarités profondes entre textes, similarités topologiques entre objets ou entre 
structures diverses..etc..). Malgré le nombre très important d’articles sur ces thématiques, il 
semble qu’une synthèse globale  reste néanmoins à faire.  
 
1.1 Considérations Axiomatiques Générales 
   L’axiomatique relative aux principes  structurants le domaine des  indices de similarités 
est, somme toute, assez pauvre,  non seulement au niveau mathématique mais également au 
niveau philosophique. Nous avions signalé ce fait dans un article écrit conjointement avec 
H. Benhadda, H. Benhadda et F. Marcotorchino  (1996), suivant  en cela les traces d’une 
réflexion du philosophe D. Parrochia (1992) sur le sujet. De même on trouve chez les philo-
sophes logiciens  Willard van Orman  Quine, en particulier dans l’un de ses derniers ar-
ticles, voir  W.V. O. Quine (1998) et Rudolf. Carnap (1928) , comme l’avait  également fait 
en son temps le philosophe épistémologiste  L. Brunchwicg (1921), quelques réflexions 
intéressantes sur la notion de « similarité » ainsi que sur les structures ontologiques et les 
principes descriptifs associés. Mais ceci aboutit a une axiomatique relativement faible dont 
nous donnons ci-dessous quelques principes de base et auxquels nous ferons parfois réfé-
rence dans la suite. 
 
a) Axiome n°1 : Positivité 
Un indice de similarité S,  est une fonction prenant ses valeurs dans I x I, où I est un En-
semble fini  d’objets, à  valeur dans  ℜ+ (ensemble des réels positifs ou nuls), donc S est 
une fonction positive1, d’où : 
                                                  IxI  )y,x(        0)y,x(S ∈∀≥   
x, peut représenter un vecteur dans un espace à plusieurs dimensions (disons Rm, ou appar-
tenir  à R, tout simplement) . Sauf cas particulier, nous identifierons : 
{ } xà....xx,x,xx m321= ,    et    { } yà....yy,y,yy m321= ,    pour éviter les 
notations vectorielles. 
 
b) Axiome n°2 : Symétrie 
Un indice de similarité S,  est une fonction prenant ses valeurs dans I x I à valeur dans  ℜ+ 
(ensemble des réels positifs ou nuls) et telle que, pour  deux objets x et y appartenant à un 
ensemble fini I ,  S doit vérifier l’axiome ou le principe de symétrie : 
                                                 IxI  )y,x(         )x,y(S)y,x(S ∈∀=   
                                                 
1
 La positivité est un axiome non totalement obligatoire, car certains indices notés «  xy » (comme on le verra) 
varient de -1 à +1 et ont des comportements de coefficients de corrélation. Ceci étant dit, il suffit  de remplacer  xy 
par S(x,y)=1/2(xy+1), pour se trouver titulaire d’un indice « S », vérifiant alors tous les « bons » axiomes. De la 
même façon , on passe d’un « indice de distance »  dxy   ou d’une « distance vraie » à un indice de similarité en  
posant 
xyd1
1)y,x(S
+
=
, ou  S(x,y)=1-d(x,y) , ou bien encore S(x,y)=1-½ d²(x,y)  (on abordera ce point dans le 
texte )  
 
RNTI-A-3- 205 -
Essai de Typologie Structurelle des Indices de Similarités  
 
c) Axiome n°3 : Auto-similarité maximale  (ou Axiome de « propreté ») 
Un indice de similarité S,  est  dit « propre », on dit aussi   qu’il vérifie  l’axiome d’  « au-
to-similarité maximale » si :  
 S  vérifie l’inégalité : 
                                          I  y    ,xy         )y,x(S)x,x(S ∈≠∀≥  
Puisque on a de même :  
                                  I  y    ,xy         )y,x(S)y,y(S ∈≠∀≥    
on en déduit que l’axiome d’auto-similarité maximale induit la propriété : 
 
                                          ( ) IxI  y,x        y)S(y,x),S(x, Min)y,x(S ∈∀≤  
 
 
d) Axiome n°4 :  Transitivité Généralisée Indicielle et dérivés 
Dans le cas où un indice de similarité vérifie       0 ≤ S(x,y) ≤ 1 
1. et que son auto-similarité maximale  implique  S(x,x)= 1  (l’indice est alors dit :  
« normé ») 
(si ce n’est pas  le cas il suffit simplement d’effectuer la transformation sui-
vante :      
y)S(x,Max
y)S(x,y)(x,S'y)S(x,                  
yx,
=→
 
         pour se trouver titulaire d’un indice variant de 0 à 1. On dit alors que l’indice est 
« re-normé » 
 
2. et qu’il vérifie  la propriété suivante dite de  « Transitivité Généralisée Indi-
cielle » :   
 
(f 1)                           S(x,y) + S(y,z)- S(x,z)   1     ∀ (x,y,z) 
 
Alors, la quantité d(x,y)=1 – S(x,y) vérifie l’inégalité triangulaire : 
En effet : 
               L’inégalité précédente sur  S(x,y) en posant  S(x,y) = 1 – d(x,y), implique : 
        (1-d(x,y)) + (1-d(y,z)) - (1-d(x,z)) ≤ 1      d(x,z) ≤  d(x,y) + d(y,z)  (inégalité triangulaire) 
 
De plus  du fait que  S(x,x)=1 on a : d(x,x)=0  (dans ce cas d(x,y) est une « semi-distance ») 
Si en   plus on a : S(x,y)=1   x = y alors d(x,y)=0   x = y  et d(x,y) est une « distance »  vraie. 
 
Par ailleurs, J.C. Gower (1966) a généralisé un résultat de I. Schoenberg  datant de (1938) 
I. Schoenberg (1938) à propos du fait que si la matrice {S(x,y)} est définie non négative  
(NND)  et que  S(x,x) =1, ∀ x ,   alors la quantité :                                        
 y)]S(x,-2[1y)d(x, =     
 représente une distance euclidienne.   
 
La « Transitivité Généralisée Indicielle » (TGI) est,  pour un indice de similarité,  la 
propriété « duale » de l’ « Inégalité Triangulaire » pour une distance ou une dissimilari-
té.   
RNTI-A-3 - 206 -
                                                                                                    F. Marcotorchino 
 
En particulier si  S(x,y) est un indice de similarité vérifiant les trois premiers axiomes et 
qu’il est construit à partir d’un indice de distance sous la forme : 
y)(x,d1y)S(x,ou  y)d(x,1y)S(x, 221−=−=   , on dira que l’indice de similarité est « mé-
trisable »  (premier cas) ou  «métrisable euclidien » (deuxième cas) . 
 
 
e) Théorème n°1 : (Généralisation homographique de la TGI) 
 
Si  Sd(x,y) est un indice de similarité normé,  c’est à dire dont la valeur maximale est égale 
à 1 et vérifiant  la propriété d’auto-similarité maximale , alors tout indice Su(x,y),  vérifiant 
l’auto-similarité maximale  de la forme :  
 
                            ⇔
−
=
y))(x,S(
y)(x,Sy)(x,S
d
d
u
   
1y)(x,S
y)(x,S
y)(x,S
u
u
d
+
=
 
vérifiera la propriété de « Transitivité Généralisée Indiciale » et sera donc métrisable si les 
coefficients  α et β  de la fonction homographique précédente, liant l’indice Sd(x,y) à Su(x,y) 
vérifient eux –mêmes des propriétés particulières  que nous allons expliciter. 
 
Tout d’abord la fonction homographique associée Su(x,y) doit vérifier : 
1:siobtenueseraimalemaxritéautosimila'l1
-
1
x)(x,S
x)(x,S
x)(x,S
d
d
u +===
−
=
  
et elle doit  s’annuler si Sd (x,y)=0  le numérateur du rapport est forcément de la forme : 
αSu(x,y), car sinon on ne peut annuler la fonction homographique associée. 
D’autre part  si l’indice Su(x,y) est métrisable, il doit pouvoir vérifier  une inégalité de la 
forme  donnée ci dessous, (en effet il suffit de remplacer Sd(x,y) par sa valeur en fonction 
de Su(x,y) dans l’inégalité TGI, pour obtenir :  
[ ][ ][ ] zy,x,   z)(x,S z)(y,S1 y)(x,S1

1
 -  1z)(x,Sz)(y,Sy)(x,S uuuuuu ∀+−−≤−+  
la quantité :    
[ ][ ][ ]
 1 à inférieureet   positive être devant   zy,x,   z)(x,S z)(y,S1 y)(x,S1

1
 uuu ∀+−−
 
ce qui est vrai car  (1-Su(x,y))≤ 1 idem pour (1-Su(y,z))≤ 1, ce qui implique donc que les 
coefficients : δ, λ, μ  soient positifs.  
Ceci induit, après calculs d’identification des coefficients des formes monomiales asso-
ciées,  les relations suivantes entre les différents coefficients :  
(i) α=β+1 (déjà vue) 
(ii) μ=α2 
(iii) δ=β2                                            
(iv) λ=α2-1 
On voit que ces différentes valeurs sont  paramétrables par rapport à un seul paramètre :  α 
ou β, de ce fait, cette   inégalité se réécrit en fonction d’un seul paramètre  par exemple 
« β », selon l’expression : 
 
(f2)   [ ][ ] zy,x,   
1)(
2)(
z)(x,S
1

 z)(y,S1 y)(x,S1 -  1z)(x,Sz)(y,Sy)(x,S 2u
2
uuuuu ∀








+
+
+		






+
−−≤−+
 
RNTI-A-3- 207 -
Essai de Typologie Structurelle des Indices de Similarités  
soit également sous la forme équivalente: 
[ ][ ] [ ] zy,x,   2)(z)(x,S z)(y,S1 y)(x,S1
1)(

 -  1z)(x,Sz)(y,Sy)(x,S uuu2uuu ∀++−−+≤−+
 
 Comme la quantité :       [ ][ ] [ ] zy,x,   2)(z)(x,S z)(y,S1 y)(x,S1
1)(

 uuu2 ∀++−−+
 
est positive si β≥0 ,  l’indice Su(x,y)  vérifie bien : 
                                       zy,x,     1z)(x,Sz)(y,Sy)(x,S uuu ∀≤−+     
c’est à dire l’inégalité TGI, il  est  donc métrisable. (cqfd) 
    
En remplaçant Su(x,y) par (1-du(x,y)) (son indice de distance) associé, l’inégalité  (f 2) se 
transforme en :  
 [ ] [ ] [ ] [ ] zy,x,   
1)(
2)(
z)(x,d1
1

 z)(y,d y)(x,d -  1z)(x,d1z)(y,d1y)(x,d-1 2u
2
uuuuu ∀








+
+
+−		






+
≤−−−+
  
soit :                
zy,x,
z)(y,dy)(x,d
1
1
   z)(y,d y)(x,d
1
2
 - z)(y,dy)(x,d
z)(x,d
uu
2
uuuu
u ∀
		






+
−
+
+
≤
 
Théorème n°1 :  Tout indice de similarité Su(x,y),  fonction homographique d’un indice 
Sd(x,y) vérifiant l’inégalité TGI, normé et exprimable sous  la forme :  
1y)](x,S[1
y)(x,S
y)(x,S
d
d
u +−
=
,  vérifie à son tour l’inégalité TGI et est  donc  métrisable.   
 
Théorème n°1 (bis) : D’autre part, si l’indice Sd(x,y)= 1-1/2d2(x,y), alors l’indice  
1y)](x,S[1
y)(x,S
y)(x,S
d
d
u
+−
=
 est exprimable suivant la formule Su(x,y)=1-1/2d’2(x,y) et est alors 
métrisable Euclidien .  
 
En effet si Su(x,y) est bien exprimable suivant la formule précédente alors il existe une 
métrique Euclidienne d’2(x,y) telle que :  
1y)(x,d
y)(x,d1
y)(x,d'1 2
2

2
2
1
2
2
1
+
−
=−
,   montrons que  ceci implique que d’2(x ,y)=2(1-S’(x,y)), donc 
que d’2(x,y) vérifie le théorème de Gower-Schoenberg .  
 
De l’égalité précédente on tire : 
2y)(x,d
y)(x,d1)2( y)(x,d' 2
2
2
+
+
=
 soit : 






+
−=
2y)(x,d
y)(x,d-212y)(x,d' 2
2
2  
En remplaçant d2(x,y) par 2(1-Sd(x,y)) dans la formule ci-dessus, il vient : 






+−
−=
1y)](x,S[1
y)(x,S
12y)(x,d'
d
d2  
soit  d’2(x,y) = 2(1-S’(x,y)) puisque l’on reconnaît dans S’(x,y) la quantité Su(x,y) (indice de 
similarité normé) que nous avions définie précédemment. d’2(x,y) vérifiant le Théorème 
RNTI-A-3 - 208 -
                                                                                                    F. Marcotorchino 
de Gower Schoenberg est donc une distance Euclidienne. Et l’indice Su(x,y) est bien métri-
sable Euclidien.(cqfd) 
 
De la même façon,  si un indice de similarité  normé, est construit à partir d’une expres-
sion comme :  S(x,y) = 1 – d(x,y) et si d(x,y) vérifie l’inégalité « ultramétrique » suivante :  
 
                            d(x,z)  Max (d(x,y), d(y,z))  ∀ x, y,z 
 
Alors l’indice de similarité associé vérifiera l’inégalité  de Transitivité Ultramétrique 
Indicielle   suivante :  
            
(f 3)                                    S(x,z)  ≥ Min (S(x,y), S(y,z)) 
 
Ce résultat s’obtient en remplaçant d(x,y) par 1-S(x,y) dans l’inégalité ultramétrique sur 
d(x,y) précédente. Cette inégalité implique la Transitivité Généralisée Indicielle, en effet 
comme S(x,z)  ≥ Min (S(x,y), S(y,z))  on a : 
                               S(x,y) + S(y,z) - S(x,z) ≤ S(x,y)+S(y,z)- Min (S(x,y), S(y,z)) 
Soit donc : 
S(x,y) + S (y,z) - S(x,z) ≤ S(x,y)+ S(y,z)- [ 1/2(S(x,y)+ S(y,z)) - 1/2  ⏐S(x,y)-S(y,z)⏐) 
Et donc finalement : 
.                              S(x,y) + S(y,z) - S(x,z) ≤   Max (S(x,y),S(y,z))  ≤ 1 
(cqfd) 
 
 
f) Pseudo Axiome n°5 : Axiome dit du  « typage de Carnap » 
 
   On pourrait rajouter à cette liste un « pseudo » axiome « logique »  associé à l’axiome 3,  
celui dit « du typage » dû au philosophe logicien Autrichien  Rudolf Carnap (1928)qui 
peut se traduire par : 
 Un « type TY »  étant défini par l’ensemble des individus vérifiant un ensemble fini de  
propriétés :  
                         TY(x) ={x	x,   vérifie les propriétés (p1,p2,…pu)} 
 alors pour tout individu « w »  tel que TYw ∉ , on doit avoir : 
                                                      w)S(x,y)S(x,Min
TYTYy)(x,
≥
×∈
.  
En d’autres termes tous les objets vérifiant un type TY donné doivent être plus semblables 
entre eux qu’ils ne le sont à tout objet quelconque extérieur à l’ensemble caractérisé par ce 
Type . Attention, ce « pseudo » axiome est tout à fait caractéristique des classes ou types 
« monothétiques » , mais peut ne pas être systématiquement vérifié par les  classes ou 
types « polythétiques ». 
 
 
g) Règle et borne dites de « Solomon et Fortier »  
 
   Dans leur article datant de 1966,  H. Solomon et  J. Fortier  (1966) définissent,  pour tout 
indice de similarité  S(x,y) variant de 0 à 1,   une règle,   que l’on peut appliquer de façon 
générale  et qui stipule que dès lors que la valeur d’un indice  est supérieure à  une borne 
RNTI-A-3- 209 -
Essai de Typologie Structurelle des Indices de Similarités  
correspondant au « milieu » de son intervalle de variation, on considérera que x et y seront 
« plus semblables » que « dissemblables », en un mot on pourra parler de similarité (par 
rapport à cet indice)  entre x et y. Cette règle s’écrit donc : 
                 
2
1y)S(x, ≥  
 On peut étendre cette règle au cas où l’intervalle de variation n’est plus (0-1), on écrira 
alors cette règle « étendue »  sous la forme : 
                                        
2
y)S(x,Maxy)S(x,Min
y)S(x, yx,yx,
+
≥  
 
La borne de Solomon-Fortier est intéressante au sens qu’elle permet d’étalonner un indice 
au milieu de son intervalle de variation (disons un point de passage obligé) et ainsi 
d’autoriser  des comparaisons structurelles entre indices. Nous étalonnerons surtout, pour 
un indice donné,  la valeur des « matchings » entre les profils de « x » et « y » en comparant 
cette valeur au  nombre de variables dans le contexte spécifique et particulier de la « dis-
jonction complète » (voir § 2.2.2.1) . C’est le processus complet dérivé de l’application de 
cette règle qui sera utilisé comme critère de valorisation d’un indice dans les paragraphes 
suivants. 
1.2 Quelques Définitions de Base  
    Dans le suite du texte nous parlerons de « Descripteurs » ou d’ « Attributs » ou de 
« propriétés » quand nous aurons affaire  à des variables de « Présence - Absence », nous 
noterons :  J  cet ensemble, et  nous poserons : 
P = J   le cardinal de cet ensemble J (indice d’un attribut = j ).  
 D’autre part,  nous parlerons de  « Variables »  ou de variables « vraies » au sens statis-
tique du terme lorsque nous aurons affaire  à  des colonnes de  tableaux de données, que 
ces variables soient nominales (catégorielles), hiérarchisées (notes, rang, fréquences etc..), 
ou continues, nous  appellerons :  M cet ensemble  et : 
       m= M  le cardinal de cet ensemble (indice d’une variable = k ). 
Enfin, et très classiquement cette fois, nous appellerons : I, l’ensemble des individus ou 
sujets étudiés, entre  lesquels, on calculera des indices de similarité.  Nous poserons, ce 
qui est un classique de l’analyse des données : I = {ensemble des individus} et : 
       N=  Ι  = le cardinal  de  cet ensemble (indice d’un individu = i). 
 
 
 
RNTI-A-3 - 210 -
                                                                                                    F. Marcotorchino 
2 Les Représentations possibles et les  différences entre 
l’Espace IxJ, l’Espace IxM et l’Espace Relationnel : IxI. 
2.1 Les Tableaux K=IxJ et T=IxM  
    Considérons maintenant les tableaux  suivants : Tableau 1, à valeurs {0-1} , de dimen-
sions   (N,P)  (croisant des  individus notés {Oi }avec des variables binaires ou des modali-
tés {mj }, et le Tableau 2, de dimensions (N,m), (croisant les mêmes individus  {Oi}avec des 
variables catégorielles ou hiérarchisées, ou numériques  {Vk}), on a :      
 
Tableau 1                        Tableau 2 
 
 
          
  
 
 
 
 
 
 
 
 
Dans le cas du  Tableau IxJ, simple, de dimensions (N,P),   cas des données de « Présence – 
Absence », il apparaît  que toutes les données sont 0 ou 1,  (l’individu possède = 1, ou ne 
possède  pas = 0, une propriété j (Attribut j)). 
Dans le cas du Tableau T = IxM,  de dimensions (N,m) - cas de variables vraies - les quanti-
tés données à l’intersection d’une ligne i et d’une colonne k peuvent prendre des valeurs 
quelconques.  Dans le cas d’une  variable catégorielle ou hiérarchisée, le nombre de va-
leurs (finies et assez peu nombreuses) en général prises par la variable Vk, donnera    le 
nombre total de modalités ( les différentes valeurs possibles) de cette variable.   
           Soit pk  ce  nombre, pk = (Ensemble des valeurs différentes de Vk) et l’on a : 
 
=
=
m
1k
kpP  , k ∈ {1,2…..m},  est le nombre total de modalités du Tableau, (à ne pas  con-
fondre avec « m »,  qui lui est le nombre total de variables). 
 
En effet, si l’on prend par exemple  l’individu N° 2 du tableau  (N× m) précédent , on voit 
que le profil de i2, est donné par:  
 
            i2  =  
     
 V
1
V
2
V
k
V
m
O1 1 3 2 5 
O2 4 3 1 4 
O3 5 4 3 5 
Oi 0 1 2 5 
Oi’ 5 3 1 1 
 
    
ON 4 4 1 2 
 m1 m mj mj’  mP 
O1 1 0 1 0 0 1 
O2 0 1 0 1 0 1 
O3 1 0 1 0 1 0 
Oi       
Oi’       
 
      
ON 1 0 0 1 1 1 
4 3 1 4 
RNTI-A-3- 211 -
Essai de Typologie Structurelle des Indices de Similarités  
la décomposition en profil disjonctif complet de l’individu i2 du fait que V1 a 5 modalités, 
V2 a 4 modalités, V3 a 3 modalités, enfin V4 a 5 modalités s’écrit : 
 
 
    
Sur ce tableau disjonctif on a bien m (Nombre de variables ) = 4,    N = I   
 
  P, la dimension la plus large = Nombre total de modalités =  5+ 4 +3 + 5 =  17, dans le cas 
présent,  donc : 
=
=
m
1k
kpP , k ∈{ 1,2…..4};  vaut ici:  P = 17.   
Donc, il y a équivalence au niveau de l’information apportée entre le tableau Nxm et le 
Tableau NxP, qu’on appellera Tableau Disjonctif Complet  dans ce cas, et on le notera K,  
son terme général est donné par : 
 



sinon 0
j modalité la possède iobjet l' si 1 
=k ij  
seuls le nombre de colonnes (P au lieu de m) et les valeurs  dans les cases ont changé : {0,1} 
dans le tableau NxP, valeurs quelconques dans le tableau Nxm. 
Posons maintenant:   
=
=
m
1k
kp
m
1p  alors  mpP =  , si  en particulier, toutes les variables 
ont le même nombre de modalités soit « μ » ce nombre, alors  P = μ m.  
 
Remarque n°1: on peut considérer que le tableau de «présence - absence» est  un   tableau disjonc-
tif  particulier lorsque l’on découpe une variable de  «présence – absence » en deux variables dis-
jonctives,  l’une de « présence » et l’autre d’ « absence » d’une propriété. On respecte dès lors les 
contraintes d’un tableau disjonctif complet avec comme changement majeur, le fait que l’on double 
le nombre de colonnes de la matrice de « présence absence »  avec un nombre de variables initial  
égal à m d’où   P=2m  est le nombre des modalités .  Nous verrons ultérieurement que, de ce fait, le 
modèle particulier  de « présence – absence » disparaît au profit d’un modèle disjonctif particulier 
où toutes les variables ont deux modalités.  
 
2.2 Cas des Tableaux Relationnels C=IxI et B=JxJ 
    Une dernière notation très utile,  et particulière,  est à retenir et à rajouter à la liste pré-
cédente. Lorsqu’on a affaire à des données représentables sous forme vectorielle (cas des 
« m » variables) ou dans un cas plus complexe encore: le cas de données non représen-
tables sous forme vectorielle, mais sous forme de graphe, il existe une autre représentation 
appelée, représentation relationnelle qui permet de déployer une Théorie qui lui est consa-
crée, à savoir :   « l’Analyse Relationnelle ou l’Analyse des  Représentations  Relation-
nelles » . Une abondante littérature existe sur ce domaine que nous donnons en bibliogra-
phie (voir en particulier J. Ah-Pine (2007), H.Benhadda et F.Marcotorchino (1998) et 
(1996), F. Marcotorchino (1984), (1989), (1991), F.Marcotorchino et P.Michaud (1981), 
F. Marcotorchino et N. El Ayoubi (1991) en tant qu’échantillon de cette approche). Mais 
V1 V2 V3 V4 
0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 
RNTI-A-3 - 212 -
                                                                                                    F. Marcotorchino 
 
pour la suite de l’exposé, il nous paraît important d’en donner quelques définitions ba-
siques, (voir les explications ci-après) :   
 
2.2.1 Tableau Relationnel de « Condorcet » C, croisant IxI de Taille (NxN)  
    Le modèle mathématique  sur lequel est basée l’Analyse Relationnelle des Données est 
lié à une façon particulière de prendre en compte  des variables, quel qu’en soit le type. En 
fait, il s’agit de prendre en compte les données individuelles sous forme de Relation Bi-
naire (ceci permet de croiser des clients par rapport à une variable en Marketing , des 
textes en linguistique, des  Patients en Médecine etc..). A titre d’illustration, considérons le 
cas suivant où est représentée une variable catégorielle (nominale) à savoir la « nationali-
té »  appliquée à un petit  ensemble  de 5 personnes notées { A, B, C, D, E} ayant 3 Nationa-
lités. La variable V “nationalité”, est codée 1 pour les citoyens Français:  {A et B}, 2  pour 
l’Espagnol {C}, 3 pour les Anglais : {D et E}. Dans ce cas, deux individus sont en relation 
s’ils ont la « même Nationalité ». C’est bien entendu une relation  binaire, dont le graphe 
de représentation sous forme matricielle  C est donné ci – après: 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
Remarque n°2: Si nous avions changé le codage   1 en 2 , 2 en 7 et 3 en 13  (par exemple), il est 
évident que la matrice Relationnelle  C n’aurait pas été affectée par ce  changement, (en fait en cas 
de variables catégorielles, les codages n’ont pas de signification particulière, seule l’appartenance à 
des classes de valeurs de modalités différentes,  compte). En fait la représentation de C  sous forme 
matricielle s’obtient en posant  la valeur « 1 » à l’intersection de la Ligne A et de la Colonne B si:  
l’« Objet A » a  « la même modalité  »  que  l’ « Objet B » et   « 0 » sinon. Ceci est fait sans tenir 
compte explicitement de la valeur de la catégorie mais seulement de façon implicite.  En fait dans ce 
cas, nous sommes dans une situation où la Relation  est une pure   « Relation d’Equivalence ».  Il 
existe une correspondance claire entre la représentation codée de V, et sa représentation associée C 
en termes de graphe ou de matrice (NxN) binaire, mais comme nous l’avons vu précédemment cette 
correspondance n’est pas biunivoque.   Néanmoins, la matrice  C  représentant la variable  V est une 
Matrice  {0-1}, contenant la même  information que celle apportée par la variable catégorielle  V. En 
général, une  Matrice Binaire  contient au minimum, la même information que celle contenue dans sa 
 
 A B C D E 
1 A 1 1 0 0 0 
1 B 1 1 0 0 0 
2 C 0 0 1 0 0 
3 D 0 0 0 1 1 
3 E 0 0 0 1 1 
V  C 
RNTI-A-3- 213 -
Essai de Typologie Structurelle des Indices de Similarités  
variable nominale associée, codée sous forme « vecteur linéaire ». Mais bien plus,  si nous considé-
rons le cas, où, dans notre premier exemple, on suppose à titre illustratif que l’Individu C a la triple 
“Nationalité” : (multi-appartenance : Passeports Français, Espagnol et Anglais). Il est dès lors  
impossible de coder cette nouvelle  information dans la variable  V, telle qu’elle est. Mais ceci ne 
pose aucun problème en environnement relationnel, voir la nouvelle représentation C’ de C ci-
après : 
 
 
 
 
 
 
 
 
 
 
 
On voit sur le tableau précédent, qu’il est impossible de tenir compte de la triple apparte-
nance dans le codage de V, alors que dans le codage relationnel, il suffit de rajouter des 
« 1 »  (en gras sur la figure) à l’intersection des lignes et des colonnes de l’individu C à 
l’intersection des lignes et des colonnes des autres individus de départ. 
Dans le cas de cette configuration relationnelle, on peut créer des critères de classification  
sur l’ensemble des individus ou sur l’ensemble des variables (voir l’article sur Analyse 
Factorielle Relationnelle dans  F.Marcotorchino (1989) et (1991)) ou  des indices de com-
paraisons entre deux tableaux (matrices) relationnels, c’est-à-dire entredeux variables  V 
et V’, ou plus généralement entre deux matrices C et C’.  Des résultats fondamentaux ré-
sultent de cette notation relationnelle . 
 
2.2.2 Additivité des Matrices  Relationnelles  de type  « Condorcéen » 
  Quelle que soit  une matrice relationnelle Ck, représentant une relation binaire associée à 
une  variable Vk quelconque, elle s’écrit de la façon suivante :  
a) Si la variable, Vk,  est une variable purement qualitative, on a le codage suivant : 
 
)'i(V)i(V 
onsin
si
0
1
C
kk
k
'ii
=



=
 
b) Dans le cas d’une variable quantitative le codage associé peut prendre plusieurs formes 
possibles dont une assez simple,(mais non optimale), décrite ci-dessous : 
  A B C D E 
1 A 1 1 1 0 0 
1 B 1 1 1 0 0 
2 C 1 1 1 1 1 
3 D 0 0 1 1 1 
3 E 0 0 1 1 1 
V  C’=Nouveau C 
RNTI-A-3 - 214 -
                                                                                                    F. Marcotorchino 
 
        
s)'i(V)i(V 
onsin
si
0
1
C
kk
k
'ii
≤
−



=
 
 Où « s » est un seuil donné. 
Alors, posons  : 
 (f 4)                                             
=
=
m
1k
k
ii'ii' CC
 
où « m » est le nombre de variables de départ, et où le nombre total d’objets {Oi}, on l’a 
vu, est posé égal à « N » par la suite. (N pouvant atteindre des valeurs égales à plusieurs 
millions dans les problématiques réelles, CRM et Marketing bancaires par exemple)). 
Cette matrice est la matrice dite de « Condorcet » de l’Analyse Relationnelle. La métho-
dologie relationnelle s’appuie sur la définition de cette matrice globale de similarités qui 
dans les cas les plus usuels de similarité s’exprime comme un produit scalaire (équivalent 
à un « noyau » (« Kernel de la théorie de l’apprentissage ).:  
 (f 5)                                             
=
=
P
1j
j'iij'ii kkC
2
 
(où kij représente le codage disjonctif (vu au § précédent) pour l’ensemble des modalités 
de l’individu Oi), c’est à dire dans le cas ou les valeurs {0 ou 1} sont obtenues par disjonc-
tion du Tableau 2, du  précédent  paragraphe. 
Cette matrice traduit le degré de ressemblance entre deux objets i et i’.   
A  partir de cette matrice de ressemblance, on peut construire une matrice « duale » de 
celle de Condorcet dite matrice des « dissemblances » ou dissimilarités   soit  ii'C ,  le-
terme général de cette matrice alors on a :       
                                             
ii'ii' CmC −=   (si pas de données manquantes) 
 
                            mCC ii'ii' ≤+    (si données manquantes) 
  
Tout tableau de Condorcet  de terme général Cii’, vérifie (voir  F.Marcotorchino et 
P.Michaud (1981)), la condition de « transitivité générale » : 
 
(f 6)                                           )"i,'i,i(mCCC
"ii"i'i'ii ∀≤−+  
Cette condition de transitivité générale provient  du fait que le tableau  
=
=
m
1k
k
ii'ii' CC   (voir 
formule (f 4) ), est la somme de « m » relations d’Equivalence, qui vérifient chacune  (par 
définition d’une relation d’équivalence) la condition de transitivité, c’est à dire : 
                                                 
2
 L’analyse relationnelle a été le cadre de développement de nombreuses mesures de similarités dites régularisées 
qui permettent de tenir compte de la structure interne des unités lexicales dans le calcul de similarité entre deux 
documents. Cette approche consiste à donner un poids, calculé de manière empirique, à chaque unité lexicale qui 
permet de mettre en avant son caractère discriminant. Nous renvoyons le lecteur intéressé aux travaux de 
H.Benhadda  et F.Marcotorchino (1998) et H.Benhadda ( 1996). 
 
 
RNTI-A-3- 215 -
Essai de Typologie Structurelle des Indices de Similarités  
(f  7)                                        ( ) k ,i",i'i,    1CCC k
"ii
k
"i'i
k
'ii ∀∀≤−+   
qui s’interprète en disant que si  «  i » est en relation avec « i’ » (soit  ( ) k ,i'i,    1C kii' ∀∀= )  
et si «  i’ » est  en relation avec « i″ » soit ( ) k  ,i",i'    1C ki"i' ∀∀=  alors on doit avoir « i » en 
relation avec « i″ »  c’est à dire que ( ) k  ,i"i,    1C kii" ∀∀= , c’est justement ce que traduit 
la formule (f 7) 
 
En sommant pour toutes les « m » valeurs de « k » , l’inégalité (f 7), on trouve l’inégalité 
proposée dans la formule (f 6), la condition « duale » sur la matrice de Condorcet ii'C , est 
une condition d’« inégalité triangulaire » : 
(f 8)                                           i"i'ii'ii" CCC +≤  
Comme nous l’avons vu ces deux relations sont souvent « duales » l’une de l’autre. La 
relation d’  « inégalité triangulaire », relation liée à des approches « métriques » de dis-
tances, correspond à la relation de « transitivité  généralisée» pour les structures de « simi-
larité » vue sous l’angle relationnel. 
Dans le cas général , dire qu’il y a plus de variables pour lesquelles les objets « i et i’ » 
sont en relation, que de variables pour lesquelles ils ne le sont pas, se traduit par la règle 
suivante  : 
                                
'ii'ii CC ≤  
        
Quand il n’y a pas de données manquantes , du fait que  mCC
'ii'ii =+  dans ce cas , il 
vient  la condition dite de majorité par paires :  
(f 9)                               
2
1
m
C
2
mC 'ii
'ii ≥≥
    
(ceci est une représentation de la règle majoritaire des comparaisons par paires de Condor-
cet (1785), qui, dans le cas où l’on  considère le tableau de Condorcet comme un indice de 
similarité est équivalente à une borne de Solomon Fortier, il suffit de diviser le tableau C 
par « m », pour  voir ce fait immédiatement).  
Cette définition est très générale car elle permet d’additionner tous types de relations bi-
naires quelconques  en allant bien au delà des structures vectorielles dont nous avons parlé 
ici. Ainsi la définition de la matrice de Condorcet  ( que nous avons donnée en (f 5)) est 
moins générale, elle ne s’applique seulement que dans le cas où l’on considère des va-
riables linéaires, telle que la variable V définie précédemment (exemple des nationalités 
cas 1) ou en cas de variable représentable sous forme de vecteur colonne (linéaire). 
 
2.2.3 Additivité longitudinale modalitaire  
   Cette additivité  est valable dans le cas de variables linéaires transformables en variables 
disjonctives (formule moins générale mais utilisée souvent en Analyse des Données)  
Dans ce cas, comme nous l’avons vu,  si K représente la matrice de terme {kij}  représenta-
tive d’une variable  V  quelconque (appelée également matrice disjonctive de V), on a, si 
pk  représente le nombre de modalités de la variable Vk : 
RNTI-A-3 - 216 -
                                                                                                    F. Marcotorchino 
 
                              
                                        ki j =  1 si  i possède la modalité j de V 
ki j =  0 si  i  ne possède  pas la modalité j de V 
dans ce cas particulier , la matrice relationnelle représentative de V (numéro k) s’écrit : 
                  
=
=
kp
1j
j'iijk'ii kkC  et  
=== ==
====

=
P
1j
j'iij
p
1j
j'iij
m
1k
p
1j
j'iij
m
1k
k
'ii'ii kkkkkkCC
m
1k
k
k
 
On retrouve ici la  justification de la formule (f 5)
 
 
Les résultats obtenus dans le cas général   restent valables,  avec néanmoins pour  la forme 
duale  k'iiC   de  
=
=
kp
1j
j'iijk'ii kkC ,  une nouvelle forme donnée par :                                               
( )
=
−=
kp
1j
2
j'iij
k
'ii kk
2
1C , 
soit pour la sommation longitudinale : 
 (f 10)                                  ( )
==
−==
P
1j
2
j'iij
k
'ii
m
1k
'ii kk
2
1CC  
 On vérifie également les formules  précédentes dans ce cas disjonctif :  
( )i'i,    1CC kii'kii' ∀=+       et     ( )i'i,    mCC 'ii'ii ∀=+    
 
En effet, comme dans le cas d’un tableau K (disjonctif complet) on a :    
                                                   i    ,  mk
P
1j
ij ∀=
=
 , il vient : 
     ( ) mkk
2
1kk
2
1kk
2
1kkCC
P
1j
P
1j
j'iij
P
1j
P
1j
2
j'i
2
ij
P
1j
2j'iijj'i
P
1j
ij'ii'ii =		
	








+=
	
	
	








+=−+=+   
= == ===
 
            
Ce qui se traduit au niveau des tableaux de Condorcet associés par la définition littérale  
suivante:  
 
« Dans le cas où  il n’y a pas de données manquantes, dire que le nombre de modalités 
(des variables) que i et i’ partagent  est plus grand que le nombre de modalités  qu’ils ne 
partagent pas, se traduit par 3» :  
                        ii'ii' CC ≥   ce qui implique   là encore  que :   Cii’  ≥  m/2     
                                                 
3
 il est à noter ici que la phrase est  différente de celle présentée au cas précédent, on parle ici de « modalités » et 
non de « variables »  
 
RNTI-A-3- 217 -
Essai de Typologie Structurelle des Indices de Similarités  
2.2.4 Représentation sous forme Vectorielle de la Matrice  Ck 
    Si l’on représente en extension vectorielle  (vecteur de longueur N²), la matrice repré-
sentative  de la variable C, et celle de la matrice C’ (nouveau C), données  dans l’exemple 
précédent ( nationalité) , on obtient : 
 
On voit bien, que nous avons rajouté 8 valeurs « 1 » dans le vecteur représentatif  de C’, les 
huit cases en « 1 » gras de la matrice (Nouveau C) présentée auparavant. Chacun  des vec-
teurs associés à C et C’, se compose  donc de 25 (N²) éléments, en 5 blocs de 5  juxtaposés, 
chaque bloc représentant une ligne  de la matrice C ou  de la matrice C’.  Ainsi sur les 
mêmes données on peut avoir 4 représentations différentes :    à savoir: des tableaux N×P, 
des tableaux N×m , des tableaux N×N et des vecteurs N2. 
a) Bref aperçu sur la réécriture du Tableau Relationnel Ck sous forme vectorielle.  
Pour toute matrice relationnelle Ck, on définira son Extension Vectorielle γk comme un 
vecteur de longueur N2   tel que :  
),....
,...

,
,(

 k
N
k
s
k
3
k
2
k
1
k
2=

,  où si k
'iiC  est le terme général de la matrice C
k
, alors : 
 
(f 11)   kskii' 
C = ,  si et seulement si  l’indice courant « s » vérifie:   
                                          i'et    i        'iN)1i(s ∀+−=   
(donc à tout couple (i,i’) correspond une valeur de l’indice « s » et une seule). 
Inversement connaissant « s » et bien sûr la dimension N, pour avoir la valeur de i et i’, il 
suffit  de procéder trivialement de la façon suivante :  
a) On divise s par N  s=a N+b,  
b) si a=0 alors :     i=1      et i’=b 
c) si a ≠0 alors      i= a+1 et i’=b 
Exemple pour N=5 , que valent les indices i et i’ de la matrice relationnelle Ck , pour s=18 ?              
On divise 18 par 5 soit 18=3x5+3, on a donc i=4 et i’=3 
 
b) Propriétés héritées au niveau vectoriel 
Un bon nombre  de propriétés relatives aux notations relationnelles se retrouvent, de façon  
quasi héréditaire, vérifiées au niveau des notations vectorielles, mais avec néanmoins 
quelques précautions à prendre, comme le montre l’induction de la propriété de transitivi-
té.   
En effet, pour toute variable Ck, relation  d’équivalence, on a vu en  (f  7) que l’on avait 
l’inégalité : 
                                     ( ) k ,i",i'i,    1CCC kii"ki"i'kii' ∀∀≤−+   
C 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 
C’ 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 
RNTI-A-3 - 218 -
                                                                                                    F. Marcotorchino 
 
En utilisant maintenant la convention d’extension vectorielle (f 11),   cette inégalité précé-
dente induit au niveau du vecteur  ),....
,...

,
,(

 k
N
k
s
k
3
k
2
k
1
k
2=

 les contraintes sui-
vantes :   
 (f 12)                              k       1   
-     
  
 k
s"
k
s'
k
s ∀≤+  
Cependant les indices s, s’ et s’’ , ne sont pas quelconques, car ils sont liés par les trois 
égalités suivantes, impliquées par les  formules (f 11) et (f 7) : 
 
                                 
"iN )1i("s
"iN )1'i(  's
'iN )1i(  s
+−=
+−=
+−=
       avec i <i’<i’’ 
Propriété n°1 : Inégalité sur les indices représentant une relation d’équivalence  
En éliminant deux à deux les indices  ou quantités présentes  dans  2 des  égalités  ci-
dessus,  et en tenant compte que si N=⏐I ⏐ est donné,  alors chacun des  indices :  i,,i’, i’’  
tels que i < i’<i’’ vérifie : i ≤ N , i’≤N, i’’≤ N, on peut montrer que les indices  s, s’ et s’’ véri-
fient alors  l’inégalité non triviale suivante :  
(f 13)                                     
N
'sNs  "s −+≤  
 
2.2.5 Tableau Relationnel croisant JxJ de taille (PxP) ou « Matrice de Burt »  
     De la même façon que nous avons défini le tableau de Condorcet C du paragraphe 
précédent, nous pouvons définir , dans le cas où les modalités j de l’espace J sont les mo-
dalités de variables discrètes ou catégorielles une matrice dite « Matrice de Burt », notée 
B,  qui se calcule également à partir des valeurs  du tableau Disjonctif  Complet K :  
 



sinon 0
j modalité la possède iobjet l' si 1 
=kij  
Ce tableau B a pour terme général la valeur Bjj’, donnée par :  
 (f 14)                                          
=
=
N
1i
ij'ijjj' kkB  
 
Ce tableau très utilisé en Analyse Factorielle des Correspondances Multiples (voir G. 
Saporta (1990) , F.Caillez et JP.Pages (1976) ou F.Marcotorchino (1991))  a de nom-
breuses propriétés structurelles dont on donne ci dessous les principales : 
 
           )B,B(MinB
'j'jjj'jj ≤  
 
            2
N
1i
'ijij
P
1j
P
1'j
'jj
P
1j
P
1'j
m.NkkB == 
== == =
 
RNTI-A-3- 219 -
Essai de Typologie Structurelle des Indices de Similarités  
Dans le cas ou les variables  Vk de départ sont des variables catégorielles, il existe une 
« dualité » évidente  entre les Tableaux de « Burt » et de « Condorcet » (voir 
F.Marcotorchino (1989), (1991)). En effet  on a: 

=
=
P
1j
j'iij'ii kkC ,  
=
=
N
1i
'ijij'jj kkB  , soit en notations matricielles : C= K 
tK et B= tK K 
 
Propriété n°2 : Egalité des Normes de Frobenius des matrices de  Condorcet et de  Burt 
        De ces relations précédentes on tire  la relation « unificatrice » suivante : 
 
  
= === = === = == =
=
















=




















=
P
1j
P
1'j
2
'jj
N
1'i
'j'ij'i
P
1j
P
1'j
N
1i
'ijij
P
1'j
'j'i'ij
N
1i
N
1'i
P
1j
j'iij2'ii
N
1i
N
1'i
BkkkkkkkkC  
 soit :  
(f 15)                                                 

= == =
=
P
1j
P
1'j
2
'jj
2
'ii
N
1i
N
1'i
BC
 ,  
En d’autres termes la somme des carrés des termes généraux des deux tableaux sont 
égales. Ce qui,  en termes matriciels,  est équivalent à l’égalité du carré des normes de 
Frobenius associées : 
                                                               
2
F
2
F
CB =    
 
 
 
 
 
 
 
 
 
3 Les Quantités de Base du Calcul des Similarités 
   Quelle que soit la façon dont les données sont prises en compte ou mises en matrices 
adéquates : (NxP, Nxm, NxN), l’information de base, quand on travaille  sur les similarités 
entre deux  « objets » x et y, revient  à calculer les 4 quantités suivantes : représentables 
dans un tableau de contingence (2x2) : 
Si l’on note les deux vecteurs de représentation d’un objet x  et d’un objet y  : 
( ) Pà1devariantj.,.,...x,..xx,xx Pj21= ,  ( ) Pà1devariantj.,.,...y,..yy,yy Pj21=  
En posant « xj  » le fait que pour la modalité « j », x  vaut 1, et (1-xj ) le fait que x vaut 0  
alors les quantités suivantes caractérisent l’ensemble de tous les cas possibles de combi-
naisons vectorielles associées:   
 
 
 
 
RNTI-A-3 - 220 -
                                                                                                    F. Marcotorchino 
 
  
 
1. Nombre de «matchings » de x sur  y   =>         
j
P
1j
jyxy)11(x, 
=
=
 
où  11(x,y)4 représente les configurations où  x et y valent 1 simultanément 
2. Nombre de «non matchings » de x sur y =>     )y)(1x(1y)00(x,
P
1j
jj
=
−−=
 
où  00(x,y) représente les configurations ou x et y  valent simultanément 0 
3. Nombre d’erreurs en y de x sur y     =>           )y(1xy)10(x,
P
1j
jj
=
−=
 
où  10(x,y) représente le nombre de configurations où   x  vaut 1 et y vaut  0 
4. Nombre d’erreurs en x  de x sur y     =>     
=
−=
P
1j
jj )yx(1y)01(x,
 
où  01(x,y) représente le nombre de configurations où   x  vaut 1 et y vaut  0 
5. De la même façon , on voit que : 

===
=−+=+=
P
1j
jj
P
1j
jj
P
1j
j x)y(1xyxy)10(x,y)11(x,x)11(x,   
cette somme représente le nombre de valeurs pour lesquelles x =1, on note par convention 
11(x,x) cette quantité. 
6. A l’identique, on a :                       

===
=−+=+=
P
1j
jj
P
1j
jj
P
1j
j yy)x(1yxy)01(x,y)11(x,y)11(y,   
 qui représente le nombre de valeurs pour lesquelles y =1, on note par convention 11(y,y) 
cette quantité. 
 
Ceci étant représentable sous la forme du  tableau de contingence, dit :« Tetrachorique » 
suivant : 
 
 
 
 
 
 
 
 
 
                                                 
4
 Par la suite pour alléger les notations,  on identifiera le vecteur )...x,..xx,(xx Pj21=

 à x, puis, au lieu de noter, 
)y,x11(  , le nombre de matchings on se contentera de la forme 11(x,y), par extension on identifiera x et son profil 
vectoriel, sous la lettre générique « x ». Enfin pour lier les deux notations vues précédemment,  on aurait pu écrire 
en identifiant  x à « i » et « xj » à « kij » :          
==
==
P
1j
yjxj
P
1j
ji'ij kkkky)11(x,
  
 
y = 1 y = 0 
x = 1 11(x,y) 10(x,y) 
x = 0 01(x,y) 00(x,y) 
RNTI-A-3- 221 -
Essai de Typologie Structurelle des Indices de Similarités  
4 Processus  de Structuration des Indices  
       Dans la forme calculable des indices de similarité, le fait avéré est que toutes les quan-
tités du tableau de contingence  (Tetrachorique) précédent, ne jouent pas un rôle équiva-
lent, et que suivant le poids accordé à l’une ou l’autre de ces quantités, on tombe sur des 
formes différentes et des constructions différentes d’indices. Nous insisterons de façon 
répétée sur la valeur et les propriétés de ces indices dans le cas de recodage sous forme 
disjonctive complète entre les profils d’ individus  {Oi} mesurés sur des  variables catégo-
rielles. Les Groupe I  et Groupe II dont il va être question dans les pages qui suivent se 
distinguent par le fait qu’ils font ou  ne font pas jouer un rôle à la quantité 00(x,y).  
 
4.1 Indices du Groupe I, donnant priorité aux structures 11(x,y) et ne 
faisant jouer aucun rôle à 00(x,y) 
4.1.1 Indices du Groupe I, Type I (indices obtenus par ratios directs)  
4.1.1.1 Indice de Dice –Czekanowski (1945-1913) 
    Cet indice, bien qu’introduit initialement par Czekanowski en 1913 dans la théorie des 
matrices de confusions,  puis redécouvert en 1920 par H.A. Gleason (dans le domaine de 
la botanique), a surtout été étudié  par L.R. Dice (1945) (utilisé par lui en botanique et en 
phylogénie, en tout cas c’est sous son nom qu’il est présenté aujourd’hui). Quoique ces 
auteurs l’aient introduit séparément, et pour des besoins justifiés dans leur discipline de 
spécialité respective,  aucun d’eux  n’a explicité  et compris le rôle central et globalisant 
de cet indice dont on verra par la suite le caractère fondamental dans la structuration des 
indices de similarité, d’autre part nous montrerons que sous certaines conditions il est 
équivalent à la notion de mesure majoritaire de comparaisons (due à A. de Condorcet en 
1785). Il s’exprime au travers de la  formule :   
 
(f 16)                
[ ] y)01(x,y)10(x,y)2.11(x,
y)2.11(x,
y)01(x,y)10(x,
2
1y)11(x,
y)11(x,y)(x,Sd
++
=
++
=
 
En fonction des quantités introduites au § 3, il s’écrit également du fait que:  
11(x,x)=11(x,y)+10(x,y) et  11(y,y)=11(x,y)+01(x,y), 
 d’où            11(x,x)+11(y,y) = 2.11(x,y)+ 10(x,y)+ 01(x,y): 
 
 (f 16’)           
 

= =
=
+
=
+
= P
1j
P
1j
jj
P
1j
jj
d
yx
yx2
y)11(y,x)11(x,
y)2.11(x,y)(x,S
 
De ce fait ,  la quantité dd (x,y)=1-Sd (x,y) s’écrit: 
                  
 

= =
=
+
== P
1j
P
1j
jj
P
1j
2
jj
dd
yx
)y-(x
y)(x,S-1y)(x,d
 
on voit  que dans le cas où  : ∀ x, 11(x,x)= 11(y,y)= Constante =μ,   l’indice de Dice s’écrit:  
RNTI-A-3 - 222 -
                                                                                                    F. Marcotorchino 
 
(f 16”)            
y)(x,
2
11

y

x
2
11
2.
)y-(x
1y)(x,S 2
2
P
1j
jj
P
1j
2
jj
d −=








−−=−= 

=
=
 
 
Il apparaît clairement que dans cette configuration où la somme en ligne des “1” de tous 
les vecteurs x,y,z... est une constante, l’indice de Dice s’exprime bien sous la forme  
S=1- (½) δ2, où δ2 est le carré d’une distance euclidienne, d’après le Théorème de Schoen-
berg-Gower  (voir axiome n°4, §  1.1), Sd(x,y) est donc un indice métrisable euclidien. 
4.1.1.2 Indice de Jaccard (1908) 
     Cet indice, l’un  des tous premiers  indices à avoir été décrit dans la littérature scienti-
fique par Paul Jaccard (1908) (ressortissant suisse du canton de Vaud, spécialiste de la 
phylogénie des plantes), est une variante du précédent, bien que découvert auparavant, il 
s’écrit : 
 
 (f 17)          [ ])y,x(01)y,x(10)y,x(11
)y,x(11)y,x(Sj
++
=
 
Il s’écrit aussi sous une forme très connue des spécialistes du traitement du langage natu-
rel: 
 
  (f 17’)        
)y,x(11)y,y(11)x,x(11
)y,x(11)y,x(Sj
−+
=    
En effet, comme nous l’avons vu au § 3:  11(x,x)=11(x,y)+10(x,y) et  11(y,y)=11(x,y)+01(x,y), 
d’où 11(x,x)+11(y,y)=2.11(x,y)+10(x,y)+01(x,y),  d’où l’obligation de soustraire 11(x,y) au 
dénominateur.  
 
Si nous explicitons cet indice grâce aux expressions développées du §.3. nous obtenons:         
  

= = =
=
−+
=
+
= P
1j
P
1j
P
1j
jjjj
P
1j
jj
j
yxyx
yx
y)11(x,-y)11(y,x)11(x,
y)11(x,y)(x,S
 
et l’indice de distance associé s’écrit: 
  

= = =
=
−+
== P
1j
P
1j
P
1j
jjjj
P
1j
2
jj
jj
yxyx
)y-(x
y)(x,S-1y)(x, d
 
 
4.1.1.3 Indice d’ Anderberg (1961) 
      Cet indice est l’un  des plus récents de la famille des indices de Type I, puisqu’il a été 
introduit d’abord en 1958 par  R.R. Sokal et P.H.A. Sneath, (à qui nous attribuerons un 
indice du Groupe II (voir § ultérieurs),   puis redécouvert ensuite par  M. R. Anderberg en 
1961, voir Anderberg (1961).  Il a été introduit  beaucoup  plus tard  que les deux précé-
dents (lesquels étaient plus intuitifs et correspondaient à des règles de similarité plus lo-
giques et plus simples),  ce n’est, lui aussi, qu’une variante de celui de Dice, lorsque l’on 
donne plus de poids aux situations de non concordance. 
RNTI-A-3- 223 -
Essai de Typologie Structurelle des Indices de Similarités  
Il s’écrit :                                                                                  
         
 (f 18)            [ ])y,x(01)y,x(102)y,x(11
)y,x(11)y,x(San
++
= 
4.1.1.4 Indice de Sørensen (1960) 
      Cet indice a été introduit par Thorvald  Sørensen, ce dernier, souvent cité comme co-
inventeur en (1948) avec Dice de l’indice qui porte son nom est également l’auteur en 
1960 d’une variante, donnée ci dessous,  variante des  indices de Type I,  avec une défini-
tion très voisine de celle de l’indice de Dice, mais en donnant moins de poids   aux situa-
tions de « non concordance ». Il s’écrit :  
                                                                             
(f19)             
[ ])y,x(01)y,x(10
4
1)y,x(11
)y,x(11)y,x(Sso
++
=

cet indice  semble un peu   “ tiré par les cheveux”  à première  vue, mais réécrit comme 
celui de Jaccard en fonction des quantités 11(x,x) et 11(y,y)  il gagne en signification en 
effet on a  :    
 
(f 19’) 
                     
[ ] [ ])y,x(11.2)y,y(11)x,x(11
)y,x(11.4)y,x(Sso
++
=
    
               
Tous ces indices  sont des variantes par rapport au poids donnés aux structures 
(10(x,y)+01(x,y)), en effet :  Dice = ½,   Jaccard = 1, Anderberg =  2 ; Sørensen = ¼ , il 
manque par symétrie à celui de Dice,  un indice dont les le poids serait de 1/8 pour  la 
configuration  globale de non concordances : Nous appellerons cet indice, l’indice d’  
« Anderberg Complémentaire »  Sac, il sera défini par :   
4.1.1.5 Indice d’ « Anderberg Complémentaire » 
      Cet indice est introduit « artificiellement » ici,  comme indice complémentaire et sy-
métrique de celui qu’ avait proposé en 1961, M. Anderberg (1961), , d’où le nom que nous 
lui donnons,  pour des raisons d’équilibrage. 
(f20)              
[ ])y,x(01)y,x(10
8
1)y,x(11
)y,x(11)y,x(Sac
++
=
 
4.1.2 Unification Homographique des Indices de Type I 
      L’ensemble des  différents indices connus,  appartenant au Groupe I :Type I, peut se 
définir   à partir de fonctions homographiques de l’indice de Dice  (c’est cette propriété 
que nous avions déjà décrite dans F. Marcotorchino , P. Michaud (1981), étudiée et reprise 
dans l’article fort structuré de S Joly et G. Le Calvé (1994), publié chez Springer-Verlag  
dans le livre  complet sur  la « Dissimilarity Analysis », édité par B. Van Cutsem (1994).  
En effet en exprimant la quantité (10(x,y)+01(x,y)) par rapport à 11(x,y) et à l’indice de Dice 
on trouve :    
RNTI-A-3 - 224 -
                                                                                                    F. Marcotorchino 
 
           
( )[ ]
)y,x(S
)y,xS1)y,x(11.2)]y,x(01)y,x(10[
d
d−
=+
 
En remplaçant la quantité de « non concordance »,  précédente par son expression en fonc-
tion de Sd(x,y) dans les formules relatives à chaque indice, la quantité 11(x,y) disparaît et 
l’on obtient des expressions ne dépendant que de Sd(x,y):  
 
 
 
 
(f 21)               
)y,x(S2
)y,x(S)y,x(S
d
dj
−
=
           et réciproquement        
)y,x(S1
)y,x(S.2)y,x(S
j
j
d
+
=
 
De la même façon on a pour Anderberg: 
(f 22)                  
)y,x(S.34
)y,x(S)y,x(S
d
d
an
−
=
            et réciproquement         
)y,x(S.31
)y,x(S.4)y,x(S
an
an
d
+
=
 
 
De même, il vient pour l’indice de Sørensen : 
(f 23)                  
1)y,x(S
)y,x(S.2)y,x(S
d
d
so
+
=
             et réciproquement          
)y,x(S2
)y,x(S)y,x(S
so
so
d
−
=
 
 
Enfin pour l’indice d’Anderberg «  Complémentaire », on obtient:  
 
(f 24)           
1)y,x(S.3
)y,x(S.4)y,x(S
d
d
ac
+
=               et réciproquement                 
)y,x(S.34
)y,x(S)y,x(S
ac
ac
d
−
=
 
 
 
  Du fait que ces indices du Groupe I,  Type I, soient tous fonction homographique de 
l’indice de Dice, nous permet de les représenter sur un diagramme unique, où l’on peut 
voir de façon simple comment ils se comportent et comment ils varient les uns par rapport 
aux autres. Par ailleurs bien évidemment tous ces indices varient de 0 à 1, ce que nous 
constatons sur le graphique :  
 
 
 
                                                                     0 ≤ Sα(x,y) ≤ 1 
       
                     
 Ces indices valent 0 si le nombre de  concordances (« matchings ») entre  x et y 
est égal à 0  11(x,y)=0 
 Ils valent 1 si la quantité 10(x,y)+01(x,y) = 0  x et y ont le même profil de 1 et de 
0   
 Ils ne sont pas définis (division par zéro) si 11(x,y)=10(x,y)=01(x,y) =0, c’est à 
dire si 00(x,y) = P . On peut par extension proposer des valeurs d’extension aux 
différents indices cités,  dans ce cas, pour éviter ces situations d’indétermination 
ou d’ambiguïté.  Les situations où le profil de deux individus « i » et « i’ » n’ont 
aucune valeur « 1 » présentes dans leur profil sont  exceptionnelles.  C’est à cette 
RNTI-A-3- 225 -
Essai de Typologie Structurelle des Indices de Similarités  
problématique rare mais  néanmoins possible que Mattijs J. Warrens (2008) 
s’attaque dans un article très récent Mars 2008,  de la Revue « Journal of Classi-
fication ».       
 
0,0
0,2
0,3
0,5
0,7
0,8
1,0
0,0
0
0,0
5
0,1
0
0,1
8
0,2
5
0,3
3
0,4
2
0,5
0
0,5
8
0,6
6
0,7
5
0,8
2
0,9
0
0,9
5
1,0
0
Anderberg
Jaccard
Dice
Sorensen
AnderCom
         Figure 1: Graphique de variation des indices du Groupe I,  Type I 
 
On constate sur ce graphique que la courbe de l’indice de Dice est la bissectrice du gra-
phique, l’indice d’Anderberg  est le symétrique, par rapport à la bissectrice (indice de 
Dice), de l’indice d’ « Anderberg Complémentaire », l’indice de Sørensen est le symé-
trique de l’indice de Jaccard par rapport à cette même bissectrice. 
D’autre part, dans le cas où les données de similarités sont calculées sur des tableaux dis-
jonctifs complets (c’est ce qui se produit en AFCM (Analyse factorielle des correspon-
dances multiples), ou en AFR (Analyse Factorielle Relationnelle)), on a de plus, les pro-
priétés supplémentaires suivantes:  
 
 
Propriété  3 : Relation avec la Valeur Disjonctive de la Distribution 11(x,y) 
     Dans le cas où les données (0-1) sont issues de tableaux disjonctifs complets ou de 
tableaux de « présence-absence »  dédoublés, voir remarque du § 2-2,   on a la propriété 
suivante : 
(i)  10(x,y) = 01(x,y) 
(ii) (10(x,y) +  01(x,y))  =   2m – 2.11(x,y)  (cas des variables disjonctives) 
(ii’) d’où compte tenu de (i) 10(x,y)=01(x,y)=m-11(x,y)  
(iii) (10(x,y) +  01(x,y))  =  P – 2.11(x,y) (cas des variables « présence - absence »  dé-
doublées) (avec 2m=  P) 
La démonstration est très simple, en effet, on sait que sur un tableau disjonctif complet le 
nombre de 1 par ligne est une constante, il  est égal à « m », nombre de variables initiales.   
Dès lors  à toute présence de 1 dans le vecteur de x,  correspond un 1 ou un 0 dans le profil 
de y . 
• Si à 1 de x correspond un 1 de y, cette concordance est comptée dans 11 (x,y) 
RNTI-A-3 - 226 -
                                                                                                    F. Marcotorchino 
 
• Si à 1 de x correspond un 0 de y, cette concordance est comptée dans 10 (x,y) 
• Si à 0 de x correspond un 1 de y, cette concordance est comptée dans 01 (x,y)   
 
A toute « non concordance » de x sur y, correspond par symétrie une « non concordance de y sur x.  
Du fait que la somme des « 1 » pour chaque individu est une constante m, le nombre  de non con-
cordances, soit (10(x,y)+01(x,y))  est compté deux fois dans la somme totale m, d’où le résultat : 
            (iv)  [ ] m)y,x(01)y,x(10
2
1)y,x(11 =++  
d’où  évidemment les formules (i) et (ii) 
De ce fait l’indice de Dice  se simplifie en :                                                   
 
(f 25)                           
m
)y,x(11)y,x(Sd = 
En utilisant les formules  (i) et (iii), il vient pour les autres indices   après simplification et 
division du numérateur et dénominateur par m   et application de (iii) :  
 
         
(f 26)                             
)y,x(11m.2
)y,x(11)y,x(Sj
−
=                                                     
        
de la même façon on a: 
 
(f 27)                          
)y,x(11.3m.4
)y,x(11)y,x(S. an
−
= 
                                    
De même, il vient pour les indices de Sørensen  et d’ « Anderberg Complémentaire »: 
 
 
(f 28)                        
)y,x(11m
)y,x( 11.2)y,x(Sso
+
=  
                                       
                               
(f 29)                       
)y,x(11.3m
)y,x(11.4)y,x(Sac
+
=

                             
 
            
Propriété 4 : Comparaison  des Indices précédents par Rapport à la Règle Majoritaire de 
Condorcet 
Si nous utilisons la formule  donnant la définition d’un tableau de Condorcet, dans le cas 
de la somme de la représentation de variables « linéaires » (approche disjonctive),  on 
constate que la  règle majoritaire,  donnée  par : 
2
mC
'ii ≥  est équivalente à :    2
1)'i,i(Sd ≥                  
RNTI-A-3- 227 -
Essai de Typologie Structurelle des Indices de Similarités  
En effet   puisque, d’après la formule (f 25)    
m
)'i,i(11)'i,i(Sd = en remplaçant x par i , et y par 
i’  car 11(i,i’) n’est rien d’autre que :  
                                 
=
=
P
1j
j'iij'ii kkC  (vue précédemment (f 5))  
si l’on remplace dans les notations du §2.2,  xj  par kij   et yj  par ki’j ,  dès lors :   Sd (i,i’) =
m
C
'ii 
   
(cqfd).  
 
 
 
 
 
Remarque n°3 : Application directe de la Règle de « Solomon-Fortier » (définie au §1.1-5) : Au 
niveau indiciel si l’on applique la règle de  Solomon et Fortier ,(voir Solomon et Fortier  (1966)),  
de façon formelle, cette règle stipule simplement que : quelque soit l’indice de similarité S(x,y) ou 
S(i,i’) considéré, on dira que deux objets « x et y » ou « i et i’ » sont en relation de « similarité au 
sens de Solomon - Fortier » si :    
2
1)'i,i(S ≥   , ou plus généralement si un indice S varie de « a » à  
« b »  b)'i,i(Sa ≤≤ ,  la règle dit que i et i’ seront en relation de « similarité » si : 
2
ba)'i,i(S +≥ , 
où 
2
ba +
 est le « milieu » de l’intervalle de variation. La borne à ½   précédente est due au fait que 
a = 0 et b=1, puisque le milieu de l’intervalle de variation correspondant est d’évidence égal à  ½. 
Ainsi si : 
                
2
mCalors
2
1)'i,i(S
'iid ≥≥
  (règle de la majorité usuelle5, ou Condorcéenne) 
 
 
 
Ceci s’interprète en disant que pour que deux objets « i et i’ » soient considérés comme 
semblables au sens de la règle de Solomon et Fortier, il faut qu’ils soient semblables  pour 
une majorité de variables. 
 
 
                                                 
5
 Il est d’ailleurs intéressant à ce propos de voir que l’Indice de Similarité de Gower (que ce dernier a introduit en 
1971 ,J. C.  Gower (1971)) qui s’écrit : k
xy
k
k
k
k
G Sw
w
1y)(x,S 
=
est une variante pondérée de l’approche 
Condorcéenne. 
RNTI-A-3 - 228 -
                                                                                                    F. Marcotorchino 
 
 
 
 
Si nous  interprétons ce résultat sur une échelle « peu sévère » <==> « sévère », par rap-
port à la règle de Solomon et Fortier, il vient : 
 
 
Peu Sévère   =======================Medium===========================Sévère  
 Ander Comp…..         Sørensen      ………   …...Dice………        ..  .Jaccard…………         Anderberg 
 
 
 
Pour le lecteur intéressé, on trouvera dans S. Joly et G. Le Calvé (1994), dans l’article de 
B.G. Baulieu (1989), ainsi que dans le livre de I. C. Lerman (1981), une présentation  des 
propriétés de métricité,  de monotonie ou  d’autres encore  que vérifient ces indices. Notre 
propos étant ici plus de structurer et classifier l’ensemble des indices que de lister  leurs 
propriétés, nous renvoyons le lecteur à ces auteurs et à leurs articles pour de plus amples 
informations .  
 
4.1.3 Un cadre unificateur pour les indices du Groupe I-Type I : le Modèle de 
Tversky 
      Une approche unificatrice a été proposée par Amos Tversky  dans son article de fond A. 
Tversky (1977), ayant pour conséquence une formulation un peu plus complexe que celles 
des indices présentés précédemment, en particulier il permet dans sa formulation une in-
fluence non systématiquement équilibrée des quantités 10(x,y) et 01(x,y).  
 
 
De même on aura pour l’indice de Jaccard: 
2
1)'i,i(S j ≥        implique    =>     3
m.2C
'ii ≥   (règle de la majorité aux  « deux tiers ») 
Pour l’indice d’ Anderberg:  
2
1)'i,i(San ≥       implique    =>     5
m.4C
'ii ≥   (règle de la majorité aux « quatre cin-
quièmes ») 
Pour l’indice de Sørensen:  
2
1)'i,i(Sso ≥        implique    =>     3
mC
'ii ≥   (règle de la majorité au « tiers ») 
Pour l’indice de Andersen Complémentaire  
2
1)i'(i,Sac ≥     implique     =>     5
mC
'ii ≥   (règle à la majorité au « cinquième ») 
RNTI-A-3- 229 -
Essai de Typologie Structurelle des Indices de Similarités  
L’indice généralisé de Tversky s’écrit :  
 (f 30)                         
y)01(x,y)10(x,y)11(x,
y)11(x,)y,x(S Ty
++
=
 
        avec :                                          α et  β ≥0 
On a bien :                                     0 ≤ STy (x,y) ≤1  
Cet indice varie de 0 à 1 est est donc un indice « normé », en effet il vaut 1 si 
10(x,y)=01(x,y)=0 et il vaut 0 si 11(x,y)=0. Il n’est pas défini si 11(x,y)=10(x,y)=01(x,y)=0 (voir la 
remarque citée page 23 sur les travaux de Mattijs Warrens(W2008))  
ll semble que la non symétrie de l’influence  des quantités 01(x,y) et 10(x,y) trouve un do-
maine particulièrement intéressant d’applications en recherche de « similarité moléculaire » 
en pharmacodynamique, et peut-être dans les essais cliniques, voir à ce propos le rapport de 
John Bradshaw de la Société Pharmaceutique  ‘Glaxo Wellcome’, J. Bradshaw (1997).  En 
effet la question à poser peut  prendre  deux formes  différentes, nous citons ici son rapport :  
   “There are two forms of question which we can ask, 
1. Assess the degree to which object x  and object y are similar to each other.  
2. Assess the degree to which object y  is similar to object x”.  
À la question de type 1., correspond un équilibre de l’influence , de ce fait :  =  , à la ques-
tion 2. peut correspondre un déséquilibre de x vers y d’où :    , voici d’ailleurs le texte 
complet de J. Bradshaw : “In this case the query is directional and we are more interested in 
the features in molecule x than we are in the features unique to molecule y,  and  , do not 
need to be equal. Molecule x may be regarded as the prototype and molecule y as the vari-
ant”. Cependant  comme il est d’ailleurs remarqué dans le texte de J. Bradshaw,  plus expé-
rimental que théorique, on se retrouve facilement, même dans ce contexte élargi, à utiliser 
l’indice de Dice ou celui de Jaccard, sans oublier bien entendu les indices extrêmement con-
nus que l’on découvrira, présentés  et étudiés en détail au § 4.1.3. et qui sont dissymétriques 
par essence, à savoir :  les indices de « Précision  P » et de « Rappel :R », donnés par : 
)y,x(10)y,x(11
)y,x(11P
+
=
  et   
)y,x(01)y,x(11
)y,x(11R
+
=
 
Propriété n°5 : Equivalence de l’ « Indice de Tversky » et de l’  « Indice de Van Rijsbergen »  
Ace propos, il est intéressant de noter que dans le cas particulier où  α + β = 1 dans la formule 
(f 30), un indice cité dans l’article de C. Michel (2000) et connu sous le nom d’ « Indice de 
Van Rijsbergen », introduit par ce dernier  dans un livre faisant référence chez les spécia-
RNTI-A-3 - 230 -
                                                                                                    F. Marcotorchino 
 
listes de l’analyse documentaire Van Rijsbergen (1979)  et qui s’exprime par rapport aux 
indices de Rappels et de Précision  sous la forme : 
 (f 30’)                        1avec
RP
P.Ry)(x,S vr =+
+
=
 
est totalement équivalent  en remplaçant P et R par leur valeurs données précédemment, à 
l’indice de Tversky, puisque après simplifications on a :   
  1avec
y)01(x,y)10(x,y)11(x,)(
y)11(x,
RP
P.Ry)(x,S vr =+
+++
=
+
=
 
et comme α+β=1 , on retrouve6 bien l’expression de l’Indice de Tversky. Conclusion si  
l’initiative de Tversky est intéressante pour avoir permis une justification de la dissymétrie 
d’influence, on connaît peu d’indices dissymétriques ayant eu une utilisation généraliste 
suffisante  pour figurer comme des indices standard. En effet peu  (voire pas) d’indices de 
type I (modèle de Tversky)  avec   ,  autres que ceux qui ont été créés pour des applica-
tions  particulières  et spécifiques ont obtenu un statut d’indices  « connus » généralisables  
dans la littérature scientifique.   
Le cas des indices SMax (x,y) (Indice de Simpson (1943)) et  SMin (x,y) (Indice de Braun-
Blanquet (1932)) rentrent également comme cas particuliers du modèle de Tversky, au 
sens que, par exemple, l’indice de Simpson qui s’écrit : 
y))y),01(x,Min(10(x,y)11(x,
y)11(x,
y))01(x,y)y),11(x,10(x,y)Min(11(x,
y)11(x,R)Max(P,y)(x,SSimpson +=++==
est équivalent à l’Indice de  Précision  si 10(x,y) ≤ 01(x,y) 
est équivalent à l’indice de  Rappel     si 01(x,y) ≤ 10(x,y) 
On peut tabuler par rapport aux différentes valeurs   de α et β , les indices qui relèvent de l’approche 
« Tverskienne », on obtient :  
                    
                              β 0 1/2 1 2 
0 Pas de sens Comparaison à  y 
Indice de 
« Rappel » ? 
1/2 Comparaison à 
x 
Dice On prédit* plus y que x ? 
1 Indice
7
 de 
« Précision » 
On prédit plus 
x que y Jaccard  
                                                 
6
 On remarque une fois encore ici,  que des indices ont été redécouverts par des auteurs différents au fil du temps, 
sans qu’aucune tentative de rapprochements avec des formalismes pré existants  n’ait été proposée.    
7
 Les indices de Rappel et de Précision sont définis explicitement et en extension au § 4-2. 
 
 
RNTI-A-3- 231 -
Essai de Typologie Structurelle des Indices de Similarités  
(*) exemple d’un tel indice : le ratio suivant :      
                                      
[ ] y)01(x,
2
1y)01(x,y)10(x,
2
1y)11(x,
y)11(x,y)(x,S
+++
=
 
dont le dénominateur est voisin de celui de Dice,  mais pondère davantage que dans Dice les 
situations d’erreurs 01(x,y) . En cas de disjonction complète, cet indice particulier de la fami-
lle Tversky vaut:  
                                                   
y)11(x,3.m
y)2.11(x,y)S(x,
−
=
 
Ce qui montre  qu’il  est bien intermédiaire entre l’indice  de Jaccard et celui de Rappel, par 
ailleurs sa borne de Solomon-Fortier donne une majorité au 3/5 ème: 
                                                   
m
5
3y)11(x,
2
1
y)11(x,3.m
y)2.11(x,y)S(x, ≥≥
−
=
 
4.1.4 Propriétés des Indices du Type I dans les cas de Disjonction des Variables 
     Il est important de comprendre à ce moment précis du discours que la disjonction com-
plète permet des simplifications considérables des propriétés des indices. En effet dans un 
souci de généralité, rappelons que le seul cas qui n’entre pas dans la catégorie de situations à 
« disjonction complète », est le cas de données de « présence-absence » pures. Cependant, 
nous avons vu que, dans ce cas, par un artifice logique qui consiste à dédoubler chaque pa-
ramètre de description par son inverse (où à 1 pour le dit paramètre correspond 0 de l’inverse, 
et vice versa), on se ramène à une situation de disjonction complète, avec P nombre total de 
descripteurs,  donné par P=2m (où m est le nombre de descripteurs initiaux et P le nombre 
nouveau de descripteurs après l’action de dédoublage. De ce fait le recours aux propriétés 
engendrées par la structure de disjonction complète devient un passage obligé qui prend toute 
son importance.   
Ainsi les propriétés que nous allons proposer sont-elles quasi générales . 
4.1.4.1 Liste de propriétés des Indices du Type I  dans les Cas de Disjonction  des Va-
riables 
Dans le cas particulier de tableaux disjonctifs complets, l’indice de Dice (du fait de son 
entière similitude à la constante « m » près, avec le tableau de Condorcet) vérifie la pro-
priété de « transitivité  généralisée» suivante (voir § 1.1 sur l’axiomatique) : 
 
Propriété n°6 : L’Indice de Dice vérifie la propriété de « Transitivité Généralisée Indicielle »  
 
(f 31)                        zy,  x,   1z)(x,Sz)(y,Sy)(x,S ddd ∀≤−+   
Il suffit pour cela de diviser la formule (f 6) relative au tableau de Condorcet par  «m» . 
Par ailleurs, nous avions vu ( voir formule (f 16″) que lorsque le nombre de « 1 » du profil 
de x,  ∀ x , était une constante, alors: 
                                     Sd(x,y)= 1-1/2d2(x,y) (où d2 (x,y) est une métrique euclidienne) 
Comme dans le cas de la disjonction complète, nous avons 11(x,x)=m,  ∀ x, nous sommes 
tout à fait dans un cas d’application de cette formule (f 16″). Nous venons de montrer en 
RNTI-A-3 - 232 -
                                                                                                    F. Marcotorchino 
 
utilisant le recours à l’écriture Condorcéenne une autre façon de voir que   l’indice de Dice  
était métrisable car il vérifie la TGI (Transitivité Généralisée Indicielle)  
 
Propriété n°7 : L’Indice de Jaccard vérifie la propriété de « Transitivité Généralisée Indi-
cielle »  
De la  même façon en remplaçant la valeur de l’indice de Dice par son expression homo-
graphique en fonction des autres indices, il vient  par exemple la relation suivante pour 
l’indice de Jaccard :  
(f 32)        [ ][ ][ ] zy,x,   3z)(x,S z)(y,S1 y)(x,S1
4
1
 -  1z)(x, Sz)(y,Sy)(x,S jjjjjj ∀+−−≤−+    
En fait l’indice Sj vérifie bien la « transitivité généralisée indicielle » (donc est métrisable) 
car « 1 » est bien une borne du premier membre de (f 32) , en effet  la quantité 
 ¼(1- Sj (x,y))(1- Sj(y,z))( Sj(x, z)+3)  est toujours positive du fait que Sj(x,y) ≤ 1 ∀  « x et y » .  
 
En fait pour démontrer ce résultat de façon directe  et très facilement, il suffisait  d’utiliser 
le  Théorème n°1 qui stipule que  si un indice Su(x,y)  s’exprime sous la forme :  
                                                     
1y)](x,S[1
y)(x,S
y)(x,S
d
d
u
+−
=
  
par rapport à un indice métrisable  Sd (x,y),  alors  il est lui même « métrisable » .   
En fait l’indice de Dice étant métrisable, comme l’indice de Jaccard s’écrit (voir formule  
(f 21)) 
)y,x(S2
)y,x(S)y,x(S
d
dj
−
=
 , il vérifie les conditions  d’applications du Théorème n°1, avec 
β=1  dans ce cas,  (cqfd) .  
Donc  Sj(x,y)  est  métrisable.  
Quoiqu’on puisse se passer d’utiliser l’inégalité (f 32) pour obtenir ce résultat, l’inégalité 
(f 32) nous permet  néanmoins de déduire  une relation très surprenante sur l’indice de 
distance dj(x,y)=1-Sj(x,y)  associé, en effet en remplaçant :  Sj(x,y) par 1-dj(x,y) , il vient : 
 
(f32’)          
zy,x, z)(x,z).d(y,y).d(x,d
4
1
  z)(y,y).d(x,d - z)](y,dy)(x,d [z)(x,d jjjjjjjj ∀++≤  
soit encore:  
(f 33)                            
zy,x,
z)(y,y)d(x,d
4
11
 z)(y,y).d(x,d - z)](y,dy)(x,d [
z)(x,d
jj
jjjj
j ∀
−
+
≤
                         
 Sous cette forme, on voit que le deuxième membre de cette inégalité est indépendant de 
dj(x,z). En effet comme chacune des valeurs d(x,y) et d(x,z) ≤ 1,  de fait  la division par  
 (1-1/4dj(x,y)dj(y,z)) qui est une valeur > 0, donc différente de 0, est possible. Ceci permet 
d’avoir une borne meilleure que celle de l’inégalité triangulaire  usuelle.  
  
La soustraction par une quantité positive permet dans les formules (f 32), (f32’) et (f33)  
d’avoir une borne plus fine permettant souvent l’obtention d’une égalité comme le montre 
le petit exemple suivant : 
 
 
 
 
 
RNTI-A-3- 233 -
Essai de Typologie Structurelle des Indices de Similarités  
 
x 1 0 0 0 1 0 1 0 0 0 1 
y 1 0 0 0 0 1 1 0 0 0 1 
z 0 1 0 0 0 1 0 1 0 0 1 
 
 
Ici on a affaire à 4 variables  disjonctivées (ayant respectivement : 3; 3; 3; et 2 modalités), d’où m=4 
L’indice de Jaccard entre les différents individus vaut : 
Sj(x,y) = 3/5 ;  Sj(y,z) =  2/6;  Sj(x,z) =1/7 
Le premier membre de l’inégalité vaut : 3/5 +2/6 -1/7 = 166/210 
Le deuxième membre de l’inégalité vaut 1 – ¼( 2/5.4/6. 22/7)= 1-44/210= 166/210 
De même au niveau de la formule (f 29″) il vient : 
                                      7
6
28
24
6
4
5
2
4
1
6
4
5
2
6
4
5
2
7
6
1
==
××−
×−+
≤   
Ce qui montre que dans ce cas, les inégalités précédentes deviennent des  égalités.  
Nous avions d’ailleurs  une égalité dans le cas de la formule valable pour l’indice de Dice puisque 
pour cet exemple :  
Sd (x,y) = ¾ ;  Sd(y,z) = ½;  Sd(x, z) = ¼ , d’où puisque ¾+½ -¼ =1, 
on a bien :  
   1z)(x,Sz)(y,Sy)(x,S ddd =−+   
En fait on peut démontrer que si l’inégalité (f 31) est une égalité alors l’inégalité (f 33) sera égale-
ment une égalité . 
  
Comme précédemment  pour l’indice de  Jaccard , en jetant un oeil à la formule  (f 21) on 
voit que l’Indice d’Anderberg s’écrit comme une fonction homographique particulière de 
l’indice de Dice, à savoir : 
)y,x(S.34
)y,x(S)y,x(S
d
d
an
−
=
, dans ce cas,  en appliquant de nouveau  le 
Théorème n°1  (page 3)  on voit que cet indice  vérifie les conditions d’applications du 
Théorème n°1, avec une valeur de β=3. . De ce fait l’Indice d’Anderberg vérifie la proprié-
té 8 : 
Propriété n°8  :  L’indice d’Anderberg  est un indice « métrisable ».   
De plus si le terme 11(x,x)=11(y,y) est constant (exemple s’il est issu de tableaux disjonctifs 
complets), les indices de Jaccard et d’Anderberg sont métrisables euclidiens .    
 
4.2 Indices du Groupe I, Type II (indices obtenus comme fonction des 
ratios de « Rappel » et de « Précision ») 
      Par analogie  avec la « recherche documentaire », et en droite ligne avec les remarques 
liées à la présentation de l’indice général de Tversky  (dissymétrie des influences),  on 
définit les ratios dits de « Précision » « P »et de « Rappel » « R » , respectivement,  
comme les quantités: 
 
RNTI-A-3 - 234 -
                                                                                                    F. Marcotorchino 
 
  (f 34)                    
)y,x(10)y,x(11
)y,x(11P
+
=
     et
)y,x(01)y,x(11
)y,x(11R
+
=
 
En effet  supposons que nous obtenions : x comme résultat d’une recherche sur un do-
maine y,  la quantité : 10(x,y) peut être considérée comme un facteur de « bruit »,   on 
génère dans x des « items » (des valeurs 1 de x qui ne correspondent pas à ce qu’on aurait 
du  s’attendre par rapport à   y ( 0 de y correspondant à des 1 de x)), ces items parasites de x 
qui n’ont pas de correspondants dans y peuvent être considérés comme du « bruit » que  
l’on  a généré  à tort, lors d’un processus de recherche documentaire. Inversement la quan-
tité 01 (x,y) peut être considérée comme du « silence », on « rate » par x de l’existant sur y 
c’est la raison du mot « silence ». La précision est d’autant plus forte qu’on ne crée pas de 
bruit  en effet si 10(x,y)=0 la précision est maximale, inversement si le silence est égal à 0, 
si 01(x,y)=0,  le rappel est alors égal à 1, on récupère donc par les « matchings » de x 
l’ensemble de ce que l’on devait trouver sans oubli sur y. 
Bien que cette présentation des ratios P et R ne soit qu’analogique, la référence au domaine 
de la recherche documentaire, (on dirait de nos jours « recherche  Internet »), permet de se 
faire une idée concrète de la signification intuitive de ces ratios. Ayant intuitivement la 
connaissance d’une « signification » de ces ratios, nous allons voir qu’ils jouent un rôle 
important dans un certain nombre d’indices du Groupe I en particulier leurs différentes 
moyennes. On appellera Groupe I, Type II , le regroupement des indices appartenant à 
cette famille très « structurée » d’indices. 
4.2.1 Indices de Type II-A (Indices obtenus comme différentes « moyennes » des 
ratios de « rappel » et de « précision ») 
4.2.1.1 Indice de Kulczynski (1923) 
L’indice de Kulczynski a été défini par l’auteur (voir  Kulczynski (1927)) comme la 
« moyenne arithmétique » des quantités P et R. Il s’écrit donc:    
                                                                    
(f 35)            [ ] 





+
+
+
=+= )y,x(01)y,x(11
)y,x(11
)y,x(10)y,x(11
)y,x(11
2
1RP
2
1)y,x(S k  
 
A   cette occasion, on voit que si l’on note: 
 11(x,x)=Somme des valeurs “1” du profil de x   
 11(y,y)=la somme des valeurs “1” du profil de y, 
alors :  
                           [ ] 





+=+= )y,y(11
)y,x(11
)x,x(11
)y,x(11
2
1RP
2
1)y,x(S k  
 
soit encore:        [ ] 





+=+= )y,y(11
1
)x,x(11
1
2
)y,x(11RP
2
1)y,x(S k                
En posant : 
y)]11(y, x),[11(x,MH
1
y)11(y,
1
x)11(x,
1
2
1
=





+
 (moyenne harmonique des 1 de x et 
des 1 de y) 
L’indice de Kulczynski s’écrit également sous la forme suivante, sous laquelle il est éga-
lement connu:  
RNTI-A-3- 235 -
Essai de Typologie Structurelle des Indices de Similarités  
        
(f 36)                                  
)]y,y(11 ),x,x(11[MH
)y,x(11)y,x(Sk =  
Cet indice varie de 0 à 1, il vaut: 
• 1 si  10(x,y)=01(x,y)=0 
• 0 si  11(x,y)=0 
 
Propriété N°9: Propriété de l’indice de Kulczynski en cas de Disjonction complète 
Comme nous l’avons vu pour les indices du Groupe I -Type I, l’étalonnage d’un indice par 
rapport à ses valeurs en cas de disjonction complète est un moyen efficace de mesurer la 
“valeur intrinsèque” du dit indice par rapport à son pouvoir de discrimination . En effet en 
utilisant le processus suivant dans l’ordre précis  indiqué: 
a) Donner l’expression de l’indice en cas de disjonction complète, 
b) Calculer la borne induite sur la quantité 11(x,y), (seule quantité réellement variable 
du tableau de contingence dans les conditions de disjonction complète) par rapport  
à la règle de Solomon-Fortier, que nous avons indiquée précédemment 
c) Evaluer cette borne qui permet une sorte d’étalonnage pour un indice par rapport 
aux autres.   
 
Appliquons le principe:a)bc sur l’indice de Kulczynski, il vient: 
Tout d’abord rappelons les conditions que vérifient les cases du tableau de contingence Te-
trachorique si il y a “Disjonction complète”: En cas de disjonction complète on a vu en effet 
que le nombre de variables « m »  était tel que  :   
                            [ ] m)y,x(01)y,x(10
2
1)y,x(11 =++  
d’autre part on a  par définition :            P)y,x(01)y,x(10)y,x(00)y,x(11 =+++  
et bien sûr et de façon évidente :             10(x,y)=01(x,y) =m-11(x,y) 
D’où l’expression nouvelle de l’indice de Kulczynski: 
 
                         [ ] )y,x(S
m
)y,x(11
m
)y,x(11
m
)y,x(11
2
1RP
2
1)y,x(S dk ==



+=+=  
 
On reverra les conséquences qu’impliquent ce résultat au paragraphe §4.2.3.2.   
4.2.1.2 Indice d’Ochiaï (1957) 
L’indice d’Ochiai8 se définit comme la  « moyenne géométrique » des indices P et R, sa 
paternité est attribuée par Sokal et Sneath au zoologue Japonais Ochiai (1957), qui l’aurait 
introduit, comme un « cosinus » entre profils binaires  de description dichotomique en 
classification d’espèces  de poissons   dès 1957,  il s’écrit donc :  
                                                 
8
 L’indice connu sous le nom d’indice de Sorgenfrei , introduit un an plus tard que celui de Ochiaï, par T. Sorgen-
frei (1958) n’est en fait que le carré de l’indice d’Ochiaï. 2
O
2
Sorg )]y,x(S[)y,y(11)x,x(11
)y,x(11S =
+
=
 et n’a pas d’intérêt 
particulier, sinon d’être inférieur à celui de Jaccard, et bien entendu à celui d’Ochiaï. Par ailleurs, même si l’indice 
dit «  d’Ochiai »  ait été atribué à Ochiai, il semble qu’il ait été introduit antérieurement   par H. Driver  et A. 
Kroeber , voir H. Driver et A. Kroeber  (1932)  
RNTI-A-3 - 236 -
                                                                                                    F. Marcotorchino 
 
 
(f 37)                               
            
)]y,x(01)y,x(11)][(y,x(10)y,x(11[
)y,x(11R.P)y,x(So
++
==
  
 
D’autre part en utilisant  la définition des “1” de x et des “1” de y, l’indice d’Ochiai   s’écrit 
également:  
 (f 38)                    
y)]x),11(y,[11(x,MG
y)11(x,
y)x)11(y,11(x,
y)11(x,y)(x,S o ==
 
Sous cette forme, il peut s’interprêter comme un “cosinus” entre les profils de x et de y 
 
(sous cette forme, également, on voit qu’il ne différe formellement de l’indice de Kulc-
zynski, que par le choix d’une moyenne géométrique9 plutôt que d’une moyenne harmoni-
que au dénominateur). Par ailleurs la distance définie par: y)(x,S2(1y)(x,d oo −=   est ap-
pelée “distance d’Ochiai” dans la littérature10, ce qui fait de l’Indice d’Ochiai un indice 
métrisable   
 
Propriété N°10: Propriété de l’indice d’Ochiai en cas de Disjonction complète 
Comme nous l’avons vu pour l’indice de Kulczynski, appliquons à l’indice d’Ochiai le 
principe a)b)c) défini au § précédent. On obtient la nouvelle formulation de l’indice 
d’Ochiai: 
 
(f 38)                                 )y,x(S
m
)y,x(11
m
)y,x(11)y,x(S d2o ===
 
                                                 
9
 Il est intéressant de constater  dans ce cas particulier (nous l’avions déjà vu pour l’indice de Van Rijsbergen), que 
la littérature scientifique produit un nombre considérable d’articles retrouvant des évidences pour certains, et des 
progrès scientifiques  pour les autres,  comme le montre la citation suivante extraite d’un article de G.M. Maggira, 
J.D. Petke et J. Mestres, paru en  Avril 2002 dans la  Revue « Journal of Mathematical Chemistry », Vol 31, 
N°3,(MPM 2002) …  « A formalism is presented that incorporates the entirety of all field-based molecular similarity 
indices of general form Sij=Ωij/h(ii,jj), where the numerator is given by the inner product or “overlap” of field 
functions Fi and Fj corresponding to the ith and jth molecules, respectively, and the denominator is given by a 
suitable mean function of the self-similarities ii and jj. This family of similarity indices includes the index initially 
introduced by Carbó nearly twenty years ago, where h(ii, jj) is taken to be the geometric mean of ii and jj, and the 
well-known indices due to Hodgkin and Richards, and Petke, where h(ii,jj) is taken to be the arithmetic mean 
and maximum of ii and jj, respectively. Two new indices based upon the harmonic mean and minimum of ii and jj 
are also defined, and it is demonstrated that the entire set of field-based similarity indices can be generated from a 
one-parameter family of functions, called generalized means, through proper choice of the parameter value and 
suitable limiting procedures. Ordering and rigorous bounds for all of the indices are described as well as a number of 
inter-relationships among the indices. The generalization of field-based similarity indices, coupled with the relation-
ships among indices that have been developed in the present work, place the basic theory of these indices on a more 
unified and mathematically rigorous footing that provides a foundation for a better understanding of the quantitative 
aspects of field-based molecular similarity». Nous voyons que « nos amis chimistes » retrouvent des propriétés 
« indicielles » connues depuis la création des indices de Kulczynski ou Ochiai  (depuis 80 ans pour l’un et 63 ans 
pour l’autre..) 
 
 
10
 Voir en particulier page 521 du remarquable   livre de F. Caillez et J.P. Pages « Introduction à l’Analyse des 
Données » aux éditions SMASH   voir (F. Caillez et J.P. Pages (1976)) 
RNTI-A-3- 237 -
Essai de Typologie Structurelle des Indices de Similarités  
La borne étant  donnée par le milieu de l’intervalle de variation qui est: (0,1), on doit com-
parer l’indice d’Ochiai à la borne de Solomon Fortier qui vaut ici 1/2 , ceci implique : 
11(x,y) ≥ m/2 
On retrouve ici le fait que la borne de Solomon Fortier induit la règle de la majorité simple 
de Condorcet. 
   
 4.2.1.3 Indice de Moyenne Harmonique de P et R 
 
Cet indice que nous noterons Sh(x,y) correspond à la moyenne harmonique du Rappel et 
de la Précision 
Il est donc défini par:   
(f 39)                         




+=
R
1
P
1
2
1
)y,x(S
1
h
       soit en d’autres termes :  
                                                                                       
                             
y)01(x,y)11(x,
y)11(x,
y)10(x,y)11(x,
y)11(x,
y)01(x,y)11(x,
y)11(x,
x
y)10(x,y)11(x,
y)211(x,
RP
2.P.Ry)(x,S h
+
+
+
++
=
+
=
   
                            
Soit après de premières simplifications: 
 
)]y,x(01)y,x(10)y,x(11.2)[y,x(11
)y,x(11.2
RP
R.P.2)y,x(S
2
h
++
=
+
=
 
 
 
Puis en simplifiant Numérateur et Dénominateur simultanément, et les divisant par 2,  il 
vient : 
 
    (f 40)     )y,x(S
)]y,x(01)y,x(10[
2
1)y,x(11
)y,x(11
)]y,x(01)y,x(10)y,x(11.2[
)y,x(11.2)y,x(S dh =
++
=
++
=
 
 
En fait, l’indice de moyenne harmonique11 entre P et R n’est autre que l’indice de Dice, 
que nous avions déjà défini précédemment (voir formule( f16)) . 
En utilisant le passage aux « 1 » de x et « 1 » de y, on voit que l’indice de Dice peut s’écrire 
également : 
                                                 
11On  a déjà vu que l’on peut généraliser l’indice de Moyenne Harmonique c’est ce qu’a proposé C.J. Van Rijbergen  
(1979 )  en introduisant une moyenne  pondérée du type :  1 et
RP
.P.Ry)(x,Svr =+
+
=
,  (d’ailleurs on  aurait 
put le faire également pour les autres moyennes, mais l’intérêt est faible en particulier au niveau du concept sous-
jacent  et de la possibilité d’ interprétation simple des influences réciproques de P et R).   
 
 
RNTI-A-3 - 238 -
                                                                                                    F. Marcotorchino 
 
(f 41)                          
)]y,y(11),x,x(11[MA
)y,x(11
)]y,y(11)x,x(11[
)y,x(11)y,x(S
2
1d
=
+
=
 
(où MA désigne la moyenne Arithmétique des “ 1” de x et des “1” de y) , ceci, en plus des 
remarques et des propriétés introduites aux paragraphes précédents, montre bien le carac-
tère « central » de l’indice de Dice, puisqu’il était déjà membre du Groupe I, Type I.   
Comme il est connu que :  
                     Moyenne Harmonique  Moyenne Géométrique  Moyenne Arithmétique, 
Nous avons donc :  
                                      ( )RP 
2
1
   R.P     
RP
R.P2
+≤≤
+
       :  
                                
On obtient de ce fait les inégalités suivantes entre cette série de 3 indices : 
                                             y x,       )y,x(S)y,x(S)y,x(S kod ∀≤≤      
 De plus, on a également:                             
                                                     )y,x(S   )y,x(S  )y,x(S kdo =  
 
L’indice d’Ochiai est la moyenne géométrique de l’indice de Dice et de l’indice de Kulc-
zynski. 
 
Le tableau suivant récapitule les propriétés de ces 3 indices : 
 
 
 
En fonction de P et de R En fonction de 11(x,x) et 11(y,y) 
DICE MH(P,R) 11(x,y)/MA(11(x,x),11(y,y)) 
OCHIAI MG(P,R) 11(x,y)/MG(11(x,x),11(y,y)) 
KULCZYNSKI MA(P,R) 11(x,y)/MH(11(x,x),11(y,y) 
  
Si nous regardons en détail  et développons les expressions des indices d’Ochiai et de  
Kulczynski , on peut montrer que  ces deux indices peuvent s’écrire en fonction des quan-
tités     
                ²  =  (11(x,y) + ½ (10(x,y) + 01(x,y)) )² et  ² = ¼ (10(x,y)  - 01(x,y))² 
 
Selon les formules suivantes: 
 
                                  
22k 
y)11(x, )y,x(S
−
=
    et   
22o 
y)11(x, )y,x(S
−
=
  
 
 
RNTI-A-3- 239 -
Essai de Typologie Structurelle des Indices de Similarités  
4.2.2 Propriétés des indices du Groupe I, Type II-A, en cas de Disjonction Com-
plète 
Propriété n°11: Dans le cas particulier, où l’on travaille sur des matrices disjonctives com-
plètes, ces trois indices précédents sont égaux  et en particulier leurs expressions sont équiva-
lentes à celle de l’indice de Dice. 
En effet du fait que (10(x,y) + 01 (x,y)) = 2(m- 11(x,y)) ( voir formule (i) §3.1.2.1),, et que 
d’autre part, il y a autant de configurations 10(x,y) que de configurations 01(x,y),  on a 
01(x,y) = 10(x,y) ; dès lors la quantité 2 est égale à 0. Comme =0, il vient:  
 
                         
k
y)11(x, )y,x(S =     et   

)y,x(11

y)11(x, )y,x(S
2o
==
   
En remplaçant  par sa valeur, on retrouve bien la définition de l’indice de Dice. 
On vérifie bien de ce fait  la Propriété sus-dite :    
                                         Sd(x,y) = So(x,y) = Sk (x,y) 
 
4.3 Indices du Groupe I, Type II-B (indices obtenus comme autres fonc-
tions des ratios de « Rappel » et de « Précision ») 
4.3.1 Indice de moyenne harmonique quadratique normée de  P, R 
Cet indice noté  SN(x,y) , est défini par :                                                                            
                                             
(f 42)     
22
22N
Q
1
P
1
2
)]y,x(01)y,x(11[)]y,x(10)y,x(11[
y).11(x,2)y,x(S
+
=
+++
=
       
 
Cet indice varie bien de 0 à 1, il vaut 1 si 01(x,y)=10(x,y) =0  et 0 si 11(x,y) = 0. 
En utilisant les notations en ² et ² définies précédemment, on peut montrer que cet indice 
se simplifie selon la formule suivante: 
22N 
y)11(x, )y,x(S
+
=
    et  si l’on compare son expression à celle de l’indice d’Ochiai       
22
o

y)11(x, )y,x(S
−
=
  
une relation évidente est dérivable  de ce qui précède, il suffit de comparer les dénomi-
nateurs, puisque       22  +  22  − on voit que : 
 
(f 43)                                    )y,x(S   )y,x(S oN ≤   
  
De plus , on a  de façon complémentaire le résultat suivant :    
                                             
[ ] [ ] [ ]2
2
2
N
2
o y)11(x,
.2
)y,x(S
1
)y,x(S
1 
=+             
RNTI-A-3 - 240 -
                                                                                                    F. Marcotorchino 
 
(cette dernière quantité étant 2 fois l’inverse de l’indice de Dice au carré) , on a donc la 
relation suivante liant ces trois indices :  
(f 44)                                     
[ ] [ ] [ ] 





+= 2
N
2
o
2
d )y,x(S
1
)y,x(S
1
2
1
)y,x(S
1 
  
Sous cette forme il apparaît clairement que  l’indice de Dice au carré est la moyenne 
harmonique de l’indice N au carré  et de l’indice d’Ochiai au carré. 
D’autre part  on peut montrer que l’indice SN(x,y) s’exprime en fonction de l’indice de 
Dice, l’indice de Kulczynski et de l’indice d’Ochiai suivant les deux formules suivantes :  
                                        
(f 45)               












−
=




−
=
2
o
d
d
k
d
d
N
)y,x(S
)y,x(S2
)y,x(S
)y,x(S
)y,x(S2
y)(x,.S)y,x(S
       
On constate, une fois encore  le rôle « central » de l’indice de Dice, du fait de son rôle de 
« moyenne Harmonique  carrée » de SN(x,y) et  So(x,y) ,  et compte tenu  de la formule 
(f 43),  liant ces deux quantités et du fait que So(x,y)≥0 et SN(x,y)  ≥ 0, on tire la relation 
d’inégalités  suivante :   
 
(f 46)                                             SN(x,y) ≤ Sd(x,y) ) ≤ So(x,y) 
 
comme par ailleurs , nous avons vu  au paragraphe précédent que : 
                                                     Sd(x,y) ≤  So(x,y) ) ≤ Sk(x,y)  
ceci implique   que dans le cas général: 
 
(f 47)                                       SN (x,y) ≤ Sd(x,y) ≤ So(x,y) ≤ Sk(x,y) 
4.3.2 Indices du Min et du Max de P et de R  
Ces indices que nous noterons SMin(x,y) et SMax(x,y) varient également de 0 à 1 ils  
s’écrivent : 
                                                     SMin(x,y) = Min  (P,R)                                        
                                                     SMax(x,y) = Max (P,R)   
Le premier de ces deux indices est connu dans la littérature anglo-saxonne sous le nom 
d’indice de « Braun Blanquet »,  (voir J. Braun-Blanquet  (1932)),  utilisé par l’auteur en 
phytosociologie également, le  second d’entre eux SMax(x,y) est également connu sous le 
nom d’ « indice de Simpson » dans la littérature anglo-saxonne (voir G. Simpson (1943)), 
introduit en 1943 par l’auteur,  il est surtout utilisé dans le domaine de la similarité molé-
culaire.   
Comme les numérateurs sont égaux, et comme on a  la propriété suivante :                       
                 Min (a,b)=1/2(a + b] −1/2	a −b 	et    Max (a,b)=1/2(a + b) +1/2 	a −b 	, 
 
RNTI-A-3- 241 -
Essai de Typologie Structurelle des Indices de Similarités  
(f48) [ ])y,x(01)y,x(11),y,x(10)y,x(11Max
)y,x(11)y,x(SMin
++
=
    et         
[ ])y,x(01)y,x(11),y,x(10)y,x(11Min
)y,x(11)y,x(SMax
++
=
 
 
mais   comme : 
Max (11(x,y)+10(x,y), 11(x,y)+01(x,y))  = 1/2[2.11(x,y) + 10(x,y)+01(x,y)) +1/2	10(x,y)-01(x,y) 	 
Soit : 
Max (11(x,y)+10(x,y), 11(x,y)+01(x,y)) = α + β  où 
 α et β  ont été définies précédemment :   =  (11(x,y) + ½ (10(x,y) + 01(x,y)) ) et  
  = ½ |10(x,y)  - 01(x,y)| 
de  même, 
Min (11(x,y) +01(x,y),11(x,y)+01(x,y)) =  α − β   
 
Dès lors les nouvelles formulations de  SMin (x,y) et de   SMax(x,y)    sont les suivantes:  
                            

y)11(x,)y,x(SMin
+
=    et    

y)11(x,)y,x(SMax
−
=  
4.3.2.1   Quelques Propriétés des Indices du Min et du Max de P et R  
Si l’on calcule les moyennes arithmétique,  géométrique et harmonique de  SMin (x,y) et de  
SMax (x,y) 
on obtient :  
[ ] )y,x(S

y)11(x,   2
2
1)y,x(S)y,x(S
2
1
k22MaxMin =







−
=+ ,  comme indiqué au § 4.2.1.3 
a) Première Propriété:  
L’indice de Kulczynski est la « moyenne arithmétique» des indices  )y,x(SMin  et 
)y,x(SMax   [ ])y,x(S)y,x(S 2
1)y,x(S MaxMink +=   
b) Deuxième  Propriété:  
De la  même façon , on peut montrer que l’indice d’Ochiai )y,x(So    est la « moyenne 
géométrique » de ces deux quantités 
                                         )y,x(S )y,x(S)y,x(S MaxMino =  
 
En effet comme Max (P,R).Min (P,R) = P×R , le résultat précédent s’en déduit simplement. 
c) Troisième Propriété:  
De même on retrouve  un résultat connu  pour la moyenne harmonique,  puisque comme 
nous l’indique la formule :      
 
 (f 49)              






+=





+=



+= )y,x(S
1
)y,x(S
1
2
1
)R,P(Min
1
)R,P(Max
1
2
1
R
1
P
1
2
1
)y,x(S
1
MaxMinh
.    
On en déduit que d’après la formule (f 40),  l’indice de Dice   est la moyenne harmonique   
des indices )y,x(SMin  et )y,x(SMax  sous la forme :   
RNTI-A-3 - 242 -
                                                                                                    F. Marcotorchino 
 
               






+= )y,x(S
1
)y,x(S
1
2
1
)y,x(S
1
MaxMind
 
4.3.2.2 Indice de Mac Connaughey (Variante Corrélative de l’Indice de Kulczynski)  
   Cet indice,  qui aurait pu être introduit plus tard  dans cet article, au § 4.4, comme cas 
particulier  des indices du  Groupe  II-Type II,  car issu de valeurs calculables sur le ta-
bleau de contingence Tetrachorique, n’est en fait après simplification d’écriture qu’une 
variante « indice de corrélation »  de l’indice de Kulczynski et , de fait, se doit d’être ratta-
ché aux indices du Groupe I. En effet cet indice dont on trouvera mention dans  l’article  
Boyce et Ellison  (2001) , s’écrit de la façon suivante :  
 (f 50)                    






++
−
=
y)]01(x,y)y)].[11(x,10(x,y)[11(x,
y)y).01(x,10(x,y)][11(x,y)(x,S
2
McC
 
 Donné sous cette forme,  l’indice de Mac Connaughey semble être un indice, nouveau   
qui varie de –1 à +1 ( -1 si 11(x,y)=0, +1 si 10(x,y)=01(x,y)=0). En fait il n’en est rien , il se 
décompose en deux  parties symétriques et duales  relativement aux indices de Rappel et 
de Précision.  En effet par un simple jeu d’écriture, on voit que cet indice s’exprime en 
fonction de P et de R  selon la formule suivante : 
(f 51)                  [ ] 1y)(x,S21
2
RP2 1RPR)]P)(1(1RPy)(x,S kMcC −=−


 +
=−+=−−−=
 
C’est donc une simple translation linéaire de l’indice de Kulczynski , il vaut 1 quand 
l’indice de Kulczinski vaut 1 et il vaut –1 quand l’indice de Kulczynski vaut 0.  
4.3.2.3 Indice  ou fonction F(γ ) de compromis P,R  
  Cette fonction,  qui est souvent utilisée par les spécialistes du TAL (Traitement et Analy-
se de la Langue) (voir J. Beney (2008)) comme “bonne” mesure de compromis entre Rap-
pel et Précision a été définie,  par l’expression:  
                                           
RP
1)P.R( y)(x,F 2
2

+
+
=
 
En divisant le numérateur et le dénominateur par la quantité : (γ²+1), on voit que l’on re-
trouve exactement l’indice de Van Rijsbergen défini en (f 30’) , une fois posé : 
1
1et
1
 22
2
+
=
+
=
 on vérifie bien  dès lors que  : α+β=1 et que: 
1poury)(x,Sy)(x,S
RP
P.R
RP
1)P.R( y)(x,F Tyvr2
2
 =+==
+
=
+
+
=
 
en conclusion par rapport à la typologie que nous venons de faire,  cette fonction F 
n’apporte rien de plus  que l’Indice de Tversky écrit sous la forme :  
                    
y)01(x,
1
1y)10(x,
1
y)11(x,
y)11(x,y)(x,S
22
2Ty
+
+
+
+
=
 
cependant on peut noter que:  F(1)=Indice de Dice , F(0)=Précision, F(∞) =Rappel, en 
dehors de ce petit résultat   cette écriture est donc totalement équivalente à celle de Tvers-
ky et nous ne conserverons pas cette fonction dans notre discussion finale.  . 
RNTI-A-3- 243 -
Essai de Typologie Structurelle des Indices de Similarités  
4.3.3 Bilan comparatif de positionnement des Indices du Groupe I 
Propriété n°12: Egalité des indices en cas de disjonction complète  
Dans le cas particulier, où l’on travaille sur des matrices disjonctives complètes, les trois 
indices du GROUPE I, Type II-B, auxquels on peut rajouter P et R (ils jouent en fait le 
rôle de SMin(x,y) et  SMax(x,y) suivant que l’un est supérieur à l’autre) sont égaux  et en parti-
culier leur expression est équivalente à celle de l’indice de Dice et vaut :  11(x,y)/α 
Ceci s’obtient en posant β=0 dans chacune des formules en α et β relatives à ces indices . 
Dans le cas disjonctif complet on a donc: 
               Sd(x,y)=So(x,y)=Sk (x,y) = SN(x,y) = SMax(x,y) = SMin(x,y) =P = R 
Une conséquence  évidente,   est que,   de facto, tous ces indices du Groupe I Type II 
sont, en cas de disjonction complète, de la forme:  
                                                             S=1-(1/2)d2  
 et dès lors sont des indices de similarités métrisables euclidiens  
 
 
Propriété n°13: Ordonnance des  Indices du Groupe I au sens Général 
Dans le cas général  nous obtenons l’inégalité suivante entre tous les indices du Type II: 
 
            SMin(x,y)  ≤  SN(x,y)  ≤  Sd(x,y)   ≤  So(x,y)  ≤ Sk(x,y)  ≤  SMax(x,y) 
Si nous rajoutons tous les indices du GROUPE I (Type I, Type II - (A et B)), les inégalités 
entre eux nous permettent d’écrire , pour tout couple (x,y) :  
San (x,y) ≤  Sj(x,y) ≤  SMin(x,y) ≤ SN(x,y) ≤ Sd(x,y)  ≤  So(x,y) ≤ Sk(x,y) ≤ SMax(x,y) 
 
Il reste à positionner Sas (x,y)et Sso (x,y),    comme    Sso (x,y) ≤ Sas (x,y) , il reste à positionner 
Sso (x,y) par rapport à l’échelle précédente. 
Comme Sso (x,y) s’exprime sous la forme suivante par rapport à α : 

y)11(x,)y,x(Sso
−
=  
   où  α= 11(x,y) +1/2 (10(x,y) +01(x,y)) et   δ= ¼ (01(x,y) +10(x,y)) 
               :  
comparons  donc   

y)11(x,)y,x(Sso
−
=    à  

y)11(x,)y,x(SMax
−
=   (voir précédemment) 
Pour que 

y)11(x,)y,x(SMax
−
=   soit  inférieur à 

y)11(x,)y,x(Sso
−
=
  
il suffit que :  

y)11(x,

y)11(x,
−
≤
−
 ,  soit  donc : α− δ  ≤   α− β   , c’est-à-dire : β  ≤  δ, ce qui 
implique:  
                                                 ½ 	01(x,y)−10(x,y)	 ≤  ¼ (01(x,y) +10(x,y))  
 
Pour enlever le signe  «	», il suffit de passer au Max et Min, il vient alors : 
 
    2(Max (01(x,y),10(x,y))−Min (01(x,y),10(x,y))) ≤ (Max (01(x,y),10(x,y)) +Min (01(x,y),10(x,y)))  
soit: 
RNTI-A-3 - 244 -
                                                                                                    F. Marcotorchino 
 
(f 52)                                     Max [ 01(x,y), 10(x,y))  ≤   3 Min (01(x,y),10(x,y))  
 
Si cette condition  (f 52) est vérifiée on a donc:   SMax (x,y) ≤  Sso (x,y)  et de ce fait :  
 
(f 52’) San (x,y ) ≤ Sj(x,y) ≤ SMin(x,y) ≤ SN(x,y) ≤  Sd(x,y)  ≤ So(x,y) ≤ Sk(x,y) ≤ SMax(x,y) ≤ Sso(x,y) ≤ Sac(x,y)  
 
Si la condition inverse se produit: Max [01(x,y),10(x,y))  >  3 Min (01(x,y),10(x,y)), nous ne 
sommes plus assurés de la séquence précédente, il faut alors comparer Sac(x,y)  à SMax(x,y), 
nous avons  à comparer α −δ’ et α− β   (avec δ’= 3/8 (01(x,y) +10(x,y))).  
De la même façon que précédemment, il faut comparer ces quantités  à l’aide des notations 
en Min et Max  et  pour que SMax(x,y) soit  inférieur à Sac(x,y):   il faut et il suffit que :  
                 α − δ’  ≤   α − β   et de ce fait, il faut que :  β  ≤  δ’ , c’est à dire : 
 
Max (01(x,y),10(x,y))−Min (01(x,y),10(x,y)) ≤ 3/4 (Max (01(x,y),10(x,y)) +Min (01(x,y),10(x,y)))  
soit: 
(f 53)                                 Max[01(x,y),10(x,y)) ≤  7 Min(01(x,y),10(x,y))  
 
dès lors si:           3 Min(01(x,y),10(x,y))  ≤ Max ( 01(x,y),10(x,y))  ≤  7 Min (01(x,y),10(x,y)) ,  alors: 
 
(f 53’)   San(x,y) ≤ Sj(x,y)≤ SMin(x,y)≤ SN(x,y)≤ Sd(x,y) )≤ So(x,y)≤ Sk(x,y)≤ Sso(x,y) ≤  SMax(x,y) ≤ Sac(x,y)    
 
Si cette dernière condition n’est pas vérifiée, soit maintenant si :  
(f 54)                               7 Min (01(x,y),10(x,y)) ≤ Max(01(x,y),10(x,y)) 
 alors on aura: 
(f 54’)    San (x,y)≤ Sj(x,y) ≤ SMin(x,y) ≤ SN(x,y)≤ Sd(x,y) )≤ So(x,y) ≤ Sk(x,y)≤ Sso(x,y)≤ Sac (x,y)≤SMax(x,y) 
 
Dans le cas particulier,   où l’on a disjonction complète, les résultats se simplifient en  : 
 
a) Puisque alors β=0, on a une première série d’égalités (pour les indices fonctions de P et 
de R),  
               SMin(x,y) = SN(x,y) = Sd(x,y)  = So(x,y) = Sk (x,y) =  
m
y)11(x,)y,x(SMax =    
b) Pour les indices classiques du Groupe I-Type I (Ratios directs), on obtient les inégalités 
suivantes:  
 
y)3.11(x,m
y)4.11(x,y)(x,S
y)11(x,m
y)2.11(x,y)(x,S
m
y)11(x,y)(x,S
y)11(x,2m
y)11(x,y)(x,S
y)3.11(x,4m
y)11(x,y)(x,S acsodjan +=≤+=≤=≤−=≤−=
 
En conclusion, dans le cas de disjonction complète le rôle central de Sd(x,y) est amplifié 
car : dans le cas du système d’égalités (a)  tous les indices sont égaux à Sd(x,y), dans le 
système d’inégalités (b), Sd(x,y) joue le rôle de « médiane » des indices,  indices  qui sont 
tous, par ailleurs, fonctions homographiques de Sd(x,y).  
 
RNTI-A-3- 245 -
Essai de Typologie Structurelle des Indices de Similarités  
4.3.4  En guise de Conclusion sur les Indices du  Groupe I 
  Commenous  venons de le voir, les indices du Groupe I se divisent en deux classes dis-
tinctes, même si nous avons vu  que cette classification n’est pas une partition puisque 
l’Indice de Dice, par exemple, se retrouve dans les deux Types.  Par ailleurs, le modèle de 
Tversky (1977) qui tend à unifier ces deux types par une formulation unificatrice ne per-
met pas d’exploiter la logique réelle de formation des indices. Nous  avons vu néanmoins 
à ce propos que les  cases connues de la nomenclature récapitulative représentent des in-
dices d’usage courant et intuitifs. Plus intéressante  est la tentative faite par Julien Ah Pine 
dans sa thèse de l’université Paris VI (voir J. Ah-ine (2007)),  sur les aspects mathéma-
tiques : algébriques et combinatoires de l’Analyse Relationnelle ; en effet ce dernier re-
donne (pp73 à 88) une interprétation « métrique » (scalaire généralisée) de ces indices du 
Groupe  I permettant leur extension au delà du domaine des données « binaires » vers le  
domaine des données » continues ».  
Pour  ce faire il introduit deux paramètres géométriques présents de façon sous-jacente 
dans chacun de ces indices du Groupe I, à savoir : le  cosinus de l’angle formé par les 
vecteurs binaires »  d’une part, le rapport de la plus grande norme des deux sur la plus 
petite. Il montre ainsi que l’extension continue potentielle de certains des indices du 
Groupe I , vers un formalisme de « bon » indice totalement général s’applique en particu-
lier  à l’indice de Dice  et à l’indice d’Ochiaï .  Outre qu’il retrouve par là même et d’une 
façon totalement différente ce que nous avions mentionné précédemment sur les « bons » 
indices, il donne également une interprétation géométrique  en terme de « projecteurs » 
aux deux indices partiels de « Rappel » et de « Précision ». Nous renvoyons le lecteur à 
son travail    pour de plus amples renseignements.    
 
4.4 Indices appartenant au GROUPE II, faisant jouer un rôle   aux 
structures  11(x,y) et  00(x,y). 
4.4.1 Indices du Groupe II,  Type I (indices obtenus par ratios directs, faisant 
jouer un rôle  linéaire aux structures 00(x,y)) 
4.4.1.1 Indice de Sokal et Michener (1958),  Green-Rao (1969) 
   Cet indice (voir R. Sokal et C. Michener (1958)), qui porte également le nom de 
« simple matching index » est l’un des plus intuitifs de ceux introduits dans la littérature 
des indices de similarité, en effet si l’on revient à l’expression du tableau contingentiel 
« tetrachorique » (2×2) introduit précédemment au § 3, on voit que  ce coefficient,  l’un  
des premiers à avoir été décrit dans la littérature, est  le rapport des cases de la diagonale 
du tableau, divisé par la somme des quatre cases du tableau précédent.  
En fait si la variante « similarité » est attribuée généralement  à  Sokal et Michener (1958), 
Green et Rao12 (1969) ayant introduit, quant à eux,  la variante  « dissimilarité » de 
                                                 
12
 I.C. Lerman (1970), attribue à Hamann (1961),  l’indice qui est défini 
par :
P
y)]01(x,y)[10(x,y)00(x,y)11(x,y)(x,SHa
+−+
=
 , c’est en fait la différence entre l’Indice de Sokal et 
Michener et celui de Green et Rao, il varie de( –1à +1) 
RNTI-A-3 - 246 -
                                                                                                    F. Marcotorchino 
 
l’indice (qui est d’ailleurs le complémentaire de celui de Sokal et Michener par rapport à 
la somme des cases du tableau « Tetrachorique »), il se trouve que l’idée originale de ce 
concept est bien plus ancienne encore. En effet on peut la faire remonter à A. de Condor-
cet (1785), voir F. Marcotorchino (1981), F. Marcotorchino et N. El Ayoubi  (1991), ce 
critère de Condorcet , qui dans le cas de comparaisons de vecteurs relationnels est équiva-
lent au coefficient de   Rand  (voir W. Rand (1971))  lequel coefficient semble avoir été 
introduit avant Rand par H.Borko et All. (1968) (voir à ce propos le livre de M. Anderberg 
(1973) page 206). En tout état de cause c’est ce principe de « simple matching » qui pré-
vaut dans l’approche Condorcéenne, introduite en 1785. Ce qui d’une certaine façon met 
tout le monde d’accord quant à la paternité de l’idée. Le critère de « simple matching » 
s’écrit donc :  
 
(f 55)                
)y,x(01)y,x(10)y,x(00)y,x(11
)y,x(00)y,x(11
P
)y,x(00)y,x(11)y,x(Ssm
+++
+
=
+
=
 
 
Cet indice varie de 0 à 1,  
• il vaut 0 si 11(x,y)=00(x,y)=0   
• il vaut 1 si 10(x,y)=01(x,y)=0  
 
Propriété n°14 :  l’indice de Sokal et Michener vérifie la condition de « Transitivité Générali-
sée Indicielle » 
 Montrons par ailleurs que  Ssm(x,y) vérifie la condition de Transitivité Généralisée Indi-
cielle, c’est à dire que l’on a  : 
 (f 56)                                      zy,  x,   1z)(x,Sz)(y,Sy)(x,S smsmsm ∀≤−+  
soit :                  Pz)]00(x,z)[11(x,z)00(y,z)11(y,y)00(x,y)11(x, ≤+−+++  
 
En remplaçant ces valeurs en fonctions des quantités xj et yj , il vient  après simplifications: 
                              0z xyzy yx j
P
1j
j
P
1j
jj
P
1j
P
1j
jjj ≤−−+ 


 

=== =
 
Le membre de gauche de cette inégalité peut également s’écrire sous la forme produit 
suivante : 
(f 57)                     )zy)(yx(z xyzy yx jjj
P
1j
jj
P
1j
j
P
1j
jj
P
1j
P
1j
jjj −−=−−+ 



 

==== =
  
Comme xj,yj et zj sont des valeurs égales à 0 ou 1 ∀j, il suffit de montrer que pour toutes les 
valeurs de l’indice « j », le  produit (xj-yj)(yj-zj),  ne peut en aucun cas être strictement posi-
tif.  Pour ce faire explorons exhaustivement les 8=23 configurations possibles des valeurs 
xj, yj, zj., on obtient le tableau suivant : 
 
xj yj zj Valeur du produit  (xj-yj) (yj-zj) 
0 0 0 0 
0 0 1 0 
0 1 0 -1 
1 0 0 0 
0 1 1 0 
1 0 1 -1 
1 1 0 0 
1 1 1 0 
RNTI-A-3- 247 -
Essai de Typologie Structurelle des Indices de Similarités  
 
On constate que le produit (xj-yj)(yj-zj) est toujours négatif ou nul pour toutes les configura-
tions des valeurs xj, yj,,zj,  donc que la quantité somme de ces produits sera négative, soit :  
0)z- y)(y(x jj
P
1j
jj ≤−

=
 
 La formule (f56) est donc vraie (cqfd) 
Conclusion : L’indice de Sokal et Michener est donc un indice de similarité « métrisable » 
l’indice de distance associé s’écrit  :  
                                             
P
)y-(x
y)(x,S-1y)(x,d
P
1j
2
jj
smsm


=
==
 
Si  P est un nombre pair on peut écrire  P=2p’, il vient alors: 
 (f 58)                  
y)(x,
2
11
p'
y
p'
x
2
11
p'
)y-(x
2
11y)(x,S 2
2
P
1j
jj
P
1j
2
jj
sm −=



	
	


−−=−= 



=
=
 
L’indice de Sokal et Michener est donc un indice métrisable euclidien , d’après le théorè-
me de Gower –Schoenberg. 
 
 4.4.1.2 Indice de Rogers et Tanimoto (1960) 
  Cet indice, introduit par les auteurs dans un article sur l’écologie botanique (voir (D. 
Rogers et T. Tanimoto (1960)), joue,  pour les indices du Groupe II -Type I,  un rôle ana-
logue à celui joué par  l’indice d’Anderberg  pour les indices du Groupe I - Type I, en effet 
il pondère légèrement plus (poids =2)  les cas d’« erreurs » de matching. Il est défini par : 
 
(f 59)               
)]y,x(00)y,x(11[P.2
)y,x(00)y,x(11
)]y,x(01)y,x(10[2)y,x(00)y,x(11
)y,x(00)y,x(11)y,x(Srt
+−
+
=
+++
+
=
 
    
 
En éliminant les quantités communes : 11(x,y)+00(x,y) et (10(x,y)+01(x,y)), entre les deux 
indices précédents on obtient la relation suivante entre l’indice de Rogers et Tanimoto et 
celui de  « Simple Matching » : 
 
(f 60)              
)]y,x(S2[
)y,x(S)y,x(S
sm
sm
rt
−
=
  et réciproquement : 
]1)y,x(S[
)y,x(S.2)y,x(S
rt
rt
sm
+
=
 
Propriété n°15 :  l’indice de Rogers et Tanimoto vérifie « la condition de Transitivité Générali-
sée Indicielle et est métrisable »  
En effet en se reportant à la formule (f57) ci-dessus , on voit que les conditions 
d’application des Théorème n°1 et Théorème n°1 bis  sont vérifiées par l’indice de Rogers 
et Tanimoto , il suffit de voir que comme  
)]y,x(S2[
)y,x(S)y,x(S
sm
sm
rt
−
=
  s’écrit  
1y)](x,S[1
y)(x,S
y)(x,S
sm
sm
rt
+−
=
 avec β=1, il est donc métrisable, 
d’après le Théorème n°1 et métrisable euclidien d’après le Théorème n°1 bis, si P est pair.   
RNTI-A-3 - 248 -
                                                                                                    F. Marcotorchino 
 
4.4.1.3 Indice de Sokal et Sneath  (1963) 
   Cet indice, introduit par les auteurs en 1963 (voir (Sokal et Sneath ( 1963)) et rejustifié 
dans leur livre de 1973 (voir Sokal et Sneath (1973)) est  une variante des  indices précé-
dents,  avec une définition très voisine de celle qu’a l’indice de Dice au regard des indices 
du Groupe I-Type I, en effet il donne moins de poids  que  les deux configurations  précé-
dentes aux situations de non concordance. Il s’écrit :   
 
(f 61)                
)]y,x(00)y,x(11[P
)]y,x(00)y,x(11.[2
)]y,x(01)y,x(10[)y,x(00)y,x(11
)y,x(00)y,x(11)y,x(S
2
1ss ++
+
=
+++
+
=
 
 
En éliminant les quantités communes : (11(x,y)+00(x,y)) et (10(x,y)+01(x,y)), entre l’indice 
de Sokal et Sneath et celui de « Simple Matching », on obtient la relation homographique 
ci dessous :  
 
(f 62)               
]1)y,x(S[
)y,x(S.2)y,x(S
sm
sm
ss
+
=
 et réciproquement :    
)]y,x(S2[
)y,x(S)y,x(S
ss
ss
sm
−
=
 
 
Enfin en éliminant  Ssm(x,y) dans les deux formules  (f 61) et (f 62), on obtient la relation 
suivante entre les indices de Sokal- Sneath et  Rogers - Tanimoto : 
 
(f63) 
]1)y,x(S.3[
)y,x(S.4)y,x(S
rt
rt
ss
+
=
 et la formule réciproque : 
)]y,x(S.34[
)y,x(S)y,x(S
ss
ss
rt
−
=
 
 
 
Du fait que ces 3 indices du Groupe II,  Type I, soient tous fonction homographique de 
l’indice de « Simple Matching », nous permet de les représenter sur un diagramme unique, 
où l’on peut voir de façon simple comment ils se comportent et comment ils varient les 
uns par rapport aux autres. Par ailleurs bien évidemment tous ces indices varient de 0 à 1, 
ce que nous constatons d’ailleurs sur le graphique de la Figure N°2 :  
     
1)y,x(S0  ≤≤  
 
• Ces indices valent 0 si le nombre de  concordances (« matchings »)  positives et con-
cordances  négatives sont nulles  entre  x et y   11(x,y)=0 et 00(x,y)=0 
•  Ils valent 1 si la quantité (10(x,y)+01(x,y) = 0  x et y ont le même profil de 1 et de 0   
• Ces trois indices vérifient les inégalités suivantes ∀ (x,y) : 
 
(f64)                                 1)y,x(S)y,x(S)y,x(S0 sssmrt ≤≤≤≤  
RNTI-A-3- 249 -
Essai de Typologie Structurelle des Indices de Similarités  
.
0,0
0,2
0,3
0,5
0,7
0,8
1,0
0,
00
0,
10
0,
20
0,
30
0,
40
0,
50
0,
60
0,
70
0,
80
0,
90
1,
00
Tanimoto
SimpMatch
Sokal-Sne
Figure 2: Graphique de variation des indices du GROUPE II,  Type I 
4.4.2 Quelques propriétés des indices du Groupe II-Type I en cas de disjonction 
complète 
        Dans le cas ou les indices précédents sont calculés sur les tableaux obtenus par dis-
jonction complète, des simplifications vont se produire qui permettent des convergences.  
 
En cas de disjonction complète on a vu en effet que le nombre de variables « m »  était tel 
que  :   
      [ ] m)y,x(01)y,x(10
2
1)y,x(11 =++  
d’autre part on a :  11(x,y)+00(x,y)+10(x,y)+01(x,y)=P  
De ce fait  la quantité [ ] )y,x(11.2m2)y,x(01)y,x(10 −=+   remplacée dans l’égalité sur P 
nous donne : 
 
(f 65)    m2)y,x(11P)y,x(00 −+=  
Alors en remplaçant cette valeur dans les trois indices précédents nous obtenons  pour 
chacun d’entre eux des indices qui ne dépendent que de 11(x,y) et des constantes P et m: 
 
a) Expression du coefficient de « Simple Matching » 
 Le coefficient  Ssm vaut alors : 
P
m.2
P
)y,x(11.21
P
m.2)y,x(11P)y,x(11
P
)y,x(00)y,x(11)y,x(Ssm −+=
−++
=
+
=
 
b) Expression du coefficient de Sokal et Sneath 
Le coefficient  Sss vaut dans ce cas : 
m)y,x(11P
m)y,x(111
2.m-y)2.11(x,2P
]m.2)y,x(11.2[ 2P2
)]y,x(00)y,x(11[P
)]y,x(00)y,x(11.[2)y,x(Sss
−+
−
+=
+
−+
=
++
+
=
 
RNTI-A-3 - 250 -
                                                                                                    F. Marcotorchino 
 
 
c)  Expression du coefficient de Rogers-Tanimoto 
Le coefficient  Srt  vaut dans ce cas : [ ]
)]y,x(11.2m2[P
)y,x(11.2m.221)]y,x(11.2m.2[P
)]y,x(11.2m.2[P
)]y,x(00)y,x(11[P.2
)y,x(00)y,x(11)y,x(Srt
−+
−
−=
−+
−−
=
+−
+
=
 
 
Comme dans le cas de disjonction complète, on a toujours le résultat suivant : 
m
)y,x(11)y,x(Sd =   (voir formule (f 25)) montrons que ces trois indices sont dans le cas de 
disjonction complète des fonctions de l’indice de Dice :  
 
Il suffit pour cela de diviser Numérateur et Dénominateur des indices précédents  par 
« m », il vient : 
 
• [ ])y,x(S1
P
m.21
P
m.2
P
)y,x(11.21)y,x(S dsm −−=−+=  ou réciproquement : 
[ ])y,x(S1
m.2
P1)y,x(S smd −−=  
 
• 
)]y,x(S1[mP
)]y,x(S1[m1
m)y,x(11P
m)y,x(111)y,x(S
d
d
ss
−−
−
−=
−+
−
+=        ou réciproquement : 
)]y,x(S1[
)]y,x(S1[
 
m.2
P1)y,x(S
ss2
1
ss
d
−
−
−=
 
 
• [ ]
)]y,x(S1[m2P
)]y,x(S1[m41)]y,x(11.2m2[P
)y,x(11.2m.221)y,x(S
d
d
rt
−+
−
−=
−+
−
−= ou réciproquement : 
)]y,x(S1[
)]y,x(S1[
 
m2
P1)y,x(S
rt
rt
d
+
−
−=
 
Dès lors la comparaison de ces indices au travers de la « borne de Salomon -Fortier » que 
nous avions utilisée précédemment pour l’indice de Dice  ( qui se traduisait par  la règle 
majoritaire de Condorcet) induit les bornes suivantes pour ces trois indices du Groupe II-
Type I : 
 [ ]
2
my)11(x,         
P
m1      y)(x,S          
2
1y)(x,S1
2.m
P1      
2
1y)(x,S smsmd ≥⇔−≥⇔≥−−⇔≥     
2
my)11(x,            
m-2P
m
-1    y)(x,S        
2
1
y)](x,S[1
y)](x,S[1
 
2.m
P1         
2
1y)(x,S ss
ss2
1
ss
d ≥⇔≥⇔≥
−
−
−⇔≥
       
2
my)11(x,              
mP
2.m1y)(x, S               
2
1
y)](x,S[1
y)](x,S[1
 
2m
P1          
2
1y)(x,S rt
rt
rt
d ≥⇔
+
−≥⇔≥
+
−
−⇔≥
 
 
Remarque n°5 : Dans le cas particulier où l’on se trouve dans les conditions de la Remarque n°1, 
tableau de « présence-absence » dédoublé , on a P=2m, de ce fait les inégalités précédentes se 
simplifient et l’on obtient :  
Dice" de Indice"l'sur      appliquée Fortier   Salomon      de règle lapour   Sorensen" de indice"l' avec
 Sneath"et  Sokal" de indicel' de eEquivalenc   
3
2
mm4
m1)y,x(S           
mP2
m1      )y,x(S   ssss ⇔=
−
−≥⇔
−
−≥
Dice" de Indice"l'sur      appliquée Fortier   Salomon      de règle lapour   Jaccard" de indice"l' avec 
   Tanimoto" Rogers" de indicel' de eEquivalenc   
3
1
mm.2
m.21)y,x(S           
mP
m.21      )y,x(S   ssrt ⇔=
+
−≥⇔
+
−≥  
 
RNTI-A-3- 251 -
Essai de Typologie Structurelle des Indices de Similarités  
Remarque n°6 : Dans la configuration précédente, nous avions privilégié une comparaison de ces 
trois indices en référence au fait que l’indice de Dice vérifiait lui même la condition de Salomon et 
Fortier et nous avons voulu mesurer l’impact induit  au niveau de chacun d’entre eux sur  les bornes 
ainsi générées. 
Une autre approche intéressante consiste en la démarche inverse, (comme nous l’avions fait dans le 
cas des indices du Groupe I –Type I),  c’est à dire à exhiber  les contraintes que doit vérifier la 
quantité : 11(x,y) relativement à chacun de ces indices pour que la condition de Salomon –Fortier 
soit vérifiée. 
 
• 
4
P
my)11(x,              
2
1
 
P
2.m
P
y)2.11(x,1            
2
1y)(x,S sm −≥⇔≥−+⇔≥
 
• 
3
P
my)11(x,                  
2
1
    
my)11(x,P
my)11(x,1             
2
1y)(x,Sss −≥⇔≥
−+
−
+⇔≥
 
• [ ]
6
P
-my)11(x,         
2
1
y)]2.11(x,[2mP
y)2.11(x,2.m21              
2
1y)(x,S rt ≥⇔≥
−+
−
−⇔≥
 
On constate immédiatement à l’aune de ces valeurs, dépendantes de P et de m, que pour les 
tableaux disjonctifs complets à grand nombre de modalités, ces bornes ont peu de  signifi-
cation, en effet supposons que .p  soit  le  nombre de modalités moyen de l’ensemble des 
variables alors m.pP = , de ce fait les bornes précédentes  
s’écrivent respectivement : )
6
p
-m(1   ),
3
p
-m(1   ),
4
p1(m − , supposons, par exemple,  que  
5p =  (ce qui est un chiffre peu élevé, très souvent rencontré  dans applications  con-
crètes), alors les bornes sont négatives pour l’indice de Simple Matching et  Sokal et 
Sneath,  donc la condition de Salomon-Fortier est toujours vérifiée, et il suffit  que 11(x,y) 
soit supérieur à m/6 pour que  la condition de Salomon -Fortier soit vérifiée par l’indice de 
Rogers et Tanimoto . Ces indices ne seront donc pas très utilisables dans le contexte de 
tableaux disjonctifs associés à des variables qualitatives dès lors que le nombre moyen de 
modalités est supérieur à  3, on privilégiera  de ce fait les indices du Groupe I-Type I dans 
ce contexte.   
 
4.4.3 Indices « non Classiques » du Groupe II - Type I (indices obtenus par ratios 
directs, faisant jouer un rôle aux structures 00(x,y), au Numérateur et au 
Dénominateur) 
     En plus des indices dits « classiques », en un mot les plus utilisés de ce Groupe II-Type 
I, il existe des variantes  jouant sur des pondérations à la fois au numérateur pour la confi-
guration 00(x,y) et au dénominateur pour les configurations 10(x,y) et 01(x,y). En fait la 
forme13 générale SG(x,y) des indices du Groupe II-Type I est  donnée par :  
  
(f 66)                             
y)]01(x,y)[10(x,y)00(x,y)11(x,
y)00(x,y)11(x,)y,x(SG
+++
+
=
 
                                                 
13
 En jouant sur l’intersection du modèle SG  précédent et du Modèle de Tversky , on peut fabriquer un indice encore 
plus général avec 4 paramètres  variables, de la forme : 
y)01(x,y)10(x,y)00(x,y)11(x,
y)	00(x,y)11(x,)y,x(SGG +++
+
=
 
 
RNTI-A-3 - 252 -
                                                                                                    F. Marcotorchino 
 
On retrouve dans le tableau ci-dessous en fonction des valeurs de α et β le nom des indi-
ces déjà rencontrés et nous expliciterons  dans ce paragraphe ceux qui n’ont pas encore été 
définis. 
 
 
 
                 β      1/2 1 2 
0 Rao2 Rao (1945)  
1/2 Marco-Michaud2 (1980) 
Marco-Michaud 
(1980) 
 
1 
Sokal- Sneath (1968) Sokal-Michener 
(1958) 
Rogers-
Tanimoto(1960) 
 
 
4.4.3.1 Indice de T.R. Rao (1945)  
  Cet indice, bien qu’introduit initialement par PF. Russel et T..R. Rao en 1940, redétaillé 
ensuite par R. Rao seul en 1945 est assez peu utilisé dans la pratique car il est souvent trop 
sévère et s’éloigne de structures d’équilibre interprétables. Il consiste dans le simple rap-
port entre le nombre de Matching 11(x,y) divisé par le nombre total d’attributs descriptifs,  
qu’on notera, comme défini au début de l’article , par P. Ce nombre définissant soit le 
nombre de variables descriptives de « présence-absence », soit le nombre de modalités de 
l’ensemble des variables, quand on travaille sur un tableau disjonctif complet. Du fait de la 
présence des configurations 00(x,y) au dénominateur (quantités  qui sont souvent très 
grandes ), les valeurs de l’indice de Rao  sont souvent très faibles. Par ailleurs contraire-
ment aux autres indices du groupe II, il ne fait pas jouer de rôle aux configurations 00(x,y) 
au numérateur  (ici α=0 ce qui ne permet pas  le rééquilibrage). Suite à ce que nous venons 
de mentionner au paragraphe précédent, il apparaît que cet indice est  encore moins bien 
adapté que les indices  précédents aux calculs de similarités sur  tableaux disjonctifs com-
plets.  Sa forme est donc : 
 
  (f 67)             
)y,x(01)y,x(10)y,x(00)y,x(11
)y,x(11
P
)y,x(11)y,x(Sr
+++
==
  
Il varie bien de 0 à 1, il vaut: 
• 0 si 11(x,y)=0 
• 1 si simultanément : 10(x,y)=01(x,y)=00(x,y)=0   (ce qui est une contrainte extrêmement  
dure à obtenir ) 
 
Cet indice n’a pas de propriétés particulières  en cas de disjonction complète , en effet en 
remplaçant  00(x,y), 10(x,y) et 01(x,y) par leurs valeurs en fonction de 11(x,y) et de P, du fait 
que  00(x,y)=11(x,y)+P-2m, 01(x,y)=10(x,y)=m-11(x,y), on retrouve :  
P
)y,x(11)y,x(Sr =  
L’application de la règle de “Solomon Fortier” en cas de disjonction complète donne le 
résultat “paradoxal” suivant: 
(f 68)          
2
P)y,x(11
2
1
P
)y,x(11
2
1)y,x(Sr ≥≥≥  
RNTI-A-3- 253 -
Essai de Typologie Structurelle des Indices de Similarités  
Ce résultat  est impossible à atteindre  dans le contexte  de “disjonction complète”, sauf 
dans un cas . En effet, le minimum pour P par rapport à m est obtenu sur les tableaux de 
“présence-absence dédoublés” pour lesquels P=2m en remplaçant P par 2m dans l’inégalité 
précédente, on obtient: 
      m)y,x(11 ≥   
Comme,   par définition 11(x,y)m, le seul cas possible est 11(x,y) =m, pour toutes les autres 
valeurs de P: 3m, 4m, 5m...x.m, l’inégalité  (f 68) est impossible à vérifier.  
Ceci montre, encore une fois, que l’indice de Rao ne doit être utilisé que dans des configu-
rations spéciales et en particulier, jamais sur des problèmes disjonctivés, hormis le cas 
mentionné.                                   
4.4.3.2 Indice de Marcotorchino-Michaud (1980)  
    En 1980  (voir  F. Marcotorchino et P. Michaud (1980)), nous avions introduit l’indice 
suivant : 
 (f 69)         
)y,x(01)y,x(10)y,x(00)y,x(11
)y,x(00)y,x(11
P
)y,x(00)y,x(11
)y,x(S 2
1
2
1
mm
+++
+
=
+
=
 
 
Cet indice (pour lequel α=1/2) “neutralise” la trop forte influence négative des configura-
tions 00(x,y) au dénominateur, vue dans le cas de l’indice de Rao, tout en leur donnant  un 
poids moins positif toutefois que dans le “simple matching “ index de Sokal et Michener. 
C’est un indice de compromis linéaire entre l’indice de Rao et l’indice de “Simple Mat-
ching”, d’ailleurs, il s’écrit: 
                                                 [ ]y)(x,Sy)(x,S
2
1y)(x,S smrmm +=  
  
Comme l’indice de Rao, il varie de 0 à 1, il vaut:  
• 0 si 11(x,y)=00(x,y)=0. Cependant on peut se poser la question, dans ce cas, de 
l’extrême rareté d’une telle situation qui correspond au fait que les profils de x et y 
sont totalement inverses l’un de l’autre, cas des situations de vecteurs de présence-
absence à produit scalaire nul. Ceci dit,  dans de grands tableaux cette situation peut 
néanmoins se produire, et de ce fait,   la valeur 0 est rare, mais  potentiellement attein-
te.   
• 1 si 10(x,y)=01(x,y)=0  et 00(x,y)=0, cependant dans le cas où 10(x,y)=01(x,y)=0, puisque 
dans ce cas P=00(x,y)+11(x,y), il vaut: 
             
P2
)y,x(11
2
1
P
P)y,x(11
P
)]y,x(11P[)y,x(11
)y,x(S 2
12
1
mm +=


 +
=
−+
=
 
• le fait marquant ici est que si 10(x,y)= 01(x,y)=0, l’indice est toujours supérieur à ½ et 
il vaut 1 si  en plus 00(x,y)=0, soit 11(x,y)=P . La remarque, faite pour le cas de 
l’obtention de la valeur 0, s’applique ici également, pour une situation inverse. Cette 
situation , ne peut se produire,  en effet, que pour des tableaux de données de présen-
ce-absence,  lorsque deux individus x et y possèdent l’ensemble complet de toutes les 
propriétés, en d’autres termes que leurs profils sont deux vecteurs composés de va-
leurs “1”.  
 
RNTI-A-3 - 254 -
                                                                                                    F. Marcotorchino 
 
Il est à noter cependant, qu’en cas de disjonction complète,  du fait des relations entre les 
différentes cases du tableau, déjà présentées auparavant,  la valeur de l’indice se simplifie 
en :                 
                     
P
m
2
1
P
y)11(x,
2
3
P
m]2[Py)11(x,
y)(x,S 2
1
2
3
mm −+=
−+
=
 
Comme dans ce cas,  (disjonction complète), on ne peut avoir  11(x,y) et 00(x,y)  simul-
tanément nuls tous les deux,  l’indice prend sa valeur minimale pour 11(x,y) = 0 et  vaut 
alors :  
P
m
2
1y)(x,Smm −=   
On voit qu’il ne vaudra 0 que si P=2m (cas de la disjonction  tableaux de présence-absence, 
où chaque variable ne peut avoir que 2 modalités), on se retrouve alors dans le cas , déjà 
discuté plus haut, de la valeur 0 de l’indice   (vecteurs de présence-absence à produit sca-
laire nul). 
 Il prend sa valeur maximum dans le cas où  11(x,y)=m ,valeur pour laquelle il vaut : 
2P
m
2
1y)(x,Smm +=  
On voit qu’il ne prendra la valeur maximale 1 que lorsque P=m, c’est à dire dans le cas où 
l’on identifie un tableau  de présence absence avec un tableau  dédoublonné de présence-
absence). Cependant cette situation n’est qu’un artefact, on parlera en fait de tableau dis-
jonctif “vrai”, dès lors qu’une variable possède au minimum 2 modalités. Si toutes les 
variables ont deux modalités , on obtient la valeur maximale qui vaut : 
   
4
3
4m
m
2
1y)(x,Smm =+=  
Propriété de l’ indice de Marcotorchino-Michaud  en cas de disjonction complète 
En cas de disjonction complète, la règle de Solomon-Fortier est applicable ici  à une borne 
(
2
MaxSMinS+ ), (voir §1.1),  puisque l’indice varie « potentiellement » de 0 à 1,  mais plus 
exactement selon des bornes dépendant du rapport m/P. Ici, compte tenu des bornes précé-
dentes, la borne de Solomon-Fortier associée s’écrit :  
    
4P
m
2
1
2P
m
2
1
P
m
2
1
2
1
2
MaxSMinS
−=


		





	


++


	


−=
+  
La vérification de la borne de Solomon-Fortier au sens particulier du contexte disjonctif,  
induit donc  ici :    
                                    
4P
m
2
1y)(x,Smm −≥ , 
 soit: 
           
2
my)11(x,m
4
3y)11(x,
2
3
4P
m
2
1
P
m
2
1
P
y)11(x,
2
3 ≥≥−≥−+   
 
Ce résultat est intéressant au titre qu’il  prouve que Smm(x,y) est l’un des deux seuls,  parmi 
les indices du Groupe II–Type I, pour lequel, en cas de disjonction complète,   l’application 
de la règle de Solomon-Fortier fait disparaître la référence à la valeur de P et où l’application 
du principe fait réapparaître la règle majoritaire de Condorcet. 
RNTI-A-3- 255 -
Essai de Typologie Structurelle des Indices de Similarités  
Ce résultat montre également que, quand l’on parle de borne de Salomon-Fortier,  c’est bien 
à la quantité  
2
SMaxSMin +
 que l’on doit faire référence et non simplement à la valeur  ½, qui 
suppose, elle,  une variation réelle de 0 à 1 (bornes atteintes ) .  
 
Une autre approche, nous montre bien la différence entre la borne vraie de Salomon Fortier 
et la borne théorique  Si  l’on fait apparaître le cas disjonctif en fin de calculs, on illustre 
clairement ce point. 
En effet  si l’on reprend la formule  (f 69), et, puisque dans le cas général, sans référence aux 
limitations du cas disjonctif , on a vu que l’indice Smm varie de 0 à 1, on peut donc  lui appli-
quer la borne simple à ½.  Ceci nous donne : 
  
                      
2
y)01(x,y)10(x,
2
y)11(x,
2
1
y)01(x,y)10(x,y)00(x,y)11(x,
y)00(x,y)11(x, 21 +≥≥
+++
+
 
 
On voit déjà à ce stade  que la référence à 00(x,y)  disparaît, cette formule est générale.  Si 
maintenant  on revient dans un processus où il y a eu disjonction,  la quantité 10(x,y)+01(x,y) 
est égale à 2(m-1l(x,y)), soit en remplaçant cette valeur dans l’inégalité précédente :  
         
3
2my)11(x,
2
y)]11(x,2[m
2
y)11(x,
≥
−
≥
 
On retrouve bien ici une  majorité Condorcéenne des 2/3, que nous avions obtenue précé-
demment dans le cas de l’Indice de Jaccard, l’un des indices représentant le Groupe I – Type 
I . 
 
On constate donc que, contrairement aux indices de Sokal et Michener, Sokal et Sneath et 
Rogers et Tanimoto, la valeur P disparaît de la borne sur 11(x,y) d’une part et que l’indice 
impose une « majorité simple » des variables pour la valeur des  « matchings » 11(x,y) (cas 
disjonctif particulier), d’autre part  une règle des 2/3 dans le cas général.  Cette dernière pro-
priété fait de cet indice, une mesure  tout à fait intéressante dans le cas de structures disjonc-
tivées, ou de présence –absence avec beaucoup de valeurs nulles,  qui ,quoique étant diffé-
rente, se comporte comme l’indice de Jaccard (qui, lui, appartient au Groupe I-TypeI). Cette 
légère dépondération au numérateur des configurations 00(x,y),  redresse quelque peu le dé-
faut inhérent aux indices du Groupe II - Type I, à savoir : ne pas être adaptés aux traitements 
des données disjonctives ou à valeurs nulles très nombreuses.   
 
4.4.3.3 Indice de Marcotorchino-Michaud-2 (1980)  
S’appuyant sur le même  principe que précédemment, un autre indice du même genre que le 
précédent donne des résultats également  intéressants, il s’agit de l’indice suivant : 
 
(f 70)                             
[ ])y,x(01)y,x(10)y,x(00)y,x(11
)y,x(00)y,x(11
)y,x(S
2
1
2
1
2mm
+++
+
=
  
Comme le précédent cet indice varie de 0 à 1, il vaut:  
• 0 si 11(x,y)=00(x,y)=0. Cependant on peut lui appliquer la même remarque que dans le 
cas précédent , a savoir l’extrême rareté d’une telle situation qui correspond au fait 
que les profils de x et y sont totalement inverses l’un de l’autre.  
RNTI-A-3 - 256 -
                                                                                                    F. Marcotorchino 
 
• 1 si 10(x,y)=01(x,y)=0 et 00(x,y)=0, La remarque, faite pour le cas de l’obtention de la 
valeur 0, s’applique ici également, pour une situation inverse. Cette situation , ne peut 
se produire,  en effet, que pour des tableaux de données de présence-absence,  lorsque 
deux individus x et y possèdent l’ensemble complet de toutes les propriétés.  
Il est à noter cependant, comme dans le cas de l’indice précédent,  qu’en cas de disjonction 
complète,  du fait des relations entre les différentes cases du tableau, déjà présentées aupa-
ravant,  la valeur de l’indice se simplifie en : 
                   
2m-2Py)11(x,2
2mPy)11(x,3y)(x,Smm2 +
−+
=
 
Comme dans ce cas,  (disjonction complète), on ne peut avoir  11(x,y) et 00(x,y)  simul-
tanément nuls, puisque 11(x,y)+00(x,y)=P,  l’indice prend sa valeur minimale pour 11(x,y) = 
0 et  vaut alors :  
                              
2m-2P
2m-Py)(x,Smm2 =
  
On voit qu’il ne vaudra 0 que si P=2m (cas de la disjonction  tableaux de présence-absence, 
où chaque variable ne peut avoir que 2 modalités), on se retrouve alors dans le cas , déjà 
discuté pour l’indice Smm(x,y). 
 
 Il prend sa valeur maximum dans le cas où  11(x,y)=m ,valeur pour laquelle il vaut : 
2P
m
2
1
2P
mPy)(x,Smm2 +=
+
=
 
 
De façon surprenante, cette valeur est identique à celle trouvée pour  l’indice précédent.  
On voit qu’il ne prendra la valeur maximale 1 que lorsque P=m, c’est à dire dans la même 
situation que Smm(x,y). La remarque faite  pour Smm(x,y) s’applique ici aussi . Le maximum 
“vrai” (par opposition au “Maximum théorique”) sera obtenu si les variables ont toutes 
deux modalités, ce qui permet d’obtenir une la valeur maximale qui vaut : 
     
4
3
4m
m
2
1y)(x,Smm2 =+=  
La borne « générale de Salomon Fortier » s’écrit dans ce cas : 
                              
m)P2(P
m)m)(P(P2m)P(P
2
1
2P
mP
m)-2(P
2m-P
2
1
2
MaxSMinS
−
+−+−
=


		





	

 +
+


		


=
+  
Si l’on suppose que mpP= , il vient  en remplaçant P par cette valeur: 






−
−=
+
1)p(p2
11
2
1
2
MaxSMinS  
 
L’application de la règle de Salomon Fortier associée au cas de cet indice en environne-
ment disjonctif, nous donne, après remplacement de P par m p  : 






−
−
≥





−
−≥
+
−+
1p2
2p2
2
my)11(x,
1)p(p2
11
2
1
2m-p2my)11(x,2
2mpmy)11(x,3  
Contrairement au cas précédent, qui donnait une règle majoritaire indépendante de p . La 
règle associée ici est dépendante de p , mais tend  assez vite vers une règle de la majorité 
Condorcéenne 
2
m
 , dès lors que  p  est suffisamment grand. 
 
 
RNTI-A-3- 257 -
Essai de Typologie Structurelle des Indices de Similarités  
 
 
Propriété de l’ indice de Marcotorchino-Michaud-2  en cas de disjonction complète théorique 
En cas de disjonction complète, la règle de Solomon - Fortier , si l’on revient aux bornes max 
et min « théoriques » de l’indice, induit l’inégalité suivante, où l’on a remplacé 
½(10(x,y)+01(x,y)) par sa valeur en fonction de 11(x,y) à savoir m-11(x,y):  
         
2
m)y,x(11)y,x(00
2
m)y,x(00)y,x(11)]y,x(11m[)y,x(00)y,x(11
)y,x(00)y,x(11
2
1)y,x(S 2
1
2
1
2
12
1
2mm ≥+≥+≥
−++
+
≥   
On constate,  dans ce cas,  que l’on fait  encore disparaître les configurations 00(x,y) de 
chaque côté de l’inégalité de la règle de Solomon Fortier. Dans ce cas particulier  l’indice qui 
a été doublement rééquilibré , aboutit cette fois ci sur une borne pour 11(x,y), qui n’est rien 
d’autre que la règle de la « majorité  simple ».  Cette dernière propriété en fait un indice en-
core plus intéressant que le précédent  dans le cas de structures disjonctivées ou de tableaux  
de présence-absence à grands nombre de valeurs nulles,  il se comporte comme l’indice de 
Dice , quoique étant d’un Groupe différent.  
 
 
4.4.4 Indices du GROUPE II,  Type II (indices obtenus comme  ratios de fonc-
tions non linéaires   des  quantités du tableau « Tetrachorique ») 
4.4.4.1 Indice lié au Coefficient de corrélation Tetrachorique 
  Cet indice calcule le coefficient de corrélation à partir du tableau Tetrachorique (il est éga-
lement connu sous le nom de coefficient de Bravais-Pearson) , tel qu’introduit au paragraphe 
§.3 (page 19),  il est défini par :  
 
(f71)      
)]y,x(01)y,x(00)][y,x(10)y,x(00)].[y,x(01)y,x(11)][y,x(10)y,x(11[
)]y,x(01).y,x(10)y,x(00).y,x(11[)y,x(ST
++++
−
=
 
Contrairement aux autres indices, rencontrés précédemment,  cet indice varie de -1 à +1, 
comme tout coefficient de corrélation. En particulier : 
• Il vaut   +1 si 10(x,y)   et  01(x,y)=0 
• Il vaut    –1 si   11(x,y)  et  00(x,y)=0 
 
Comportement asymptotique de ce coefficient pour des situations particulières 
  Dans le cas où l’on se sert de ce coefficient ou indice de similarité sur des processus de 
« matching » de listes comme dans le cas de processus de recherche sur Internet (voir § 
4.2.), la quantité 10(x,y) peut être considérée comme un facteur de « bruit »,   inversement  
la quantité 01(x,y) peut être considérée comme du « silence », on « rate » par x de l’existant 
sur y, c’est la raison du mot « silence ».Mais qu’en est-il de la quantité 00(x,y) ?. Dans le 
contexte décrit ci dessus, la quantité 00(x,y) représente ce qui n’est pas lié à l’univers d’un 
questionnement, c’est à dire « tout le reste » hors de la recherche représentée par x ou de 
RNTI-A-3 - 258 -
                                                                                                    F. Marcotorchino 
 
l’univers qu’on veut atteindre représenté par  y. De ce fait, il arrive qu’on ne soit pas ca-
pable de connaître la taille de 00(x,y), qui par ailleurs est forcément très très grande par 
rapport à 11(x,y), 01(x,y) ou 10(x,y) puisqu’il s’agit du reste de l’univers. Les quantités 
10(x,y) et 01(x,y) sont négligeables par rapport à 00(x,y) et dès lors le coefficient ST(x,y) se 
simplifie suivant la formule : 
 
 
(f 72)            
2T )]y,x(00)].[y,x(01)y,x(11)][y,x(10)y,x(11[
)]y,x(00).y,x(11[)y,x(S
++
≅
 
 
Cette simplification permet d’éliminer 00(x,y), à la fois au numérateur et au dénominateur, 
ce qui aboutit à : 
 
(f 73)     
.R.P)y,x(01)y,x(11
)y,x(11
)]y,x(10)y,x(11[
)y,x(11
)]y,x(01)y,x(11)][y,x(10)y,x(11[
)y,x(11)y,x(ST =
++
=
++
≅
 
On retrouve ainsi la moyenne géométrique des indices de Rappel et de  Précision, en 
d’autres termes l’Indice d’Ochiai. 
 
Propriété n°17: dans le cas où 00(x,y) est grand par rapport à  10(x,y) et 01(x,y), l’indice de 
similarité fondé sur le coefficient de corrélation tetrachorique a un comportement très voisin 
de celui de l’indice d’Ochiai et de fait varie de 0 à 1 et non de –1 à +1: 
    )y,x(S)y,x(S oT ≅  
 
Comportement de l’indice ST(x,y) en cas  de Disjonction Complète 
En cas de disjonction complète, comme nous l’avons vu au § 4.1.2 (Propriété n°3),  nous 
avons à notre disposition les formules d’équivalence suivantes : : 
[ ] m)y,x(01)y,x(10
2
1)y,x(11 =++  
P)y,x(01)y,x(10)y,x(00)y,x(11 =+++  
 m2)y,x(11P)y,x(00 −+=   
Nous rajoutons en plus,  une relation évidente, que nous n’avions pas exploitée précé-
demment et qui va nous servir ici : 
10(x,y)=01(x,y) ce qui implique que :  )y,x(11m)y,x(01)y,x(10 −==  
 
L’indice « Tetrachorique » se reformule alors selon l’expression suivante : 
(f 74)       
)mP.(m
mP).y,x(11
]mP][mP].[m][m[
)]y,x(11m[]m2)y,x(11P).[y,x(11)y,x(S
22
T
−
−
=
−−
−−−+
=
 
Sous cette nouvelle expression, on voit que l’indice vaut 1 si 11(x,y)=m,  et vaut :  
)mP(
m
−
−
 si 11(x,y)=0 
Il n’a donc plus un intervalle de variation symétrique  puisque : 1)y,x(S)mP(
m
T ≤≤
−
−
 
 
RNTI-A-3- 259 -
Essai de Typologie Structurelle des Indices de Similarités  
Par ailleurs si l’on étalonne son comportement vis à vis de la « Borne de Solomon et For-
tier », on obtient un résultat qui prouve que cet indice, outre son comportement lié asymp-
totiquement à l’indice d’Ochiai , est un « bon » indice de similarité.  
 En effet comme 1)y,x(S)mP(
m
T ≤≤
−
−
, le véritable milieu de l’intervalle de variation  de 
l’indice ST(x,y), n’est plus ½ comme pour les indices rencontrés précédemment, mais  le 
milieu de  l’intervalle: 




−
− 1   ,
mP
m
  
C’est à dire que la quantité: 




−
−
mP
m12/1 ,  soit: 
)mP(2
m2P
−
−
 ,     devient la “borne de Solo-
mon- Fortier” associée.  Dès lors   on voit que  la règle devient:  
2
my)11(x,        
m)-2(P
2.m-P
      
m)-m(P
m-y).P11(x,
        )mP.(2
m2P.
        )y,x(S
2
T ≥≥
−
−
≥ , 
 
On voit que dans ce contexte, le critère se comporte exactement comme l’indice de Dice 
au voisinage du milieu du segment de variation et l’on retrouve la “règle de la Majorité de 
Condorcet” .   
4.4.4.2 Indices Dérivés, variantes   du Coefficient Tétrachorique 
Un nombre important d’indices ont été définis par de nombreux auteurs, en tenant compte 
du même numérateur que  l’indice Tetrachorique, mais en faisant varier son dénominateur. 
Dans cette famille citons en quelques uns :    
 
a) Indice de Maxwell et Pilliner (1968) 
Ce coefficient qui varie de –1 à +1 est défini par : 
 
)]y,x(10)y,x(00)][y,x(01)y,x(11[)]y,x(01)y,x(00)][y,x(10)y,x(11[
)]y,x(01).y,x(10)y,x(00).y,x(11[2
)]y,y(00).y,y(11[)]x,x(00).x,x(11[
)]y,x(01).y,x(10)y,x(00).y,x(11[2)y,x(SMP
+++++
−
=
+
−
=
 
On constate que si 10(x,y)=01(x,y) , alors: 
)y,x(S)]y,x(10)y,x(00)][[y,x(10.)y,x(11[2
.]))y,x(10()y,x(00).y,x(11[2)y,x(S T
2
MP =
++
−
=
 
c’est exactement ce que vaut le coefficient  Tétrachorique dans ce cas. En particulier en 
cas de disjonction complète , on a: 
[ ] m)y,x(01)y,x(10
2
1)y,x(11 =++   
10(x,y)=01(x,y) 
P)y,x(01)y,x(10)y,x(00)y,x(11 =+++  
m2)y,x(11P)y,x(00 −+=   
En remplaçant ces quantités dans le coefficient de Maxwell et Pilliner, on obtient sa valeur 
en cas de disjonction complète, soit: 
 
)mP.(m
mP).y,x(11)y,x(S
2
MP
−
−
=
, c’est exactement la valeur  qu’on avait obtenue pour le coefficient 
de similarité Tetrachorique,  voir formule (f74), ce qui veut dire que le coefficient de 
Maxwell et Pilliner a le même comportement que le coefficient Tetrachorique vis à vis de 
la borne de Solomon et Fortier.  
RNTI-A-3 - 260 -
                                                                                                    F. Marcotorchino 
 
 Par ailleurs comme l’a montré  M.J. Warrens  (2008), en revenant sur le positionnement 
des Moyennes: Harmonique, Géométrique et Arithmétique (comme nous l’avons fait au § 
4.2.1.3), en utilisant le recodage “astucieux” suivant : 
)]y,x(10)y,x(00)][y,x(01)y,x(11[
)y,x(01)y,x(10)y,x(00).y,x(11
vet)]y,x(01)y,x(00)][y,x(10)y,x(11[
)y,x(01)y,x(10)y,x(00)y,x(11
u
++
−
=
++
−
=
 
on peut exprimer les indices de Maxwell et Pilliner et Tétrachorique comme respective-
ment les moyennes : Harmonique des quantités u et v et Géométrique des quantités u et v 
sous la forme: 
v.u)y,x(Set)vu(
v.u2)y,x(S TMP =+=
 
Comme ces indices varient de –1 à +1 ceci implique la propriété suivante au niveau des 
valeurs absolues des coefficients: 
 
 
b) Indice de  Fleiss (1975) 
 
Dans le même ordre d’idée, la moyenne arithmétique de “u” et “v”   existe,  il s’agit d’un 
coefficient fort peu connu et signalé également  par M.J. Warrens  dans M.J. Warrens 
(2008),  sous le nom de coefficient de J.L. Fleiss (1975), qui s’écrit:  
)vu(
2
1)y,x(SF +=  
])]y,x(10)y,x(00)][y,x(01)y,x(11[
1
)]y,x(01)y,x(00)][y,x(10)y,x(11[
1)][y,x(01)y,x(10)y,x(00)y,x(11[
2
1)y,x(SF
++
+
++
−=
 
Là encore, si 10(x,y)=01(x,y) , le coefficient de Fleiss est égal au Coefficient Tetrachorique  
(c’est ce qui se produit en cas de disjonction complète).  
D’autre part comme : Moyenne géométrique (u,v) ≤   Moyenne Arithmétique de (u,v),  
on obtient:     
 
 
Dans cette famille d’indices dérivés de l’indice Tetrachorique,  il apparaît clairement que ce 
dernier du fait de sa position de « médiane » des deux autres aura la préférence des utilisa-
teurs, d’autre part nous l’avons vu, il joue un rôle de « vrai » coefficient de corrélation.  
 
c)   Indices déduits de l’Inégalité « au Determinant » de J. Hadamard 
Ces indices de similarité  ne sont  pas,   à proprement parler , des  indices découverts par 
Jacques Hadamard (1865-1963), mais parmi les multiples travaux du grand mathématicien, 
une inégalité célèbre qui porte son nom va nous servir, ici, pour donner l’expression d’un 
indice qui peut être considéré comme un dérivé de l’Indice Tétrachorique.  
En effet l’inégalité d’Hadamard s’établit comme suit :  
Théorème n°2 :Soit M une matrice carrée dont les vecteurs colonnes sont  { V1, V2,… Vn }, on 
note 2kV , la norme euclidienne du vecteur colonne Vk : 

=
=
n
1s
2
ks2k vV  
, alors le théorème 
dit  de « l’inégalité d’Hadamard » stipule que l’inégalité suivante est vraie :          
                             
2n2221 V...VV]Mdet[ ≤  
1)y,x(S)y,x(S0 TMP ≤≤≤
1)y,x(S)y,x(S)y,x(S0 FTMP ≤≤≤≤
RNTI-A-3- 261 -
Essai de Typologie Structurelle des Indices de Similarités  
Dans le cas où aucun des Vk n’est nul, on a l’égalité si et seulement si les vecteurs Vk sont 
orthogonaux deux à deux.  
 
Considérons alors  le tableau tétrachorique suivant : 
 
 
 
 
 
 
Posons :  
 
                  M =  
 
 
De ce fait les  vecteurs colonnes associés sont  V1={11(x,y), 01(x,y)} et V2={10(x,y), 00(x,y)} et 
l’application du Théorème N°2 se fait trivialement en se rappelant que pour cette  matrice 
2x2 ,  le determinant vaut :       )]y,x(01)y,x(10)y,x(00).y,x(11[]Mdet[ −=  
L’inégalité de Hadamard implique donc :  
2222 )]y,x(00[)]y,x(10[)]y,x(01[)]y,x(11[)y,x(01)y,x(10)y,x(00).y,x(11 ++≤−  
Dès lors la quantité suivante dénommée  : SHad (x,y), c’est à dire:  
2222Had )]y,x(10[)]y,x(00[)]y,x(01[)]y,x(11[
)y,x(01)y,x(10)y,x(00).y,x(11)y,x(S
++
−
=
 
varie de –1 à +1 , c’est donc bien un indice de similarité dérivé de l’Indice Tétrachorique. 
Cet indice vaut 1 si 01(x,y)=10(x,y)=0 et vaut –1 si 11(x,y)=00(x,y)=0 (c’est à dire lorsque 
les vecteurs colonnes V1 et V2  sont orthogonaux, comme il  en est fait mention dans 
l’intitulé du  Théorème N°2.  D’autre part, comme on pouvait intervertir les roles de x et y 
dans la définition de la Matrice M, on aurait tout aussi bien pu obtenir l’indice suivant à 
partir de l’inégalité de Hadamard:  
 
2222'Had )]y,x(01[)]y,x(00[)]y,x(10[)]y,x(11[
)y,x(01)y,x(10)y,x(00).y,x(11)y,x(S
++
−
=
 
 Les bornes 1 et –1 étant atteintes dans les mêmes configurations que précédemment.    
 
Ainsi lors de la même façon que dans le cas des indices de Maxwell et Pilliner ou Fleiss , en 
posant:  u = SHad (x,y)  et v = S Had’(x,y)  
 
 
y = 1 y = 0 
x = 1 11 10 
x = 0 01 00 
11(x,y) 10(x,y) 
01(x,y) 00(x,y) 
RNTI-A-3 - 262 -
                                                                                                    F. Marcotorchino 
 
On peut définir la famille des indices (symétrisés) dérivés de Hadamard  suivants:    
   )vu()y,x(Setv.u)y,x(S)vu(
v.u2)y,x(S 213HAD2HAD1HAD +==+=
 
Ainsi par exemple on a:  
22222222
2HAD
)]y,x(10[)]y,x(00[])y,x(01[)]y,x(11[)]y,x(01[)]y,x(00[)]y,x(10[)]y,x(11[
)y,x(01)y,x(10)y,x(00).y,x(11)y,x(S
++++
−
=
 
Comme   pour tout couple de nombres positifs {a,b}: on  l’inégalité   22 ba)ba( +≥+ , il  
apparaît de façon évidente que le dénominateur de ST(x,y) est supérieur  à celui de 
SHAD2(x,y) et donc que l’on a la les inégalités suivante: 
 
 
 
En jouant ensuite sur l’ordonnance des moyennes pour les indices de Hadamard , couplée 
aux résultats obtenus  précédemment en  b) il  vient :   
1)y,x(S)y,x(S)y,x(S)y,x(S)y,x(S0 3HAD2HADFTMP ≤≤≤≤≤≤  
 
4.4.4.3 Les Indices Y et Q de Yule 
   Les indices de similarité Y et Q de Yule dont une première version partielle est donnée 
dans le livre de  Yule et  Kendall (voir G. Yule et M.G. Kendall (1950)), et réétudiée par la 
suite par G. Yule, seul, se calculent également à partir du tableau de contingence Tetracho-
rique, puisqu’ils font jouer un rôle  aux quatre quantités principales en jeu. Sur le principe,  
l’indice Y est le plus connu des deux,  on parle à son sujet de coefficient de « colliga-
tion », en effet il a été construit à partir des notions d’ « odd ratios », souvent utilisés en 
statistique des contingences  par les anglo-saxons. Il est défini par : 
  
(f 75)              
)y,x(01).y,x(10)y,x(00).y,x(11
)y,x(01).y,x(10)y,x(00).y,x(11)y,x(SY
+
−
=
 
Comme on le voit immédiatement cet indice varie de -1 à +1, il vaut : 
•  1  si 10(x,y) ou  01(x,y)=0 
• -1  si 11(x,y) ou  00 (x,y) =0 
Contrairement au cas du Coefficient ST(x,y), il est a noter la présence du « ou » et non du 
« et » pour l’obtention des cas +1 et –1 de l’indice, ceci, entre autre, permet de différencier 
les deux  indices, qui par ailleurs ont des comportements assez voisins.  
Contrairement au cas de l’indice ST(x,y), il est à noter, également ici, que cet indice est peu 
(voire pas du tout) adapté aux situations  où   00(x,y) est très grand, en effet  il est prati-
quement voisin de 1 dans ces cas là et donc peu discriminant.  
 
L’indice Q de Yule est une variante de l’indice précédent, en effet il s’écrit : 
  
1)y,x(S)y,x(S0 2HADT ≤≤≤
RNTI-A-3- 263 -
Essai de Typologie Structurelle des Indices de Similarités  
(f 76)              
)y,x(01).y,x(10)y,x(00).y,x(11
)y,x(10).y,x(01)y,x(00).y,x(11)y,x(SQ
+
−
=  
Il varie également de –1 à +1 et vaut :  
•  1  si 10(x,y)  ou  01(x,y)=0 
• -1  si 11(x,y) ou  00 (x,y) =0 
 
Si l’on compare l’indice Q de Yule et l’indice Tetrachorique, il est évident que l’indice Q 
de Yule a une valeur qui sera toujours supérieure à l’indice  de l’indice Tetrachorique . En 
effet on a à comparer : 
 
)]y,x(01)y,x(00)][y,x(10)y,x(00)].[y,x(01)y,x(11)][y,x(10)y,x(11[
)]y,x(01).y,x(10)y,x(00).y,x(11[)y,x(ST
++++
−
=
 et   
)y,x(01).y,x(10)y,x(00).y,x(11
)y,x(10).y,x(01)y,x(00).y,x(11)y,x(SQ
+
−
=
 
Ces deux indices ont la même valeur du numérateur  et en revanche ils ont un dénomina-
teur différent . 
Or si l’on pose y)y).01(x,10(x,y)y).00(x,11(x,A +=   et si l’on élève le dénominateur de 
l’indice y)(x,ST  au carré , on voit que le  dénominateur concerné s’écrit: 
          (A+11(x,y)10(x,y)+00(x,y)01(x,y)) (A+11(x,y)01(x,y)+00(x,y)10(x,y))=A2+  (où  
  0) 
 
Or le carré du dénominateur de l’indice Q de Yule  est justement égal à A2 , de ce fait on a: 
 
                       Dénominateur de l’indice Q de Yule  Dénominateur de l’indice Tétrachorique 
Ceci implique donc la relation: 
                                                    yx,y)(x,Sy)(x,S QT ∀≤  
(car les deux indices peuvent être positifs ou négatifs) 
Par ailleurs, il serait intéressant de voir comment varient SY(x,y) et SQ(x,y), l’un en fonction 
de l’autre, puisqu’ils utilisent tous les deux les mêmes quantités. Pour plus de simplicité, 
on va travailler sur leurs variantes transformant leur formalisme d’indices de « corréla-
tion » variant de –1 à +1 en indices de similarité variant de 0 à 1 , pour ce faire , il suffit de 
reprendre la note de bas de page n°1 et calculer : 
                        yx,1]y)(x,S[
2
1y)(x,S'et1]y)(x,[S
2
1
 y)(x,S' QQYY ∀+=+=  
Les deux nouveaux indices s’écrivent alors : 
y)y).01(x,10(x,y)y).00(x,11(x,
y)y).00(x,11(x,y)(x,S'et
y)y).01(x,10(x,y)y).00(x,11(x,
y))y).00(x,11(x,y)(x,S' YQ
+
=
+
=
 
Dire que : 
                 
)yy).01(x,10(x,y)y).00(x,11(x,y)y).01(x,10(x,y)y).00(x,11(x,y)(x,S'y)(x,S' YQ ≥≥≥  
 ceci implique que :  
                                              
2
1y)(x,S'y)(x,S' YQ ≥≥
,  
 
dans le cas inverse l’inégalité se produira dans le sens contraire et l’on aura : 
                                              
2
1y)(x,S'y)(x,S' YQ ≤≤
 
 
RNTI-A-3 - 264 -
                                                                                                    F. Marcotorchino 
 
Comportement des indices SY(x,y) et SQ(x,y) en cas  de Disjonction Complète 
En utilisant la série de formules déjà mentionnée au § précédent , on peut simplifier 
l’expression de ces deux indices dans le cas de disjonction complète et l’on obtient pour 
l’indice SQ (x,y), (le seul à pouvoir donner des simplifications interprétables puisque ne 
faisant pas appel à des racines carrées)  :  
 
 (f 77)       
22
2
2
2
Q )]y,x(11m[2)m)y,x(11.P(
m)y,x(11.P
)]y,x(11m[]m2)y,x(11P).[y,x(11
)]y,x(11m[]m2)y,x(11P).[y,x(11)y,x(S
−+−
−
=
−+−+
−−−+
=
 
Sous cette dernière forme on voit que l’indice vaut :  1 si 11(x,y) = m et  –1 si 11(x,y)=0 
Puisque l’intervalle de variation de SQ(x,y) est ici (-1,+1) le milieu de l’intervalle de varia-
tion est égal à 0,. et de ce fait la borne de Solomon- Fortier  pour SQ(x,y) est donnée par :  
SQ(x,y)≥0, ce qui implique : 
 
(f78)          
P
m)y,x(11         0m)y,x(11.P           0
)]y,x(11m[2)m)y,x(11.P(
m)y,x(11.P)y,x(S
2
2
22
2
Q ≥≥−≥
−+−
−
=
 
 
Montrons que cette borne pour 11(x,y),  bien que non aberrante lorsque le nombre moyen 
de modalités par variable n’est pas trop fort, le devient si ce nombre augmente . En effet 
nous savons que pmP = , où p  est le nombre moyen de modalités par variable, de ce fait la  
borne donnée dans l’équation (f 78) devient: 
 
                                            
p
m
pm
m
P
m)y,x(11     
22
==≥  
Pour p=2 on retrouve la règle majoritaire simple ou de Condorcet , pour p=3 , on obtient 
une règle au tiers etc.,  en fait on obtient une règle inversement proportionnelle au nombre 
de modalités moyen.  
 
En d’autre termes cet indice n’aura aucun pouvoir discriminant dès lors que le nombre 
moyen de modalités est fort (si par exemple on travaille sur m=10 variables, chacune ayant 
10 modalités, on voit qu’il suffit que 11(x,y)=1 pour que l’indice atteigne la borne de simi-
larité de Solomon-Fortier). 
Le lecteur pourra vérifier facilement par lui-même  que la  borne sur 11(x,y) associée à la 
règle de  Solomon-Fortier est exactement la même pour  l’indice SY(x,y) que celle associée 
à l’indice SQ(x,y) et donnée par la formule (f 78).  
 
4.4.4.4 L’indice de Moyenne Arithmétique des « quatre ratios » d’Anderberg (1973) 
Cet indice qui est explicitement défini dans le livre de Michael Anderberg (1973), page 
91, a été introduit par ce dernier comme une généralisation de la moyenne arithmétique 
des indices de « Rappel » et « Précision » de Kulczynski à l’ensemble des ratios probabi-
listes possibles, issus du tableau Tetrachorique. Certain l’attribue d’ailleurs à Sokal et 
Sneath (1963).  Il se définit de la façon suivante : 
 
RNTI-A-3- 265 -
Essai de Typologie Structurelle des Indices de Similarités  
(f79)      






+
+
+
+
+
+
+
= )y,x(10)y,x(00
)y,x(00
)y,x(01y,x(00
)y,x(00
)y,x(01)y,x(11
)y,x(11
)y,x(10)y,x(11
)y,x(11
4
1)y,x(S 4R  
 
Cet indice varie bien de 0 à 1, il vaut: 
• 1 si 10(x,y)=01(x,y)=0   
• 0 si 11(x,y)=00(x,y)=0 
En s’inspirant  de la propriété du passage aux moyennes harmoniques des quantités 
11(x,x), 11(y,y), 00(x,x), 00(y,y) ,  déjà vue au sujet de l’indice de Kulczynski  (voir (f 35)) 
on a une autre expression posssible et plus compacte  de cet indice : 
(f 80)              






+=
y)]x),00(y,[00(x,MH
y)00(x,
y)]x),11(y,[11(x,MH
y)11(x,
2
1y)(x,SR4
 
 
Le développement de la formule (f 79) par réduction au même  dénominateur  est possible 
mais entrainerait des calculs fastidieux, le dénominateur serait identique par ailleurs au 
carré de celui de la formule (f 71) concernant le coefficient de corrélation Tetrachorique.  
 
Comportement de l’indice SR4(x,y) en cas  de Disjonction Complète 
Comme nous l’avons fait précédemment, un bon moyen de comprendre un peu plus avant 
comment se comporte cet indice revient à le calculer dans le contexte particulier de la 
situation de disjonction complète. En effet dans ce cas la formule globale se simplifie et un 
certain nombre de propriétés caractéristiques peuvent être mises en évidence. En effet en 
cas de disjonction complète l’indice SR4 (x,y) se simplifie selon la formulation suivante : 
   
       




−
−+
+=



−
−+
+
−
−+
++=
mP
m2)y,x(11P
m
)y,x(11
2
1
mP
m2)y,x(11P
mP
m2)y,x(11P
m
)y,x(11
m
)y,x(11
4
1)y,x(S 4R
 
 
ce qui, après réduction au même dénominateur et simplifications au numérateur,  nous 
donne: 
 
 (f 81)       
)mP(m.2
mP).y,x(11
2
1
)mP(m.2
)mP(mmP).y,x(11
mP
m2)y,x(11P
m
)y,x(11
2
1)y,x(S
22
4R
−
−
+=
−
−+−
=



−
−+
+=
 
Sous cette dernière forme on voit que l’indice vaut 1 si 11(x,y)=m  (sa valeur maximum) et 
vaut: 
)mP.(2
m
2
1
−
−
, soit 
)mP.(2
m.2P
−
− si 11(x,y)=0, son intervalle de variation est donc:  
1)y,x(S)mP.(2
m.2P
4R ≤≤
−
−
, et le milieu du segment associé est donné par:  
                                 
)mP(4
P1)mP(4
m4P3
)mP.(2
m.2P1
2
1
−
−=
−
−
=








−
−
+  
Si l’on applique la règle de Solomon-Fortier sur cette valeur précédente comme étalonna-
ge de l’ indice, on obtient:   
(f 82)         
2
my)11(x,         )mP(4
P1)mP(m2
mP)y,x(11
2
1
            )mP(4
P1)y,x(S
2
4R ≥
−
−≥
−
−
+
−
−≥  
 
RNTI-A-3 - 266 -
                                                                                                    F. Marcotorchino 
 
Là encore, on voit que la règle de Solomon Fortier  appliquée à cet indice, avec  un seuil 
“milieu d’intervalle de variation”,  redonne la règle de la majorité simple de Condorcet au 
niveau d’une borne sur 11(x,y). Cet indice bien que complexe à calculer est donc plus 
cohérent que les deux indices de Yule. En particulier il semble avoir un comportement 
voisin de celui de l’indice Tetrachorique à une homothétie près. 
 
4.4.4.5  L’indice de Moyenne Géométrique  des « quatre ratios » d’Ochiai (1973) 
 Cet indice comme le précédent est une généralisation sur les 4 cases du tableau Tetracho-
rique de l’indice d’Ochiai , on peut d’ailleurs  l’attribuer également à Anderberg, même si 
ce dernier en donne la paternité au zoologiste Japonais, par filiation. C’est de façon simple 
la moyenne géométrique d’ordre 4 des quatre ratios précédemment définis pour l’indice 
SR4(x,y). Cet indice est défini par :  
 
(f83)     44o )y,x(01)y,x(00
)y,x(00
x)y,x(10)y,x(00
)y,x(00
x)y,x(01)y,x(11
)y,x(11
x)y,x(10)y,x(11
)y,x(11)y,x(S
++++
=
 
Cet indice varie de 0 à 1, il vaut : 
• 1 si 10(x,y)=01(x,y)=0 
• 0 si 11(x,y)=00(x,y)=0 
   
Comportement de l’indice So4(x,y) en cas  de Disjonction Complète 
 Comme nous l’avons fait pour l’indice d’Anderberg précédent, pour avoir une bonne idée du 
comportement de cet indice, calculons  sa valeur  dans le contexte particulier de la situation 
de disjonction complète. En effet dans ce cas la formule globale se simplifie, et comme dans 
le cas de SR4(x,y)  un certain nombre de propriétés caractéristiques peuvent être mises en 
évidence. En effet en cas de disjonction complète l’indice  So4(x,y) se simplifie selon la for-
mulation suivante : 
 
(f 84)        44o
mP
m2)y,x(11P
x
mP
m2)y,x(11P
x
m
)y,x(11
x
m
)y,x(11)y,x(S
−
−+
−
−+
=
 
 
Soit après simplifications :  
(f 85)        
mP
m2)y,x(11P
x
m
)y,x(11)y,x(S 4o
−
−+
=
 
 
 
Sous cette forme  simplifiée, on voit que cet indice vaut 1 si 11(x,y)=m (valeur maximum du 
« matching » en cas de disjonction complète) et il vaut 0 si 11(x,y)=0. 
A titre de comparaison  et pour l’étalonner, calculons la borne induite sur 11(x,y) dès que l’on 
applique la règle de Solomon et Fortier. Ici l’intervalle de variation, même dans ce cadre 
disjonctif est (0, 1), la borne de la règle de Solomon- Fortier est donc fixée à ½ , d’où : 
 
 (f 86)                      
     
2
1
mP
m2)y,x(11P
x
m
)y,x(11
            
2
1)y,x(S 4o ≥
−
−+
≥  
 
RNTI-A-3- 267 -
Essai de Typologie Structurelle des Indices de Similarités  
 
 
 
 
 
 
 
Le développement de la formule (f 85) aboutit à résoudre l’inégalité du second degré en 11(x,y) suivante14 : 
0   )mP.(m
4
1
-y)2m).11(x,-(P  y)(x,11 2 ≥−+  ,  avec  3m3mP-Pm)m(P2m)(P 222 +=−+−=  
le calcul du déterminant de cette équation et le fait que  11(x,y) varie de 0 à m, donc est toujours positif, nous permet 
de définir la racine positive de l’équation qui est donnée par : 
                              [ ][ ] pmPoù1)2p)(1p(m)2p(m
2
1
z
2
1 =+−−+−−=
  
Comme : 
                         [ ][ ] 





+−+−−=+−−+−− )1)1p((
p
1
m)2p(m
2
11)2p)(1p(m)2p(m
2
1 32 ,  
on obtient : 








−
+−−+−−= ]
)1p(
1)1p[(
p
1)1p(m)2p(m
2
1
z
21
en simplifiant l’expression sous le signe « racine carrée » et en 
utilisant un développement limité de la racine carrée au voisinage de 0 (ce qui a d’autant plus de sens que p  est non 
négligeable), il vient :     
                             
2
222 1)p(
1
p
1
8
1
1)p(
1
p.
1
2
11
1)p(
1
p
11 





−
−+





−
−−≅





−
+−
  
en remplaçant cette valeur dans l’expression de z1, on obtient la une valeur très légèrement supérieure pour z1,  à 
savoir : 









		


+
−
++−−++−≅














−
−−−+−−= )
p
1(O
1)p( 2
1
p 8
1
p2
111)pm(2mpm
2
1
1)p(
1
p
111)pm(2)pm(
2
1
z 32221
, 
Pour satisfaire l’inégalité (f 86), 11(x,y) doit être supérieur à l’approximation de z1,  donnée ci-dessus . 
La borne de la règle de Solomon-Fortier devient alors  :   
                                                
1)p(p8
5]pm[9.
4
my)11(x,
−
−
+≥      
Si le nombre moyen de modalités est égal à 5 par exemple,  on voit que 11(x,y) doit vérifier approximativement  une 
règle de majorité Condorcéenne simple (m/2). 
On voit qu’à la limite, si  p  croît, la borne tend vers 
4
m
, c’est à dire  vers une « majorité au 
quart ».  
Dans ce cas là, comme d’ailleurs dans le cas d’indices du Groupe I Type II auquel l’indice 
d’Ochiai , vrai, appartient, on voit que cet indice est plus « généreux »  que l’indice des « 4 
ratios d’Anderberg » , voire trop généreux ce qui montre qu’il n’a que peu d’intérêt comme 
mesure discriminante. 
                                                 
14
 Les valeurs de 11(x,y) étant entières, les calculs sur l’inégalité (f 86) se font en supposant une relaxation en 
valeurs réelles de 11(x,y) , 0 ≤ 11(x,y) ≤ m, au lieu d’avoir 11(x,y) ∈ { 0,1,2,…m } 
 
 
RNTI-A-3 - 268 -
                                                                                                    F. Marcotorchino 
 
4.4.4.6 L’indice de Moyenne Harmonique  des « quatre ratios » 
    Continuant dans le même principe de généralisation que précédemment, nous définirons 
un indice de  moyenne harmonique des quatre ratios tetrachoriques, en  définissant ce nouvel 
indice Sh4(x,y) par : 
(f 84)       





 +
+
+
+
+
+
+
= )y,x(00
)y,x(01)y,x(00
)y,x(00
)y,x(10)y,x(00
)y,x(11
)y,x(01)y,x(11
)y,x(11
)y,x(10)y,x(11
4
1
)y,x(S
1
4h
 
 
Cet indice peut être simplifié selon la formule: 
  





 ++
+
++
= )y,x(00
)y,x(01)y,x(10)y,x(00.2
)y,x(11
)y,x(01)y,x(10)y,x(11.2
4
1
)y,x(S
1
4h
 
Comme par ailleurs : 11(x,y)+00(x,y)+10(x,y)+01(x,y)=P, il peut être exprimé uniquement en 
fonction des quantités 00(x,y) et 11(x,y), il vient: 
 
                 





 +−
+
+−
= )y,x(00
)y,x(00.)y,x(11P
)y,x(11
)y,x(11)y,x(00P
4
1
)y,x(S
1
4h
 
 
Après réduction au même dénominateur et inversion de la formule il vient: 
                   








−−+
= 24h )]y,x(11y,x(00[)]y,x(00)y,x(11[P
)y,x(00).y,x(114)y,xS  
 
Sous cette dernière formulation on voit que   cet indice vaut : 
• 1 si 10(x,y)=01(x,y)=0 , en effet dans ce cas P=00(x,y)+11(x,y) et le dénominateur revient 
à : 4.11(x,y).00(x,y) 
• 0 si 11(x,y) =0  
Comportement de l’indice Sh4(x,y) en cas  de Disjonction Complète 
Comme précédemment donnons un étalonnage de cet indice par rapport à la règle de Solo-
mon et Fortier en cas de disjonction complète. En remplaçant 00(x,y) par P+11(x,y)-2m, et en 
revenant à la formule (f74) nous avons  l’expression suivante de l’indice: 
 
(f88)                           






−+
−
+=
m2)y,x(11P
)mP(
)y,x(11
m
2
1
)y,x(S
1
4h
 
 
A partir de  cette expression obtenue lors d’une disjonction complète, on voit bien que cet 
indice est maximum lorsque 11(x,y)=m,  puisque qu’alors on trouve 2/2. 
 
Calculons maintenant la valeur de la borne sur 11(x,y), lorsqu’on applique la règle de Solo-
mon et Fortier. 
Puisque l’intervalle de variation est bien: (0, 1), la borne choisie pour l’indice sera ½. 
 
La formule (f 88) induit donc l’inégalité fonction de 11(x,y) suivante:  
2
1
)m2P(mP).y,x(11
]m.2)y,x(11P)[y,x(11.2
              
2
1)y,xS 4h ≥
−+
−+
≥  
 
RNTI-A-3- 269 -
Essai de Typologie Structurelle des Indices de Similarités  
Ce qui implique l’inégalité quadratique suivante pour 11(x,y): 
 (f 89)                 0)m2P(m]m.8P.3)[y,x(11)y,x(11.4 2 ≥−−−+   
 
En tenant compte de la remarque faite dans la note de bas de page n°4, la borne inférieure sur 11(x,y) sera la racine 
positive de l’équation du second degré précédente. Le déterminant n’est pas simple, il est égal à : 
[ ] [ ] 222 Pm2P.8)m2P(m16m8P3 +−=−+−=Δ  
La racine positive z1 est donnée par : 
8
P]m.2P[8P3m8
z
22
1
+−+−
=
 en jouant sur le fait que pmP = , on obtient : 






+=





+−=





+−+−≅





+−+−=
+−+−
=
p9
341
3
m
p27
272
3
168
8
m]
p81
272
p9
16[1p3p38
8
m
p9
32
p9
321p3p38
8
m
8
1]
p
28[1pm)p3m(8
z 22
2
1
 
L’approximation sur la racine carrée étant d’autant plus significative que p  est fort, on voit que la borne pour 
11(x,y)  se traduit ici par : 
     






+≥
p
3.771
3
my)11(x, ,  
 
4.4.4.7 Indice de Baroni-Urbani  et  Buser  (1976)  
   Cet indice,  introduit en 1976 (voir Baroni, Urbani et Buser (1976)) par des spécialistes de 
systématique zoologique se distingue des précédents en ce sens qu’il dissymétrise l’influence 
des configurations de « matchings »,  qu’il traite non linéairement , des configurations de 
« non matching » , qu’il traite linéairement, le  tout en pondérant légèrement plus le « mat-
ching 11 », bref un indice pas « naturel  du tout » quant à sa filiation . Cependant il semble 
donner satisfaction aux experts des  domaines de la zoologie (systématiciens, phylogénistes), 
de la biologie (spécialistes des mesures de bio-diversité)  ou de l’écologie en général (voir à 
ce propos  l’article de  Richard Boyle et Paula Ellison  (2001)).  
 
 (f 90)                   








+++
+
=
y)10(x,y)01(x,y)11(x,y)y).00(x,11(x,
y)11(x,y)y).00(x,11(x,
y)(x,SBuB
 
Cet indice varie  bien de 0 à 1, il vaut 1 quand 10(x,y)=01(x,y)=0 et il vaut 0 quand 11(x,y)=0 . 
Pour ce faire une idée de plus précise de cet indice on peut le comparer à l’indice Y de Yule, 
donné par : 
 
                                    
y)y).01(x,10(x,y)y).00(x,11(x,
y)y).01(x,10(x,y)y).00(x,11(x,
y)(x,SY
+
−
=
 
qui met en jeu des  quantités voisines.  Mais ce dernier, on l’a vu,, se comporte comme un 
indice de type indice de corrélation puisqu’il varie de -1 à 1,  mais en utilisant la remarque de 
bas de page n°1, on sait que : S(x,y)=1/2(xy+1) construit à partir d’un indice de corrélation rede-
vient un indice de similarité variant de 0 à 1.  
On peut donc comparer l’indice   y)(x,SBuB   
à l’indice       [ ]
y)y).01(x,10(x,y)y).00(x,11(x,
y)y).00(x,11(x,1y)(x,S
2
1y)(x,S YY'
+
=+=
 
Pour ce faire montrons que : 
RNTI-A-3 - 270 -
                                                                                                    F. Marcotorchino 
 
                               
y)00(x,y)10(x,y)11(x,y)y).00(x,11(x,
y)11(x,y)y).00(x,11(x,
y)y).01(x,10(x,y)y).00(x,11(x,
y)y).00(x,11(x,
+++
+
≥
+
 
En effet après développement on obtient : 
 
         (i) y)y).01(x,10(x,y)]11(x,y)y).00(x,11(x,[y)y).00(x,11(x,y)]01(x,y)[10(x, +≥+  
Or    (ii)  y)y).01(x,10(x,2y)01(x,y)10(x,]y)01(x,y)10(x,[ 2 −+=− ,  
 
en remplaçant  l’expression de 10(x,y)+01(x,y) , telle qu’elle apparaît dans (ii) et en la repor-
tant dans (i) , on obtient :  
        
(iii) [ ] y)y).01(x,10(x,y)]11(x,y)y).00(x,11(x,[y)y).00(x,11(x,y)y).01(x,10(x,2]y)01(x,y)10(x,[ 2 +≥+−  
soit  après simplification: [ ] ]y)y).00(x,11(x,y)]11(x,[y)y).01(x,10(x,[y)y).00(x,11(x,]y)01(x,y)10(x,[ 2 −≥−  
Le membre de gauche de cette inégalité est toujours positif , alors que le membre de droite 
est toujours négatif , sauf en cas de disjonction bivalente, i.e ; P=2m. En effet en général  
00(x,y) 11(x,y) d’où :   y)11(x,y)y).00(x,11(x, ≥  
De ce calcul nous déduisons : 
                                                        yx,y)(x,Sy)(x,S' BuBY ∀≥  
Comportement de l’indice SBuB(x,y) en cas  de Disjonction Complète 
En cas de disjonction complète, on développe l’expression précédente  en fonction de 11(x,y), 
de P et de m  selon les formules  obtenues en remplaçant  00(x,y), 10(x,y) et 01(x,y) par leurs 
valeurs en fonction de 11(x,y) et de P, du fait que  on retrouve : 00(x,y)=11(x,y)+P-2m, 
01(x,y)=10(x,y)=m-11(x,y), 
 
       








−++
++
=
y)11(x,2m2m]-Py)y)[11(x,11(x,
y)11(x,2m]-Py)y)[11(x,11(x,
y)(x,SBuB
 
Comme la borne de  Solomon Fortier  vaut ½ , puisque l’indice varie bien de 0 à 1, la borne 
de référence sera obtenue pour la valeur  11(x,y) , telle que:     
2
1
y)11(x,2m2m]-Py)y)[11(x,11(x,
y)11(x,2m]-Py)y)[11(x,11(x,
2
1
 y)(x,SBuB ≥








−++
++
≥
 
 
Cette inégalité implique l’équation  du second degré suivante: 
                           04m10]mpy)[11(x,y)(x,8.11 22 ≥−++−  (où  l’on  a remplacé P par pm ) 
 
On  prend la racine positive z1, comme nous l’avons fait précédemment en simplifiant les expressions sous  les 
racines, nous obtenons: 






−=





−=











+−−+−+≅





−+−+=
−+−+
=
p4
354
p
m
p
140
p
64
16
m
p
140
p
50
p
14
p
101pp10
16
m
p
28
p
20
 1pp10
16
m
16
]
p
28
p
20[1pm10]pm[
z 23222
2
1
 
                        Ceci implique donc que :     






−≥
p4.
354
p
my)11(x,  
On voit par exemple que si 4p = , alors 11(x,y) doit être supérieur à  0,45 m , c’est à dire que si m=9 (par exemple)  
on doit avoir 11(x,y)4, (puisque les valeurs de 11(x,y) sont toujours des valeurs entières), on vérifie bien  d’après  
la formule(f87)  que : 
RNTI-A-3- 271 -
Essai de Typologie Structurelle des Indices de Similarités  
 
57,0
38,23
38,13
1488
488
)418()18364.(4
4)18364.(4
y)11(x,2m2m]-Py)y)[11(x,11(x,
y)11(x,2m]-Py)y)[11(x,11(x,
y)(x,SBuB ==
+
+
=
−+−+
+−+
=








−++
++
=
 
On voit d’ailleurs sur cet exemple qu’il faut que 11(x,y) soit strictement supérieur à 4 , si 11(x,y) n’était égal qu’ à 3 
la valeur de l’indice serait égale à  0,4768, ce qui ne permettrait pas de vérifier la Borne de Solomon Fortier. 
Le comportement  limite de l’indice n’est pas évident si   p  prend des valeurs  grandes, on 
voit que la borne implique  une majorité au 
p
4
  èmes, ce qui n’en fait pas un indice de carac-
tère général utilisable dans des conditions standard.  
 
4.4.5 Indices du GROUPE II,  Type III (indices obtenus comme  ratios de fonc-
tions complexes  non standard  des  quantités du tableau « Tetrachorique ») 
     Dans ce paragraphe nous introduirons certains indices utilisés en statistique  pour mesurer 
les interactions et les associations sur tableaux de contingences,  puisque le tableau Tetracho-
rique  n’est, après tout, qu’un tableau de contingence (2x2) particulier.   
 
Dans cette configuration l’utilisation des coefficients d’association sur tableau de contin-
gence peut ou non (cela dépend du contexte ) servir de base à des indicateurs de similarité, à 
condition d’une part de distinguer les configurations dites de « matchings » positifs des con-
figurations  de « matchings » négatifs, ce que ne font pas d’amblée ces coefficients 
d’association .   
Rappelons ici qu’un tableau de contingence croisant deux variables catégorielles x et y, x 
ayant p modalités  et y ayant q modalités se présente sous la forme suivante :   
 
 
 
    
 
 
 
 
 
 
 
 
 
Où  







=
=
=
=
objetsd'totalNombren
ydevmodalitélaayantobjetsd'Nombren
xdeumodalitélaayantobjetsd'Nombren
,ydevetxdeumodalitélafoislaàayantobjetsd'Nombren
..
v.
.u
vu
 
 
Nous donnerons dans les paragraphes suivants des coefficients ou indices d’association que 
nous évaluerons en tant qu’indices de similarité. Ceci se fera au travers d’un processus con-
     y 
x 
1 2 v .. q 
 
1      n1. 
2      n2. 
u   vun  
  
 n
 u . 
..       
p       
 
n
.1 n.2 n. v   n.. 
RNTI-A-3 - 272 -
                                                                                                    F. Marcotorchino 
 
sistant à remplacer les valeurs vun  du tableau de contingence général précédent par les 
valeurs correspondantes du tableau particulier de contingence que nous avons nommé « Te-
trachorique » et qui se présente sous la forme :  
 
  
 
 
 
 
 
Dans le cas du tableau Tetrachorique les valeurs p et q  du tableau général   sont égales à 2 , 
la valeur Pn
..
= ,   et les différentes  valeurs vun sont au nombre de 4, à savoir : 11(x,y), 
10(x,y , 01(x,y) et 00(x,y).   
 
4.4.5.1  Indice de similarité déduit  du Coefficient d’Ecart à l’Indétermination Contingen-
tielle, du coefficient de Janson-Vegelius et du Critère de Rand 
 
 Rappelons que cet indice d’  « Ecart à l’Indétermination » , dont on pourra trouver les pro-
priétés dans  F. Marcotorchino (1984) et F. Marcotorchino et N. El Ayoubi (1991), se pré-
sente sous la forme : 
                                           


= =









		


−+−=
p
1u
q
1v
2
..v.u.
uv pq
n
p
n
q
n
ny)Ind(x,  
Cet indice est en fait le numérateur du coefficient J(x,y) de Janson et Vegelius (voir S. Janson 
et J. Vegelius  (1982)) , coefficient spécial de corrélation,  donné  lui-même sous la forme 
d’un ratio composite : 
 
(f 91)                                                  
y)D(x,
y)N(x,y)J(x, =  
Le numérateur est donné par : 
                                          
pq
n
p
n
q
n
ny)N(x,
2
..
q
1v
2
v.
p
1u
2
.up
1u
q
1v
2
vu +−−=





 ==
= =
 
le dénominateur étant donné par :  
                                          


==
+





−+





−=
q
1v
2
2
..2
v.
p
1u
2
2
..2
.u q
n
q
21n
p
n
p
21ny)(x, D   
 
Par ailleurs,  on peut montrer ( voir les articles précités de  (1984) et (1991) ) que : 
 
 y = 1 y = 0 
x= 1 11(x,y) 10(x,y) 
x= 0 01(x,y) 00(x,y) 
RNTI-A-3- 273 -
Essai de Typologie Structurelle des Indices de Similarités  
     y)N(x,
pq
n
p
n
q
n
n
pq
n
p
n
q
n
ny)(x,Ind
2
..
q
1v
2
v.
p
1u
2
.up
1u
q
1v
p
1u
2
vu
q
1v
2
..v.u.
uv =+−−=








		


−+−=





 

 ==
= = = =
 
  
Cet indice  J(x,y) varie bien de 0 à 1 . 
• Il  vaut 0 en cas d’Indétermination totale sur toutes les cases du tableau de contingence 
voir F. Marcotorchino (1984) pour des détails sur cette structure particulièrement inté-
ressantes  des données), c’est à dire si : 
vetu
pq
n
p
n
q
n
n0
pq
n
p
n
q
n
n
..v.u.
vu
p
1u
q
1v
2
..v.u..
uv ∀


		


−+==











		


−+−


= =
 
• Il vaut 1 en cas d’association complète (voir (M1984)), c’est à dire d’une part si : p=q, 
d’autre part si pour toute cellule (u,v) du tableau de contingence on a :  
                                                
vu0n
vunnn
vu
v.u.vu
≠∀=
=∀==
   
       dans cette configuration on voit, de façon simple, que :   
    

=
+





−==
p
1u
2
2
..2
.u p
n
p
21ny)N(x,y)(x, D    
Considérons alors le Coefficient d’ « Association de Janson –Vegelius »  donné sous forme 
développée  par : 
 
 
(f 92)                 








+


		


−








+


		


−









		


−+−
==






==
= =
q
1v
2
2
..2
v.
p
1u
2
2
..2
.u
p
1u
q
1v
2
..v..u
vu
q
n
q
21n
P
n
p
21n
pq
n
p
n
q
n
n
y)D(x,
y)N(x,y)J(x,
 
 
En remplaçant  dans l’expression du coefficient complexe de Janson -Vegelius :   n
..  
par P, p 
et q par 2  et 
vun  par l’une des valeurs  :  11(x,y), 10(x,y), 01(x,y), 00(x,y), on obtient , 
l’expression très simplifiée suivante: 
[ ] [ ]
2
2
22
2
P
y))01(x,y)(10(x,y)00(x,y)11(x,
4
P
4
P
y))01(x,y)(10(x,y)00(x,y)11(x,
4
1
y)J(x, +−+=
+−+
=
 
Dès lors, on peut définir à partir du Coefficient de similarité de Janson-Vegelius, l’ indice de 
similarité  SJV(x,y) associé défini par : 
 
(f 93)                    [ ]
P
y))01(x,y)(10(x,y)00(x,y)11(x,y)J(x,y)(x,S VJ
+−+
==
 
On constate  sous cette forme et après simplification des calculs,  que l’indice obtenu n’est ni 
plus ni moins que la version « corrélative »  de l’indice de Sokal et Michener (ou indice de 
« Simple Matching »)  (voir (f 55)), c’est à dire qu’il varie de –1 à +1.  
 
                            +1 si 10(x,y)=01(x,y)=0  et –1 si 11(x,y)=00(x,y)=0 
 
RNTI-A-3 - 274 -
                                                                                                    F. Marcotorchino 
 
On aurait pu également obtenir  ce résultat de façon encore plus simple, en se rappelant (voir 
F. Marcotorchino (1984)) que le coefficient de Janson-Vegelius dans le cas de tableaux de 
contingence (2x2), est égal à :  
              2x Coefficient de contingence de Rand  -1 , 
 
 où le Coefficient de Rand , (voir W. Rand (1971)) est donné par :   
           
2
..
p
1u
q
1v
p
1u
q
1v
2
..
2
.v
2
.u
2
vu
n
nnnn2
y)x,(R


 
 

= = = =
+−−
=
 
On retrouve ainsi l’illustration des remarques indiquées au paragraphe 4.4..1.1:  
En effet :                       
2
..
p
1u
q
1v
p
1u
q
1v
2
..
2
.v
2
.u
2
vu
n
nn2n2n4
1-y)R(x, 2 


 
 

= = = =
+−−
=
 
En remplaçant les valeurs du tableaux Tetrachorique dans l’expression précédente , on ob-
tient trivialement :  
           [ ]
2
2
2
..
p
1u
q
1v
p
1u
q
1v
2
..
2
.v
2
.u
2
vu
P
y))01(x,y)(10(x,y)00(x,y)11(x,
n
nn2n2n4
1-y)R(x, 2 +−+=
+−−
=


 
 

= = = =
 
d’où : 
                          
[ ]
P
y))01(x,y)(10(x,y)00(x,y)11(x,1y)2.R(x,y)J(x,y)(x,S VJ
+−+
=−==
 
(cqfd) 
Sous cette dernière forme on voit que cet indice est  strictement équivalent à l’Indice de 
Hamann (voir note de bas de page  n°11), c’est à dire à la différence entrel’Indice de Sokal et 
Michener et l’ Indice de Green –Rao. 
 
4.4.5.2  Indice de similarité déduit  du Coefficient  de Light et Margolin , Haldane  et du 
Coefficient de Goodman-Kruskal 
De la même manière que dans le cas  du coefficient de Janson et Vegelius , on peut s’inspirer 
de la littérature sur les indices d’association  sur tableaux de contingence, pour  déduire et 
définir d’autres indices de similarité par un processus équivalent à celui utilisé dans le cas 
précédent.  Parmi les choix possibles, une excellente famille d’indices d’association (non 
standard quant à leur construction) est celle créée autour de la filiation des indices de Good-
man-Kruskal, Light et Margolin , Haldane. Ainsi historiquement l’indice le plus complet est 
celui qui a été introduit en 1954  par Goodman Kruskal et redéfini  dans leur  livre (voir  L. 
A.Goodman et W.H. Kruskal (1979) ),  sous le nom de « Tau » de Goodman- Kruskal. Il est 
donné   ci dessous  dans sa formulation  pour tableau de contingence à caractère général :  
 
(f 94)                                  




 

=
= = =
−
−
= q
1v
2
v.
..
..
p
1u
q
1v
q
1v
2
v.
...u
2
vu
n
n
1
n
n
n
1
n
n
y)(x,
 
                           
On peut montrer que le Coefficient de Light et Margolin (1971) est équivalent au Numéra-
teur du Coefficient de Goodman Kruskal, et qu’ historiquement en (1940), Haldane avait 
RNTI-A-3- 275 -
Essai de Typologie Structurelle des Indices de Similarités  
déjà proposé un coefficient quasi équivalent au Coefficient de Light et Margolin (pour plus 
de détails sur  propriétés de ces indices et sur leur filiation on consultera l’article F . Marco-
torchino (1984) ). 
Quoique dissymétrique, ce coefficient de Goodman-Kruskal se comporte pour ses valeurs 
maximum et minimum comme le coefficient de Tchuprow, ou comme le Coefficient du 2.  
 
• Il  vaut 0 en cas d’Indépendance contingentielle sur toutes les cases du tableau de con-
tingence (voir  Goodman , Kruskal (1979) ), c’est à dire si : 
                           
vetu
n
nn
n
..
v..u
vu ∀=
 
• Il vaut 1 en cas d’association complète , c’est à dire d’une part si : p=q, d’autre part si 
pour toute cellule (u,v) du tableau de contingence on a :  
                                                
vu0n
vunnn
vu
v.u.vu
≠∀=
=∀==
   
        
Pour évaluer la valeur du Coefficient d’association de Goodman Kruskal sur le tableau de 
contingence (2x2) Tetrachorique, il suffit de remplacer :   n
..  
par P, p et q par 2  et 
vun  par 
l’une des valeurs  :  11(x,y), 10(x,y), 01(x,y), 00(x,y), on obtient  après les  remplacements 
proposés, l’ expression  suivante: 
 
[ ]
[ ]22
22
2222
y))10(x,y)(00(x,y))01(x,y)(11(x,
P
1P
y))10(x,y)(00(x,y))01(x,y)(11(x,
P
1
y)01(x,y)00(x,
y)(x,01y)(x,00
y)10(x,y)11(x,
y)(x,10y)(x,11
y)(x,
+++−
+++−
+
+
+
+
+
=τ
 
qui après développements et nouvelles simplifications revient à :                   
 
[ ]
y)]01(x,y)y)][00(x,10(x,y)y)][11(x,10(x,y)y)][00(x,01(x,y)[11(x,
y)y)10(x,01(x,y)y)00(x,11(x,y)(x,
2
++++
−
=
 
 
Dès lors, on peut définir à partir du Coefficient d’association de Goodman Kruskal, un indice 
de  similarité dit de Goodman Kruskal, SGK(x,y) défini, comme pour Janson-Vegelius, par la 
racine carré du Coefficient d’association, calculé sur le tableau de contingence Tetracho-
rique, qui peut comme on l’a vu être positive ou négative ; il vient : 
 
(f95)    [ ]
y]01(x,y)y)][00(x,10(x,y)y)][00(x,01(x,y)y)][11(x,10(x,y)[11(x,
y)y)01(x,10(x,y)y)00(x,11(x,y)(x,y)(x,SGK
++++
−
==
 
 
En se référant au § 4.4.4.1,  formule (f 71) , on voit que malgré les calculs complexes occa-
sionnés, cet indice de similarité n’est rien d’autre que l’indice de similarité Tetrachorique 
ST(x,y) (ou de Bravais-Pearson) , défini directement à partir du tableau 2x2 associé. En con-
clusion on a donc : 
 
)y(x,Sy)(x,y)(x,S TGK ==  
 
 
RNTI-A-3 - 276 -
                                                                                                    F. Marcotorchino 
 
4.4.5.3  Indice de similarité déduit  du Coefficient d’ « Ecart carré à l’Indépendance » et 
du Coefficient Contingentiel de I.C. Lerman 
Une autre famille d’indices d’association est issue d’une Représentation Relationnelle géné-
rale des indices d’Association sur tableau de contingence.  Ces indices font partie de la ver-
sion la plus complète des indices d’association de types relationnels dont la formule générale 
(voir F. Marcotorchino (1984), F. Marcotorchino et N. El Ayoubi (1991), A. Idrissi (2000) 
s’écrit sous la forme : 
 
 (f 96)                              








= == =
= =
−−
−−
=
N
1i
N
1i'
2
yii'
N
1i
N
1i'
2
xii'
N
1i
N
1i'
yii'xii'
)(y)(x
)(y)(x
y)A(x,
 
 
où la variable  x  (catégorielle) est représentée, comme nous l’avions   vu au § 2.2.1, par son 
expression relationnelle sous forme d’une matrice binaire de terme général : {xii’ } , idem 
pour y, représentable sous forme d’une matrice relationnelle binaire : {yii’ }. Et où   x  et   y 
sont, respectivement, une moyenne dérivée de la distribution des {xii’ } et une moyenne déri-
vée de la distribution des  {yi i’ }. Comme ceci a été montré (en particulier dans la thèse de N. 
Amal Idrissi  (2000)), puis repris par A. Hicham et G.Saporta (2003)  et revu et raffiné  s 
dans   le travail  de  J. Ah-Pine (2007) ),   suivant les valeurs choisies pour  x  et   y , on re-
trouve  des coefficients d’association connus. Ainsi , on  a :  
• si   x =1/2     et   y =1/2  (Moyennes logiques)           1y)2.R(x,y)A(x, −= , on retrouve le 
critère de Rand 
• si  x =1/p et  y =1/q  (Moyennes Probabilistes)         y)J(x,y)A(x, = ,  on retrouve le 
critère Janson Vegelius 
• si   x =
2
..
n
x
 et   y = 
2
..
n
y
 (Moyennes empiriques)     y)L(x,y)A(x, = ,  on retrouve un 
critère voisin du critère de « Vraisemblance du Lien »  de I.C. Lerman (1987), dont la 
formulation contingentielle (adaptée à notre problématique) est donnée ci dessous :   
 
 
(f 97)                          









 


 

=
=
=
=
= =
= =






	
	
	
	


−






	
	
	
	


−
−
=
q
1v
2
..
q
1v
2
v.
2
v.
p
1u
2
..
p
1u
2
.u
2
.u
p
1u
q
1v
2
..
p
1u
q
1v
2
v.
2
.u
2
vu
n
n
1n
n
n
1n
n
nn
n
y)L(x, 
 
 
Le numérateur de ce coefficient   à savoir la quantité : 
                                              



 

= =
= =
−
p
1u
q
1v
2
..
p
1u
q
1v
2
v.
2
.u
2
vu
n
nn
n
  
RNTI-A-3- 277 -
Essai de Typologie Structurelle des Indices de Similarités  
est connue sous  le nom de Critère de l’ « Ecart Carré à l’Indépendance15 »,  critère qui pos-
sède de nombreuses propriétés structurelles  intéressantes  ( on trouvera dans  Marcotorchino 
(1984,) ,  une étude complète de ce critère,  d’un point de vue formel, structurel  et applica-
tif).   
 
Ce coefficient L(x,y), dérivé du Coefficient de I. C. Lerman,  possède les propriétés suivantes 
à propos de ses valeurs maximales et minimales.   
• Il  vaut 0 en cas d’Indépendance contingentielle sur toutes les cases du tableau de con-
tingence,  c’est à dire si : 
                                     
vetu
n
nn
n
..
v..u
vu ∀=
 
       En effet dans ce cas  le numérateur de L(x,y) s’annule  de façon évidente. 
• Il vaut 0 également dans le cas d’une solution « parasite » (qui se présente uniquement  
sur des tableaux 2x2)  (voir (F. Marcotorchino (1984 partie III) ),  et pour laquelle si le 
tableau 2x2 s’ écrit : 
            
 y Non y 
x a b 
Non x c d 
       
       la configuration  suivante  se produit: 
        (i)        dcbanaveccbda 2222 +++=+=+    (on identifie ici n et n.. )   
    Du fait que l’équation précédente est équivalente à : 
       (ii)        2bcc)(b2add)(a 22 −+=−+  
    on a également : 
      (iii)       bc)2(adc])[bd]([anbc)2(adc)(bd)(a 22 −=+−+−=+−+   
 
Parmi les solutions de l’équation Diophantienne  ( i),  (il y en a une infinité) nous en donnons  ci dessous une famille  
paramétrée (voir (F. Marcotorchino (1984)) :                 
{ } ..)0,1,2,..m,:entièresvaleursdesprenant  (s1sd5,sc 5,2sb 7,2s a +=+=+=+=  
  Il est facile de vérifier que si s=1 par exemple,  les valeurs : a=9, b=7, c=6 , d=2 , sont telles qu’elles annulent  le    
coefficient    L(x,y), calculé sur le tableau :   
 
 
 
 
bien que l’on ne soit pas (loin de là) dans une configuration d’indépendance contingentielle.  
On peut voir ,  de façon évidente, que pour cette série de solutions  2c])[bd]([a:aons −=+−+∀ ,  de  ce  
implique que (ad – bc) = - n  puisque l’on travaille sur des valeurs entières. 
 
En effet :  
         n= (2s+7)+(s+1)+(2s+5)+(s+5)=6s+18, ad = 2 s2 + 9s + 7,  bc = 2 s2 +15s+ 25, a+d = 3s +8 , b+c = 3 s +10  
d’où : (ad – bc) = - (6s+18) =-n  et    (a+d) –(b+c) = (3 s +8) –(3s+10) = -2 
 y Non y 
x 9 7 
Non x 6 2 
                                                 
15
 A ne pas confondre avec le carré de l’écart à l’indépendance (Numérateur du Coefficient  de Tchuprow) ou  la 
forme de base  du Coefficient du 2  qui s’écrit : 2p
1u
q
1v
..
.vu.
vu )
n
nn(n


= =
−
 
 
 
RNTI-A-3 - 278 -
générale  et  
fait   ceci 
                                                                                                    F. Marcotorchino 
 
 
• Il vaut 1 en cas d’association complète , c’est à dire d’une part si : p=q, d’autre part si 
pour toute cellule (u,v) du tableau de contingence on a :  
                                                       
vu0n
vunnn
vu
v.u.vu
≠∀=
=∀==
   
       En effet dans ce cas Numérateur et Dénominateur sont égaux. 
 
• Enfin le calcul de la valeur minimale de cet indice n’est pas du tout évident.  Nous 
allons donner la solution dans le cas d’un tableau 2x2 et montrer la difficulté associée 
pour trouver la solution optimale de ce problème.  
 
Calculons, dans un premier temps, la valeur minimale du Numérateur dans le cas du tableau  
de contingence (2x2) général suivant: 
 
    
 y Non y 
x a b 
Non x c d 
 
On peut montrer, que dans le  cas d’un tableau 2x2, la quantité  correspondant au numérateur  
de L(x,y)  s’écrit sous la forme suivante: 
2
..
222222222p
1u
q
1v
2
..
p
1u
q
1v
2
v.
2
.u
2
vu
n
]d)(bc)[(a]d)(cb)[(a]dcb[ad)cb(a
n
nn
n
++++++−++++++
=−



 

= =
= =
 
Après développement de la formule précédente et au bout de calculs assez  fastidieux , on 
montre   que cette quantité se factorise selon la formule suivante :  
 
(f 98)       ])c(bdbc)[a(ad
n
2
n
]d)(bc)[(a]d)(cb)[(a]dcb[ad)cb(a 2222
22
..
222222222
+−+−=
++++++−++++++  
Le « dénominateur du numérateur » en question étant la constante n2, on peut se contenter de 
travailler au niveau du « numérateur du numérateur ». On voit que cette expression est posi-
tive si , à la fois « a et d » sont positifs et « b et c » nuls  (ce qui correspond à un cas favo-
rable) , mais il se trouve qu’elle est également positive si « a et d » sont nuls et « b et c » 
positifs ( cas d’une configuration non favorable).  
 
 
Il apparaît donc évident que si l’on veut obtenir une configuration où la valeur de (f 98) soit  
négative , il faut Minimiser la fonction des quatre inconnues   (a,b,c,d) suivante :     
 
                  
 
                                  
        
                                          ( ))c(bdabc)(ad2Min 2222
dc,b,a,
+−+−  
vérifiant les contraintes : 
RNTI-A-3- 279 -
Essai de Typologie Structurelle des Indices de Similarités  
         
nd0  n,c0n,b0n,a 0    (ii)          
constante)est n(où ncbda      (i)          
≤≤≤≤≤≤≤≤
=+++
 
Soit en utilisant une approche Lagrangienne :  
 
                                    n)-dcb	(a-)]c(b)d(a[bc)(ad2Min 2222
abcd
++++−+−  
        vérifiant : 
        
nd0  n,c0n,b0n,a 0    (ii)          
         
≤≤≤≤≤≤≤≤
                                                 
Un raisonnement de bon sens va nous permettre de simplifier la résolution de ce Problème d’optimisation non 
linéaire  à  4 variables16. En effet  on constate sur la formule (f98) que pour que cette  fonction F(a,b,c,d)  soit 
négative, il faut que l’on ait simultanément: 
                                     0)]c(bd[a    et              0bc)(ad 2222 >+−+<−   (cas n°1) 
 ou                                0)]c(bd[a  et              0bc)(ad 2222 <+−+>−   (cas n°2) 
 
On voit  que l’on peut   donc séparer le comportement de « a » et « d »  de celui de « b » et « c ». En effet  pour 
Minimiser F(a,b,c,d)  :  
* Il faut pour le couple {a, d} que l’on ait : la quantité produit « a.d » minimale et la quantité «a2+d2
 
» maxi-
male  (ou l’inverse cas n°2) 
*  Il faut à l’inverse pour  le couple {b,c} :  que la quantité produit « b.c » soit maximale et la quantité «b2+c2
 
» 
minimale (ou l’inverse cas n°2)   
 
Nous choisissons ici le cas n°1  qui va nous garantir une solution où « d » sera  maximum . En supposant que 
l’on ait  arbitrairement découpé n en deux parties quelconques  n1 et n2 telles que : 
 
         
nd0  n,c0n,b0n,a 0    (ii)          
constante)est n(où n  nn avec   (iii)          
ncb    (ii)          
nda     (i)          
21
2
1
≤≤≤≤≤≤≤≤
=+
=+
=+
 
Du fait que   (a+d)2= a2+d2-2ad   
on voit que : si   (a+d)= n1=constante,  alors il y a équivalence entre : Maximiser (a2+d2)     et     Minimiser (2ad)   
ou  de façon duale : Maximiser (2ad )    et Minimiser (a2+d2)     
On  déduit des remarques faites précédemment que :  rendre « ad » minimum rendra automatiquement «a2+d2 »     
maximum  et de même  pour le couple {b,c} rendre le couple « cd » maximum rendra la quantité «b2+c2
 
» mi-
nimale  
-Dans le cas particulier du couple {b,c} puisque l’on veut rendre la quantité produit «bc » maximale, on va se 
servir d’un résultat qui découle des remarques calculatoires faites précédemment à savoir : « le produit de 2 
nombres dont la somme S est constante  est maximum si ces deux nombres sont égaux », la conséquence 
pour notre problème est que : quelle que soit la valeur n2 , on doit avoir  b = c = n2/2   à l’optimum.   
-De la même façon le produit de 2 nombres dont la somme S est constante  est minimum si l’un des deux 
nombres est égal à S et l’autre est nul. », la conséquence pour notre problème est que : quelle que soit la valeur 
n1 , on doit avoir a ou d=0 à l’optimum .  On vient donc de voir qu’au moins l’une ou l’autre des valeurs « a » 
et « d » est nulle  (nous choisissons a=0) et que de plus « b = c » .  
 
Le problème que l’on veut résoudre s’écrit maintenant sous une forme certes non linéaire mais très simplifiée :                  
                                                ]b2d[)b(2Min 222
ba,
−−
 
                             vérifiant les contraintes : 
                                                 
16
 On ne pose pas encore à ce niveau une contrainte d’intégrité des quantités {a,b,c,d}, qu’on suppose continues 
dans un premier temps. 
RNTI-A-3 - 280 -
                                                                                                    F. Marcotorchino 
 
 
produit)du  négativité lagarantit  contrainte (cette b2d    (iii)         
n,b0n,d 0    (ii)          
constante)est n(où nb2d      (i)          
22 ≥
≤≤≤≤
=+
 
 
La contrainte (iii) alliée à la contrainte (i)  impliquent  immédiatement que : 
n 2929,0
22
nb =
+
≤
      (nous nous en resservirons ultérieurement) 
 
Du fait  que l’on n’a pas encore introduit la contrainte d’intégrité, la solution du problème  précédent revient à 
résoudre un programme non linéaire en (d, b)  à variables continues positives. En utilisant  la contrainte (i) et 
en remplaçant « b par x »  (pour se ramener à des notations familières et  classiques de variables continues in-
connues) , on peut ramener ce problème à un programme d’optimisation non linéaire (du 4ème degré) à 1 seule  
variable x qui s’écrit : 
22
n
 x0  (iii)         
         :vérifiant
] x2 2x)[(nx2F(x)Max 222
 x
+
≤≤
−−=
 
(On passe du Min  au Max, en enlevant le signe «- » devant la fonction )  
 
Etudions  les conditions d’optimalité du premier et du deuxième ordre  par rapport à x,  on obtient : 
 
 [ ]
 0 ] x4x n 6  -n [x2soit0 x8  xn12xn22
xd
F(x)d((i)) 22322 =+=+−=   
[ ] (iii)  condition  la  x vérifie quefait  du est vraie relation  cette024x 24nx n2
x
F(x)((ii)) 222
2
≤+−=
∂
∂      
La première condition  ((i)) (condition du premier ordre) signifie que le x* cherché doit annuler la première dé-
rivée de F(x)  par rapport à x .  
La deuxième condition ((ii))  (condition du second ordre) signifie, du fait que  0
x
F(x)
2
2
≤
∂
∂ ,  que la fonction-
nelle F(x) est concave par rapport à x, donc que si x* est trouvé, ce sera un maximum  unique pour F(x) (c’est 
justement ce que l’on cherche)  et non un minimum. Puisqu’à l’optimum  on doit avoir x* vérifiant la condition 
du 1er ordre ((i)),  on est amené à résoudre l’équation du second degré en x suivante :  
                                                              4 x2-6 n x +n2 = 0  
  
dont la solution qui nous intéresse est donnée par :  
n19098,0
4
n)53(
4
5n3n
*x
2
=−=
−
=
 
en effet la deuxième racine : 
                                         
n3090,1
4
n)53(
4
5n3n
*'x
2
=+=
+
=
 
ne vérifie pas la condition (iii) et est donc éliminée, puisque : 
                                       
22
n
 x0          
+
≤≤   
 n’est pas compatible avec le fait que x’*est supérieur à n,  x* peut également s’écrire : 
61803,1
2
51Or"d' Nombre"  leest      où   n 
2
1n
4
)5(14
x* =
+
=Φ


 Φ
−=
+−
=
 
Rappelons que nous voulons calculer  la valeur Minimum par rapport à d, b , c  de la quantité : 
                            
                                                
ncbd     (i)         
: contrainte la sous
)]c(b)(d[bc)( 2  c)b,F(d, 222
=++
+−−=
 
RNTI-A-3- 281 -
Essai de Typologie Structurelle des Indices de Similarités  
comme nous avions vu que : b =c   et  puisque : b* = x* à l’optimum,  on a donc :  
 
Or"d' Nombre"  leest      où   n 
2
1c**b               Φ


 Φ
−==
 
de ce fait  comme d= n - 2b , il vient :               1)n(d* −=  
On vérifie bien que : 
 21)
2
1(1puisque)
2
(12nn1)(car2(b*)(d*) 222222 +≥+−≥−≥  
En remplaçant d*, b*,c* par leurs valeurs dans F(d,b,c) il vient : 
44422
2
n0225424859,0n1
8
52n)
2
2(11)(
2
12c*)b*,F(d*, −=



−−=



−−−


	


−−=
 
                   
 
Pour  obtenir  cette expression  simplifiée, on a  utilisé les propriétés suivantes du Nombre d’Or : 
                                                  





+Φ=Φ+Φ=Φ
+Φ=Φ+Φ=Φ
+Φ=Φ
23
12
1
234
23
2
 
Nous rappelons que la valeur trouvée ici est la valeur minimale de F(d,b,c)  pour d, b, c,  à valeurs continues, 
nous n’avons pas tenu compte des conditions d’intégrité de d, b, c .  
Ceci nous aurait obligé à utiliser une solution par  Programmation non linéaire en nombres entiers ;  en utilisant 
par exemple un algorithme dérivé des approches « cutting planes » de M. Grötschel, M. Jünger, G. Reinelt  
(1982)».  
 
Outre que cette approche ne permet pas d’avoir des solutions explicites et que les calculs sont très complexes, 
même pour des valeurs faibles du nombre de variables, elle sortirait du cadre de cet article. Une solution appro-
chée, et tout à fait réaliste, pour trouver la meilleure solution en nombres entiers du problème précédent, vu que 
le nombre de situations possibles à explorer est très faible puisqu’il n’y a que deux degrés de liberté ici,  con-
siste alors à  prendre les valeurs entières : 
                          minimalessoient*cc~*bb~et*d-d~ :quetellesc~,b~,d~ −=−   
et telles que : *bb~2*dd~ −+−   ait une valeur minimale sous la contrainte : nb
~2d~ =+   
n618033,0N)1( de
 entière  partied~pour    idemet  n19098,0n 
2
1de  entière   partiec~   b~où  d'       
=−Φ
==


 Φ
−== on  
choisira  la  solution  pour  laquelle : 
nb~2d~  contrainte  la sous*bb~2*dd~Min ait on l' que tellessoient  b~et  d~ =+−+−      
A titre d’exemple , prenons  n=24 , alors  on trouve la solution  entière optimale  représentable par le tableau 
suivant :  
 y Non y 
x 0 5 
Non x 5 14 
 
Et F(d,b,c) « optimale17, »  (valeur minimale) ,  calculée sur ce tableau est donnée par :  -7300  
Rappelons que la valeur théorique optimale  continue aurait été donnée par : - 0,0225424859 n4= - 7479, 055  ,  
l’erreur d’approximation est  ici de l’ordre de 2,3%. 
On vérifie facilement que toute autre solution est moins bonne, en effet prenons par exemple :  
 
 y Non y 
                                                 
17
 Rappelons nous qu’ il faudrait pour calculer  à sa juste valeur le numérateur du  coefficient  de Lerman, diviser 
cette quantité par n². mais ceci a peu d’importance car cette quantité n², disparaîtra en fait du numérateur de L(x,y)  
dès que nous le calculerons en simultanéité avec le dénominateur.  
RNTI-A-3 - 282 -
                                                                                                    F. Marcotorchino 
 
x 0 4 
Non x 4 16 
 
La valeur associée de F(a,b,c) = - 7168 dans ce cas.  
Considérons maintenant le tableau suivant,  légèrement modifié par rapport au précédent:   
 
 y Non y 
x 0 5 
Non x 3 16 
La valeur de F(d,b,c)  associée à ce deuxième tableau   est égale à : -6660  (on constate bien  sur ce petit 
exemple  que dès que  « b  c » , la valeur « d » restant inchangée , la valeur de la fonction est inférieure en va-
leur absolue au cas où  « b = c »). 
 
Revenons maintenant à l’expression du critère L(X,Y) complet et  non plus au simple 
Numérateur qui concerne le seul « Critère d’Ecart carré à l’Indépendance ». Pour 
évaluer la valeur Minimale du Coefficient d’association de Lerman  sur un tableau de 
contingence (2x2), il suffit de remplacer dans la formule (f 94) :   n
..  
par P, p et q par 2  
et 
vun  par l’une des valeurs  : { a, b, c, d }.  
Le dénominateur de la formule (f94) s’écrit alors :   
                        d]c)(b[2(a]d)(bc)d)][(ab)(c[2(a]d)(cb)[(a 2222 ++++++++++  
Soit encore sous une forme plus symétrique :   
               d)]c)(bd)(ac)(b[(a]d)(bc)][(ad)(cb)[(a2 2222 ++++++++++  
 
En  vérité, cette formule est à diviser par n², tout comme pour le numérateur de la for-
mule (f95), de ce fait la quantité n²   disparaît au numérateur et au dénominateur, de 
même  pour la constante multiplicative 2. On obtient au final l’expression  suivante 
(après les  remplacements proposés, des simplifications des formules complexes obte-
nues et  enfin une factorisation ,) :  
 
                                                     
y)(x,D
y)(x,N
x
y)(x,D
y)(x,Ny)L(x,
2
2
1
1
=
 
où : 
                                          
d][cd][bc][ab][a
bc]-ad[
y)(x,D
y)(x,N
1
1
++++
=
 
 
             et  où 
                                   
)d][bc]([a)d][cb]([a
)]c(b-d[a
y)(x,D
y)(x,N
2222
2222
2
2
++++++
++
=
 
L’indice de Lerman Modifié est donc le Produit de deux indices dont l’un est l’indice Tetra-
chorique que nous avons déjà défini , l’autre étant un indice que nous allons expliciter  dans 
les paragraphes suivants. Mais revenons au calcul du Minimum de L(x,y) 
 
 
Comme nous avons vu que dans le cas où le Numérateur atteint sa valeur minimale soit « a » soit « d » devait être 
égal à 0 , posons  « a=0 », les valeurs précédentes se simplifient en :    
d][cd][bbc
-bc][
y)(x,D
y)(x,N
1
1
++
=
                                
( ) ]d(bc]d)(c[b
)]c(b-[d
y)(x,D
y)(x,N
2222
222
2
2
++++
+
=
 
RNTI-A-3- 283 -
Essai de Typologie Structurelle des Indices de Similarités  
En utilisant la contrainte : d+2b=n  et en remplaçant de nouveau b=c par x ,  il vient le  problème d’optimisation 
suivant :  
  (f 99)            
[ ]
[ ][ ] ( )
 
22
n
x0     (ii)         
:vérifiant
xx)n(x)(n
] x2n x4[nx
xx)(nxx)(nxx)(n
 x2  xn4xnF(x)Max 22
22
222222
4322
x
+
≤≤
+−−
+−
=
+−+−−
+−
=
 
Comme nous avons affaire maintenant à une fonction d’une seule variable , il suffit d’appliquer la condition du 
premier ordre à la fonctionnelle F(x) précédente.  
Comme F(x) se présente comme le rapport 
v(x)
u(x) de deux fonctions de x . 
La condition de dérivation du premier ordre s’écrit  alors  après simplifications:                            
0
]xx)[(nx)-(n
n-x8n14nx-8x
dx
dF(x)
2222
3223
=
+−
+
=
. 
Il faut donc résoudre l’équation du 3ème degré18 suivante pour obtenir x* : 
)précédente (ii) contrainte voir  vraiofficed'est  qui (cen  x: que  réserve  sous                
   0n-xn 814n x-8x      (f100) 3223
≠
=+
 
On obtient  la solution optimale exacte: x*=0,171350939.n  et   de fait  a*=n-x*=0,6572982.n  Dans la formule (f 
98)  on constate néanmoins que le coefficient numérique 2,210929 est assez voisin de  5 et plus exactement :                                 




	
	








−=−≅
3
10
515025,05210929,0
 
D’où après développements  une deuxième approximation de x* fournie 
par :
n17135141,0]279[
480
n]
40
1
20
2[
12
n
 ]50,025)-  5( -[7
12
n
   x*                    102) (f
  
=Φ+=−Φ+=≅
 
On constate ici que l’erreur n’intervient qu’au bout du 6ème chiffre après la virgule, ce qui  nous permettra d’utiliser 
la formule (f 100) comme formule explicite pour la suite.  
En particulier, on aura  en fin de compte :                                
]2161[
240
n2b*nd*et     
480
n]2[79c*b* Φ−=−=Φ+==                                                                            
Comme précédemment, ces valeurs optimales ont été calculées pour un environnement de valeurs continues  et sans 
tenir compte des contraintes d’intégrité.                                                                                                                                 
A titre d’exemple , prenons  n=24 ,  on trouve  alors : 
16d~et       4 c~b~où  d'
7752,15
240
24]2161[ de entière partied~et     1124,4
480
24]2[79 de entière partie   c~b~
===
=Φ−==Φ+==              
La solution entière optimale  est  donc donnée par le tableau suivant :  
 
                                                 
18
 La solution de ce problème s’obtient en utilisant le procédé  de Cardan- Tartaglia, pour une équation de la 
forme : 0xxx 23 =+++  avec  0,.  On sait alors que la solution Z* (réelle) de  Z3+r Z+ t est donnée 
par :
]42185898,42109294,9[
12
n)]1(249210929,27[
12
n
 ]5 2,21092949 -[7
12
n
   x*: vientil  
125 encore ici  poseon      n,
24
14
*Z   x*
Φ−=−Φ−==
−Φ=+=  
 
 
RNTI-A-3 - 284 -
                                                                                                    F. Marcotorchino 
 
 
Et L(x,y) minimum absolu calculé pour n=24 est donné par :     
                                                        
0,10769]420.4.[20
2.16]4.4[16)y~,x~L( 22
2
−=
+
−−
=
        
        
rappelons que la valeur théorique optimale  continue aurait été donnée en calculant L(x,y) sur un tableau théorique 
où au lieu de ‘4’ on aurait : ‘4,1124’ , et au lieu de ‘16’ , on aurait ’15,775,’  soit : 
                                      
 valeur cette   0,107811
33730,78
3636,50y*)L(x*, −=−=                                                                                  
on voit qu’elle est très légèrement supérieure  à la valeur précédente  l’écart   0,00011)y~,x~L(y*)L(x*, =− ,   
n’étant que de  11/10000 .                                                                                                                                             
En fait cette valeur minimale théorique L(x*,y*) est indépendante de n,  en effet : posons b*=ω.n (avec 
=0,1713509 et d*=η n (avec = 0,6572982) (valeurs données en (f102) plus haut).   Il   
vient : [ ]
[ ] [ ] ])[(1)(1
]2[
nn)(nnn)(n
]n2n[n
[b*]b*][n*b*)b(n
2[b*][d*][b*]y*)L(x*, 22
222
222
222222
22
222
ω+ω−ωω−
ω−ηω
−=
ω+ω−ωω−
ω−ηω
−=
+−−
−−
=
 
On voit que les valeurs n disparaissent  et que d’autre part  comme =(1- 2) on peut  tout exprimer en fonction de 
. 
C’est d’ailleurs ce que nous avions fait lors de l’optimisation en jouant sur l’inconnue x  (voir formule (f 96)).   
Après simplification  du Numérateur et du Dénominateur par n et élimination de  , il vient :   
]22)[1(1
]4[1y*)L(x*, 2
2
+−−
+−
−=
 
 
 
Il suffit de remplacer «  »  par sa valeur   0,1713509 dans l’expression précédente, il vient :   
1078119,0 
5933296,0
063968,0
]0,17135 . 20,171350 20,828649[1
].0,171352.0,171354-[10,17135y*)(x*,L 2
2
Min −=−=
+−
+
−=
  
Cette valeur indépendante de n est le minimum théorique de l’indice de Lerman modifié sur un tableau de    
contingence (2x2) .  On voit ici la complexité de la situation, car les valeurs minimisant le Numérateur de L(x,y) 
c’est à dire celles pour lesquelles le critère d’  « Ecart Carré à l’Indépendance » est minimum, ne sont pas celles qui 
minimisent L(x,y) .En effet reprenons ces valeurs , on   
avait  : 1)n-( d*et       Or"d' Nombre"  leest      où   n 
2
1c**b               Φ=Φ


 Φ
−==
.  
Remplaçons ces valeurs dans l’expression de L(x*,y*) donnée  précédemment en fonction de a*,b*,c*, il vient :    
[ ]
[ ] 1055728,043
85
2
1
22
2
-12)1(
2
-1
[b*]b*][n*b*)b(n
2[b*][d*][b*]
y*)L(x*,
22
2
2
22
222
−=
−Φ
−Φ
−=




	
	





 Φ
−+


ΦΦ




	
	





 Φ
−−Φ


 Φ
−=
+−−
−−
=
 
La formule précédente peut d’ailleurs s’exprimer  selon la suite de  Fibonacci  (liée elle même au Nombre d’Or): en 
effet si l’on pose F1=1, F2=1, F3=2, F4=3, F5=5, F6=8, F7= 13 ….. on voit que la formule précédente s’écrit :   
 
                                                                 
1FF
FF
4-3
85y*)L(x*,
54
65
+−Φ
−Φ
=
Φ
−Φ
−=
 
On voit que cette valeur,  même si elle est  très proche de la précédente ( 0,1078118 versus 0,1055728) , n’est 
pas optimale, même si elle optimisait par ailleurs le numérateur  seul. Si  on exprimait la solution Minimale to-
tale par rapport au nombre d’Or on voit que seul le dénominateur serait légèrement  modifié en effet : 
 
 
9829,0FF
FF
1078119,0y*)(x*,L
54
65
Min
+−Φ
−Φ
=−=
 
 y Non y 
x 0 4 
Non x 4 16 
 
RNTI-A-3- 285 -
Essai de Typologie Structurelle des Indices de Similarités  
 
Revenons maintenant au calcul de l’Indice de Lerman modifié sur le vrai tableau Tetracho-
rique et non sur un tableau (2x2) quelconque, dès lors, comme précédemment, pour évaluer 
la valeur du Coefficient d’association de Lerman  sur le tableau de contingence (2x2) Tetra-
chorique, il suffit de remplacer :   n
..  
par P, p et q par 2  et 
vun  par l’une des valeurs  : { 
11(x,y), 10(x,y), 01(x,y), 00(x,y)}, on obtient  après les  remplacements proposés, des simplifi-
cations des formules complexes obtenues et  une factorisation finale, qui se traduit par 
l’expression suivante: 
 
                                                     
y)(x,D
y)(x,N
y)(x,D
y)(x,Ny)L(x,
2
2
1
1
=
 
 
où : 
                   
[ ]
y)]01(x,y)y)][00(x,10(x,y)y)][11(x,10(x,y)y)][00(x,01(x,y)[11(x,
y)y)10(x,01(x,y)y)00(x,11(x,
y)(x,D
y)(x,N
1
1
++++
−
=
 
 
et 
[ ]
[ ][ ]2222
2222
2
2
y)]01(x,y)[00(x,y)]10(x,y)[11(x,y)]10(x,y)[00(x,y)]01(x,y)[11(x,
y))(x,01y)(x,(10y)(x,00y)(x,11
y)(x,D
y)(x,N
++++++
+−+
=
 
 
 
On reconnaît dans le rapport :  
[ ]
y)]01(x,y)y)][00(x,10(x,y)y)][11(x,10(x,y)y)][00(x,01(x,y)[11(x,
y)y)10(x,01(x,y)y)00(x,11(x,
y)(x,D
y)(x,N
1
1
++++
−
=
 
 
l’indice de similarité Tetrachorique ST(x,y), défini par la formule (f 71).  
 
 
Mais qu’en est-il de l’indice suivant ? : 
                      
[ ]
[ ][ ]2222
2222
L
2
2
y)]01(x,y)[00(x,y)]10(x,y)[11(x,y)]10(x,y)[00(x,y)]01(x,y)[11(x,
y))(x,01y)(x,(10y)(x,00y)(x,11y)(x,S
y)(x,D
y)(x,N
++++++
+−+
==
 
 
C’est un indice (de type corrélatif )  non rencontré jusqu’ici ,  qui est donc nouveau  et qui 
vaut : 
•  1 si 10(x,y)=01(x,y)=0  (configuration où les deux profils sont identiques) 
• -1 si 11(x,y)=00(x,y)=0  (configuration où les deux profils sont systématiquement en 
opposition)  
 
Pour avoir un indice S’L (x,y) variant de 0 à 1, nous devons faire la translation suivante :  
                                                       






+= 1
y)(x,D
y)(x,N
2
1y)(x,S'
2
2
L
  
Ce nouvel  indice vaut donc : 
• 1 si 10(x,y)=01(x,y)=0  (configuration où les deux profils sont identiques) 
RNTI-A-3 - 286 -
                                                                                                    F. Marcotorchino 
 
• ½ si  112(x,y)+002(x,y)= 012(x,y) + 102(x,y) (configuration d’équilibre quadratique entre 
les configurations de « matching » et les configuration de « non matching » ) . Nous 
avons déjà vu page 72 que cette  situation était équivalente à :  
                       ]y)y)10(x,01(x,y)y)00(x,2.[11(x,y)]01(x,y)(10(x,y)00(x,y)[11(x,P −=+−+      
c’est à dire si : 
o soit les 4 valeurs sont  égales : 11(x,y)=00(x,y)=10(x,y)=01(x,y)    
o soit  également pour toutes les   décompositions entières paramétrées,   so-
lutions de l’équation Diophantienne associée  (voir page 72 où une telle so-
lution paramétrée est donnée ; et voir F. Marcotorchino , P. Michaud  
(1981) pour d’autres solutions)  
• Il vaut : 0 si 11(x,y)=00(x,y)=0 .  
 
 
Comportement de l’indice SL(x,y) en cas  de Disjonction Complète 
En cas de disjonction complète on a 10(x,y)=01(x,y)=(m-11(x,y)) et 00(x,y)=P+11(x,y)-2m 
L’indice (forme corrélative) s’écrit alors : 
 
 
[ ]
[ ] 2222
22
22
222
L
m]-[P[m]
y)]11(x,2P[m1
m]-[P[m]
y)]11(x,2P[mmm]-[P
m]-[P[m]
y))11(x,-(m22m)y)11(x,(Py)(x,11y)(x,S
+
−
−=
+
−−+
=
+
−−++
=
 
 
et  l’indice de similarité vrai, s’écrit alors :  
 
                        
2222L m][Pm
y)]11(x,P[m11
m]-[P[m]
y)]11(x,2P[m1
2
1y)(x,S'
−+
−
−=





+
+
−
−=
 
si l’on pose P=m p  où p  est le nombre moyen de modalités de l’ensemble des variables  
l’indice précédent se simplifie en : 
 
              




−
−+
−=
−+
−
−=
−+
−
−=
−+
−
−=
m
y)11(x,1
1)p(1
p1]1)p(m[1
y)]11(x,[mp1
m]p[mm
y)]11(x,[mpm1
m][Pm
y)]11(x,P[m1y)(x,S' 222222L
 
 
• La valeur 1 pour S’L(x,y) est obtenue quand m=11(x,y) soit en cas de « matching » to-
tal entre les profils de x et y  
• La valeur minimale n’est pas 0  dans le cas de disjonction totale car on ne peut pas 
avoir 00(x,y)=0, en fait dans ce cas 00(x,y)=P-2m  et 11(x,y)=0, ce qui donne une va-
leur minimale égale à : 
                              
11)p(
2)p1)(p(
1)p(1
p1
m][Pm
Pm1y)(x,S' 2222L +−
−−
=
−+
−=
−+
−=
 
o  2ou       1p Si = ,    
on constate que l’indice vaut 0 : il s’annule réellement  dans le cas où 
la valeur moyenne vaut 1 du fait que nous sommes alors dans la situa-
tion de tableau de « présence –absence » vrai, il vaut 0 également dans 
le cas où la valeur moyenne du nombre de modalités vaut 2  (ce qui se 
RNTI-A-3- 287 -
Essai de Typologie Structurelle des Indices de Similarités  
produit dans le cas de dédoublement disjonctif de variables  binaires 
pures., 
 
o 1verstendy)(x,S'fortement,croîtp Si L   
 
De ce fait la borne de Solomon Fortier n’est donc pas égale à ½ mais au milieu de l’intervalle 
allant de la valeur minimale ci dessus à la valeur  1,  soit : 
                                              
( )2222SF m][Pm2
Pm11
m][Pm
Pm1
2
1Borne
−+
−=





+
−+
−=
 
                                           
la valeur de 11(x,y) pour satisfaire cette borne doit donc vérifier l’inégalité  : 
 
                                   
( ) 2
my)11(x,
m][Pm2
Pm1
m][Pm
y)]11(x,P[m1y)(x,S' 2222L ≥
−+
−≥
−+
−
−=
 
11(x,y) doit donc être supérieur à la majorité de Condorcet .  
 
Conclusion sur l’Indice de Lerman modifié 
Nous venons de voir qu’à partir de l’indice d’association de Lerman (version modifiée) , 
nous avons pu générer deux indices de similarités différents  et distincts définis à partir de la 
formule : 
  
  (f103)                                      )y(x,y).S(x,Sy)L(x, LT=  
 
Le premier est l’indice Tetrachorique (ou de Bravais –Pearson),  l’autre un peu plus com-
plexe vient d’être étudié ci dessus sous le nom d’Indice de similarité de Lerman modifié.  
Chacun des deux indices vérifie une condition de Solomon-Fortier  impliquant une majorité à 
m/2.  Chacun des deux sous leurs formes corrélatives varient de –1à +1.  
Chacun séparément   a du sens,  en revanche, leur produit n’en a pas en tant qu’indice de 
similarité.   
 
4.4.5.4 Indice de similarité déduit  du Coefficient «  » de Goodman-Kruskal 
   Goodman et Kruskal on proposé en 1954 (voir leur livre déjà cité (1954)) un indice 
d’association qu’ils ont appelé « indice de prédiction optimale symétrique ». Cet indice qui 
possède d’excellentes propriétés statistiques en structure est malheureusement formé à partir 
d’expressions mathématiques faisant intervenir des Maxima , donc difficiles à calculer dans 
un processus automatique à caractère systématique, comme c’est le cas dans les problèmes 
d ‘  « Association  Maximale ». Nous donnons ci-dessous son expression, calculable sur 
tableau de contingence général : 
 
(f 104)                     
v
v
u
u
..
p
1u
q
1v
v
v
u
u
uv
u
uv
v
nMaxnMax2n
nMaxnMaxnMaxnMax
y)(x,
−−
−−+
=
 
= =
 
• L’indice (x,y) varie entre 0 et 1 : 
 
RNTI-A-3 - 288 -
                                                                                                    F. Marcotorchino 
 
o Il vaut 1  en cas d’Association complète  
o Il vaut 0 en cas d’Indépendance statistique 
 
 
Comme précédemment, pour évaluer la valeur de ce Coefficient d’association  (x,y) de 
Goodman Kruskal   sur le tableau de contingence (2x2) Tetrachorique, il suffit de remplacer :   
n
..  
par P, p et q par 2  et 
vun  par l’une des valeurs  : { 11(x,y), 10(x,y), 01(x,y), 00(x,y)}, on 
obtient  après les  remplacements proposés, les résultats suivants : 
 
    
 
= =




−+−+−+−+=+
p
1u
q
1v
uv
u
uv
v
y)00(x,y)10(x,y)01(x,y)11(x,y)00(x,y)01(x,y)10(x,y11(x,
2
1PnMaxnMax
           
[ ]y)]00(x,y)[10(x,y)01(x,y)11(x,y)]00(x,y)[(01(x,y)10(x,y)11(x,
2
1PnMaxnMax v.
v
.u
u
+−+++−++=+  
Mais pour nous éviter des calculs fastidieux,  comme le tableau Tetrachorique est un tableau 
(2x2) particulier revenons  au cas d’un tableau (2x2) général sous la forme : 
 
 
y Non y  
x a b a+b 
Non x c d c+d 
 
a+c b+d N 
 
Reformulons les expressions précédentes au moyen des quantités {a, b , c, d }, il vient : 
 
      ( ) 
= =
−+−+−+−+=+=
p
1u
q
1v
uv
u
uv
v
dcdbcaba
2
1NnMaxnMaxA(i)  
      ( )d)(bc)(ad)(cb)(a
2
1NnMaxnMaxB(ii) v.
v
.u
u
+−+++−++=+=  
Comme il existe a priori 4 ! =24 ordres totaux possibles (il y a isomorphisme entre l’ensemble 
des ordres totaux et l’ensemble n={Groupe symétrique des permutations de n objets} ), ceci   
sans compter les possibilités de préordres associées. Nous illustrerons la valeur du coefficient  
(x,y) de Goodman Kruskal  en caractérisant les familles d’ordres induits et en le calculant 
par rapport aux séquences des lettres {a,b,c,d}, ou ce qui est équivalent à la structure des 
permutations associées.  
 
Par convention on notera  par exemple <abcd> la permutation ou l’ordre total généré par la 
séquence : a>b>c>d c’est à dire : 11(x,y)>10(x,y)>01(x,y)>00(x,y)  
 
Etudions alors les différentes configurations possibles : 
 
• Cas de la FamilleI des ordres respectant la séparation des couples blocs {a,d} et {b,c}, 
elle regroupe deux sous-familles : 
o La sous famille N°1, elle est constituée des ordres ou permutations : 
<ad bc>, <ad cb>,<da bc>, <da cb> 
Pour cette famille la valeur de A est identique pour tous ces ordres, car toutes les valeurs absolues 
de la quantité A sont désambiguïsées, elle est donnée par: 
RNTI-A-3- 289 -
Essai de Typologie Structurelle des Indices de Similarités  
   c)](bd[aNA +−++=  
la valeur de B ne peut être obtenue directement , elle nécessite des comparaisons par rapport aux 
structures induites par les valeurs absolues non désambiguïsées . Par exemple si l’on prend l’ordre 
<ad bc> on voit que  
               B=N+ (a-d)  si (a+c)> (b+d)  et B=N+(b-c)  dans le cas inverse . 
En fait la construction se fait autour du principe représenté ci-dessous caractéristique de la 
permutation <adbc> et facilement généralisable. 
  
 
 
 
 
 
 
 
 
      
 
 
 
 
 
 
 
 
 
  Ainsi pour la permutation  <ad cb>  B vaudra soit N+ (a-d)  soit  N+ (c-b) 
 Pour la permutation <dabc>, B vaudra : soit N+ (d -a) soit   N + (b-c)  
    Pour la permutation <dacb>, B vaudra : soit N+ (d -a) soit   N + (c-b), pour cette famille  de     
permutations on voit que le coefficient  (x,y) vaudra : 
N
c)(bd)(a
B2N
BAy)(x,
−
−+−+
=
−
−
=
 
 valant soit (a-d), soit (b-c),soit (d-a), soit (c-b) suivant les cas  avec de ce fait respectivement: 
 
 
c)(b2d
c)(b2dy)(x,
++
+−
=
 ou  
2cd)(a
2b-d)(ay)(x,
++
+
=
 ou 
c)(b2a
c)(b2ay)(x,
++
+−
=
ou 
b2da
2cday)(x,
++
−+
=
 
 
o Sous Famille N°2 elle regroupe les ordres : <bcad>, <cbad>, <bcda>, <cb da> 
Pour les 4 ordres de cette famille on a :  
d)](a-c)[(bNA +++= = N+((Item rang n°1+item rang n°2)- (item rang n°3 + item  rang 
n°4))  
Ainsi pour la permutation  <bcad > : B vaudra soit N+ (a -d)  soit  N+(b -c) 
  Pour cette famille de permutations on voit que le coefficient (x,y) vaudra : 
   
N
d)(ac)(b
B2N
BAy)(x,
−
−+−+
=
−
−
=
 
 valant soit (a-d), soit (b-c),soit (d-a), soit (c-b) suivant les cas  avec de ce 
fait respectivement : 
                           
2dcb
2a-cby)(x,
++
+
=
ou 
d)(a2c
d)(a-2cy)(x,
++
+
=
 ou 
2ac)(b
2dcby)(x,
++
−+
=
 ou  
d)(a2b
d)(a-2by)(x,
++
+
=
 
 
D’une façon générale pour toutes les permutations { I Famille 4321 >∈< } 
A= N+((Item rang n°1+item rang n°2)- (item rang n°3 + item  rang n°4))  
                         Soit  A=N+((1+2)-(3+4 )) 
  a  d  b  c  
a+b>d+c  	   
calcul sûr 
a+c ? d+b  	 comparai-
son à faire 
RNTI-A-3 - 290 -
                                                                                                    F. Marcotorchino 
 
                             et B=N+(1-2) ou B=N+(3-4)  
Dès lors d’une façon générale l’indice (x,y) pour toute permutation appartenant à cette Fa-
mille I  
vaudra :     
)( 2
)(2
y)(x,
432
432
++
+−
=
   ou    
421
321
2
2
y)(x,
++
−+
=
 
 
• Cas de la Famille II des ordres imbriquant les couples blocs {a,d} et {cd}, elle se 
compose de la famille  des 8 ordres suivants : 
o <abdc>,<acdb>,<dbac>,<dcab>,<bacd>, <bdca>, <cabd>, <cdba> : 
pour cette famille, on peut montrer que : 
                   A= N + (item en 1ère position - item en 4ème position)  
ainsi on aura A= N + (a – c) pour la 1ere permutation <abdc> 
A= N+  (a-b)  pour la deuxième <acdb>,   A=N + (d-c)  pour la troisième etc.. 
Pour B on aura B=N+(item  en 1ème position – item en 3ème) ou B=N+(item en 2ème – item en 
4ème), ces deux valeurs possibles de B dépendant de la désambiguïsation de la valeur absolue 
restante. 
Ainsi B=N+(a-d)  pour <abdc> ou B=N+(b-c) pour cette même permutation <abdc> 
De  fait pour cette permutation on a les valeurs suivantes de (x,y) : 
c)(b2d
cd
d)(aN
d)-(a-c)-(a
B2N
BAy)(x,
++
−
=
−−
=
−
−
=
ou  
d)(a2c
ba
c)-(bN
c)-(b-c)-(ay)(x,
++
−
=
−
=
 
D’une façon générale l’indice (x,y) associé à une permutation :  
II Famille 4321 >∈<  
Aura deux valeurs possibles  soit: 
                                   
)( 2

y)(x,
423
43
++
−
=
   ou   
)( 2

y)(x,
314
21
++
−
=
 
 
• Cas de la Famille III des ordres tels que  les structures {a,d}et {b,c} s’englobent  
ou s’emboîtent mutuellement , elle est composée des 8 ordres ou permutations sui-
vantes : 
o <abcd>,<acbd>,<dbca>, <dcba>, <badc>,<bdac>,<cadb>,<cdab> 
pour cette famille toutes les valeurs absolues sont désambiguïsées et on aura uniquement une 
seule valeur pour B , en effet on peut vérifier que : 
  A=N+(item en 1ère position – item en 4ème position )  
       et     B=N+(item en 1ère position – item en 4ème position)  
Comme le Numérateur du coefficient (x,y) est égal à A-B et qu’ici  A=B  
l’indice (x,y) associé à une permutation : III Famille 4321 ∈><  
aura une seule et unique valeur nulle , soit :  
 
0y)(x, =  
 
.  .  
Revenons au tableau de contingence Tetrachorique proprement dit et appliquons les résultats 
précédents à deux configurations qui peuvent se produire fréquemment (en particulier dans le 
cas  général d’un tableau de données de type « présence-absence » pour lequel il n’y a pas a 
priori de structure sur les éléments qui permettent d’éliminer des configurations). Choisis-
sons par exemples les 3 configurations d’ordres totaux suivants : 
N°1= 00(x,y)>11(x,y)>01(x,y)> 10(x,y)  
N°2= 11(x,y)>10(x,y)>00(x,y)> 01(x,y) 
N°3= 11(x,y)>10(x,y)>01(x,y)> 00(x,y) 
 
RNTI-A-3- 291 -
Essai de Typologie Structurelle des Indices de Similarités  
• L’ordre  N°1 appartient de façon évidente à la Famille I, il est équivalent à <dacb> 
avec les notations précédentes. Dès lors les valeurs possibles de l’indices sont don-
nées par :   
     
)( 2
)(2
y)(x,
432
432
++
+−
=
        ou          
421
321
2
2
y)(x,
++
−+
=
 
après identification de 1, 2, 3, 4 respectivement à  00(x,y), 11(x,y), 01(x,y), 10(x,y)  
il vient : 
 
o )y01(x,y)11(x,y)10(x,y)00(x,     si    
y)(x,01y)(x,10y)2.11(x,
y](x,01y)[01(x,y)2.11(x,y)(x, +>+
++
+−
=
 
(On retrouve ici un indice connu puisque l’indice de Dice est égal à :                     
   
y)(x,01y)(x,10y)2.11(x,
y)]2.11(x,y)(x,Sd
++
=
) 
                d’où                                      
       1y)(x,S2y)(x, d −=  
o )y01(x,y)11(x,y)10(x,y)00(x,     si      
y)2.10(x,y)00(x,y)11(x,
y)2.01(x,y)00(x,y)11(x,y)(x, +<+
++
−+
=
 
 
Compte tenu de l’ordre induit , on voit que dans les deux cas de figure : (x,y)  0 
                                                                    
 
• L’ordre N°2 appartient, lui, à la Famille II des ordres à imbrication, il est équiva-
lent à <abdc> . Les valeurs possibles de l’indice (si l’on identifie 1, 2, 3, 4 respec-
tivement à  11(x,y), 10(x,y), 00(x,y), 01(x,y) ) sont données de façon générale par : 
 
)( 2

y)(x,
423
43
++
−
=
    ou     
)( 2

y)(x,
314
21
++
−
=
 
 
on aura donc : 
 
o y)01(x,y)11(x,y)10(x,y)00(x,    si     
y)01(x,y)10(x,y)2.00(x,
y)(x,10y)00(x,y)(x, +>+
++
−
=
  
o y)01(x,y)11(x,y)10(x,y)00(x,    si     
y)(x,00y)(x,11y)2.01(x,
y)(x,10y)11(x,y)(x, +<+
++
−
=
 
 On voit ici encore que dans les deux cas de figure précédents , compte tenu de 
l’ordre induit : 
 3 > 4  et 1 >2 , on a :          (x,y)  0 
 
• L’ordre N°3 appartient à la Famille III des ordres à emboîtement , il est équivalent 
à <abcd>,  de facto  
on aura donc :          (x,y) = 0 dans cette configuration 
 
 
Comportement de l’indice  (x,y)  de Goodman-Kruskal  en cas  de Disjonction Com-
plète 
RNTI-A-3 - 292 -
                                                                                                    F. Marcotorchino 
 
En cas de disjonction complète , le tableau  Tetrachorique se ramène à : 
 
 y Non y  
x 11(x,y) m-11(x,y) m 
Non x m-11(x,y) P+11(x,y)-2m P-m 
 m P-m N 
   
  Les formules suivantes : 
               ( ) 
= =
−+−+−+−+=+=
p
1u
q
1v
uv
u
uv
v
dbcbcaba
2
1NnMaxnMaxA(i)  
              [ ]d)(bcad)(cba
2
1NB(ii) +−+++−++=  
se simplifient, puisqu’ici N=P, en:  
 
        (i)             A= P+|m-2.11(x,y)|+ |P+2.11(x,y)-3m|      
(ii) B= P+ | P-2m| 
(iii) En cas de disjonction complète :00(x,y)>11(x,y)  (sauf pour P=2m), 10(x,y)=01(x,y)=m-11(x,y)  
seule reste posée la question du positionnement de 11(x,y) par rapport à 10(x,y) .  
Si 11(x,y)>10(x,y)=01(x,y) alors 11(x,y)>m-11(x,y) => 11(x,y)>m/2 (majorité de Condorcet) et  
l’ordre associé est : 00(x,y)>11(x,y)>10(x,y)=01(x,y)  (cas des ordres à séparation vus précédem-
ment) 
Si 11(x,y)<10(x,y)=01(x,y) alors  11(x,y) <m-11(x,y)    =>  11(x,y)m/2 l’ordre associé est l’ ordre 
à emboîtement : 00(x,y)>10(x,y)=01(x,y)>11(x,y)  
 
• Si P=2m alors B=P=2m et : 
                              si 11(x,y) > m/2   alors   1y)(x,2S
m
my)2.11(x,y)(x, d −=
−
=
  
                              si  11(x,y) < m/2   alors   (x,y) =0    
 
• Si P 3m  alors B=2P-2m et A= 2P +211(x,y) –3m + |211(x,y)-m|b 
             
                              si 11(x,y)>m/2   alors   1y)(x,2S
2m
m2y)4.11(x,y)(x, d −=
−
=
 
  
                     si 11(x,y)  m/2   alors (x,y) =0 
               (en effet dans ce cas on se retrouve comme précédemment  dans une situation d’emboîtement  avec              
00(x,y)>01(x,y)=10(x,y)>11(x,y)) 
 
 En conclusion l’indice de Goodman Kruskal calculé sur Tableau Tetrachorique en cas de 
disjonction complète se présente comme un indice de similarité à « cliquet » ou à seuil, qui, 
suivant la valeur de 11(x,y), est nul ou équivalent  à  2 Sd(x,y)-1  (Homothétie sur l’indice de 
Dice)  ce qui veut dire par ailleurs que  dans le cas de disjonction complète l’indice:  
 
                                   S(x,y) =1/2 ((x,y)+1)  est équivalent à  Sd (x,y) si  11(x,y) > m/2 
La condition de Solomon Fortier appliquée à cet indice comme il varie de 0 à 1 si 11(x,y)>m/2 
se traduira par l’inégalité : 
   (x,y)   1/2  2 Sd(x,y)-1  1/2  2 Sd(x,y)   3/22.11(x,y)  3/2.m  11(x,y)   3/4 m  (ma-
jorité au ¾)  
RNTI-A-3- 293 -
Essai de Typologie Structurelle des Indices de Similarités  
On a tracé ci-dessous le graphe le l’indice Lambda de Goodman Kruskal   (x,y) en fonction 
de l’indice de Dice ou de façon équivalente du rapport 11(x,y)/m dans le contexte de disjonc-
tion complète. 
 
0
0,2
0,4
0,6
0,8
1
1,2
0 0,2 0,333 0,5 0,625 0,76 0,9 1
Lambda
Dice
 
 
 
4.4.5.5. Indice de similarité déduit  du Coefficient « κ » de Cohen 
 
  Comme le souligne G. Saporta dans son livre de  (2006) (réédition de son premier ouvrage 
de 1990), ce coefficient de contingence est destiné à mesurer l’accord entre deux variables 
qualitatives (partitions) ayant le même nombre de modalités p. ;  n
..
 unités statistiques sont 
réparties suivant ces  p catagories pour les deux partitions. Il y aura accord total entre ces 
deux partitions si les termes diagonaux sont les seuls termes  non nuls du tableau de contin-
gence suivant. (La première référence à ce coefficient est donnée dans un article du biostatis-
tien et psychométricien  Jacob Cohen datant de 1960 (1960)).  
 
 
 
 
 
 
 
 
 
 
 
 
 
L’indice s’écrit alors :  
 
(f 105) 
 
     y 
x 
1 2 v .. p 
 
1      n1. 
2      n2. 
u 
  
vun  
  
 n
 u . 
..       
p       
 n
.1 n.2 n. v   n..

 
=
= =
−
−
= p
1u
u.u.2
..
p
1u
p
1u
u.u.2
..
uu
..
nn
n
11
nn
n
1
n
n
1
y)(x,
RNTI-A-3 - 294 -
                                                                                                    F. Marcotorchino 
 
 
 
        Cet indice vaut : 
 1 en cas d’association complète et totale   
-1 en cas où tous les termes de la diagonales sont nuls et les termes hors diagonales sont 
égaux 
Dans le cas qui nous concerne nous travaillons sur un tableau (2x2), vérifiant donc p= q =2 
(les deux variables ont même nombre de classes). Ce tableau est du type suivant : 
 
 
 y Non y  
x a b a+b 
Non x c d c+d 
 a+c b+d N 
 
 
De ce fait nous pouvons  calculer  le coefficient κ(x,y) sur le tableau  précédent, il vient  
 
 
(f 106) 
 
 
 
Après simplification on obtient:  
(f 107):  
 
 
Cet indice possède une autre expression équivalente en effet il s’écrit :  
 
(f 107’)                    
)dc)(ca()db)(ba(
]bcad[2)y,x(
+++++
−
=
 
En effet les dénominateurs de (f 107)  et (f 107’)  sont égaux après développement, néanmoins 
grâce à l’expression (f 107’) , on voit que,  en posant : 
)dc)(ca(
)bcad(
vet)db)(ba(
)bcad(
u
++
−
=
++
−
=
 
 
)vu(
v.u2)v,u(HarmoniqueMoyenne)y,x(
+
==
 
et  
vu)v,u(eGéométriquMoyenne)y,x(ST ==  
 
On en déduit que :    
 
 
Le coefficient de Cohen vaut : 
 
•  +1, en cas d’association complète et totale  b=c=0  et  a et d ≠0 
d)]d)(c(bc)b)(a[(a
N
11
d)]d)(c(bc)b)(a[(a
N
1d)(a
N
1
y)(x,
2
2
+++++−
+++++−+
=
)d(a)c(bd)N(a
)d(a)c(bc)](bd)N[(a
bc]2[adc)(bN
bc]2[ady)(x, 2222
2222
+−+++
+−+++−+
=
−++
−
=
1)y,x(S)y,x(0 T ≤≤≤
RNTI-A-3- 295 -
Essai de Typologie Structurelle des Indices de Similarités  
• -1, au cas où tous les termes de la diagonales sont nuls et les termes hors diagonale 
sont égaux 
 
En effet, on  voit  grâce à la formule (f 106) que quand a+d=N (c’est à dire b=c=0),  alors : 
                                                         
1
)d(a
N
11
)d(a
N
11
y)(x,
22
2
22
2
=
+−
+−
=
  
grâce à la deuxième formulation  on voit que quand a=d=0, alors b+c=N  et  κ(x,y) devient : 
 
 
 
 
ce coefficient est minimal lorque « bc »  est maximum et  « b2+c2 » minimum , or nous avons 
vu au §4.4.5.3 que ceci se produisait quand les deux nombres sont égaux en effet : « le pro-
duit de 2 nombres dont la somme S est constante (ici égale à N)  est maximum si ces deux 
nombres sont égaux », la conséquence pour notre problème est que : quelle que soit la valeur 
N , on doit avoir  b = c = N/2   à l’optimum.  D’où le fait signalé que l’indice de Cohen  Kap-
pa est égal à –1 dans ce cas . 
 
Comme l’indice Kappa  de Cohen varie de –1 à +1, il évoque un indice corrélatif, pour en 
faire un indice de similarité vrai, variant de 0 à 1,  il suffit de construire l’indice de similarité 
« affine » associé au Kappa de Cohen en remplaçant dans les formulation précédentes « a par 
11(x,y) », « b par 10(x,y) », « c par 01(x,y) »,  « d par 11(x,y) », et N par P et en calculant la quanti-
té ½(κ(x,y)+1), il vient: 
 
y)]01(x,y)P[10(x,y)]01(x,y)10(x,y)00(x,y)2[11(x,
y)]01(x,y)[10(x,
2
Py)]01(x,y)10(x,y)00(x,y)2[11(x,
c)N(bbc)ad2(
c)(b
2
Nbc)ad2(
1]y)(x,[
2
1
 y)(x,S
++−
++−
=
++−
++−
=+=
 
 
sous cette forme on  voit que l’indice de similarité vaut :  
• Sκ(x,y) =0  si 11(x,y)=00(x,y)=0 avec la condition supplémentaire :  10x,y)=01(x,y)=N/2 
• Sκ(x,y) =1/2  si 11(x,y).00(x,y)= 10(x,y).01(x,y) (condition d’indépendance) 
• Sκ(x,y) =1  si  10(x,y)=01(x,y)=0 
 
Si l’on compare le coefficient Kappa de Cohen et le coefficient Q de Yule on voit qu’ils ont 
des points communs  puisqu’ils qu’ils utilisent les mêmes quantités,  mais pas de la même 
manière.  
y)y).01(x,10(x,y)y).00(x,11(x,
y)y).10(x,01(x,y)y).00(x,11(x,
bc)(ad
bc)(ady)(x,SQ
+
−
=
+
−
=
 
 
 
Comportement de l’indice S(x,y) en cas  de Disjonction Complète 
En cas de disjonction complète l’indice Kappa précédent du fait des symétries entre valeurs 
se simplifie  selon la formule : 
2222 cb
2bc
2bcc)(b
2bc
2bcN
2bc-y)(x,
+
−
=
−+
−
=
−
=
RNTI-A-3 - 296 -
                                                                                                    F. Marcotorchino 
 
 
                     
y)]11(x,-2P[m]y)]11(x,[m2m)y)11(x,(Py)2[11(x,
y)]11(x,-P.[m]y)]11(x,[m2m)y)11(x,(Py)2[11(x,
 y)(x,S 2
2

+−−−+
+−−−+
=
 
Dire que S(x,y)  1/2 implique que : 
        
2
1
y)]11(x,-2P[m]y)]11(x,[m2m)y)11(x,(Py)2[11(x,
y)]11(x,-P.[m]y)]11(x,[m2m)y)11(x,(Py)2[11(x,
 y)(x,S 2
2
 ≥
+−−−+
+−−−+
=
 
 
c’est à dire : 
                             11(x,y)(P+11(x,y)-2m)  (m-11(x,y))2 
soit : 
                        )y(x,11y)2m11(x,my)2m11(x,y)(x,11y)P11(x, 222 +−≥−+  
ce qui implique :   
p
my)11(x,   m,pP    poseon      l'  si
P
my)11(x,
2
≥=≥
 
On retrouve ici une borne équivalente à celle obtenue pour l’indice de similarité dérivé du 
Coefficient de contingence SQ de Yule (voir § 4.4.4.2). 
 
 
4.5  Indices à « valuations », ou  « pseudo-indices de similarités » 
   Nous appelerons indices de similarité  à « valuations » ou « indices d’abondance », les 
indices que nous allons présenter maintenant. En fait ces indices n’ont pas été définis a 
priori pour des tableaux de données binaires de présence–absence mais pour des tableaux 
de données du type du tableau n°1, introduit au § 2.1, mais où les valeurs ne sont plus {0 
ou 1} mais  des « comptages » d’occurrences (ce que les anglo-saxons appelent « abon-
dance matrices » de terme général {tij }.    
 
  
  
  
  
  
  
   
  
                                        
En fait les matrices de « présence-absence » sont des cas particuliers de « matrices 
d’abondance »,  mais bien entendu les indices associés, sont a priori différents de ceux que 
nous avons  présentés jusqu’ici. Il est intéressant de noter par ailleurs que la plupart des 
indices introduits dans ce contexte l’ont été par des spécialistes de l’étude des plantes et 
 m1 m2 mj mj’  mP 
O1 t11 t12 t1j    
O2 
      
O3 t31 t32     
Oi 
  tij    
 Oi’ 
      
 
      
ON tN1  tNj   tNP 
RNTI-A-3- 297 -
Essai de Typologie Structurelle des Indices de Similarités  
principalement des « phytosociologues » ou des spécialistes de ce que les anglo-saxons 
appellent « plant ecology ».  
Notre propos,  dans ce paragraphe, est de voir si certains de  ces indices, dédiés aux ma-
trices d’abondance,  vont générer  dans leur restriction aux cas de tableaux de « présence-
absence », des indices différents de ceux  qui auraient déjà été présentés.  Même dans le 
cas où nous retrouverons  des indices de similarité déjà étudiés précédemment (c’est ce qui 
va se produire), la structure intrinséque de  ces indices est différente de celle que nous 
avons rencontrée  jusqu’à maintenant. Ceci est  riche d’enseignements sur la façon dont les 
phytosociologues les ont imaginés et pensés.   
Par convention,  ici,  les individus x et y seront décrits par leurs profils vectoriels: 
  
x = {tx1, tx2, tx3,……txj..txP} et  y = {ty1, ty2, ty3,……tyj..tyP} 
 
4.5.1 Indices d’abondance  (ou à valuations) fonction de la différence  (t ij -t i’j) 
4.5.1.1 Indice de Lance et Williams (1966) 
   Cet  « indice d’abondance » est défini par :  
(f108)                         
=
+
−
=
P
1j jyjx
jyjx
LW )t(t
tt
P
1y)(x,I  
On voit de façon évidente  qu’il varie de 0 à 1 ,  
Il vaut en effet  0 si tx j = ty j  ∀j,  et il vaut 1 si ∀j , txj≠0  ty j=0  et réciproquement  si  ty j ≠0   . 
tx j = 0, en effet dans ce dernier cas on obtient un ratio concernant l’indice « j » qui vaut 
toujours 1. Si cette situation se produit P fois, la division par P ramène la valeur de l’Indice  
ILW(x,y) à 1. La façon de transformer   un indice d’abondance  en un indice de similarité 
normé paraît donc ici évidente,  il suffit de poser : 
                                                    SLW(x,y) = 1- ILW (x,y) 
L’indice SLW(x,y) varie bien maintenant de 0 à 1 , il vaut 1 si x et y ont un profil identique,   
et 0 s’ils sont totalement en opposition.  
Intéressons nous maintenant à la restriction de cet indice dans le cas où les valeurs {tij} en 
l’occurrence t x j et t y j  sont des valeurs {0 ou 1},  
(Attention : on suppose par convention  ici que les configurations où txj=tyj=0  qui a priori 
impliquent  une division par 0) se traduisent par un ratio égal à 1  :  
Dans ce cas,  ∀ j , le ratio :   
yjxj
yjxj
tt
tt
+
−
 vaut 0 ou 1, il vaut 0 si la valeur tij est identique pour x et 
y et il vaut 1 en cas contraire.    
RNTI-A-3 - 298 -
                                                                                                    F. Marcotorchino 
 
 De ce fait :              ]y)01(x,y)[10(x,
P
1
)t(t
tt
P
1y)(x,I
P
1j jyjx
jyjx
LW +=
+
−
= 
=
 
On a alors la propriété suivante:  
 
 
Propriété n°18 : L’Indice de Similarité  de Lance Willliams dans sa restriction 0-1 avec la con-
vention précédente (pour les cas 0-0)  n’est rien d’autre que le critère de Sokal et Michener 
(Simple Matching)  
En effet on a:  
               y)(x,S
P
y)00(x,y)11(x,y)]01(x,y)[10(x,
P
11)t(t
tt
P
11y)(x,S SM
P
1j jyjx
jyjx
LW =
+
=+−=
+
−
−= 
=
 
 
4.5.1.2 Indice de Odum (1950),  plus connu sous le nom d’Indice de  « Bray-Curtis » 
(1957) 
 
Cet indice est défini par :  
(f109)                         


=
=
+
−
= P
1j
yjxj
P
1j
yjxj
BC
)t(t
tt
y)(x,I
 
Ici on n’a pas besoin (et c’est un avantage), comme dans le cas précédent,  de convention 
particulière pour les cas (0-0). Cet indice vaut 0 si tx j=ty j ∀ j , et il vaut 1 si ∀j , txj≠0  ty j=0  et 
réciproquement  si  ty j ≠0   . tx j = 0, 
Dans le cas où l’on se restreint à des valeurs tij ∈{0,1}, le numérateur de l’indice n’est rien 
d’autre que la quantité  
                                           y)01(x,y)10(x,tt
P
1j
jyjx +=−
=
 
Le dénominateur est égal à : 
                                     y)01(x,y)10(x,y)11(x,.2y)11(y,x)11(x,)t(t
P
1j
yjxj ++=+=+
=
 
L’indice de similarité associé défini par   SBC(x,y)= 1- IBC(x,y)  est donc égal à :  
                
)y(x,S
y)]01(x,y)[10(x,
2
1y)11(x,
y)11(x,
y)01(x,y)10(x,y)211(x,
y)2.11(x,y)(x,S dBC =
++
=
++
=
 
 
Propriété n°19 : L’Indice de Similarité  de Bray-Curtis (Odum), dans sa restriction 0-1, est stric-
tement identique à l’indice de Dice  
 
4.5.2 Indices d’abondance  (ou à valuations) fonction de  Max(tij,ti’j)  ou Min (tij, ti’j)  
4.5.2.1 Indice de Kulczinski formel (1930) 
Cet indice est défini par :  
RNTI-A-3- 299 -
Essai de Typologie Structurelle des Indices de Similarités  
(f110)                         


=
=
+
= P
1j
yjxj
P
1j
yjxj
K
)t(t
)t,(tMin
y)(x,I
 
  
Du fait que Min (a,b)=½ (a+b) - ½ |a - b|, il apparaît de facon évidente que cet indice est égal à :  
 
                                 
y)(x,I
2
1
2
1
)t(t
)t,(tMin
y)(x,I BCP
1j
yjxj
P
1j
yjxj
K −=
+
=


=
=
 
Cet indice vaut ½  si tx j=ty j ∀ j , et il vaut 0  si ∀j , txj≠0  ty j=0  et réciproquement  si  ty j ≠0   . tx j 
= 0, 
 
Dans le cas où l’on se restreint à des valeurs tij ∈{0,1}, on a vu que : SBC(x,y)= 1- IBC(x,y)    
D’où comme  IBC(x,y)= 1-2 IK(x,y) , il vient alors : 
                                       SBC(x,y)=1-(1-2IK(x,y))= 2 IK(x,y)  
en posant              SK(x,y)=2IK(x,y) , il apparaît que cet indiced’abondance  induit au coeffi-
cient 2 près ,  un indice de similarité  égal à l’indice de « Dice ». 
4.5.2.2 Indice de Marczewski et Steinhaus (1937) 
Cet indice est défini par :  
 
(f111)                         


=
=
−
= P
1j
yjxj
P
1j
yjxj
SM
)t,(tMax
tt
y)(x,I
 
 
Dans ce cas encore, en jouant sur le fait que Max(a,b) =½ (a+b) + ½ |a - b| , on voit que la quan-
tité 1/IMS(x,y)   peut se simplifier, en effet on obtient :  
1y)(x,I
y)(x,2Iy)(x,I
y)(x,I
1
x
2
1
2
1
t-t
)t(ttt
y)(x,I
1
BC
BC
MS
BC
P
1j
jyjx
P
1j
P
1j
yjxj2
1
yjxj2
1
MS +
=+=
++−
=

 
=
= =
 
Sous cette forme, il apparaît de façon évidente que IMS(x,y) varie de 0 à 1 , puisque IBC (x,y) 
varie de 0 à 1 lui-même.  
Maintenant définissons l’« indice de similarité de Marczewski et Steinhaus » comme la 
quantité : 
                                                       SMS (X,Y)=1-IMS (X,Y) 
Dès lors,  dans le cas où l’on se restreint à des valeurs tij binaires on peut montrer que 
l’indice précédent s’écrit :  
                              
y)(x,S2
y)(x,S
y)(x,I1
y)(x,I1y)x,S
d
d
BC
BC
MS(
−
=
+
−
=
 
où Sd(x,y) est l’indice de Dice (voir 4.1.1.1) .  La fonction homographique précédente n’est 
autre que la formule (f17) caractéristique de l’indice de Jaccard.  
Donc en conclusion , on a la propriété n°20 suivante : 
 
RNTI-A-3 - 300 -
                                                                                                    F. Marcotorchino 
Propriétén°20 : L’indice de similarité déduit de l’indice d’abondance de Marczewski –Steinhaus 
n’est rien d’autre dans sa restriction booléenne que l’indice de Jaccard 
 
 
 
 
 
 
En guise de conclusion sur les indice du type « indices à valuations ».  
Dans la liste précédente il n’a pas été fait mention (et d’aucuns pourraient s’en étonner) des 
indices qui se calculent à partir de données de fréquences ou  d’occurrences de phénomènes 
(comme par exemple le comptage de termes apparaissant dans des textes).  
Outre les indices de contingences dont nous avons vu quelques exemplaires au § 4.4.,  qui 
peuvent être utilisés dans ce contexte, comme également pourrait l’être le classique  Critère 
du 2;  il se trouve qu’un certain nombre d’auteurs provenant de la Linguistique computa-
tionnelle ou de la recherche documentaire  ont élaboré  des coefficients beaucoup plus adap-
tés au  domaine de la « comparaison documentaire » ou  totalement en adaquation avec  la 
recherche sur Internet. C’est le cas de l’américain Gerard Salton  (voir G. Salton (1968)  et 
(1983)) qui a proposé  avec son équipe,  tout d’abord son « Cosinus simple de profils fré-
quentiels  pondérés»,  puis son fameux «  TF-IDF Cosine »,  (« Term Frequency –Inverse 
Document Frequency »,  coefficient qu’il a d’ailleurs appellé le « best fully weighted sys-
tem » ). Lui et l’anglaise Karen Sparck Jones (1971), ont été les pionniers de ces recherches 
sur les mesures de matching entre documents. On trouvera dans l’article simple et bien struc-
turé de A. Lelu (2002) un essai de comparaison des mesures de Salton avec  d’autres ap-
proches issues de méthodologies « neuronales » ou « factorialistes ».  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
RNTI-A-3- 301 -
Essai de Typologie Structurelle des Indices de Similarités  
 
100
Indices Groupe Type Formule Borne S.F. Variation 
Dice Group I Typ1 y)01(x,y)10(x,y)211(x,
y)2.11(x,y)(x,Sd ++=
 
m/2 0 S  1 
Jaccard Group I Typ1 [ ])y,x(01)y,x(10)y,x(11
)y,x(11)y,x(Sj ++=
 2m/3 0 S  1 
Anderberg Group I Typ1 [ ])y,x(01)y,x(102)y,x(11
)y,x(11)y,x(San
++
=
 4m/5 0 S  1 
Sorensen Group I Typ1 [ ])y,x(01)y,x(10
4
1)y,x(11
)y,x(11)y,x(Sso
++
=
 
m/3 0 S  1 
Anderberg 2 Group I Typ1 [ ])y,x(01)y,x(10
8
1)y,x(11
)y,x(11)y,x(Sac
++
=
 
m/5 0 S  1 
Kulczynski Group I Typ 2A 




	
+
+
+ y)01(x,y)11(x,
y)11(x,
y)10(x,y)11(x,
y)11(x,
2
1
y)(x,Sk
 
m/2 0 S  1 
Ochiaï Group I Typ 2A )]y,x(01)y,x(11)][(y,x(10)y,x(11[
)y,x(11)y,x(So
++
=
 
m/2 0 S 1 
Rappel Group  I Typ 2A y)10(x,y)11(x,
y)11(x,y)(x,SR
+
=
 
m/2 0 S  1 
Précision Group  I Typ 2A y)(x,01y)11(x,
y)11(x,y)(x,SP
+
=
 
m/2 0 S  1 
Quadra/ Norm Group  I Typ 2B 22N y)]01(x,y)[11(x,y)]10(x,y)[11(x,
y).11(x,2y)(x,S
+++
= m/2 0 S  1 
Braun Blanquet Group I Typ 2B [ ])y,x(01)y,x(11),y,x(10)y,x(11Max
)y,x(11)y,x(SMin ++=
 
m/2 0 S  1 
Simpson Group I Typ 2B [ ])y,x(01)y,x(11),y,x(10)y,x(11Min
)y,x(11)y,x(SMax ++=
 
m/2 0 S  1 
McConaughey Group I Typ 2B 




	
++
−
=
y)]01(x,y)y)].[11(x,10(x,y)[11(x,
y)y).01(x,10(x,y)][11(x,y)(x,S
2
McC
 
m/2 -1 S +1 
Sokal- Michen Group II Typ 2B y)01(x,y)10(x,y)00(x,y)11(x,
y)00(x,y)11(x,y)(x,Ssm
+++
+
=
 
m-P/4 0 S  1 
Sokal-Sneath Group II Typ I y)]00(x,y)[11(x,P
y)]00(x,y)2.[11(x,y)(x,Sss ++
+
=
 
m-P/3 0 S  1 
Rogers-Tanim Group II Typ I y)]00(x,y)[11(x,2.P
y)00(x,y)11(x,y)(x,Srt +−
+
=
 
m-P/6 0 S) 1 
Rao Group II Typ I y)01(x,y)10(x,y)00(x,y)11(x,
y)11(x,y)(x,S r
+++
 
P/2 0 S  1 
Marco/ Mich1 Group II Typ I y)01(x,y)10(x,y)00(x,y)11(x,
y)00(x,y)11(x,
y)(x,S 2
1
mm
+++
+
=
 
2m/3 0 S  1 
Marco/ Mich2 Group II Typ I [ ])y,x(01)y,x(10)y,x(00)y,x(11
)y,x(00)y,x(11
)y,x(S
2
1
2
1
2mm
+++
+
=
 
m/2 0 S  1 
Tetrachorique Group II Typ II 
)]y,x(01)y,x(00)][y,x(10)y,x(00)].[y,x(01)y,x(11)][y,x(10)y,x(11[
)]y,x(01).y,x(10)y,x(00).y,x(11[)y,x(ST
++++
−
=
 
m/2 -1 S +1 
Yule Y Group II Typ II 
)y,x(01).y,x(10)y,x(00).y,x(11
)y,x(01).y,x(10)y,x(00).y,x(11)y,x(SY
+
−
=
 
m2/P -1 S +1 
Yule Q Group II Typ II 
)y,x(01).y,x(10)y,x(00).y,x(11
)y,x(10).y,x(01)y,x(00).y,x(11)y,x(SQ
+
−
=
 
m2/P -1 S +1 
MA4  Ratios Group II Typ II 




	
+
+
+
+
+
+
+
= )y,x(10)y,x(00
)y,x(00
)y,x(01y,x(00
)y,x(00
)y,x(01)y,x(11
)y,x(11
)y,x(10)y,x(11
)y,x(11
4
1)y,x(S 4R
 
m/2 0 S  1 
MG4 Ratios Group II Typ II 44o )y,x(01)y,x(00
)y,x(00
x)y,x(10)y,x(00
)y,x(00
x)y,x(01)y,x(11
)y,x(11
x)y,x(10)y,x(11
)y,x(11)y,x(S
++++
=
 4/m≅ 0 S  1 
MH4 Ratios Group II Typ II 





	 +
+
+
+
+
+
+
= )y,x(00
)y,x(01)y,x(00
)y,x(00
)y,x(10)y,x(00
)y,x(11
)y,x(01)y,x(11
)y,x(11
)y,x(10)y,x(11
4
1
)y,x(S
1
4h
 





	
+
p9
341
3
m
 
0 S  1 
Urbani-Buser Group II Typ II 







	
+++
+
=
y)10(x,y)01(x,y)11(x,y)y).00(x,11(x,
y)11(x,y)y).00(x,11(x,y)(x,SBuB
 





	
−
p4.
354
p
m
 
0 S  1 
Lerman mod Group II Typ III [ ]
[ ][ ]2222
2222
L
y)]01(x,y)[00(x,y)]10(x,y)[11(x,y)]10(x,y)[00(x,y)]01(x,y)[11(x,
y))(x,01y)(x,(10y)(x,00y)(x,11y)(x,S
++++++
+−+
=
 
m/2    -1 S+1 
Kappa-Cohen Group II Typ III 
y)]01(x,y)P[10(x,y)]01(x,y)10(x,y)00(x,y)2[11(x,
y)]01(x,y),(P/2)[10(xy)]01(x,y)10(x,y)00(x,y)2[11(x,
 y)(x,S
++−
++−
=
 
m/2 0S 1 
RNTI-A-3 - 302 -
                                                                                                    F. Marcotorchino 
5. Liaison « Indices de Similarité » - « Critères de Contin-
gence », vers un bouclage du processus typologique 
De même que nous avions utilisé au §4.4.5, les expressions de certains critères ou coeffi-
cients de contingence pour retrouver ou définir de nouveaux indices de similarité (par 
exemple l’indice de similarité de « Lerman modifié »), nous allons tenter l’inverse dans ce 
paragraphe en  partant de la notion de codage vectoriel de matrices relationnelles tel que 
nous l’avons introduit au § 2.4.4 .  
En d’autres termes, et pour boucler la boucle, nous allons nous servir des définitions 
d’indices de similarité sur vecteurs binaires, pour retrouver ou éventuellement redécouvrir 
des coefficients d’association sur tableaux de contingence au sens statistique usuel. Rappe-
lons que le codage vectoriel de matrices relationnelles se définit selon le principe : 
Pour toute matrice relationnelle Ck, on   définit  son Extension Vectorielle γk comme un 
vecteur de longueur N2   tel que :  
),....,...,,( k
N
k
s
k
3
k
2
k
1
k
2=

,  où si k
'iiC  est le terme général de la matrice C
k
, alors : 
 
k
s
k
ii' C = ,  si et seulement si  l’indice courant « s » vérifie:   
                                          i'et    i        'iN)1i(s ∀+−=   
Partant de ce principe en posant : 
),....,...,,( k
N
k
s
k
3
k
2
k
1
k
2=

 et ),....,...,,( k'Nk'sk'3k'2k'1k' 2=

 
On peut utiliser,  comme pour n’importe quel tableau binaire, la présentation des données 
sous forme d’un tableau de contingence Tetrachorique , en remplaçant x et y par k  et 
k' , il vient : 
 
 
 
 
 k'  = 1 k'  = 0 
k = 1 11( k , k' ) 10( k , k' ) 
k = 0 01( k , k' ) 00( k , k' ) 
RNTI-A-3- 303 -
Essai de Typologie Structurelle des Indices de Similarités  
 
De ce fait, certains des indices de similarité définis précédemment peuvent être utilisés 
comme indices sur les linéarisations vectorielles  relationnelles, une fois retraduites en 
termes des égalités : kskii' C =  . Donnons quelques exemples, choisis  parmi les indices les 
plus connus:  
5.1 Indices du Groupe  I  
5.1.1 Indice de Dice (Morey-Agresti) 
L’indice de Dice défini par : 
[ ] y)01(x,y)10(x,y)2.11(x,
y)2.11(x,
y)01(x,y)10(x,
2
1y)11(x,
y)11(x,y)(x,Sd
++
=
++
=
 se transforme dans cette configura-
tion en : 
[ ] 

= == =
= =
+
=
γγ+γγ+γγ
γγ
=γγ N
1i
N
1'i
'k
'ii
N
1i
N
1'i
k
'ii
N
1i
N
1i'
'k
'ii
k
ii'
'kk'kkk'k
'kk
'kk
d
CC
CC2.
),01(),10(
2
1),11(
),11(),(S
 
et du fait des liaisons entre “expressions relationnelles” et “notations contingentielles” (voir 
F. Marcotorchino (1984)), on peut  dans ce cas réécrire l’indice de Dice,  (sous réserve que 
Ck et Ck’ représentent des variables nominales ayant respectivement “p” et “q” modalités) sous 
forme d’un coefficient de contingence: 
(f112)                  
 



= =
= =
= == =
= =
+
=
+
=γγ p
1u
q
1v
2
v.
2
.u
p
1u
q
1v
2
vu
N
1i
N
1'i
'k
'ii
N
1i
N
1'i
k
'ii
N
1i
N
1i'
'k
'ii
k
ii'
'kk
d
nn
n2
CC
CC2.
),(S
 
On retrouve dans ce cas un indice de contingence connu sous le nom de Morey-Agresti , 
d’où:     
Indice de Dice (sur matrice relationnelle vectorielle)  Coefficient  d’association de Morey-
Agresti (sur tableau de contingence) 
 
5.1.2 Indice d’Ochiaï (Fowlkes-Mallows) 
De la même façon que dans le cas de l’Indice de Dice, l’indice d’Ochiaï appliqué au tableau 
Tetrachorique précédent nous redonne un Coefficient de contingence connu. En effet nous 
avons vu que l’indice d’Ochiaï était défini par :   
 
                                
)]y,x(01)y,x(11)][(y,x(10)y,x(11[
)y,x(11)y,x(So
++
=
 
 
 
Soit après remplacement de x et y par k et k’: 
RNTI-A-3 - 304 -
                                                                                                    F. Marcotorchino 
Il vient alors: 
            


= == =
= =
=
γγ+γγγγ+γγ
γγ
=γγ
N
1i
N
1'i
'k
'ii
N
1i
N
1'i
k
'ii
N
1i
N
1i'
'k
'ii
k
ii'
'kk'kk'kkk'k
'kk
'kk
o
CC
CC.
),(01),(11),(10),11(
),11(),(S
 
et de façon identique au cas de l’indice de Dice, en utilisant également les liaisons entre 
“expressions relationnelles” et “notations contingentielles” (voir F. Marcotorchino (1984)), 
on peut  dans ce cas réécrire l’indice d’Ochiaï,  (sous réserve que Ck et Ck’ représentent des 
variables nominales ayant respectivement “p” et “q” modalités) sous forme d’un coefficient 
de contingence: 
(f113)                      




==
= =
= == =
= =
==γγ
q
1u
2
v.
p
1u
2
.u
p
1u
q
1v
2
vu
N
1i
N
1'i
'k
'ii
N
1i
N
1'i
k
'ii
N
1i
N
1i'
'k
'ii
k
ii'
'kk
o
nn
n
CC
CC.
),(S
 
Quiconque , familier des statistiques contingentielle peut reconnaître dans la formule (f113) 
l’expression du Coefficient de Contingence de Fowlkes et Mallows  (voir Fowlkes et Ma-
llows(1983)). On trouvera également  une étude détaillée de ce critère  et les bornes qui lui 
sont associées dans la thèse de H. Messatfa (1989) . 
 
Indice d’Ochiaï (sur matrice relationnelle vectorielle)  Coefficient  d’association de 
Fowlkes et Mallows (sur tableau de contingence) 
 
 
5.1.3 Indice de Kulczynski (Hubert, Arabie) 
Nous avons vu au §  4.2.1.1, que l’indice de Kulczynski était donné par :  
 





	
+
+
+
= )y,x(01)y,x(11
)y,x(11
)y,x(10)y,x(11
)y,x(11
2
1)y,x(S k
 
En appliquant le même raisonnement que pour les indices de Dice et Ochiaï , on obtient le 
résultat suivant:  
[ ] [ ]











	
+=




	
γγ+γγ
γγ
+
γγ+γγ
γγ
=γγ


= == =
= =
N
1i
N
1'i
'k
'ii
N
1i
N
1'i
k
'ii
N
1i
N
1i'
'k
'ii
k
ii'
'kk'kk
'kk
'kk'kk
'kk
'kk
k
C
1
C
1
2
CC
),(01),(11
),(11
),10(),(11
),11(
2
1),(S
 
soit en notations contingentielles et  en appliquant toujours les  remarques et restrictions  
définies pour Dice et Ochiaï: 
(f114)

 
 
 
 



= =
= =
= =
= = ==
= = =
= =
= == =
= =











	
+
=
+
=











	
+=γγ
p
1u
q
1v
p
1u
q
1v
2
v.
2
.u
p
1u
q
1v
2
v.
2
.u
2
uvN
1i
N
1i
N
1'i
'k
'ii
k
'ii
N
1'i
N
1i
N
'i
N
1i
N
1'i
'k
'ii
k
'iiN
1i
N
1'i
'k
'ii
k
'iiN
1i
N
1'i
'k
'ii
N
1i
N
1'i
k
'ii
N
1i
N
1i'
'k
'ii
k
ii'
'kk
k
nn2
nn
n
CC2
CC
CC
C
1
C
1
2
CC
),(S
 
RNTI-A-3- 305 -
Essai de Typologie Structurelle des Indices de Similarités  
En fait les indices  ),(S 'kkd γγ , ),(S 'kko γγ , ),(S 'kkk γγ  possèdent le même numérateur 

= == =
=
p
1u
q
1v
2
uv
'k
'ii
N
1i
N
1'i
k
'ii nCC et ne différent que par leurs dénominateurs qui jouent le rôle de 
borne supérieure pour le numérateur. Les dénominateurs respectifs sont: la moyenne 
Arithmétique, la moyenne Géométrique, et la moyenne Harmonique  des quantités 
 
= =
p
1u
q
1v
2
v.
2
.u netn , qui jouent effectivement le rôle de bornes de variation pour le numéra-
teur. Ceci a été étudié pour l’ensemble de ces trois critères par L. Hubert et P.Arabie 
(1985), par A. Agresti et L. Morey (1984) ainsi que par H. Messatfa  (1989).  
Ces trois critères sont donc connus, le premier a été étudié par Agresti et Morey , le second a 
été étudié par Fowlkes et Mallows qui lui ont donné leurs noms, le dernier a été étudié par 
L.Hubert et P. Arabie ainsi par H.  Messatfa qui a fait  une étude comparative d’autres bornes 
possibles au dénominateur, en plus des trois précédentes.   
 
 
5.2 Indices du Groupe II  
5.2.1 Indice de Sokal et Michener et Green Rao  (Condorcet, Rand) 
L’indice de Sokal et Michener est défini au § 4.4.1.1 par : 
)y,x(01)y,x(10)y,x(00)y,x(11
)y,x(00)y,x(11
P
)y,x(00)y,x(11)y,x(Ssm
+++
+
=
+
=
 
il se transforme dans la  configuration en notations relationnelle vectorielles selon 
l’expression  suivante: 
[ ] 2
N
1i
N
1i'
N
1i
N
1'i
'k
'ii
k
'ii
'k
'ii
k
ii'
'kk'kk'kkk'k
'kk'kk
'kk
sm N
CCCC
),01(),10(),(00),11(
),00(),11(),(S





	
+
=
γγ+γγ+γγ+γγ
γγ+γγ
=γγ
 
= = = =  
ceci du fait des liaisons entre “expressions relationnelles” et “profils vectoriels”. On recon-
naît dans le numérateur de l’expression relationnelle présentée à droite de l’indice de Sokal 
et Michener, la forme symétrique du critère de Condorcet valable pour le croisement entre 
deux variables qualitatives.  
De plus sous réserve que Ck et Ck’ représentent des variables nominales ayant respectivement 
“p” et “q” modalités et en utilisant les formules de passage relations contingences  (voir 
encore F. Marcotorchino (1984), on obtient la formule contingentielle suivante (en identifiant 
les notations  N et n
.. 
): 
(f115)  
2
..
p
1u
q
1v
p
1u
q
1v
2
..
2
v.
2
.u
2
uv
2
N
1i
N
1i'
N
1i
N
1'i
'k
'ii
k
'ii
'k
'ii
k
ii'
'kk
sm
n
nnnn2
N
CCCC
),(S
   
= = = == = = =
+−−
=





	
+
=γγ    
On reconnaît dans l’expression à droite ci dessus, l’une des formes possibles du critère de 
Rand , W. Rand (1971) , en tout cas celle étudiée par F. Marcotorchino  (1984) . 
En conclusion l’indice de similarité de  Sokal et Michener nous permet de retrouver en con-
sécution et dans la foulée le Coefficient de Condorcet (approche relationnelle) et celui de 
Rand (approche contingentielle).               
RNTI-A-3 - 306 -
                                                                                                    F. Marcotorchino 
 
5.2.2 Indice de Similarité Tetrachorique (ou de Bravais –Pearson) (Lerman)  
De même que dans le cas de l’Indice de Sokal et Michener, intéressons nous maintenant à un 
autre indice de similarité du Groupe II (en l’occurrence du Type II) , à savoir l’indice « Te-
trachorique » donné  (page 55) par :  
 
)]y,x(01)y,x(00)][y,x(10)y,x(00)].[y,x(01)y,x(11)][y,x(10)y,x(11[
)]y,x(01).y,x(10)y,x(00).y,x(11[)y,x(ST
++++
−
=
 
 
Soit en  remplaçant x et y par k et k’: 
),(01),(00),(10),(00),(01),(11),(10),11(
),(01),(10),).00(,11(),(S
'kk'kk'kk'kk'kk'kk'kkk'k
'kk'kk'kk'kk
'kk
T
γγ+γγγγ+γγγγ+γγγγ+γγ
γγγγ−γγγγ
=γγ
 
en utilisant également les liaisons entre “expressions vectorielles relationnelles” et “notations 
relationnelles  (voir §2.4.4), on peut  dans ce cas réécrire l’indice Tétrachorique ou de Bra-
vais Pearson  sous forme de l’expression suivante: 
                    

   
= == == == =
= = = = = = = =
−
=γγ
N
1i
N
1'i
'k
'ii
N
1i
N
1'i
k
'ii
N
1i
N
1'i
'k
'ii
N
1i
N
1'i
k
'ii
N
1i
N
1i'
N
1i
N
1'i
N
1i
N
1'i
N
1i
N
1'i
'k
'ii
k
'ii
'k
'ii
k
'ii
'k
'ii
k
'ii
'k
'ii
k
ii'
'kk
T
CCCC
CCCCCC.CC.
),(S
 
En utilisant maintenant les formules de passages contingence<=> relations (voir F. Marco-
torchino  (1984) ) nous allons transformer l’expression de l’indice ci dessus en une forme 
contingentielle, on obtient après développements et simplifications (après identification des 
notations  N et n
..
):  
 
(f116)           

 
====
=== =
−−
−
=γγ
q
1v
2
v.
2
..
p
1u
2
.u
2
..
q
1v
2
v.
p
1u
2
.u
q
1v
2
v.
p
1u
2
.u
p
1u
q
1v
2
uv
2
..
'kk
T
nnnnnn
nnnn
),(S
 
 
Si nous divisons le numérateur et le dénominateur de la formule précédente par n
..
,
 il est 
intéressant de constater que  l’expression donnée par la formule (f116) est strictement équi-
valente à la formule (f97) caractérisant le coefficient de contingence de IC Lerman. Ici il 
apparaît bien que la boucle est bien bouclée, l’utilisation des tableaux de contingence et des 
coefficients nous avait permis de déboucher sur un indice de similarité nouveau : l’indice de  
similarité de « Lerman modifié ». Le passage par les notations « relationnelles vectorielles en 
extension » nous permet réciproquement  de retrouver le coefficient de contingence de 
Lerman comme un cas d’illustration contingentielle du coefficient de similarité Tetracho-
rique ou de Bravais Pearson.   
Attention, c’est bien par un « jeu d’écritures »  que nous avons obtenu cette équivalence,  car 
nous avions vu que l’indice L(x,y) était égal au produit ST(x,y)SL(x,y),  nous ne démontrons 
pas ici que l’égalité ST(x,y)=L(x,y) est vraie, mais que dans l’« espace  relationnel » 
l’équivalence des formules existe.    
 
RNTI-A-3- 307 -
Essai de Typologie Structurelle des Indices de Similarités  
Ce que nous venons d’obtenir pour quelques  indices de similarité nous permettant de redé-
couvrir des coefficients de contingence connus ou moins connus, pourrait être généralisé à 
l’ensemble des indices de similarité présentés dans ce travail, nous laissons le soin au lecteur 
de voir (à  titre d’exercice ) si certains indices ainsi listés auraient des formes contingentielles 
intéressantes ou originales ? 
 
 
 
RNTI-A-3 - 308 -
                                                                                                    F. Marcotorchino 
6. Conclusion sur les Indices de Similarités et leur Usage 
    Comme nous venons de le voir , nous avons  passé en revue plus d’une  trentaine d’indices 
de similarités différents (auxquels on peut ajouter ceux issus de la définition des restrictions 
binaires des « indices d’abondance »). Nous en  avons présenté plus de 35 et listé 28 des 
principaux,  certains de ces indices sont d’usage courant,  d’autres sont plus ésotériques, mais 
ils existent en tant que tels et peuvent  donc être utilisés dans des conditions particulières.  
Comme nous l’avons vu également un certain nombre d’entre eux ont été définis soit explici-
tement , soit historiquement,  soit par l’usage.  
Ainsi les indices de Dice, de Jaccard, de Sørensen, d’Anderberg, de Rogers-Tanimoto, de 
Sokal et Sneath, de Sokal et Michener, de Simpson,   de Braun-Blanquet, d’Ochiai, de Yule, 
d’ Urbani-Baroni-Buser, de Kulczinski, de Mac Connaughey , de Russel-Rao,  ont été intro-
duits directement par ces auteurs, pour des usages qui se rapportaient à leurs besoins. A ce 
propos un nombre important des indices cités ont été reinventés au fil du temps, après la 
découverte initiale,  par des spécialistes de disciplines différentes (voir à ce propos la note de 
bas de page n°8). Nous avons tenté dans cet article d’attribuer  aux indices  le nom de 
l’« inventeur » le plus « ancien » ou le plus sûr . Par ailleurs nous avons vu qu’il y a une 
deuxième classe d’indices, ceux  qui n’ont pas été introduits de façon directe,  mais qui l’ont 
été  à la suite de raisonnements ou de déductions.  
Ainsi en construisant  des indices d’association à partir de  tableaux de contingence (2x2) 
avons nous retrouvé en fin de calculs, soit des indices, déjà introduits par  ailleurs, soit des 
indices originaux comme le sont  par exemple les indices dérivés  du Coefficient de Lerman 
ou  du coefficient de Goodman Kruskal, soit  enfin nous en avons obtenus par  déduction par 
rapport à des propriétrés mathématiques générales (exemple : Indices d’Hadamard) . Ils 
n’étaient, à ma connaissance  pas connus des utilisateurs d’indices classiques (ce qui prouve 
qu’il y a de la place pour en trouver de nouveaux). Les indices bâtis autour des  « 4 ratios » 
(à partir de l’idée originale d’Anderberg) ne sont pas, eux aussi, très connus, et très pratiqués.  
Pour s’éloigner des pistes usuelles des approches comme celle de Tversky sont intéressantes,   
au sens  qu’elle a permis d’introduire de nouvelles familles d’indices à la suite de raisonne-
ments d’ordre logique, même si les indices les plus connus de cette famille d’indices 
« Tverskiens » sont les indices de Rappel et de Précision (qui ne sont  rien d’autre au fond ,  
suivant le cas,  que l’indice de Simpson ou l’indice de Braun –Blanquet). Cette approche 
fondée sur le raisonnement logique  nous avait également permis d’introduire à la suite d’un 
travail sur les  bornes « à la majorité » de ces indices, les indices auxquels nous avons donné 
notre nom. Enfin une place particulière doit être faite à l’indice que nous avons appellé in-
dice Tetrachorique, au sens qu’il est au centre des convergences  des  calculs effectués sur les 
4 quantités du tableau de contingence du même nom.  
D’un point de vue pratique le lecteur de cet article, serait sans doute soucieux,  tout au moins 
nous le pensons,  d’avoir   une clé de lecture lui permettant de savoir quels sont les « bons 
indices de similarités », en d’autres termes de faire une selection des meilleurs d’entre eux, 
pour un usage généraliste.  
 C’est exactement ce que nous  proposons ci après.  
 
 
 
 
RNTI-A-3- 309 -
Essai de Typologie Structurelle des Indices de Similarités  
Liste d’ « Indices Candidats » comme Indices validés d’usage courant   
 
 Avant tout il convient de se donner des critères permettant de définir ce qu’est un « bon » 
indice.  En voici une liste possible, hiérarchisée, correspondant aux cas d’usage les plus clas-
siques, d’autres pourraient également convenir dans certaines configurations particulières 
d’utilisation ou de domaines d’application : 
1. Un « bon » indice se devra de varier de 0 à 1 (ou du moins de valoir 1 pour 
S(x,x) ) (autosimilarité maximale « normée ») 
2. Un « bon » indice devra vérifier  une borne de Solomon Fortier égale à « m/2 »   
pour 11(x,y), en cas de disjonction complète 
3. Un « bon » indice devra vérifier si possible la Transitivité Indicielle Générali-
sée, ce qui signifie que la dissimilarité associée pourra être  une « distance » et 
dans le cas « favorable » une  distance  euclidienne  
4. Un « bon » indice se doit d’avoir une structure de calcul linéaire  des valeurs 
du numérateur  et du dénominateur de l’indice faisant jouer un rôle aux quanti-
tés : 11(x,y), 01(x,y), 10(x,y) et 00 (x,y). ceci du fait que sinon les calculs générés 
sont génants et coûteux pour les applications induites.  
 
Par rapport à cette liste hierarchisée, nous voyons que pour les Indices du Groupe I :  ceux 
de  « Dice »,  et d’« Ochiai »,    qui satisfont aux quatre exigeances : 1, 2, 3 , 4 ,  sont donc 
les indices ayant le spectre le plus général, qu’il faut  choisir en priorité. On choisira ensuite 
les indices de Jaccard  (1,3,4) et de Kulcsinsky (1,2,4) qui ne vérifient que 3 des propriétés 
précédentes  Puis suivant l’usage  qui peut en être fait,  les indices de « Rappel » et de 
« Précision » (ou indices de Simpson & Braun Blanquet) qui  sont incontournables dans le 
domaine du Text Mining , ou du moins dans le domaine de la recherche documentaire.  
  
On peut rajouter à cette liste pour les  Indices du Groupe II : les indices suivants : l’indice  
« Tetrachorique affine » (c’est à dire la forme ramenée à varier de 0 à 1 de cet indice) qui 
vérifie les points 1 et 2 , l’indice de « Marcotorchino-Michaud2 »  (qui vérifie les condi-
tions 1, 2, 4),  de même pour l’indice de Moyenne Arithmétique des 4 ratios d’Anderberg 
(qui  vérifie  les conditions 1,  2 et  4  également) . On rajoutera dans la mesure où  l’usage 
des configurations  00(x,y) s’impose, le coefficient de  Sokal et Michener   (puisqu’il est une 
variante du critère de Rand ou de Condorcet) . 
 
D’une façon plus précise,  l’utilisation et le choix d’un indice peut dépendre d’habitudes ou 
de normes d’usage, ainsi nous avons vu qu’en « chimie moléculaire » un certain nombre 
d’indices sont souvent proposés et utilisés,  qui ne le sont par aucune autre communauté 
scientifique (par exemple l’indice de Mac Caunnaughey, cité dans N. Jeliazkova (JN2007) 
qui est    quasiment inconnu des autres domaines d’usage ).  
On voit également que même au niveau du vocabulaire,   l’usage d’une communauté fait 
souvent référence à un nom d’indice,  pour un usage approprié,  sans se poser la question de 
sa signification en dehors de ses propres normes. A  ce propos les remarques intéressantes 
sur l’Indice de Simpson ou (de celui de Braun Blanquet)  dans   Bradshaw (1997) et Boyce et 
Ellison ( 2001) caractérisant leur usage auprès de la communauté des chimistes moléculaires 
est à comparer aux rôles joués par les indices de « Rappel » et de « Précision » auprès de la 
communauté des spécialistes du Traitement des langues (TAL) Parfois, on aboutit à des 
RNTI-A-3 - 310 -
                                                                                                    F. Marcotorchino 
redécouvertes ou à des impressions de complexité apparente qui n’existent pas,  en fait,   si 
l’on revient à l’expression originelle d’une mesure de similarité et bien entendu si l’on sait à 
quelle filiation elle appartient. Ainsi dans un ouvrage très récent (2008), et fort intéressant 
par ailleurs, intitulé « Classification Supervisée de Documents » (2008)(éditions Hermes-
Lavoisier),  l’auteur,  J. Beney  fait une digression  de trois pages sur les propriétés de la 
Fonction F(γ) (« dite Fonction F », fonction non triviale du Rappel et de la Précision, chère 
aux tenants des « métriques » et des évaluations dans le domaine du TAL), alors que cette 
fonction, même utile, n’est que partielle et reprend des indices connus et très anciens (Dice 
ou  Ochiai .. Kulczinski etc..) amplement étudiés et validés par d’autres19.  Ce qui est dit ici à 
propos des communautés du TAL ou de la Chimie Moléculaire aurait pu être étendu tout 
aussi bien aux communautés de la zoologie, de la biométrie, de la phylogénie, de la phytoso-
ciologie  etc… 
Il existe encore beaucoup de choses à dire sur les Indices de Similarité, nous arrêtons ici ce 
long descriptif , mais d’autres analyses complémentaires et exhaustives seraient encore 
utiles. A titre d’exemple, les réflexions autour d’approches logiques simples ou logiques 
floues,  telles que celles proposées par l’équipe de B. Bouchon-Meunier  du LIP6, qu’on 
pourra consulter  dans Bouchon Meunier-Marsala (2003) et (2000) ainsi que dans  Lesot, 
Rifqi, Benhadda (2009), d’une part,  ou des approches jouant sur la pondération de  l’ordre 
d’apparition des « matchings »,  comme celles exposées  dans les articles de C. Michel 
(2001) ou L. Egghe (2006), d’autre part, permettraient d’organiser les familles d’indices 
suivant des axes de nature, certes différente,  mais  de fait  complémentaire  à celle dont la 
structure  a été proposée dans ce texte.  
 
 
 
 
 
 
7. Références 
Anderberg M.(1973) :  « Cluster Analysis for Applications », Book n°19, Probability and 
Statistics Series, Academic Press, New-York, 
Agresti A., Morey L (1984).: « An adjustment of the Rand’s Statistic for chance agreement », 
Journal of Educational and Psychological Measurement, Vol44, pp.33-37, 
 Ah-Pine J. (2007): « Sur les Aspects Algébriques et Combinatoires de l’Analyse Relation-
nelle », Thèse de l’Université Paris VI, (2007) 
Arabie P. , Hubert L.(1985) :« Comparing Partitions », Proceedings of the Fourth European 
Meeting of the Classifications Societies, Cambridge,  
                                                 
19
 Ainsi F(1)= Indice de Dice , F(0)= Indice de Précision,, F(∞)= Indice de Rappel . Ok tout çà existe déjà ,  mais 
quid des autres fonctions évidentes de R et P appartenant au Groupe I Type II  (comme l’indice d’Ochiai ( qui est 
limite du Chi²de contingence), où l’indice de Tversky),  pourquoi les gens du TAL ne les considèrent-ils pas  et ont-
ils privilégié la fonction F ?.  
RNTI-A-3- 311 -
Essai de Typologie Structurelle des Indices de Similarités  
Benhadda H. (1998) : « La Similarité Régularisée et ses applications en Classification auto-
matique », Thèse de l’Université Paris VI,   
Baulieu F. B. (1989) : «A classification of presence/absence based dissimilarity coeffi-
cients», Journal of Classification, Vol. 6,, pp. 233-246,Springer-Verlag, New York, Ber-
lin, Braun –Blanquet J. (1932) : « Plant Sociology, the Study of Hart Communities » 
Livre, Mac-Graw Hill, New York,   
Benavent  C. (2001): « Analyse des Proximités », Rapport de l’IAE des Pays de l’Adour, 17 
pages,  disponible sur le site :christophe.benavent @free.fr  
Beney J. (2008):  « Classification Supervisée de Documents », livre publié aux éditions 
Hermes-Lavoisier),   
Bisson  G. (2000): « La similarité: une notion symbolique/numérique ». Livre : Apprentis-
sage symbolique-numérique (tome 2). Eds Moulet Brito. Editions CAPADUES, 
Bradshaw J. (1997) : « Introduction to Tversky similarity measure», Proceedings of MUG 
'97 - 11th Annual Daylight User Group Meeting   Février 1997, 
Brunchwicg L. (1921) : «Les Etapes de la Philosophie Mathématique » , Livre, A. Blanchard 
Editeur, (nouvelle Edition 1981), ancienne édition 1921, 
Benhadda H.,  Marcotorchino F.(1998) : « Introduction à la Similarité Régularisée », Revue 
de Statistique Appliquée, n°56,  pp. 45-69,, Dunod, Paris,  
Bouchon-Meunier B., Marsala C. (2003) : « Logique floue, principes, aide à la décision », 
livre Collection Information-Commande-Communication, Hermes-Lavoisier Editeurs , 
Paris,  
Boyce R. L., Ellison P. C.(2001): « Choosing the Best Similarity Index When Performing 
Fuzzy Set Ordination on Binary Data»,  Journal of Vegetation Science, Vol. 12, No. 5 pp. 
711-720, 
Baroni-Urbani C., Buser M.W. (1976) : « Similarity of binary data », Journal of Syst. Zool. 
n° 24 , pp: 165-178.,  
Burnaby T.P. (1970): «On a method for character weighting similarly coefficient, employing 
the concept of information »,  Journal of  Math. Geology., Vol. 2, n° 1,  pp. 25-38, Car-
nap  R. (1928) : « Der Logische Aufbau der Welt », Weltkreis Verlag , Berlin , 
Caillez F., Pages J.P. (1976): : «Introduction à l’Analyse des Données », Publications de 
l’ASU et du BURO, éditeur la SMASH,  
Cohen J. (1960) : «A coefficient of agreement for nominal scales », Educational and Psycho-
logical Measurement Journal, Vol 20, pp37-46,  
Chandon J.L., Pinson S. (1981) : «  Analyse Typologique : Théorie et Applications », Mas-
son, Paris,  
Decaestecker C. (1992): « Apprentissage en Classification Conceptuelle Incrémentale » , 
Thèse de l’Université Libre de Bruxelles (Faculté des Sciences),  
Dice L.R. (1945): « Measures of the amount of ecological association between species », 
Ecology Journal, Vol 26, pp.297-302,   
RNTI-A-3 - 312 -
                                                                                                    F. Marcotorchino 
Deheuvels P., Marcotorchino F. (2000) : « Statistique et Informatique, la Nouvelle Conver-
gence », Revue RST de l’Académie des Sciences  n°8, Juillet  TECD , 
Driver, H. E., et Kroeber, A. L.(1932) : «Quantitative expression of cultural relationship». 
The University of California Publications in American Archaeologyand Ethnology, 31, 
211-256, 
Egghe L. , Rousseau R (2006).: «Classical retrieval and overlap measures satisfy the re-
quirements for rankings based on a Lorenz curve» , in  Information Processing & Man-
agement, Vol 42, Issue 1, pp.106-120,  
Fleiss J.L.(1975): « Measuring Agreement between two judges in the presence or absence of 
a Trait», Biometrics, N°31, pp 651-659,  
Fowlkes E.B., Mallows J. (1983) : « A method for comparing two hierarchical clusterings», 
JASA (Journal of the American Statistical Association ), Vol 78, pp.553-584, 
Goodall  D.W.: (1966) « A new Similarity Index based on Probability» , Biometrics, n° 22,  
pp. 882- 907,  
Goodman L.A., Kruskal W.H. (1979) : « Measures of Association for Cross Classification », 
Book by Springer Verlag , Berlin, New-York, 
Gower  J.C. (1966): « Some distance properties of latent root and vector methods used in 
multivariate analysis», Biometrika, n°53, pp:325-338,  
Gower  J.C. (1971): « A General Coefficient of Similarity and some of its Properties», Jour-
nal of Biometrics, n°27, pp:857-874,  
Gower J., Legendre P. (1986) : « Metric and Euclidean properties of dissimilarity coeffi-
cients», Journal of Classification,  N°3, pp.5-48, North Holland,  
Grötschel M., Jünger M., Reinelt G. (1982) : « A Cutting Plane Algorithm for the Linear 
Ordering Problem», Research Report  N°82219 Operations Research, Universität zu 
Bonn, Germany,    
Green P., Rao V.R.(1969) : «Note on proximity Measures and Cluster Analysis» , Journal of 
Marketing Research» , Vol6, pp.359-364,  
Guttmann L. (1941): « The Quantification of a Class of Attributes , A theory and Method of 
Scales Construction», Horst P. Editor, Social Sciences Research Council, New York , 
Hicham A.,Saporta G. (2003) : «Mesures de distance entre modalités de variables qualita-
tives; application à la classification », Revue de Statistique Appliquée, Vol 51, n°2, 
pp. 75-90, 
 Idrissi Amal N. (2000): «Contribution à l'Unification de Critères d'Association pour Va-
riables Qualitatives » , Thèse de l’Université Paris VI, 
Jaccard P. (1908): « Nouvelles Recherches sur la distribution florale » , Bulletin de la Socié-
té Vaudoise des Sciences Naturelles, Vol n°44, pp.223-270,  
Joly S., Le Calvé G.(1986) : « Metric and Euclidean Properties of Dissimilarity Coeffi-
cients », Revue de Statistiques et Analyse des Données n°11, pp :30-50 ) 
RNTI-A-3- 313 -
Essai de Typologie Structurelle des Indices de Similarités  
Joly S., Le Calvé G. (1994) : « Similarity functions », Lecture Notes in Statistics, (In Van 
Cutsem, B. editor),  Springer-Verlag, vol. 93,  pp. 67-86,  
Jeliazkova  N. (2005): « Chemical Similarity », European Chemicals Bureau (ECB) Work-
shop on Chemical Similarity and Threshold of Toxicological Concern (TTC)  Approach-
es ,  Ispra, Italy,  
Jackson, A.A., Somers, K.M. et Harvey, H.H. (1989): « Similarity coefficients: measures for 
co-occurrence and association or simply measures of occurrence? »,  Am. Nat. Journal  
Vol:133: pp.436-453,. 
Janson S. , Vegelius J. (1982): «Correlation Coefficient for more than one Scale Type»,  
Multivariate Behavioral Research Journal, Vol 17, Issue 2, pp.271-284, 
Kulczinski S. (1927) : «Classes des Sciences Mathématiques et Naturelles», Bulletin Interna-
tional de l’Académie Polonaise des Sciences et des Lettres, pp57-203, 
Lerman I.C. (1970):  « Les Bases de la Classification Automatique», Livre chez Gauthier-
Villars, Paris, 
Lerman I.C.  (1981): « Classification et Analyse Ordinale des Données »,  Livre, Dunod, 
Paris,  
Lerman I.C. (1987) : « Construction d'un indice de similarité entre objets décrits par des 
variables d'un type quelconque, application au problème du consensus en classification »  
Revue de Statistique Appliquée, vol. 35, n° 2,  pp :39-60, 
Lelu A. (2002):  «Comparaison de trois mesures de similarités utilisées  en documentation 
automatique et analyse textuelle », Proceedings des 6ème JADT ( 6 èmes Journées 
d’Analyse des Données Textuelles),  
Lesot M.J., Rifqi M. et Benhadda  H. (2009): « Similarity Measures for binary  and numeri-
cal Data » , pp 63-84 in  Journal of Knowledge Engineering and Software Data Para-
digms, Interscience Editor,  
Marcotorchino F. (1989): « Liaison Analyse Factorielle-Analyse Relationnelle (I) : "Dualité 
Burt-Condorcet», Etude du Centre Scientifique IBM France, No F142,  
Marcotorchino F. (1984) : « Présentation des Critères d’Association en Analyse des Données 
Qualitatives », Publication AD0185, Université Libre de Bruxelles, pp :1-57, (1984). 
Marcotorchino F. (1987): « Block seriation problems: A unified approach», Applied stochas-
tic models and Data Analysis  Journal N°3, pp.73–91, 
Marcotorchino F.(1991) : « L'analyse Factorielle-Relationnelle (parties 1 et 2) ». Etude du 
Centre Scientifique IBM France, M06 pp :1à 122, 
Marcotorchino F.,  Benhadda H.(1996) : « Introduction à la Similarité Régularisée », Etude 
MAP011, pp1-78 du Centre Européen de Mathématiques Appliqués, ECAM/IBM,  
Marcotorchino F., El Ayoubi N. (1991): «Paradigme logique des écritures relationnelles de 
quelques critères fondamentaux d'association »  Revue de Statistique Appliquée, Vol 39, 
n°2, pp :25-46 , 
RNTI-A-3 - 314 -
                                                                                                    F. Marcotorchino 
Messatfa H. (1989) : « Unification Relationnelle des Critères et des Structures de Contin-
gences», Thèse de l’Université Paris VI, LSTA,  
Marcotorchino F., Michaud P. (1978) : « Optimisation en analyse ordinale des données ».  
Livre Masson, Paris,   
Marcotorchino F.,  Michaud P. (1981) .: « Agrégation des Similarités en Classification Au-
tomatique », Revue de Statistique Appliquée, Vol 30, n°2 , Paris,  
Michel C. (2000) : «Ordered similarity measures taking into account the rank of docu-
ments », Journal d’ Information Processing and Management, n°37, pp. 603-622 ,  
Maggira G.M., Petke J.D., Mestres J. (2002):  « Similarity Indexes for Chemistry» in  Journal 
of Mathematical Chemistry », Vol 31, N°3,   
 Ochiai  A. (1957): «Zoogeographic studies on the soleoid  fishes found in Japan and  its 
neighbouring »,  Bulletin of the Japanese Society for Scientific Fisheries, N°22, pp.526-
530,  
Parrochia D.  (1992): «Mathématiques & existence :Ordres Fragments, Empiètements »,  
Publication :Seyssel, Champ Vallon , Collection Milieux,  
Quine W. van O. (1998): The Pre-Established Harmony of Subjective Perceptual Similarity” 
in Proceedings of the Twentieth World Congress of Philosophy, Volume 6, (Boston, Au-
gust, 1998) (reprinted in W. V. Quine.:  Confessions of a Confirmed Extensionalist ) in 
Floyd, Juliet and Shieh, Sanford (editors) (2008).  
Rand  W.H. (1971): «Objective Criteria for the Evaluation of Clustering Methods », Journal 
of the American Statistical Association, Vol. 66,  
Rifqi  M., Berger V. , Bouchon- Meunier  B. (2000): « Discrimination Power of Measures of 
Comparison »  , Fuzzy Sets and Systems, vol.110, pp. 189-196, 
Rogers D.J., Tanimoto T.T. (1960): « A computer program for classifying plants », Vol 132, 
pp 1115-1118, Science Journal ,  
Saporta G. (1990): «Probabilités Analyse des Données et Statistique », livre (2ème édition 
augmentée) , Editions Technip (2006), (1ère édition  (1990)) 
Salton G. (1968) : « Automatic Information Organization and Retrieval », book, Mac Graw 
Hill Editor,New York,  
Salton G, Mac Gill  M.J. (1983) : «Introduction to Modern Information Retrieval », Mac 
Graw Hill  Editor, New York)  
Schoenberg I.J. (1938): «Metric Space and Positive Definite Functions », Transactions of the 
American Mathematical Society, n°44, PP:522-536, New York,   
Solomon H., Fortier  J. (1966): «Clustering Procedures »,  Multivariate Analysis, P. Krish-
naiah (Editor), Academic Press, New york, 
Simpson  G.G.(1943) : «American Journal of Science », N°241, pp.1-31, 
Sneath, P.H.A. and Sokal, R.R. (1973). «Numerical Taxonomy: the Principles», Book Mac 
Graw Hill, 
RNTI-A-3- 315 -
Essai de Typologie Structurelle des Indices de Similarités  
Sokal R.R.,  Michener C.D.(1958) : «A Statistical Method for Evaluating Systematic Rela-
tionships », University of Kansas Science Bull., n°38, pp:1409-1438,  
Sokal R.R,. Sneath P.H.A.,  (1963): «Principles of Numeric Taxonomy », livre, Freeman  
Editeur, San Francisco, 
Sørensen T. (1948) « A method of establishing groups of equal amplitude in plant sociology 
based on similarity of species content and its application to analyses of the vegetation on 
Danish commons »,. K. Dan. Vidensk. Selsk. Biol. Skr. Vol n°5: pp.1-34, 
Sparck Jones K. (1971) : «Automatic keyword classification for retrieval », book by  Butter-
worth, London,  
Snijders  T.A. et al. (1990): «Distribution of some similarity coefficients for dyadic binary 
data in the case of associated attributes », Journal of Classification n° 7, , pp. 5-31, 
Springer-Verlag,  
Tversky  A. (1977): « Features of Similarity » Psychological Reviews Vol 84 n°4 pp:327-
352, 
Van Cutsem B. (editor) (1994) : «Classification and Dissimilarity Analysis », book by 
Springer-Verlag , Collection: Lecture Notes in Statistics n°93, New-York, Berlin, 
Van Rijsbergen C.J.(1979): «Information Retrieval», Livre Publié par Butterworth-
Heinemann ,  Newton, Massachussets, USA,  
Warrens M.J. (2008): «On the Indeterminacy of Resemblance Measures for Binary (Pres-
ence/Absence) Data», Journal of Classification, Vol 25, Issue n°1, pp.125-136, Springer 
Verlag, Berlin,  
Warrens M.J. (2009): «Bounds of Resemblance Measures for Binary (Presence-Absence) 
Variables», Journal of Classification, Vol 25, Issue n°2, pp.195-208, Springer Verlag, 
Berlin,  
Yule G.U. , Kendall M.G  (1950).: «An Introduction to the Theory of Statistics », 14th edi-
tion, book by Hafner , New York, (1950). New published  edition  by  Arnold (1976).  
 
 
 
 
 
 
RNTI-A-3 - 316 -
                                                                                                    F. Marcotorchino 
 
 
Nom de l’Indice Emplacement  de définition ou Renvois 
1 Anderberg Simple Défini en  4.1.1.3  
2 Anderberg Complémentaire Défini en  4.1.1.4 
3 Anderberg (4 Ratios) Défini en  4.4.4.4 
4 Baroni-Urbani -Buser Défini  en 4.4.4.7 
5 Borko  (voir  Sokal et Michener) 
6 Braun -Blanquet   Défini en 4.3.2 (voir  Min, voir  Simpson voir Max) 
7 Bravais - Pearson   Défini en 4.4.4.1 (voir Tetrachorique)  
8 Bray et Curtis Défini en 4.5.1.2  (voir Dice, voir Odum ) 
9 Carbo Cité en note de bas de page n°9   (Voir  Ochiai ) 
10 Cohen (Kappa) Défini  en 4.4.5.5 
11 Condorcet (voir  Rand voir Sokal et Michener)  
12 Czekanowski (voir  Dice) 
13 Dice Défini en 4.1.1.1 (voir Czekanowski) 
14 Fonction F  Défini en 4.3.2.3  (voir Van Rijbergen voir Tversky) 
15 Fleiss  Défini en 4.4.4.2.b  
16 Fowlkes-Mallows Défini en 5.1.2 
17 Goodman - Kruskal (Lambda) Défini en 4.4.5.4  (voir Dice)  
18 Goodman - Kruskal (Tau) Défini en 4.4.5.2 (voir  Tetrachorique) 
19 Gower Cité en note de bas de page n°5  
20 Green et Rao  (voir Sokal et Michener voir Hamann) 
21 Hadamard Défini en 4.4.4.2.c 
22 Hamann Défini en note de bas de page n°12  
23 Hodgkin -Richards -Petke Défini en note de bas de page n°9  (voir  Dice) 
24 Hubert-Arabie Défini en 5.1.3 (voir Kulczynski ) 
25 Indice du Max (P,R) Défini en 4.3.2  (voir  Simpson) 
26 Indice du Min (P,R) Défini en 4.3.2 (voir Braun-Blanquet) 
27 Jaccard Défini en 4.1.1.2 
28 Janson -Vegelius Défini en 4.4.5.1 (voir  Hamann, voir Sokal-Michener) 
29 Kulczynski (abondance) Défini en 4.5.2.1 (voir  Dice)  
30 Kulczynski (0-1) Défini en 4.2.1.1 
31 Kulczynski (4 Ratios)  Défini en 4.4.4.4 
32 Lance- Williams (abondance) Défini en 4.5.1.1 (voir  Sokal Michener)  
33 Lerman « Modifié » Défini en 4.4.5.3 
34 Mac Connaughey Défini en 4.3.2.2 (voir  Kulczynski) 
35 Marcotorchino-Michaud (1) Défini en 4.4.3.2 
36 Marcotorchino-Michaud (2) Défini en 4.4.3.3 
37 Marczewski- Steinhaus (abondance) Défini en 4.5.2.2 (voir  Jaccard) 
38 Maxwell-Pilliner  Défini en 4.4.4.2.a   
39 Morey-Agresti Défini en 5.1.1 
40 Ochiai Défini en 4.2.1.2 
41 Ochiai (4 Ratios)  Défini en 4.4.4.5 
42 Odum Défini en 4.5.1.2 (voir  Bray-Curtis) 
43 Précision  (Indice de)   (voir  Rappel, voir  Tversky) 
44 Rand  Défini en 4.4.5.1  (voir Janson et Vegelius) 
45 Rao Défini en 4.4.3.1 
46 Rappel (Indice de)    (voir  Précision, voir Tversky) 
47 Rogers et Tanimoto Défini en 4.4.1.2 
48 Sokal et Michener Défini en 4.4.1.1  (voir Green et Rao) 
49 Sokal et Sneath Défini en 4.4.1.3  
50 Sørensen Défini en 4.1.1.4 
51 Sorgenfrei Cité en note de bas de page n°8  
52 Tetrachorique  (Coefficient)  Défini en 4.4.4.1 (voir  Bravais Pearson)   
53 Tversky Défini en 4.1.3  
54 Van Rijsbergen  Cité  en note de bas de page n°11
55 Yule Q et Y  Définis en 4.4.4.3 
RNTI-A-3- 317 -
Essai de Typologie Structurelle des Indices de Similarités  
 
 
RNTI-A-3 - 318 -
