 © Revue MODULAD, 2005 - 1 - Numéro 32 
UNE INTRODUCTION AU POSITIONNEMENT MULTIDIMENSIONNEL 
 
Dominique Desbois 
INRA-SAE2 Nancy et SCEES - 251, rue de Vaugirard, 75732 Paris Cedex 15. 
Courriel :dominique.desbois@agriculture.gouv.fr  Fax : +33 1 49 55 85 00 
 
Résumé : 
Le positionnement multidimensionnel, est une méthode de représentation graphique d’un 
ensemble de similarités ou de dissimilarités mais aussi une procédure de construction d’échelles 
communes à un ensemble d’attributs subjectifs. Cette note a pour but d'aider les utilisateurs dans la 
mise en oeuvre du positionnement multidimensionnel au moyen des procédures SPSS 
PROXIMITIES et ALSCAL. Cette mise en oeuvre concerne l'analyse des tableaux de dissimilarité 
construits à partir de tableaux multidimensionnels de données individuelles. Le listage des résultats 
obtenus à partir d’exemples vient illustrer l’exposé théorique consacré aux méthodes. 
 
Abstract : 
Multidimensional positioning is a graphical method used to chart a set of similarities or 
dissimilarities but also a procedure used to build common scales from a set of subjective attributes. 
The aim of this note is to help the users in the implementation of multidimensional scaling by means 
of SPSS procedures, PROXIMITIES and ALSCAL. This implementation relates to the analysis of the 
dissimilarity tables built starting from multidimensional tables of individual data. Starting from 
examples, the listing of outputs obtained comes to illustrate the theoretical part devoted to the 
methods. 
 
Mots clés : 
Positionnement multidimensionnel, analyse des proximités, tableaux de dissimilarités, analyse 
factorielle sur tableaux de distance , logiciel statistique SPSS. 
 
1. L’analyse des préférences pour l’étude de la rationalité des choix 
 
Sur quels critères choisit-on un aliment : sa couleur, sa texture, son odeur, son prix ? Quels sont les 
éléments déterminant le choix des électeurs : l’appartenance politique du candidat, les positions 
exprimées, son charisme individuel ? Quelles caractéristiques interpersonnelles rentrent en jeu dans 
le comportement de sélection mutuelle aboutissant à la constitution de groupes d’individus au sein 
d’un collectif ? En d’autres termes, peut-on expliquer ces comportements individuels d’achat, de 
vote, d’adhésion à un groupe en identifiant les déterminants des choix effectués afin d’en expliciter 
la rationalité  ? 
L’analyse des préférences exprimées par un groupe de sujets relativement à un ensemble d’objets a 
pour objectif de mettre en évidence les caractéristiques des objets corrélées avec le choix des sujets 
en réponse au stimulus que constitue la situation d’achat, de vote ou d’adhésion. Comment faire 
pour révéler la structure qui se cache derrière les disparités de comportement observées dans 
l’expression de ces préférences ? 
En analyse des données, il existe deux façons de répondre à ces questions. La première est la voie 
proposée par l’ensemble des techniques factorielles qui cherchent à construire des échelles 
objectives correspondant aux choix implicites des individus en analysant directement les tableaux 
multidimensionnels de données individuelles par des méthodes telles que l’analyse en composantes 
principales ou l’analyse des correspondances. 
La seconde est d’analyser les proximités entre individus, ressemblances ou dissemblances résultant 
de l’observation des comportements, qu’elles soient relevées directement à l’issue de 
l’expérimentation ou qu’elles soient calculées sur la base des tableaux multidimensionnels de 
données individuelles au moyen d’indices de similarité (plus le nombre est grand plus les objets 
sont semblables) ou de dissimilarité (plus le nombre est grand plus les objets sont dissemblables).  
 © Revue MODULAD, 2005 - 2 - Numéro 32 
D’un usage moins répandu que l’analyse factorielle chez les statisticiens francophones, le 
positionnement multidimensionnel constitue pourtant l’une des techniques fondamentales utilisées 
en analyse des préférences sur l’ensemble des domaines d’application de la psychométrie, en 
particulier dans la conception et le marketing des produits agro-alimentaires. 
À partir de la matrice des similarités ou dissimilarités interindividuelles ainsi obtenue, le 
positionnement multidimensionnel permet d’obtenir une représentation géométrique s’ajustant au 
mieux selon un critère donné à l’ensemble des proximités observées et d’en proposer une 
interprétation révélée par la structure du nuage des points représentant les stimuli projetés dans un 
espace euclidien. Si l’ajustement de cette représentation euclidienne aux dissimilarités observées se 
fait d’après une procédure qui respecte les écarts entre dissimilarités, on parle de modèle métrique. 
Si le mode d’ajustement respecte simplement l’ordre entre les dissimilarités, on parle alors de 
modèle non métrique. 
 
Figure 1 : géométrie euclidienne en dimension 2. 
 
 
 
Figure2 : une vérification graphique du théorème de Pythagore. 
 
x11 x21
⎥⎦
⎤⎢⎣
⎡=⎥⎦
⎤⎢⎣
⎡=
2
5
,
5
1
21 xx
X1
X2
D2
D1
a2
b2
h2 222 bah +=
( ) ( ) ( ) 252515, 22212 =−+−=xxd
x12
x22
( ) ( ) ( )22212221112, xxxxd −+−=xx1
 © Revue MODULAD, 2005 - 3 - Numéro 32 
Classiquement, similarités ou dissimilarités sont obtenues en demandant directement aux sujets 
d’estimer ou de classer ressemblances ou dissemblances entre paires d’objets. En marketing, on 
peut vouloir analyser simultanément les préférences d’un panel de consommateurs pour un 
ensemble déterminé de produits. Les produits agro-alimentaires sont alors considérés en tant 
qu’objets ou stimuli de l’expérimentation, et les panélistes sont les sujets ou experts participants à 
l’expérimentation (pour un exemple dans le domaine oenologique, cf. [Pagès 2003]). De même dans 
le domaine financier ou politique, on peut vouloir synthétiser les jugements émis par différents 
experts sur les risques présentés un ensemble d’opérateurs financiers ou de pays : il y aura ainsi 
plusieurs matrices de similarités ou de dissimilarités à examiner. 
Les similarités ou dissimilarités peuvent également être issues de mesures objectives telles que la 
distance à vol d’oiseau entre deux villes ou de dénombrements factuels effectués selon une 
nomenclature ou une typologie fixée a priori au sein d’une population donnée ou d’un groupe 
d’espèces pour certaines unités spatiales ou territoriales. Enfin, on peut calculer similarités ou 
dissimilarités au sein de la population étudiée sur la base d’indices statistiques basés sur des 
données multivariées issues de mesures, d’enquêtes ou de recensements. Par exemple, les disparités 
entre régions ou pays d’Europe peuvent être calculées chaque année pour un tableau de bord donné 
(batterie fixe d’indicateurs statistiques). Les pays ou régions figurent alors en tant qu’objets ou 
stimuli dont les proximités ou disparités peuvent alors être représentées par une image euclidienne 
bi ou tridimensionnelle, susceptible de varier au cours du temps. Dans un tel contexte d’application, 
les années d’observation peuvent également tenir lieu d’individus ou de sujets. 
Comme pour bien d’autres méthodes exploratoires, la nature des données conduit à privilégier 
l’utilisation de certaines variantes parmi l’ensemble des modèles de positionnement 
multidimensionnel disponibles. De ce point de vue, on distingue essentiellement trois types 
d’échelles de mesure : ordinal, intervalle ou ratio, les exemples de dissimilarités basées sur des 
données nominales étant rarement traités dans le cadre méthodologique du positionnement 
multidimensionnel. Ces trois niveaux de mesure définissent en fait deux types de dissimilarités et 
d’analyse. Le niveau ordinal conduit à des dissimilarités qualitatives et des analyses non métriques. 
Les échelles à intervalle ou de ratio aboutissent à des dissimilarités quantitatives et à des analyses 
métriques ou non métriques. 
Le format des données doit également être pris en compte dans la spécification de la procédure de 
traitement des données. Les données peuvent être de format symétrique ou asymétrique pour des 
matrices de similarités ou de dissimilarités (lignes et colonnes de la matrice se réfère au même 
ensemble I d’objets), ou bien de format rectangulaire (les dissimilarités sont définies pour les objets 
de l’ensemble I des lignes relativement aux critères de l’ensemble J des colonnes). 
 
 
Portrait de Pythagore de Samos, « Images of Mathematicians on Postage Stamps » Jeff Miller 
(Webring « Mathematics on Stamps »). 
 
 © Revue MODULAD, 2005 - 4 - Numéro 32 
2. Introduction aux concepts du positionnement multidimensionnel 
 
Les techniques de positionnement multidimensionnel trouvent leur origine dans les études 
psychométriques [Richardson, 1938] visant à comprendre comment les individus tissent des 
associations entre objets pour effectuer des regroupements, des classifications. Cependant, des 
études antérieures en biologie comparée, classant les espèces sur la base des réactions sériques 
interspécifiques [Boyden, 1933], utilisent sans la nommer une construction géométrique 
s’apparentant au positionnement multidimensionnel. Depuis lors, le positionnement 
multidimensionnel est devenu une technique de représentation géométrique largement utilisée dans 
des domaines aussi divers que le marketing, la sociologie électorale, ou plus récemment l’analyse 
sensorielle. 
L’idée fondamentale du positionnement multidimensionnel est de représenter chaque objet ou 
stimulus dans un espace euclidien, habituellement bi ou tridimensionnel, de telle sorte que deux 
objets semblables soient représentés par deux points proches l’un de l’autre, et un couple 
dissemblable par des points éloignés. 
Le problème mathématique fondamental que pose la réalisation concrète de cette idée est de trouver 
une représentation euclidienne d’un ensemble de points à partir de leurs distances respectives. Ce 
problème a été résolu en 1938 par Young et Householder au moyen d’une méthode très proche de 
l’analyse factorielle, faisant appel à la décomposition spectrale d’une matrice symétrique (cf. infra 
partie 4, encadré). 
Le choix du mode d’ajustement des proximités observées ( )iiii ′=′ ,δδ  aux distances issues de la 
représentation euclidienne ( )iidd ii ′=′′ ,  par les disparités iid ′ˆ , définies par la relation f  telle que 
( ) iiii df ′′ = ˆδ  appelée fonction de représentation, constitue une des spécifications essentielles du 
modèle de positionnement multidimensionnel. 
Si cette relation f , est une fonction linéaire, soit : 
• ( ) iiii bf ′′ = δδ  le modèle sans constante proposé initialement par Richardson en 1938 ; ce 
modèle est adapté aux échelles de mesure de type ratio ; 
• ( ) iiii baf ′′ += δδ  le modèle avec constante proposé par Torgerson en 1952 ; ce modèle 
est adapté aux échelles de mesure de type intervalle ; 
alors le modèle de positionnement multidimensionnel est qualifié de métrique. 
Sinon, on peut simplement imposer que la relation f  soit une transformation monotone (croissante 
ou décroissante) afin de respecter les proximités de classement des similarités ou des dissimilarités. 
En outre, on peut préciser de façon plus ou moins restrictive le caractère monotone (monotonicité) 
de la relation, soit respectivement : 
• ( ) ( ) jjjjiiiijjii dffd ′′′′′′ ==⇒ ˆˆ δδδδ pp  (monotonicité forte) ; 
• ( ) ( ) jjjjiiiijjii dffd ′′′′′′ =≤=⇒ ˆˆ δδδδ p  (monotonicité faible) ; 
(les symboles p  et ≤  désignent ici une relation d’ordre stricte, respectivement large). 
Dans ce cas, le positionnement multidimensionnel est qualifié de non-métrique. Le positionnement 
multidimensionnel est également non-métrique si la représentation fournie ne précise que le rang et 
non la position des stimuli pour chaque dimension. 
Des spécifications complémentaires peuvent être introduites afin de pouvoir représenter une 
configuration euclidienne qui soit un compromis entre les jugements individuels exprimés par 
différents experts, par exemple, en termes de dissimilarités : le modèle appelé INDSCAL (pour 
Individual Differences Scaling) introduit des pondérations distinctes selon les individus sujets de 
l’expérience sur chacune des dimensions de l’espace euclidien. 
En fonction du nombre de matrices de dissimilarités, du niveau de mesure des données et du type de 
représentation choisi, on est amené à choisir un modèle spécifique parmi un ensemble de techniques 
de représentation géométrique regroupées sous l’appellation générique de positionnement 
multidimensionnel. La terminologie utilisée permet de distinguer parmi ces techniques quatre 
 © Revue MODULAD, 2005 - 5 - Numéro 32 
grandes familles de modèles selon le choix de l’espace de représentation et le nombre de matrices 
de dissimilarités à représenter : 
• le modèle de positionnement multidimensionnel classique (PMC) utilisant un espace 
euclidien pour représenter une matrice unique de dissimilarités ; 
• le modèle de positionnement multidimensionnel répété (PMR) proposant une 
représentation unique de plusieurs matrices de dissimilarités dans un espace euclidien ; 
• le modèle de positionnement multidimensionnel pondéré (PMP), popularisé sous le label 
INDSCAL, utilisant des poids pour représenter des matrices de dissimilarités distinctes 
dans un espace euclidien ; 
• le modèle de positionnement multidimensionnel généralisé (PMG) visant également à 
représenter plusieurs matrices de dissimilarités dans un espace euclidien. 
Certaines distinctions sont également introduites par la terminologie suivant la nature des 
dissimilarités à représenter : si les dissimilarités sont exprimées selon une échelle ordinale (rangs ou 
classements), les modèles de positionnement multidimensionnels utilisés sont qualifiés de non-
métriques ; s’il s’agit d’une échelle de mesure (intervalles, ratios), alors les modèles de 
positionnement multidimensionnel sont qualifiés de métriques. 
La procédure PROXIMITIES de SPSS permet de calculer les écarts ou les proximités entre 
individus sur la base d’indices de similarité ou de dissimilarité. La procédure ALSCAL de SPSS 
permet de construire des structures géométriques multidimensionnelles, le plus souvent bi ou 
tridimensionnelles, s’ajustant au mieux aux similarités ou dissimilarités observées ou calculées. 
L’algorithme de positionnement multidimensionnel utilisé par ALSCAL est directement issu des 
travaux de Forrest W. Young, professeur émérite de psychométrie à l’Université de Caroline du 
Nord à Chappel Hill [Young, Takane et Lewyckyj, 1978]. 
 
Portrait de Forrest W. Young  
par Patricia M. Young 
 © Revue MODULAD, 2005 - 6 - Numéro 32 
3. Un exemple démonstratif : la topographie des parcours routiers 
 
L’objectif du positionnement multidimensionnel est de construire une représentation d’un ensemble 
I d’objets  telle que les positions relatives de ces objets représentés traduisent les dissemblances ou 
ressemblances existant entre ces objets en termes d’éloignement ou respectivement de proximité. 
Ce problème de représentation est très proche de celui auquel est confronté l’arpenteur qui doit 
déduire une carte topographique des différents relevés de distance effectués entre des lieux distincts. 
Les cartes routières où figure souvent en annexe une table des distances à parcourir entre les 
différentes villes de la région décrite peuvent constituer un premier exemple susceptible d’éclairer 
cette analogie. En utilisant une carte routière de la France, on peut établir le relevé des distances 
kilométriques à parcourir pour joindre par la route les principales métropoles régionales 
(cf. tableau 1). Les villes figurent les objets et les relevés kilométriques mesurent les dissimilarités 
entre objets. 
La distance par la route pour aller d’Angers (ligne v02) à Amiens (colonne V01) est de 
399 kilomètres (contenu de la case [ 2 , 1 ]). Cette distance est la même que pour aller d’Amiens 
(ligne v01) à Angers (colonne V02), soit 399 km (case [ 1 , 2 ]). Cette observation résulte de la 
propriété de symétrie de l’indice de dissimilarité d utilisé : ( ) ),(, iidiid ′=′          [1] 
 i figurant l’index des lignes et i’ celui des colonnes. Elle se traduit par la symétrie lignes/colonnes 
constatée dans ce tableau : le contenu de chaque case [ i, i’ ] est égal au contenu de la case 
symétrique [ i’, i ]. Cette propriété caractérise également les indices de similarité entre objets ( ) ),(, iisiis ′=′          [1’] 
En outre, on constate que les distances routières entre villes figurant dans ce tableau sont des 
nombres strictement positifs à l’exception des cases[ i, i ] de la diagonale dont le contenu est nul 
(case [ 2 , 2 ], la distance d’Angers à Angers est égale à 0). Cela traduit la propriété 
d’identifiabilité de l’indice de dissimilarité s: ( ) iiiid ′=⇔=′ 0,         [2] 
Les indices de similarités partagent une propriété similaire : 
 ( ) iiMaxiis ′=⇔=′,         [2’] 
la borne maximum Max pouvant être égale par exemple à 1 ou bien à l’infini selon la définition de 
l’indice retenu. 
Une dernière constatation moins élémentaire peut être faite en examinant le tableau plus 
soigneusement : la distance kilométrique du trajet direct Angers-Paris est inférieure à n’importe 
laquelle des distances parcourues sur un itinéraire indirect passant par une ville-tiers. Prenons le 
trajet indirect Angers-Tours-Paris comme exemple : Angers-Tours – 106 km, plus Tours-Paris – 
234 km, soit 340 km distance supérieure à celle parcourue lors d’un trajet direct Angers-Paris, 303 
km). Ceci reste vrai quel que soit le couple de villes à relier. Cette observation empirique « la ligne 
droite est le plus court chemin pour aller d’un point à un autre » traduit une propriété géométrique 
caractéristique des espaces métriques, dénommée l’inégalité triangulaire : ( ) ( ) ( ) Iiiiiidiidiid ∈′′′∀′′′+′′≤′ ,,,,,       [3] 
 
   
 
 
 
   
Muni de ces trois propriétés, l’indice de dissimilarité d constitue alors une instance d’une 
classe particulière de fonctions du produit cartésien II ×  (l’ensemble des couples 
( ) Iiiii ∈′′ ,, ), à valeurs dans l’ensemble des réels positifs +ℜ que l’on appelle une distance 
(entre les objets i) ou encore une métrique (de leurs écarts). Les ensembles d’objets I muni 
d’une métrique sont appelés espaces métriques. 
Si les objets sont représentés par des vecteurs d’observations, alors ces espaces vectoriels 
peuvent être munis d’une géométrie où les notions usuelles d’angle et d’orthogonalité se 
transcrivent en termes de produit scalaire. Si les observations sont des nombres réels, on 
peut construire une représentation cartésienne des objets dont les coordonnées sont définies 
par rapport à un repère orthonormé, c’est à dire relativement à une origine O et à des axes 
orthogonaux dont la direction et la métrique des écarts sont définies par des vecteurs 
unitaires (i.e. de longueur ou norme 1). 
Dans ces espaces vectoriels, les distances euclidiennes, sont définies comme la racine carrée 
de la somme des carrés des écarts, terme à terme, entre coordonnées cartésiennes. Cette 
définition généralise à un espace multidimensionnel (i.e. à plusieurs variables - pℜ ) le calcul 
élémentaire effectué dans le plan ( 2ℜ ) de la longueur de l’hypoténuse du triangle rectangle 
(cf. figure 1). Ainsi, les distances euclidiennes définissent des géométries vectorielles qui sont 
invariantes par translation, rotation ou déplacement (composée d’une translation et d’une 
rotation) et qui coïncident avec notre perception de l’espace à 3 dimensions. Un espace muni 
d’une distance euclidienne est appelé un espace euclidien. 
A titre illustratif, on peut utiliser le principe du positionnement multidimensionnel pour 
obtenir une représentation euclidienne des parcours routiers entre les principales 
agglomérations françaises (cf . figure 3) où les villes se positionnent en fonction de leurs 
éloignements respectifs. 
 
N 
S 
E 
O 
Figure 3 : topographie des parcours routiers entre les principales villes françaises. 
 © Revue MODULAD, 2005 - 9 - Numéro 32 
Le premier axe (« Dimension 1 ») de la représentation est toujours celui correspondant aux 
écarts observés les plus importants en termes de disparités. Le second axe (« Dimension 2 ») 
est orienté selon une direction orthogonale au premier, correspondant aux écarts les plus 
importants parmi ceux qui ne relèvent pas du premier axe. Et ainsi de suite, l’ensemble des 
axes s’ordonne selon l’application de cette règle d’extraction. 
Une rotation appropriée de ce système d’axes orthogonaux nous conduit à interpréter la 
première dimension comme un axe Nord-Sud et la seconde dimension comme un axe Est-
Ouest. La topographie obtenue diffère sensiblement de la représentation cartographique qui 
nous est familière : les déformations sont principalement imputables au fait que le réseau 
routier dans certaines régions impose des trajets où la distance parcourue en automobile est 
notablement supérieure à la distance géographique (« à vol d’oiseau »). 
Une telle représentation est obtenue par l’intermédiaire d’un algorithme itératif permettant de 
minimiser l’écart entre les distances qui se déduisent de la représentation euclidienne 
recherchée et les disparités iid ′ˆ , définies comme des fonctions des dissimilarités observées :
 ( )iiii fd ′′ = δˆ , fonctions convenablement choisies pour respecter soit les écarts soit 
l’ordre entre les dissimilarités observées. 
En effet, l’analyse des proximités mis au point par Shepard en 1962 a montré qu’il est 
possible d’obtenir des représentations métriques ajustées à partir de relations ordinales entre 
distances et proximités. Cette méthode est généralisée par Kruskal qui propose en 1964 une 
approche en termes d’optimisation construite autour de la définition d’un critère d’ajustement. 
Définition de la fonction objectif 
Afin de pouvoir conduire l’estimation selon une procédure d’optimisation, Kruskal propose 
de définir la fonction objectif qui constitue le critère d’ajustement à minimiser. Il s’agit d’une 
procédure des moindres carrés où l’on cherche à minimiser la somme des carrés des écarts 
entre les distances issues de la représentation euclidienne et les disparités, fonction des 
proximités observées : [ ]( )∑∑
= =′
′′ −
n
i
n
i
iiii fd
1 1
2δ   
Pour assurer la comparabilité entre des ensembles de stimuli distincts, ces écarts peuvent être 
ramenés à un facteur d’échelle commun : ∑∑
= =′
′
n
i
n
i
iid
1 1
2 , ce qui conduit au ratio suivant :
 
[ ]( )
∑∑
∑∑
= =′
′
= =′
′′ −
n
i
n
i
ii
n
i
n
i
iiii
d
fd
1 1
2
1 1
2δ
 et en termes d’optimisation à une première définition du critère 
d’ajustement de la fonction de représentation f appelé le f-stress : 
  
[ ]( )
∑∑
∑∑
= =′
′
= =′
′′ −
=− n
i
n
i
ii
n
i
n
i
iiii
d
fd
stressf
1 1
2
1 1
2δ
 
De par sa définition, le stress d’une fonction de représentation est positif ou nul. Plus le f-
stress est élevé, moins la configuration spatiale X, définie par la matrice X  des coordonnées 
des points de la solution étudiée, est adaptée à l’ensemble ∆  des proximités observées. 
Si le f-stress est nul, la configuration spatiale X s’adapte parfaitement à l’ensemble ∆  des 
disparités, c’est à dire :  ( ) ( ) IIiifd iiii ×∈′∀= ′′ ,δ  
 © Revue MODULAD, 2005 - 10 - Numéro 32 
Le stress d’une configuration spatiale X, pour un l’ensemble ∆  de disparités est définie par 
l’optimun du critère d’ajustement pour l’ensemble des fonctions de représentation 
considérées :  ( ) ( ){ }fstressfXstress
f
,,, min X∆−=∆ . 
La fonction objectif ainsi définie est appelée le stress de type I. Le stress est un indicateur 
normalisé variant entre 0 et 1, la valeur nulle indiquant un ajustement parfait. 
 
Ainsi que le montre l’historique des itérations de l’algorithme du positionnement 
multidimensionnel pour la topographie des parcours routiers, la convergence est atteinte au 
bout de quatre itérations fixant la valeur finale du stress de la configuration à 0,06, valeur 
faible indiquant un très bon ajustement ; 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Tableau 2 : itérations de l’algorithme d’optimisation et valeurs du stress de type I pour la 
topographie des parcours routiers. 
 
La qualité de cet ajustement peut être précisée grâce à un indicateur calculé pour la 
configuration finale, le 2R , coefficient de corrélation au carré (« squared correlation 
(RSQ) ») entre les distances et les disparités. Ce coefficient s’interprète en termes de 
pourcentage de variabilité expliquée. Dans cet exemple, 98 % de la variabilité des distances 
issues de la configuration euclidienne est expliquée par les disparités, qui en raison du modèle 
choisi (modèle euclidien respectant les écarts), sont des fonctions linéaires affines des 
dissimilarités observées, soit : ( ) iiii abf ′′ += δδ . 
Iteration history for the 2 dimensional solution (in squared distances)
 
                  Young's S-stress formula 1 is used. 
                Iteration     S-stress      Improvement 
                    1           ,11701 
                    2           ,08476         ,03225 
                    3           ,08211         ,00265 
                    4           ,08191         ,00020 
 
                         Iterations stopped because 
                 S-stress improvement is less than   ,001000 
 
            Stress and squared correlation (RSQ) in distances 
 
RSQ values are the proportion of variance of the scaled data (disparities)
           in the partition (row, matrix, or entire data) which 
            is accounted for by their corresponding distances. 
             Stress values are Kruskal's stress formula 1. 
 
                For  matrix 
    Stress  =   ,06013      RSQ =  ,98008 
_ 
 © Revue MODULAD, 2005 - 11 - Numéro 32 
Le diagramme de Shepard constitue pour sa part un outil graphique de vérification de la 
qualité de cet ajustement en permettant de visualiser la relation entre distances et disparités 
sous la forme d’un diagramme bi-dimensionnel : 
 
Figure 4 : le diagramme de Shepard permettant de visualiser la relation entre distances et disparités. 
 
Le diagramme de Shepard de la figure 4 montre que la nature de la relation entre distances et 
disparités est linéaire et croissante. 
 
 
Ile de Samos, patrie de Pythagore, « Images of Mathematicians on Postage Stamps » Jeff Miller 
(Webring « Mathematics on Stamps »). 
Topographie des parcours routiers entre villes françaises
Diagramme de Shepard : distance euclidienne
Proximités
543210
D
is
ta
nc
es
5
4
3
2
1
0
 © Revue MODULAD, 2005 - 12 - Numéro 32 
4.  Le modèle classique, analyse factorielle sur tableau de distances 
 
Cette présentation théorique du modèle classique n’est pas indispensable à la compréhension 
globale de l’exposé en première lecture pour un lecteur principalement intéressé par les 
applications de la méthode. La structure et les notations de la section sont reprises de 
l’ouvrage [Cox et Cox , 2001] 
Le modèle classique du positionnement multidimensionnel (« classical multidimensional 
scaling ») a été initialement développé par Torgerson en 1952 comme outil d’analyse des 
résultats d’expérimentation à caractère psychométrique (cf. par exemple, l’étude en 1957 de 
Rothkopf sur la confusion des signaux Morse), appliquant la méthode de Young et 
Householder (1938) fondée sur la décomposition spectrale d’une matrice symétrique à termes 
réels pour trouver une représentation euclidienne d’un ensemble de points à partir de leurs 
distances respectives. Le modèle classique du positionnement multidimensionnel est présenté 
par [Cailliez et Pages 1976] sous le terme francophone d’analyse factorielle sur tableau de 
distances (AFTD) 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
4.1. Représentation euclidienne d’un tableau de distances 
Soit un ensemble de n objets à représenter dans un espace euclidien de dimension p. Chaque 
objet i est représenté par un point construit à partir du vecteur de coordonnées 
[ ]tipiji
ip
ij
i
i xxx
x
x
x
,,,,1
1
LL
M
M
=
⎥⎥
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎢⎢
⎣
⎡
=x  avec [ ] iii xxxx ×==
⎥⎥
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎢⎢
⎣
⎡
×= ′
=
′′ ∑ tp
j
jiij
ip
ij
i
ipijii xx
x
x
x
xxx
1
1
1 ,,,,
M
M
LL  
définissant le produit scalaire entre les deux vecteurs ix  et i′x . 
Décomposition spectrale d’une matrice symétrique. 
Soit A , une matrice carrée ( )nn× , symétrique à termes réels ( ℜ∈′iia ). 
Cette matrice est diagonalisable. 
Désignons l’ensemble des valeurs propres par { }nii ,,1; L=λ  dont les vecteurs propres 
associées { }nii ,,1; L=v  sont orthonormés ( iiiti ′≠∀=× ′ 0vv  et iiti ∀=× 1vv ). 
Alors, la matrice A  peut s’écrire sous la forme : ( )∑
=
⊗•==
n
i
t
iii
t
1
vvVΛVA λ  
 avec  ( )ni
n
i λλλ
λ
λ
λ
,,,,
00
00
00
00
1
1
LL
LL
OOM
MOOM
MOO
LL
diagΛ =
⎥⎥
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎢⎢
⎣
⎡
=  ; 
 [ ]ni vvvV LL1=  tel que nntt ×== IVVVV  (matrice orthonormale) ; 
et ⊗  symbolisant le produit de Kronecker de deux matrices. 
 © Revue MODULAD, 2005 - 13 - Numéro 32 
La distance euclidienne entre deux points i et i’ est donnée par la norme de la somme des 
carrés des écarts : 
( ) ( ) ( ) ( ) 2
1
22 , iiiiii xxxxxx ′′
=
′′ −=−×−=−=′ ∑
tp
j
jiij xxiid   [4] 
Soit la matrice B  des produits scalaires définie par i'
t
iiib xx ×=′ , la procédure de 
positionnement multidimensionnel simple consiste à calculer B  à partir du carré des distances 
observées puis à extraire de la matrice B  les coordonnées ix  du point i, solutions du 
problème posé. 
4.2. Calcul de la matrice des produits scalaires 
La solution étant déterminée à une translation près, on choisit de situer l’origine du repère 
euclidien au barycentre du nuage des points. Dans ce repère affine, les coordonnées des points 
sont centrées : 0
1
=∑
=
n
i
ijx . 
Le produit scalaire étant une forme bilinéaire symétrique, en développant l’équation [4], on 
trouve : ( ) itiitiitiiid ′′′ ×−×+×=′ xxxxxx 2,2  [5] 
(en définissant le produit scalaire dans le plan 2ℜ  avec le cosinus de l’angle entre deux 
vecteurs, soit : θcosvuvu =× , on retrouve le calcul de la longueur d’un côté du triangle à 
partir de celles des deux autres côtés et du cosinus de l’angle opposé). 
En sommant respectivement sur chacun des indices i et i’ et en utilisant le fait que les 
coordonnées sont centrées ( ∑∑
=′
′
=
′ =×=×
n
i
i
t
i
n
i
i
t
i
11
0xxxx ), on obtient : 
• ( ) ( )itin
i
i
t
i
n
i
niid ′′
==
×+×=′ ∑∑ xxxx
11
2 ,  d’où ( ) ∑∑
==
′′′′ ×−=×
n
i
i
t
i
n
i
i
t
i n
iid
n 11
2 1',1 xxxx  [6] 
• ( ) ( )itin
i
i
t
i
n
i
niid xxxx ×+×=′ ∑∑
=′
′′
=′ 11
2 ,  d’où ( ) ∑∑
=′
′′
=′
×−=×
n
i
i
t
i
n
i
i
t
i n
iid
n 11
2 1',1 xxxx  [6’] 
En sommant [6’] sur l’indice i, on obtient : 
• ( ) ∑∑ ∑∑∑
==′ =
′′
= =′
×=×+×=′
n
i
i
t
i
n
i
n
i
i
t
ii
t
i
n
i
n
i
nnniid
11 11 1
2 2, xxxxxx  [7] 
Pour chaque élément i'
t
iiib xx ×=′ de la matrice des produits scalaires, on obtient en 
substituant d’après [6] et [6’] : 
( )[ ] ( ) ( ) ( ) ⎥⎦⎤⎢⎣⎡ ×+′−′−′−=×−×−′−= ∑ ∑∑ = ==′′′′
n
i
n
i
i
t
i
n
i
i
t
ii
t
iii n
iid
n
iid
n
iidiidb
1 1
2
1
222 2,1,1,
2
1,
2
1 xxxxxx
et d’après [7] : 
( ) ( ) ( ) ( )⎥⎦
⎤⎢⎣
⎡ ′+′−′−′−= ∑ ∑∑∑
= = =′=′
′
n
i
n
i
n
i
n
i
ii iidn
iid
n
iid
n
iidb
1 1 1
2
2
2
1
22 ,1,1,1,
2
1
 
 © Revue MODULAD, 2005 - 14 - Numéro 32 
En posant : 
( )iida ii ′−=′ ,2
1 2  ∑
=′
′=
n
i
iii an
a
1
,..
1   ∑
=
′′ =
n
i
iii an
a
1
,.
1  ∑∑
= =′
′=
n
i
n
i
iian
a
1 1
,2..
1  
il est possible d’exprimer la matrice B  des produits scalaires en fonction de la matrice A , 
définie par [ ] ( )iida iiii ′−== ′′ ,2
1 2
,,A , sous la forme du produit matriciel suivant : 
  HAHB =   [8] 
où H  est l’opérateur de centrage défini par t
n
11IH ⊗−= 1 , 
1  étant le vecteur constant 
⎥⎥
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎢⎢
⎣
⎡
=
1
1
1
M
M
1 de dimension n,  
et t11⊗ , la matrice carrée de dimension (nxn) 
⎥⎥
⎥⎥
⎥⎥
⎦
⎤
⎢⎢
⎢⎢
⎢⎢
⎣
⎡
=⊗
111
111
111
LL
MOM
MOM
LL
t11 . 
La matrice B  des produits scalaires s’obtient donc, à un facteur 
2
1−  près, à partir de la 
matrice des distances au moyen d’une double opération de centrage, effectuée d’une part sur 
les lignes et d’autre part sur les colonnes de cette matrice, qui consiste à enlever la moyenne 
des lignes et la moyenne des colonnes, puis à rajouter la moyenne générale du tableau. 
 
4.3. Extraction des coordonnées 
La matrice B  des produits scalaires, s’exprime dans le repère cartésien barycentrique comme 
le produit matriciel du tableau (nxp) des coordonnées centrées X  par son transposé tX  : 
 tXXB =  
La matrice B  est symétrique, semi-définie positive et de rang p : ( )XXXB rrrp t === )()(  
Elle possède donc p valeurs propres jλ  non nulles et pn −  valeurs propres nulles et peut être 
exprimée dans les termes de sa décomposition spectrale : 
  tVΛVB =  
où Λ  est la forme diagonale de la matrice dans la base des vecteurs propres, avec : 
 ( )pj λλλ ,,,,1 LLdiagΛ =  et [ ]pj vvvV LL1= , la matrice de passage dont 
les colonnes sont les vecteurs propres associés. 
Par identification, on en déduit la matrice X  des coordonnées centrées : 
 2
1
ΛVX =  
avec ( )pj λλλ ,,,,121 LLdiagΛ =  
 
 © Revue MODULAD, 2005 - 15 - Numéro 32 
4.4. Représentation euclidienne d’un tableau de dissimilarités 
En pratique, l’utilisation du positionnement multidimensionnel s’effectue plus souvent à partir 
d’un tableau de dissimilarités [ ] IIii ×′δ  qu’à partir d’un tableau de distances [ ] IIiid ×′ . 
Si la matrice B  des produits scalaires, formée à partir de la matrice A , définie par 
[ ] ( )iia iiii ′−== ′′ ,2
1 2
,, δA , est définie positive de rang p, alors on peut trouver une 
représentation euclidienne correspondante dans un espace de dimension p, et la distance ( )iid ′, , entre les points i et i’ dans cet espace euclidien, est égale à la dissimilarité ( )ii ′,δ . 
La réciproque est également vraie : une matrice B  de produits scalaires formée à partir de 
distances euclidiennes dans un espace de dimension p est semi-définie positive. 
Etant donnée une matrice B  semi-définie positive, formée à partir d’un tableau de 
dissimilarités entre les n éléments d’un ensemble d’objets, il existe une représentation 
euclidienne de dimension 1−n  telle que les distances entre les points soient égales aux 
dissimilarités entre objets 
Si la matrice B  n’est pas semi-définie positive, la plus simple des solutions envisageables est 
de se limiter au valeurs propres positives. Un autre type de solution, utilisé dans 
l’implantation de l’algorithme ALSCAL réalisée par SPSS, est d’ajouter une constante à 
l’ensemble des éléments du tableau des dissimilarités ( )ii ′,δ , à l’exception des termes 
diagonaux, pour former un nouveau système de dissimilarités ( )ii ′∗ ,δ  : 
 ( ) ( ) ( )iiciiii ′∗ −+′=′ κδδ 1,,  
avec ⎩⎨
⎧
′≠
′==′
iisi
iisiii
0
1κ , le symbole de Kronecker 
telle que la matrice B  correspondante soit semi-définie positive. 
Le problème de la détermination de la valeur minimale de cette constante est traité par 
[Cailliez, 1983] qui recommande plutôt la transformation suivante du tableau des 
dissimilarités :  ( ) ( ) ( )iiciiii ′∗ −+′=′ κδδ 1,, 2  
 
4.5. Choix du nombre d’axes pour la représentation euclidienne 
Si la matrice B  est semi-définie positive, alors la dimension p de la représentation 
euclidienne est égale au nombre de valeurs propres non nulles. Si B  n’est pas semi-définie 
positive, alors la dimension p de l’espace euclidien est égale au nombre de valeurs propres 
positives. Il s’agit de la dimension maximale de la solution euclidienne. 
En pratique, le nombre q d’axes retenus pour la représentation euclidienne doit être plutôt 
faible. On utilise généralement les axes correspondant aux deux ou trois premières valeurs 
propres. 
Le choix du nombre q optimal d’axes (le nombre de « dimensions ») à retenir pour la 
représentation euclidienne peut s’effectuer en tenant compte du pourcentage de variance 
expliquée. La somme des distances au carré entre les points est fonction de la trace de la 
matrice B  (somme des valeurs propres). 
Si B  est semi-définie positive, la trace de B  est égale à : ( ) ∑∑∑
= =′
′
−
=
==
n
i
n
i
ii
n
i
i dn
tr
1 1
2
1
1 2
1λB  
 © Revue MODULAD, 2005 - 16 - Numéro 32 
La proportion de variance expliquée par un sous-espace de dimension q est alors égale à :
 ( )
∑
∑
−
=
== 1
1
1
n
i
i
q
j
j
q
λ
λ
τ  
Si B  n’est pas semi-définie positive, soit on ne prend en compte dans le calcul que les valeurs 
propres positives (solution simplifiée), soit on choisit comme indicateur (addition d’une 
constante) : 
( )
∑
∑
−
=
== 1
1
*
1
*
n
i
i
q
j
j
q
λ
λ
τ  
Dans l’exemple de la topographie des parcours routiers entre villes françaises, le pourcentage 
de variance expliquée des proximités par les distances issues de la représentation euclidienne 
est de 98 % ("RSQ=0,98008", cf. tableau 2) 
 
4.6. Algorithme du positionnement multidimensionnel classique 
A partir de ce qui précède, l’algorithme du positionnement multidimensionnel classique peut 
se résumer ainsi : 
i) lire la matrice des dissimilarités [ ] IIii ×′= δ∆  ; 
ii) calculer la matrice 
II
ii
×
′ ⎥⎦
⎤⎢⎣
⎡−= 2
2
1δA  ; 
iii) calculer la matrice [ ] IIiiii aaaa ×′′ +−−= ....B  ; 
iv) extraire les valeurs propres non nulles { }11 −ni λλλ LL  et les vecteurs 
propres associés [ ]11 −ni vvv LL  sous la contrainte de normalisation 
ii
t
i λ=× vv  
s’il y a des valeurs propres négatives, soit : 
a) les annuler (version simplifiée) et aller à l’étape v) 
b) transformer les dissimilarités en ajoutant une constante de valeur minimale 
(e.g. fonction ( ) ( ) ( )iiciiii ′∗ −+′=′ κδδ 1,, 2 ) et retourner à l’étape ii) ; 
v) choisir un nombre q adéquat de dimensions en utilisant le pourcentage de 
variance expliqué ( )qτ  comme critère ; 
vi) extraire les coordonnées euclidiennes ijjij vx λ=  des points i pour chaque 
dimension j. 
La détermination de la valeur de la constante dans la procédure SPSS n’est pas explicitée 
mais, d’après la documentation disponible, l’ajout de la constante est effectué selon la 
fonction ( ) ( ) ( )iiciiii ′−+′′=′′ κδδ 1,, . 
 © Revue MODULAD, 2005 - 17 - Numéro 32 
4.7. Lien avec l’analyse en composantes principales 
 
En partant du tableau X  des données centrées, on peut calculer la matrice de variance-
covariance empirique : ( ) XXS tn 1
1
−= . 
L’analyse en composantes principales (ACP) s’effectue en diagonalisant l’opérateur d’inertie 
tΨΜΨS = , avec ( )pj µµµ ,,,,1 LLdiagM =  ce qui permet d’extraire les valeurs propres { }pjj ,,1, L=µ  et les vecteurs propres { }pjj ,,1, L=ψ . 
Les composantes principales sont alors obtenues par projection : xψ tjjc = . 
Soit tXXB = , la matrice des produits scalaires. Les vecteurs propres de B  sont définis par :
 jjj
t
j vvXXBv λ==  
En prémultipliant par tX , on obtient : j
t
jj
tt vXvXXX λ=  or jjjt ψXψX µ= . 
Par identification, on en déduit jj µλ =  et jj ψv = . 
Il y a donc équivalence entre le positionnement multidimensionnel classique (analyse des 
proximités avec une métrique euclidienne) et l’ACP. Les p coordonnées principales des 
stimuli obtenues en positionnement multidimensionnel classique sont simplement les p 
composantes principales des individus dans une ACP. 
 
 
Portrait d’Euclide, « Images of Mathematicians on Postage Stamps » Jeff Miller  
(Webring « Mathematics on Stamps »). 
 
 © Revue MODULAD, 2005 - 18 - Numéro 32 
5. Un exemple illustratif : les céréales du petit déjeuner 
Cet exemple est extrait d’une comparaison des céréales du petit déjeuner présentée en 1993 à 
une réunion sur les graphiques en statistique, organisée par l’ASA (American Statistical 
Association). Cette expérimentation portait initialement sur 77 produits jugés selon 11 
critères. L’extrait suivant concerne uniquement les céréales produites par un des fabricants, 
soit 23 produits distincts. Les critères étudiés sont le nombre de calories (<calories>), les 
teneurs en protéines (<protein>), en graisses (<fat>), en sodium (<sodium>), en fibres 
(<fiber>), en complexes carbohydratés (<carbo>), en sucres (<sugars>), le numéro d’étagère 
(<shelf>) compté à partir du sol, les teneurs en potassium (<potass>) et en vitamines 
(<vitamins>). 
Figure 5 : le tableau des données d’enquête. 
 
En utilisant le modèle de positionnement multidimensionnel classique, on constate sur cet 
exemple, en situation réelle d’application de la méthode, que l’ajustement obtenu est 
beaucoup moins bon que sur les données topograhiques. En effet, le pourcentage de variabilité 
expliquée n’est plus que de 69 % (cf. tableau 3, "RSQ= ,69342"). L’indicateur de la 
qualité de l’ajustement que constitue le stress a augmenté de manière notable : 0,27 
("Stress= ,26845") contre 0,06 obtenu avec l’exemple précédent (en fait, une 
illustration ad hoc de la méthode). 
De même si l’on consulte le diagramme de Shepard associé à ce résultat (cf. figure 8), on 
constate qu’un certain nombre de disparités s’éloignent très significativement d’un modèle de 
représentation linéaire affine, voire s’affranchissent du modèle d’une relation monotone entre 
distances et disparités. De l’examen du diagramme de Shepard, on conclut que le modèle 
métrique n’est pas adapté à cet exemple et qu’il conviendrait de poursuivre l’analyse de cet 
exemple avec un modèle non métrique. 
 © Revue MODULAD, 2005 - 19 - Numéro 32 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Tableau 3 : itérations de l’algorithme d’optimisation et valeurs du stress de type I les céréales du petit déjeuner. 
 
Cependant, si l’on compare avec une méthode factorielle, l’analyse en composantes 
principales (ACP) du tableau X  des données, on constate que les projections sur les deux 
premiers axes factoriels (53% de variance expliquée) donne une configuration (cf. figure 7) 
très proche de la représentation euclidienne fournie par l’algorithme ALSCAL pour les 
options correspondant au positionnement multidimensionnel classique : les projections sur 
l’axe F2 de l’ACP sont de signe contraire à celles sur la dimension D2 du positionnement 
multidimensionnel. On vérifie donc ici l’équivalence entre le modèle de positionnement 
multidimensionnel classique et l’analyse en composantes principales. 
En fait, le résultat fourni par la procédure ALSCAL correspond à un positionnement 
multidimensionnel réalisé sans transformation monotone donnant une approximation de la 
solution du positionnement classique que constitue l’analyse factorielle du tableau de 
distances ; les différences entre les deux solutions tiennent à la nature de l’algorithme utilisé 
puisqu’une analyse factorielle réalise une projection (opération contractant les distances) 
tandis que le positionnement multidimensionnel sans transformation monotone réalise une 
approximation où les disparités pourront être soit supérieures soit inférieures aux distances à 
reconstituer ; dans le cas d’une véritable AFTD, cela se traduit par un diagramme de Shepard 
où tous les points sont situés sous la diagonale tandis que dans notre exemple les points se 
situent de part et d’autre de la diagonale. 
Autre distinction entre les deux méthodes : dans l’AFDT, la solution à n-1 dimensions est 
incluse dans la solution à n dimensions en raison du processus de recherche des directions 
propres, ce qui n’est pas forcément vrai en positionnement multidimensionnel où la recherche 
d’une solution à trois dimensions se fait indépendamment de la recherche d’une solution à 
deux dimensions. 
 
Iteration     S-stress      Improvement 
                    1           ,37423 
                    2           ,31488         ,05935 
                    3           ,30540         ,00948 
                    4           ,30413         ,00127 
                    5           ,30393         ,00020 
                         Iterations stopped because 
                 S-stress improvement is less than   ,001000 
 
            Stress and squared correlation (RSQ) in distances 
 
RSQ values are the proportion of variance of the scaled data 
(disparities) 
           in the partition (row, matrix, or entire data) which 
            is accounted for by their corresponding distances. 
             Stress values are Kruskal's stress formula 1. 
                For  matrix 
    Stress  =   ,26845      RSQ =  ,69342 
   
 
 
ALSCAL : configuration des stimulii
distance euclidienne, modèle métrique intervalle
Dimension 1
43210-1-2
D
i
m
e
n
s
i
o
n
 
2
2,0
1,5
1,0
,5
0,0
-,5
-1,0
-1,5
-2,0
AllB
AllF
Crac
MuC
Sma
NutW 
Spec
JRF
N JRCN 
Cris 
RiKr 
CorF 
Prod
FroF 
Nut
&
Rais
FruB
CorP 
RaBr 
Fr
M
Froo
NGA
AppJ
Figure 6 : représentation euclidienne des marques de céréales. 
 © Revue MODULAD, 2005 - 21 - Numéro 32 
 F1 (32%)
43210-1-2
F
2
 
(
2
1
%
)
3
2
1
0
-1
-2
Spec
Smac
RiKr
Rais
RaBr
Prod
NutW
Nut&
NGAR
MuCB
JRFN
JRCN
FruB
Froo
FroF
FrMW
Cris
Crac
CorP
CorF
AppJ
AllF
AllB
Figure 7 : projection des marques de céréales sur les deux premiers axes de l’ACP du tableauX . 
 © Revue MODULAD, 2005 - 22 - Numéro 32 
 
Ajustement linéaire des distances par les disparités
Modèle : distance euclidienne, intervalle
Disparités
543210
D
i
s
t
a
n
c
e
s
5
4
3
2
1
0
Figure 8 : diagramme de Shepard pour la représentation euclidienne des marques de céréales. 
   
6. Spécification des paramètres du positionnement multidimensionnel 
 
Pour effectuer un positionnement multidimensionnel, il convient de sélectionner la procédure 
Positionnement multidimensionnel de l’option Positionnement du menu Analyse afin 
d’obtenir la boîte de dialogue permettant de spécifier les principaux paramètres du 
positionnement multidimensionnel. 
 
Figure 9 : appel de la procédure SPSS de positionnement multidimensionnel simple. 
 
Les spécifications requises concernent en premier lieu les dissimilarités (Bloc de spécification 
<Distances>) qui peuvent être lues soit directement sous forme de forme de matrice carrée 
(<Données en matrice(s)>) soit calculées à partir de tableaux de données rectangulaires 
croisant observations en lignes et variables en colonnes (<Calculées à partir des données>). 
Ici (cf. figure 10), le choix a été de calculer ces dissimilarités entre les lignes du tableau de 
données (option <Entre observations>du choix de <Calcul des indices> à partir des 
valeurs centrées réduites (choix <Centrer-réduire> de la liste <Standardiser> du bloc 
<Transfomer les valeurs>). La liste des variables soumises à ce calcul est définie par leur 
sélection dans la liste spécifique <Variables : :>. 
La seconde étape (cf. figure 11) consiste à spécifier le modèle d’ajustement des dissimilarités 
aux distances afin de pouvoir en déduire une représentation euclidienne. Le choix effectué est 
celui correspondant à un ajustement linéaire de type affine (choix <Intervalle> du bloc 
<Niveau de mesure> pour un modèle de positionnement multidimensionnel classique 
(choix <Distance euclidienne> du bloc <Modèle de positionnement>). Dans le présent 
contexte d’un modèle de dimensionnement simple, c’est l’option par défaut (<Matrice>) de 
conditionnement (bloc <Conditionnement>) qui est retenue puisque l’ensemble des 
dissimilarités entre les marques de céréales est obtenu à partir d’une même échelle de mesure. 
 © Revue MODULAD, 2005 - 24 - Numéro 32 
Enfin, on demande (bloc <Dimension>, option par défaut <Minimum=2>, <Maximum=2>) 
que la représentation euclidienne s’effectue dans un espace de dimension 2. 
Figure 10 : calcul de l’indice de dissimilarité entre objets. 
 
 © Revue MODULAD, 2005 - 25 - Numéro 32 
Figure 11 : choix du modèle d’ajustement des dissimilarités aux distances. 
 © Revue MODULAD, 2005 - 26 - Numéro 32 
Figure 12 : options du traitement, critères de convergence et résultats. 
 
Concernant les diverses options proposées de traitement (cf. figure 12), on demande 
d’afficher (bloc <Afficher>) la représentation euclidienne des objets (choix <Diagramme 
des stimuli>), la matrice symétrique des proximités calculées (choix <Matrice des 
données>) qui constitue les « données » à partir duquel s’est effectué l’ajustement linéaire 
affine et la sélection des paramètres de la procédure (choix <Récapitulatif des options du 
modèle> qui permettra de se repérer ultérieurement parmi les listings des différents essais 
effectués. 
 © Revue MODULAD, 2005 - 27 - Numéro 32 
L’ajustement des disparités aux distances s’effectuant à partir d’un algorithme numérique de 
recherche du minimum de la fonction objectif (S-STRESS), un certain nombre de paramètres 
permettent de contrôler la convergence de cet algorithme itératif : figurent dans le bloc 
<Critères>, les valeurs par défaut d’arrêt de l’algorithme (<Convergence du stress 
S=0,001>), de borne minimale de la fonction objectif ( <Minimum du stress S=0,005>), 
du maximum d’itérations autorisées (<Maximum des itérations=30>. De même, on définit 
une borne minimale autorisée pour les dissimilarités, option par défaut (<=0>), en assimilant 
les valeurs inférieures à des valeurs manquantes. 
Toutes ces valeurs par défaut peuvent bien sûr être modifiées dans les essais que l’on est 
amené à effectuer pour rechercher la convergence de l’algorithme itératif. 
 
Références bibliographiques 
 
Les références ci-dessous correspondent soit à des travaux cités dans le texte de cette note, 
soit à des articles princeps, soit à des ouvrages de synthèse. Consultée lors de la révision de 
cette note, la synthèse récente « Positionnement multidimensionnel et quantification 
vectorielle » de Gérard d’Aubigny (2003) permettra au lecteur intéressé d’approfondir ce 
sujet. 
Cox T.F., Cox M.A.A. (2001) Multidimensional Scaling (2nd Ed.), Chapman & Hall/CRC, 
Londres. 
Cailliez F. (1983) « The Analytical Solution of the Additive Constant Problem », 
Psychometrika, 48, 305-308. 
Cailliez F., Pages J.P. (1976) Introduction à l’analyse des données, SMASH, Paris. 
Aubigny (d’) G. (2003) « Positionnement multidimensionnel et quantification vectorielle», in 
Traitement du signal et de l’image. Analyse des Données Govaert G. (dir.) 
Hermès, 105-150. 
Richardson M.W. (1938) « Multidimensional Psychophysics », Psychological Bulletin 35, 
659-660. 
Rothkopf E.W. (1957) « A Measure of Stimulus Similarity and Errors in some Paired-
Associate Leaning Tasks », J. of Experimental Psychology 53, 94-101. 
Shepard R.N. (1962) « The Analysis of Proximities: Multidimensional Scaling with an 
Unknown Distance Function », Psychometrika 27, 125-140, 219-246. 
Kruskal J.B. (1964a) « Multidimensional Scaling by Optimizing Goodness of Fit to a Non 
Metric Hypothesis », Psychometrika, 29, 1-27. 
Kruskal J.B. (1964b) « Non Metric Multidimensional Scaling: a Numerical Method », 
Psychometrika, 29, 115-129. 
Kruskal J.B., Wish M. (1984) « Multidimensional Scaling », Quantitative Applications in the 
Social Sciences, 11, Sage University Paper. 
Pagès J. (2003) « Recueil direct de distances sensorielles: application à l’évaluation de dix 
vins blancs du Val de Loire ». Sciences des aliments, 23, 679-688. 
Torgerson W.S. (1952) « Multidimensional Scaling: I Theory and Method », Psychometrika, 
17, pp. 401-419. 
Tournois J., Dycke P. (1993) Pratique de l'échelonnement multidimensionnel, De Boeck-
Wesmael, Bruxelles. 
Young F.W., Harris D.F. (1994. « Chapter 7: Multidimensional Scaling », in SPSS 
Professional Statistics 6.1, Marijja J. Norusis (dir.), Chicago, IL, USA, 155-222. 
 © Revue MODULAD, 2005 - 28 - Numéro 32 
Young F.W., Takane Y., Lewykyj R. (1978) « ALSCAL: A Nonmetric Multidimensional 
Scaling Program With Several Difference Options », Behavioral Research 
Methods and Instrumentation, 10, pp. 451-453. 
Young F.W., Lewykyj R. (1979) ALSCAL-4 User’s Guide, Data Analysis and Theory 
Associates, Carborro, NC, USA. 
Young G., Householder A.S. (1938) « Discussion of a Set of Points in Terms of their Mutual 
Distances », Psychometrika, 3, pp. 19-22. 
 
 
 
 
Portrait d’Alston Scott Householder (1904-1993),  
Extrait  de “The History of Mathematics Archive” 
 John O'Connoret Edmund Robertson, School of Mathematics and Statistics, University of St Andrews 
 
 
Remerciements 
L’auteur remercie Francis Caillez, Jérôme Pagès et Gilbert Saporta pour leurs remarques 
critiques et les conseils prodigués à la lecture de la version initiale de cette note, cependant 
les éventuelles erreurs et omissions qui pourraient demeurer relèvent de sa seule 
responsabilité. 
