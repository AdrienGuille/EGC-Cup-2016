Une approche de rÃ©partition des donnÃ©es dâ€™un entrepÃ´t basÃ©e 
sur lâ€™Optimisation par Essaim Particulaire   
 
HacÃ¨ne Derrar*, Omar Boussaid**, Mohamed Ahmed-Nacer* 
 
* Laboratoire LSI, DÃ©partement Informatique, USTHB Alger 
Bp 32 El Alia, bab Ezzouar/ Ager   
Hderrar@yahoo.fr, Anacer@mail.cerist.dz 
** Laboratoire ERIC, UniversitÃ© Lyon2 
Campus Porte des Alpes, 69676 Bron Cedex 
Omar.Boussaid@univ-lyon2.fr 
 
RÃ©sumÃ©.  Dans le contexte des entrepÃ´ts de donnÃ©es, le partitionnement des 
tables, des index et des vues matÃ©rialisÃ©es en fragments stockÃ©s et consultÃ©s 
sÃ©parÃ©ment apporte des amÃ©liorations considÃ©rables en terme de gestion des 
donnÃ©es et de coÃ»t de traitement. Lors de leurs conceptions, ces techniques se 
basent sur lâ€™analyse dâ€™informations statistiques recueillies Ã  partir des requÃªtes 
les plus frÃ©quentes. Cependant, en raison de leurs caractÃ©ristiques les requÃªtes 
dÃ©cisionnelles rendent ce contexte dâ€™analyse trÃ¨s variable. Ceci rend avec le 
temps, les schÃ©mas de fragmentation rÃ©alisÃ©s inappropriÃ©s et par consÃ©quent 
une dÃ©gradation des performances du systÃ¨me. A partir de ce constat, et consi-
dÃ©rant que la validitÃ© dâ€™une approche de partitionnement est soumise Ã  
lâ€™Ã©preuve du temps et dÃ©pend des besoins et de lâ€™environnement, on propose 
dans ce papier une approche de rÃ©partition des donnÃ©es de lâ€™entrepÃ´t basÃ©e sur 
une mÃ©thode issue des approches biomimÃ©tiques.   
 
1 Introduction  
Dans le contexte des entrepÃ´ts de donnÃ©es, le choix de la mÃ©thode et du schÃ©ma de frag-
mentation conjuguÃ© avec lâ€™Ã©volution perpÃ©tuelle des systÃ¨mes, des applications et enfin des 
donnÃ©es constituent les vÃ©ritables problÃ¨mes qui entravent une meilleure exploitation de cette 
technique. En effet, une approche de fragmentation inappropriÃ©e et mal conÃ§ue influe consi-
dÃ©rablement sur les performances du systÃ¨me et plus particuliÃ¨rement lors de lâ€™exÃ©cution des 
opÃ©rations coÃ»teuses telles que la jointure et la multi-jointure qui caractÃ©risent les requÃªtes 
dÃ©cisionnelles.   
Lâ€™approche prÃ©sentÃ©e dans ce papier sâ€™inscrit dans le cadre dâ€™une solution aux problÃ¨mes 
induits par lâ€™application dâ€™une stratÃ©gie de fragmentation inadaptÃ©e aux changements perpÃ©-
tuels du contexte dans lequel est exploitÃ© lâ€™entrepÃ´t de donnÃ©es. Cette solution consiste Ã  
mettre en Å“uvre un processus dâ€™automatisation visant la redistribution des donnÃ©es Ã  lâ€™issue 
dâ€™une dÃ©gradation des performances observÃ©e lors de lâ€™exploitation de lâ€™entrepÃ´t. Nous pro-
posons dans cet article, une approche de rÃ©partition des donnÃ©es basÃ©e sur une technique 
dâ€™optimisation issue des approches biomimÃ©tiques. Celle-ci permet, Ã  lâ€™issue dâ€™une phase 
dâ€™Ã©valuation, de dÃ©terminer un schÃ©ma de fragmentation optimisant les performances.  Cet 
article est organisÃ© comme suit, dans la premiÃ¨re section, nous prÃ©sentons un Ã©tat de lâ€™art sur 
Lâ€™OEP pour la rÃ©partition des donnÃ©es 
les approches de fragmentation utilisÃ©es. Dans la section 2, nous dÃ©crivons dâ€™une maniÃ¨re 
gÃ©nÃ©rale le problÃ¨me gÃ©nÃ©rÃ© par les techniques de partitionnement et nous positionnons notre 
approche ainsi que lâ€™apport attendu. Dans les sections 3 et 4, nous dÃ©crivons respectivement 
le principe de lâ€™approche, ainsi que son application dans les entrepÃ´ts de donnÃ©es. Dans la 
section 5, nous prÃ©sentons les rÃ©sultats expÃ©rimentaux obtenus en utilisant le benchmark 
APB-1 release II implÃ©mentÃ© sous Oracle 10g. Enfin, nous terminions cet article par une 
conclusion et des perspectives.    
2 Positionnement    
A lâ€™issue dâ€™une Ã©tude de lâ€™Ã©tat de lâ€™art sur les techniques de fragmentation des entrepÃ´ts 
de donnÃ©es, il en ressort que toutes les approches de fragmentation, horizontale, verticale ou 
mixte, se basent lors de leur conception sur lâ€™analyse dâ€™informations statistiques recueillies Ã  
partir de lâ€™exÃ©cution des requÃªtes les plus frÃ©quentes.  De ce fait, lâ€™adaptation des techniques 
de fragmentation aux entrepÃ´ts de donnÃ©es sâ€™avÃ¨re plus dÃ©licate en raison principalement de 
la nature des requÃªtes analytiques. Ces requÃªtes sont longues, complexes et nÃ©cessitent par-
fois un grand nombre d'opÃ©rations de sÃ©lection, dâ€™agrÃ©gation. Elles peuvent manipuler des 
centaines voir des milliers de tuples. Les requÃªtes analytiques sont extrÃªmement variables, 
elles sont  gÃ©nÃ©ralement composÃ©es dâ€™une maniÃ¨re interactive et peuvent Ãªtre exÃ©cutÃ©es une 
ou plusieurs fois. Ce type de requÃªtes appelÃ©es aussi requÃªtes ad hoc, correspond Ã  des re-
quÃªtes saisies en ligne sans une longue rÃ©flexion prÃ©alable (Gardarin, 2005). Toutes ces ca-
ractÃ©ristiques rendent, avec le temps, le schÃ©ma de fragmentation mis en place, inappropriÃ© 
Ã©tant donnÃ© quâ€™il a Ã©tÃ© conÃ§u Ã  partir dâ€™informations statistiques instables. 
Par ailleurs, les travaux qui ont traitÃ© lâ€™adaptation des techniques de fragmentation se sont 
focalisÃ©s sur lâ€™aspect logique en le dissociant complÃ¨tement de lâ€™aspect physique de la con-
ception des entrepÃ´ts de donnÃ©es. En effet, la conception du schÃ©ma de fragmentation et la 
stratÃ©gie de placement des fragments sont deux approches totalement dÃ©pendantes. Elles se 
basent lors de leurs conceptions sur les mÃªmes informations recueillies lors de lâ€™exploitation 
des donnÃ©es, en vue dâ€™accomplir le mÃªme objectif, Ã  savoir lâ€™amÃ©lioration des performances 
des systÃ¨mes.  
De cet Ã©tat de fait, les techniques de fragmentation initialement conÃ§ues pour 
lâ€™amÃ©lioration des performances peuvent dans le cadre des entrepÃ´ts de donnÃ©es constituer 
les principaux obstacles pour une meilleure exploitation des donnÃ©es. En effet, il ne sâ€™agit 
pas de procÃ©der Ã  une simple application de ces techniques mais Ã©galement dâ€™assurer une 
adaptabilitÃ© parfaite aux caractÃ©ristiques spÃ©cifiques des entrepÃ´ts de donnÃ©es. Pour bÃ©nÃ©fi-
cier pleinement de leurs avantages, les techniques de fragmentation et de placement des 
donnÃ©es doivent Ãªtre constamment revues et adaptÃ©es au contexte de lâ€™exploitation de 
lâ€™entrepÃ´t. Pour ce faire, nous proposons une approche permettant de concrÃ©tiser cette adap-
tabilitÃ© par lâ€™introduction de lâ€™aspect dynamicitÃ© qui sâ€™avÃ¨re Ãªtre une maniÃ¨re Â« intelligente Â» 
de rÃ©organiser les donnÃ©es en vue dâ€™assurer, en permanence, les meilleures performances en 
termes de traitement des requÃªtes, de coÃ»t de communication et de capacitÃ© de stockage. 
Notre approche, suppose lâ€™existence dâ€™un schÃ©ma de fragmentation dÃ©jÃ  mis en place. Elle 
consiste dâ€™abord, Ã  lâ€™issue dâ€™une dÃ©gradation des performances, Ã  rechercher un schÃ©ma plus 
optimal et procÃ©der par la suite Ã  la redistribution des donnÃ©es entre fragments. Dans ce pa-
pier, nous dÃ©finissons un nouveau modÃ¨le de coÃ»t adaptÃ© Ã  notre approche ainsi quâ€™un Algo-
H.Derrar et al. 
 
rithme de sÃ©lection dâ€™un schÃ©ma de fragmentation optimal inspirÃ© des approches biomimÃ©-
tiques.  
  
3  Une approche de rÃ©partition des donnÃ©es dans un entrepÃ´t  
On suppose lâ€™existence dâ€™un schÃ©ma de fragmentation conÃ§u et implÃ©mentÃ© sur un entre-
pÃ´t de donnÃ©es. Le principe de notre approche consiste, Ã  lâ€™issue dâ€™une dÃ©gradation des per-
formances, Ã  dÃ©terminer un autre schÃ©ma de fragmentation plus optimal et procÃ©der par la 
suite Ã  la  redistribution des donnÃ©es selon ce nouveau schÃ©ma. Cependant, cette dÃ©marche 
nÃ©cessite, dans un premier temps, Ã  Ã©valuer estimer le schÃ©ma de fragmentation existant. 
NÃ©anmoins, mesurer la qualitÃ© dâ€™un schÃ©ma de fragmentation dont on ne connaÃ®t pas Ã  priori 
le modÃ¨le de coÃ»t utilisÃ© est une tÃ¢che qui nâ€™est pas toujours Ã©vidente. De plus, la majoritÃ© 
des algorithmes de conception logique de la fragmentation sont dirigÃ©s par la mesure 
dâ€™affinitÃ©. Câ€™est Ã  dire le calcul des frÃ©quences dâ€™accÃ¨s des requÃªtes, uniquement entre une 
paire dâ€™attributs. Ce qui ne permet pas, par consÃ©quent, de mesurer  lâ€™affinitÃ© entre tous les 
attributs dâ€™une partition.  
Il sâ€™avÃ¨re donc nÃ©cessaire de dÃ©finir un nouveau modÃ¨le de coÃ»t permettant dâ€™Ã©valuer et 
de mesurer lâ€™affinitÃ© dâ€™un schÃ©ma de fragmentation. Ce modÃ¨le de coÃ»t devra Ãªtre gÃ©nÃ©rique 
et flexible permettant Ã©ventuellement de prendre en considÃ©ration dâ€™autres mÃ©triques telles 
que : le type des requÃªtes, les informations de placement des donnÃ©es, la capacitÃ© de stockage 
et  le coÃ»t de transfert des donnÃ©es entre sites. 
 
 
3.1  Une nouvelle fonction objective 
 
Ã‰tant donnÃ© que toute approche de fragmentation se conÃ§oit Ã  partir dâ€™informations por-
tants sur les frÃ©quences dâ€™accÃ¨s des requÃªtes aux donnÃ©es. Lâ€™idÃ©e consiste Ã  utiliser ce dÃ©no-
minateur commun entre toutes les approches pour dÃ©finir une nouvelle fonction de coÃ»t. 
Celle-ci permettra dâ€™Ã©valuer un schÃ©ma de fragmentation selon les frÃ©quences dâ€™accÃ¨s des 
requÃªtes aux diffÃ©rents fragments. Pour mesurer donc la qualitÃ© dâ€™un schÃ©ma de fragmenta-
tion, nous adaptons une technique dâ€™estimation utilisÃ©e dans le domaine de la statistique Ã  
savoir le critÃ¨re de lâ€™erreur au carrÃ©e (Square-Error). Elle consiste Ã  Ã©valuer un schÃ©ma de 
fragmentation par le calcul de lâ€™erreur au carrÃ©e des frÃ©quences des accÃ¨s des requÃªtes sur les 
attributs des diffÃ©rents fragments.   
La formulation, ci-dessous, relative Ã  la dÃ©finition de notre modÃ¨le de coÃ»t a Ã©tÃ© inspirÃ©e 
des travaux de Jain et Dubes (1998) et de Muthuraj (1992), qui lâ€™ont utilisÃ© dans le cadre 
dâ€™une mÃ©thode dâ€™apprentissage non supervisÃ©e pour le regroupement dâ€™attributs. Pour des 
raisons de simplification, on considÃ¨re dans notre cas un entrepÃ´t de donnÃ©es Ã©voluant dans 
un contexte de traitement local des requÃªtes et dont la table de fait est fragmentÃ©e selon une 
approche verticale. Nous considÃ©rons que les tables de dimension sont de petite taille et par 
consÃ©quent, elles ne seront pas fragmentÃ©es. De plus, notre approche ne considÃ¨re pas une 
matrice dâ€™affinitÃ© dâ€™attributs, mais une matrice dâ€™usage dâ€™attributs composÃ©e, en colonnes 
des attributs et en lignes des requÃªtes frÃ©quentes. Les termes de la matrice sont les frÃ©quences 
dâ€™accÃ¨s des requÃªtes aux attributs. Le calcul de lâ€™erreur au carrÃ©e permettra de mesurer 
lâ€™affinitÃ© des  partitions de taille diffÃ©rentes. Soit la formulation suivante :  
Lâ€™OEP pour la rÃ©partition des donnÃ©es 
n : nombre total des attributs de la table de faits ; 
Q : nombre total des requÃªtes frÃ©quentes ; 
fq : frÃ©quence dâ€™accÃ¨s de la requÃªte q pour q = 1,2,.., Q ; 
M : nombre total des fragments ; 
ni : nombre dâ€™attributs dans le fragment i ; 
ğ‘“ğ‘ğ‘—
ğ‘– : la frÃ©quence dâ€™accÃ¨s de la requÃªte q Ã  lâ€™attribut j dans le fragment i,  avec  ğ‘“ğ‘ğ‘—
ğ‘– â‰  0 ; 
Aij : le vecteur attribut de lâ€™attribut j dans le fragment i, oÃ¹ ğ‘“ğ‘ğ‘—
ğ‘–  est une composante de ce             
vecteur ; 
Siq : lâ€™ensemble dâ€™attributs du fragment i accÃ©dÃ© par la requÃªte q ; Ã©gale Ã  0 si la requÃªte q 
nâ€™accÃ¨de pas au fragment i ; 
| Siq | : nombre dâ€™attributs du fragment i accÃ©dÃ© par la requÃªte q ; 
 
Etant donnÃ©e une table de faits F de n attributs fragmentÃ©e verticalement en M frag-
ments (F1, F2, â€¦, FM) contenant chacun ni attributs. Ainsi,  ğ‘›ğ‘–
ğ‘€
ğ‘–=1 = ğ‘›. Le vecteur moyen Vi 
pour le fragment i est dÃ©fini par : ğ‘‰ğ‘– = 
1
ğ‘›ğ‘–
  ğ´ğ‘–ğ‘—
ğ‘›ğ‘–
ğ‘—=1                   0 < i < M                      (1) 
Le vecteur moyen V reprÃ©sente la moyenne des accÃ¨s des requÃªtes Ã  tous les attributs du 
fragment i.  Pour un vecteur dâ€™attributs Aij, (Aij - Vi) est dÃ©nommÃ© Â« le vecteur diffÃ©rence Â» de 
lâ€™attribut j dans le fragment i. Lâ€™erreur au carrÃ©e pour le fragment Fi est la somme des carrÃ©es 
de la longueur des vecteurs diffÃ©rences de tous les attributs dans le fragment i. Il est calculÃ© 
par la formule suivante : ğ‘’ğ‘–  
2 =  (ğ´ğ‘–ğ‘— âˆ’  ğ‘‰ğ‘– )
ğ‘„  (ğ´ğ‘–ğ‘—  âˆ’  ğ‘‰ğ‘– )
ğ‘›ğ‘–
ğ‘—=1             0 < i < M          (2) 
Si Aij = Vi alors ğ‘’ğ‘– 
2 = 0. Ce cas signifie : soit quâ€™il y a un seul attribut dans chaque frag-
ment soit que tous les attributs dans chaque fragments sont nÃ©cessaires pour lâ€™exÃ©cution de la 
requÃªte. Dans ce papier on sâ€™intÃ©resse au cas oÃ¹ Aij â‰  Vi  afin de pouvoir comparer les frag-
ments selon la pertinence des attributs.  
Lâ€™erreur au carrÃ©e du schÃ©ma de fragmentation globale est calculÃ©e par la formule sui-
vante :                       ğ¸ğ‘€ 
2 =  ğ‘’ğ‘– 
2ğ‘€
ğ‘–=1                                                                                 (3) 
Dâ€™oÃ¹ :  ğ¸ğ‘€  
2 =   (ğ´ğ‘–ğ‘— âˆ’  ğ‘‰ğ‘–)ğ‘„  (ğ´ğ‘–ğ‘— âˆ’  ğ‘‰ğ‘–)
ğ‘›ğ‘–
ğ‘—=1
ğ‘€
ğ‘–=1                                                    (4) 
Une autre Ã©criture de lâ€™Ã©quation 4 permettra de mieux percevoir la contribution de  
chaque requÃªte pour le calcul de lâ€™erreur au carrÃ©e de chaque fragment. Ainsi, le vecteur 
moyen Vi pour le fragment i peut Ãªtre dÃ©fini comme suit :  
ğ‘‰ğ‘– = 
 
 
 
 
 
 
 
 
|ğ‘ ğ‘–1| âˆ—  ğ‘“1
ğ‘›ğ‘–
|ğ‘ ğ‘–2| âˆ—  ğ‘“2
ğ‘›ğ‘–â€¦â€¦ .
â€¦â€¦ .
|ğ‘ ğ‘–ğ‘ | âˆ—  ğ‘“ğ‘
ğ‘›ğ‘–  
 
 
 
 
 
 
 
 
Le vecteur attribut Aij, dont ses composantes sont les frÃ©quences dâ€™accÃ¨s, est :  Aij  = 
 
 
 
 
 
ğ‘“1ğ‘—
ğ‘–
ğ‘“2ğ‘—
ğ‘–
â€¦â€¦ .
â€¦â€¦ .
ğ‘“ğ‘ğ‘—
ğ‘–
 
 
 
 
 
 
H.Derrar et al. 
 
Dâ€™oÃ¹ : ğ¸ğ‘€ 
2 =    ğ‘“1ğ‘—
ğ‘– âˆ’  
|ğ‘ ğ‘–1|âˆ— ğ‘“1
ğ‘›ğ‘–
,â€¦ , ğ‘“ğ‘ğ‘—
ğ‘– âˆ’  
|ğ‘ ğ‘–ğ‘ |âˆ— ğ‘“ğ‘
ğ‘›ğ‘–
      
 
 
 
 
 
 
  ğ‘“1ğ‘—
ğ‘– âˆ’  
|ğ‘ ğ‘–1|âˆ— ğ‘“1
ğ‘›ğ‘–
ğ‘“2ğ‘—
ğ‘– âˆ’  
|ğ‘ ğ‘–2|âˆ— ğ‘“2
ğ‘›ğ‘–â€¦â€¦ .
â€¦â€¦ .
ğ‘“ğ‘ğ‘—
ğ‘– âˆ’  
|ğ‘ ğ‘–ğ‘ |âˆ— ğ‘“ğ‘
ğ‘›ğ‘–  
 
 
 
 
 
 
ğ‘›ğ‘–
ğ‘—=1
ğ‘€
ğ‘–=1     (5) 
Par simplification de lâ€™Ã©quation ci-dessus, on aura :  
ğ¸ğ‘€ 
2 =     ğ‘“ğ‘
2 âˆ— |ğ‘ ğ‘–ğ‘ |  1 âˆ’
|ğ‘ ğ‘–ğ‘ |
ğ‘›ğ‘–
    ğ‘„ğ‘=1
ğ‘€
ğ‘–=1     (6) 
Cette Ã©quation est la mÃªme que lâ€™Ã©quation 4, sous une autre forme. On peut donc perce-
voir dâ€™aprÃ¨s cette Ã©quation lâ€™apport des accÃ¨s aux fragments contenant des attributs qui ne 
sont requises par les requÃªtes pour le calcul de ğ¸ğ‘€ 
2 . 
Ainsi, ğ¸ğ‘€ 
2  est notre fonction de coÃ»t dans un contexte dâ€™exploitation locale dâ€™un entrepÃ´t 
de donnÃ©es. Elle signifie que la valeur de  ğ¸ğ‘€ 
2  est proportionnelle au coÃ»t dÃ» Ã  lâ€™accÃ¨s aux 
fragments contenants des attributs non pertinents. Plus la valeur de cette erreur se rapproche 
de 0 plus le schÃ©ma de fragmentation est optimal. Il revient donc dans la suite de cet article, Ã  
chercher un schÃ©ma de fragmentation qui minimise cette valeur.  
La prochaine phase consiste donc Ã  rechercher un schÃ©ma de fragmentation minimisant  la 
valeur de ğ¸ğ‘€ 
2 .    
 
3.2    Un algorithme OEP pour la rÃ©partition des donnÃ©es  
 
La fonction coÃ»t, en lâ€™occurrence lâ€™erreur au carrÃ©e, du schÃ©ma de fragmentation mis en 
place ayant Ã©tÃ© calculÃ©e, il sâ€™agit dans cette phase de dÃ©terminer un schÃ©ma qui minime cette 
fonction objective.  La recherche de tel optimum a un coÃ»t exponentiel en temps de calcul et 
en espace mÃ©moire. En effet, cela fait partie des problÃ¨mes NP-difficiles et la sÃ©lection des 
partitions dâ€™attributs demanderait lâ€™exploration de tout lâ€™espace de recherche. Pour n attri-
buts, la recherche exhaustive consiste Ã  explorer 2
n
-1 sous-ensembles possibles. Pour remÃ©-
dier Ã  cela, le recours Ã  des heuristiques est nÃ©cessaire. Pour ce faire, notre approche se base 
sur  une mÃ©taheuristique en lâ€™occurrence lâ€™Optimisation par Essaim Particulaire (OEP).  
Les algorithmes OEP ont Ã©tÃ© introduits par Kennedy et Eberhart (1995) comme une alter-
native aux algorithmes gÃ©nÃ©tiques standards. Ces algorithmes sont inspirÃ©s des essaims 
dâ€™insectes (ou des bancs de poissons ou des nuÃ©es dâ€™oiseaux) et de leurs mouvements coor-
donnÃ©s. En effet, tout comme ces animaux qui se dÃ©placent en groupe pour trouver de la 
nourriture ou Ã©viter les prÃ©dateurs, les algorithmes Ã  essaim de particules recherchent des 
solutions pour un problÃ¨me dâ€™optimisation. Les individus de lâ€™algorithme sont appelÃ©s parti-
cules et la population est appelÃ©e essaim. 
Dans cet algorithme, une particule dÃ©cide de son prochain mouvement en fonction de sa 
propre expÃ©rience, qui est dans ce cas la mÃ©moire de la meilleure position quâ€™elle a rencon-
trÃ©e, et en fonction de son meilleur voisin. Ce voisinage peut Ãªtre dÃ©fini spatialement en 
prenant par exemple la distance euclidienne entre les positions de deux particules ou socio-
mÃ©triquement (position dans lâ€™essaim de lâ€™individu). Les nouvelles vitesse et direction de la 
particule seront dÃ©finies en fonction de trois tendances : la propension Ã  suivre son propre 
chemin, sa tendance Ã  revenir vers sa meilleure position atteinte et sa tendance Ã  aller vers 
son meilleur voisin. Les algorithmes Ã  essaim de particules peuvent sâ€™appliquer aussi bien Ã  
des donnÃ©es discrÃ¨tes quâ€™Ã  des donnÃ©es continues. 
Lâ€™OEP pour la rÃ©partition des donnÃ©es 
Les algorithmes Ã  essaim de particules ont Ã©tÃ© utilisÃ©s pour rÃ©aliser diffÃ©rentes tÃ¢ches. Dans 
le cadre de la sÃ©lection dâ€™attributs, Agrafiotis et Cedeno (2002) proposent un algorithme basÃ© 
sur les essaims de particules pour lâ€™Ã©tude de la relation quantitative entre la structure et 
lâ€™activitÃ© de composant chimique (Quantitative Structure Activity Relationship). Omran et 
al., (2002) utilisent les essaims de particules pour effectuer une classification dâ€™images. Dans 
le cadre de lâ€™extraction de rÃ¨gles de classification, les OEP ont Ã©tÃ© comparÃ©s aux algorithmes 
gÃ©nÃ©tiques et Ã  lâ€™algorithme C4.5 (Sousa et al.,2003) et ont Ã©tÃ© appliquÃ©s Ã  la gÃ©nÃ©ration de 
rÃ¨gles pour dÃ©finir le profil des utilisateurs dâ€™un site web (Ujin et Bentley, 2003) et Ã  
lâ€™extraction de rÃ¨gles Ã  partir dâ€™un rÃ©seau de neurones (He at al., 1998). Aussi, Xiao et al., 
(2003) utilisent une mÃ©thode hybride basÃ©e sur les essaims de particules et lâ€™algorithme de 
clustering â€œSelf-Organizing Mapsâ€ pour rÃ©aliser un partitionnement des gÃ¨nes. Dâ€™autres 
travaux ont portÃ© sur lâ€™extension de cette heuristique en vue dâ€™Ã©largir son champ dâ€™adaptation 
(Clerc 2004, Gourgand 2007).  
Notre choix de lâ€™application de lâ€™OEP par rapport Ã  dâ€™autres mÃ©thodes Ã©volutionnaires 
(typiquement, les algorithmes gÃ©nÃ©tiques) se justifie principalement par le fait que cette heu-
ristique :  
- met lâ€™accent sur la coopÃ©ration plutÃ´t que sur la compÃ©tition. Il nâ€™y a pas de sÃ©-
lection. Lâ€™idÃ©e Ã©tant quâ€™une particule mÃªme actuellement mÃ©diocre doit Ãªtre 
conservÃ©e ; 
- permet dâ€™effectuer un regroupement distribuÃ© donc sans contrÃ´le ;  
- sâ€™applique au problÃ¨me dâ€™optimisation combinatoire dynamique dans le cas ou 
la fonction objective varie dans le temps ; 
- permet dâ€™utiliser des fonctions multi-objectifs. 
3.2.1  Principe et algorithme de base   
 
On considÃ¨re dans lâ€™espace de recherche un essaim de particules. Chaque particule est en 
mouvement selon une vitesse. A partir des informations dont elle dispose, une particule doit 
dÃ©cider de son prochain mouvement, câ€™est-Ã -dire dÃ©cider de sa nouvelle vitesse. Pour ce 
faire, elle combine linÃ©airement trois informations : sa vitesse actuelle ; sa meilleure perfor-
mance ; la meilleure performance de ses voisines (ses informatrices). 
A lâ€™aide de trois paramÃ¨tres parfois appelÃ©s coefficients de confiance, qui pondÃ¨rent trois 
tendances : tendance Ã  suivre sa propre voie ; tendance conservatrice (revenir sur ses pas) ; 
tendance Â« panurgienne Â» (suivre le meilleur voisin) ; 
Les Ã©quations complÃ¨tes du mouvement dâ€™une particule peuvent alors sâ€™Ã©crire de la ma-
niÃ¨re suivante :  ğ‘£(ğ‘¡ + 1)= ğ‘1ğ‘£(ğ‘¡) + ğ‘2(ğ‘ğ‘– âˆ’  ğ‘¥(ğ‘¡)) + ğ‘3(ğ‘ğ‘” âˆ’  ğ‘¥(ğ‘¡))           (7) 
 ğ‘¥(ğ‘¡ + 1)= x(ğ‘¡) + ğ‘£(ğ‘¡ + 1)                                           (8) 
 
 
 
 
 
 
 
H.Derrar et al. 
 
 
                                                                   Pi                             
 
 
                                                     pg                                                       
    x 
                    c1           c2                   c3             
                                    v 
                             Vitesse actuelle           
FIG 1. SchÃ©ma de principe du dÃ©placement dâ€™une particule. 
4   Application Ã  la rÃ©partition des donnÃ©es dâ€™un entrepÃ´t  
Pour illustrer notre approche, nous considÃ©rons un schÃ©ma de fragmentation dont la  table 
de faits F de n attributs partitionnÃ©e verticalement en M fragments (F1, F2, â€¦, FM) de ni attri-
buts chacun. Lâ€™erreur carrÃ©e ğ¸ğ‘€ 
2 de ce schÃ©ma ayant Ã©tÃ© calculÃ©e, il sâ€™agit donc de dÃ©terminer 
un schÃ©ma de fragmentation de la table de faits minimisant la valeur değ¸ğ‘€ 
2 . Nous considÃ©-
rons une population de n individus oÃ¹ chaque individu reprÃ©sente un attribut de la table de 
faits se dÃ©plaÃ§ant dans un espace de dimension 2 en lâ€™occurrence une grille. La taille de la 
grille G est de forme carrÃ©e et sa taille est dÃ©terminÃ©e automatiquement en fonction du 
nombre dâ€™individus Ã  traiter. Pour n individus, G comporte L cases par cÃ´tÃ© avec : ğ¿ =
  2ğ‘› . Cette formule permet de sâ€™assurer que le nombre de cases est au moins Ã©gal au 
nombre dâ€™individus. A lâ€™inverse des autres approches qui utilisent les grilles (Lumer et Faie-
ta, 1994), nous permettons Ã  plusieurs individus dâ€™Ãªtre placÃ©s dans une mÃªme case, ce qui 
forme donc une partition.  
 
5  Etude expÃ©rimentale  
Nous avons implÃ©mentÃ© les Ã©tapes de notre approche de redistribution des donnÃ©es sous 
le langage Java. Pour son Ã©valuation, nous avons utilisÃ© le benchmark APB-1 release II 
Council (1998) implÃ©mentÃ© sous Oracle 10g. Ce benchmark, utilise un schÃ©ma en Ã©toile 
composÃ© de quatre tables de dimensions (Prodlevel de 9000 tuples, Custlevel de 900 tuples, 
Timelevel de 24 tuples et Chanlevel de 9 tuples) et une table de faits (Actvars de 24 000 000 
tuples). Pour le calcul des temps dâ€™exÃ©cution des requÃªtes, nous avons utilisÃ© lâ€™utilitaire Aqua 
Data Studio 2.0.7. Pour mener nos tests, nous avons utilisÃ© un ensemble de 50 requÃªtes en-
globant diffÃ©rents opÃ©rateurs : opÃ©rations de jointure, de sÃ©lection et des fonctions de calcul 
et dâ€™agrÃ©gations (SUM, COUNT, AVG, MIN, MAX).   
 Afin de montrer la validitÃ© de notre approche, nous avons dâ€™abord commencÃ© par dÃ©-
montrer que les performances se dÃ©gradent quand on exÃ©cute des requÃªtes qui ne figurent pas 
dans la charge de traitement utilisÃ©e lors de la fragmentation de lâ€™entrepÃ´t de donnÃ©es. Ainsi, 
Ã  partir dâ€™une charge de traitement recueillie sur lâ€™exploitation de lâ€™entrepÃ´t de donnÃ©es, nous 
avons commencÃ© par fragmenter la table de faits selon une approche horizontale et plus par-
ticuliÃ¨rement selon la stratÃ©gie de partitionnement par intervalle supportÃ©e par Oracle 10g (la 
Position 
Actuelle 
Meilleure 
performance 
Actuelle  
Vers la meilleure 
performance  de 
mes voisins 
Nouvelle 
Position 
Lâ€™OEP pour la rÃ©partition des donnÃ©es 
commande PARTITON BY RANGE) et nous avons calculÃ© le temps dâ€™exÃ©cution des requÃªtes 
que nous lâ€™avons comparÃ© avec le temps dâ€™exÃ©cution de nouvelles requÃªtes ne figurant pas 
dans la charge de traitement.   
Notre Ã©tude expÃ©rimentale sâ€™est dÃ©roulÃ©e par la suite selon deux Ã©tapes. Dans une pre-
miÃ¨re Ã©tape, nous fragmentons la table de faits selon une approche verticale en utilisant les 
vues matÃ©rialisÃ©es et Ã  partir dâ€™un ensemble de requÃªtes frÃ©quentes nous calculons lâ€™erreur au 
carrÃ© du schÃ©ma de fragmentation. Dans une seconde phase, nous appliquons notre algo-
rithme OEP afin de dÃ©terminer un nouveau schÃ©ma de fragmentation optimal qui minimise la 
valeur de lâ€™erreur au carrÃ©e.  
Par ailleurs, diffÃ©rents tests ont Ã©tÃ© rÃ©alisÃ©s sur le calcul de lâ€™erreur au carrÃ©e selon diffÃ©-
rents schÃ©ma de fragmentation et nous avons constatÃ© que  le nombre de fragments est inver-
sement proportionnel Ã  la valeur de lâ€™erreur au carrÃ©e. Plus le nombre de fragments est grand 
plus le coÃ»t dâ€™accÃ¨s aux attributs impertinents devient minime (Fig 3). Ce qui montre Ã©gale-
ment lâ€™apport de la fragmentation verticale si les attributs de fragmentation ont Ã©tÃ© bien dÃ©fi-
nis. 
 
           CoÃ»t dâ€™accÃ¨s aux 
      attributs non pertinents  
 
 
                                               0    Nombre de fragments          n 
                   FIG.3- Influence du nombre de fragments sur le coÃ»t dâ€™accÃ¨s aux attributs 
En ce qui concerne lâ€™exÃ©cution de notre programme dâ€™optimisation, les tests ont Ã©tÃ© foca-
lisÃ©s sur le paramÃ©trage et plus particuliÃ¨rement sur les coefficients de confiance c2 et c3. 
Pour une meilleure convergence, ces coefficients doivent Ãªtre puisÃ©s dans un intervalle de 
valeur alÃ©atoire entre 0 et une valeur maximale c. lâ€™Ã©quation 12 sâ€™Ã©crira comme suit :   
ğ‘£(ğ‘¡ + 1)= ğ‘1ğ‘£(ğ‘¡) + ğ‘ğ‘™ğ‘’ğ‘(0, ğ‘ğ‘šğ‘ğ‘¥ )(ğ‘ğ‘– âˆ’  ğ‘¥(ğ‘¡)) + ğ‘ğ‘™ğ‘’ğ‘(0, ğ‘ğ‘šğ‘ğ‘¥ )(ğ‘ğ‘” âˆ’  ğ‘¥(ğ‘¡))              (9)     
Aussi, les valeurs de ğ‘1 et ğ‘ğ‘šğ‘ğ‘¥  ne doivent pas Ãªtre choisies indÃ©pendamment. Selon les 
diffÃ©rents tests effectuÃ©s, le premier doit Ãªtre infÃ©rieur Ã  1 et le second peut Ãªtre calculÃ© par la 
formule : ğ‘ğ‘šğ‘ğ‘¥ =  2/0,97725 ğ‘1 . Plus ğ‘1 est proche de 1 plus lâ€™exploration de lâ€™espace de 
recherche est amÃ©liorÃ©.  
 
 7    Conclusion et perspectives  
 
Dans cet article nous avons prÃ©sentÃ© une nouvelle approche de rÃ©partition des donnÃ©es 
basÃ©e sur un algorithme dâ€™optimisation  inspirÃ© du comportement de certains animaux volant 
ou nageant qui se dÃ©placent en groupe. Cette approche consiste, Ã  lâ€™issue dâ€™une dÃ©gradation 
des performances,  de redistribuer les donnÃ©es selon un nouveau schÃ©ma de fragmentation 
optimal. Nous avons Ã©galement dÃ©fini un nouveau modÃ¨le de coÃ»t, basÃ© sur les frÃ©quences 
dâ€™accÃ¨s aux attributs. Ce modÃ¨le peut Ãªtre Ã©tendue pour Ãªtre multi-objectifs en permettant la 
prise en charge dâ€™autres mÃ©triques telles que : le temps dâ€™exÃ©cution des requÃªtes et le temps 
de transferts des donnÃ©es.  
Pour nos travaux futurs, nous envisageons dâ€™abord de continuer les tests expÃ©rimentaux 
portant sur le paramÃ©trage de notre programme et de procÃ©der par la suite Ã  sa validation en 
comparant les rÃ©sultats obtenus avec dâ€™autres travaux qui ont utilisÃ© dâ€™autres algorithmes 
Ã©volutionnaires (gÃ©nÃ©tique, colonie de fourmis artificielles). Nous envisageons Ã©galement,  
H.Derrar et al. 
 
dâ€™Ã©tendre les tests de notre algorithme sur dâ€™autres approches de fragmentation, le faire pas-
ser Ã  lâ€™Ã©chelle en considÃ©rant un entrepÃ´t de donnÃ©es distribuÃ© avec un modÃ¨le de coÃ»t multi-
objectifs.  
 
RÃ©fÃ©rences 
Agrafiotis,D.K., W. Cedeno (2002). Feature selection for structure-activity correlation using 
binary particle swarms. Journal of Medicinal Chemistry, 45(5) :1098â€“1107. 
Clerc,M., (2004). Discrete Particle Swarm Optimization. In G.C. Onwubolu and B.V. Babu, 
editors,New Optimization Techniques in Engineering, Springer-Verlag,(219-204). 
Gardarin,G. (2005). Base de donnÃ©es. Edition Eyrolles.  
Gourgand,M., S.M.TchomtÃ© (2007). Une extention de lâ€™optimisation par essaims particu-
laires. SÃ©minaire francophone sur lâ€™OEP. France.  
He,Z., C.Wei, L. Yang, X. Gao, S. Yao, R.C. Eberhart, et Y. Shi. (1998). Extracting rules 
from fuzzy neural network by particle swarm optimization. In Proceedings of IEEE Con-
gress on Evolutionary Computation (CEC), pages 74â€“77, Anchorage, Alaska, USA. 
Jain,A., R. Dubes (1998). Algorithms for clustering Data. Prentice Hall Advanced Reference 
Series, Englewood Cli_s, NJ. 
Kennedy,J., R.C. Eberhart (1995). Particle swarm optimization. In IEEE Service Center, 
editor, Proceedings of the 1995 IEEE International Conference on Neural Networks, 
pages 1942â€“1948. 
Muthuraj,J.,(1992). A formal approach to the vertical partitioning problem in distributed 
database design. UniversitÃ© de Florida. USA.  
Omran,A., Salman, et A.P. Engelbrecht (2002). Image classification using particle swarm 
optimization. In Proceedings of the 4th Asia-Pacific Conference on Simulated Evolution 
and Learning (SEAL), pages 370â€“374. 
Sousa,T., A. Neves, A. Silva (2003). Swarm optimisaton as a new tool for data mining. In 
Proceedings of NIDICS, Nice, France. 
Ujjin,S., P.J. Bentley (2003). Particle swarm optimization recommender system. In Proceed-
ings of the IEEE Swarm Intelligence Symposium 2003, pages 124â€“131, Indianapolis, In-
diana, USA. 
Xiao,X., E.Dow, R.Eberhart, Z.BenMiled, et R.J.Oppel (2003). Gene clustering using self-
organizing maps and particle swarm optimization. In Second IEEE International Work-
shop on High Performance Computational Biology (HICOMB). 
 
Summary 
In the context of the data warehouses, partitioning tables, indexes and materialized views 
in fragments stored and consulted separately brings considerable improvements in term of 
management of the data and the cost of treatment. During their conceptions, these techniques 
base on the analysis of statistical information collected from the most frequent requests. 
However, because of their characteristics the decisional requests return this context of analy-
sis very variable. This make in time the realized plans of fragmentation inappropriate and 
consequently a degradation of the performances of the system. From this report and consi-
dering that the validity of an approach of partitioning is subjected to the time and depends on 
needs and on the environment, we propose in this paper an approach of distribution of the 
data based on a method resulting from the biomimetic approaches. 
