Ade´quation des mode`les de repre´sentation aux
me´thodes de cate´gorisation
Simon Jaillet∗, Maguelonne Teisseire∗
Ge´rard Dray∗∗
∗LIRMM-CNRS - ISIM-Universite´ Montpellier 2
161 rue Ada, 34392 Montpellier Cedex 5 France
{jaillet, teisseire}@lirmm.fr
∗∗LGI2P, EMA Site EERIE,
Parc Scientifique G. Besse, 30319 Nimes France
gerard.dray@ema.fr
Re´sume´. Cet article s’interesse a` la proble´matique de la cate´gorisation de
documents et plus particulie`rement a` l’impact de la me´thode de repre´senta-
tion des documents dans le processus de cate´gorisation. A partir de dif-
fe´rents jeux de documents repre´sente´s dans un espace vectoriel tout d’abord
base´ sur les concepts puis base´ sur une approche de type TF -IDF , nous
e´valuons les me´thodes de cate´gorisation SVM et Rocchio. Nous compa-
rons ensuite les deux me´thodes pre´ce´dentes avec une me´thode de cluste-
ring flou. Nous dressons ensuite le bilan des diffe´rentes repre´sentations des
textes en terme de qualite´ des re´sultats de classification.
1 Introduction
Les documents nume´riques disponibles sont en nombre perpe´tuellement croissant.
L’inte´reˆt de disposer de me´thodes, de techniques efficaces de classification n’est plus a`
de´montrer et de nombreux travaux de recherche [Sebastiani, 2002, Yang et Liu, 1999]
se focalisent sur cet aspect. Les re´sultats obtenus sont utiles aussi bien pour la recherche
d’information que pour l’extraction de connaissance. L’objectif est de classer de fac¸on
automatique les documents dans des cate´gories qui ont e´te´ de´finies soit pre´alablement
par un expert, il s’agit alors de classification supervise´e ou cate´gorisation, soit de fac¸on
automatique, il s’agit alors de classification non supervise´e ou encore clustering. De
fac¸on tre`s globale, le processus de cate´gorisation de document peut eˆtre de´compose´
selon : (1) une e´tape de formalisation textuelle des documents, (2) une e´tape d’appren-
tissage.
Dans cet article, nous nous inte´resserons plus particulie`rement a` l’impact de la
repre´sentation des documents textuels (et des cate´gories) sur les diffe´rents algorithmes
d’apprentissage (supervise´s ou non). Il existe de nombreuses repre´sentations textuelles
cependant la plus utilise´e est la repre´sentation statistique de type TF -IDF ou` chaque
dimension de l’espace vectoriel correspond a` un e´lement textuel, nomme´ terme d’in-
dexation. Dans [Jaillet et al., 2003], les documents sont repre´sente´s non plus en fonc-
tion des mots qu’ils contiennent mais en fonction d’une projection de ces derniers
sur un ensemble fini de concepts. L’objectif est d’inte´grer plus de se´mantique dans
la mode´lisation des documents. Mais enrichir les donne´es manipule´es ne permet pas
Fouille de texte
toujours d’ame´liorer les re´sultats des approches de cate´gorisation. Dans quelle me-
sure leurs performances sont-elles lie´es a` un mode`le de repre´sentation des documents ?
L’objectif de cet article est donc a` partir d’une base commune de repre´sentation des
documents de comparer les re´sultats des diffe´rentes approches de cate´gorisation de
re´fe´rences dans le domaine dont Rocchio [Rocchio, 1971] et les Support Vector Ma-
chines (SVM) [Joachims, 1998b]. Pour cette e´tude, la base commune est constitue´e
de la repre´sentation statistique de type TF -IDF et de la repre´sentation conceptuelle
des documents de´finie dans [Jaillet et al., 2003]. L’objectif des expe´rimentations est
de mettre ainsi en e´vidence l’impact du mode`le de repre´sentation sur les diffe´rentes
me´thodes de cate´gorisation. L’analyse s’est e´galement porte´e sur l’utilisation du mode`le
de repre´sentation conceptuel (le plus riche se´mantiquement) avec une approche de type
clustering. Le clustering consiste a` diviser les donne´es en groupes sans connaˆıtre a
priori leurs classes d’appartenance. L’ensemble des groupes obtenus n’a de sens, dans
notre contexte, que par l’interpre´tation qui consiste a` e´tiqueter chaque cluster par une
cate´gorie 1. Il devient alors possible de comparer les re´sultats obtenus avec ceux des
me´thodes pre´ce´dentes Rocchio et SVM.
L’article est organise´ de la fac¸on suivante. Dans la section 2, nous pre´sentons
la proble´matique de la cate´gorisation et de´finissons le mode`le de cate´gorisation tex-
tuel (MCT) utilise´. La section 3 de´taille les deux mode`les de repre´sentation : le pre-
mier statistique de type TF -IDF et le second base´ sur les concepts. La section 4
pre´sente les cate´goriseurs : Rocchio [Rocchio, 1971], Support Vector Machine (SVM)
[Joachims, 1998b] ainsi qu’une approche de clustering flou (le subtractive clustering) et
leur formalisation dans le cadre du MCT propose´. Dans la section 5, nous analysons les
diffe´rentes expe´rimentations re´alise´es sur des donne´es issues de de´peˆches de presse. Et
enfin, nous concluons en analysant l’impact de la repre´sentation des documents dans
le processus ge´ne´ral de cate´gorisation.
2 Cate´gorisation de documents
La plupart des algorithmes de cate´gorisation se basent sur des me´thodes d’appren-
tissage qui, a` partir d’un jeu d’entraˆınement, permettent de cate´goriser de nouveaux
documents. Ce type de me´thodes sont dites inductives car elles induisent de la connais-
sance a` partir des donne´es en entre´e (les documents) et des sorties (leurs cate´gories).
Pour re´aliser un processus de cate´gorisation, la premie`re e´tape consiste donc a` for-
maliser les textes afin qu’ils soient utilisables aussi bien pour les algorithmes d’appren-
tissage, que lors de l’e´tape de cate´gorisation. Cette e´tape est bien entendu cruciale car
c’est elle qui permettra ou non aux me´thodes d’apprentissage de produire une bonne
ge´ne´ralisation a` partir du jeu d’entraˆınement.
Le but de la recherche sur la cate´gorisation automatique de textes est donc de
trouver un algorithme permettant d’assigner un texte a` une ou plusieurs cate´gories
avec le plus grand taux de re´ussite possible.
1La strate´gie de la cate´gorie majoritaire dans le cluster est la plus souvent utilise´e mais d’autres
me´thodes sont envisageables.
RNTI - E -
Simon Jaillet et al.
Formellement, un processus de cate´gorisation se de´finit comme une fonction :
Φ˘ : D × C → {V rai, Faux}
Avec D l’ensemble des documents et C l’ensemble des cate´gories.
L’objectif d’un processus de cate´gorisation est donc d’approximer la fonction pre´ce´-
dente par une fonction Φ dans le but de maximiser une fonction d’e´valuation. Le
proble`me de la cate´gorisation peut donc se re´sumer a` trouver un mode`le mathe´matique
capable de repre´senter, afin de comparer la “se´mantique” des textes et des cate´gories.
Dans la suite de l’article, nous utilisons le mode`le de cate´gorisation textuelle de´fini
dans [Jaillet et al., 2003] pour repre´senter les diffe´rentes e´tapes du processus de cate´go-
risation qui sont : (1) L’e´tape de formalisation des documents, (2) L’e´tape de formali-
sation des cate´gories, (3) La de´finition d’une mesure de similarite´ entre documents et
cate´gories, (4) La politique de cate´gorisation.
Le mode`le de cate´gorisation textuel ge´ne´ral MCTGen se de´finit par le tuple :
MCTGen = (MT,MC). MT correspond au mode`le de repre´sentation textuelle dont
l’objectif est de formaliser au mieux la “se´mantique” des documents au sein d’une
repre´sentation mathe´matique. MT se de´finit par le tuple :
MT (VT , RT , repT , VC , C) avec,
VT un vocabulaire qui est un ensemble fini de dimension | VT |
T un ensemble de segments textuels tel que : ∀t ∈ T, t ∈ V ∗T
RT une repre´sentation mathe´matique (espace me´trique, ensemble
ordonne´, etc...)
repT : T → RT une fonction permettant de ge´ne´rer une repre´sentation
r ∈ RT a` partir d’un segment textuel t ∈ T
VC un ensemble de segments textuels fini de dimension | VC |
C un ensemble de cate´gories tel que : C ⊆ P(VC)
MC repre´sente les phases d’apprentissage et de cate´gorisation. Le mode`le de cate´go-
risation MC se de´finit par le tuple :
MC = (RC , repC , simTC,PC) avec,
RC une repre´sentation mathe´matique (espace me´trique,
ensemble ordonne´, etc...)
repC : C → RC une fonction permettant de ge´ne´rer une repre´sentation
r ∈ RC a` partir d’une cate´gorie c ∈ C
simTC : RT ×RC → R+ une relation entre rt ∈ RT , rc ∈ RC
PC : T × C → {0, 1} une politique de cate´gorisation avec t ∈ T, c ∈ C
Nous de´finissons aussi {TApp, TTest} une partition de T de´finissant respectivement
le jeu d’apprentissage et le jeu de test. TApp est utilise´ pour construire repC , TTest sert
seulement lors de l’e´valuation.
RNTI - E -
Fouille de texte
L’intereˆt de ce mode`le est de formaliser et de diffe´rencier chacune des e´tapes du
processus de cate´gorisation : la formalisation des textes et des cate´gories 2 ainsi que
la de´finition d’une mesure de similitude et d’une politique de cate´gorisation. Dans
une proble´matique de cate´gorisation, l’inte´reˆt de repT (formalisation des textes) re´side
dans sa capacite´ a` pouvoir “extraire” l’information du texte ne´cessaire a` une bonne
cate´gorisation. Quant a` l’inte´reˆt de repC (formalisation des cate´gories), il re´side dans sa
capacite´ a` pouvoir mode´liser la notion de cate´gorie, c’est-a`-dire extraire d’un ensemble
de textes l’information qui leur est commune.
Dans la section 3 de´crivant la repre´sentation des documents, nous de´finissons la
partie MT du MCT et dans la section 4 pre´sentant les me´thodes de cate´gorisation,
nous de´veloppons la partie MC du MCT .
3 Repre´sentation des documents
3.1 Les diffe´rentes approches
La repre´sentation textuelle la plus utilise´e est issue de Salton dont l’imple´mentation
la plus connue est SMART [Salton, 1971, Salton et McGill, 1983]. Dans ce formalisme
vectoriel, chaque dimension de l’espace correspond a` un e´lement textuel, nomme´ terme
d’indexation, pre´alablement extrait du jeu d’apprentissage. La construction du vecteur
d’un texte est de´termine´e par des proprie´te´s statistiques de chacun des termes d’in-
dexation du texte en question. C’est ge´ne´ralement une repre´sentation de type TF -IDF
(Term Frequency times Inverse Document Frequency) qui est utilise´ pour construire le
vecteur d’un document.
TF -IDF n’est pas le seul sche´ma de ponde´ration vectoriel, mais c’est un des plus
utilise´s et des plus efficaces [Sebastiani, 2002]. Cependant d’autres repre´sentations tex-
tuelles ont e´te´ expe´rimente´es. La premie`re concerne l’utilisation de phrases, a` la place
de “mots uniques”, comme terme d’indexation. Mais les expe´rimentations effectue´es
n’ont pas e´te´ tre`s fructueuses. Meˆme si les phrases semblent posse´der plus d’infor-
mation se´mantique, leurs proprie´te´s statistiques ne permettent pas de de´finir des hy-
pothe`ses statistiques fiables [Lewis, 1992]. En effet, la faible probabilite´ d’apparition
d’une phrase ne permet pas d’approximer le risque re´el de manie`re correcte graˆce au
risque empirique. Cependant, les recherches dans ce domaine restent actives. D’ailleurs
les travaux de Caropreso et al. [Caropreso et al., 2001] montrent une ame´lioration sen-
sible des re´sultats graˆce a` l’utilisation de phrases statistiques au lieu de phrases syn-
taxiques.
Une autre approche de repre´sentation textuelle “plus se´mantique” se base sur le
Langage Universel d’Echanges (Universal Networking Language ou UNL) de´fini dans
[H. Uchida, 1999]. UNL est un formalisme permettant de repre´senter la “se´mantique”
de chaque document par un graphe. Toute information e´crite en language naturel peut
eˆtre convertie en UNL puis traduite dans n’importe quelle langue cible. La repre´sentation
de type UNL de´finit des liens se´mantiques similaires a` ceux de [Woods, 1993]. En UNL,
2Il est tre`s courant que l’espace de repre´sentation permettant de formaliser les textes et les cate´gories
soit identique (RT = RC). Dans Rocchio par exemple, les textes et les cate´gories sont repre´sente´s par
des vecteurs appartenant au meˆme espace.
RNTI - E -
Simon Jaillet et al.
chaque phrase d’un document est de´finie par un hyper graphe ou` les noeuds sont des
concepts et les arcs oriente´s des relations. Parce que la comparaison de graphes n’est
pas intuitive, Shah et al. de´crit dans [Shah et al., 2002] une me´thode de repre´sentation
de ces graphes pour eˆtre exploite´e dans un processus de cate´gorisation. Ne´anmoins, le
formalisme utilise´ par Shah est aussi un formalisme vectoriel.
Dans [Jaillet et al., 2003], les auteurs proposent une nouvelle me´thode de repre´senta-
tion des documents. Au lieu de de´finir un espace vectoriel dont chaque dimension
repre´sente un terme d’indexation, souvent assimile´ a` un stem (radical), l’ensemble des
termes est projete´ sur un ensemble fini de concepts extrait d’un thesaurus. L’inte´reˆt
d’une telle me´thode est de re´duire les effets polyse´miques du vocabulaire. En effet, deux
synonymes partageront un ensemble de meˆmes concepts. Cette repre´sentation permet
donc une factorisation des termes par regroupement de leur champ se´mantique.
Par ailleurs, d’autres approches utilisent une repre´sentation de type conceptuelle,
c’est le cas de LSI (Latent Semantic Indexing)[Deerwester et al., 1990] et de WCM
(Word Category Map)[Kohonen et al., 2000], afin de re´soudre le proble`me de la syno-
nymie. Cependant l’efficacite´ de ces deux me´thodes de´pend de la distribution de pro-
babilite´ des mots au sein du jeu d’entraˆınement. En effet, comme aucune information
n’est connue a priori, le jeu d’entrainement a une influence cruciale sur la ge´ne´ration
de l’espace de concepts de ces me´thodes, et donc de la repre´sentation textuelle.
3.2 Repre´sentation statistique des documents (TF -IDF )
La majorite´ des approches de cate´gorisation sont axe´es sur une repre´sentation vec-
torielle des textes de type TF -IDF . Cette repre´sentation est aussi tre`s utilise´e en
recherche d’information [Sebastiani, 2002]. TF (term frequency) par IDF (inverse do-
cument frequency) correspond a` la fre´quence d’un terme multiplie´e par l’inverse de sa
fre´quence en document. Pour plus d’information sur la construction d’un tel vecteur le
lecteur se refe`rera a` l’article [Salton et Buckley, 1988].
L’e´tape de repre´sentation textuelle des documents peut-eˆtre formalise´e par le mode`le
MTTF−IDF suivant :
VT l’ensemble des termes d’indexation de dimension | VT |
T un ensemble de textes tel que : ∀t ∈ T, t ∈ VT ∗
R l’espace vectoriel R|VT |
repT : T → R une fonction permettant de ge´ne´rer un vecteur
~r ∈ R a` partir d’un segment textuel t ∈ T
C un ensemble de cate´gories tel que : C ⊆ P(TApp)
La fonction repT se base sur les deux fonctions suivantes :

STEMMER(t)→ LISTE-STEMMES
qui produit une liste de stemmes a` partir d’un texte t ∈ T
VECTEUR(LISTE-STEMMES)→ R|VT |
qui ge´ne`re un vecteur de type TF -IDF a` partir d’une liste de stemmes
RNTI - E -
Fouille de texte
3.3 Repre´sentation conceptuelle des documents
Pour permettre une telle repre´sentation des documents, il est ne´cessaire de pouvoir
projeter n’importe quel mot dans l’espace ge´ne´re´ a` partir d’un ensemble de concepts
pre´de´finis. Comme espace de concepts, nous utilisons un the´saurus compose´ de 873
concepts hie´rarchise´s en 4 niveaux.
Un the´saurus, contrairement a` un dictionnaire, ne donne pas d’informations rela-
tives au sens et a` l’emploi des mots. Un the´saurus permet uniquement d’explorer a`
partir d’un concept (ou ide´e) les mots qui s’y rattachent et inversement. Par exemple,
le mot “me´lodie”, de´fini par les concepts 741,781 et 784 (phrase, musique et chant) du
the´saurus, sera repre´sente´ par un vecteur de dimension 873 dont toutes les composantes
sont nulles sauf celles associe´es aux concepts 741, 781 et 784 qui seront identiques (cf.
figure 1).
                         
                         
                         
                         
                        
                        
                        
                        
1 1 1
741 781 784
(dim = 873)
Phrase Musique Chant
mélodie
Fig. 1 – Repre´sentation conceptuelle du mot me´lodie.
Le the´saurus est donc de´fini comme un ensemble de couples de L × R873 avec L
l’ensemble des lemmes du the´saurus.
Bien que se basant aussi sur le formalisme vectoriel pour repre´senter les docu-
ments, cette repre´sentation reste fondamentalement diffe´rente de la repre´sentation sal-
tonnienne [Salton et McGill, 1983]. Les dimensions de l’espace vectoriel ne sont pas as-
socie´es ici a` des termes d’indexation mais a` des concepts comme dans [Chauche´, 1990].
Cependant, l’inconve´nient majeur de cette repre´sentation reste que les noms propres
du document ne sont pas pris en compte. En effet, ces derniers, e´tant se´mantiquement
vides par de´finition, ne posse`dent pas de repre´sentation au sein du the´saurus.
Les vecteurs conceptuels des textes ont e´te´ ge´ne´re´s a` l’aide du the´saurus et du
lemmatiseur de´fini dans [Schmid, 1994]. Meˆme si ce type lemmatiseur reste limite´ pour
ce qui est de l’analyse syntaxique, il offre ne´anmoins l’avantage de fonctionner dans
toutes les langues.
L’e´tape de repre´sentation textuelle des documents peut-eˆtre formalise´e par le mode`le
MTConcept suivant :
RNTI - E -
Simon Jaillet et al.

VT l’ensemble des termes d’indexation de dimension | VT |
T un ensemble de textes tels que : ∀t ∈ T, t ∈ VT ∗
R l’espace vectoriel R|VT |
repT : T → R une fonction permettant de ge´ne´rer un vecteur
~r ∈ R a` partir d’un segment textuel t ∈ T
C un ensemble de cate´gories tel que : C ⊆ P(TApp)
La fonction repT , se base sur les trois fonctions suivantes :

TREE-TAGGER(t)→ LISTE-LEMMES
qui produit une liste de lemmes a` partir d’un texte t ∈ T
VECTEUR(LEMMES)→ R873
qui ge´ne`re un vecteur a` partir d’une liste de lemmes
THESAURUS(l)→ R873
qui associe a` chaque lemme l ∈ L du the´saurus un vecteur ∈ R873
Apre`s avoir extrait l’ensemble des lemmes d’un texte, une association, graˆce a` la
fonction THESAURUS, est re´alise´e entre les lemmes et le vecteur qui leur est associe´
au sein du the´saurus. Ensuite, le vecteur conceptuel de chaque texte est calcule´ en
fonction de la moyenne normalise´e des lemmes qu’il contient :
~rt =
~rl1 + ~rl2 + ...+ ~rln
|| ~rl1 + ~rl2 + ...+ ~rln ||
4 Les approches de cate´gorisation
Pour comparer l’impact de la repre´sentation des documents sur les me´thodes de
cate´gorisation, nous avons choisi deux cate´goriseurs : Rocchio [Rocchio, 1971] et les
machines a` vecteur de support (SVM) [Burges, 1998] ainsi qu’une approche de cluste-
ring flou, le subtractive clustering (regroupement par soustraction - RS) [Chiu, 1994].
Nous pre´sentons ces trois me´thodes selon le mode`le de cate´gorisation MC.
4.1 Rocchio
Rocchio [Rocchio, 1971] est l’une des me´thodes les plus anciennes en cate´gorisation.
Nous la de´finissons ici dans sa version initiale. Les cate´gories sont repre´sente´es dans
une espace vectoriel similaire aux documents. En effet, le vecteur d’une cate´gorie est
de´fini comme la moyenne des vecteurs des textes qu’elle contient (repC).
Une fois les textes et les cate´gories repre´sente´s dans un meˆme espace, la simili-
tude entre un texte et une cate´gorie est de´finie par la distance euclidienne (sim).
Par conse´quent, la politique de cate´gorisation se re´sume a` associer a` chaque texte la
cate´gorie dont la distance euclidienne est la plus proche (PC).
RNTI - E -
Fouille de texte
Sans de´tailler les algorithmes repCRocchio , simRocchio et PCRocchio triviaux, nous
repre´senterons la me´thode Rocchio graˆce au mode`le MCRocchio suivant :
C un ensemble de cate´gories tel que : C ⊆ P (TApp).
repCRocchio : C → R la fonction permettant de ge´ne´rer un vecteur
rc ∈ RC a` partir d’une cate´gorie c ∈ C.
simRocchio : RT ×RC → R la distance euclidienne entre rt et rc avec
rt ∈ RT , rc ∈ RC .
PCRocchio : T × C → {0, 1} la politique de cate´gorisation de´finie avec t ∈ T, c ∈ C.
4.2 Machine a` vecteur de support
Les machines a` vecteur de support (SVM) sont a` l’origine de nouvelles me´thodes
de cate´gorisation [Joachims, 1998b] bien que les premie`res publications sur le sujet
datent des anne´es 60 [Vapnik et Chervonenkis, 1964]. Le principe des SVM consiste
en une strate´gie de minimisation structurelle du risque [Vapnik, 1995]. Le lecteur
peut se re´fe´rer a` [Burges, 1998] pour une pre´sentation ge´ne´rale de la me´thode. En
ce qui concerne son application a` la proble´matique de cate´gorisation de documents,
l’approche par SVM permet de de´finir, par apprentissage, une surface de se´paration
entre des exemples positifs et ne´gatifs minimisant le risque d’erreur et maximisant la
marge entre deux cate´gories. La figure 2 montre une telle se´paration dans le cas d’une
se´paration line´aire par un hyperplan. Il est inte´ressant de remarquer qu’en re´duisant
le jeu d’entraˆınement uniquement aux vecteurs de support, l’algorithme calculerait le
meˆme hyperplan que pour le jeu d’entraˆınement complet. La marge se pre´sente alors
comme la plus courte distance entre un vecteur de support et “son” hyperplan.
De manie`re formelle, un hyperplan peut eˆtre de´fini par :
~w · ~x− b = 0
Avec ~x un point arbitraire, ~w un vecteur et b le biais.
Soit D = {(~xi, yi)} notre jeu d’entraˆınement et yi ∈ {±1} de´finissant l’e´tat, positif
ou ne´gatif, de l’exemple. Trouver l’hyperplan maximisant la marge se´paratice ( 2||w|| )
revient a` re´soudre le proble`me suivant :
{
minimiser 12 ||w||2 + Csvm
∑
ξi
sous les contraintes ∀i, yi(~w · ~xi + b)− 1 + ξi ≥ 0 (avec ξi ≥ 0)
Csvm est un parame`tre utilisateur. Le parameˆtre Csvm correspond a` la pe´nalite´
affecte´ a` chaque erreur. Plus Csvm est e´leve´, plus l’erreur est conside´re´e comme impor-
tante.
Graˆce a` une extention de cet algorithme, il est aussi possible de re´soudre des
proble`mes qui ne sont pas line´airement se´parables, mais l’ame´lioration obtenue pour la
cate´gorisation de documents reste minime selon [Joachims, 1998b]. En ce qui concerne
la repre´sentation vectorielle des textes, ce sont en ge´ne´ral les stemmes (radicaux) qui
sont utilise´s comme termes d’indexation.
RNTI - E -
Simon Jaillet et al.
1
||W||
ι
Hyperplan
Marge de
séparation
σ (x)=0
: Support
: Exemple positif
: Exemple négatif
.
Fig. 2 – Repre´sentation de l’hyperplan optimal
On repre´sentera la cate´gorisation par SVM line´aire graˆce au mode`le MCSVM sui-
vant :
C un ensemble de cate´gories tel que : C ⊆ P (TApp).
RC un ensemble d’hyperplans .
repCSVM : C → RC la fonction permettant de ge´ne´rer un hyperplan
rc ∈ RC a` partir d’une cate´gorie c ∈ C.
simSVM : RT ×RC → R la position du point rt par rapport a` l’hyperplan rc avec
rt ∈ R, rc ∈ RC .
PCSVM : T × C → {0, 1} la politique de cate´gorisation de´finie avec t ∈ T, c ∈ C.
Avec pour repCSVM , simSVM les algorithmes suivants :
Algorithm 1: repCSVM
Data : Une cate´gorie c ∈ C
Result : Une repre´sentation rc ∈ RC
begin
// c¯ est de´fini comme le comple´mentaire de c sur C
c¯ = C − c;
rc =l’hyperplan maximisant la marge entre c¯ et c et minimisant l’erreur;
return rc;
end
Nous ne de´taillerons pas PCSVM qui est trivialement base´ sur le re´sultat de la
fonction simSVM .
RNTI - E -
Fouille de texte
Algorithm 2: simSVM
Data : Deux repre´sentations ~r1 ∈ R, r2 = (~w, b) ∈ RC
Result : Un boole´en ∈ {0, 1}
begin
~w = la normale de r2;
b = la constante de r2;
//Calcule la position de ~r1 par rapport a` l’hyperplan r2
if (~r1 · ~w + b ≥ 1) then
return 1;
else
return 0;
end
4.3 Clustering flou
Le clustering flou consiste regrouper un ensemble de n objets au sein de c partitions
diffe´rentes. L’e´tat d’une partition est exprime´ par une matrice U = (uij) de dimension
c× n, ou` :
uij ∈ [0, 1], i = 1, . . . , c, j = 1, . . . , n (1)
Dans ce cas, uij repre´sente “le degre´ d’appartenance” du j-e`me objet a` la i-e`me par-
tition. Les premiers travaux sur l’application du concept de sous-ensembles flous dans
l’analyse du clustering ont e´te´ effectue´s par Ruspini [Ruspini, 1969].
La recherche de toutes les combinaisons possibles, a` partir des donne´es d’appren-
tissage, pour l’obtention de ces partitions est quasi impossible.
De ce fait, plusieurs me´thodes ont e´te´ de´veloppe´es pour obtenir le clustering flou
[Sato et al., 1997, Bezdek, 1981, Chiu, 1994, Ruspini, 1969]. Dans cet article nous trai-
tons de la me´thode du subtractive clustering (Regroupement par Soustraction - RS)
propose´e par Chiu [Chiu, 1994] applique´e au proble`me de la cate´gorisation de textes.
On repre´sente la cate´gorisation par la me´thode du subtractive clustering par le
mode`le MCSC suivant :
RC Un ensemble de clusters et leurs fonctions d’appartenance
repCRS : C → RC L’algorithme permettant d’obtenir les clusters
r ∈ RC relatif a` une cate´gorie c ∈ C.
simRS : RT ×RC → R+ Le degre´ d’appartenance du vecteur rt ∈ R
au cluster rc ∈ RC .
PCRS : T × C → {0, 1} La politique de cate´gorisation avec t ∈ T, c ∈ C.
Le principe du subtractive clustering est de´crit par l’algorithme 3 repCSC .
Les parame`tres de de´part du RS sont Ra, Rb, εinf et εsup ou` :
– Ra = [ra1 , . . . , rap ] est un vecteur rayon qui de´finit d’une part, la taille de la zone
servant a` calculer la densite´ de voisinage, et d’autre part, la taille des groupe-
ments. Chacune des composantes raj spe´cifie le rayon dans la j
e`me dimension.
RNTI - E -
Simon Jaillet et al.
– Rb = [rb1 , . . . , rbp ] est un vecteur qui de´finit la distance minimale entre deux
groupements dans chaque dimension.
– εinf et εsup sont des scalaires servant a` arreˆter le processus de se´lection des
groupements.
Le choix des rayons raj est de´terminant car il influe fortement sur le re´sultat final
du regroupement. Leurs valeurs sont fixe´es suivant la base de donne´es e´tudie´e. Quant
aux autres parame`tres, nous obtenons en pratique des re´sultats plutoˆt satisfaisants en
posant rbj = 1.5 raj , εsup = 0.5 et εinf = 0.15. La valeur de ces parame`tres est estime´e
empiriquement par Chiu.
Algorithm 3: repCRS
Etape 1
1. Fixer les parame`tres Ra, Rb, εinf et εsup.
2. Pour chaque point xi, initialiser la densite´ Pxi suivant l’e´quation
Pxi(1) =
n∑
l=1
e
−4
∑p
j=1
(
xi,j−xl,j
raj
)2
(2)
3. Accepter x∗1 comme un groupement tel que Px∗1 = maxi(Pxi).
Etape 2
1. Mettre a` jour chaque Pxi suivant l’e´quation
Pxi(k + 1) = Pxi(k)− Px∗k(k) e
−4
∑p
j=1
(
xi,j−x∗k,j
rbj
)2
(3)
2. Poser Px∗
k
= maxi(Pxi).
3. Si Px∗
k
> εsup Px∗1
Alors accepter x∗k comme un groupement, et aller a` 1.
4. Si Px∗
k
< εsup Px∗1 et Px∗k ≥ εinf Px∗1
Alors poser dmin comme la plus petite des distances entre x∗k et
tous centres des groupements trouve´s pre´ce´demment x∗l :
d2min = min
l=1,..,(k−1)
{
p∑
j=1
(
x∗k,j − x∗l,j
raj
)2}
(4)
Sinon aller a` 6.
5. Si dmin +
Px∗
k
Px∗
1
≥ 1
Alors accepter x∗k comme un groupement, et aller a` 1.
Sinon rejeter x∗k, initialiser le potentiel de x
∗
k a` 0, et aller a` 2.
6. Arreˆter la proce´dure de se´lection.
RNTI - E -
Fouille de texte
Le RS proce`de en deux e´tapes. Dans la premie`re e´tape, il e´value une fonction pour
le guider dans la recherche de centres de groupement. Cette fonction correspond a` une
mesure de densite´ de voisinage effectue´e a` l’inte´rieur d’un noyau gaussien. L’emploi
d’un noyau gaussien permet de ponde´rer l’influence des points : un point proche du
centre a un roˆle plus important dans la mesure de la densite´ Pxi qu’un point e´loigne´.
La largeur du noyau est de´finie par le vecteur rayon Ra.
Dans la seconde e´tape, le RS recherche ite´rativement les centres de groupements.
L’algorithme se´lectionne d’abord le point dont la densite´ est maximale. Puis, pour
e´viter de choisir un autre groupement trop proche, toutes les mesures Pxi sont mises a`
jour de sorte que la mesure d’un point se trouvant a` proximite´ du point se´lectionne´ se
voit diminuer de manie`re importante. Cette mise a` jour de la densite´ a peu d’influence
sur la mesure d’un point qui se trouve a` une distance supe´rieure a` ‖Rb‖ =
∑p
j=1 r
2
bj
du
point se´lectionne´. Le RS re´ite`re plusieurs fois le processus jusqu’a` ce que le test d’arreˆt
soit ve´rifie´.
Les points 4 a` 6 de la seconde e´tape servent a` tester l’arreˆt du processus de se´lection.
Le test d’arreˆt du RS est de´fini par un intervalle. Si la mesure du point se´lectionne´
tombe dans l’intervalle, alors nous acceptons le point se´lectionne´ comme centre de
groupement suivant une certaine condition. En l’occurrence, la somme entre dmin et
le rapport Px∗
k
/Px∗1 doit eˆtre supe´rieure a` 1. Si la condition n’est pas ve´rifie´e, alors
le point n’est pas retenu comme centre de groupement, et nous re´ite´rons. Enfin, si la
mesure du point se´lectionne´ de´passe l’intervalle, alors l’algorithme s’arreˆte.
Il est important de pre´ciser qu’a` ce stade de la me´thode, aucune information sur
les classes d’appartenance des textes n’a e´te´ prise en compte. C’est uniquement dans
la strate´gie finale de cate´gorisation (simSC , PCSC) que sera utilise´e cette information.
La relation simTC(~r1, x∗k) repre´sente le degre´ d’appartenance µk(~r1) du vecteur ~r1
au centre k de coordonne´es x∗k et de rayon d’influence Ra.
La politique de cate´gorisation PCSC consiste a` e´tiqueter chaque cluster par la classe
majoritaire a` l’inte´rieur de celui-ci. Lorsqu’un nouveau vecteur est pre´sente´, la classe
du cluster posse´dant le plus grand degre´ d’appartenance lui est attribue´e.
5 Expe´rimentations
Les deux me´thodes de cate´gorisation sont teste´es sur les deux types de repre´sentation
propose´s : la repre´sentation statistique (de type TF -IDF ) et la repre´sentation par
concept. L’approche par clustering, quant’a` elle, n’est applique´e qu’a` la repre´sentation
conceptuelle des documents.
5.1 Les donne´es
Pour la re´alisation des expe´riences, nous avons utilise´ un jeu de donne´es compose´
de 8239 de´peˆches de presse re´parties en 28 cate´gories (cf. tableau 1). Pour effectuer
la repre´sentation conceptuelle des textes, un espace vectoriel de dimension 873 a e´te´
construit a` partir d’un The´saurus de re´fe´rence. Enfin, un ensemble de 10974 stems
(radicaux) diffe´rents a e´te´ extrait du jeu d’entraˆınement pour la repre´sentation de type
TF -IDF .
RNTI - E -
Simon Jaillet et al.
Algorithm 4: simRS
Data : Deux repre´sentations ~r1 ∈ RT , r2 = ( ~x∗k, Ra) ∈ RC
x∗k = [x
∗
k,1, ..., x
∗
k,p] Ra = [ra1 , ..., rap ].
Result : Un re´el ∈ [0, 1]
begin
La fonction d’appartenance µk associe´e au groupement est de´finie par :
Soit v = [ v1 , . . . , vp ] ∈ Rp,
dk = t(v − x∗k)Mk (v − x∗k)avec Mk =
 1/r
2
a1 0
. . .
0 1/r2ap
 (5)
et,
dk,j = |vj − x∗k,j | (6)
on a,
µk(v) = e−4 d
2
k = e
−4
∑p
j=1
(
dk,j
raj
)2
(7)
ou` dk est la distance euclidienne ponde´re´e entre le groupement x∗k et l’e´le´ment
v, et dk,j est la distance par dimension j entre le groupement x∗k et l’e´le´ment
v.
end
5.2 Estimation des performances des mode`les
5.2.1 Mesures des performances
Pour e´valuer les performances des me´thodes de cate´gorisation, nous utilisons la
mesure Fβ [Rijsbergen, 1979] :
De´finition 1 Fβ :
Fβ =
(β2 + 1)piiρi
β2pii + ρi
Fβ est base´e sur les notions de rappel (nombre de textes bien classe´s sur le nombre
total de textes a` cate´goriser) et de pre´cision (nombre de textes bien classe´s sur le
nombre de textes classe´s dans cette cate´gorie) de´finies ci-dessous :
De´finition 2 Rappel et pre´cision :
pii =
V Pi
V Pi + FPi
, ρi =
V Pi
V Pi + FNi
avec V Pi, FPi, FNi de´finissant, pour une cate´gorie i, respectivement les textes bien
classe´s, les textes assigne´s par erreur ainsi que les textes omis par le classifieur.
RNTI - E -
Fouille de texte
Nom de la cate´gorie i Nombre de documents
Nouvelles internationales 943
Agriculture-Agroalimentaire 305
Banque-Finance-Assurance 352
Administration-Institution 310
Automobile-Construction me´canique 278
Ae´ronautique-Naval-De´fense 303
Enseignement-Formation 268
Electronique-Construction e´lectrique 229
Communication-Media-Pub-Culture 353
Distribution-Commerce 256
Hotellerie-Restauration 217
Immobilier-BTP-Logement 229
Industries Extractives-Matie`res 306
Industries Diverses 254
Internet-Commerce e´lectronique 219
Informatique-Bureautique-SSII 270
Luxe-Mode-Textile 259
Sante´-Pharma-Chimie 311
Services aux entreprises 170
Services aux particuliers 171
Te´le´coms 325
Transports-Logistique 322
Achat-Logistique 263
Direction 300
Finance 331
Marketing-Communication 193
Ressources humaines 278
Commercial Vente 224
Tab. 1 – Nombre de documents par cate´gories
Par la suite, nous utiliserons la politique du ”microaveraging” pour e´valuer le clas-
sifieur dans sa globalite´. C’est la mesure la plus utilise´e pour comparer des me´thodes
de cate´gorisation entres elles [Sebastiani, 2002, Yang, 1999].
De´finition 3 microaveraging :
piµ =
∑|C|
i=1 V Pi∑|C|
i=1(V Pi + FPi)
, ρµ =
∑|C|
i=1 V Pi∑|C|
i=1(V Pi + FNi)
Cette mesure accorde la meˆme importance a` la performance de chaque document
contrairement a` la “macro-averaging” qui re´alise une moyenne par cate´gorie.
RNTI - E -
Simon Jaillet et al.
5.2.2 Validation croise´e
Pour e´viter les phe´nome`nes de biais introduits par le de´coupage de la base de
donne´es en ensembles d’apprentissage et de test, nous avons opte´ pour une validation
croise´e de nos me´thodes. Nous avons se´pare´ la base initiale en dix sous-ensembles tout
en conservant la proportion des cate´gories. Puis nous avons applique´ les me´thodes
pre´sente´es pre´ce´demment sur neuf des sous-ensembles et estimer les performances sur
le dixie`me sous-ensemble. Ces ope´rations ont e´te´ re´pe´te´es dix fois. Nous avons ainsi
obtenu dix mesures de performances pour chaque me´thode de cate´gorisation. Mesures
que nous avons ensuite agre´ge´es par une moyenne pour obtenir la performance globale
de chaque me´thode.
5.3 Re´sultats
Pour la me´thode des SVM, nous avons utilise´ son imple´mentation line´aire a` l’aide du
package SVMLight [Joachims, 1998a] avec comme parame`tre Csvm de´fini dans {5, 20, 50}
pour la repre´sentation conceptuelle et Csvm de´fini dans {0.1, 10, 100} pour la repre´senta-
tion de type TF -IDF . La me´thode du subtractive clustering a e´te´ imple´mente´e sous
MATLAB. Les meilleurs re´sultats ont e´te´ obtenus pour des parame`tres ra fixe´s tous
e´gaux a` 0.85, les autres parame`tres e´tant re´gle´s en utilisant les valeurs pre´conise´es
par Chiu [Chiu, 1994]. Cette me´thode a e´te´ utilise´e uniquement sur la repre´sentation
conceptuelle. La dimension de l’espace de repre´sentation TF -IDF ne permet pas d’uti-
liser cette me´thode dans sa version originale. Celle-ci doit faire l’objet de modifications
permettant de de´finir une fonction d’appartenance adapte´e a` cet espace.
Le Tableau 2 pre´sente les re´sultats obtenus par les trois me´thodes en utilisant la
repre´sentation par vecteurs conceptuels. Dans cet espace, la me´thode SVM donne les
re´sultats les meilleurs, proches cependant la me´thode de Rocchio. Les re´sultats de la
me´thode du SC originale sont, quant a` eux, un peu en retrait par rapport aux re´sultats
de ces me´thodes. Une premie`re analyse plus de´taille´e montre que les clusters identifie´s
par l’algorithme ne posse`de pas de cate´gorie a` majorite´ franche. En effet, la plus part
d’entre eux posse`dent plusieurs cate´gories en proportions tre`s proches. Ce proble`me
semble eˆtre du a` une localisation tre`s dense des vecteurs dans une portion re´duite de
l’espace (l’angle le plus e´leve´ entre deux vecteurs est d’une dizaine de degre´s). Dans ces
conditions, la distance euclidienne utilise´e dans le calcul des fonctions d’appartenance
n’est pas suffisamment discriminante pour de´terminer les meilleurs clusters a` l’aide
d’une me´thode non supervise´e. Cependant, les re´sultats obtenus par cette me´thode
sont assez prometteurs pour que les travaux sur le clustering flou soient poursuivis ;
notamment, pour le choix des fonctions d’appartenance et des distances a` utiliser.
Le Tableau 3 re´sume les re´sultats de la validation croise´e obtenus par les me´thodes
de Rocchio et de SVM sur la repre´sentation TF -IDF . Dans cet espace, a` l’inverse
du pre´ce´dent, c’est la me´thode de Rocchio qui donne les meilleurs re´sultats. Cette
expe´rience met tout d’abord en e´vidence les choix critiques de l’espace de repre´sentation
et de la me´thode de classification dans une proble´matique de cate´gorisation auto-
matique de documents. De plus, il montre l’influence du corpus sur les me´thodes de
cate´gorisation. En effet, si SVM reste le meilleur cate´goriseur pour les corpus de type
Reuters [Sebastiani, 2002, Yang et Liu, 1999], ce n’est pas le cas ici pour notre cor-
RNTI - E -
Fouille de texte
Echantillon Fµ1 sur les 28 categories
de la Validation Rocc. SVM avec Csvm e´gale a` SC
Croise´e 5 20 50
1 0.34 0.36 0.39 0.38 0.27
2 0.38 0.41 0.42 0.39 0.27
3 0.37 0.42 0.46 0.43 0.32
4 0.36 0.40 0.47 0.46 0.29
5 0.36 0.44 0.48 0.45 0.29
6 0.39 0.46 0.51 0.50 0.29
7 0.37 0.44 0.48 0.44 0.29
8 0.34 0.43 0.46 0.46 0.32
9 0.33 0.40 0.46 0.43 0.30
10 0.35 0.42 0.46 0.43 0.31
Moyenne Fµ1 0.36 0.42 0.46 0.44 0.30
Tab. 2 – Re´sultats des me´thodes de cate´gorisation sur la repre´sentation conceptuelle
des textes
pus francophone. Cependant, la cate´gorisation a` base de SVM reste stable pour les
deux types de repre´sentation textuelles contrairement a` Rocchio qui s’e´croule lors de
la repre´sentation conceptuelle des textes.
La mauvaise performance de Rocchio sur la repre´sentation conceptuelle s’explique
par le fait suivant : les dimensions les plus “value´es” des vecteurs ne sont pas force-
ment les plus dicriminantes. En effet les concepts discriminants sont ge´ne´ralement des
concepts “rares” ayant une faible valuation au sein des vecteurs. [Jaillet et al., 2003]
ont d’ailleurs montre´ la “non-optimalite´” du cosinus, comme mesure de similarite´, sur
ce type de vecteurs. En revanche, SVM se montre pratiquement stable sur les deux
types de repre´sentation. Cette stabilite´ s’explique par le fait que SVM utilise un algo-
rithme d’apprentissage qui minimise le risque structurel. Par conse´quent l’importance
de chacune des dimensions (c’est a` dire des concepts) ne de´pend pas uniquement de la
valuation de ce dernier.
6 Conclusion
Les expe´riences effectue´es dans cet article permettent de mieux comprendre les
particularite´s des me´thodes de cate´gorisation. Tout d’abord, les re´sultats obtenus sou-
lignent la stabilite´ de la me´thode de cate´gorisation base´e sur les SVM quelque soit la
repre´sentation des documents utilise´e. Ne´anmoins, pour la repre´sentation de type TF -
IDF , SVM, conside´re´e comme la meilleure me´thode de cate´gorisation [Sebastiani, 2002,
Yang et Liu, 1999], a obtenu des performances infe´rieures a` celles de Rocchio sur notre
jeu de de´peˆches francophones. Enfin, meˆme si le mode`le de repre´sentation est plus
riche, l’utilisation de me´thodes de cate´gorisation classiques ne permet pas toujours
d’ame´liorer les performances. C’est pourquoi, il est souvent ne´cessaire de proposer de
RNTI - E -
Simon Jaillet et al.
Echantillon Fµ1 sur les 28 categories
de la Validation Rocc. SVM avec Csvm e´gale a`
Croise´e 5 20 50
1 0.51 0.38 0.38 0.38
2 0.55 0.44 0.44 0.44
3 0.56 0.48 0.48 0.47
4 0.56 0.51 0.52 0.51
5 0.59 0.50 0.50 0.50
6 0.60 0.51 0.51 0.51
7 0.58 0.49 0.50 0.48
8 0.55 0.48 0.49 0.48
9 0.52 0.50 0.52 0.50
10 0.53 0.47 0.48 0.47
Moyenne Fµ1 0.55 0.47 0.48 0.47
Tab. 3 – Re´sultats des me´thodes de cate´gorisation sur la repre´sentation de type TF -
IDF des textes
nouveaux classifieurs re´ellement adapte´s comme la me´thode des deux e´carts de´finie
pour une repre´sentation des textes base´e sur les concepts [Jaillet et al., 2003].
Cette e´tude permet d’envisager plusieurs perspectives. Tout d’abord, il serait inte´res-
sant d’approfondir les expe´rimentations afin d’e´valuer l’influence du corpus sur les
me´thodes de repre´sentation. Les jeux de donne´es du type ”Nouvelles” ou d’articles
plus longs vont modifier ne´cessairement le choix de la me´thode de repre´sentation. Dans
quelle mesure est-il inte´ressant d’inte´grer une mode´lisation plus se´mantique des textes
pour des articles courts ? Dans quelle mesure les performances du cate´goriseur sont-elles
ame´liore´es et a` quel prix ? Il serait e´galement inte´ressant d’envisager une repre´sentation
mixte, couplant les deux me´thodes de repre´sentation, inte´grant les avantages de la
repre´sentation statistique (TF -IDF ) et conceptuelle donnant ainsi la possibilite´ d’uti-
liser des classifieurs standards.
Re´fe´rences
[Bezdek, 1981] J. C. Bezdek. Pattern Recognition with Fuzzy Objective Function Algo-
rithm. New York, Plenum Press, 1981.
[Burges, 1998] Christopher J. C. Burges. A tutorial on support vector machines for
pattern recognition. Data Mining and Knowledge Discovery, 2(2) :121–167, 1998.
[Caropreso et al., 2001] M. Caropreso, S. Matwin, et F. Sebastiani. A learner-
independent evaluation of the usefulness of statistical phrases for automated text
categorization. In Text Databases and Document Management : Theory and Prac-
tice, pages 78–102. 2001.
[Chauche´, 1990] J. Chauche´. De´termination se´mantique en analyse structurelle : une
expe´rience base´e sur une de´finition de distance. TA Information, 31/1 :17–24, 1990.
RNTI - E -
Fouille de texte
[Chiu, 1994] S. L. Chiu. Fuzzy model identification based on cluster estimation. Jour-
nal of Intelligent and Fuzzy Systems, 2 :267–278, 1994.
[Deerwester et al., 1990] Scott C. Deerwester, Susan T. Dumais, Thomas K. Landauer,
George W. Furnas, et Richard A. Harshman. Indexing by latent semantic analysis.
Journal of the American Society of Information Science, 41(6) :391–407, 1990.
[H. Uchida, 1999] T. Della Senta H. Uchida, M. Zhu. The UNL, A Gift for a Millen-
nium. UNU Institute of Advanced Studies, 1999.
[Jaillet et al., 2003] Simon Jaillet, Maguelonne Teisseire, Jacques Chauche, et Violaine
Prince. Classification automatique de documents : Le coefficient des deux e´carts. In
INFORSID, pages 87–102, Nancy, 2003.
[Joachims, 1998a] T. Joachims. Making large-scale support vector machine learning
practical. In Advances in Kernel Methods : Support Vector Machines. 1998.
[Joachims, 1998b] Thorsten Joachims. Text categorization with support vector ma-
chines : learning with many relevant features. In Proceedings of ECML-98, 10th
European Conference on Machine Learning, pages 137–142, 1998.
[Kohonen et al., 2000] T. Kohonen, S. Kaski, K. Lagus, J. Saloja¨rvi, J. Honkela,
V. Paatero, et A. Saarela. Self organization of a massive document collection. IEEE
Transactions on Neural Networks, 11(3) :574–585, 2000.
[Lewis, 1992] D.D. Lewis. An evaluation of phrasal and clustered representations on a
text categorization task. In ACM SIGIR ’92, pages 37–50, 1992.
[Rijsbergen, 1979] C. J. Van Rijsbergen. Information retrieval. Butterworths, London,
2 edition, 1979.
[Rocchio, 1971] J. Rocchio. Revelance feedback in information retrieval. In in the
SMART Retrieval System : Experiments in Automatic Document Processing, pages
313–323, 1971.
[Ruspini, 1969] E. H. Ruspini. A new approach to clustering. Inform. Control.,
15(1) :22–32, 1969.
[Salton et Buckley, 1988] G. Salton et C. Buckley. Term weighting approaches in au-
tomatic text retrieval. Information Processing and Management, 24(5) :513–523,
1988.
[Salton et McGill, 1983] G. Salton et M. J. McGill. Introduction to modern information
retrieval. 1983.
[Salton, 1971] G. Salton. The smart retrieval system – experiments in automatic do-
cument processing, 1971.
[Sato et al., 1997] S. Sato, Y. Sato, et L. C. Jain. Fuzzy Clustering Models and Appli-
cations. Physica-Verlag Heidelberg, A Springer-Verlag Company, 1997.
[Schmid, 1994] H. Schmid. Probabilistic part-of-speech tagging using decision trees.
In International Conference on New Methods in Language Processing, 1994.
[Sebastiani, 2002] Fabrizio Sebastiani. Machine learning in automated text categori-
sation. In Proceedings of ACM Computing Surveys, volume 34, pages 1–47, 2002.
RNTI - E -
Simon Jaillet et al.
[Shah et al., 2002] C. Shah, B. Chowdhary, et P. Bhattacharyya. Constructing better
document vectors universal networking language (unl). In Proceedings of Interna-
tional Conference on Knowledge-Based Computer Systems, 2002.
[Vapnik et Chervonenkis, 1964] V. Vapnik et A. Chervonenkis. A note on one class of
perceptrons. Automatic and Remote Control, 25, 1964.
[Vapnik, 1995] V. Vapnik. The Nature Of Statistical Learnig Theory. Springer, 1995.
[Woods, 1993] W. Woods. What’s in a link : Foundation for semantic network. Journal
of Documentation, 49 :188–207, 1993.
[Yang et Liu, 1999] Y. Yang et X. Liu. A re-examination of text categorization me-
thods. In 22nd Annual International SIGIR, pages 42–49, 1999.
[Yang, 1999] Yiming Yang. An evaluation of statistical approaches to text categoriza-
tion. Information Retrieval, 1(1/2) :69–90, 1999.
RNTI - E -
1RNTI - E -  
 
 
 
 
 
 
 
 
