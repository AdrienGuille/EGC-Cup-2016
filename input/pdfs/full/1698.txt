Contr√¥le du risque multiple pour la s√©lection de r√®gles
d'association significatives
St√©phane Lallich
‚àó
, Elie Prudhomme
‚àó
, Olivier Teytaud
‚àó‚àó
‚àó
Laboratoire E.R.I.C, Universit√© Lumi√®re Lyon 2
5, avenue Pierre Mend√®s-France, 69676 BRON Cedex  France
stephane.lallich@univ-lyon2.fr, Elie.Prudhomme@etu.univ-lyon2.fr
‚àó‚àó
Artelys
215 avenue Jean-Jacques Rousseau, 92136 Issy-les-Moulineaux
olivier.teytaud@artelys.com
R√©sum√©. Les algorithmes d'extraction de r√®gles d'association parcourent
efficacement le treillis des itemsets pour constituer une base de r√®gles ad-
missibles √† des seuils de support et de confiance, mais donnent une mul-
titude de r√®gles peu exploitables. Nous sugg√©rons d'√©purer de telles bases
en √©liminant les r√®gles non statistiquement significatives. La multitude de
tests pratiqu√©s conduit m√©caniquement √† multiplier les r√®gles s√©lection-
n√©es √† tort. Apr√®s avoir pr√©sent√© des proc√©dures issues de la biostatistique
qui contr√¥lent non pas le risque, mais le nombre de fausses d√©couvertes,
nous proposons BS_FD, un algorithme original fond√© sur le bootstrap
qui s√©lectionne les r√®gles significatives en contr√¥lant le nombre de fausses
d√©couvertes. Des exp√©rimentations montrent l'efficacit√© de ces proc√©dures.
Mots-clefs : R√®gle d'association, qualit√©, contr√¥le du risque multiple.
1 Admissibilit√©, int√©r√™t et signification statistique
La recherche des r√®gles d'association int√©ressantes est un probl√®me classique de
l'Extraction des Connaissances √† partir des Donn√©es √† la suite des travaux de [Agrawal
et al., 1993] dans le cadre des bases de donn√©es transactionnelles. Dans une telle base, un
enregistrement est une transaction et les champs correspondent aux articles disponibles.
On note n le nombre de transactions et p le nombre d'articles. L'acte d'achat (item)
associ√© √† chaque article est une variable bool√©enne. Sur l'ensemble des transactions,
on a une matrice bool√©enne X, de dimensions n et p. La conjonction des actes d'achat
(itemset) associ√©s √† un ensemble d'articles est vue comme une variable bool√©enne.
A partir de la matrice bool√©enne X, on veut extraire des r√®gles du type "si un client
ach√®te du pain et du fromage, alors probablement il ach√®te aussi du vin". Une r√®gle
d'association est une expression r du type A‚Üí B, o√π l'ant√©c√©dent A et le cons√©quent
B sont des itemsets qui n'ont pas d'items communs. On note na et nb les nombres
de transactions qui r√©alisent respectivement les items de A et de B, nab le nombre de
celles qui r√©alisent √† la fois A et B. Les proportions correspondantes sont d√©sign√©es par
pa, pb et pab. Ce formalisme se g√©n√©ralise √† toute base de donn√©es dont on a extrait
une table bool√©enne cas-attributs.
Contr√¥le du risque et s√©lection de r√®gles
Les algorithmes d'extraction usuels reposent sur le support et la confiance, en
particulier Apriori l'algorithme fondateur [Agrawal et Srikant, 1994] et les am√©lio-
rations qui en ont √©t√© propos√©es. Le support d'une r√®gle est la proportion de tran-
sactions qui r√©alisent √† la fois A et B, Supp (A‚Üí B) = pab = nabn , alors que sa
confiance est la proportion de transactions qui r√©alisent B, parmi celles qui r√©alisent
A, Conf (A‚Üí B) = pabpa = nabna = 1‚àí
nab
na
.
Les algorithmes d'extraction "support-confiance" parcourent le treillis des itemsets
pour rechercher les itemsets fr√©quents, dont le support d√©passe un seuil minsupp, avec
une efficacit√© li√©e √† l'antimonotonie du treillis. On en d√©duit les r√®gles dont la confiance
d√©passe le seuil minconf , obtenant la base de r√®gles admissibles aux seuils choisis. De
telles bases comportent un grand nombre de r√®gles, pas toujours int√©ressantes.
La s√©lection des r√®gles int√©ressantes √† partir d'une base de r√®gles admissibles n√©ces-
site d'√©valuer celles-ci √† l'aide de mesures ayant les qualit√©s requises compte tenu de la
nature des r√®gles d'association et des attentes de l'utilisateur. Nous avons recens√© de
telles mesures et propos√© des crit√®res pour les √©valuer [Lallich et Teytaud 2003], ainsi
qu'une proc√©dure d'aide √† la d√©cision pour les choisir [Lenca et al., 2003]. Pour chaque
mesure choisie, on fixe le seuil minimal √† partir duquel une r√®gle est s√©lectionn√©e ou
l'on retient un nombre fix√© des meilleures r√®gles.
Le crit√®re "prise en compte du nombre d'observations" oppose les mesures statis-
tiques et les mesures descriptives. Il est logique a priori de souhaiter qu'une mesure soit
statistique, les r√©sultats observ√©s √©tant d'autant plus fiables que n est grand. Cependant,
compte tenu de la taille des bases sur lesquelles on recherche des r√®gles d'association, de
telles mesures perdent leur pouvoir discriminant, ainsi l'indice d'implication [Lerman
et al., 1981] et l'intensit√© d'implication [Gras 1979]. Des solutions tr√®s int√©ressantes ont
√©t√© propos√©es : l'indice probabiliste discriminant [Lerman et Az√©, 2003] qui centre et
r√©duit les valeurs de l'indice d'implication sur une base de r√®gles et l'intensit√© d'impli-
cation entropique [Gras et al., 2001] qui affecte l'intensit√© d'implication d'un facteur
correctif tenant compte de l'entropie des exp√©riences B/A et A/B. Mais il s'ensuit un
m√©lange des notions de signification et d'int√©r√™t, une perte d'intelligibilit√© de la mesure
et sa loi est plus difficile √† √©tudier.
Paradoxalement, le nombre de cas n est le m√™me pour toutes les r√®gles de la base,
ce qui milite pour d'abord tester la signification statistique des r√®gles, au sens de sa-
voir si elles renforcent r√©ellement la probabilit√© du cons√©quent. On testera l'hypoth√®se
d'ind√©pendance de A et B, not√©e H0, en direction d'une d√©pendance positive (hypo-
th√®se alternative unilat√©rale not√©e H1), pour ensuite utiliser des mesures descriptives
intelligibles et discriminantes de l'int√©r√™t des r√®gles sur la base filtr√©e. Nous proposons
ainsi une nouvelle d√©marche qui dissocie la signification statistique de l'√©valuation de
l'int√©r√™t. Elle comporte trois √©tapes :
 √©tape 1 : application d'un algorithme "support-confiance" √† la base de cas, pour
constituer une base de r√®gles admissibles aux seuils choisis.
 √©tape 2 : filtrage de la base de r√®gles par le test d'ind√©pendance de A et B pour
chaque r√®gle, soit une multitude de tests ; on pourrait tester tout √† la fois l'ind√©-
pendance et le d√©passement significatif des seuils de support et de confiance.
 √©tape 3 : analyse des r√®gles figurant dans la base filtr√©e par des mesures descrip-
tives v√©rifiant les crit√®res retenus par l'utilisateur [Lenca et al., 2003].
RNTI - 1
Lallich et al.
Dans cet article, nous approfondissons l'√©tape 2 qui pose le probl√®me de contr√¥ler
la multiplicit√© de tests, pour √©viter l'inflation de "faux positifs". En effet, si chaque test
est pratiqu√© au risque de 1e esp√®ce Œ±, on engendre m√©caniquement des "faux positifs",
ici des r√®gles s√©lectionn√©es alors qu'elles ne renforcent pas r√©ellement la probabilit√©
du cons√©quent. Nous avons propos√© des m√©thodes de contr√¥le du risque utilisant la
th√©orie de l'apprentissage statistique et la VC-dimension [Teytaud et Lallich, 2001],
ou le bootstrap [Lallich et Teytaud, 2003]. Dans la pratique, ces m√©thodes sont peu
puissantes, ignorant des r√®gles significatives.
La section 2 d√©taille le test de signification appliqu√© √† chaque r√®gle. Le contr√¥le
des faux positifs et l'id√©e de contr√¥ler le nombre de fausses d√©couvertes plut√¥t que le
risque sont expos√©s en section 3. Les proc√©dures de contr√¥les r√©cemment d√©velopp√©es en
biostatistique sont pr√©sent√©es en section 4 et une m√©thode de contr√¥le originale fond√©e
sur le bootstrap est propos√©e en section 5. Enfin, nous appliquons ces m√©thodes pour
filtrer quelques bases de r√®gles (section 6) et nous concluons (section 7).
2 Test de signification d'une r√®gle
Consid√©rons une r√®gle A ‚Üí B et une mesure de qualit√© ¬µ, croissante avec nab √†
marges fix√©es. On dira que la r√®gle A‚Üí B est significative au sens de la mesure ¬µ si la
valeur ¬µobs = ¬µ (A‚Üí B) remet en cause H0 dans le sens de H1, au risque de 1e esp√®ce
Œ±. Pour d√©cider de la signification, on calcule la p-value de ¬µobs qui est la probabilit√©
d'obtenir une valeur aussi grande que ¬µobs sous H0 et on s√©lectionne la r√®gle si l'on a
p-value < Œ±. Cette d√©marche impose de conna√Ætre la loi de ¬µ (A‚Üí B) sous H0.
Dans le cadre d'une mod√©lisation √† marges fix√©es, on suppose que sous H0 les
"1" de A et les "1" de B sont r√©partis au hasard, ind√©pendamment, en respectant
les marges. On d√©montre que le nombre d'exemples suit une loi hyperg√©om√©trique,
Nab ‚â° H(n,npa,pb) ‚â° H(n,npb,pa) (par convention, les variables al√©atoires sont en
majuscules). Pour une valeur observ√©e nab, √† marges fix√©es :
p‚àí value = Pr(Nab ‚â• nab) = Pr(H(n,npa,pb) ‚â• nab)
On peut op√©rer l'approximation normale de cette loi hyperg√©om√©trique sous des
conditions peu contraignantes, √† savoir nanb ‚â• 5n et nanb ‚â• 5n, o√π Œ¶ est la fonction
de r√©partition de la loi normale centr√©e r√©duite N(0,1). En notant tab = nabnanb , la valeur
attendue de Nab sous H0, r le coefficient de corr√©lation entre A et B, il vient :
p‚àí value = 1‚àí Œ¶
(
nab‚àítab‚àö
na
n‚àí1 tabpb
)
u 1‚àí Œ¶
(
nab‚àítab‚àö
npapbpapb
)
= 1‚àí Œ¶ (r‚àön)
Le coefficient de corr√©lation r est donc une mesure privil√©gi√©e pour tester l'ind√©pen-
dance (H0) face √† une d√©pendance positive (H1).
3 Risque et erreurs de 1e esp√®ce
Pour rechercher les r√®gles A ‚Üí B statistiquement significatives parmi les m r√®gles
de la base de r√®gles, on r√©p√®te m fois le test d'ind√©pendance entre A et B face √† une
d√©pendance positive. On rencontre ainsi un probl√®me classique en fouille des donn√©es,
RNTI - 1
Contr√¥le du risque et s√©lection de r√®gles
R√©alit√© \ D√©cision Acceptation Rejet Total
H0 est vraie U V m0
H1 est vraie T S m1
Total W R m
Tab. 1  Synth√®se des r√©sultats de m tests
le contr√¥le des erreurs de 1e esp√®ce (ou faux positifs). Si l'on teste m r√®gles non signifi-
catives au risque Œ±, m√©caniquement on s√©lectionne √† tort mŒ± r√®gles (soit 500 r√®gles, si
m = 10000 et Œ± = 0.05). La correction de Bonferroni, qui consiste √† pratiquer chaque
test au risque
Œ±
m , pour que le risque de rejeter au moins une fois √† tort H0, not√© par la
suite FWER, soit √©gal √† Œ±, n'est pas une bonne solution pour deux raisons :
 le FWER est en fait non contr√¥l√©, compris entre Œ±met Œ±, ne valant Œ± que si toutes
les r√®gles sont ind√©pendantes.
 le FWER est tr√®s conservateur en faveur de H0, ce qui augmente consid√©rable-
ment le risque de 2e esp√®ce ou risque de ne pas s√©lectionner une r√®gle pertinente.
Pour r√©gler ce probl√®me, il faut √©valuer les erreurs de 1e esp√®ce par une quantit√©
moins s√©v√®re que le FWER et contr√¥ler celle-ci, notamment lorsque les tests ne sont
pas ind√©pendants. Les r√®gles ne sont pas ind√©pendantes en raison des items qu'elles
partagent et des d√©pendances entre items. Diff√©rentes solutions ont √©t√© d√©velopp√©es, le
plus r√©cemment en s√©lection de g√®nes s'exprimant diff√©remment suivant l'√©tiquette de
la biopsie. On trouvera une remarquable synth√®se de ces travaux dans [Ge et al., 2003].
L'id√©e fondamentale [Benjamini et Hochberg, 1995] est de consid√©rer non pas le
risque d'erreur de la proc√©dure de test lorsqu'elle est pratiqu√©e une fois, mais le nombre
d'erreurs commises lorsque l'on r√©it√®rem fois la proc√©dure. A partir du tableau 1 (o√π les
quantit√©s en majuscules sont des variables al√©atoires observables, celles en minuscules
√©tant fixes, mais inconnues en ce qui concerne m0 et m1), on peut d√©finir diff√©rents
indicateurs des erreurs commises. Nous pr√©sentons ici les deux plus connus, le FWER
(Family wise error rate ou taux d'erreur en famille compl√®te) et le FDR (False discovery
rate ou taux de fausses d√©couvertes).
FWER est la probabilit√© de rejeter au moins une fois √† tortH0, FWER = Pr(V > 0).
Il a l'inconv√©nient d'√™tre bien trop s√©v√®re pour une multiplicit√© de tests, mais il nous a
sugg√©r√© une variante flexible originale, o√π l'on s'autorise V0 fausses d√©couvertes. Nous
l'appelons User Adjusted Family Wise Error Rate, UAFWER = Pr(V > V0), pour le
contr√¥le duquel nous proposons un algorithme fond√© sur le bootstrap (section 5).
Pour rem√©dier aux inconv√©nients du FWER, diverses quantit√©s reposant sur l'es-
p√©rance de V , le nombre de fausses d√©couvertes, √©ventuellement normalis√©e, ont √©t√©
propos√©es. La plus connue est le FDR [Benjamini et Hochberg 1995], la proportion
attendue de r√®gles s√©lectionn√©es √† tort parmi les r√®gles s√©lectionn√©es. Lorsque R = 0,
on pose
V
R = 0, soit FDR = E(Q), o√π Q vaut
V
R si R > 0, 0 sinon. Il s'ensuit :
FDR = E(VR | R > 0)P (R > 0)
[Storey, 2001] a propos√© le pFDR, une variante du FDR, adapt√©e √† l'estimation du
taux d'erreur sachant que l'hypoth√®se nulle a √©t√© refus√©e au moins une fois :
pFDR = E(VR | R > 0)
RNTI - 1
Lallich et al.
Ces quantit√©s ont l'int√©r√™t d'√™tre moins s√©v√®res sur le r√©sultat des m tests, au prix
de l'acceptation de quelques s√©lections √† tort dont on contr√¥le la proportion, ce qui
augmente pour chaque test la probabilit√© pour qu'une r√®gle pertinente soit s√©lectionn√©e
(puissance). On a FDR ‚â§ FWER et FDR ‚â§ pFDR, d'o√π FDR ‚â§ pFDR ‚â§ FWER
pour m grand, car Pr(R > 0) tend vers 1 quand m cro√Æt. Une fois choisie une d√©finition
du risque multiple de 1e esp√®ce, se pose le probl√®me de son contr√¥le. Nous allons
examiner successivement le cas du FWER et celui du FDR.
4 Proc√©dures de contr√¥le
4.1 Contr√¥le du FWER
Correction de Bonferroni La correction de Bonferroni consiste √† calculer des p-
values ajust√©es afin de prendre en compte la multiplicit√© des tests. Etant donn√©es la
statistique de test Tr relative √† la r√®gle r, r = 1,2,...m, et la p-value correspondante pr,
on d√©finit la p-value ajust√©e, not√©e pÀúr, par pÀúr = min {mpr,1} . On s√©lectionne toutes
les r√®gles ayant une p-value ajust√©e inf√©rieure au risque Œ±0. On montre :
FWER = 1‚àí Pr(‚ãÇmr=1 (Pr > Œ±0m ) | H0)
Sous condition d'ind√©pendance des r√®gles, il vient FWER = 1‚àí (1‚àí Œ±0m )m ‚âà Œ±0.
A d√©faut d'ind√©pendance, on a :
Œ±0
m ‚â§ FWER ‚â§ Œ±0.
Proc√©dure Step-down de Holm Les proc√©dures pas √† pas examinent les p-values
par ordre croissant et font √©voluer le seuil tout au long de la proc√©dure. [Holm, 1979]
consid√®re qu'une variable s√©lectionn√©e correspond √† une situation o√π H0 est fausse, ce
qui am√®ne √† ne prendre en compte pour le nouveau seuil que les variables restant √†
examiner. Les p-values √©tant rang√©es dans l'ordre croissant, o√π p(k) d√©signe la k
e
p-
value, on refuse H0 tant que p(k) <
Œ±0
m‚àík+1 . On accepte H0 pour toutes les p-values qui
suivent la premi√®re acceptation. Cette proc√©dure, facile √† mettre en oeuvre, donne de
bons r√©sultats lorsque le nombre de tests est faible, la correction du seuil ayant alors
de l'importance. Elle reste mal adapt√©e √† un grand nombre de tests.
Proc√©dure minP de Westfall et Young [Westfall et Young, 1993] ont propos√©
minP une proc√©dure d'ajustement des p-values qui contr√¥le le FWER mais oblige √†
calculer pÀúr = Pr(mink=1,2,...,m Pk ‚â§ pr | H0). Ce calcul doit √™tre op√©r√© par randomi-
sation des √©tiquettes de cas, si les variables (ici des r√®gles) ne sont pas ind√©pendantes.
Bien adapt√© √† la recherche des g√®nes s'exprimant diff√©remment suivant l'√©tiquette de
la biopsie, ce proc√©d√© ne convient pas √† la recherche des r√®gles d'association.
4.2 Contr√¥le du FDR
Proc√©dure Benjamini, Liu On doit √† [Benjamini et Liu, 1999], une m√©thode s√©-
quentielle pour contr√¥ler le FDR en cas d'ind√©pendance. Les p-values sont prises dans
l'ordre croissant et l'on rejette l'hypoth√®se nulle tant que la p-value examin√©e p(i) est
inf√©rieure √†
iŒ±0
m . Cette proc√©dure assure un FDR √©gal √†
m0
m Œ±0 en cas d'ind√©pendance.
Elle est compatible avec des donn√©es positivement d√©pendantes.
RNTI - 1
Contr√¥le du risque et s√©lection de r√®gles
Proc√©dure SAM de Storey Cette proc√©dure [Storey, 2001] repose sur l'estimation
de m0 puis celle de E(V ) et enfin celle du FDR. N√©cessitant une randomisation des
√©tiquettes, elle n'est pas adapt√©e au cas des r√®gles.
pFDR Pour estimer pFDR = E(VR | R > 0), qui est la proportion de fausses d√©tec-
tions, on utilise l'approximation [Storey, 2001] :
ÀÜpFDR(Œ¥) = 0ÀÜ.m.Œ¥#{pi‚â§Œ¥,i=1,...,m}
- m est le nombre de variables √† tester, ici le nombre de r√®gles ;
- Œ¥ d√©finit la zone de rejet ; les hypoth√®ses correspondant aux p-value inf√©rieures ou
√©gales √† Œ¥ sont rejet√©es ;
- pi est la i
eme
plus grande p-value ;
- pi0 = m0m est la proportion d'hypoth√®ses nulles ; ici, pi0 est estim√© par fÀÜ(1), o√π fÀÜ est
une cubic spline avec 3 degr√©s de libert√© de 0ÀÜ(Œª) sur Œª. On a 0ÀÜ(Œª) =
#{pi‚â•Œª,i=1,...,m}
m(1‚àíŒª)
et Œª d√©signe la zone d'acceptation dont les valeurs sont comprises entre 0 et 0.95.
Le pFDR est donc d√©fini par rapport √† une zone de rejet qu'il faut choisir par avance.
Une fois le pFDR global calcul√©, les variables sont contr√¥l√©es par une proc√©dure step-
down gr√¢ce aux q-values d√©finies pour chaque p-value par qÀÜ(pm) = 0ÀÜ.pm et :
qÀÜ(pi) = min
(
0ÀÜ.m.pi
i ,qÀÜ(pi+1)
)
; i = m‚àí 1, . . . ,1
La q-value est au pFDR ce que la p-value est √† l'erreur de 1
e
esp√®ce ou ce que la
p-value ajust√©e est au FWER. Pour toute r√®gle dont la p-value a une q-value inf√©rieure
au pFDR, on rejette H0 et l'on s√©lectionne la r√®gle.
5 Contr√¥le du UAFWER par l'algorithme BS_FD
5.1 Notations
 on note T l'ensemble des transactions, n = Card(T ), p le nombre d'items ;
 R une base de r√®gles d'association valides au sens de crit√®res pr√©d√©finis, par
exemple le support et la confiance, m = Card(R), R‚àó un sous-ensemble de R
rassemblant les r√®gles valides significatives au sens du crit√®re c ;
 c(r) d√©signe l'√©valuation de la r√®gle r selon le crit√®re c, c‚Ä≤(r) l'√©valuation empirique
de la r√®gle r selon le crit√®re c sur l'ensemble T ;
 V : nombre de faux positifs, Œ¥ : risque de la proc√©dure de contr√¥le des faux positifs,
avec V0 nombre de faux positifs que l'on ne souhaite pas d√©passer au risque Œ¥.
5.2 But
On veut s√©lectionner parmi les r√®gles r de la base R celles qui sont statistiquement
significatives pour le crit√®re c, au sens o√π leur √©valuation c(r) est significativement plus
√©lev√©e que c0(r), valeur attendue sous H0, l'hypoth√®se d'ind√©pendance de A et B.
Nous avons sugg√©r√© [Lallich et Teytaud, 2003] diff√©rents algorithmes qui utilisent
les outils de l'apprentissage statistique pour garantir que 100% des r√®gles trouv√©es
sont significatives au risque Œ± donn√©, ainsi l'algorithme BS fond√© sur le bootstrap.
RNTI - 1
Lallich et al.
Les exp√©rimentations ont confirm√© que cette approche √©tait trop prudente et par l√†
m√™me peu puissante. Prenant en compte l'id√©e d'accepter de fa√ßon contr√¥l√©e un certain
nombre de fausses d√©couvertes, √† l'instar des travaux de Benjamini (section 3), nous
proposons BS_FD qui adapte l'algorithme BS au contr√¥le du nombre de faux positifs.
L'algorithme BS_FD s√©lectionne les r√®gles candidates de telle sorte que l'on contr√¥le
UAFWER = P (V > V0), assurant que le nombre de r√®gles s√©lectionn√©es √† tort (faux
positif) ne d√©passe pas V0 au risque Œ¥. Plus pr√©cis√©ment, on garantit que P (V > V0)
converge vers Œ¥, √† la limite d'un grand √©chantillon de transactions.
5.3 Algorithme BS_FD
Pour garantir c(r) > c0(r), on peut se limiter sans perte de g√©n√©ralit√© √† garantir
c(r) > 0, en rempla√ßant c(r) par le crit√®re translat√© c(r)‚àí c0(r). On note par la suite
# l'op√©rateur "cardinal", associant √† un ensemble son cardinal (i.e. #E est le cardinal
de l'ensemble E.
1. D√©finir c‚Ä≤(r), l'√©valuation empirique de c(r) sur l'ensemble T de transactions.
2. Un grand nombre de fois (pour i = 1,2,...,l) - Tirer au sort, avec remise, une liste
T ‚Ä≤ d'√©l√©ments de T , de m√™me cardinal que T .
- D√©finir c‚Äù(r), l'√©valuation de c(r) sur la liste T ‚Ä≤ de transactions.
- Calculer Œµ(V0,i) minimal, tel que #{c‚Äù(r) > c‚Ä≤(r) + Œµ(V0,i)} ‚â§ V0
3. On obtient l valeurs Œµ(V0,i). Calculer Œµ(Œ¥), le quantile (1‚àí Œ¥) des Œµ(V0,i).
4. Garder dans R‚àó toutes les r√®gles r de R telles que c‚Ä≤(r) > Œµ(Œ¥).
Pour r√©aliser la derni√®re partie de l'√©tape 2. de l'algorithme, on applique la proc√©dure
"calculerEpsilon(i,Œ¥,V0)" d√©finie ci-dessous.
Proc√©dure "calculerEpsilon(i,Œ¥,V0)"
- tableauEpsilon = (0,0,...,0) tableau de taille m
- pour r variant de 0 √† m‚àí 1 : tableauEpsilon(r) = c‚Äù(r)‚àí c‚Ä≤(r)
- Calculer le (V0 + 1)
e
plus grand √©l√©ment de tableauEpsilon
5.4 Justification de la m√©thode
Les m√©thodes de bootstrap [Efron, 1979] ont d'abord un aspect tr√®s intuitif de par
leur id√©e d'approcher l'√©cart entre la loi empirique et la loi r√©elle par l'√©cart entre
la loi bootstrapp√©e et la loi empirique. En outre, elles ont de profondes justifications
math√©matiques [Gin√© et Zinn, 1984] qui n√©cessitent une formalisation pr√©cise de la
question pos√©e.
Formellement, l'objectif est que la fonction de r√©partition du nombre de r√®gles telles
que c(r) < 0 malgr√© c‚Ä≤(r) >  ait pour valeur au moins 1 ‚àí Œ¥ en V0. On a #{c(r) ‚â§ 0
et c‚Ä≤(r) > } major√© par #{c‚Ä≤(r) ‚â• c(r) + }.
Les th√©or√®mes sur le bootstrap appliqu√© √† une famille de fonctions v√©rifiant des
hypoth√®ses minimales [Van der Waart et Wellner, 1996], nous permettent d'approcher
cette quantit√© par #{c‚Ä≤‚Ä≤(r) ‚â• c‚Ä≤(r) + }.
RNTI - 1
Contr√¥le du risque et s√©lection de r√®gles
5.5 Cas de plusieurs crit√®res
En pratique, on s'int√©resse souvent √† plusieurs crit√®res, dans notre cas √† la confiance,
au support, plus un crit√®re de non-ind√©pendance. L'extension de l'algorithme BS_FD,
not√©e BS_FD_mc se fait simplement en utilisant comme crit√®re unique le min des
diff√©rents crit√®res. Ainsi pour un travail sur 3 crit√®res c1, c2 et c3, consid√®re-t-on c(r) =
min {c1(r),c2(r),c3(r)}. Utiliser BS_FD_mc sur c au risque Œ¥ fournit bien des r√®gles
garanties √† la fois pour les crit√®res c1, c2 et c3 au risque Œ¥.
Afin d'optimiser le risque de seconde esp√®ce, on gagnera √† travailler sur des trans-
formations (diff√©rentiables au sens de Hadamard) des ci qui rendent ces crit√®res ho-
mog√®nes, par exemple des p-values ou des r√©ductions, en divisant l'√©cart empirique de
chaque crit√®re √† sa valeur de r√©f√©rence par l'estimation de l'√©cart-type issue des c‚Ä≤(r).
5.6 Complexit√© de BS_FD
La complexit√© de BS_FD est proportionnelle √† l √ó m √ó n, en consid√©rant que le
g√©n√©rateur de nombres au hasard fonctionne en temps constant. En effet, la complexit√©
de recherche du ke plus grand √©l√©ment d'un tableau est proportionnelle √† la taille du
tableau. La valeur de l doit √™tre assez grande pour que l'impr√©cision li√©e √† la finitude de
l ne nuise pas √† la confiance globale, mais elle ne d√©pend ni de m ni de n. L'algorithme
est donc globalement lin√©aire en m√ó n, avec une forte constante l, li√©e au bootstrap.
6 Exp√©rimentations
6.1 Description des donn√©es
Les m√©thodes de filtrage pr√©sent√©es ici ont √©t√© appliqu√©es √† cinq bases de r√®gles
disponibles sur la plateforme HERBS [Vaillant et al. 2003]. Celles-ci ont √©t√© extraites
√† l'aide d'Apriori suivant l'impl√©mentation de [Borgelt et Kruse 2002] de bases de
cas du site UCI (http://www.ics.uci.edu/mlearn/MLSummary.html) : Contraceptive
Method Choice (CMC), Flags (Flags), Wisconsin breast Cancer (WBC), Solar Flare
I (SFI) et Solar Flare II (SFII). Nous avons calcul√© pour chaque m√©thode le taux de
r√©duction de chaque base, apr√®s retrait des r√®gles non significatives.
6.2 Caract√©ristiques et r√©sultats
Le tableau ci-dessous est compos√© de deux sous-tableaux qui r√©capitulent les carac-
t√©ristiques de chaque base et le nombre de r√®gles s√©lectionn√©es suivant chaque m√©thode :
 Contr√¥le √† 5% : on s√©lectionne les r√®gles ayant une p-value ‚â§ 5%.
 Bonferroni : la correction est appliqu√©e sur un seuil de 5%.
 Holm : la proc√©dure est appliqu√©e avec un seuil de 5%.
 BS_FD (r) : risque de 5%, avec un V0 √©gal au r√©sultat du pFDR, appliqu√© au
coefficient de corr√©lation r compar√© √† 0, unilat√©ralement √† droite.
RNTI - 1
Lallich et al.
Caract√©ristiques CMC Flags WBC SF I SF II
Nb cas 1473 194 699 323 1066
Nb r√®gles 2878 3329 3095 5402 3596
Tx couverture 100% 100% 96.2% 100% 100%
Tx recouvrement 259 1848 646 1828.6 2277
Seuil support 5% 50% 10% 20% 20%
Seuil confiance 60% 90% 70% 85% 85%
R√©sultats CMC Flags WBC SF I SF II
contr√¥le √† 5% 1401 2181 3094 2544 2558
pFDR 916 (3) 1200 (3) 3095 (0) 900 (5) 1625 (4)
FDR (Benj.) 913 (0.003) 1198 (0.0027) / 899 (0.006) 1626 (0.0022)
BS_FD (r) 794 (3) 1074 (3) 3093 (0) 604 (5) 738 (4)
Holm 742 564 3094 432 1020
Bonferroni 731 539 3042 427 1006
Tab. 2  Filtrage de quelques bases de r√®gles
 FDR : la m√©thode d√©crite en section 4 est utilis√©e avec un seuil √©gal √† celui de la
derni√®re q-value s√©lectionn√©e par le pFDR, indiqu√© entre parenth√®ses (pour pou-
voir comparer grossi√®rement le pFDR et le FDR, il est n√©cessaire de s√©lectionner
les r√®gles √† un degr√© de contr√¥le voisin).
 pFDR : la m√©thode est utilis√©e avec une zone de rejet de 0.1%. Entre parenth√®ses
est indiqu√© le nombre moyen de rejets √† tort. La zone de rejet est choisie telle
que ce nombre soit le plus acceptable possible.
 BS_FD (m.c) : identique √† BS_FD (r) avec trois crit√®res, r (compar√© √† 0), le
support et la confiance (compar√©s aux seuils utilis√©s en extraction).
A partir du tableau 2, on op√®re diff√©rentes constatations :
 Sur l'une des bases, WBC, le filtrage est totalement inefficace y compris la cor-
rection de Bonferroni. La raison en est qu'une seule r√®gle de la base de d√©part a
une p-value sup√©rieure √† 0.05 (√† savoir 0.184), une autre est √† 0.023, les autres
p-values sont inf√©rieures √† 0.01, 3036 d'entre elles valent 0.0000 !
 Pour les 4 autres bases, le filtrage par la simple r√©p√©tition du test d'ind√©pendance
r√©duit notablement la base : 51%, 34%, 53%, 39%.
 Dans la base ainsi filtr√©e, il reste encore beaucoup de faux positifs, que les diff√©-
rentes m√©thodes de contr√¥le du risque permettent encore d'√©liminer.
 Comme pr√©vu, la proc√©dure de contr√¥le du risque la plus s√©v√®re est la correction
de Bonferroni, donnant sur les 4 bases des taux de r√©duction de 75%, 81%, 65% et
60%. Par sa s√©v√©rit√© m√™me, cette proc√©dure est peu puissante, limitant certes les
faux positifs, mais au prix d'une augmentation des faux n√©gatifs. La proc√©dure
de Holm donne des r√©sultats voisins, son inefficacit√© venant du tr√®s grand nombre
de r√®gles qui rend inutile la correction du seuil pas √† pas.
 Les m√©thodes pFDR, FDR(Benjamini) et notre m√©thode BS_FD donnent des r√©-
sultats interm√©diaires, correspondant √† ce que l'on pouvait attendre. La m√©thode
BS_FD appara√Æt comme la plus s√©v√®re des 3, plus particuli√®rement sur Solar
RNTI - 1
Contr√¥le du risque et s√©lection de r√®gles
R√©sultats CMC_app CMC_val croisement Taux
sans contr√¥le 3391 2742 2742 0.81
contr√¥le √† 5% 1835 1462 1238 0.68
pFDR 1347 (3) 996 (4) 938 0.70
BS_FD (r) 1302 (3) 955 (4) 903 0.69
Holm 1149 858 795 0.69
BS_FD (m.c) 159 (3) 276 (4) 125 0.79
Tab. 3  R√©sultats de la base CMC en validation
Flare II, mais la raison est que le param√©trage de pFDR et FDR(Benjamini) as-
sure un nombre moyen de fausses d√©couvertes √©gal √† V0, alors que BS_FD assure
que V0 n'est d√©pass√© qu'avec le risque 0.05, ce qui est plus exigeant.
 La proc√©dure de filtrage est d'autant plus n√©cessaire qu'elle permet d'√©liminer
des r√®gles qui seraient s√©lectionn√©es avec bon nombre de mesures de qualit√©.
Ainsi les r√®gles logiques dont le cons√©quent est tr√®s fr√©quent (e.g. Solar Flare II)
ont-elles une valeur maximale pour toutes les mesures qui donnent une valeur
fixe maximale aux r√®gles logiques, alors qu'elles n'ont aucune esp√®ce d'int√©r√™t et
que leur p-value est non significative. A l'inverse, le calcul des p-values ne pr√©juge
pas du classement ult√©rieur des r√®gles par des mesures descriptives favorisant les
r√®gles les plus int√©ressantes, par exemple des mesures √† la fois dissym√©triques et
qui avantagent les r√®gles dont le cons√©quent est rare.
6.3 Validation des r√©sultats
Alors que le d√©coupage de la base de cas en base d'apprentissage et base de validation
est courant en apprentissage supervis√©, il n'est jamais pratiqu√© dans le domaine des
r√®gles d'association. La raison est sans doute que les r√®gles d'association ressortent de
l'apprentissage non supervis√© et que leur extraction suivant le support et la confiance
est une t√¢che d√©terministe clairement d√©finie, comme le souligne [Freitas, 2000]. Dans
la mesure o√π nous avons introduit un test de signification, il est logique de distinguer
base d'apprentissage et base de validation pour √©tudier la pertinence sur la base de test
des r√®gles s√©lectionn√©es sur la base d'apprentissage.
La base CMC a √©t√© s√©par√©e au hasard pur en 2 bases de m√™me taille. Sur CMC_app,
nous avons extrait une base de r√®gles admissibles au sens de l'algorithme Apriori et
nous avons filtr√© ces r√®gles √† l'aide des diff√©rentes m√©thodes pr√©sent√©es. Ensuite (tableau
3), nous avons examin√© comment se comportaient les r√®gles admissibles issues de la base
CMC_app (col. 1) lorsqu'elles √©taient appliqu√©es √† la base CMC_val (col. 2) et nous
avons calcul√© parmi les r√®gles s√©lectionn√©es par chaque m√©thode sur CMC_app combien
√©taient encore s√©lectionn√©es par la m√™me m√©thode sur CMC_val (col. 3). On constate
ainsi que 80% des r√®gles admissibles pour CMC_val le sont encore pour CMC_app,
alors que ce taux descend √† 70% lorsque l'on filtre la base de r√®gle pour ne garder
que les r√®gles significatives, quelle que soit la m√©thode. En revanche, l'application de
BS_FD(m.c) avec les trois crit√®res, support, confiance et r, permet de revenir √† ce taux
de 80% au prix il est vrai d'une s√©rieuse diminution du nombre de r√®gles.
RNTI - 1
Lallich et al.
7 Conclusion et travaux futurs
Nous partons d'un principe simple, il ne faut garder dans une base de r√®gles que
celles qui renforcent la conclusion sur le cons√©quent. Pour ce faire, nous proposons une
strat√©gie de filtrage des bases de r√®gles qui conduit √† pratiquer une multitude de tests
unilat√©raux √† droite sur le coefficient de corr√©lation entre A et B. Cette strat√©gie est
fond√©e sur le contr√¥le du nombre de r√®gles s√©lectionn√©es √† tort et non pas du risque,
assurant par l√† une plus grande puissance, tout en permettant √† l'utilisateur d'arbi-
trer entre "r√®gles s√©lectionn√©es √† tort" et "r√®gles pertinentes non s√©lectionn√©es". Nous
proposons un algorithme original BS_FD qui a l'avantage de contr√¥ler directement le
nombre de "faux positifs" et non pas leur moyenne, en tenant compte de la d√©pendance
des r√®gles, tout en permettant de tester plusieurs crit√®res √† la fois. Les exp√©rimenta-
tions montrent l'efficacit√© de la strat√©gie propos√©e qui permet de r√©duire sensiblement
la taille de la base, facilitant le recours ult√©rieur √† des mesures de qualit√© descriptives
qui apportent un point de vue compl√©mentaire sur la pertinence des r√®gles.
Une extension de travail est pr√©vue en fouille des donn√©es g√©nomiques pour re-
chercher des r√®gles discriminantes. Les proc√©dures de contr√¥le du risque int√©ressent
l'ensemble des m√©thodes de fouille des donn√©es o√π l'on multiplie les tests.
R√©f√©rences
[Agrawal et Srikant, 1994] R. Agrawal et R. Srikant. Fast algorithms for mining asso-
ciation rules. Proc. of the 20th VLDB Conference, Santiago, Chile, 1994.
[Agrawal et al., 1993] R. Agrawal, T. Imielinski et A. Swami. Mining associations
between sets of items in large databases, Proc. of the ACM SIGMOD Conf., Wa-
shington DC, USA, 1993.
[Benjamini et Hochberg, 1995] Y. Benjamini, Y. Hochberg. Controlling the false dis-
covery rate : a practical and powerful approach to multiple testing, J. R. Statisc.
Soc., B, 57:289-300, 1995.
[Benjamini et Liu, 1999] Y. Benjamini et W. Liu. A step-down multiple-hypothesis
procedure that controls the false discovery rate under independance, J. Stat. Planng
Inf., 82:163-170, 1999.
[Borgelt et Kruse, 2002] C. Borgelt et R. Kruse. Induction of association rules : Apriori
implementation. Proc. 15th Conf. on Comp. Stat., Physika Verlag, Germany, 2002.
[Efron, 1979] B. Efron. Bootstrap methods: Another look at the jacknkife, Annals of
statistics, 7:1-26, 1979.
[Freitas, 2000] A. Freitas. Understanding the crucial difference between classification
and discovery of association rules. SIGKDD Explorations, vol. 2, 1:65-69, 2000.
[Ge et al., 2003] Y. Ge, S. Dudoit et T.P. Speed. Resampling-based multiple testing
for microarray data analysis, Tech. Rep. 663, Univ. of California, Berkeley, 2003.
[Gin√© et Zinn, 1984] E. Gin√© et J. Zinn. Bootstrapping general empirical measures,
Annals of probability, 18:851-869, 1984.
[Gras, 1979] R. Gras. Contribution √† l'√©tude exp√©rimentale et √† l'analyse de certaines
acquisitions cognitives et de certains objectifs didactiques en mathematiques, Th√®se
RNTI - 1
Contr√¥le du risque et s√©lection de r√®gles
d'Etat, Rennes 1, 1979.
[Gras et al., 2001] R. Gras, P. Kuntz, R. Couturier et F. Guillet. Une version entropique
de l'intensit√© d'implication pour les corpus volumineux, Revue ECA, Extraction des
Connaissances et Apprentissage, Herm√®s, 1:69-80, 2001.
[Holm, 1979] S. Holm. A simple sequentially rejective multiple test procedure. Scand.
J. Statistic., 6:65-70, 1979.
[Lallich et Teytaud, 2003] S. Lallich et O. Teytaud. Evaluation et validation de l'int√©r√™t
des r√®gles d'association, √† para√Ætre RNTI, Revue des Nouvelles Technologies de
l'Information, C√©padu√®s, Toulouse.
[Lenca et al. 2003] P. Lenca, P. Meyer, P. Picouet, B. Vaillant et S. Lallich. Cri-
t√®res d'√©valuation des mesures de qualit√© des r√®gles d'association, RNTI, Revue
des Nouvelles Technologies de l'Information, 1:123-134, C√©padu√®s, Toulouse.
[Lerman et Az√©, 2003] I.C. Lerman et J. Az√©, Une mesure contextuelle dicriminante
de qualit√© des r√®gles d'association, EGC'03, RIA-ECA, 17, 1-2-3:247-262, 2002.
[Lerman et al., 1981] I.C. Lerman, R. Gras et H. Rostam. Elaboration et √©valua-
tion d'un indice d'implication pour des donn√©es binaires, I et II, Math√©matiques et
Sciences Humaines, 74:5-35, 75:5-47, 1981.
[Storey, 2001] J.D. Storey. The positive false discovery rate and the q-value, √©crit en
2001, √† para√Ætre Annals of Statistics 2003.
[Teytaud et Lallich, 2001] O. Teytaud et S. Lallich. Bornes uniformes en extraction de
r√®gles d'association, Actes Colloque CAp'01, Grenoble, 133-148, 2001.
[Vaillant et al. 2003] B. Vaillant, P. Picouet et P. Lenca. An extensible platform for
rule quality measure benchmarking. R. Bisdorff (Ed), Human Centered Processes,
187-191, 2003.
[Van Der Vaart et Wellner, 1996] A. Van Der Vaart et J.A. Wellner.Weak Convergence
and Empirical Processes, Springer Series in Statistics, 1996.
[Vapnik, 1995] V.N. Vapnik. The nature of statistical learning, Springer, 1995.
[Westfall et Young, 1993] P.H. Westfall et S.S. Young. Resampling based multiple
testing : examples and methods for p-values adjustment, John Wiley & Sons, 1993.
Summary
Association rules extraction algorithms allow to efficiently go through the item-
sets lattice in order to constitute a base of rules acceptable at predefined support and
confidence levels. However they result in a multitude of rules hardly exploitable. We
suggest to refine such bases by eliminating non statistically significant rules. The mul-
titude of performed tests mechanically leads to a multiplication in false discoveries. We
first present procedures issued from biostatistic which aim at controlling not the risk,
but the number of false discoveries. Then, we propose BS_FD, an original algorithm
based on bootstrap, which selects significant rules while controlling the number of false
discoveries. By experimenting these procedures on different rule bases, we show their
ability to refine rules bases.
Keywords : Association rule, quality, multiple testing risk control.
RNTI - 1
