Classification incrÃ©mentale supervisÃ©e : un panel introductif
Christophe Salperwyckâˆ—,âˆ—âˆ—, Vincent Lemaireâˆ—
âˆ—Orange Labs
2, Avenue Pierre Marzin 22300 Lannion
prenom.nom@orange.ftgroup.com
âˆ—âˆ— LIFL (UMR CNRS 8022) - UniversitÃ© de Lille 3
Domaine Universitaire du Pont de Bois
59653 Villeneuve dâ€™Ascq Cedex
RÃ©sumÃ©. Les dix derniÃ¨res annÃ©es ont Ã©tÃ© tÃ©moin du grand progrÃ¨s rÃ©alisÃ© dans
le domaine de lâ€™apprentissage statistique et de la fouille de donnÃ©es. Il est pos-
sible Ã  prÃ©sent de trouver des algorithmes dâ€™apprentissage efficaces et automa-
tiques. Historiquement les mÃ©thodes dâ€™apprentissage faisaient lâ€™hypothÃ¨se que
toutes les donnÃ©es Ã©taient disponibles et pouvaient Ãªtre chargÃ©es en mÃ©moire
pour rÃ©aliser lâ€™apprentissage. Mais de nouveaux domaines dâ€™application de la
fouille de donnÃ©es Ã©mergent telles que : la gestion de rÃ©seaux de tÃ©lÃ©communica-
tions, la modÃ©lisation des utilisateurs au sein dâ€™un rÃ©seau social, le web mining...
La volumÃ©trie des donnÃ©es explose et il est nÃ©cessaire dâ€™utiliser des algorithmes
dâ€™apprentissage incrÃ©mentaux. Cet article a pour but de prÃ©senter les principales
approches de classification supervisÃ©e incrÃ©mentale recensÃ©es dans la littÃ©rature.
Il a pour vocation de donner Ã  un lecteur dÃ©butant des indications de lecture sur
ce sujet; sujet qui connaÃ®t dÃ©jÃ  des applications industrielles.
1 Introduction
Les dix derniÃ¨res annÃ©es ont Ã©tÃ© tÃ©moin des grands progrÃ¨s rÃ©alisÃ©s dans le domaine de
lâ€™apprentissage automatique et de la fouille de donnÃ©es. Ces techniques ont montrÃ© leurs ca-
pacitÃ©s Ã  traiter des volumÃ©tries importantes de donnÃ©es et ce sur des problÃ¨mes rÃ©els (Guyon
et al., 2009; FÃ©raud et al., 2010). NÃ©anmoins le plus important effort a Ã©tÃ© rÃ©alisÃ© pour des
analyses de donnÃ©es homogÃ¨nes et stationnaires et Ã  lâ€™aide dâ€™algorithmes centralisÃ©s. La plu-
part des approches dâ€™apprentissage automatique supposent que les ressources sont illimitÃ©es,
par exemple que les donnÃ©es tiennent en mÃ©moire vive. Dans ce contexte les algorithmes clas-
siques dâ€™apprentissage utilisent des bases dâ€™apprentissage de taille finie et produisent des mo-
dÃ¨les statiques. Cependant la volumÃ©trie des donnÃ©es continue de croÃ®tre et ce plus vite que les
capacitÃ©s de traitement.
De nouveaux domaines dâ€™application de la fouille de donnÃ©es Ã©mergent oÃ¹ les donnÃ©es ne
sont plus sous la forme de tableaux de donnÃ©es persistants mais plutÃ´t sous la forme de donnÃ©es
"passagÃ¨res". Parmi ces domaines on citera : la gestion de rÃ©seaux de tÃ©lÃ©communications, la
modÃ©lisation des utilisateurs au sein dâ€™un rÃ©seau social, le web mining... Le dÃ©fi scientifique
principal est alors dâ€™automatiser lâ€™ensemble des Ã©tapes du processus dâ€™apprentissage mais aussi
Classification incrÃ©mentale supervisÃ©e : un panel introductif
les Ã©tapes nÃ©cessaires au dÃ©ploiement du modÃ¨le et ce sur des volumÃ©tries trÃ¨s larges. Lâ€™un des
dÃ©fis techniques est de concevoir des algorithmes permettant ce passage Ã  lâ€™Ã©chelle. Parmi lâ€™en-
semble des axes dâ€™Ã©tudes, qui permettent ce passage Ã  lâ€™Ã©chelle, lâ€™apprentissage incrÃ©mental
semble rÃ©pondre naturellement Ã  cette problÃ©matique.
Lorsque le terme dâ€™apprentissage incrÃ©mental est utilisÃ© en informatique il fait rÃ©fÃ©rence
aux algorithmes permettant dâ€™entraÃ®ner un modÃ¨le de maniÃ¨re incrÃ©mentale. Au fur et Ã  mesure
que de nouvelles informations (donnÃ©es) sont prÃ©sentÃ©es Ã  lâ€™algorithme, celui-ci apprend et
ce sans avoir besoin de rÃ©apprendre le modÃ¨le Ã  partir de zÃ©ro ni mÃªme Ã  avoir Ã  stocker
lâ€™ensemble des donnÃ©es.
Cet article a pour but de prÃ©senter pour diffÃ©rents types de classifieurs supervisÃ©s une liste
de lectures introductives qui prÃ©sente les principales approches de classification supervisÃ©e
incrÃ©mentale recensÃ©es dans la littÃ©rature. Il a pour vocation Ã  donner Ã  un lecteur dÃ©butant des
bases sur ce sujet ; sujet qui connaÃ®t dÃ©jÃ  des applications industrielles (Almaksour et al., 2009;
Saunier et al., 2004).
La section (Section 2) qui suit cette introduction a pour but de situer lâ€™apprentissage incrÃ©-
mental parmi les diffÃ©rentes familles dâ€™algorithmes dâ€™apprentissage existantes mais aussi de
poser un certain nombre de dÃ©finitions, et notions utiles pour la comprÃ©hension de cet article.
Les notations utilisÃ©es dans la suite du document sont Ã©galement dÃ©taillÃ©es dans cette section.
La troisiÃ¨me section dÃ©crit les principaux algorithmes dâ€™apprentissage incrÃ©mentaux clas-
sÃ©s par typologie de classifieurs (arbre de dÃ©cision, SVM...) ; ces derniers nâ€™Ã©tant pas tous
naturellement incrÃ©mentaux. On se place ici principalement dans le cadre oÃ¹ les donnÃ©es sont
stockÃ©es seulement sur disque mais ne peuvent Ãªtre toutes placÃ©es en mÃ©moire de maniÃ¨re Ã 
utiliser un algorithme hors-ligne (voir section 2.1.1).
Lorsque les donnÃ©es ne sont plus stockables sur disque il est alors impÃ©ratif de travailler
directement sur le flux entrant des donnÃ©es. Dans ce cas une adaptation des algorithmes dâ€™ap-
prentissage incrÃ©mentaux est requise. Ces adaptations sont dÃ©crites au cours de la section 4
pour les principales techniques de classification.
Lâ€™intÃ©rÃªt croissant de la communautÃ© pour lâ€™apprentissage incrÃ©mental ces derniÃ¨res annÃ©es
(on peut en juger par le nombre croissant de workshop ou de confÃ©rences organisÃ©s sur ce
sujet) a produit de nombreux algorithmes mais aussi diffÃ©rents indicateurs de comparaison
entre algorithmes. Le but de la section 5 est de prÃ©senter les mÃ©triques et/ou indicateurs de
comparaison les plus communÃ©ment utilisÃ©s. Enfin avant de conclure il nâ€™est pas possible de
parler dâ€™apprentissage incrÃ©mental sans consacrer une section Ã  la notion de contexte. Câ€™est le
but de la section 6.
2 PrÃ©ambule
2.1 HypothÃ¨ses et contraintes
En matiÃ¨re dâ€™apprentissage automatique, il existe diffÃ©rentes hypothÃ¨ses ou contraintes qui
portent Ã  la fois sur les donnÃ©es et sur le type de concept que lâ€™on cherche Ã  modÃ©liser. Cette
partie en dÃ©crit quelques unes dans le contexte de lâ€™apprentissage incrÃ©mental de maniÃ¨re Ã 
comprendre les approches prÃ©sentÃ©es dans les sections 3 et 4 de cet article.
Dans la suite de cet article on sâ€™intÃ©resse aux problÃ¨mes de classification binaire. On ap-
pelle exemple une observation x. Lâ€™espace de tous les exemples possibles est notÃ© X . Les
exemples sont supposÃ©s Ãªtre indÃ©pendants et tirÃ©s alÃ©atoirement au sein dâ€™une distribution de
C. Salperwyck et al.
probabilitÃ© notÃ©e DX , et Ãªtre munis de leur Ã©tiquette (y âˆˆ {âˆ’1,+1}). On appelle modÃ¨le
un classifieur (f ) qui dÃ©termine la classe qui doit Ãªtre assignÃ©e Ã  un exemple x (f : X â†’
{âˆ’1,+1}. Chaque exemple est dÃ©crit par un ensemble dâ€™attributs.
2.1.1 Sur les exemples dâ€™apprentissage
Les modÃ¨les que lâ€™on cherche Ã  apprendre sont basÃ©s sur des exemples reprÃ©sentatifs dâ€™un
problÃ¨me de classification (dans le cadre de cet article). Lâ€™algorithme dâ€™apprentissage utilise
ces exemples de maniÃ¨re Ã  entraÃ®ner le modÃ¨le. Mais ces exemples sont plus ou moins dispo-
nibles : tous dans une base de donnÃ©es, tous en mÃ©moire, partiellement en mÃ©moire, un par un
dans un flux... On trouve dans la littÃ©rature diffÃ©rents types dâ€™algorithmes selon les types de
disponibilitÃ© dâ€™exemples diffÃ©rents (peu dâ€™exemples, beaucoup, Ã©normÃ©ment et en continu).
Le cas le plus simple correspond Ã  avoir un modÃ¨le basÃ© sur une quantitÃ© dâ€™exemples
reprÃ©sentatifs qui peuvent Ãªtre chargÃ©s en mÃ©moire et exploitÃ©s directement.
Dans dâ€™autres cas, la quantitÃ© dâ€™exemples est trÃ¨s importante et il est impossible de tous
les charger en mÃ©moire. Il faut donc concevoir un algorithme qui puisse gÃ©nÃ©rer un modÃ¨le
sans avoir besoin que tous les exemples soient en mÃ©moire. On peut alors chercher Ã  dÃ©couper
les donnÃ©es en plusieurs petits ensembles (chunks) de maniÃ¨re Ã  pouvoir les traiter les uns
aprÃ¨s les autres et ne pas avoir Ã  tout charger en mÃ©moire et / ou Ã  utiliser des techniques de
parallÃ©lisation de lâ€™algorithme dâ€™apprentissage. Le lecteur trouvera dans (Provost et Kolluri,
1999) une Ã©tude sur les mÃ©thodes utilisÃ©es pour traiter cette problÃ©matique de volumÃ©trie :
parallÃ©lisation, partitionnement de lâ€™espace...
Dans le pire des cas, les donnÃ©es sont trÃ¨s volumineuses et arrivent de maniÃ¨re continue,
on parle alors de flux de donnÃ©es. Les exemples ne peuvent Ãªtre vus quâ€™une seule fois et dans
lâ€™ordre dans lequel ils arrivent. Lâ€™algorithme doit rÃ©aliser lâ€™apprentissage trÃ¨s rapidement afin
de ne pas ralentir le flux de donnÃ©es.
2.1.2 Sur la disponibilitÃ© du modÃ¨le
La mise en place dâ€™un modÃ¨le de prÃ©diction se rÃ©alise en deux Ã©tapes : 1) une Ã©tape dâ€™ap-
prentissage du modÃ¨le, 2) une Ã©tape dâ€™exploitation du modÃ¨le. Dans le cas dâ€™un apprentissage
non incrÃ©mental ces Ã©tapes sont rÃ©alisÃ©es lâ€™une aprÃ¨s lâ€™autre mais dans le cas de lâ€™apprentissage
incrÃ©mental, on repasse en phase dâ€™apprentissage dÃ¨s quâ€™un nouvel exemple arrive. Cette phase
peut Ãªtre plus ou moins longue et il est parfois nÃ©cessaire de pouvoir en maÃ®triser la complexitÃ©
calculatoire. (Dean et Boddy, 1988) sâ€™intÃ©resse Ã  cette problÃ©matique et dÃ©finit le concept dâ€™al-
gorithme de prÃ©diction anytime. Câ€™est un algorithme (i) qui est capable dâ€™Ãªtre arrÃªtÃ© Ã  tout
moment et de fournir une prÃ©diction ; et (ii) dont la qualitÃ© de la prÃ©diction est proportionnelle
au temps consommÃ©.
2.1.3 Sur le concept
Supposons un problÃ¨me de classification supervisÃ©e oÃ¹ lâ€™algorithme dâ€™apprentissage ob-
serve une sÃ©quence dâ€™exemples munis de leurs Ã©tiquettes. La classe dâ€™appartenance des exemples
suit une loi de probabilitÃ© notÃ©e PY . On appelle concept cible pour un exemple xi la probabilitÃ©
jointe P (xi, yi) = P (xi)P (yi|xi).
Le caractÃ¨re non stationnaire du problÃ¨me Ã  rÃ©soudre peut Ãªtre prÃ©sent (principalement)
sous deux principales formes de dÃ©rives.
Classification incrÃ©mentale supervisÃ©e : un panel introductif
Le concept cible nâ€™est pas toujours constant dans le temps, parfois il se modifie ou dÃ©rive,
on parle alors de dÃ©rive de concept (Michalski et al., 1986). Gama dans (Gama, 2010) divise
cette dÃ©rive en deux sous catÃ©gories : soit elle est douce on parle alors de dÃ©rive de concept
("concept drift"), soit elle est abrupte et on parle alors de saut de concept ("concept shift"). Ces
deux types de dÃ©rives correspondent Ã  un changement de la probabilitÃ© P (Y |X) au cours du
temps. Les algorithmes de la littÃ©rature peuvent Ãªtre classÃ©s selon quâ€™ils supportent ou non le
changement de concept.
La distribution des donnÃ©es peut varier au cours du temps (P (X)) sans modification des
P (Y |X), on parle alors de covariate shift (Joaquin Quinonero-Candela et al., 2009). Le â€œco-
variate shiftâ€ apparaÃ®t aussi dans le cas oÃ¹ lâ€™on effectue une sÃ©lection dâ€™exemples non i.i.d.
comme par exemple une sÃ©lection de donnÃ©es dâ€™apprentissage artificiellement Ã©quilibrÃ©e (mais
non Ã©quilibrÃ© dans le jeu de test) ou encore dans le cadre de lâ€™apprentissage actif (Bondu et
Lemaire, 2008). Il existe un dÃ©bat sur cette notion de covariate shift, on peut en effet supposer
que la distribution sous-jacente des exemples (DX ) ne change pas mais que ce sont que les
exemples que lâ€™on observe effectivement qui changent.
Dans la suite de cet article et en particulier dans la section 6 on sâ€™intÃ©ressera principalement
Ã  la dÃ©rive de P (Y |X). On supposera, Ã©tant donnÃ© un contexte, quâ€™il nâ€™y a pas de covariate
shift. Le lecteur intÃ©ressÃ© trouvera dans (Joaquin Quinonero-Candela et al., 2009) et (CornuÃ©-
jols, 2009) des Ã©lÃ©ments sur le sujet du covariate shift.
Gama dans (Gama, 2010) traite par ailleurs de la notion de contexte. Un contexte est dÃ©fini
par un ensemble dâ€™exemples pour lesquels il nâ€™y a pas de dÃ©rive de concept. Un flux de donnÃ©es
peut donc Ãªtre vu comme une sÃ©quence de contexte. Etre capable de traiter ce flux consiste
alors Ã  Ãªtre capable de dÃ©tecter les dÃ©rives de concepts et/ou dâ€™Ãªtre capable de travailler avec
plusieurs contextes en simultanÃ© (voir Section 6).
2.1.4 Questions Ã  se poser
Les diffÃ©rents paragraphes ci-dessus montrent quâ€™il est nÃ©cessaire, lors de la mise en place
dâ€™un systÃ¨me basÃ© sur un classifieur supervisÃ©, de se poser certaines questions :
â€“ Les exemples peuvent-ils Ãªtre stockÃ©s en mÃ©moire ?
â€“ Quelle est la disponibilitÃ© des exemples : tous prÃ©sents ? en flux ? visibles une seule fois ?
â€“ Le concept est-il stationnaire ?
â€“ Lâ€™algorithme doit-il Ãªtre anytime ?
â€“ Quel est le temps disponible pour mettre Ã  jour le modÃ¨le ?
Les rÃ©ponses Ã  ces questions doivent permettre de sÃ©lectionner les algorithmes adaptÃ©s Ã  la
situation et de savoir si on a besoin dâ€™un algorithme incrÃ©mental, voire dâ€™un algorithme spÃ©ci-
fique aux flux.
2.2 Les familles dâ€™algorithmes dâ€™apprentissage
La partie prÃ©cÃ©dente a prÃ©sentÃ© les diffÃ©rentes contraintes par rapport aux exemples qui
peuvent parfois arriver en continu, en quantitÃ© et vitesse importantes. Selon ces diffÃ©rents cas
de figures il existe diffÃ©rents types dâ€™algorithmes dâ€™apprentissage qui peuvent Ãªtre utilisÃ©s.
2.2.1 Apprentissage hors ligne
Lâ€™apprentissage hors ligne correspond Ã  lâ€™apprentissage dâ€™un modÃ¨le sur un jeu de donnÃ©es
reprÃ©sentatif du problÃ¨me et disponible au moment de lâ€™apprentissage. Ce type dâ€™apprentis-
C. Salperwyck et al.
sage est rÃ©alisable sur des volumes de taille faible Ã  moyenne (jusquâ€™Ã  quelques Go). Au delÃ 
le temps dâ€™accÃ¨s et de lecture des donnÃ©es devient prohibitif et il devient difficile de rÃ©aliser
un apprentissage rapide (qui ne prennent pas des heures ou des jours). Ce type dâ€™algorithme
montre ses limites dans le cas oÃ¹ (i) les donnÃ©es ne sont pas entiÃ¨rement chargeables en mÃ©-
moire ou arrive de maniÃ¨re continue ; (ii) la complexitÃ© calculatoire de lâ€™algorithme dâ€™appren-
tissage est supÃ©rieure Ã  une complexitÃ© dite quasi-linÃ©aire. Lâ€™apprentissage incrÃ©mental est bien
souvent une alternative intÃ©ressante face Ã  ce genre de problÃ¨me.
2.2.2 Apprentissage incrÃ©mental
Lâ€™apprentissage incrÃ©mental correspond Ã  un systÃ¨me capable de recevoir et dâ€™intÃ©grer de
nouveaux exemples sans devoir rÃ©aliser un apprentissage complet. Un algorithme dâ€™apprentis-
sage est incrÃ©mental si, pour nâ€™importe quels exemples x1, ..., xn il est capable de produire des
hypothÃ¨ses f1, ..., fn tel que fi+1 ne dÃ©pend que de fi et de lâ€™exemple courant xi. Par exten-
sion de la dÃ©finition la notion â€œdâ€™exemple courantâ€ peut Ãªtre Ã©tendu Ã  un rÃ©sumÃ© des derniers
exemples vus, rÃ©sumÃ© utile Ã  lâ€™algorithme dâ€™apprentissage utilisÃ©. Les propriÃ©tÃ©s dÃ©sirÃ©es dâ€™un
algorithme incrÃ©mental sont un temps dâ€™apprentissage beaucoup plus rapide par comparaison Ã 
lâ€™apprentissage hors ligne. Pour atteindre cet objectif les algorithmes ne lisent souvent quâ€™une
seule fois les exemples ce qui permet en gÃ©nÃ©ral de traiter de plus grandes volumÃ©tries.
2.2.3 Apprentissage en ligne
Le qualificatif â€œen ligneâ€ est ajoutÃ© lorsque que lâ€™arrivÃ©e des exemples se fait de maniÃ¨re
continue pour rÃ©aliser cet apprentissage et que lâ€™algorithme est capable de fournir un modÃ¨le
intÃ©grant ce nouvel exemple. Les exigences en termes de complexitÃ© calculatoire sont plus
fortes que pour lâ€™apprentissage incrÃ©mental. Par exemple on cherchera Ã  obtenir une com-
plexitÃ© calculatoire constante (O(1)) si lâ€™on dÃ©sire rÃ©aliser un algorithme dâ€™apprentissage Ã 
partir de flux. Il sâ€™agit dâ€™apprendre et de prÃ©dire Ã  la vitesse du flux. Bien souvent sâ€™ajoutent Ã 
cette diffÃ©rence essentielle des contraintes de mÃ©moire et des problÃ¨mes de dÃ©rive de concept.
2.2.4 Apprentissage anytime
La dÃ©finition de lâ€™apprentissage anytime est ici restreinte au fait dâ€™apprendre le meilleur
modÃ¨le possible (Ã©tant donnÃ© un critÃ¨re dâ€™Ã©valuation) jusquâ€™Ã  une interruption (qui peut Ãªtre
lâ€™arrivÃ©e dâ€™un nouvel exemple). La famille des algorithmes par contrat est assez proche de celle
des algorithmes anytime. (Zilberstein et Russell, 1996) proposent un algorithme sâ€™adaptant aux
ressources (temps / processeur / mÃ©moire) qui lui sont passÃ©es en paramÃ¨tres.
3 Apprentissage incrÃ©mental
3.1 Introduction
De nombreux algorithmes dâ€™apprentissage sont adaptÃ©s au problÃ¨me de la classification
supervisÃ©e. Sans tous les citer il existe : les SÃ©parateurs Ã  Vastes Marges (SVM), les rÃ©seaux
de neurones, les mÃ©thodes des k plus proches voisins, les arbres de dÃ©cision, la rÃ©gression
logistique, lâ€™analyse discriminante linÃ©aire, etc. Lâ€™utilisation de tel ou tel algorithme dÃ©pend
fortement de la tÃ¢che Ã  rÃ©soudre et du dÃ©sir dâ€™interprÃ©tabilitÃ© du modÃ¨le. Dans cet article il
Classification incrÃ©mentale supervisÃ©e : un panel introductif
est impossible de tous les passer en revue. Les sections ci-dessous se concentrent sur les algo-
rithmes les plus utilisÃ©s dans le cadre de lâ€™apprentissage incrÃ©mental.
3.2 Arbre de dÃ©cision
Un arbre de dÃ©cision (Quinlan, 1986; Breiman et al., 1984) est un modÃ¨le de classifica-
tion (pour cet article) prÃ©sentÃ© sous la forme graphique dâ€™un arbre. Lâ€™extrÃ©mitÃ© de chaque
branche est une feuille qui prÃ©sente le rÃ©sultat obtenu en fonction des dÃ©cisions prises Ã  par-
tir de la racine de lâ€™arbre jusquâ€™Ã  cette feuille. Les feuilles intermÃ©diaires sont appelÃ©es des
nÅ“uds. Chaque nÅ“ud de lâ€™arbre contient un test sur un attribut qui permet de distribuer les
donnÃ©es dans les diffÃ©rents sous-arbres. Lors de la construction de lâ€™arbre un critÃ¨re de puretÃ©
comme lâ€™entropie (utilisÃ© dans C4.5) ou Gini (utilisÃ© dans CART) est utilisÃ© pour transformer
une feuille en nÅ“ud. Lâ€™objectif est de produire des groupes dâ€™individus les plus homogÃ¨nes
possibles du point de vue de la variable Ã  prÃ©dire (pour plus de dÃ©tails voir par exemple (Cor-
nuÃ©jols et Miclet, 2010) chapitre 13). En prÃ©diction, un exemple Ã  classer "descend" lâ€™arbre
depuis la racine jusquâ€™Ã  une unique feuille. Son trajet dans lâ€™arbre est entiÃ¨rement dÃ©terminÃ©
par les valeurs de ses attributs. Il est alors affectÃ© Ã  la classe dominante de la feuille avec pour
score la proportion dâ€™individus dans la feuille qui appartiennent Ã  cette classe.
Les arbres de dÃ©cision possÃ¨dent les avantages suivant : (i) la lisibilitÃ© du modÃ¨le, (ii) la
capacitÃ© Ã  trouver les variables discriminantes dans un important volume de donnÃ©es. Les algo-
rithmes de rÃ©fÃ©rences de la littÃ©rature sont ID3, C4.5, CART mais ils ne sont pas incrÃ©mentaux.
Des versions incrÃ©mentales des arbres de dÃ©cision sont assez rapidement apparues. (Schlim-
mer et Fisher, 1986) propose ID4 et (Utgoff, 1989) propose ID5R qui sont basÃ©s sur ID3 mais
dont la construction est incrÃ©mentale. ID5R garantit la construction dâ€™un arbre similaire Ã  ID3
alors quâ€™ID4 peut dans certains cas ne pas converger et dans dâ€™autre cas avoir une prÃ©diction
mÃ©diocre. Plus rÃ©cemment (Utgoff et al., 1997) propose ITI dont le fonctionnement est basÃ©
sur le maintien de statistiques dans les feuilles permettant une restructuration de lâ€™arbre lors de
lâ€™arrivÃ©e des nouveaux exemples.
La lisibilitÃ© des arbres ainsi que leur rapiditÃ© de classement en font un choix trÃ¨s perti-
nent pour une utilisation sur dâ€™importantes quantitÃ©s de donnÃ©es. Cependant les arbres ne sont
pas trÃ¨s adaptÃ©s aux changements de concept car dans ce cas dâ€™importantes parties de lâ€™arbre
doivent Ãªtre Ã©laguÃ©es et rÃ©apprises.
3.3 SÃ©parateurs Ã  Vaste Marge
Les bases des SÃ©parateurs Ã  Vaste Marge (SVM) datent de 1963 et ont Ã©tÃ© proposÃ©es par
Vapnik, pÃ¨re de cette thÃ©orie. Cependant les premiÃ¨res vraies publications basÃ©es sur ce pro-
cÃ©dÃ© de classification sont apparues dans (Boser et al., 1992; Cortes et Vapnik, 1995). Lâ€™idÃ©e
de base est de trouver lâ€™hyperplan qui maximise la distance (la marge) entre les exemples de
classes diffÃ©rentes.
Des versions incrÃ©mentales des SVM ont Ã©tÃ© proposÃ©es, parmi celles-ci (Domeniconi et
Gunopulos, 2001) propose un dÃ©coupage des donnÃ©es en partitions et quatre techniques diffÃ©-
rentes pour rÃ©aliser lâ€™apprentissage incrÃ©mental :
â€“ ED - Error Driven technique : lors de lâ€™arrivÃ©e de nouveaux exemples, ceux qui sont mal
classifiÃ©s sont conservÃ©s pour modifier le SVM.
C. Salperwyck et al.
â€“ FP - Fixed Partition technique : un apprentissage sur chacune des partitions est rÃ©alisÃ© et
les vecteurs supports rÃ©sultants sont agrÃ©gÃ©s ensemble (Syed et al., 1999).
â€“ EM - Exceeding-Margin technique : lors de lâ€™arrivÃ©e de nouveaux exemples, ceux qui se
situent dans la zone de marge de lâ€™hyperplan sont conservÃ©s. Lorsquâ€™un nombre assez
important de ces exemples est collectÃ© le SVM est mis Ã  jour.
â€“ EM+E - Exceeding-margin+errors technique : utilisation de â€œEDâ€ et â€œEMâ€, les exemples
qui se situent dans la zone de marge et ceux qui sont mal classifiÃ©s sont conservÃ©s.
(Fung et Mangasarian, 2002) propose un PSVM - Proximal SVM, qui au lieu de voir une
frontiÃ¨re comme Ã©tant un plan, la voit comme plusieurs plans (un espace) Ã  proximitÃ© du plan
de frontiÃ¨re. Les exemples supportant les vecteurs supports ainsi quâ€™un ensemble de points
situÃ©s dans lâ€™espace proche autour de lâ€™hyperplan frontiÃ¨re sont conservÃ©s. En faisant Ã©voluer
cet ensemble, on enlÃ¨ve certains exemples trop anciens et on rajoute les nouveaux exemples ce
qui permet de rendre le SVM incrÃ©mental.
Plus rÃ©cemment lâ€™algorithme LASVM (Bordes et Bottou, 2005; Bordes et al., 2005; Loosli
et al., 2006) a Ã©tÃ© proposÃ©. Il sâ€™appuie sur une sÃ©lection active des points Ã  intÃ©grer dans la
solution et donne des rÃ©sultats trÃ¨s satisfaisants pour une utilisation en ligne. Lâ€™apprentissage
peut Ãªtre interrompu Ã  tout moment, avec une Ã©tape Ã©ventuelle de finalisation (qui correspond
Ã  Ã©liminer les vecteurs supports devenus obsolÃ¨tes). Cette Ã©tape de finalisation faite rÃ©guliÃ¨-
rement au cours de lâ€™apprentissage en ligne permet de rester proche des solutions optimales.
Du cÃ´tÃ© de la complexitÃ© calculatoire il nâ€™y a quâ€™une rÃ©solution analytique Ã  chaque Ã©tape. Du
cÃ´tÃ© mÃ©moire, lâ€™algorithme peut Ãªtre paramÃ©trÃ© et câ€™est alors une question de compromis entre
temps de calcul et espace mÃ©moire.
3.4 SystÃ¨me Ã  base de rÃ¨gles
En informatique, les systÃ¨mes Ã  base de rÃ¨gles (Buchanan, 1984) sont utilisÃ©s comme un
moyen de stocker et de manipuler des connaissances pour interprÃ©ter lâ€™information de maniÃ¨re
utile. Un exemple classique dâ€™un systÃ¨me fondÃ© sur des rÃ¨gles est le systÃ¨me expert dâ€™un do-
maine spÃ©cifique qui utilise des rÃ¨gles pour faire des dÃ©ductions ou des choix. Par exemple, un
systÃ¨me expert peut aider un mÃ©decin Ã  choisir le bon diagnostic qui repose sur un ensemble
de symptÃ´mes. Un systÃ¨me Ã  base de rÃ¨gles possÃ¨de une liste de rÃ¨gles ou base de rÃ¨gles, qui
constitue la base de connaissances. Cette base connaissance est soit donnÃ©e par un expert du
domaine soit Ã©laborÃ©e (extraite) Ã  partir dâ€™un ensemble dâ€™apprentissage. Si elle est extraite de
maniÃ¨re automatique il existe un certain nombre de critÃ¨res qui permettent de juger de la qua-
litÃ© des rÃ¨gles. Nous invitons le lecteur Ã  se reporter Ã  (Lallich et al., 2007) pour une revue et
une analyse dâ€™un grand nombre de mesures existantes.
Plusieurs algorithmes Ã  base de rÃ¨gles ont Ã©tÃ© dÃ©veloppÃ©s pour Ãªtre mis Ã  jour de maniÃ¨re
incrÃ©mentale, parmi ceux-ci on peut citer :
â€“ STAGGER (Schlimmer et Granger, 1986) est le premier systÃ¨me Ã  avoir Ã©tÃ© conÃ§u pour
traiter le concept drift. Il se base sur deux processus : le premier modifie le poids des
attributs des rÃ¨gles et le deuxiÃ¨me ajoute de nouveaux attributs dans les rÃ¨gles.
â€“ FLORA, FLORA3 (Widmer et Kubat, 1996) dont le principe de fonctionnement repose
sur des fenÃªtres et un systÃ¨me de gestion des contextes pour les enregistrer et les rÃ©activer
si nÃ©cessaire.
Classification incrÃ©mentale supervisÃ©e : un panel introductif
â€“ AQ-PM (Maloof et Michalski, 2000) est basÃ© sur un systÃ¨me de conservation des exemples
aux frontiÃ¨res des rÃ¨gles et dâ€™un mÃ©canisme dâ€™oubli lui permettant de faire face aux
changements de concepts.
3.5 Approche Bayesienne naÃ¯ve
Dans cette section on sâ€™intÃ©resse au prÃ©dicteur classifieur (ici restreint au classifieur) naÃ¯f
de Bayes. Le classifieur Bayesien naÃ¯f (Langley et al., 1992) suppose que les variables ex-
plicatives sont indÃ©pendantes sachant la classe cible. Cette hypothÃ¨se rÃ©duit drastiquement
les calculs nÃ©cessaires. Ce prÃ©dicteur sâ€™est avÃ©rÃ© trÃ¨s compÃ©titif sur de nombreux jeux de don-
nÃ©es rÃ©els. Ses performances dÃ©pendent gÃ©nÃ©ralement dâ€™une estimation prÃ©cise des probabilitÃ©s
conditionnelles univariÃ©es et dâ€™une sÃ©lection de variables efficace.
Le principal avantage de cette approche est sa vitesse dâ€™apprentissage et sa faible variance.
Avec trÃ¨s peu de donnÃ©es la prÃ©cision est bien souvent meilleure quâ€™avec dâ€™autres algorithmes
comme lâ€™expÃ©rimente Domingos dans (Domingos et Pazzani, 1997). Cette qualitÃ© fait que le
Bayesien naÃ¯f est assez souvent utilisÃ© en combinaison avec dâ€™autres algorithmes, comme par
exemple les arbres de dÃ©cision dans (Kohavi, 1996) : NBTree. De plus par nature lâ€™approche
Bayesienne naÃ¯ve est naturellement incrÃ©mentale et peut Ãªtre mis Ã  jour sans quâ€™il soit nÃ©ces-
saire de tout recalculer. En effet, il suffit de mettre Ã  jour les comptes permettant de calculer
les probabilitÃ©s conditionnelles univariÃ©es. Ces probabilitÃ©s Ã©tant basÃ©es sur une estimation
des densitÃ©s, le problÃ¨me rÃ©side dans lâ€™estimation incrÃ©mentale des densitÃ©s conditionnelles.
(John et Langley, 1995) expÃ©rimentent deux mÃ©thodes dâ€™estimation de densitÃ© : une gaussienne
unique et des noyaux multiples. Il prÃ©sente leurs complexitÃ©s spatiales et temporelles ainsi que
lâ€™incrÃ©mentalitÃ© naturelle de lâ€™estimation par une gaussienne en mettant Ã  jour la moyenne et
la variance. (Lu et al., 2006) propose IFFD, une mÃ©thode de discrÃ©tisation incrÃ©mentale per-
mettant de ne pas rÃ©aliser une discrÃ©tisation complÃ¨te Ã  lâ€™arrivÃ©e de chaque exemple et donc de
ne pas recalculer toutes les probabilitÃ©s conditionnelles. IFFD ne rÃ©alise que deux opÃ©rations :
ajout dâ€™une valeur Ã  un intervalle ou Ã©clatement dâ€™un intervalle en deux.
Les mÃ©thodes Bayesiennes non naÃ¯ves rÃ©alisent des agrÃ©gations de variables et/ou valeurs
mais ne sont pas aisÃ©ment incrÃ©mentales.
3.6 Plus proches voisins - approche passive
Les mÃ©thodes passives (lazy learning (Aha, 1997)), comme par exemple les k plus proches
voisins (k-ppv), sont appelÃ©es passives car il nâ€™y a pas rÃ©ellement de phase dâ€™apprentissage
mais simplement une conservation de certains exemples. A proprement parler, on ne construit
jamais de modÃ¨le Â« global Â» des donnÃ©es, on se contente dâ€™un modÃ¨le local construit Ã  la de-
mande au moment de lâ€™apparition dâ€™un nouveau motif. Rendre ces mÃ©thodes incrÃ©mentales
est donc assez simple car il suffit de mettre Ã  jour la base dâ€™exemples conservÃ©e voire de
nâ€™en garder quâ€™une partie comme le propose (Brighton et Mellish, 2002). Tout le traitement a
lieu pendant la phase de classification lors de la recherche du plus proche voisin. Lâ€™approche
typique de ce type de mÃ©thodes est de trouver au sein de lâ€™ensemble des exemples dâ€™apprentis-
sage conservÃ©s ceux qui sont les plus proches de la donnÃ©e que lâ€™on souhaite Ã©tiqueter. La(es)
classe(s) des exemples proches trouvÃ©e(s) donne une bonne indication de la classe Ã  prÃ©dire
pour la donnÃ©e prÃ©sentÃ©e.
C. Salperwyck et al.
La littÃ©rature sâ€™est consacrÃ©e en grande partie dâ€™une part (i) Ã  accÃ©lÃ©rer la recherche des
k-ppv (V. Hooman et al., 2000; Moreno-Seco et al., 2002) et dâ€™autre part (ii) Ã  lâ€™apprentissage
de mÃ©trique (Kononenko et Robnik, 2003; Globersonn et Roweis, 2005; Weinberger et Saul,
2009). On trouvera aussi dans (Sankaranarayanan et al., 2007) un travail trÃ¨s intÃ©ressant dont
une comparaison â€œincrÃ©mental versus non incrÃ©mentalâ€ dâ€™une mÃ©thode Ã  k-ppv.
4 Apprentissage incrÃ©mental sur flux
4.1 Introduction
Depuis les annÃ©es 2000, le volume de donnÃ©es Ã  traiter a fortement augmentÃ© avec lâ€™essor
dâ€™internet et plus rÃ©cemment des rÃ©seaux sociaux. Ces donnÃ©es arrivent sÃ©quentiellement et en
continu et ne sont accessibles quâ€™au moment de leur passage : on parle alors de flux de donnÃ©es.
Des algorithmes spÃ©cifiques pour traiter lâ€™apprentissage supervisÃ© de maniÃ¨re optimale dans
ces conditions ont Ã©tÃ© proposÃ©s. Cette partie est une prÃ©sentation des principales mÃ©thodes de
la littÃ©rature. Dans cette section la partie sur les arbres de dÃ©cision est plus dÃ©taillÃ©e, ceci Ã©tant
dÃ» au nombre dâ€™articles dÃ©diÃ©s Ã  ces techniques.
On peut se demander en premier lieu quelles sont les propriÃ©tÃ©s dÃ©sirÃ©es dâ€™un algorithme
de classification incrÃ©mentale sur les flux. Domingos dans un article de rÃ©flexion sur lâ€™appren-
tissage sur les flux (Domingos et Hulten, 2001) propose les critÃ¨res suivants :
â€“ durÃ©e faible et constante pour apprendre les exemples ;
â€“ lecture dâ€™une seule fois des exemples et dans leur ordre dâ€™arrivÃ©e ;
â€“ utilisation dâ€™une quantitÃ© de mÃ©moire fixÃ©e Ã  priori ;
â€“ production dâ€™un modÃ¨le proche de celui qui aurait Ã©tÃ© gÃ©nÃ©rÃ© sâ€™il nâ€™y avait pas eu la
contrainte de flux ;
â€“ possibilitÃ© dâ€™interroger le modÃ¨le Ã  nâ€™importe quel moment (anytime) ;
â€“ possibilitÃ© de suivre les changements de concept.
Des critÃ¨res assez similaires avaient dÃ©jÃ  Ã©tÃ© abordÃ©s par (Fayyad et al., 1996) dans le cadre
des bases de donnÃ©es de taille importante. Plus rÃ©cemment, (Stonebraker et al., 2005) propose
huit propriÃ©tÃ©s dâ€™un bon algorithme de traitement temps rÃ©el des flux. Cependant il se situe
plutÃ´t dans le cadre de la base de donnÃ©es que dans celui de lâ€™apprentissage. Le tableau 1
prÃ©sente une comparaison des diffÃ©rentes propriÃ©tÃ©s dÃ©sirÃ©es selon les auteurs.
(1) (2) (3)
itÃ©ratif/incrÃ©mental x x
lecture une seule fois des donnÃ©es x x x
gestion de la mÃ©moire/ressources x x x
anytime x x x
gestion de la dÃ©rive de concept x
TAB. 1 â€“ PropriÃ©tÃ©s dâ€™un bon algorithme dâ€™apprentissage sur flux de donnÃ©es : (1)= (Fayyad
et al., 1996) ; (2)= (Hulten et al., 2001) ; (3)= (Stonebraker et al., 2005) .
Dans un deuxiÃ¨me temps on sâ€™intÃ©resse aux Ã©lÃ©ments de comparaison des diffÃ©rents al-
gorithmes. Le tableau 2 compare les diffÃ©rents algorithmes par rapport aux critÃ¨res gÃ©nÃ©ra-
lement utilisÃ©s (Zighed et Rakotomalala, 2000) pour Ã©valuer un algorithme dâ€™apprentissage.
Classification incrÃ©mentale supervisÃ©e : un panel introductif
La complexitÃ© en dÃ©ploiement est donnÃ©e dans ce tableau pour un problÃ¨me Ã  deux classes et
reprÃ©sente la complexitÃ© au pire cas pour obtenir lâ€™une des probabilitÃ©s conditionnelles pour
un exemple en test (P (Ck|X)). On notera que cette complexitÃ© maximale est rarement atteinte
pour certain classifieur : Ã  titre dâ€™exemple pour un arbre elle est de fait (si lâ€™arbre nâ€™est pas
complÃ¨tement dÃ©sÃ©quilibrÃ©) en O(h) oÃ¹ h dÃ©signe la hauteur de lâ€™arbre.
CritÃ¨re Arbre dedÃ©cision SVM
Plus proche
voisin
SystÃ¨me Ã 
base de
rÃ¨gles
Bayesien
naÃ¯f
QualitÃ© de lâ€™algorithme dâ€™apprentissage
RapiditÃ© dâ€™apprentissage + - - + + - +
ComplexitÃ© en dÃ©ploiement O(a) O(sj) O(nj) O(ab) O(j)
RapiditÃ© et facilitÃ© de mise Ã  jour - - - + + + + +
CPU - mÃ©moire + + - - + +
Pertinence du classifieur obtenu
PrÃ©cision + + + + + + + +
SimplicitÃ© (nombre de paramÃ¨tres) - - + + + + +
RapiditÃ© de classement + + - - + + +
ComprÃ©hensibilitÃ© + + - + + + + + +
GÃ©nÃ©ralisation - SensibilitÃ© au bruit - - + + - - + +
TAB. 2 â€“ Comparatif des principaux algorithmes. On note dans ce tableau : n le nombre
dâ€™exemples ; j le nombre dâ€™attributs ; a le nombre de rÃ¨gles ; b le nombre moyen de prÃ©mices
par rÃ¨gle et s le nombre de vecteurs supports.
Finalement les diffÃ©rences entre apprentissage incrÃ©mental et apprentissage incrÃ©mental
pour flux de donnÃ©es sont prÃ©sentÃ©es dans le tableau 3. On appelle phase de "Post-optimisation"
une phase qui aurait pour but dâ€™amÃ©liorer la solution trouvÃ©e aprÃ¨s la premiÃ¨re passe sur les
exemples. Cette passe de post-optimisation peut chercher Ã  amÃ©liorer le modÃ¨le obtenu sans
nÃ©cessairement avoir besoin de relire les exemples.
IncrÃ©mental IncrÃ©mental sur flux
RÃ©glage des paramÃ¨tres du classifieur
via une validation croisÃ©e Non Non
Lecture dâ€™une seule fois des donnÃ©es Oui Oui
Post-optimisation en fin dâ€™apprentissage Oui Non
ComplexitÃ© calculatoire en apprentissage et en prÃ©diction Faible TrÃ¨s faible
Gestion de la mÃ©moire/ressources Oui Oui
Gestion (ou estimation) de la prÃ©cision vs algorithme offline Oui Oui
Gestion prÃ©cision versus temps pour apprendre Non Oui
Gestion de la dÃ©rive de concept Non Oui
Anytime (interruptible) Non RecommandÃ©
TAB. 3 â€“ PropriÃ©tÃ©s de la classification incrÃ©mentale vis-Ã -vis de la classification incrÃ©men-
tale sur flux (oui=requis, non=non requis).
La suite de cette section propose des algorithmes qui non seulement sont incrÃ©mentaux
mais semblent aussi adaptÃ©s aux flux de donnÃ©es : capable dâ€™apprendre sans ralentir le flux
C. Salperwyck et al.
(complexitÃ© plus basse que ceux de la section prÃ©cÃ©dente), capable dâ€™Ãªtre rÃ©glÃ©s pour aller vers
un compromis temps/mÃ©moire/prÃ©cision ; et sâ€™attaquant au problÃ¨me de la dÃ©rive de concept.
Ils remplissent tout ou partie des Ã©lÃ©ments du tableau 3.
4.2 Arbre de dÃ©cision
4.2.1 PrÃ©ambule
Limitation des anciens algorithmes : SLIQ (Mehta et al., 1996), SPRINT (Shafer et al.,
1996), RAINFOREST (Gehrke et al., 2000) sont des algorithmes spÃ©cialement conÃ§us pour
fonctionner sur des bases de donnÃ©es de taille importante. Cependant il leurs est nÃ©cessaire
de voir plusieurs fois les donnÃ©es et ils ne satisfont donc pas les contraintes des flux. Certains
algorithmes nâ€™ont besoin de voir les donnÃ©es quâ€™une seule fois comme ID5R (Utgoff, 1989)
ou son successeur ITI (Utgoff et al., 1997). Cependant lâ€™effort pour mettre Ã  jour le modÃ¨le est
parfois plus consÃ©quent que celui pour reconstruire un modÃ¨le Ã  partir de rien. Ces algorithmes
ne peuvent alors plus Ãªtre considÃ©rÃ©s comme â€œen ligneâ€ ou â€œanytimeâ€.
Taille des arbres : De par sa mÃ©thode de construction la taille dâ€™un arbre de dÃ©cision croÃ®t
avec lâ€™arrivÃ©e de nouvelles donnÃ©es (Oates et Jensen, 1997) sans pour autant toujours amÃ©liorer
son taux de bonne prÃ©diction ((Zighed et Rakotomalala, 2000) - p203). Dans le cas des flux,
lâ€™arbre nâ€™arrÃªtera donc pas de grandir si aucun traitement nâ€™est prÃ©vu pour limiter sa croissance.
De nouveaux algorithmes ont Ã©tÃ© dÃ©veloppÃ©s afin de traiter le cas de lâ€™apprentissage sur les flux.
DÃ©rive de concept : Dans le cas oÃ¹ une dÃ©rive de concept apparaÃ®t dans le flux de donnÃ©es
lâ€™arbre doit Ãªtre Ã©lagÃ© ou si possible restructurÃ© (Utgoff, 1989; Utgoff et al., 1997).
Borne dâ€™Hoeffding : De trÃ¨s nombreux algorithmes dâ€™apprentissage incrÃ©mentaux sur les
flux utilisent la borne dâ€™Hoeffding (Hoeffding, 1963) pour dÃ©terminer le nombre minimal de
donnÃ©es nÃ©cessaire Ã  la transformation dâ€™une feuille en nÅ“ud. La borne dâ€™Hoeffding permet
de sâ€™assurer que la vraie moyenne dâ€™une variable alÃ©atoire comprise dans un intervalle R ne
sera pas diffÃ©rente, Ã   prÃ¨s, de sa moyenne estimÃ©e aprÃ¨s n observations indÃ©pendantes, tout
cela avec une probabilitÃ© de 1 âˆ’ Î´ :  =
âˆš
R2
2n ln(
1
Î´ ). Lâ€™intÃ©rÃªt de cette borne est quâ€™elle ne
dÃ©pend pas de la distribution des valeurs mais seulement de : (i) de la plage de valeurs R,
(ii) du nombre dâ€™observations n, (iii) de la confiance dÃ©sirÃ©e Î´. Par contre cette borne est plus
conservatrice que des bornes prenant en compte la distribution des valeurs.
4.2.2 Les principaux algorithmes rencontrÃ©s
On cite ci-dessous les principaux et rÃ©cents algorithmes dâ€™arbres incrÃ©mentaux pour flux
de donnÃ©es trouvÃ©s dans la littÃ©rature :
â€¢ VFDT (Domingos et Hulten, 2000) est considÃ©rÃ© comme un article de rÃ©fÃ©rence de
lâ€™apprentissage sur flux de donnÃ©es sachant gÃ©rer plusieurs millions dâ€™exemples. Il est trÃ¨s
largement citÃ© et comparÃ© aux nouvelles approches proposÃ©es depuis lâ€™annÃ©e 2000 sur la
mÃªme problÃ©matique. Dans VFDT, la crÃ©ation de lâ€™arbre est incrÃ©mentale et aucun exemple
nâ€™est conservÃ©. Le taux dâ€™erreurs de lâ€™algorithme est plus important en dÃ©but dâ€™apprentissage
quâ€™un algorithme comme C4.5. Cependant aprÃ¨s avoir appris plusieurs centaines de milliers
dâ€™exemples, ce taux dâ€™erreur devient plus faible car C4.5 nâ€™est pas capable de travailler avec
Classification incrÃ©mentale supervisÃ©e : un panel introductif
des millions dâ€™exemples et doit donc nâ€™en utiliser quâ€™une partie. La figure 1 extraite de lâ€™article
de VFDT montre ce comportement et lâ€™intÃ©rÃªt de VFDT par rapport Ã  C4.5. De plus, Domin-
gos et Hulten ont prouvÃ© que les â€œHoeffding Treesâ€ sont proches de lâ€™arbre appris qui aurait Ã©tÃ©
gÃ©nÃ©rÃ© par un algorithme hors ligne. Afin de pouvoir mieux rÃ©pondre Ã  la problÃ©matique des
flux VFDT peut Ãªtre paramÃ©trÃ©. Les deux principaux paramÃ¨tres sont : (i) la quantitÃ© maximale
de mÃ©moire Ã  utiliser, (ii) le nombre minimal dâ€™exemples Ã  voir avant de rÃ©aliser le calcul du
critÃ¨re.
FIG. 1 â€“ Comparaison de C4.5 avec VFDT (extraite de (Domingos et Hulten, 2000))
â€¢ CVFDT (Hulten et al., 2001) est une extension de VFDT pour gÃ©rer les changements
de concept. Des sous arbres alternatifs sont construits si un changement de concept est dÃ©-
tectÃ©. Ces sous-arbres alternatifs remplacent le sous arbre original quand leurs taux dâ€™erreurs
deviennent plus faibles. Pour limiter lâ€™utilisation de la mÃ©moire seuls les sous arbres les plus
prometteurs sont conservÃ©s. MalgrÃ© lâ€™utilisation dâ€™une fenÃªtre temporelle sur les exemples, la
complexitÃ© reste en O(1) car on ne parcours pas Ã  nouveau toutes les donnÃ©es de la fenÃªtre mais
on utilise seulement la nouvelle donnÃ©e arrivÃ©e. Dâ€™aprÃ¨s les expÃ©rimentations numÃ©riques de
(Hulten et al., 2001) sur le jeu de donnÃ©es des â€œhyperplans en mouvementâ€ (voir Tableau 4).
On constate que le modÃ¨le contient quatre fois moins de nÅ“uds mais consomme cinq fois plus
de temps comparativement Ã  VFDT.
â€¢ VFDTc (Gama et al., 2003) est une extension de VFDT qui gÃ¨re les attributs numÃ©riques
continus et non plus seulement catÃ©goriels. Dans chaque feuille on conserve par attribut les
comptes des valeurs numÃ©riques qui ont atteint cette feuille. Cela permet par la suite de trouver
la meilleure valeur de coupure pour cet attribut pour transformer un nÅ“ud en feuille. De plus
un classifieur Bayesien naÃ¯f est ajoutÃ© dans les feuilles afin dâ€™amÃ©liorer la prÃ©diction. (Gama
et al., 2003) observe quâ€™il faut de 100 Ã  1000 exemples avant de transformer une feuille en
nÅ“ud. Ces exemples dans les feuilles ne sont pas utilisÃ©s pour amÃ©liorer le modÃ¨le tant que
la feuille nâ€™est pas transformÃ©e en nÅ“ud. VFDTc propose dâ€™utiliser ces exemples en ajoutant
dans chaque feuille un modÃ¨le local. Le classifieur Bayesien naÃ¯f est connu pour apprendre
bien et vite sur peu de donnÃ©es (cf. 3.5). Câ€™est donc le classifieur choisi pour Ãªtre utilisÃ© dans
les feuilles. Cette modification amÃ©liore la prÃ©diction de lâ€™arbre sur les jeux de tests WaveForm
et LED de lâ€™UCI.
C. Salperwyck et al.
â€¢ Dans IADEM (Ramos-Jimenez et al., 2006) et IADEMc (del Campo-Avila et al., 2006)
la construction de lâ€™arbre est aussi basÃ©e sur la borne dâ€™Hoeffding. La croissance de lâ€™arbre
est gÃ©rÃ©e Ã  lâ€™aide du taux dâ€™erreurs de celui-ci. Lâ€™arbre se dÃ©veloppe jusquâ€™Ã  arriver au taux
dâ€™erreurs maximum passÃ© en paramÃ¨tre de lâ€™algorithme. IADEMc est une extension qui permet
de gÃ©rer les attributs continus et qui possÃ¨de un classifieur Bayesien naÃ¯f dans les feuilles
(comme pour VFDTc). Les expÃ©rimentations rÃ©alisÃ©es sur les jeux de tests WaveForm et LED
montrent les diffÃ©rences suivantes par rapport Ã  VFDTc : une prÃ©diction lÃ©gÃ¨rement moins
bonne mais des arbres dont la taille Ã©volue beaucoup moins.
â€¢ Enfin Kirkby dans (Kirkby, 2008) rÃ©alise une Ã©tude sur les â€œHoeffding Treeâ€ et pro-
pose des amÃ©liorations Ã  lâ€™aide dâ€™ensemble dâ€™â€œHoeffding Treeâ€. Sa premiÃ¨re modification
consiste Ã  avoir dans les feuilles soit un modÃ¨le basÃ© sur la classe majoritaire soit un modÃ¨le
Bayesien naÃ¯f. Ses expÃ©riences ont montrÃ© que le Bayesien naÃ¯f nâ€™Ã©tait pas toujours le meilleur
choix. Le classifieur qui a la plus faible erreur est conservÃ© comme classifieur dans les feuilles.
Sa deuxiÃ¨me modification aboutit Ã  la proposition des â€œHoeffding Option Treesâ€ (inspirÃ© de
(Kohavi et Kunz, 1997)) qui sont une variante des â€œHoeffding treesâ€ possÃ©dant plusieurs sous-
arbres dans chaque nÅ“ud. Les mÃªmes exemples dâ€™apprentissage peuvent mettre Ã  jour plusieurs
arbres en mÃªme temps. La prÃ©diction se fait par un vote Ã  la majoritÃ© qui dÃ©termine la classe
prÃ©dite. Les techniques de bagging et de boosting sont aussi expÃ©rimentÃ©es : le bagging permet
une amÃ©lioration de la prÃ©diction mais pour le boosting le rÃ©sultat est plus mitigÃ©.
4.2.3 Discussion
Limite des arbres : Du fait de la structure en arbre, le premier nÅ“ud a une trÃ¨s grande
importance et si un changement de concept se produit sur ce nÅ“ud ou sur des nÅ“uds assez haut,
lâ€™Ã©volution de lâ€™arbre est plus difficile, voire une reconstruction complÃ¨te peut Ãªtre nÃ©cessaire
comme lâ€™indique (Wang et al., 2003). Dans ce cas particulier, lâ€™utilisation des arbres pour la
classification sur un flux non stationnaire peut sâ€™avÃ©rer coÃ»teuse. La capacitÃ© Ã  se restructurer
dâ€™un arbre construit de maniÃ¨re incrÃ©mentale est donc certainement un Ã©lÃ©ment clef de rÃ©ussite.
Du cotÃ© â€œanytimeâ€, (Seidl et al., 2009) propose lâ€™utilisation dâ€™un arbre Bayesien conte-
nant dans ses nÅ“uds des informations sur la meilleure prÃ©diction. Ainsi sâ€™il nâ€™est pas possible
dâ€™arriver Ã  une feuille de lâ€™arbre on utilise la prÃ©diction disponible dans les nÅ“uds.
4.3 SÃ©parateurs Ã  Vaste Marge
Les SVMs sont assez peu abordÃ©s dans la littÃ©rature comme classifieur pour les flux de
donnÃ©es. Dans (Tsang et al., 2006), une version des SVMs pour apprendre sur dâ€™importantes
quantitÃ©s dâ€™exemples est prÃ©sentÃ©e. Elle est basÃ©e sur une approximation de la solution opti-
male Ã  lâ€™aide de la rÃ©solution de problÃ¨mes de type â€œMEB - Minimum Enclosing Ballsâ€. Sa
complexitÃ© spatiale est indÃ©pendante de la taille de lâ€™ensemble dâ€™apprentissage. Un paramÃ¨tre
permet de rÃ©gler la prÃ©fÃ©rence pour la rapiditÃ© ou la prÃ©cision du classifieur.
(Dong et al., 2005) prÃ©sentent une optimisation des mÃ©thodes existantes afin dâ€™augmenter
la capacitÃ© des SVMs. Cette optimisation utilise la technique â€œdiviser pour rÃ©gnerâ€ en sÃ©parant
le problÃ¨me en sous problÃ¨me et en trouvant et en Ã©liminant rapidement les exemples nâ€™Ã©tant
pas des vecteurs supports.
On pourrait aussi utiliser LASVM (Bordes et Bottou, 2005; Bordes et al., 2005; Loosli
et al., 2006) sur chaque point du flux prÃ©sentÃ© : soit il est Ã©ligible pour devenir "vecteur sup-
Classification incrÃ©mentale supervisÃ©e : un panel introductif
port" (VS) et alors on met Ã  jour la solution courante ; soit il nâ€™est pas Ã©ligible (loin des fron-
tiÃ¨res courantes indÃ©pendamment de son Ã©tiquette), on ne fait rien. Au pire des cas lorsquâ€™un
exemple est Ã©ligible, la complexitÃ© est au mieux en O(s2) avec s le nombre courant de vecteur
supports. Dans les deux cas (Ã©ligible ou non), le calcul des Ã©lÃ©ments du noyau pour ce point et
le calcul des vecteur supports doivent Ãªtre rÃ©alisÃ©s. On sâ€™aperÃ§oit donc que la complexitÃ© nâ€™est
pas nÃ©gligeable ce qui explique peut Ãªtre que dâ€™un point de vue applicatif on trouve peu de
"LASVM" appliquÃ©s sur des flux de donnÃ©es (comparÃ© Ã  la complexitÃ© des arbres incrÃ©men-
taux par exemple). Un article rÃ©cent prÃ©sente les garanties des algorithmes en ligne du type
LASVM (Usunier et al., 2010).
Lâ€™une des voies dâ€™amÃ©lioration est lâ€™utilisation de SVM linÃ©aire et la parallÃ©lisation des
calculs comme proposÃ© par Poulet et al. (Do et al., 2009). Lâ€™utilisation de ces SVMs sur GPUs
permet dâ€™apprendre sur des flux rapides et dâ€™obtenir des amÃ©liorations, en termes de rapiditÃ©,
supÃ©rieures Ã  un facteur 100.
4.4 SystÃ¨me Ã  base de rÃ¨gles
On trouve peu dâ€™articles concernant lâ€™approche Ã  base de rÃ¨gles appliquÃ©e aux flux. Des
algorithmes incrÃ©mentaux basÃ©s sur les systÃ¨mes Ã  bases de rÃ¨gles existent mais ils ne sont pas
prÃ©vus pour des flux de donnÃ©es. On trouve nÃ©anmoins une sÃ©rie de trois articles de Ferrer et
al. sur ce sujet (Ferrer-Troyano et al., 2005, 2006). Ces derniers proposent lâ€™algorithme FACIL
qui est la premiÃ¨re approche de base de rÃ¨gles incrÃ©mentale sur flux de donnÃ©es et est basÃ© sur
AQ-PM (Maloof et Michalski, 2000).
Lâ€™approche de lâ€™algorithme FACIL se dÃ©finit de la maniÃ¨re suivante :
â€“ Lors de lâ€™arrivÃ©e dâ€™un nouvel exemple, on recherche pour toutes les rÃ¨gles ayant son
Ã©tiquette lesquelles le couvrent et on incrÃ©mente leur support positif.
â€“ Si lâ€™exemple nâ€™est pas couvert alors on recherche la rÃ¨gle qui nÃ©cessite une â€œaugmen-
tationâ€ minimum de son espace couvert. De plus cette augmentation doit Ãªtre limitÃ©e Ã 
une certaine valeur fixÃ©e par un paramÃ¨tre Îº pour Ãªtre acceptÃ©e.
â€“ Si aucune rÃ¨gle ayant la mÃªme Ã©tiquette que lâ€™exemple ne le couvre alors on recherche
dans lâ€™ensemble de rÃ¨gles ayant une Ã©tiquette diffÃ©rente. Si on trouve des rÃ¨gles le cou-
vrant on ajoute lâ€™exemple aux rÃ¨gles comme exemple nÃ©gatif et on incrÃ©mente leur sup-
port nÃ©gatif.
â€“ Si aucune rÃ¨gle ne couvre cet exemple, une nouvelle rÃ¨gle peut Ãªtre crÃ©Ã©e.
â€“ Chaque rÃ¨gle possÃ¨de sa propre fenÃªtre dâ€™oubli de taille variable.
4.5 Approche Bayesienne naÃ¯ve
Lâ€™apprentissage par une approche Bayesienne naÃ¯ve consiste dans un premier temps Ã  rÃ©ali-
ser une estimation des probabilitÃ©s conditionnelles aux classes (voir section 3.5). Cette estima-
tion est trÃ¨s souvent rÃ©alisÃ©e aprÃ¨s une Ã©tape de discrÃ©tisation des variables explicatives. Dans
le cadre des flux de donnÃ©es seule cette premiÃ¨re Ã©tape est modifiÃ©e pour satisfaire la contrainte
du flux. Dans lâ€™Ã©tat de lâ€™art on trouve deux types de publications concernant la discrÃ©tisation
incrÃ©mentale. Celles, assez peu nombreuses, qui concernent lâ€™apprentissage et celles beaucoup
plus nombreuses relatives aux systÃ¨mes de gestion de bases de donnÃ©es qui conservent des
statistiques sous forme dâ€™histogramme.
C. Salperwyck et al.
Dans le cas de lâ€™apprentissage, Gama et Pinto dans (Gama et Pinto, 2006), propose PiD :
â€œPartition Incremental Discretizationâ€ qui rÃ©alise une discrÃ©tisation incrÃ©mentale pour ensuite
rÃ©aliser un apprentissage avec une mÃ©thode Bayesienne naÃ¯ve. Cette discrÃ©tisation est une so-
lution basÃ©e sur deux niveaux :
â€“ au niveau 1, une premiÃ¨re discrÃ©tisation est rÃ©alisÃ©e oÃ¹ lâ€™on stocke les comptes des
classes pour chaque intervalle et oÃ¹ lâ€™on fait Ã©voluer ces intervalles si nÃ©cessaires de la
maniÃ¨re suivante : si jamais des valeurs en dehors du domaine arrivent alors on rajoute
des intervalles (âˆ¼EqualWidth) ; si un intervalle contient trop de valeurs alors on le dÃ©-
coupe en 2 intervalles (âˆ¼EqualFreq). La mise Ã  jour se fait de maniÃ¨re incrÃ©mentale. Ce
premier niveau doit contenir plus dâ€™intervalles que le niveau 2. Le nombre dâ€™intervalles
est un paramÃ¨tre.
â€“ au niveau 2, la discrÃ©tisation rÃ©alisÃ©e au niveau 1 est utilisÃ©e pour rÃ©aliser la discrÃ©ti-
sation finale qui peut Ãªtre (au choix) : EqualWidth, EqualFreq, K-means, Proportional
discretization, Recursive entropy discretization, MDL.
Le problÃ¨me de cette mÃ©thode est que tout dÃ©pend de la discrÃ©tisation de niveau 1. On peut
perdre de lâ€™information sur les bornes de coupure (car on ne garde pas toutes les valeurs) et
sur les comptes (quand on divise Ã  nouveau un intervalle). En cas de distribution Zipfienne
ou de prÃ©sence dâ€™observations aberrantes, on peut se retrouver avec un nombre dâ€™intervalles
beaucoup plus important que prÃ©vu sur le niveau 1.
Dans le cadre des systÃ¨mes de gestion des bases de donnÃ©es (SGBD) on retrouve les esti-
mations par histogramme. Elles sont utilisÃ©es pour avoir des statistiques sur les donnÃ©es afin
de crÃ©er les meilleurs plans dâ€™exÃ©cution et savoir quelles optimisations utiliser. Ces techniques
supportent la plupart du temps lâ€™insertion et la suppression de donnÃ©es dans les bases, or dans
le cas de lâ€™apprentissage il nâ€™est pas nÃ©cessaire de les supporter.
Gibbons et al (Gibbons et al., 2002) proposent des techniques incrÃ©mentales de mise Ã  jour
des histogrammes pour les systÃ¨mes de bases de donnÃ©es. Leur approche est basÃ©e sur deux
structures :
â€“ un rÃ©servoir de donnÃ©es contenant des donnÃ©es reprÃ©sentatives des donnÃ©es rÃ©elles (basÃ©
sur la technique du â€œReservoir samplingâ€ (Vitter, 1985)) ;
â€“ des histogrammes de type â€œEqual Freqâ€ rÃ©sumant les donnÃ©es.
4.6 Plus proches voisins - approche passive
Les algorithmes des plus proches voisins sont facilement incrÃ©mentaux (cf. 3.6). Dans
le cadre de la problÃ©matique dâ€™apprentissage en flux, les solutions consistent Ã  trouver la
meilleure base dâ€™exemples Ã  conserver pour une faible mÃ©moire en (i) oubliant des exemples
les plus anciens, (ii) agrÃ©geant les exemples proches. Dans la littÃ©rature on trouve diffÃ©rentes
mÃ©thodes basÃ©es sur les plus proches voisins pour les flux :
â€“ (Law et Zaniolo, 2005) utilisent une technique de discrÃ©tisation de lâ€™espace dâ€™entrÃ©e afin
de limiter le stockage des exemples.
â€“ (Beringer et HÃ¼llermeier, 2007) conservent les exemples les plus rÃ©cents et gÃ¨rent une
fenÃªtre dâ€™oubli.
Classification incrÃ©mentale supervisÃ©e : un panel introductif
5 Ã‰valuation des algorithmes
RÃ©cemment de nombreux algorithmes ont Ã©tÃ© publiÃ©s pour lâ€™apprentissage sur les flux de
donnÃ©es. Cependant il est difficile de rÃ©aliser une comparaison de ces algorithmes entre eux.
En effet les diffÃ©rents auteurs nâ€™utilisent pas toujours les mÃªmes mÃ©thodes ni les mÃªmes jeux
de tests. Gama dans (Gama et al., 2009) puis dans (Gama, 2010) (chapitre 3) propose une mÃ©-
thode dâ€™expÃ©rimentation pour lâ€™Ã©valuation et la comparaison des algorithmes dâ€™apprentissage
sur les flux. Nous allons dans une premiÃ¨re partie nous intÃ©resser Ã  la mesure du taux de prÃ©dic-
tion utilisÃ©e et dans une seconde partie aux jeux de donnÃ©es utilisÃ©s. Ensuite nous discuterons
dâ€™autres points de comparaison possibles.
5.1 Mesures de prÃ©cision et ensemble de test
Pour lâ€™apprentissage â€œhors-ligneâ€, la mÃ©thode la plus utilisÃ©e est la validation croisÃ©e en
â€œk foldsâ€ (avec k=10). On dÃ©coupe les donnÃ©es en 10 ensembles de taille identique. On se
sert du premier ensemble comme jeu de test et des autres comme exemples dâ€™apprentissage,
puis on prend le deuxiÃ¨me comme jeu de test et les autres pour lâ€™apprentissage, et ainsi de
suite dix fois pour utiliser tous les jeux de tests diffÃ©rents. Les donnÃ©es dâ€™un flux de par leur
quantitÃ© et leur disponibilitÃ© ne sâ€™accommode pas facilement de ce genre de mÃ©thode. Selon
que le flux soit stationnaire ou non-stationnaire (prÃ©sence de changement de concept), plusieurs
mÃ©thodes dâ€™Ã©valuation sont envisageables. Elles sont basÃ©es sur des jeux de donnÃ©es construits
diffÃ©remment :
â€“ un jeu de donnÃ©es indÃ©pendant pour rÃ©aliser le test et que lâ€™on garde tout au long de
lâ€™expÃ©rimentation
â€“ un jeu de donnÃ©es remis Ã  jour rÃ©guliÃ¨rement en tirant au hasard des exemples du flux
qui nâ€™ont pas encore Ã©tÃ© utilisÃ©s pour lâ€™apprentissage
â€“ un jeu de donnÃ©es pris dans les exemples dâ€™apprentissage avant quâ€™ils ne soient ap-
pris (aussi appelÃ© â€œtester puis apprendreâ€ (Kirkby, 2008) ou â€œprÃ©quentielâ€ (Gama et al.,
2009)). Lâ€™indicateur de prÃ©cision est alors calculÃ© de maniÃ¨re incrÃ©mentale. Cette mÃ©-
thode est plus pessimiste que celle du jeu de donnÃ©es indÃ©pendant. La figure 2 compare
les erreurs de prÃ©diction pour lâ€™algorithme VFDT sur le jeu de test WaveForm entre lâ€™ap-
proche â€œjeu de donnÃ©es indÃ©pendantâ€ et â€œprÃ©quentielâ€ (Gama et al., 2009). Lâ€™utilisation
de fenÃªtre ou de facteur dâ€™oubli permet de rendre cet Ã©valuateur moins pessimiste comme
le propose (Gama et al., 2009) et comme illustrÃ© dans la figure 3. De cette maniÃ¨re les
mauvaises prÃ©dictions du passÃ© nâ€™influencent plus (ou moins) les nouvelles mesures de
la prÃ©diction de lâ€™algorithme.
Flux stationnaire : Dans le cas oÃ¹ le flux est stationnaire, les trois mÃ©thodes prÃ©cÃ©demment
prÃ©sentÃ©es peuvent Ãªtre utilisÃ©es, nÃ©anmoins la mÃ©thode basÃ©e sur le jeu de test indÃ©pendant
est celle que lâ€™on retrouve majoritairement.
Flux non stationnaire : Dans le cas oÃ¹ le flux nâ€™est pas stationnaire (avec changement
de concept), on ne peut pas utiliser toutes les mÃ©thodes prÃ©cÃ©dentes directement. La mÃ©thode
basÃ©e sur le jeu de test indÃ©pendant â€œholdoutâ€ ne convient pas car elle ne sera pas capable de
bien Ã©valuer les diffÃ©rents concepts. Au contraire la mÃ©thode â€œprÃ©quentielâ€ est particuliÃ¨rement
bien adaptÃ©e car son jeu de test Ã©volue avec le flux.
C. Salperwyck et al.
FIG. 2 â€“ Comparaison entre lâ€™erreur avec le jeu de test indÃ©pendant et prÃ©quentiel
FIG. 3 â€“ Comparaison entre lâ€™erreur avec jeu de test indÃ©pendant et prÃ©quentiel avec des
facteurs dâ€™oubli
5.2 Jeux de donnÃ©es
Bien souvent dans la littÃ©rature, une premiÃ¨re Ã©valuation des algorithmes est rÃ©alisÃ©e sur les
bases UCI classiques. Cela permet dâ€™avoir une premiÃ¨re idÃ©e des performances de lâ€™algorithme
bien quâ€™un algorithme sur les flux ne soit pas forcÃ©ment prÃ©vu pour bien fonctionner sur des
petits jeux de donnÃ©es. Ensuite pour simuler les flux, plusieurs approches sont possibles selon
que lâ€™on souhaite avoir un flux avec ou sans gestion de la dÃ©rive de concept. Le tableau 4
prÃ©sente une synthÃ¨se des jeux utilisÃ©s dans les diffÃ©rentes publications. Le lecteur trouvera
dâ€™autres jeux de donnÃ©es dans (Gama, 2010) page 209.
5.2.1 GÃ©nÃ©rateur de flux sans prÃ©sence de dÃ©rive de concept
Afin dâ€™avoir assez de donnÃ©es pour tester les algorithmes dâ€™apprentissage sur les flux, des
gÃ©nÃ©rateurs artificiels existent pour permettre de gÃ©nÃ©rer des milliards dâ€™exemples. Un Ã©tat de
Classification incrÃ©mentale supervisÃ©e : un panel introductif
lâ€™art de ces gÃ©nÃ©rateurs est prÃ©sentÃ© dans (Kirkby, 2008). Les principaux gÃ©nÃ©rateurs sont :
â€“ Random RBF Generator (Radial Basis Function) : basÃ© sur des â€œbullesâ€ ayant un centre.
On a plusieurs bulles de points de diffÃ©rents paramÃ¨tres Ã  diffÃ©rentes positions dans
lâ€™espace. Ensuite on gÃ©nÃ¨re des exemples appartenant Ã  ces bulles.
â€“ Random Tree Generator : gÃ©nÃ©ration dâ€™un arbre avec certains paramÃ¨tres et ensuite on
gÃ©nÃ¨re les donnÃ©es Ã  partir de lâ€™arbre. Ce gÃ©nÃ©rateur favorise les algorithmes dâ€™appren-
tissage basÃ©s sur les arbres.
â€“ LED Generator : prÃ©diction pour un afficheur LED.
â€“ Waveform Generator : problÃ¨me Ã  trois classes gÃ©nÃ©rÃ© Ã  partir de fonctions en forme
dâ€™onde diffÃ©rentes et combinÃ©es.
â€“ Function Generator : les exemples sont gÃ©nÃ©rÃ©s Ã  partir de rÃ¨gles sur les attributs qui
dÃ©terminent la classe.
5.2.2 GÃ©nÃ©rateur de flux avec prÃ©sence de dÃ©rive de concept
Afin de pouvoir tester les performances de leurs algorithmes sur des flux de donnÃ©es avec
des changements de concept, des auteurs (voir Tableau 4) ont proposÃ© des gÃ©nÃ©rateurs de flux
pour lesquels on peut paramÃ©trer la position et la quantitÃ© du changement (voir aussi (Gama,
2010) page 209). Il faut aussi noter que les concepts prÃ©sentÃ©s section prÃ©cÃ©dente peuvent Ãªtre
facilement modifiÃ©s pour contenir des dÃ©rives de concept.
Nom ProposÃ© par UtilisÃ© dans Type Taille
STAGGER (Schlimmer etGranger, 1986)
(Beringer et HÃ¼llermeier, 2007;
Bifet et Kirkby, 2009; Kolter et
Maloof, 2003; Bifet et al., 2009)
Artificiel infini
SEA Concept (Street et Kim, 2001) (Gama et al., 2005) Artificiel infini
Hyperplan en
mouvement (Hulten et al., 2001)
(Bifet et al., 2009; Beringer et
HÃ¼llermeier, 2007; Wang et al.,
2003; Ferrer-Troyano et al., 2005;
Narasimhamurthy et Kuncheva,
2007)
Artificiel infini
Forest Covertype UCI (Gama et al., 2003; Law etZaniolo, 2005; Bifet et al., 2009) RÃ©el 581K
Poker Hand UCI (Bifet et al., 2009) RÃ©el 1M
TAB. 4 â€“ Flux de donnÃ©es pour les algorithmes pour les flux
5.2.3 Jeu de donnÃ©es rÃ©elles
Les jeux de donnÃ©es rÃ©els â€œForest Covertypeâ€ et â€œPoker Handâ€ de lâ€™UCI, contiennent plu-
sieurs centaines de milliers dâ€™exemples. Dans ces deux jeux lâ€™existence et la position du chan-
gement de concept ne sont pas connues. De part leur taille assez importante ils sont utilisÃ©s
pour simuler un flux de donnÃ©es rÃ©elles. Les auteurs ci-dessous proposent eux des donnÃ©es qui
leurs sont propres :
â€“ proxy web de lâ€™UniversitÃ© de Washington pour Domingos dans (Domingos et Hulten,
2000; Hulten et al., 2001)
â€“ consommation Ã©lectrique en Australie pour Gama dans (Gama et al., 2005)
Le principal reproche que lâ€™on peut faire Ã  ces jeux de donnÃ©es est quâ€™ils ne sont pas
accessibles et donc quâ€™ils ne pourront pas Ãªtre rÃ©utilisÃ©s pour rÃ©aliser des comparaisons.
C. Salperwyck et al.
5.3 Evaluation entre algorithmes
On trouve trÃ¨s majoritairement la mÃªme mÃ©thodologie de comparaison dans la littÃ©rature.
Dans un premier temps, les auteurs dâ€™un nouvel algorithme effectuent une comparaison avec
des algorithmes connus mais non prÃ©vus pour fonctionner sur des flux de donnÃ©es comme :
C4.5, ID3, Bayesien naÃ¯f, forÃªt dâ€™arbres... Lâ€™idÃ©e est de voir les performances sur de pe-
tites quantitÃ©s de donnÃ©es contre des algorithmes connus. Puis dans un second temps ils se
confrontent aux autres algorithmes dÃ©jÃ  prÃ©sents dans la littÃ©rature de lâ€™apprentissage sur les
flux. Le lecteur pourra trouver dans (Kirkby, 2008) ainsi que dans (Gama et al., 2009) un
tableau comparatif des mÃ©thodes dâ€™Ã©valuation entre certains des algorithmes citÃ©s dans cet
article.
Environnement dâ€™Ã©valuation : Lâ€™un des problÃ¨mes lorsque lâ€™on veut rÃ©aliser une comparai-
son entre divers algorithmes de classification est de rÃ©aliser facilement des expÃ©rimentations.
En effet, bien souvent il est difficile dâ€™obtenir le code source de lâ€™algorithme puis de rÃ©ussir
Ã  construire un exÃ©cutable et parfois les formats dâ€™entrÃ©e et de sortie sont diffÃ©rents entre les
divers algorithmes. Pour lâ€™apprentissage hors-ligne lâ€™environnement WEKA (Witten et Frank,
2005) proposÃ© par lâ€™universitÃ© de Waikato permet de rÃ©aliser rapidement des expÃ©rimentations.
Cette mÃªme universitÃ© a proposÃ© en 2009 une boÃ®te Ã  outils dâ€™expÃ©rimentation pour les flux :
MOA (Bifet et Kirkby, 2009). On y retrouve la majoritÃ© des gÃ©nÃ©rateurs vus prÃ©cÃ©demment
ainsi quâ€™un nombre important dâ€™algorithmes dâ€™apprentissage sur les flux basÃ©s sur les arbres
dâ€™Hoeffding.
Autres points de comparaison : La mesure de prÃ©cision basÃ©e sur lâ€™AUC (Fawcett, 2004)
est la mesure de comparaison principale dans le cadre de la classification supervisÃ©e. Dans le
cadre des flux de donnÃ©es dâ€™autres mesures sont parfois utilisÃ©es en complÃ©ment :
â€“ taille du modÃ¨le (nombre de nÅ“uds pour les arbres, nombre de rÃ¨gles, espace mÃ©moire...)
â€“ vitesse dâ€™apprentissage (nombre dâ€™exemples appris par seconde)
La comparaison de la vitesse dâ€™apprentissage de deux algorithmes peut poser des problÃ¨mes car
il suppose que le code/logiciel est disponible publiquement. De plus, on nâ€™Ã©value pas seulement
la vitesse dâ€™apprentissage mais aussi la plate-forme sur laquelle tourne lâ€™algorithme et la qualitÃ©
de lâ€™implÃ©mentation. Ces mesures sont utiles pour donner un ordre dâ€™idÃ©e mais doivent Ãªtre
prises avec prÃ©cautions et non pas comme des Ã©lÃ©ments absolus de comparaison.
Kirkby (Kirkby, 2008) rÃ©alise ses expÃ©rimentations sous diffÃ©rentes contraintes de mÃ©-
moire simulant divers environnements : rÃ©seau de capteurs, PDA, serveur. On peut donc com-
parer les diffÃ©rents algorithmes par rapport Ã  lâ€™environnement dans lequel il serait exÃ©cutÃ©.
On peut aussi mentionner le fait que la mesure de prÃ©cision nâ€™a pas de sens dans lâ€™absolu en
cas de dÃ©rive de concept. Le lecteur pourra alors se tourner vers des protocoles dâ€™apprentissage,
comme le mistake-bound (Littlestone et Warmuth, 1989). Dans ce cadre, lâ€™apprentissage se
dÃ©roule en cycles oÃ¹ les exemples sont vus un par un ; ce qui cadre bien avec lâ€™apprentissage
sur des flux de donnÃ©es. Au dÃ©but lâ€™algorithme dâ€™apprentissage (A) apprend une hypothÃ¨se
(ft) et la prÃ©diction pour lâ€™instance courante est ft(xt). Puis lâ€™Ã©tiquette rÃ©elle de lâ€™exemple
(yt) est rÃ©vÃ©lÃ©e Ã  lâ€™algorithme dâ€™apprentissage qui peut avoir fait une erreur (yt 6= ft(xt)).
Puis le cycle reprend jusquâ€™Ã  un horizon de temps donnÃ© (T ). La borne dâ€™erreur est reliÃ©e Ã  la
mesure du maximum dâ€™erreur commise sur la pÃ©riode de temps T .
Classification incrÃ©mentale supervisÃ©e : un panel introductif
Limites des techniques dâ€™Ã©valuation : Des techniques dâ€™Ã©valuation ont Ã©tÃ© rÃ©cemment pro-
posÃ©es par la communautÃ© et une recherche de consensus est en cours (Gama et al., 2009). En
effet, des critÃ¨res comme le nombre dâ€™exemples appris par seconde ou une vitesse de prÃ©dic-
tion dÃ©pend de la machine et de la mÃ©moire utilisÃ©e ainsi que de la qualitÃ© de codage. Il faut
donc trouver des critÃ¨res et/ou plateformes communs afin de pouvoir rÃ©aliser une comparaison
aussi impartiale que possible.
6 Gestion de la dÃ©rive de concept
Dans cette section le problÃ¨me dâ€™apprendre quand la distribution des exemples varie au
cours du temps est abordÃ©. Si le processus sous-jacent qui â€œgÃ©nÃ¨reâ€ les donnÃ©es nâ€™est pas sta-
tionnaire le concept cible Ã  apprendre peut varier au cours du temps. Lâ€™algorithme dâ€™apprentis-
sage doit donc Ãªtre capable de dÃ©tecter ces changements et dâ€™adapter le modÃ¨le de classification
supervisÃ©e en consÃ©quence.
On considÃ¨re dans cette section que le concept Ã  apprendre peut varier dans le temps mais
quâ€™il est persistant et consistant (voir (Lazarescu et al., 2004)) entre deux changements. La
pÃ©riode de temps existante entre deux changements de concept est appelÃ©e contexte (voir la
Section 2.1.3 (Gama, 2010)). La dÃ©rive de concept apparaÃ®t Ã  travers les exemples qui sont gÃ©-
nÃ©rÃ©s : les anciennes observations du processus deviennent caduques vis-Ã -vis des observations
actuelles du processus. Les anciennes observations nâ€™appartiennent pas au mÃªme contexte que
les observations actuelles.
Si on suppose quâ€™entre deux changements de contexte (Conti i reprÃ©sentant lâ€™index du
contexte) il existe un concept (Conci) suffisamment persistant et consistant pour lequel on
peut collecter assez dâ€™exemples dâ€™apprentissage alors gÃ©rer la dÃ©rive de concept se ramÃ¨ne
souvent Ã  la dÃ©tection de ce changement. On prÃ©cise que lâ€™on sâ€™intÃ©resse dans cette section
uniquement aux variations de P (Y |X). La question de la dÃ©tection de nouveautÃ©s (Marsland,
2003) nâ€™est pas abordÃ©e.
Si lâ€™on sait dÃ©tecter ces changements de concepts au cours du temps on pourra alors :
â€“ soit rÃ©apprendre le modÃ¨le de classification Ã  partir de zÃ©ro ;
â€“ soit adapter le modÃ¨le courant ;
â€“ soit adapter un rÃ©sumÃ© des donnÃ©es sur lequel se fonde le modÃ¨le courant ;
â€“ soit travailler avec la sÃ©quence des modÃ¨les de classification appris au cours du temps.
La suite de cette section est organisÃ©e en deux parties : la premiÃ¨re partie dÃ©crit des mÃ©-
thodes pour dÃ©tecter la dÃ©rive de concept ; la seconde partie dÃ©crit des mÃ©thodes pour adapter
le modÃ¨le de classification parmi celles dÃ©crites ci-dessus.
6.1 DÃ©tection de la dÃ©rive de concept
On considÃ¨re ici uniquement la partie dÃ©tection de la dÃ©rive sans sâ€™occuper de la gestion
qui en est faite aprÃ¨s. La dÃ©tection de la dÃ©rive de concept peut Ãªtre rÃ©alisÃ©e principalement Ã 
lâ€™aide de deux voies : (i) la surveillance des performances du modÃ¨le courant de classification
et (ii) la surveillance de la distribution des exemples.
Pour la premiÃ¨re voie :
â€“ (Widmer et Kubat, 1996) proposent de dÃ©tecter le changement de concept en analysant
le taux dâ€™erreurs de classification et les modifications qui se produisent dans les struc-
C. Salperwyck et al.
tures de lâ€™algorithme dâ€™apprentissage (ajout de nouvelles dÃ©finitions dans les rÃ¨gles dans
son cas). A partir dâ€™une certaine variation de ces indicateurs, on diminue la taille de la
fenÃªtre dâ€™apprentissage sinon on la laisse croÃ®tre afin dâ€™avoir plus dâ€™exemples pour rÃ©ali-
ser un meilleur apprentissage. Ce fut lâ€™un des premiers travaux sur ce sujet et sur lequel
sâ€™appuient beaucoup dâ€™autres auteurs comme Gama dans le paragraphe ci-dessous.
â€“ Gama dans (Gama et al., 2009) propose dâ€™utiliser le test statistique de Page-Hinkley
(Page, 1954). Gama le modifie en y ajoutant des facteurs dâ€™oubli. Ce test est basÃ© sur le
calcul des Ã©carts par rapport Ã  la moyenne dâ€™une variable. Son intÃ©rÃªt rÃ©side dans le fait
quâ€™il est Ã  la fois performant, simple Ã  calculer et incrÃ©mental.
Pour la seconde voie on pourra utiliser des mÃ©thodes paramÃ©triques, ou test statistique
qui prÃ©suppose souvent de ce que lâ€™on veut dÃ©tecter : changement dans la moyenne, dans la
variance, dans les quantiles, etc. Par exemple lorsque Gama utilise le test de Page-Hinkley
il cherche Ã  dÃ©tecter une rupture dans une moyenne. Une mÃ©thode paramÃ©trique est a priori
imbattable quand le type de rupture rentre exactement dans son biais mais son paramÃ©trage peut
devenir un problÃ¨me dans des conditions limites (biais non prÃ©sent dans les donnÃ©es). De faÃ§on
gÃ©nÃ©rale, il sâ€™agit dâ€™un compromis entre le biais particulier et lâ€™efficacitÃ© de la mÃ©thode. Si on
cherche Ã  dÃ©tecter nâ€™importe quel type de rupture il semble difficile de trouver une mÃ©thode
paramÃ©trique qui en soit capable.
6.2 MÃ©thodes adaptatives
AprÃ¨s avoir dÃ©tectÃ© la dÃ©rive de concept il faut : (i) soit rÃ©apprendre le modÃ¨le de classi-
fication Ã  partir de zÃ©ro ; (ii) soit adapter le modÃ¨le courant ; (iii) soit adapter un rÃ©sumÃ© des
donnÃ©es sur lequel se fonde le modÃ¨le courant ; (iv) soit travailler avec la sÃ©quence des modÃ¨les
de classification appris au cours du temps.
Si on dÃ©cide de rÃ©apprendre le modÃ¨le Ã  partir de zÃ©ro : lâ€™algorithme dâ€™apprentissage sâ€™ap-
puie alors :
â€“ soit sur une mÃ©moire partielle des exemples : (i) un nombre fini des derniers exemples,
(ii) un nombre adaptatif des derniers exemples (iii) un rÃ©sumÃ© des derniers exemples. La
taille de la fenÃªtre des derniers exemples utilisÃ©e ne peut en aucun cas excÃ©der lâ€™horizon
de lâ€™avant derniÃ¨re dÃ©rive dÃ©tectÃ©e (Widmer et Kubat, 1992).
â€“ soit sur une mÃ©moire "complÃ¨te" des exemples comme les mÃ©thodes capables de stocker
des statistiques sur les exemples sous la contrainte dâ€™une capacitÃ© mÃ©moire donnÃ©e et
dâ€™une prÃ©cision donnÃ©e (Greenwald et Khanna, 2001)
Les mÃ©thodes qui dÃ©cident dâ€™adapter le modÃ¨le de classification peuvent sâ€™appuyer :
â€“ soit sur plusieurs modÃ¨les de classification utilisÃ©s en mÃªme temps comme par exemple
les mÃ©thodes ensemblistes (â€œbaggingâ€ (Breiman, 1996)) qui consistent Ã  utiliser plu-
sieurs classifieurs en mÃªme temps afin dâ€™amÃ©liorer les capacitÃ©s de prÃ©diction de ceux-
ci :
â€“ (Street et Kim, 2001) proposent lâ€™algorithme SEA : â€œStreaming Ensemble Algorithmâ€
qui utilise un ensemble de classifieurs sur les flux. Le flux remplit un tampon de
taille dÃ©finie et dÃ¨s que le tampon est plein lâ€™algorithme C4.5 est lancÃ© dessus. On
se retrouve donc avec une suite de classifieurs gÃ©nÃ©rÃ©s que lâ€™on met dans un pool.
Une fois le pool plein, si le nouveau classifieur amÃ©liore la prÃ©diction du pool alors
il est conservÃ©, sinon il est rejetÃ©. Dans (Wang et al., 2003) la mÃªme technique est
Classification incrÃ©mentale supervisÃ©e : un panel introductif
utilisÃ©e mais diffÃ©rents types de classifieurs composent lâ€™ensemble : bayÃ©sien naÃ¯f,
C4.5, RIPPER...
â€“ Dans (Kolter et Maloof, 2003), un poids est affectÃ© Ã  chaque classifieur, les poids sont
mis Ã  jour uniquement lors de la mauvaise prÃ©diction du nouvel exemple. Dans ce cas
un nouveau classifieur est ajoutÃ© et les poids des autres classifieurs sont diminuÃ©s. Les
classifieurs ayant un poids trop faible sont retirÃ©s de lâ€™ensemble.
â€“ (Bifet et Gavalda, 2007; Bifet et al., 2009) propose aussi une mÃ©thode pour mettre Ã 
jour lâ€™ensemble : ADWIN (ADaptative WINdowing). Elle est basÃ©e sur la dÃ©tection
des changements de concept Ã  lâ€™aide dâ€™un rÃ©servoir de taille variableW . Le rÃ©servoir
sâ€™agrandit quand il nâ€™y a pas de changements de concept et diminue lorsquâ€™il en ren-
contre un. Cette approche ne consomme comme mÃ©moire que log(W ) et ne nÃ©cessite
pas de paramÃ¨tre. Quand un changement est dÃ©tectÃ© le plus mauvais classifieur est
retirÃ© et un nouveau classifieur est ajoutÃ© Ã  lâ€™ensemble.
â€“ soit sur plusieurs modÃ¨les de classification mais les classifieurs sont utilisÃ©s un Ã  un, les
autres modÃ¨les dÃ©jÃ  construits dans le passÃ© sont considÃ©rÃ©s comme un pool de candidats
potentiels (Gama et P., 2009; Gomes et al., 2010)
Ce sont aussi les exemples (et donc les modÃ¨les) qui servent Ã  apprendre le modÃ¨le de
classification qui peuvent aussi Ãªtre pondÃ©rÃ©s au cours du temps. Depuis les annÃ©es 80 des
solutions comme les fenÃªtres et les facteurs dâ€™oubli ont Ã©tÃ© proposÃ©es : (Schlimmer et Granger,
1986; Widmer et Kubat, 1992, 1996; Salganicoff, 1997). Le sujet est toujours dâ€™actualitÃ© et il
constitue une nouvelle problÃ©matique pour les algorithmes dâ€™apprentissage en flux. On citera
(Salganicoff, 1997) :
â€“ TWF (Time-Weighted Forgetting) : plus lâ€™exemple est ancien plus son poids est faible ;
â€“ LWF (Locally-Weighted Forgetting) : Ã  lâ€™arrivÃ©e dâ€™un nouvel exemple on augmente le
poids des exemples qui sont proches de lui et on baisse ceux des autres. Les rÃ©gions
ayant des exemples rÃ©cents sont ainsi conservÃ©es (ou crÃ©Ã©es si elles nâ€™existaient pas) et
les rÃ©gions nâ€™en ayant peu ou pas sont supprimÃ©es ;
â€“ PECS (Prediction Error Context Switching) : lâ€™idÃ©e de LWF est reprise mais tous les
exemples sont gardÃ©s en mÃ©moire et une vÃ©rification des Ã©tiquettes des nouveaux exemples
par rapport aux anciens est effectuÃ©e. Une probabilitÃ© des exemples est calculÃ©e grÃ¢ce
aux comptes des exemples ayant ou nâ€™ayant pas la mÃªme Ã©tiquette. Seulement les meilleurs
exemples sont utilisÃ©s pour rÃ©aliser lâ€™apprentissage.
7 Conclusion
Cet article synthÃ©tique introductif a prÃ©sentÃ© les principales approches de classification
incrÃ©mentale recensÃ©es dans la littÃ©rature. Dans un premier temps les diffÃ©rentes problÃ©ma-
tiques de lâ€™apprentissage ont Ã©tÃ© prÃ©sentÃ©es ainsi que les nouveaux problÃ¨mes imposÃ©s par la
contrainte des flux : quantitÃ© et vitesse importante des donnÃ©es et la possibilitÃ© de ne les voir
quâ€™une fois. Ces caractÃ©ristiques imposent de se tourner vers des algorithmes spÃ©cifiques :
incrÃ©mentaux voire spÃ©cialisÃ©s pour les flux. Ces principaux algorithmes ont Ã©tÃ© dÃ©crits par
rapport Ã  la classe Ã  laquelle ils appartiennent : arbre de dÃ©cisions, SVM... On remarque par
ailleurs que dans la littÃ©rature les arbres de dÃ©cisions incrÃ©mentaux, qui satisfont plus facile-
ment les contraintes de vitesse de prÃ©diction et/ou dâ€™apprentissage, sont prÃ©dominants.
Au niveau des verrous Ã  lever, lâ€™adaptation aux changements de concept est lâ€™un des chal-
lenges les plus importants et difficiles Ã  rÃ©soudre. En effet, il faut dâ€™une part trouver quand le
C. Salperwyck et al.
changement a lieu puis modifier le modÃ¨le en consÃ©quence et ceci avec le moins de fausses
dÃ©tections possibles. Le compromis prÃ©cision / vitesse / mÃ©moire semble une voie intÃ©res-
sante si ce compromis pouvait Ãªtre directement Ã©crit comme un critÃ¨re Ã  optimiser lors de
lâ€™apprentissage du classifieur. On peut aussi citer la propriÃ©tÃ© anytime qui nâ€™est que trÃ¨s peu
implÃ©mentÃ©e en respectant sa dÃ©finition stricte : â€œalgorithme qui peut Ãªtre arrÃªtÃ© Ã  tout moment
et qui retourne une prÃ©dictionâ€. On peut aussi noter quâ€™un flux de donnÃ©es peut Ãªtre vu comme
un environnement changeant sur lequel sâ€™exerce un modÃ¨le de classification. Les erreurs de
classification sont ensuite accessibles dans un horizon de temps limitÃ©. Par consÃ©quent on peut
penser que les algorithmes liÃ©s Ã  la thÃ©orie des jeux ou Ã  lâ€™apprentissage par renforcement
devraient aussi pouvoir Ãªtre formalisÃ©s pour lâ€™apprentissage incrÃ©mental sur flux.
La plupart des tests sont rÃ©alisÃ©s sur des gÃ©nÃ©rateurs de donnÃ©es ou des jeux de donnÃ©es de
lâ€™UCI dâ€™importante volumÃ©trie (mais de moins dâ€™un million dâ€™exemples) mais rarement sur des
flux rÃ©els. Certains auteurs proposent des flux provenant dâ€™industriels (consommation dâ€™Ã©lec-
tricitÃ© par exemple) mais on ne connaÃ®t pas prÃ©cisÃ©ment leurs caractÃ©ristiques : stationnaire
ou non, niveau de bruit, type de modÃ¨le sous-jacent... DÃ¨s lors, les rÃ©sultats obtenus sont pro-
blÃ¨mes (ou flux) dÃ©pendants. Il serait intÃ©ressant Ã  terme dâ€™avoir, comme cela existe dÃ©jÃ  avec
le dÃ©pÃ´t de lâ€™UCI, une liste de flux caractÃ©risÃ©s et librement accessibles. Il en va de mÃªme pour
une plateforme dâ€™expÃ©rimentation mÃªme si lâ€™universitÃ© de Wakaito nous propose dÃ©jÃ  lâ€™envi-
ronnement MOA qui sâ€™inspire de WEKA. Etant Ã  un jeune stade de son dÃ©veloppement MOA
nÃ©cessite dâ€™Ãªtre complÃ©tÃ© avec les nouvelles mÃ©thodes comme le fut WEKA Ã  ses dÃ©buts.
RÃ©fÃ©rences
Aha, D. W. (Ed.) (1997). Lazy Learning. Springer.
Almaksour, A., H. MouchÃ¨re, et E. Anquetil (2009). Apprentissage incrÃ©mental et synthÃ¨se
de donnÃ©es pour la reconnaissance de caractÃ¨res manuscrits en-ligne. In DixiÃ¨me Colloque
International Francophone sur lâ€™Ã©crit et le Document.
Beringer, J. et E. HÃ¼llermeier (2007). Efficient instance-based learning on data streams. Intel-
ligent Data Analysis 11(6), 627â€“650.
Bifet, A. et R. Gavalda (2007). Learning from time-changing data with adaptive windowing.
In SIAM International Conference on Data Mining, pp. 443â€“448.
Bifet, A., G. Holmes, B. Pfahringer, R. Kirkby, et R. GavaldÃ  (2009). New ensemble methods
for evolving data streams. Proceedings of the 15th ACM SIGKDD international conference
on Knowledge discovery and data mining - KDD â€™09, 139.
Bifet, A. et R. Kirkby (2009). DATA STREAM MINING A Practical Approach. Journal of
empirical finance 8(3), 325â€“342.
Bondu, A. et V. Lemaire (2008). Etat de lâ€™art sur les methodes statistiques dâ€™apprentissage
actif. RNTI A2 Apprentissage artificiel et fouille de donnÃ©es, 189.
Bordes, A. et L. Bottou (2005). The Huller : a simple and efficient online SVM. Proceedings
of the 16th European Conference on Machine Learning (ECML2005).
Bordes, A., S. Ertekin, J. Weston, et L. Bottou (2005). Fast kernel classiffiers with online and
active learning. Journal of Machine Learning Research 6, 1579â€“1619.
Boser, B., I. Guyon, et V. Vapnik (1992). A training algorithm for optimal margin classifiers. In
Proceedings of the fifth annual workshop on Computational learning theory, pp. 144â€“152.
Classification incrÃ©mentale supervisÃ©e : un panel introductif
ACM New York, NY, USA.
Breiman, L. (1996). Bagging predictors. Machine learning 24(2), 123â€“140.
Breiman, L., J. Friedman, R. Olshen, et C. Stone (1984). Classification and regression trees.
Chapman and Hall/CRC.
Brighton, H. et C. Mellish (2002). Advances in instance selection for instance-based learning
algorithms. Data mining and knowledge discovery 6(2), 153â€“172.
Buchanan, B. G. (1984). Rule Based Expert Systems : The Mycin Experiments of the Stanford
Heuristic Programming Project. Addison-Wesley.
CornuÃ©jols, A. (2009). Blueprint on Ubiquitous Knowledge Discovery, Chapter On-line lear-
ning : Where are we so far ? May M. and Saitta L. eds. - Springer.
CornuÃ©jols, A. et L. Miclet (2010). Apprentissage artificiel - Concepts et algorithmes. Eyrolles.
Cortes, C. et V. Vapnik (1995). Support-vector networks. Machine Learning 20(3), 273â€“297.
Dean, T. et M. Boddy (1988). An analysis of time-dependent planning. In Proceedings of the
seventh national conference on artificial intelligence, pp. 49â€“54.
del Campo-Avila, J., G. Ramos-JimÃ©nez, J. . Gama, et R. Morales-Bueno (2006). Improving
Prediction Accuracy of an Incremental Algorithm Driven by Error Margins. Knowledge
Discovery from Data Streams, 57.
Do, T., V. Nguyen, et F. Poulet (2009). GPU-based parallel SVM algorithm. Jisuanji Kexue yu
Tansuo 3(4), 368â€“377.
Domeniconi, C. et D. Gunopulos (2001). Incremental support vector machine construction. In
ICDM, pp. 589â€“592.
Domingos, P. et G. Hulten (2000). Mining high-speed data streams. In Proceedings of the
sixth ACM SIGKDD international conference on Knowledge discovery and data mining, pp.
71â€“80. ACM New York, NY, USA.
Domingos, P. et G. Hulten (2001). Catching up with the data : Research issues in mining data
streams. In Workshop on Research Issues in Data Mining and Knowledge Discovery.
Domingos, P. et M. Pazzani (1997). On the optimality of the simple Bayesian classifier under
zero-one loss. Machine learning 130, 103â€“130.
Dong, J.-x., A. Krzyzak, et C. Y. Suen (2005). Fast SVM training algorithm with decompo-
sition on very large data sets. IEEE transactions on pattern analysis and machine intelli-
gence 27(4), 603â€“618.
Fawcett, T. (2004). ROC graphs : Notes and practical considerations for researchers. Machine
Learning 31, 1â€“38.
Fayyad, U. M., G. Piatetsky-Shapiro, P. Smyth, et R. Uthurusamy (1996). Advances in Know-
ledge Discovery and Data Mining. Menlo Park, CA, USA : American Association for Arti-
ficial Intelligence.
FÃ©raud, R., M. BoullÃ©, F. ClÃ©rot, F. Fessant, et V. Lemaire (2010). The orange customer ana-
lysis platform. In Industrial Conference on Data Mining (ICDM), pp. 584â€“594.
Ferrer-Troyano, F., J. Aguilar-Ruiz, et J. Riquelme (2006). Data streams classification by
incremental rule learning with parameterized generalization. In Proceedings of the 2006
ACM symposium on Applied computing, pp. 661. ACM.
C. Salperwyck et al.
Ferrer-Troyano, F., J. S. Aguilar-Ruiz, et J. C. Riquelme (2005). Incremental rule learning
based on example nearness from numerical data streams. In Proceedings of the 2005 ACM
symposium on Applied computing, pp. 572. ACM.
Fung, G. et O. Mangasarian (2002). Incremental support vector machine classification. In Pro-
ceedings of the Second SIAM International Conference on Data Mining, Arlington, Virginia,
pp. 247â€“260.
Gama, J. (2010). Knowledge Discovery from Data Streams. Chapman and Hall/CRC Press.
Gama, J., P. Medas, et P. Rodrigues (2005). Learning decision trees from dynamic data streams.
Journal of Universal Computer Science 11(8), 1353â€“1366.
Gama, J. et K. P. (2009). Tracking recurring concepts with metalearners. In Progress in
Artificial Intelligence : 14th Portuguese Conference on Artificial Intelligence, pp. 423.
Gama, J. et C. Pinto (2006). Discretization from data streams : applications to histograms and
data mining. Proceedings of the 2006 ACM symposium on Applied.
Gama, J., R. Rocha, et P. Medas (2003). Accurate decision trees for mining high-speed data
streams. In Proceedings of the ninth ACM SIGKDD international conference on Knowledge
discovery and data mining, pp. 523â€“528. ACM New York, NY, USA.
Gama, J., P. P. Rodrigues, R. Sebastiao, et P. Rodrigues (2009). Issues in evaluation of stream
learning algorithms. In Proceedings of the 15th ACM SIGKDD international conference on
Knowledge discovery and data mining, pp. 329â€“338. ACM New York, NY, USA.
Gehrke, J., R. Ramakrishnan, et V. Ganti (2000). RainForest - a framework for fast decision
tree construction of large datasets. Data Mining and Knowledge Discovery 4(2), 127â€“162.
Gibbons, P., Y. Matias, et V. Poosala (2002). Fast incremental maintenance of approximate
histograms. ACM Transactions on Database 27(3), 261â€“298.
Globersonn, A. et S. Roweis (2005). Metric learning by collapsing classes. In Neural Infor-
mation Processing Systems(NIPS).
Gomes, J. B., E. Menasalvas, et P. A. S. Sousa (2010). Tracking recurrent concepts using
context. In Proceedings of the 7th international conference on Rough sets and current
trends in computing (RSCTCâ€™10).
Greenwald, M. et S. Khanna (2001). Space-efficient online computation of quantile summa-
ries. In SIGMOD, pp. 58â€“66.
Guyon, I., V. Lemaire, G. Dror, et D. Vogel (2009). Analysis of the kdd cup 2009 : Fast scoring
on a large orange customer database. JMLR : Workshop and Conference Proceedings 7, 1â€“
22.
Hoeffding, W. (1963). Probability inequalities for sums of bounded random variables. Journal
of the American Statistical Association.
Hulten, G., L. Spencer, et P. Domingos (2001). Mining time-changing data streams. In Procee-
dings of the seventh ACM SIGKDD international conference on Knowledge discovery and
data mining, pp. 97â€“106. ACM New York, NY, USA.
Joaquin Quinonero-Candela, J., M. Sugiyama, A. Schwaighofer, et N. D. Lawrence (2009).
Dataset shift in Machine Learning. MIT Press.
John, G. et P. Langley (1995). Estimating continuous distributions in bayesian classifiers.
Classification incrÃ©mentale supervisÃ©e : un panel introductif
In In Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence, pp.
338â€“345. Morgan Kaufmann.
Kirkby, R. (2008). Improving Hoeffding Trees. Ph. D. thesis, University of Waikato.
Kohavi, R. (1996). Scaling up the accuracy of naive-Bayes classifiers : A decision-tree hybrid.
In Proceedings of the Second International Conference on Knowledge Discovery and Data
Mining, Volume 7. Menlo Park, USA : AAAI Press.
Kohavi, R. et C. Kunz (1997). Option decision trees with majority votes. In ICML â€™97 : Pro-
ceedings of the Fourteenth International Conference on Machine Learning, San Francisco,
CA, USA, pp. 161â€“169. Morgan Kaufmann Publishers Inc.
Kolter, J. et M. Maloof (2003). Dynamic weighted majority : A new ensemble method for
tracking concept drift. In Proceedings of the Third International IEEE Conference on Data
Mining, pp. 123â€“130.
Kononenko, I. et M. Robnik (2003). Theoretical and empirical analysis of relieff and rrelieff.
Machine Learning Journal 53, 23â€“69.
Lallich, S., O. Teytaud, et E. Prudhomme (2007). Association rule interestingness : Measure
and statistical validation. In F. Guillet et H. Hamilton (Eds.), Quality Measures in Data
Mining, Volume 43 of Studies in Computational Intelligence, pp. 251â€“275. Springer Berlin
/ Heidelberg.
Langley, P., W. Iba, et K. Thompson (1992). An analysis of bayesian classifiers. In Internatio-
nal conference on Artificial Intelligence, AAAI, pp. 223â€“228.
Law, Y. et C. Zaniolo (2005). An adaptive nearest neighbor classification algorithm for data
streams. Lecture notes in computer science 3721, 108.
Lazarescu, M. M., S. Venkatesh, et H. H. Bui (2004). Using multiple windows to track concept
drift. Intelligent Data Analysis 8(1), 29â€“59.
Littlestone, N. et M. Warmuth (1989). The weighted majority algorithm. 30th Annual Sympo-
sium on Foundations of Computer Science, 256â€“261.
Loosli, G., S. Canu, et L. Bottou (2006). SVM et apprentissage des trÃ¨s grandes bases de
donnÃ©es. CAp ConfÃ©rence dâ€™apprentissage.
Lu, J., Y. Yang, et G. Webb (2006). Incremental discretization for naive-bayes classifier. Ad-
vanced Data Mining and Applications, 223 â€“ 238.
Maloof, M. et R. Michalski (2000). Selecting examples for partial memory learning. Machine
Learning 41(1), 27â€“52.
Marsland, S. (2003). Novelty detection in learning systems. Neural Computing Surveys 3,
157â€“195.
Mehta, M., R. Agrawal, et J. Rissanen (1996). SLIQ : A fast scalable classifier for data mining.
Lecture Notes in Computer Science 1057, 18â€“34.
Michalski, R. S., I. Mozetic, J. Hong, et N. Lavrac (1986). The Multi-Purpose incremental
Learning System AQ15 and its Testing Application to Three Medical Domains. Proceedings
of the Fifth National Conference on Artificial Intelligence, 1041â€“1045.
Moreno-Seco, F., L. Mico, et J. Oncina (2002). Extending laesa fast nearest neighbour algo-
rithm to find the k nearest neighbours. In SSPR & SPR, pp. 718â€“724.
C. Salperwyck et al.
Narasimhamurthy, A. et L. Kuncheva (2007). A framework for generating data to simulate
changing environments. In Proceedings of the 25th conference on Proceedings of the 25th
IASTED International Multi-Conference : artificial intelligence and applications, Volume
549, pp. 389. ACTA Press.
Oates, T. et D. Jensen (1997). The Effects of Training Set Size on Decision Tree Complexity. In
ICML â€™97 : Proceedings of the Fourteenth International Conference on Machine Learning,
pp. 254â€“262.
Page, E. (1954). Continuous inspection schemes. Biometrika 41(1-2), 100.
Provost, F. et V. Kolluri (1999). A Survey of Methods for Scaling Up Inductive Algorithms.
Data Min. Knowl. Discov. 3(2), 131â€”-169.
Quinlan, J. R. (1986). Learning Efficient Classification Procedures and Their Application to
Chess End Games. Machine Learning - An Artificial Intelligence Approach, 463â€“482.
Ramos-Jimenez, G., J. del Campo-Avila, et R. Morales-Bueno (2006). Incremental algorithm
driven by error margins. Lecture Notes in Computer Science 4265, 358.
Salganicoff, M. (1997). Tolerating concept and sampling shift in lazy learning using prediction
error context switching. Artificial Intelligence Review 11(1), 133â€“155.
Sankaranarayanan, J., H. Samet, et A. Varshney (2007). A fast all nearest neighbor algorithm
for applications involving large point-clouds. Computers & Graphics.
Saunier, N., S. Midenet, et A. Grumbach (2004). Apprentissage incrÃ©mental par sÃ©lection de
donnÃ©es dans un flux pour une application de sÃ©curitÃ© routiÃ¨re. In ConfÃ©rence dâ€™Apprentis-
sage (CAP), pp. 239â€“251.
Schlimmer, J. et D. Fisher (1986). A case study of incremental concept induction. In Procee-
dings of the Fifth National Conference on Artificial Intelligence, pp. 496â€“501.
Schlimmer, J. et R. Granger (1986). Incremental learning from noisy data. Machine lear-
ning 1(3), 317â€“354.
Seidl, T., I. Assent, P. Kranen, R. Krieger, et J. Herrmann (2009). Indexing density models
for incremental learning and anytime classification on data streams. In Proceedings of the
12th International Conference on Extending Database Technology : Advances in Database
Technology, pp. 311â€“322. ACM.
Shafer, J., R. Agrawal, et M. Mehta (1996). SPRINT : A scalable parallel classifier for data
mining. In Proceedings of the International Conference on Very Large Data Bases, pp.
544â€“555.
Stonebraker, M., U. Ã‡etintemel, et S. Zdonik (2005). The 8 requirements of real-time stream
processing. ACM SIGMOD Record 34(4), 42â€“47.
Street, W. et Y. Kim (2001). A streaming ensemble algorithm (SEA) for large-scale classifica-
tion. In Proceedings of the seventh ACM SIGKDD international conference on Knowledge
discovery and data mining, pp. 377â€“382. ACM New York, NY, USA.
Syed, N., H. Liu, et K. Sung (1999). Handling concept drifts in incremental learning with
support vector machines. In Proceedings of the fifth ACM SIGKDD international conference
on Knowledge discovery and data mining, pp. 317â€“321. ACM New York, NY, USA.
Classification incrÃ©mentale supervisÃ©e : un panel introductif
Tsang, I., J. Kwok, et P. Cheung (2006). Core vector machines : Fast SVM training on very
large data sets. Journal of Machine Learning Research 6(1), 363.
Usunier, N., A. Bordes, et L. Bottou (2010). Guarantees for approximate incremental SVMs.
In Proceedings of the Thirteenth International Conference on Artificial Intelligence and
Statistics, Volume 9, pp. 884â€“891.
Utgoff, P. (1989). Incremental induction of decision trees. Machine Learning 4(2), 161â€“186.
Utgoff, P., N. Berkman, et J. Clouse (1997). Decision tree induction based on efficient tree
restructuring. Machine Learning 29(1), 5â€“44.
V. Hooman, V., C.-S. Li, et V. Castelli (2000). Fast search and learning for fast similarity
search. In Storage and Retrieval for Media Databases, Volume 3972, pp. 32â€“42.
Vitter, J. (1985). Random sampling with a reservoir. ACM Trans. Math. Software 11(1), 37â€“57.
Wang, H., W. Fan, P. S. Yu, et J. Han (2003). Mining concept-drifting data streams using
ensemble classifiers. In Proceedings of the ninth ACM SIGKDD international conference
on Knowledge discovery and data mining - KDD â€™03, New York, New York, USA, pp. 226â€“
235. ACM Press.
Weinberger, K. et L. Saul (2009). Distance metric learning for large margin nearest neighbor
classification. The Journal of Machine Learning Research (JMLR) 10, 207â€“244.
Widmer, G. et M. Kubat (1992). Learning flexible concepts from streams of examples :
FLORA2. In Proceedings of the 10th European conference on Artificial intelligence, Num-
ber section 5, pp. 463â€“467. John Wiley & Sons, Inc.
Widmer, G. et M. Kubat (1996). Learning in the presence of concept drift and hidden contexts.
Machine learning 23(1), 69â€“101.
Witten, I. H. et E. Frank (2005). Data mining : practical machine learning tools and tech-
niques. Morgan Kaufmann Series in Data Management Systems, Morgan Kaufmann, second
edition.
Zighed, D. et R. Rakotomalala (2000). Graphes dâ€™induction : apprentissage et data mining.
Hermes Science Publications.
Zilberstein, S. et S. Russell (1996). Optimal composition of real-time systems. Artificial
Intelligence 82(1), 181â€“213.
Summary
The last ten years were proficient in the statistical learning and data mining field and it
is now easy to find learning algorithms which are fast and automatic. Historically a strong
hypothesis was that data were all available or could be loaded into memory so that learning
algorithms can use them straight away. But recently new use cases generating lots of data come
up as for example: monitoring of telecommunication network, user modeling in dynamic social
network, web mining... The volume of data increases very rapidly and it is now necessary to
use incremental learning algorithms. This article presents the main approaches of incremental
supervised classification available in the literature. It aims to give basics knowledge to the
reader who begins in this subject.
