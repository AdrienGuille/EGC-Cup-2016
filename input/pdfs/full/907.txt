Asymptotic properties of functional maximum-likelihood
ARH parameter estimators
M.D. Ruiz-Medina and R. Salmerón
Department of Statistics and Operation Research, University of Granada
Department of Quantitative Methods for the Economy and Enterprise
mruiz@ugr.es
romansg@ugr.es
http://www.ugr.es/ mruiz/
Résumé. Dans cet article, nous nous intéressons au problème du calcul de la
variance asymptotique des estimateurs du maximum de vraisemblance des pa-
ramètres de projection de processus autorégressifs hilbertiens. Ces estimateurs
obtenus à partir d’observations fonctionnelles gaussiennes incomplètes ont été
étudiés dans Ruiz-Medina et Salmerón (2010). Notre approche consiste à es-
timer ces variances à l’aide d’une version fonctionnelle de l’algorithme SEM
(Supplemented Expectation Maximization) par Meng et Rubin (1991). La mise
en oeuvre de l’algorithme est basée sur l’extraction des fonctions propres et va-
leurs propres de l’opérateur d’autocorrélation et de son adjoint. Les effets de
l’ordre de troncature du spectre et de la discrétisation des fonctions sont illustrés
par des simulations.
1 Introduction
Functional Statistics (see, for example, Bosq, 2000 ; Bosq and Blanke, 2007 ; Ferraty and
Vieu, 2006 ; Ramsay and Silverman, 2005) provides a suitable framework to analyze large di-
mensional data sets. Complex biological and artificial systems can then be studied from this
perspective. In particular, in Biomedicine, Bioinformatics and image processing (see, for ins-
tance, Germain et al., 1999 ; Haoudi and Bensmail, 2006 ; Hyndman and Ullah, 2006 ; Leng
andMüller, 2006 ; Monk, 2003 ; Song et al., 2007, among others), the most extended projection
estimation methodology has been Functional Principal Component Analysis (FPCA), imple-
mented from the spectral decomposition of the empirical covariance operator, which is usually
computed by application of the method of moments. However, the ML (Maximum Likelihood)
estimation methodology has not been considered in these applications. In Ruiz-Medina and Sal-
merón (2010), ML projection estimators are computed from the application of the forward and
backward Kalman recursion, combined with EM algorithm (see, for example, Hartley, 1958 ;
Dempster, Laird and Rubin, 1977), in terms of the eigenfunction bases of the autocorrelation
operator and its adjoint. This projection methodology is most suitable than FPCA in the case
of ML estimation. The motivation of our paper lies on this fact, since, for the application of the
ML projection estimation methodology, information on its performance is obviously needed.
Specifically, the asymptotic variance of the ML projection estimators must be computed. The
Functional SEM algorithm
sensitivity of the ML projection estimates to the truncation order and discretization level must
be analyzed. Theses two issues will be addressed in this paper.
Within the current literature on functional projection estimation, we will cite the papers
by Abramovich and Angelini (2006), and Abramovich, Sapatinas and Vidakovic (2004) on
the derivation of wavelet-based projection estimators in the framework of FANOVA models.
Kernel-based non-parametric projection estimators are studied in the context of functional
regression models in Cardot et al. (2003). Also, we refer to Ramsay and Silverman (2005)
on FPCA-based projection estimators, in the context of functional linear models. The asymp-
totic properties of functional moment estimators and FPCA-based projection estimators for
ARH processes are studied in Bosq (2000, 2008), Bosq and Blanke (2007) and Mas (1999 ;
2007), among others. Wavelet-based autoregressive projection estimators are considered in
Antoniadis and Sapatinas (2003). A comparative study of autoregressive estimators and non-
parametric kernel-based estimators (e.g. local autoregressive estimators) is developed in Besse,
Cardot and Stephenson (2000). In all the cited references, ML estimation and, in particular,
ML projection estimators have not been studied. In particular, as commented before, in the
context of ARH processes, ML projection estimators, based on the spectral decomposition of
the autocorrelation operator, have been derived in Ruiz-Medina and Salmerón (2010). From
such a spectral decomposition, the autoregressive prediction had been previously addressed
in Ruiz-Medina, Salmerón and Angulo (2007) and Salmerón and Ruiz-Medina (2009). Spe-
cifically, the right and left eigenfunction systems associated with the autocorrelation operator
and its adjoint are considered. The projection of the autoregressive Hilbertian state equation
on these bases leads to its diagonalization. The projection of the conditioned log-likelihood
functional on these biorthogonal eigenfunction bases provides a very suitable computational
expression, where recursive ML multivariate gaussian regression methods can be applied in a
very simple form. While Functional-Principal-Component-based factorization, associated with
the spectral decomposition of the covariance operator, provides a more complicated expression
of the projected conditioned log-likelihood function (see Ruiz-Medina and Salmerón, 2010).
The asymptotic properties of the ML projection estimators derived from the implementation of
EM algorithm in combination with forward and backward recursion have not been derived yet.
This is the aim of the present paper, to compute an approximation, at each finite-dimensional
Hilbert space, defined by truncation, of the asymptotic variance of ML projection estimators.
This issue is addressed here by implementation of supplemented EM (SEM) algorithm (see
Meng and Rubin, 1991) combined with forward and backward Kalman recursion. Additio-
nally, two important aspects must be taken into account in the implementation of the referred
ML projection estimation methodology : the truncation order and the discretization level. A
simulation study is here developed to analyze the effect of the truncation order and the discre-
tization level on the quality of the ML projection estimates.
The outline of the paper is the following. In Section 2, the preliminary elements involved in
the diagonalization of the autoregressive Hilbertian state equation, in terms of the right and left
eigenfunction systems of the autocorrelation operator, are introduced. Forward Kalman filte-
ring and backward Kalman smoothing equations are then derived. In Section 3, the functional
version of SEM algorithm is implemented. A simulation study is devoted in Section 4 to ob-
tain information on the performance of the ML projection estimation methodology depending
on the truncation order and on the discretization level considered. Some final comments are
provided in Section 5.
M.D. Ruiz-Medina and R. Salmerón
2 Preliminaries
Let H be a separable Hilbert space endowed with the norm || · ||H associated with the
inner product < ·, · >H . Consider the autoregressive Hilbertian model of order one (ARH(1)
model)
Zt(x) = A[Zt−1](x) + νt(x), x ∈ D, t ∈ N?, (1)
where D ⊂ Rn is a bounded domain, Z = (Zt, t ∈ N) and ν = (νt, t ∈ N) are Hilbert-valued
random processes on the basic probability space (Ω,A, P ). Process ν is assumed to be strong
Hilbertian white noise, that is, a sequence of independent and identically distributed Hilbert-
valued random variables in H with
E(‖νt‖2H) = σ2ν <∞,
uncorrelated with the random initial condition Z0 ∈ H. The autocorrelation operator A is a
bounded operator defined on a dense domain inH, which is assumed to satisfy that there exists
a j ≥ 1, such that ‖Aj‖L < 1, with L denoting the space of linear bounded operators on H.
Remark 1 The results derived below can be similarly formulated within the ARH(p) model
framework considering its matrix AHR(1) formulation (see Salmerón and Ruiz-Medina, 2009,
and Ruiz-Medina and Salmerón, 2010).
2.1 Projection of ARH(1) equation
The derivation of the diagonal expression of the ARH(1) state equation, from its projection
on the eigenfunction systems associated with the autocorrelation operator A and its adjoint
A∗, is now provided. From now on, ∗ stands for the adjoint, or equivalently, for transposition,
in the finite-dimensional case.
Specifically, the spectral diagonal version of the functional equation (1) is derived in terms
of the respective left and right eigenfunction systems {ψi, i ∈ N} and {φi, i ∈ N} satisfying
Aψi = λiψi, i ∈ N,
A∗φi = λiφi, i ∈ N. (2)
Here, {λi, i ∈ N} denotes the sequence of eigenvalues defining the pure point spectrum of A
andA∗ (see, for example, Dautray & Lions, 1992). The systems {ψi, i ∈ N} and {φi, i ∈ N}
are dual Riesz bases, that is, they are bases of H and its dual H∗ satisfying
〈φi, ψj〉H = δi,j , i, j ∈ N.
Equivalently,
Φ∗Ψ = I, (3)
with I representing the identity operator, and Φ and Ψ being projection operators on the cor-
responding systems {φi : i ∈ N} and {ψi : i ∈ N} . From (2) and (3), operator A admits the
spectral factorization
A = ΨΛΦ∗,
Functional SEM algorithm
where Λ denotes a diagonal operator defined by the sequence of eigenvalues {λi, i ∈ N}. Ap-
plying the projection operator Φ∗ to both sizes of equation (1), the following diagonal version
is obtained
Φ∗Zt = ΛΦ∗Zt−1 +Φ∗νt.
Equivalently, for all j ∈ N,
aj(t) = λjaj(t− 1) + νj(t), j ∈ N, (4)
where
aj(t) = 〈Zt(·), φj(·)〉H , t ≥ 0, j ∈ N,
νj(t) = 〈νt(·), φj(·)〉H , t ≥ 0, j ∈ N.
2.2 Forward Kalman recursion
First, forward Kalman filtering is implemented from a truncated version of equation (4),
that is, from the projection of equation (4) on the M−finite-dimensional Hilbert dual spaces
HM and H∗M , generated by the first M left and right eigenfunctions {ψ1, . . . , ψM} and
{φ1, . . . , φM} . Thus, the following finite dimensional diagonal equation is obtained :
a(t) = Λa(t− 1) + ν(t), (5)
where, at each time t ∈ N,
a(t) = (a1(t), . . . , aM (t))
∗
,
ν(t) = (ν1(t), . . . , νM (t))
∗
,
and, as before, Λ denotes a diagonal M × M matrix with entries the eigenvalues λi, i =
1, . . . ,M. For implementation of Kalman filtering, we consider the functional observation
equation
Yt = Zt + εt, (6)
where ε = (εt, t ∈ N) represents a zero-mean strong Hilbertian white noise, which is assumed
to be uncorrelated with Z. Given the observations of process Y = (Yt, t ∈ N) up to time t,
the estimators â(t|t) = E (a(t)|Yt, . . . , Y1) and â(t|t − 1) = E (a(t)|Yt−1, . . . , Y1) of the
temporal random Fourier coefficients a(t) = (aj(t), j = 1, . . . ,M) will be computed from
the following equations
â(t|t) = â(t|t− 1) +Kt (Yt −Ψâ(t|t− 1)) ,
â(t|t− 1) = Λâ(t− 1|t− 1).
Here Kt is the gain operator, that is, the filter defining the smoothing effect on the spatial
functional data, given by
Kt = Pt|t−1Ψ
∗ (Rε +ΨPt|t−1Ψ∗)−1 ,
in terms of the covariance operator Rε of the observation noise, and the conditional second-
order moment
Pt|t−1 = var (a(t)|Yt−1, . . . , Y1) = ΛPt−1|t−1Λ+Qt,
M.D. Ruiz-Medina and R. Salmerón
denoting by Pt|t = E
(
(a(t)− aˆ(t|t)) (a(t)− aˆ(t|t))∗) and being Qt = Φ∗MRνΦM the
covariance operator of the random projections of νt on the right eigenfunction system. The
functional mean-square error is then approximated by
Pt|t = Pt|t−1 −KtΨPt|t−1.
The initial values considered are
â(0|0) = 0,
P0|0 = E (a(0)a(0)∗) ,
with a(0) = (a1(0), . . . , aM (0))∗ being the vector constituted by the truncated sequence of
Fourier coefficients of the random initial condition, i.e.,
Z0(·) ∼
M∑
i=1
ai(0)ψi(·).
2.3 Backward Kalman smoothing
The backward Kalman smoothing is implemented from the above forward recursion as
follows :
E (a(t− 1)|Yt1 , . . . , YtT ) = ât−1|t−1 +
(
Pt−1|t−1Λ̂
∗(Pt|t−1)−1
)
·
(
E (a(t)|Yt1 , . . . , YtT )− Λ̂ât−1|t−1
)
,
Var (a(t− 1)|Yt1 , . . . , YtT ) = Pt−1|t−1 +
(
Pt−1|t−1Λ̂
∗
(Pt|t−1)−1
)
· (var (a(t)|Yt1 , . . . , YtT )−Pt|t−1)
·
(
Pt−1|t−1Λ̂
∗(Pt|t−1)−1
)∗
,
for t = T, . . . , 1, where, as before, ∗ stands transposition in the finite-dimensional case.
3 Implementation of SEM algorithm
We first describe the implementation of the EM algorithm. The selection problem related
to choosing a suitable initial input values must be previously solved. We refer to Ruiz-Medina
and Salmerón (2009), where this problem is widely discussed. In particular, moment functional
estimators (see Bosq, 2000) are considered as initial values to begin with the first iteration
of forward and backward Kalman filtering followed by EM iteration. Secondly we show the
implementation of the SEM algorithm for missing functional data (see Meng and Rubin, 1991).
Functional SEM algorithm
3.1 EM iteration
This section provides the implementation of the EM algorithm for ML parameter estima-
tion of ARH processes.
To implement the EM algorithm we consider the incomplete observed functional data vec-
tor (noisy data) Y ∗ = (Y1, . . . , YtT ), which must be related with the complete functional
data vector (Z∗ = (Φ∗MZ) = (a(t1), . . . , a(tT )); (Φ∗Mε) = (ε(t1), . . . , ε(tT ))) , in terms of a
suitable transformation F, with t1, . . . , tT being the times where process Y is observed.
Under the Gaussian distribution assumption for the innovation and observation noise se-
quences, the EM algorithm is implemented, from the computation of the conditional expecta-
tion of the finite-dimensional log-likelihood function. First, the log-likelihood of the projected
complete functional data has the following expression under stationary in time of processes ν
and ε :
C + log fZ0 −
T
2
log |Φ∗MRνΦM | −
T
2
log |Φ∗MRεΦM |
−1
2
T∑
i=1
(a(ti)−Λa(ti − 1))∗ (Φ∗MRνΦM )−1 (a(ti)−Λa(ti − 1))
−1
2
T∑
i=1
(ε(ti))
∗
(Φ∗MRεΦM )
−1
(ε(ti)) .
Considering that the effect of the random initial condition is negligible at the times t1, . . . , tT ,
from standard results on quadratic forms, the conditional expectation of the complete data-
based log-likelihood given the incomplete data is computed as
C − T
2
log |Φ∗MRνΦM | −
T
2
log |Φ∗MRεΦM |
−1
2
tr
{
(Φ∗MRνΦM )
−1
(CZ −ΛB∗Z −BZΛ+ΛAZΛ)
}
−1
2
tr
{
(Φ∗MRεΦM )
−1
Cε
}
, (7)
where tr denotes the trace, and
CZ =
T∑
i=1
E (a(ti)a(ti)
∗|Yt1 , . . . , YtT ) ,
BZ =
T∑
i=1
E (a(ti)a(ti − 1)∗|Yt1 , . . . , YtT ) ,
AZ =
T∑
i=1
E (a(ti − 1)a(ti − 1)∗|Yt1 , . . . , YtT ) ,
Cε =
T∑
i=1
E (Φ∗Mεti(Φ
∗
Mεti)
∗|Yt1 , . . . , YtT ) .
Differentiating (7) with respect to Λ, Φ∗MRνΦM , and Φ∗MRεΦM , the maximum likeli-
hood estimates of the model parameters computed in the k−iteration of the Maximization step
M.D. Ruiz-Medina and R. Salmerón
(M-step) are given by
Λ̂
(k)
= diag[BZ ](k−1)[(diag[AZ ])−1](k−1)
̂Φ∗M×MRνΦM×M
(k)
=
1
T
T∑
i=1
E
[(
a(ti)− Λ̂
(k)
a(ti − 1)
)
·
(
a(ti)− Λ̂
(k)
a(ti − 1)
)T
/Y1, . . . , YT
]
=
1
T
[
C
(k−1)
Z −B(k−1)Z Λ̂
(k) − Λ̂(k)[BTZ ](k−1)
+Λ̂
(k)
A
(k−1)
Z Λ̂
(k)
]
,
̂Φ∗M×MRεΦM×M = C
(k−1)
ε /T,
where diag[A] denotes the diagonal of matrix A, and where A(k−1)Z , B
(k−1)
Z and C
(k−1)
Z are
computed from the forward Kalman filtering, and the backward Kalman smoothing, with input
values the functional parameter estimates obtained in the k− 1−iteration of the EM algorithm.
Remark 2 Note that, from the EM algorithm, the estimators Λ̂ and Q̂t are computed. However,
Φ andΨ are not, in general, known. For the estimation ofA andRν , we proceed as follows : At
the first iteration, the initial functional values considered for the eigenfunction systems {φi, i ∈
N} and {ψi, i ∈ N}, defining projection operators Φ̂0 and Ψ̂0, are constructed from the
spectral decomposition of the functional moment estimator
Â = R̂Z1Z0 · R̂−1Z0 ,
and its adjoint, where
R̂Z1Z0 =
1
T − 1
[
T−1∑
i=1
Yi ⊗ Yi+1
]
− 1
T − 1
[
T−1∑
i=1
Yi
]
⊗ 1
T − 1
[
T−1∑
i=1
Yi+1
]
R̂Z0 =
1
T
[
T∑
i=1
Yi ⊗ Yi
]
− 1
T
[
T∑
i=1
Yi
]
⊗ 1
T
[
T∑
i=1
Yi
]
− σ̂2εI, (8)
with Yi, i = 1, . . . , T, being the observed functional incomplete data, defined as in equation
(6). Estimator σ̂2ε can be computed from the nugget effect of the functional variogram (see,
for example, Ruiz-Medina, Salmerón and Angulo, 2007). In the rest of iterations, projection
operators Φ̂k and Ψ̂k are derived from the spectral decomposition of Â(k−1) computed in the
previous iteration of the EM algorithm.
3.2 Finite-dimensional approximation of the SEM algorithm
The functional SEM algorithm provides the observed-functional-data asymptotic cova-
riance operator of the infinite-dimensional ML parameter estimator, from the computation of
Functional SEM algorithm
the complete-functional-data asymptotic covariance operator, and the convergence rate opera-
tor, i.e., the operator providing information about the rate of convergence of the EM algorithm
in the Hilbert-valued random variable context. Note that, in this context, each iteration of the
EM algorithm can be expressed as
Θ(k+1) = F (Θ(k)), k ∈ N,
where F denotes the functional which implicitly describes the EM algorithm for ML estimation
of the functional parameter vectorΘ. Here, the limitΘ∗, in the bounded linear operator norm,
of the functional sequence {Θ(k), k ∈ N} is defined as
Θ∗ = F (Θ∗),
in the case where F is continuous with respect to the operator norm considered. The conver-
gence rate operator is then defined as the Fréchet derivative of the functional F at pointΘ∗.
In this section, a finite-dimensional approximation of the functional SEM algorithm is im-
plemented, in terms of the recursive projection estimators obtained in the previous section from
the EM algorithm. Specifically, the complete-functional-data asymptotic covariance operator,
I−1CFD, is approximated from the expression
I−1CFD = L
−1
T ·
[
T∑
t=1
L(t− 1)∗ (Φ∗MRνΦM )L(t− 1)
]
· L−1T ,
with LT =
T∑
t=1
L(t − 1)∗L(t − 1), L(t − 1) = diag (a1(t− 1), . . . , aM (t− 1))M×M and
Rν being the covariance operator of ν. In practice, L(t − 1) is replaced by ̂L(t− 1) =
diag (E (a(t− 1)|Yt1 , . . . , YtT ))M×M , obtained as the output of the corresponding forward
and backward Kalman recursion iteration, and Rν is replaced by R̂ν , computed as the output
of the corresponding iteration of the EM algorithm.
The finite-dimensional approximation of the convergence rate operator is computed from
the rate matrix, DM = (r(i, j))i,j=1,...,M , which is calculated as follows : First run the
forward and backward Kalman filter and EM algorithm to obtain Λ̂(k), at iteration k, and then
use the following algorithm, for i = 1, . . . ,M :
Step 1 : Compute Λ˜(k)(i,i), with i ∈ {1, . . . ,M}, by replacing in the original matrix Λ the value
of the (i, i) element by the (i, i) element of the matrix Λ̂(k). That is,
Λ˜
(k)
(i,i) =
{
λj , j = 1, . . . , i− 1, i+ 1, . . . ,M
λ̂
(k)
j , j = i,
where λ̂(k)j is the (j, j) element of Λ̂(k).
Step 2 : Run the Kalman filter and EM algorithm, with input parameter values given by the
elements of Λ˜(k)(i,i), to obtain Λ˜
(k+1)
(i,i) .
Step 3 : Obtain, for l = 1, . . . ,M, and for λ˜(k+1)(i,i) (l, l), the (l, l) element of Λ˜
(k+1)
(i,i) , the ratio
r(i, l) =
λ˜
(k+1)
(i,i) (l, l)− λl
λ̂
(k)
i − λi
. (9)
M.D. Ruiz-Medina and R. Salmerón
After that, run the forward and backward Kalman filter and EM algorithm, with initial input
parameter values given by the elements of Λ̂(k), to obtain Λ̂(k+1), and repeat steps 1, 2 and 3.
Finally, the observed-functional-data asymptotic covariance operator of the computed Λ̂
estimator is approximated by
V = I−1CFD (I −DM)−1 , (10)
with I being the identity matrix. Note that the diagonal elements of DM matrix provide infor-
mation on the convergence rates to the elements of Λ, in the EM approximation.
The finite-dimensional estimation of the asymptotic covariance operator of the estimator
̂Φ∗MRνΦM can be computed, in a similar way to the above algorithm, from the forward and
backward Kalman filter and smoothing iteration, as well as from the corresponding EM itera-
tion, considering the finite-dimensional estimation of the corresponding complete-functional-
data covariance operator and DM matrix. Similar computations must be done for the finite-
dimensional approximation of the asymptotic cross covariance operator between ̂Φ∗MRνΦM
and Λ̂.
4 Simulation study
Since in the projection estimation methodology proposed, the truncation order is selected
according to the percentage of the trace norm of the autocorrelation operator explained, a good
approximation of the theoretical trace of such an operator must be previously derived. In the si-
mulation study developed in this section, this fact is illustrated. The goal of this section is then
to investigate the fixed-domain asymptotic properties of the estimates obtained for the eigen-
values of the autocorrelation operator, as well as for the covariance operator of the functional
innovation process.
We consider the case where the ARH(1) process Z has autocorrelation operator defined in
terms of the integral operatorK with kernel
k(z; θ) =
1
θ
exp
{
−||z||
θ
}
,
where ||z|| denotes the distance between spatial locations, and θ is the scale parameter involved
in the definition of the exponential kernel.
The random initial condition is assumed to be a Hilbert-valued Gaussian random variable
with integral covariance operator defined in terms of a factorizable kernel rY0 = tY0 ∗ tY0 ,
where ∗ denotes convolution, and with
tY0(z; γ) =
1√
2 · pi · γ · exp
{
−||z||
2
2 · γ
}
.
Covariance factorization is derived in Ruiz-Medina, Angulo and Anh (2003) considering the
scale of fractional Sobolev spaces. In this example, we consider such a scale on R2. Indeed,
the underlying nuclear Hilbert structure, defined by Bessel potentials and their inverses, is
considered for the choice of the norm of the Hilbert space H where process Z, as well as
the innovation and observation processes are suitably defined as second-order Hilbert-valued
Functional SEM algorithm
FIG. 1 – Main steps in the implementation of the ML projection estimation method
processes. Specifically, the innovation process is assumed to be a functional Gaussian process
with covariance operator Rν = σ2νI, with I being the identity operator, and
σ2ν =
0.1
N
√
2 · pi .
The observation noise is also assumed to be a Gaussian spatiotemporal white noise with va-
riance σ2ε . The space H must then be endowed with the norm generated by a Bessel potential
of order α > 1 (see Embedding Theorems between fractional Besov spaces in, for example,
Triebel, 1978). Regarding the spectral factorization of the autocorrelation operator in this set-
ting, note that dual Riesz bases of H and H∗ can then be constructed from an orthonormal
basis of L2(R2) transformed by the corresponding Bessel potential and the adjoint of its in-
verse (see Ruiz-Medina, Salmerón and Angulo, 2007, and Salmerón and Ruiz-Medina, 2009,
for such a construction). The quality of the projection estimates is computed below in terms of
the Hilbert-Schmidt norm.
In the results displayed below, we consider the case where θ = 5 and γ = 1.
The steps followed in the implementation of the ML projection estimation methodology,
from the generated data, are described in Figure 1. Specifically, the first step consists of the
implementation of forward Kalman filtering, getting an approximation Ẑ of the functional
values of Z, in terms of the computation of â(t|t) andPt|t. The last two terms are entries in the
backward Kalman filter. The application of backward Kalman filter allows the computation of
matricesAZ ,BZ and CZ , i.e., the matrices involved in the estimation of functional parameters
Q and Λ by EM algorithm. These estimates will be used as initial values in a new iteration
of the forward Kalman filtering. Finally, the values obtained from the EM algorithm will also
be used to calculate V and DM through the SEM algorithm. This loop will be repeated until
convergence
Different truncation orders (M−values) (e.g., corresponding to 50%, 60%, 70%, 80%, and
90% of the trace norm of the empirical autocorrelation operator) are considered in the simu-
lation study developed below. Table 1 provides the value of M corresponding to different
percentages of the trace norm of the autocorrelation operator, when the discretization step size
changes.
M.D. Ruiz-Medina and R. Salmerón
Regular grid 16× 16 21× 21 26× 26
50% 3 5 7
60% 5 8 11
70% 8 13 19
80% 15 25 37
90% 37 62 93
N 256 441 676
TAB. 1 – Truncation orders,M , for each spatial regular grid
Regular grid AVD
16× 16 0.005088
21× 21 0.004028
26× 26 0.003437
TAB. 2 – Mean absolute difference between empirical and theoretical spectral tails
Table 2 displays the mean absolute value of the differences (AVD) between the smallest
N − 16 theoretical and estimated eigenvalues, for each spatial regular grid considered. That is
AVD =
1
N− 16
N∑
i=16
|λi − λ̂i|.
The AVD is considered to measure the distance between the empirical and the theoretical
spectral tails of the autocorrelation operator. Since consistency of the empirical eigenvalues
computed leads to the convergence of the empirical spectral tail to the theoretical one, the
AVD is used as a criterion for selection of a convenient discretization step size. Furthermore,
the local regularity properties of the autocorrelation operator are reflected in the decay velocity
of its spectrum. Therefore, we consider the lastN−16 smallest eigenvalues, where the spectral
decay velocity is captured to compute, in terms of the AVD, the most significative differences
between the empirical and theoretical autocorrelation local regularity properties. As expected,
in Table 2, it is observed that the mean absolute difference decreases when density of the
spatial grid considered increases, i.e., when discretization step size goes to zero. Also, Figure
3 illustrates the fact that differences between the empirical and theoretical spectral tails of
the autocorrelation operator disappear when the discretization step size goes to zero, i.e., the
empirical local regularity properties of the autocorrelation operator tends to the theoretical ones.
On the other hand, in Figure 9, differences between the theoretical values and EM estimates
of the eigenvalues are displayed, for N = 121, N = 256 and N = 441 spatial locations,
and different truncation orders. Additionally to the commented effect of the discretization step
size on the empirical eigenvalues, initializing the EM algorithm, it can also be seen that, for a
fixed N, the quality of the EM estimates of the eigenvalues is improved whenM increases, as
expected (see light blue line). Note that, in all the cases, differences are very small (of order of
10−17).
Figures 4-6 display the theoretical values and the functional estimates of the process of
interest Z, at times t = 1, 10, 20, and considering the truncation order corresponding to explai-
Functional SEM algorithm
0 50 100 150 200 250 300
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
Number of Eigenvalue
Ei
ge
nv
al
ue
0 2 4 6 8 10 12 14 16
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
Number of Eigenvalue
Ei
ge
nv
al
ue
FIG. 2 – Decay velocity of the theoretical eigenvalues of the autocorrelation exponential-type
kernel
ning a 90% of the trace norm of the autocorrelation operator. These results are again displayed
for a regular spatial grid withN = 121,N = 256 andN = 441 points. As before, it can be ap-
preciated that the quality of the estimates increases when the discretization step size decreases.
M.D. Ruiz-Medina and R. Salmerón
0 50 100 150 200 250 300 350 400 450
0
0.002
0.004
0.006
0.008
0.01
0.012
0.014
0.016
0.018
Number of Eigenvalue
D
iff
er
en
ce
0 100 200 300 400 500 600 700
0
0.005
0.01
0.015
0.02
0.025
0.03
Number of Eigenvalue
D
iff
er
en
ce
FIG. 3 – Absolute value differences between the last N − 16 theoretical and empirical eigen-
values for N = 441 and N = 676 spatial locations (top to bottom)
The functional quadratic errors (F.Q.E.) associated with the functional estimation of
ARH(1) process Z (after applying forward and backward Kalman recursion combined with
EM) are computed as
1
N
√
N∑
i=1
√
N∑
j=1
[
Zt(i, j)− Ẑt(i, j)
]2
.
Figure 7 displays the F.Q.E. for the three spatial functional data discretization levels considered
(N = 121,N = 256 andN = 441). As commented in Figures 4-6, the quality of the estimates
is improved when the discretization step size goes to zero. Thus, whenN increases, F.Q.E. are
mainly produced by the truncation error (see also Figures 4-6), while, for small N, truncation
and discretization errors are involved in the F.Q.E., and less quality of the estimates is observed,
for each truncation order, in comparison with large values of N.
Functional SEM algorithm
0
2
4
6
8
10
12
0
2
4
6
8
10
12
−0.025
−0.02
−0.015
−0.01
−0.005
0
0.005
0.01
0.015
0.02
Original process
0
2
4
6
8
10
12
0
2
4
6
8
10
12
−0.02
−0.01
0
0.01
0.02
0.03
Estimated process − 90%
0
2
4
6
8
10
12
0
2
4
6
8
10
12
−0.02
−0.015
−0.01
−0.005
0
0.005
0.01
0.015
0.02
0.025
Original process
0
2
4
6
8
10
12
0
2
4
6
8
10
12
−0.02
−0.015
−0.01
−0.005
0
0.005
0.01
0.015
0.02
Estimated process − 90%
0
2
4
6
8
10
12
0
2
4
6
8
10
12
−0.02
−0.015
−0.01
−0.005
0
0.005
0.01
0.015
0.02
0.025
Original process
0
2
4
6
8
10
12
0
2
4
6
8
10
12
−0.03
−0.02
−0.01
0
0.01
0.02
0.03
Estimated process − 90%
FIG. 4 – Original (left) and estimated process Z (right) at times t = 1, 10, 20 (top to bottom),
for N = 121, and truncation order 90%
Figure 8 shows the estimated variance σ̂2ν , for the truncation orders considered, and forN =
121, N = 256 and N = 441 jointly with the real value (black squares). As expected, for each
value of N, the quality of the estimates increases whenM increases (purple line).
To complete this study, the distance between the theoretical and estimated operators Λ and
Φ∗RνΦ is displayed in Figure 10, for each truncation order and regular grid, at 6 iterations.
M.D. Ruiz-Medina and R. Salmerón
0
5
10
15
20
0
5
10
15
20
−0.02
−0.015
−0.01
−0.005
0
0.005
0.01
0.015
0.02
Original process
0
5
10
15
20
0
5
10
15
20
−0.03
−0.02
−0.01
0
0.01
0.02
0.03
Estimated process − 90%
0
5
10
15
20
0
5
10
15
20
−0.02
−0.015
−0.01
−0.005
0
0.005
0.01
0.015
Original process
0
5
10
15
20
0
5
10
15
20
−0.03
−0.02
−0.01
0
0.01
0.02
0.03
0.04
Estimated process − 90%
0
5
10
15
20
0
5
10
15
20
−0.02
−0.015
−0.01
−0.005
0
0.005
0.01
0.015
0.02
Original process
0
5
10
15
20
0
5
10
15
20
−0.03
−0.02
−0.01
0
0.01
0.02
0.03
Estimated process − 90%
FIG. 5 – Original (left) and estimated process Z (right) at times t = 1, 10, 20 (top to bottom),
for N = 256, and truncation order 90%
That is, the following norms
1
M2
M∑
i=1
M∑
j=1
(
Q(i, j)− Q̂(i, j)
)2
,
1
M2
∑
i,j
(
Λ(i, j)− Λ̂(i, j)
)2
(1/M)
∑
i |Λ(i, i)− Λ̂(i, i)|
Functional SEM algorithm
0
5
10
15
20
25
0
5
10
15
20
25
−0.015
−0.01
−0.005
0
0.005
0.01
0.015
0.02
Original process
0
5
10
15
20
25
0
5
10
15
20
25
−0.08
−0.06
−0.04
−0.02
0
0.02
0.04
0.06
0.08
Estimated process − 90%
0
5
10
15
20
25
0
5
10
15
20
25
−0.02
−0.015
−0.01
−0.005
0
0.005
0.01
0.015
Original process
0
5
10
15
20
25
0
5
10
15
20
25
−0.06
−0.04
−0.02
0
0.02
0.04
0.06
Estimated process − 90%
0
5
10
15
20
25
0
5
10
15
20
25
−0.015
−0.01
−0.005
0
0.005
0.01
0.015
Original process
0
5
10
15
20
25
0
5
10
15
20
25
−0.08
−0.06
−0.04
−0.02
0
0.02
0.04
0.06
0.08
Estimated process − 90%
FIG. 6 – Original (left) and estimated process Z (right) at times t = 1, 10, 20 (top to bottom),
for N = 441, and truncation order 90%
are computed, whereQ = Φ∗RνΦ. These norms are approximately of order 10−17−10−16, for
Λ, and of order 10−8, for Φ∗RνΦ. The results displayed reflect the commented dependence on
the discretization step size and truncation order of the performance of the projection estimation
methodology proposed.
Finally, Figure 11 shows, after four iterations, the ratio of convergence in the estimation
M.D. Ruiz-Medina and R. Salmerón
of Λ̂ and Φ̂∗RνΦ, for each discretization level (N = 121, N = 256 and N = 441), and
truncation order. Faster convergence is observed forN = 441 than forN = 121. The averages
of the diagonal elements of DM matrix computed with the SEM algorithm are also displayed
in Figure 12. The diagonal of DM provides information on the ratio of convergence of the
EM estimate sequence of Λ. From expression (9), these diagonal values must be close to one
for the convergence of the estimate sequence. In Figure 12, it can be appreciated that, after 6
iterations, for all discretization step sizes, convergence is achieved by the EM estimates of the
eigenvalues of the autocorrelation operator.
5 Final Comments
The recursive functional ML projection estimation methodology developed here is based
on the biorthogonal spectral decomposition of the autocorrelation operator. The left and right
autocorrelation eigenfunction systems provide a more suitable computational framework for
implementation of recursive functional ML estimation algorithms, from incomplete functional
data. In particular, Functional Principal Component Analysis of ARH(1) processes is more
suitable for moment-based estimation (see Bosq, 2000). Finally, we remark that the asymptotic
normality of the incomplete-functional-data based ML projection estimators of the ARH(1)-
infinite-dimensional parameters is studied in Ruiz-Medina (2010).
Acknowledgments. This work has been supported in part by projects MTM2008-03903 and
MTM2009-13393 of the DGI, MEC, and P06-FQM-02271 and P09-FQM-5052 of the Anda-
lousian CICE, Spain.
References
Abramovich, F. and Angelini, C. (2006). Testing in mixed effects FANOVA models. Journal
of Statistical Planning and Inference 136, 4326-4348.
Abramovich, F., Antoniadis, A., Sapatinas, T and Vidakovic, B. (2004). Optimal testing in
functional analysis of variance models. Int. J. Wavelets Multiresolution Inform. Process.
2, 323-349.
Antoniadis, A. and Sapatinas, T. (2003). Wavelet methods for continuous-time prediction
using Hilbert-valued autoregressive processes. Journal of Multivariate Analysis 87, 133-
158.
Besse, P., Cardot, H. and Stephenson, D.B. (2000). Autoregressive forecasting of some func-
tional climatic variations. Scandinavian Journal of Statistics 27, 673-687.
Bosq, D. (2000). Linear processes in function spaces, Springer-Verlag.
Bosq, D. (2008). Nonparametric statistics for stochastic processes, estimation and prediction.
Lectures Notes in Statistics 110, Springer-Verlag, New York.
Bosq, D. and Blanke, D. (2007). Inference and prediction in large dimensions, Wiley Series
in Probability and Statistics, John Wiley & Sons.
Cardot, H., Ferraty, F., Mas, A. and Sarda, P. (2003). Testing hypotheses in the functional
linear model. Scandinavian Journal of Statistics 30, 241-255.
Functional SEM algorithm
Dautray, R. and Lions, J.L. (1992).Mathematical analysis and numerical methods for science
and technology 3, Spectral Theory and Applications, Springer-Verlag, Berlin.
Dempster, A.P., Laird, N.M. and Rubin D.B. (1977). Maximum Likelihood from Incomplete
Data via the EM Algorithm. Journal of the Royal Statistical Society. Series B (Methodo-
logical), 39, 1, 1-38.
Ferraty, F. and Vieu, P. (2006). Nonparameric functional data analysis, Springer.
Germain, F., Doisy, A., Ronot, X. and Tracqui, P. (1999). Characterization of cell deformation
and migration using a parametric estimation of image motion. IEEE Transactions on
Biomedical Engineering 46, 584-600.
Haoudi, A. and Bensmail, H. (2006). Bioinformatics and data mining in proteomics. Expert
Review of Proteomics, 3, 333–343.
Hartley, H.O. (1958). Maximum Likelihood Estimation from Incomplete Data. Biometrics,
14, 2, 174-194.
Hyndman, R.J. and Ullah, M.S. (2006). Robust forecasting of mortality and fertility rates : A
functional data approach. Computational Statistics & Data Analysis 51, 4942-4956.
Leng, X. and Müller, H.G. (2006). Classification using functional data analysis for temporal
gene expression data. Bioinformatics 22, 68–76.
Mas, A. (1999) . Normalittè asymptotique de l’estimateur empirique de l’opérateur d’autocor-
rélation d’un processus ARH(1). C. R. Acad. Sci. Paris 329 Série I 899-902.
Mas, A. (2007). Weak convergence in the functional autoregressive model. J. Multivariate
Analysis 98, 1231-1261.
Meng, X.L. and Rubin, D.B. (1991). Using EM to Obtain Asymptotic Variance-Covariance
Matrices : The SEM Algorithm. Journal of the American Statistical Association 86, 899-
909.
Monk, N.A.M. (2003). Unravelling Nature’s networks. Biochemical Society Transactions 31,
1457-1561.
Ramsay, J.O. and Silverman, B.W. (2005). Functional data analysis, Springer, New York.
Ruiz-Medina, M.D. (2010). Asymptotic normality of functional maximum-likelihood ARH
parameter estimators. (Submitted).
Ruiz-Medina, M.D., Angulo, J.M. and Anh, V.V. (2003) Fractional generalized random fields
on bounded domains. Stochastics Analysis and Applications, 21, 465-492.
Ruiz-Medina, M.D., Salmerón, R. and Angulo, J.M. (2007). Kalman filtering from POP-
based diagonalization of ARH(1). Computational Statistics & Data Analysis. 51, 4994-
5008.
Ruiz-Medina, M.D. and Salmerón, R. (2009). Functional maximum-likelihood estimation
of ARH(p) models. Stochastic Environmental Research and Risk Assessment. doi :
10.1007/s00477-009-0306-2.
Salmerón, R. and Ruiz-Medina, M.D. (2009). Multispectral decomposition of functional au-
toregressive models. Stochastic Environmental Research and Risk Assessment 23, 289-
297.
M.D. Ruiz-Medina and R. Salmerón
Song, J.J., Lee, H.J., Morris, J.S. and Kangd, S. (2007). Clustering of time-course gene ex-
pression data using fuctional data analysis. Computational Biology and Chemistry 31,
265-274.
Triebel, H. (1978) Interpolation theory, function spaces, differential operators. North-
Holland Publishing Co, New York.
Summary
This paper addresses the problem of computation of the asymptotic variance of the maxi-
mum likelihood projection parameter estimators derived in Ruiz-Medina and Salmerón (2010)
for autoregressive Hilbertian (ARH) processes, from Gaussian incomplete functional data. A
functional version of the SEM (Supplemented Expectation Maximization) algorithm, derived
by Meng and Rubin (1991), is implemented for approximation of such variances. The imple-
mentation is performed in terms of the eigenfunction systems and eigenvalues diagonalizing
the autocorrelation operator and its adjoint. A simulation study is devoted to investigate the
effect of the truncation order, and the functional data discretization level.
Functional SEM algorithm
0 2 4 6 8 10 12 14 16 18 20
1
2
3
4
5
6
7
8
9
10
x 10−4
Time
F.
Q.
E.
0 2 4 6 8 10 12 14 16 18 20
0.6
0.8
1
1.2
1.4
1.6
1.8
2
x 10−4
Time
F.
Q.
E.
0 2 4 6 8 10 12 14 16 18 20
0.6
0.8
1
1.2
1.4
1.6
1.8
2
x 10−4
Time
F.
Q.
E.
FIG. 7 – F.Q.E. in the functional estimation of Z for N = 121, N = 256 and N = 441
spatial locations (top to bottom). The purple line represents the F.Q.E. for truncation order
corresponding to 50% of the trace norm of the empirical autocorrelation operator, green line
for 60%, red line for 70%, light blue for 80%, and blue line for 90%
M.D. Ruiz-Medina and R. Salmerón
1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6
2
3
4
5
6
7
8
9
x 10−5
Iteration
Es
tim
at
ed
 v
ar
ia
nc
e
1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6
1
1.5
2
2.5
3
3.5
4
x 10−5
Iteration
Es
tim
at
ed
 v
ar
ia
nc
e
1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
2.2
2.4
x 10−5
Iteration
Es
tim
at
ed
 v
ar
ia
nc
e
FIG. 8 – Estimated variance σ̂2ν for N = 121, N = 256 and N = 441 spatial locations (top
to bottom). The blue line represents the estimate obtained for truncation order corresponding
to 50% of the trace norm of the empirical autocorrelation operator, green line for 60%, red
line for 70%, light blue for 80%, and purple line for 90%
Functional SEM algorithm
0 10 20 30 40 50 60 70 80 90 100
−8
−6
−4
−2
0
2
4
6
8
x 10−17
Number of Eigenvalue
D
iff
er
en
ce
0 50 100 150 200 250
−5
−4
−3
−2
−1
0
1
2
3
4
5
x 10−17
Number of Eigenvalue
D
iff
er
en
ce
0 50 100 150 200 250 300 350 400
−5
−4
−3
−2
−1
0
1
2
3
4
5
x 10−17
Number of Eigenvalue
D
iff
er
en
ce
FIG. 9 – Differences between theoretical values and EM estimates of the eigenvalues forN =
121,N = 256 andN = 441 spatial locations (top to bottom). Yellow line for truncation order
corresponding to 50% , green line for 60% , red line for 70% , purple line for 80%, and light
blue line for 90%.
M.D. Ruiz-Medina and R. Salmerón
1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6
1.6
1.8
2
2.2
2.4
2.6
2.8
3
3.2
x 10−17
Iteration
H
ilb
er
t−
Sc
hm
id
t n
or
m
1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6
0
1
2
3
4
5
6
7
x 10−6
Iteration
H
ilb
er
t−
Sc
hm
id
t n
or
m
1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6
1.7
1.8
1.9
2
2.1
2.2
2.3
2.4
2.5
2.6
2.7
x 10−17
Iteration
H
ilb
er
t−
Sc
hm
id
t n
or
m
1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6
0
0.5
1
1.5
2
2.5
3
3.5
x 10−6
Iteration
H
ilb
er
t−
Sc
hm
id
t n
or
m
1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
x 10−16
Iteration
H
ilb
er
t−
Sc
hm
id
t n
or
m
1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
x 10−6
Iteration
H
ilb
er
t−
Sc
hm
id
t n
or
m
FIG. 10 – The relative Hilbert-Schmidt norm of the error matrix in the estimation ofΛ, and the
Hilbert-Schmidt norm of the error matrix in the estimation of Φ∗RνΦ (left to right), for N =
121, N = 256 and N = 441 spatial locations (top to bottom). The blue line is associated with
the truncation order corresponding to 50% of the trace norm of the empirical autocorrelation
operator, green line for 60%, red line for 70%, light blue for 80%, and purple line for 90%
Functional SEM algorithm
1 1.5 2 2.5 3 3.5 4
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
Iteration
R
at
io
 o
f c
on
ve
rg
en
ce
1 1.5 2 2.5 3 3.5 4
0.85
0.9
0.95
1
1.05
1.1
Iteration
R
at
io
 o
f c
on
ve
rg
en
ce
1 1.5 2 2.5 3 3.5 4
0.8
1
1.2
1.4
1.6
1.8
2
Iteration
R
at
io
 o
f c
on
ve
rg
en
ce
1 1.5 2 2.5 3 3.5 4
0.92
0.94
0.96
0.98
1
1.02
1.04
1.06
1.08
1.1
Iteration
R
at
io
 o
f c
on
ve
rg
en
ce
1 1.5 2 2.5 3 3.5 4
0
2
4
6
8
10
12
14
Iteration
R
at
io
 o
f c
on
ve
rg
en
ce
1 1.5 2 2.5 3 3.5 4
0.94
0.96
0.98
1
1.02
1.04
1.06
1.08
Iteration
R
at
io
 o
f c
on
ve
rg
en
ce
FIG. 11 – Ratio of convergence in the functional estimation of Λ andΦ∗RνΦ (left to right), for
N = 121, N = 256 and N = 441 spatial locations (top to bottom). The blue line represents
the ratio of convergence for truncation order corresponding to 50% of the trace norm of the
empirical autocorrelation operator, green line for 60%, red line for 70%, light blue for 80%,
and purple line for 90%
M.D. Ruiz-Medina and R. Salmerón
1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
1.2
1.3
Iteration
Av
er
ag
e 
di
ag
on
al
 D
M
1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6
−1
−0.5
0
0.5
1
1.5
2
Iteration
Av
er
ag
e 
di
ag
on
al
 D
M
1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
Iteration
Av
er
ag
e 
di
ag
on
al
 D
M
FIG. 12 – Average of the diagonal elements of DM matrix, for N = 121, N = 256 and
N = 441 spatial locations (top to bottom). The blue line represents the diagonal average for
truncation order corresponding to 50%, green line for 60%, red line for 70%, light blue for
80%, and purple line for 90%
