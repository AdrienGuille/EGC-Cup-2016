Fusion et normalisation de réseaux possibilistes quantitatifs
Salem Benferhat∗
Faiza Titouna∗,∗∗
Mohamed Tayeb Laskri∗∗∗
∗CRIL-CNRS, Université d’Artois Rue Jean Souvraz 62307 Lens, France.
benferhat@cril.univ-artois.fr
∗∗Université Badji Mokhtar, Annaba.
titouna@univ-batna.dz
∗∗∗Université Badji Mokhtar, Annaba.
laskri@univ-annaba.org
Résumé. La fusion d’informations incertaines, issues de différentes sources,
est un problème important dans de nombreuses applications. Dans cet article,
nous développons une méthodologie d’analyse des opérateurs de combinaisons
possibilistes où l’information incertaine est exprimée à l’aide de réseaux possi-
bilistes quantitatifs (basés sur l’opérateur produit). Nous montrons que la fusion,
basée sur le produit, de réseaux possibilistes ayant des structures identiques, se
fait en un temps polynômial. Nous étudions ensuite la fusion de réseaux possi-
bilistes ayant différentes structures, mais dont l’union de ces réseaux ne contient
pas de cycles. La dernière partie de cet article traite le problème de la sous-
normalisation qui reflète la présence de conflits entre les différentes sources
d’informations.
1 Introduction
Le problème de la combinaison d’informations provenant de différentes sources est présent
dans différentes applications comme la robotique, le transport, la médecine ou le traitement
d’images. Cet article s’intéresse au problème de la fusion d’informations incertaines multi-
source représentées, dans le cadre de la théorie des possibilités, par les réseaux possibilistes.
Les réseaux probabilistes Jensen (1996), Pearl (1988) et les réseaux possibilistes Fonck (1992),
Borgelt et al. (1998) sont des outils importants, proposés pour une représentation et une ana-
lyse efficace de l’information incertaine. Leur succès est dû à leur simplicité et leur capacité
à représenter et à prendre en compte les relations d’indépendance qui sont importantes pour
une gestion efficace des informations incertaines. Les réseaux possibilistes sont des graphes
orientés acycliques (DAG), où chaque nœud représente une variable et chaque arc représente
une relation d’influence entre deux variables. L’incertitude est exprimée par des distributions
de possibilités conditionnelles au niveau de chaque nœud dans le contexte de ses parents.
En théorie des possibilités Zadeh (1978), Dubois et Prade (1988), il existe deux types de ré-
seaux possibilistes selon que le conditionnement possibiliste soit basé sur l’opérateur minimum
(on parle alors de réseaux possibilistes ordinaux) ou sur l’opérateur produit. Dans cet article
Fusion de réseaux possibilistes
nous considérons seulement le cas du conditionnement basé sur le produit. On parlera alors de
réseaux possibilistes quantitatifs (ou basés sur le produit).
Plusieurs travaux ont été proposés pour la fusion de bases de connaissances propositionnelles
ou pondérées (c’est à dire les formules ayant différents niveaux d’importance ou de priorité)
voir par exemple les travaux de Qi et al. (2006), Konieczny et Perez (1998), Lin et Mendelzon
(1998), Benferhat et al. (1997). Cependant très peu de travaux existent sur la fusion de réseaux
possibilistes, que ce soit dans le cadre de la théorie des possibilités ou dans le cadre de la théo-
rie des probabilités.
Nous proposons dans cet article, une méthode qui fusionne n réseaux possibilistes. Le résultat
de la fusion doit être en accord avec la sémantique de la théorie des possibilités. Nous étudions
en particulier le problème dit de sous-normalisation qui concerne le traitement des conflits
entre les sources d’informations.
Le reste de cet article est organisé comme suit: dans la section suivante, nous présentons les no-
tions de base de la théorie des possibilités et des réseaux possibilistes quantitatifs. La Section
3 rappelle le mode de combinaison conjonctive des distributions de possibilités. La Section
4 discute la fusion des réseaux possibilistes ayant la même structure graphique. La Section 5
concerne les réseaux possibilistes de structures différentes mais dont l’union de leur graphes
ne contient pas de cycles. La Section 6 traite le problème de la sous-normalisation qui reflète
la présence de conflits entre les sources. La dernière section conclut l’article.
2 Notions de base de la théorie des possibilités
Soit V = {A1,A2,...,AN} un ensemble de variables. On note parDA = {a1,..,am} le do-
maine associé à chaque variable A et par a une instance de A. L’univers de discours, défini par
le produit cartésien des domaines de toutes les variables dans V , est noté par Ω = ×Ai∈VDAi .
Chaque élément ω ∈ Ω est appelé un état (une situation) ou un événement élémentaire.
2.1 Distributions de possibilités et mesures de possibilités
Une distribution de possibilité pi est une fonction de Ω dans [0, 1]. Elle représente la
connaissance sur un ensemble de situations possibles parmi lesquelles nous distinguons celles
qui sont plus plausibles que d’autres. La valeur pi(ω) exprime un degré de compatibilité (ou
de cohérence) de la situation ω avec les connaissances codées par pi. Une distribution de pos-
sibilité pi est dite normalisée (ou cohérente), si h(pi) = maxω∈Ω pi(ω) = 1. Elle est dite
sous-normalisée si h(pi) < 1.
Étant donnée une distribution de possibilité pi définie sur un univers de discours Ω, nous dé-
finissons la mesure de possibilité d’un événement φ ⊆ Ω par Π(φ) = maxω∈φ pi(ω). Π(φ)
exprime un degré de compatibilité de l’événement φ avec les connaissances codées par pi.
En théorie des possibilités, le conditionnement consiste à modifier les connaissances dispo-
nibles, codées par une distribution de possibilités pi, par l’arrivée d’une nouvelle information
certaine φ ⊆ Ω. Pour une étude détaillée des propriétés du conditionnement voir Benferhat
et al. (2002). Il existe deux principales définitions du conditionnement possibiliste. Dans cet
S. Benferhat et al.
article nous nous intéressons uniquement au conditionnement basé sur le produit défini par :
∀ω ∈ Ω, Π(ω | φ) =
{
pi(ω)
Π(φ) ω ∈ φ
0 sinon
Par convention, si Π(φ) = 0 alors ∀ω, Π(ω | φ) = 1.
Finalement nous rappelons la notion de relations d’indépendances. L’idée de base de l’indépen-
dance causale consiste à considérer qu’une variable (ou un ensemble de variables) n’a aucune
influence sur une autre variable (ou un ensemble de variables), si apprendre que cette variable
est vraie ne modifie pas notre croyance sur l’autre variable. Notre intérêt se focalise sur la rela-
tion d’indépendance basée sur le produit, définie par : Soient X,Y et Z trois sous-ensembles de
variables disjoints. On dit que X est indépendante de Y dans le contexte de Z, si pour chaque
instance z ∈ DZ , le degré de possibilité de chaque x ∈ DX est préservé pour n’importe quelle
valeur de y ∈ DY . Plus formellement, nous avons :
∀x ∈ ×A∈XDA,∀y ∈ ×B∈YDB ,∀z ∈ ×C∈ZDC , Π(x | y ∧ z) = Π(x | z).
Pour plus de discussions sur les relations d’indépendance dans le cadre de la théorie des possi-
bilités, voir De Cooman (1997), Bouchon-Meunier et Marsala (2002), Ben Amor et al. (2000).
2.2 Réseaux quantitatifs possibilistes
Cette sous-section définit les graphes possibilistes quantitatifs. Un graphe possibiliste quan-
titatif sur un ensemble de variables V , noté par N = (piN,GN), consiste en :
– une composante graphique, notée parGN, qui est un graphe acyclique orienté DAG (Di-
rected Acyclic Graph). Les nœuds représentent les variables. Les arcs représentent les
liens d’influence entre les variables. L’ensemble des parents d’un nœud A est noté par
UA, et µa dénote une instance des parents de A. On dit que C est le fils de A s’il existe
un arc entre A et C. Par descendant de A, nous désignons l’ensemble des nœuds qui
s’obtiennent par la fermeture transitive de la relation fils.
– une composante numérique, notée par piN, qui quantifie les différents liens entre les
variables. Dans chaque nœud racine A (UA = ∅), l’incertitude est représentée par un
degré de possibilité a priori piN(a) de chaque instance a ∈ DA tel quemaxa piN(a) = 1.
Pour le reste des nœuds (UA 6= ∅) l’incertitude est représentée par un degré de possi-
bilité conditionnelle piN(a | µa) associé à chaque instance a ∈ DA et µa ∈ DUA . Ces
distributions conditionnelles satisfont la condition de normalisation suivante :
maxa piN(a | µa) = 1, pour chaque µa.
Dans la suite, les distributions de possibilités piN, définies au niveau des nœuds, seront ap-
pelées distributions de possibilités locales.
A partir de l’ensemble des degrés de possibilités locales conditionnelles et a priori, nous défi-
Fusion de réseaux possibilistes
nissons une distribution de possibilité jointe globale unique, comme celle proposée en théorie
des probabilités, (pour plus de détails voir Fonck (1992)).
Définition 1 Soit N = (piN,GN) un réseau possibiliste. La distribution jointe, associée à N,
notée piJN , est exprimée à l’aide de la règle de chaînage quantitative suivante :
piJN(A1,..,AN ) =
∏
i=1..N
Π(Ai | UAi). (1)
Exemple 1 Soit N = (piN,GN) un réseau quantitatif possibiliste. Le DAG (GN) associé à
N est représenté par la Figure 1. Les distributions de possibilités a priori et conditionnelles
associées à N sont données par la Table 1.
µ´¶³A
µ´¶³B
?
FIG. 1 – – Graphe d’un réseau possibiliste: GN.
A piN(A) A B piN(B | A) piJN(A,B)
a1 1 a1 b1 1 1
a2 0.4 a1 b2 0.1 0.1
a2 b1 0.6 0.24
a2 b2 1 0.4
TAB. 1 – – Distributions de possibilités a priori, conditionnelles piN et jointe piJN .
La distribution jointe, obtenue en utilisant la règle de chaînage quantitative (1) associée à
N, est donnée par la Table 1. Par exemple, en utilisant l’équation (1), nous avons :
piJN(a2b2) = piN(b2 | a2) ∗ piN(a2) = 1 ∗ 0.4 = 0.4.
3 La fusion possibiliste
3.1 Définition de la fusion conjonctive basée sur le produit
Un des objectifs de la fusion d’informations incertaines est d’exploiter la complémentarité
entre les sources d’informations afin d’avoir un point de vue global plus complet et plus précis
sur un problème donné. Étant donné un ensemble de distributions de possibilité pii, le mode de
combinaison de base, dans le cadre de la théorie des possibilités, est la conjonction idempotente
(i.e., le minimum) des pii, défini par :
∀ω, pi⊕(ω) = mini=1,npii(ω).
S. Benferhat et al.
Pour plus de détails sur la fusion sémantique des distributions des possibilités voir Dubois et
Prade (1994). La combinaison conjonctive idempotente est significative si toutes les sources
jouent un rôle symétrique et ont le même niveau de fiabilité. Le mode de combinaison basé
sur le minimum n’a pas d’effet de renforcement. En effet, si un expert 1 affecte un degré de
possibilité pi1(ω) < 1 à une situation ω, et un expert 2 affecte un degré de possibilité pi2(ω) ≤ 1
à cette même situation alors pi⊕(ω) = pi1(ω) si pi1(ω) < pi2(ω). C’est à dire la valeur de pi⊕(ω)
ne tient pas compte de la valeur de pi2(ω). Si les experts considèrent ω possible à un degré α,
et si leurs opinions sont indépendantes, il est peut être raisonnable de considérer le degré de
possibilité de ω inférieur à α. L’effet de renforcement peut être obtenu en utilisant un autre
mode de combinaison conjonctif comme celui basé sur le produit et défini par :
∀ω, pi⊕(ω) =
∏
i=1,n
pii(ω). (2)
Dans la suite de cet article, c’est ce mode de combinaison qui sera considéré, et par ⊕ nous
désignons l’opérateur produit ∗.
3.2 Objectifs de ce travail
Pour plus de clarté et de simplicité, nous nous limitons au cas de fusion de deux réseaux
possibilistes. Comme l’opérateur produit est symétrique et associatif, les méthodes de fusion
présentées dans cet article s’étendent facilement au cas de fusion de n réseaux possibilistes.
Soient N1 et N2 deux réseaux possibilistes. Notre objectif, illustré par la Figure 2, consiste à
construire directement à partir de N1 et de N2 un nouveau réseau possibiliste noté par N⊕. Le
nouveau réseau possibiliste représentera le résultat de la fusion, par l’opérateur produit, des
réseaux possibilistes N1 et N2 voir Figure 2. La distribution de possibilité piN⊕ associée à N⊕
doit vérifier l’équation suivante :
∀ω, piN⊕(ω) = piN1(ω) ∗ piN2(ω).
¡
¡
@
@
N1 -
N2 -
Définition 1
Définition 1 piN1
piN2
@
@⊕
¡
¡
- pi⊕
Equation 2
=
- N⊕ piN⊕-Définition 1
FIG. 2 – – Correspondance entre la fusion de réseaux possibilistes et la fusion de distributions
possibilistes.
Fusion de réseaux possibilistes
4 Fusion de réseaux possibilistes de structures identiques
Nous présentons la procédure de fusion de réseaux possibilistes ayant la même structure
graphique. Les deux réseaux possibilistes à fusionner, notés par N1 et N2, différent seulement
par les distributions de possibilités conditionnelles affectées aux variables. La définition et la
proposition suivantes montrent que le résultat de la fusion de réseaux possibilistes de structures
identiques, est immédiat.
Définition 2 Soient N1 = (piN1,GN1) et N2 = (piN2,GN2) deux réseaux possibilistes tel que
GN1 = GN2. La fusion de N1 et N2 est un réseau possibiliste, noté N⊕ = (piN⊕,GN⊕), où :
– GN⊕ = GN1 = GN2 et
– Les distributions de possibilités conditionnelles locales piN⊕ sont définies par :
∀A, piN⊕(A|UA)=piN1(A|UA) ∗ piN2(A|UA).
C’est à dire que le résultat de la fusion de N1 et N2 est un réseau possibiliste dont le
DAG est celui de N1 et N2, et dont les distributions de possibilités locales sont le produit des
distributions locales de N1 et N2.
Proposition 1 Soient N1 et N2 deux réseaux possibilistes dont les DAGs associés sont iden-
tiques. SoitN⊕ le résultat de la fusion deN1 etN2, calculé en utilisant la définition précédente.
Alors, nous avons : ∀ω ∈ Ω,piJN⊕(ω) = piJN1(ω) ∗ piJN2(ω),
où piJN⊕, piJN1, piJN2 sont respectivement les distributions de possibilités associées à N⊕, N1 et
N2 en utilisant la Définition 1.
Preuve. En utilisant la définition 1 et la définition 2, la distribution jointe associée au réseau
N⊕ s’écrit de la manière suivante :
piJN⊕(A1, . . . ,An)=
∏
i=1,n piN⊕(Ai | UAi)=
∏
i=1,n(piN1(Ai | UAi) ∗ piN2(Ai | UAi))
Étant donné que l’opérateur produit est commutatif et associatif, nous obtenons :
piJN⊕(A1, . . . ,An)=(
∏
i=1,nΠN1(Ai | UAi)) ∗ (
∏
i=1,nΠN2(Ai | UAi))
C’est à dire: ∀ω ∈ Ω,piJN⊕(ω) = piJN1(ω) ∗ piJN2(ω). ¤
Exemple 2 SoientN1 etN2 deux réseaux possibilistes. SoitGN =GN1 =GN2 le DAG associé
à N1 et N2 et représenté par la Figure 3. Les distributions de possibilités associées à N1 et N2
sont données respectivement par la Table 2.
µ´¶³A
µ´¶³B
?
FIG. 3 – – Exemple de réseaux identiques.
Le réseau possibiliste N⊕, résultat de la fusion de N1 et N2, est tel que son graphe est
le DAG de la Figure 3 et ses distributions de possibilités conditionnelles locales sont celles
données par la Table 3. Nous pouvons facilement vérifier que :
∀ω ∈ Ω, piJN⊕(ω) = piJN1(ω) ∗ piJN2(ω).
S. Benferhat et al.
A piN1(A) piN2(A) A B piN1(B | A) piN2(B | A)
a1 1 1 a1 b1 1 1
a2 0.2 0.3 a1 b2 0.3 0
a2 b1 0.1 0.7
a2 b2 1 1
TAB. 2 – – Distributions de possibilités initiales associées à N1 et N2.
A piN⊕(A) A B piN⊕(B | A)
a1 1 a1 b1 1
a2 0.06 a1 b2 0
a2 b1 0.07
a2 b2 1
TAB. 3 – – Distributions de possibilités associées à N⊕.
5 Fusion de réseaux U-acycliques
Cette section considère le cas où les réseaux possibilistes ont des structures différentes.
Cependant nous supposons que l’union des graphes ne contient pas de cycles.
L’union de deux DAGs (G1,G2) est un graphe où :
– l’ensemble de ses variables est l’union des ensembles des variables appartenant à G1 et
à G2,
– pour chaque variable A, ses parents sont ceux de G1 et G2.
Si l’union de G1 et G2 ne contient pas de cycles, on dit que G1 et G2 sont des réseaux
U-acycliques. Dans ce cas, nous montrons que la fusion peut être facilement réalisable. Nous
avons d’abord besoin de présenter des résultats intermédiaires sur l’ajout des variables et des
arcs dans la sous-section suivante.
5.1 Ajout de variables et d’arcs
La proposition suivante montre comment rajouter de nouvelles variables dans un réseau
possibiliste, sans modifier la distribution jointe du réseau :
Proposition 2 Soit N = (piN,GN) un réseau possibiliste défini sur un ensemble de variables
V . Soit A une nouvelle variable qui n’appartient pas à V. Soit N1 = (piN1,GN1) un nouveau
réseau possibiliste tel que :
– GN1 est égale à GN plus le nœud A,
– piN1 est identique à piN pour toutes les variables dans V , et égale à la distribution de
possibilité représentant l’ignorance totale pour le nœud A (c’est à dire, ∀a ∈ DA,
piN1(a) = 1).
Alors nous avons :
∀ω ∈ ×Ai∈VDAi , piJN(ω) = maxa∈DApiJN1(aω). (3)
Fusion de réseaux possibilistes
Preuve. Calculons la distribution de possibilité marginale associée à N1. Soit ω ∈ ×Ai∈V
DAi . Nous avons:maxapiJN1(aω) =maxa(piN1(a).piJN1(ω))=piJN1(ω), puisque piN1(a)=1, pour
tout a ∈ DA. Donc maxa∈DApiJN1(aω)=piJN(ω). ¤
La proposition précédente est importante dans la procédure de fusion puisqu’elle permet
si nécessaire d’augmenter, de façon équivalente, tous les réseaux possibilistes à fusionner, afin
qu’ils utilisent le même ensemble de variables.
La proposition suivante montre comment rajouter des liens à un réseau possibiliste sans
modifier sa distribution de possibilité.
Proposition 3 Soit N = (piN,GN) un réseau possibiliste. Soit A une variable, et soit UA
l’ensemble des parents de A dans GN. Soit B /∈ UA et B n’est pas un descendant de A 1. Soit
N1 = (piN1,GN1) un nouveau réseau possibiliste obtenu à partir de N en rajoutant un lien de
B vers A. La nouvelle distribution de possibilité conditionnelle associée à N1 est :
- au niveau du nœud A :
∀a ∈ DA, ∀b ∈ DB , ∀µa ∈ DUA , piN1(a | µab)=piN(a | µa).
- pour les autres nœuds :
∀C, C 6= A, ∀c ∈ DC , ∀µc ∈ DUC , piN1(c | µc)=piN(c | µc).
Alors, nous avons :
∀ω, piJN(ω) = piJN1(ω).
Preuve. Soit V = {A1, . . . ,An−1,B}, l’ensemble des variables dans le réseau possibiliste N.
Supposons que nous ajoutons un arc de B vers le nœud Ai tel que B /∈ UAi . Par construction,
les distributions de possibilités conditionnelles locales associées au nouveau réseau sont :
Pour tout X ∈ V tel que X 6= Ai, piN1(X | UX) = piN(X | UX),
Pour X = Ai, piN1(Ai | UAi ,B) = piN(Ai | UAi).
Par conséquent,
piJN1(A1, . . . ,An−1,B) = piN1(Ai | UAi ,B) ∗ (
∏n−2
j=1,j 6=i piN1(Aj | UAj )) ∗ piN1(B | UB)
= piN(Ai | UAi) ∗ (
∏n−2
j=1,j 6=i piN(Aj | UAj )) ∗ piN(B | UB)
= piJN(A1, . . . ,An−1,B).
Ainsi nous obtenons : ∀ω, piJN1(ω) = piJN(ω). ¤ .
5.2 Procédure de calcul de la fusion
Grâce aux résultats de la section précédente, et en se basant sur la Proposition 1, la fusion
de deux réseaux U-acycliques N1 et N2 est immédiate. SoitGN⊕ l’union deGN1 etGN2. Alors
la fusion de N1 et N2 est obtenue en suivant les deux étapes suivantes :
Étape 1 En utilisant les propositions 2 et 3, étendre les graphes associés à N1 et N2 jusqu’à
ce queGN1 = GN2 = GN⊕. Par extension, nous entendons, l’ajout de variables et d’arcs.
Étape 2 Appliquer la Proposition 1 sur les réseaux possibilistes obtenus dans l’étape 1
(puisque les deux réseaux ont maintenant la même structure).
1. Il est important d’exiger que B ne soit pas un descendant de A, sinon l’ajout de B vers A engendrerait un cycle.
S. Benferhat et al.
Exemple 3 Considérons les deux réseaux possibilistes dont les DAGs sont donnés par la
Figure 4. Ces deux DAGs ont des structures différentes. Les distributions de possibilités condi-
tionnelles, qui leur sont associées, sont données par les Tables 4 et 5. Le DAG GN⊕ est donné
par la Figure 5, qui est simplement l’union des deux graphes de la Figure 4.
µ´¶³ µ´¶³B D
? ¢
¢
¢®µ´¶³A
?
A
A
AU
µ´¶³C µ´
¶³
A µ´¶³B
FIG. 4 – – G1 G2 : Exemple de réseaux U-acycliques.
B piN1(B) A B piN1(A | B) A C piN1(C | A)
b1 1 a1 b1 0.3 a1 c1 1
b2 0.2 a1 b2 1 a1 c2 0.5
a2 b1 1 a2 c1 0
a2 b2 0 a2 c2 1
TAB. 4 – – Distributions de possibilités conditionnelles initiales piN1.
D piN2(D) A D piN2(A | D) B D piN2(B | D)
d1 1 a1 d1 1 b1 d1 1
d2 0 a1 d2 1 b1 d2 0.8
a2 d1 1 b2 d1 0.7
a2 d2 0 b2 d2 1
TAB. 5 – – Distributions de possibilités conditionnelles initiales piN2.
µ´¶³A
?
µ´¶³C
µ´¶³ µ´¶³B Dff
J
JJ^
¢
¢¢®
FIG. 5 – – DAG GN⊕.
Fusion de réseaux possibilistes
L’extension de GN1 et GN2 en un graphe commun GN⊕ nécessite l’ajout de variables et de
liens dans chaque graphe. Pour cela nous appliquons les étapes suivantes :
– Pour GN1 nous rajoutons :
– une nouvelle variable D dont la distribution de possibilité est :
∀d ∈ DD, piN1(d) = 1,
– un lien de la variable D vers la variable B dans le graphe. La nouvelle distribution
de possibilité conditionnelle du nœud B devient :
∀d ∈ DD, ∀b ∈ DB , piN1(b|d) = piN1(b).
– un lien de la variable D vers la variable A dans le graphe. La nouvelle distribution
de possibilité conditionnelle du nœud A devient :
∀d ∈ DD, ∀b ∈ DB , ∀a ∈ DA, piN1(a|b,d) = piN1(a|b).
Après ajout de liens, les distributions de possibilités au niveau des variables A et B dans
le réseau N1 ne sont pas modifiées conformément à la Proposition 3.
– Pour GN2 nous procédons de la même manière, c’est à dire nous rajoutons :
– une nouvelle variable C, et un lien de la variable A vers la variable C, dont la
distribution de possibilité conditionnelle est :
∀c ∈ DC , ∀a ∈ DA, piN2(c | a) = 1.
– un lien de la variable B vers la variable A, et la nouvelle distribution de possibilité
conditionnelle du nœud A devient :
∀d ∈ DD, ∀b ∈ DB , ∀a ∈ DA, piN2(a|b,d) = piN2(a|d).
Les distributions de possibilités conditionnelles, associées au DAG représentant le résultat
du graphe fusion (donné par la Figure 5), sont représentées dans la Table 6. Nous pouvons
D piN⊕(D) A C piN⊕(C | A) B D piN⊕(B | D)
d1 1 a1 c1 1 b1 d1 1
d2 0 a1 c2 0.5 b1 d2 0.8
a2 c1 0 b2 d1 0.14
a2 c2 1 b2 d2 0.2
A B D piN⊕(A | B ∧D) A B D piN⊕(A | B ∧D)
a1 b1 d1 0.3 a2 b1 d1 1
a1 b1 d2 0.3 a2 b1 d2 0
a1 b2 d1 1 a2 b2 d1 0
a1 b2 d2 1 a2 b2 d2 0
TAB. 6 – – Distributions conditionnelles associées à piN⊕.
facilement vérifier que la distribution de possibilité jointe piJN⊕, calculée en utilisant la règle
de chaînage (Définition 1), est égale au produit de piJN1 et piJN2.
6 Traitement des réseaux possibilistes sous-normalisés
La combinaison d’informations multi-source engendre parfois des conflits. Même si les
distributions de possibilités conditionnelles et jointes initiales sont normalisées, il est rare que
S. Benferhat et al.
les distributions locales et jointes associées au réseau résultat (de la fusion) soient également
normalisées. Dans cette section, nous présentons une procédure permettant de restaurer la nor-
malisation de la distribution jointe d’un réseau causal possibiliste quantitatif.
6.1 De la sous-normalisation locale à la sous-normalisation globale
Dans les réseaux causaux probabilistes Jensen (1996), Pearl (1988), lorsque toutes les dis-
tributions de probabilités locales (conditionnelles et a priori) sont normalisées, alors la distri-
bution globale jointe est normalisée. Cependant si une des distributions de probabilités locales
est sous-normalisée alors la distribution de probabilité globale est également sous-normalisée.
Cette sous-section montre que dans le cadre de la théorie des possibilités, la situation n’est pas
la même. En particulier, il est possible que des distributions locales soient sous-normalisées
mais la distribution jointe soit normalisée.
Rappelons que h(pi) représente le degré de normalisation affecté à pi et est défini par :
h(pi) = maxω∈Ωpi(ω).
Si h(pi) < 1 alors pi est dite sous-normalisée, en d’autres termes pi code un ensemble de
croyances ou de préférences conflictuelles. La normalisation de pi est réalisée en se basant
sur l’équation suivante (voir Dubois et Prade (1994)) :
∀ω, pinormalisé(ω) = pi(ω)
h(pi)
.
La proposition suivante montre que si les distributions locales a priori et conditionnelles sont
toutes normalisées alors la distribution globale jointe est également normalisée.
Proposition 4 Soit N un réseau possibiliste, où les distributions locales piN associées à N
sont normalisées, c’est à dire ∀A ∈ V , ∀µa instance des parents de A,maxapiN(a | µa) = 1.
Alors piJN est normalisée, c’est à dire h(piJN) = 1.
Preuve. Soit V = {A1, . . . ,An} l’ensemble des variables, où les parents de Ai sont dans
{Ai+1, . . . ,An}.Par définition :
h(piJN)=maxa1,...,anpiJN(a1, . . . ,an) =maxa1,...,an((
∏n−1
i=1 piN(ai | µai)) ∗ pi(an | µan)) =
maxa1,...,an−1(
∏n−1
i=1 piN(ai | µai)) ∗maxanpi(an | µan).
Par hypothèse, toutes les distributions locales sont normalisées, donc pour chaque instance µ,
maxan(pi(an | µan)) = 1. Nous avons : h(piJN)=maxa1,...,an−1(piJN(a1, . . . ,an−1)).
Le processus est répété jusqu’à a1, ainsi nous obtenons à la fin : h(piJN) = 1. ¤
Exemple 4 Soit le réseau possibiliste donné par la Figure 6 et la Table 7. Nous pouvons
vérifier que les distributions de possibilités locales initiales sont normalisées. Par conséquent
la distribution jointe, représentée par la Table 7, est aussi normalisée.
Par exemple : piJN(a1b2) = piN(a1) ∗ piN(b2 | a1) = 1.
Maintenant analysons le cas où certaines distributions locales ne sont pas normalisées. En
théorie des probabilités, si une distribution de probabilité locale est sous-normalisée alors la
distribution de probabilité jointe sera également sous-normalisée. En théorie des possibilités la
Fusion de réseaux possibilistes
µ´¶³A
µ´¶³B
?
FIG. 6 – – Réseau causal possibiliste.
A piN(A) A B piN(B | A) piJN(A,B)
a1 1 a1 b1 0.7 0.7
a2 0.3 a1 b2 1 1
a2 b1 1 0.3
a2 b2 0.2 0.06
TAB. 7 – – Distributions de possibilités initiales piN et jointe piJN normalisées.
situation n’est pas identique. Il peut y avoir des situations où des distributions locales sont sous-
normalisées et la distribution jointe est sous-normalisée. Comme il peut y avoir des situations
où les distributions locales sont sous-normalisées mais la jointe globale est normalisée. Ces
deux situations sont données par les deux exemples suivants.
Exemple 5 Cet exemple illustre une situation où les distributions de possibilités locales ne
sont pas toutes normalisées, mais la distribution jointe est normalisée. Considérons le réseau
possibiliste N donné par la Figure 7. Les distributions locales associées à ce réseau, données
µ´¶³A
¢
¢
¢®
A
A
AUµ´¶³B µ´¶³C
FIG. 7 – – Réseau causal possibiliste N.
dans la Table 8, ne sont pas toutes normalisées. En effet, au niveau de la variable B, il existe
une instance de la variable A (parent de B) tel que :maxbpiN(b | a1) 6= 1.
La distribution jointe calculée, à partir de la Table 8, est normalisée, par exemple:
piJN(a2b2c2) = piN(a2) ∗ piN(b2 | a2) ∗ piN(c2 | a2) = 1.
Exemple 6 Cet exemple illustre une situation où les distributions de possibilités locales ne
sont pas toutes normalisées et la distribution jointe est sous-normalisée. Considérons le réseau
N dont le DAG est donné par la Figure 7. Les distributions de possibilités locales (données
dans la Table 9) ne sont pas toutes normalisées. Nous avons :maxc(piN(c | a1)) = 0.2.
S. Benferhat et al.
A piN(A) A B piN(B | A) A C piN(C | A)
a1 0.1 a1 b1 0.5 a1 c1 1
a2 1 a1 b2 0.8 a1 c2 0.3
a2 b1 0 a2 c1 0.7
a2 b2 1 a2 c2 1
TAB. 8 – – Distributions de possibilités locales partiellement sous-normalisées.
A piN(A) A B piN(B | A) A C piN(C | A)
a1 1 a1 b1 1 a1 c1 0.1
a2 0.1 a1 b2 0.8 a1 c2 0.2
a2 b1 0 a2 c1 1
a2 b2 1 a2 c2 0.4
TAB. 9 – – Distributions de possibilités locales partiellement sous-normalisées.
La Table 10 donne la distribution jointe associée à N qui est sous-normalisée, puisque
h(piJN) = 0.2.
A B C piJN(A,B,C) A B C piJN(A,B,C)
a1 b1 c1 0.1 a2 b1 c1 0
a1 b1 c2 0.2 a2 b1 c2 0
a1 b2 c1 0.08 a2 b2 c1 0.1
a1 b2 c2 0.16 a2 b2 c2 0.04
TAB. 10 – – Distribution de possibilité jointe sous-normalisée.
La proposition suivante donne une situation, où des distributions locales sous-normalisées
impliqueraient toujours une distribution globale sous-normalisée.
Proposition 5 Soit N un réseau possibiliste. Supposons qu’il existe une variable A, tel que
∀µa ∈ UA, ∀a ∈ DA, maxa∈DA(piN(a | µa)) 6= 1. Alors la distribution de possibilité jointe
est sous-normalisée.
Preuve. Supposons que pour Ak, ∀µak ,maxak∈DAkpiN(ak | µak) 6= 1. Par définition :
h(piJN) =maxa1,...,anpiJN(a1, . . . ,ak, . . . ,an) =
maxa1,...,ak,...,an((
∏
i 6=k piN(ai | µai)) ∗ piN(ak | µak))=
maxa1,...,ak−1,ak+1,...,an(
∏
i 6=k piN(ai | µai)) ∗maxak(piN(ak | µak))
Commemaxak∈DAk (piN(ak | µak)) 6= 1, ∀µak .
Donc h(piJN) 6= 1. ¤
Un cas particulier emerge de la proposition précédente. C’est le cas où la distribution de
possibilité locale au niveau de la racine est sous-normalisée.
Corollaire 1 Soit N un réseau possibiliste. Soit A une variable racine tel que :
maxa∈DApiN(a) 6= 1. Alors la distribution jointe piJN est sous-normalisée.
Fusion de réseaux possibilistes
6.2 Procédure de restauration de la normalisation
Après cette caractérisation des relations entre la sous-normalisation au niveau des distribu-
tions locales et la sous-normalisation au niveau de la distribution jointe, cette section a pour
objectif de proposer une méthode de restauration de la cohérence. Plus précisément, soit N
un réseau possibiliste dont les distributions locales sont sous-normalisées. Notre but est de
construire un réseau possibiliste N1 tel que :
∀ω, piJN1(ω) =
piJN(ω)
h(piJN)
,
c’est à dire piJN1 est le résultat de normalisation de piJN .
Le principe de la procédure de normalisation deN que nous proposons consiste à construire
un réseau N1 telles que toutes les distributions locales au niveau de N1 soient normalisées.
N1 est obtenu en normalisant les distributions locales au niveau de chaque variable. Nous
commençons d’abord par le cas d’un réseau possibiliste où la distribution de possibilité au
niveau d’une variable racine est sous normalisée.
Proposition 6 Soit N un réseau possibiliste. Soit A une variable racine, telle que :
maxa∈DA(piN(a)) = α où 0 < α < 1. Définissons N1 tel que :
– GN1 = GN,
– ∀X,X 6= A, piN1(X | UX) = piN(X | UX),
– ∀a ∈ DA, piN1(a) = piN(a)/α.
Alors ∀ ω, piJN1(ω) = piJN(ω)/α.
Preuve. Supposons que A1 est une variable racine et maxa∈DA1piN(a) = α. En utilisant la
définition 1, la distribution jointe associée au réseau N1 est :
piJN1(a1, . . . ,an)=
∏
i=1,n(piN1(ai | µai))=piN1(a1) ·
∏
i=2,n(piN1(ai | µai))=
piN(a1)
α · (
∏
i=2,n piN(ai | µai))= 1α · (
∏
i=1,n piN(ai | µai))= 1αpiJN(a1, . . . ,an). ¤
La méthode explicitée dans cette proposition permet de normaliser les variables racines.
L’exemple suivant illustre cette proposition.
Exemple 7 Considérons le réseau causal N dont le grapheGN est représenté par la Figure 7
et dont les distributions de possibilités sont données par la Table 11.
A piN(A) A B piN(B | A) A C piN(C | A)
a1 0.1 a1 b1 1 a1 c1 1
a2 0.4 a1 b2 0.8 a1 c2 0
a2 b1 0 a2 c1 0.7
a2 b2 1 a2 c2 1
TAB. 11 – – Distributions de possibilités initiales associées à N.
Nous constatons que maxa∈DA(piN(a)) = 0.4 < 1. Nous définissons alors le nouveau
réseau N1 dont le grapheGN1 est identique à celui donné par la Figure 7. Les distributions de
S. Benferhat et al.
possibilités correspondantes sont définies par :
piN1(a1) = piN(a1)/0.4 = 0.1/0.4 = 0.25 et piN1(a2) = piN(a2)/0.4 = 0.4/0.4 = 1.
piN1(b | a) = piN(b | a) ∀b ∈ DB et ∀a ∈ DA.
piN1(c | a) = piN(c | a) ∀c ∈ DC et ∀a ∈ DA.
Alors, nous pouvons vérifier que :∀ ω, piJN1(ω) = piJN(ω)/0.4.
Pour une variable A, qui n’est pas racine, la normalisation de sa distribution locale se fait en
modifiant les distributions de possibilités associées aux parents de A. Bien sûr, comme nous
modifions la distribution des possibilités des parents de A, le résultat de la normalisation de
la variable A peut produire, comme effet de bord, une distribution sous-normalisée au niveau
des parents de A. De ce fait le processus de normalisation se fait de façon itérative partant des
feuilles jusqu’aux variables racines.
Considérons dans un premier temps, le cas d’une variable A, dont la distribution locale est
sous-normalisée, et qui admet un seul parent.
Proposition 7 Soit N un réseau possibiliste. Soit A une variable qui admet un seul parent B.
Supposons qu’il existe une instance ’b’ de B tel que maxa∈DApiN(a | b)= α où 0 < α < 1.
Définissons N1 tel que le graphe associé à N1 est identique à celui de N et les distributions
locales associées à N sont définies comme suit :
1. ∀C 6= A, ∀C 6= B, piN1(C | UC) = piN(C | UC).
2.
∀aj ,∀bi, piN1(aj | bi) =
{
piN(aj |bi)
α si bi = b
piN(aj | bi) sinon
3.
∀bi,∀µbi , piN1(bi | µbi) =
{
piN(bi | µbi) ∗ α si bi = b
piN(bi | µbi) sinon
Alors ∀ω, piJN1(ω) = piJN(ω).
Preuve. Considérons l’ensemble des variables A1, . . . ,An−2,A,B associé au réseau causal
possibiliste N. Soient UA = {B} etmaxa(pi(a | b)) = α avec 0 < α < 1, b instance de B.
En utilisant la Définition 1, la distribution jointe associée à N est donnée par :
∀a1 ∈ DA1 ,. . . ,∀an−2 ∈ DAn−2 ,∀aj ∈ DA, ∀bi ∈ DB ,
piJN1(a1, . . . ,an−2,aj ,bi) = piN1(aj | bi) ∗ piN1(bi | µbi) ∗
∏n−2
k=1 piN1(ak | µak).
Deux cas se présentent :
Cas 1 : bi = b
piJN1(a1, . . . ,an−2,aj ,bi) =
piN(aj | bi)
α
∗ (piN(bi | µbi) ∗ α) ∗
n−2∏
k=1
piN(ak | µak)
= piN(aj | bi) ∗ piN(bi | µbi) ∗
n−2∏
k=1
piN(ak | µak)
Fusion de réseaux possibilistes
= piJN(a1, . . . ,an−2,aj ,bi).
Cas 2 : bi 6= b
piJN1(a1, . . . ,an−2,aj ,bi) = piN1(aj | bi) ∗ piN1(bi | µbi) ∗
n−2∏
k=1
piN1(ak | µak)
= piN(aj | bi) ∗ piN(bi | µbi) ∗
n−2∏
k=1
piN(ak | µak)
= piJN(a1, . . . ,an−2,aj ,bi).
Par conséquent, nous avons bien :
∀ω ∈ Ω, piJN1(ω) = piJN(ω).¤
Expliquons les différentes conditions, citées dans la Proposition 7, qui permettent de nor-
maliser la distribution de possibilité locale au niveau du nœud A, qui admet un seul parent
B. La première condition signifie que les distributions de possibilités associées aux variables,
du réseau N1, autres que A et B, restent inchangées. La deuxième condition explicite que la
normalisation s’applique seulement sur la variable A (variable concernée par le problème de
sous-normalisation). Finalement la troisième condition opère sur la variable B (parent de A)
l’opération inverse de la normalisation, qui permet d’assurer une équivalence entre les distri-
butions jointes.
Exemple 8 Illustrons la Proposition 7 par un exemple de sous-normalisation d’une variable
B, appartenant au graphe de la Figure 7. La variable B possède un seul parent A. La table 12
donne des distributions locales initiales. On remarque que : maxbpiN(b | a2) = 0.5.
Construisons le réseau N1, correspondant au résultat de la normalisation de la variable B.
A piN(A) A B piN(B | A) A C piN(C | A)
a1 1 a1 b1 0.3 a1 c1 1
a2 0.3 a1 b2 1 a1 c2 0.3
a2 b1 0.5 a2 c1 0.7
a2 b2 0.1 a2 c2 1
TAB. 12 – – Distributions de possibilités initiales.
Le nouveau réseau N1, ainsi obtenu, est tel que son graphe est identique à celui de la Figure
7, et ses distributions de possibilités sont définies comme suit :
- Pour le nœud C :
∀i, piN1(ci | a1) = piN(ci | a1) et piN1(ci | a2) = piN(ci | a2).
- Pour le nœud A :
piN1(a1) = piN(a1) = 1 et piN1(a2) = piN(a2) ∗ 0.5 = 0.3 ∗ 0.5 = 0.15.
- Pour le nœud B :
piN1(b1 | a2) = piN(b1 | a2) / 0.5 = 1 et piN1(b2 | a2) = piN(b2 | a2) / 0.5 = 0.2.
S. Benferhat et al.
Les distributions jointes associées aux deux réseaux sont identiques. Par exemple :
piJN(a2b2c1) = piN(b2 | a2) ∗ piN(c1 | a2) ∗ piN(a2)= 0.1 ∗ 0.7 ∗ 0.3 = 0.021.
piJN1(a2b2c1) = piN1(b2 | a2) ∗ piN1(c1 | a2) ∗ piN1(a2)= 0.2 ∗ 0.7 ∗ 0.15 = 0.021.
Généralisons le résultat de la proposition précédente. Dans la suite, nous définissons une
relation d’ordre entre les variables,A ≤ B si B n’est pas descendant de A. Comme les graphes
associés aux réseaux possibilistes sont des DAGs alors si A et B sont deux variables, nous
avons toujours soit A ≤ B soit B ≤ A (nous pouvons bien sûr avoir les deux cas).
Définition 3 SoitN = (piN,GN) un réseau possibiliste. Soit A une variable dont la distribution
de possibilité locale est sous-normalisée. Soit µαa une instance de UA tel que :
maxa∈DA(piN(a | µαa )) = α où 0 < α < 1. Soit B ∈ UA tel que ∀ C 6= B ∈ UA, B ≤ C.
Le réseau possibiliste N1 = (piN1,GN1) résultat de la normalisation de N est tel que :
1. GN1= GN ∪ {C → B : C ∈ UA,C 6= B}.
2. Les distributions de possibilités locales sont définies par :
(a) ∀X 6= A, ∀X 6= B, piN1(X | UX) = piN(X | UX).
(b) ∀a ∈ DA, ∀µ′a ∈ DUA ,
piN1(a | µ′a) =
{
piN(a|µαa )
α si µ
′
a = µαa
piN(a | µa) sinon
(c) ∀b ∈ DB ,
∀µ′b, piN1(b | µ′b) =
{
piN(b | µb) ∗ α si µ′b ∧ b est consistente avec µαa
piN(b | µb) sinon.
Dans cette définition, nous rappelons d’abord qu’elle concerne la normalisation de la dis-
tribution de possibilité locale associée à une variable qui admet au moins deux parents. Dans
cette définition la variable B existe toujours (sinon le graphe contiendrait un cycle).
La première condition signifie que le graphe GN1 contient tous les liens de GN plus de nou-
veaux liens de chaque variable C (distincte de B et qui est parent de A) vers la variable B.
Concernant les distributions de possibilités du réseau N1, nous avons : La condition (a) in-
dique que les distributions de possibilités, associées aux variables qui sont différentes de A
et B, gardent les mêmes valeurs que celles données par le réseau initial. La condition (b)
normalise la distribution de possibilité associée à la variable A. La condition (c) répercute la
normalisation sur la variable B afin de préserver la distribution jointe. µ′b (resp. µ′a) dénote
une instance des parents de B (resp. des parents de A) dans le nouveau réseau N1, alors que µb
(resp. µa) dénote une instance des parents de B (resp. des parents de A) dans le réseau initialN.
Proposition 8 Soit N = (piN,GN) un réseau sous-normalisé, telle qu’il existe une variable
ayant au moins deux parents et dont la distribution de possibilité locale est sous-normalisée.
Soit N1 = (piN1,GN1) le réseau possibiliste normalisé obtenu en utilisant la définition précé-
dente. Alors :
∀ ω, piJN1(ω) = piJN(ω).
Fusion de réseaux possibilistes
Preuve. Soit N et N1 deux réseaux possibilistes définis selon la Définition 3. Supposons que
pour la variable A, il existe µαa ∈ UA tel que :maxapiN(a | µαa )=α 6= 1.
Soit ω=(a1, . . . ,an−2,a,b) où a une instance de A et b une instance de B. La distribution jointe,
associée au réseau N1, est donnée par :
piJN1(ω) = pi
J
N1(a1, . . . ,an−2,b,a) = (
∏n−2
i=1 piN1(ai | µai)) ∗ piN1(b | µ′b) ∗ piN1(a | µ′a).
Si µ′a = µαa alors
piJN1(ω) = (
∏n−2
i=1 piN(ai | µai)) ∗ (piN(b | µb) ∗ α) ∗ (piN(a | µαa )/α).
Sinon
piJN1(ω) = (
∏n−2
i=1 piN(ai | µai)) ∗ (piN(b | µb)) ∗ (piN(a | µa)).
D’où
∀ω, piJN1(ω) = piJN(ω). ¤
En se basant sur les propositions précédentes, la procédure de normalisation peut être défi-
nie comme suit :
Procédure Normalisation
Données : Un réseau possibiliste N sous-normalisé
Résultat : Un réseau possibiliste N1 normalisé
début
Ordonner l’ensemble des variables V = {A1, . . . ,An} tels que les parents de Ai
(éventuellement vide) soient inclus dans V’= {Ai+1, . . . ,An};
pour tout i = 1, . . . ,n tel que ∃µai ∈ UAi et 0 < maxaipiN(ai | µai) < 1 faire
si Ai est racine alors
appliquer la Proposition 6;
sinon
si Ai possède un seul parent µai ∈ V ′ alors appliquer la Proposition 7;
sinon appliquer la Proposition 8;
fin
Cet algorithme garantit la normalisation du réseau obtenu, puisque les propositions 6,7 et
8 donnent un résultat normalisé. Plus formellement :
Proposition 9 Soit N un réseau possibiliste sous-normalisé. Soit N1 le résultat obtenu par la
procédure de Normalisation donnée ci-dessous. Alors :
∀ω, piN1(ω) = piN(ω)h(piN) .
Preuve. Notons d’abord que normaliser les nœuds qui ne sont pas racines ne modifie pas la
distribution jointe. De ce fait l’application des propositions 7 et 8 sur les nœuds qui ne sont
pas des nœuds racines donne un réseau N2 tel que :
- ∀ω, piJN(ω) = piJN2(ω) et h(piJN) = h(piJN2),
- ∀A une variable non racine de N2, ∀µa instance des parents de A dans N2,
maxa∈DA(piN2(a | µa)) = 1.
S. Benferhat et al.
Soit {A1, . . . ,Ak} l’ensemble des racines dans N2. En utilisant la Définition 1, nous avons :
∀ai ∈ DAi , h(piJN2) =maxa1,...,ak,ak+1,...,anpiJN2(a1, . . . ,ak,ak+1, . . . ,an)
=maxa1,...,ak(
∏k
i=1 piN2(ai)) ∗maxak+1,...,an(
∏n
i=k+1 piN2(ai | µai)).
Comme les variables {Ak+1, . . . ,An} ne sont pas racines alors les distributions locales au ni-
veau de ces variables sont toutes normalisées. Par conséquent, pour toute instance ak+1, . . . ,an
fixée, l’expressionmaxak+1,...,an(
∏n
i=k+1 piN2(ai | µai)) = 1. Ceci implique que :
h(piJN2) =maxa1,...,ak(piN2(a1) ∗ . . . ∗ piN2(ak)) = (maxa1piN2(a1)) ∗ . . . ∗ (maxakpiN2(ak))
= h(piN2(A1)) ∗ . . . ∗ h(piN2(Ak)).
Maintenant, il suffit de construire un nouveau réseau N1 où pour chaque variable Ai racine,
nous remplaçons la distribution locale piN2(Ai) par piN2(Ai)/h(piN2(Ai)) (Proposition 6) :
∀ω, piN1(ω) = piN2(ω)h(piN2(A1))∗...∗h(piN2(Ak)) =
piN2(ω)
h(piJN2)
= piN(ω)
h(piJN )
.¤
7 Conclusions
Dans cet article, nous avons proposé la fusion des réseaux possibilistes quantitatifs. Nous
avons montré que dans le cas des réseaux possibilistes de même structures, la fusion est réa-
lisée d’une manière efficace. Ensuite nous avons étudié la fusion de réseaux dont l’union des
structures ne contient pas de cycles. En particulier, nous avons donné comment rajouter une
variable ou un arc sans modifier la distribution jointe. Un traitement du problème de sous-
normalisation émanant de la fusion des réseaux a été effectué. La procedure de fusion pour les
graphes U-acycliques est réalisée en un temps polynômial en fonction des paramètres (nombre
des degrés de possibilités) des graphes. En outre, la complexité du processus de normalisation
reste polynômial si le graphe a une structure particulière, par exemple celle d’un arbre.
Nos travaux futurs consistent dans un premier temps à étendre les solutions préliminaires pro-
posées dans (Benferhat et Titouna (2006)) pour les traitements des cycles, à prendre en compte
d’autres opérateurs de combinaisons possibilistes et enfin à appliquer les résultats de cet article
à un problème de localisation de robots dans un environnement incertain (Sossai et Chemello
(2002)).
Remerciements
Ce travail entre dans le cadre du projet ANR Blanc MICRAC.
Références
Ben Amor, N., S. Benferhat, D. Dubois, H. Geffner, et H. Prade (2000). Independence in
qualitative uncertainty frameworks. In Proceedings of the 7th International Conference on
Principles of Knowledge Representation and Reasoning (KR2000), 235–246.
Benferhat, S., D. Dubois, L. Garcia, et H. Prade (2002). On the transformation between possi-
bilistic logic bases and possibilistic causal networks. International Journal of Approximate
Reasoning 29, 135–173.
Fusion de réseaux possibilistes
Benferhat, S., D. Dubois, et H. Prade (1997). From semantic to syntactic approaches to infor-
maton combinaition in possibilsitc logic. Aggregation and Fusion of Imperfect information,
physica Verlag, 141–151.
Benferhat, S. et F. Titouna (2006). Agregating quantitative possibilistic networks. In Procee-
dings of the 9th International Florida Artificial Intelligence Research, (Flairs’06), 800–805.
Borgelt, C., J. Gebhardt, et R. Kruse (1998). Possibilistic graphical models. In Proceedings
of International School for the Synthesis of Expert Knowledge (ISSEK’98), Springer, Udine,
Italy, 51–68.
Bouchon-Meunier, B. et C. Marsala (2002). Independence and possibilistic conditioning. An-
nals of Mathematics and Artificial Intelligence 35, 107–124.
De Cooman, G. (1997). Possibility theory - parti: Measure and integrale thoretics groundwork;
partii: Conditional possibility; partiii: Possibilistic independence. International Journal of
General Systems 25, 291–371.
Dubois, D. et H. Prade (1988). Possibility theory: An approach to computerized processing of
uncertainty. Plenium Press, New York.
Dubois, D. et H. Prade (1994). Possibility theory and data fusion in poorly informed environ-
ments. Journal of Control Engineering Practice 2, 811–823.
Fonck, P. (1992). Propagating uncertainty in a directed acyclic graph. In Proceedings of
International Conference on Information Processing of Uncertainty in Knowledge Based
Systems (IPMU’92), 17–20.
Jensen, F. (1996). Introduction to bayesian networks. UCL Press, University college, London.
Konieczny, S. et R. Perez (1998). On the logic of merging. In Proceedings of the 6th Inter-
national Conference on Principles of Knowledge Representation and Reasoning,(KR’98),
488–498.
Lin, J. et A. Mendelzon (1998). Merging databases under constraints. International Journal
of Cooperative Information Systems 7, 55–76.
Pearl, J. (1988). Probabilistic reasoning in intelligent systems: Networks of plausible inference.
Morgan Kaufmann, San Fransisco (California).
Qi, G., W. Liu, D. Glass, et D. Bell (2006). A split-combination approach to merging know-
ledge bases in possibilistic logic. Annals of Mathematics and Artificial Intelligence 48(1-2),
45–84.
Sossai, C. et G. Chemello (2002). Coherent functions in autonomous systems. Journal of
Multiple-valued Logic and Soft Computing 9, 171–194.
Zadeh, L. (1978). Fuzzy sets as a basis for a theory of possibility. Fuzzy sets ans systems 1,
13–28.
Summary
The problem of merging multiple-source uncertain information is a crucial issue in many
applications. This paper proposes an analysis of possibilistic merging operators where uncer-
tain information is encoded by means of product-based (or quantitative) possibilistic networks.
We first show that the product-based merging of possibilistic networks having the same DAG
structures can be easily achieved in a polynomial time. We then propose solutions to merge
S. Benferhat et al.
possibilistic networks having different structures and where the union of their graphs is free of
cycles. The last section deals with the sub-normalization problem which reflects the presence
of conflicts between different sources.
