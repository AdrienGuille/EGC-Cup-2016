Classification et se´lection automatique de
caracte´ristiques de textures
Marine Campedel∗, Eric Moulines∗∗
Ecole Nationale Supe´rieure des Te´le´communications
Laboratoire de Traitement du Signal et des Images
46, rue Barrault, 75013 Paris
∗ Marine.Campedel@enst.fr,
http://www.tsi.enst.fr/˜campedel
∗∗ Eric.Moulines@enst.fr
http://www.tsi.enst.fr/˜moulines
Cette e´tude est finance´e par le Centre National d’Etude Spatiale (CNES).
Re´sume´. Choisir a priori les caracte´ristiques pertinentes pour une ap-
plication donne´e n’est pas aise´. En particulier, les outils de classification
d’images utilisent des mode`les varie´s pour repre´senter les textures. Nous
proposons de choisir les mode`les de texture les plus pertinents a` l’aide
d’une proce´dure automatique de se´lection de caracte´ristiques. Nous com-
parons pour cela l’efficacite´ de plusieurs algorithmes re´cents en e´valuant
les performances de diffe´rents classificateurs exploitant ces se´lections. Nous
de´montrons l’inte´reˆt d’une telle proce´dure de se´lection a` partir des images
de Brodatz.
1 Introduction
Face a` l’accroissement rapide des tailles des bases de donne´es, en particulier
des bases d’images, il est ne´cessaire de de´velopper de nouveaux algorithmes de
traitement facilitant a` la fois le stockage et l’indexation de ces donne´es. Nous
nous inte´ressons dans ce travail aux algorithmes de se´lection de caracte´ristiques
(appele´es aussi descripteurs), qui permettent d’extraire une information non redon-
dante et pertinente, en vue d’une exploitation efficace des bases de donne´es. Ces
algorithmes font l’objet d’une litte´rature abondante depuis une dizaine d’anne´es
[Kohavi et John, 1997, Blum et Langley, 1997, Guyon et Elisseeff, 2003] .
Les algorithmes de se´lection sont re´partis en deux groupes principaux : les ’filters’ et
les ’wrappers’. Les premiers exploitent les proprie´te´s intrinse`ques des caracte´ristiques
utilise´es, sans re´fe´rence a` une quelconque application. Les seconds, au contraire,
de´finissent la pertinence des caracte´ristiques par l’interme´diaire d’une pre´diction de
la performance du syste`me final. Les premiers sont ge´ne´ralement moins couˆteux mais
aussi moins efficaces que les seconds.
Les performances des algorithmes de´pendent de l’e´valuation de la pertinence des des-
cripteurs mais aussi de la strate´gie de recherche du sous-ensemble de caracte´ristiques.
Cette recherche ne peut pas eˆtre exhaustive (il faudrait explorer 2D combinaisons
Se´lection de mode`le de textures
pour un ensemble initial de D caracte´ristiques), diffe´rentes strate´gies d’exploration de
l’espace des caracte´ristiques sont donc pre´sente´es dans la litte´rature, en particulier
reposant sur l’usage d’algorithmes ge´netiques [Kim et al., 2002] ou de strate´gies
incre´mentales (forward) et/ou de´cre´mentales (backward) [Kohavi et John, 1997]. Il
s’agit de progessivement ajouter (ou respectivement supprimer) une caracte´ristique en
comparant le be´nefice (resp. la perte) apporte´ par l’utilisation de cette caracte´ristique.
Nous nous plac¸ons ici dans le cadre supervise´. Le principe de la se´lection est
donc de se´lectionner le sous-ensemble de caracte´ristiques permettant de discriminer
au mieux les diffe´rentes classes de donne´es. Dans le cas ’filter’, les algorithmes
calculent un poids pour chaque caracte´ristique, significatif de cette capacite´
a` rassembler les e´le´ments d’une meˆme classe et se´parer les e´le´ments e´tiquete´s
diffe´remment. Nous avons choisi de tester l’algorithme ReliefF, initialement pre´sente´
par [Kira et Rendell, 1992, Robnik-Sikonja et Kononenko, 2003]. Dans le cas ’wrap-
per’, la se´lection est directement relie´e a` la performance d’un classificateur. Nous avons
choisi trois algorithmes diffe´rents : Fisher (appele´ aussi LDA ou analyse line´aire dis-
criminante), RFE [Guyon, 2002, Guyon et Elisseeff, 2003] et L0 [Weston et al., 2003].
Ces trois algorithmes calculent la pertinence de chaque caracte´ristique a` l’aide des
poids estime´s par un classificateur line´aire (Fisher ou SVM). Nous nous inte´ressons aux
machines a` vecteurs de support (SVM) car elles limitent le risque de surapprentissage
du fait de leur capacite´ de re´gularisation (ce risque e´tant particulie`rement important
lorsque le nombre de caracte´ristiques, i.e. la dimension, est grand face a` au nombre de
donne´es).
Les quatre algorithmes e´tudie´s reposent donc sur l’estimation de poids (scores)
correspondant a` chaque caracte´ristique. Ces poids sont utilise´s pour ordonner puis
se´lectionner les K (parmi D) descripteurs les plus pertinents. Seule la me´thode L0
permet une estimation du nombre minimal K de caracte´ristiques ne´cessaires.
Notre objectif est de comparer les performances de ces diffe´rents algorithmes a` l’aide
de performances de classification (KNN, Fisher, SVM).
Le proble`me de choisir les bons descripteurs pour la classification d’images est un
proble`me re´current dans la litte´rature [Sebe et Lew, 2000, Rui et al., 2001]. Nous
proposons donc d’y re´pondre a` l’aide de techniques de se´lection automatiques. Nous
appliquons nos diffe´rentes proce´dures de se´lection sur des images de textures issues de
la base Brodatz, afin de de´terminer les caracte´ristiques les plus discriminantes, parmi
un ensemble calcule´ sur des matrices de co-occurrence (coefficients dits d’Haralick
[Haralick et al., 1973]), des filtres de Gabor et diverses ondelettes.
L’ensemble de nos simulations s’effectue a` l’aide de l’outil Matlab Spider de´veloppe´
par Elisseeff et Weston [Weston et al., 2004]. Les textures d’images sont calcule´es a`
partir des implantations de Boland [Boland, 1998], de la librairie d’ondelettes de Pyr
[Simoncelli, 2001] et des ’contourlets’ de [Do et Vetterli, 2003].
2 Algorithmes de se´lection
Les algorithmes supervise´s s’appliquent sur des bases de donne´es e´tiquete´es.
Soient les donne´es xi,i = 1,..,N et les e´tiquettes associe´es yi. Nous ne traitons que des
RNTI - C - 1
Campedel et Moulines
e´tiquettes discre`tes. Les donne´es sont nume´riques et multivalue´es sur un espace initial
de dimension D ( xi ∈ RD ).
Le principe de l’algorithme de se´lection supervise´ est d’extraire un sous-ensemble de
K caracte´ristiques dans l’ensemble de taille D initial, permettant de repre´senter au
mieux les donne´es e´tiquete´es, donc en particulier permettant de classifier au mieux ces
donne´es. Les algorithmes que nous avons e´tudie´s associent tous un score de pertinence
a` chaque type de caracte´ristique, ce qui permet de les ordonner et de se´lectionner les
K meilleurs.
2.1 ReliefF
Cet algorithme, introduit sous le nom de Relief dans [Kira et Rendell, 1992] puis
ame´liore´ et adapte´ au cas multi-classes par Kononenko sous le nom de ReliefF, ne se
contente pas d’e´liminer la redondance mais de´finit un crite`re de pertinence. Ce crite`re
mesure la capacite´ de chaque caracte´ristique a` regrouper les donne´es de meˆme e´tiquette
et discriminer celles ayant des e´tiquettes diffe´rentes. L’algorithme est de´crit ci-dessous.
L’analyse de ReliefF est effectue´e dans [Robnik-Sikonja et Kononenko, 2003].
– Initialisation des poids (scores) : wd = 0,d = 1,..,D
– Pour i = 1 : m (m limite´ a` N)
tirer ale´atoirement une donne´e de xi,
trouver les k plus proches voisins de xi ayant la meˆme e´tiquette (hits),
trouver les k plus proches voisins de xi ayant une e´tiquette diffe´rente, dans chaque
classe c (missesc),
pour chaque caracte´ristique d, mettre a` jour le poids selon la formule ci-dessous.
wd = wd −
∑
j=1 k
diff(xi,d,hitsj
mK (1)
+
∑
c =class(xi)
P (c)
1−P (class(xi))
∑k
j=1
diff(xi,d,missescj)
mK (2)
La distance utilise´e est de´finie par :
diff(xi,d,xj) =
|xid − xjd|
max(d)−min(d) (3)
max(d) ( resp. min(d) ) de´signe la valeur maximale (resp. minimale) que peut prendre
la caracte´ristique de´signe´e par l’index d, sur l’ensemble des donne´es. xid est la valeur
de la die`me caracte´ristique de la donne´e xi.
Le poids d’une caracte´ristique est d’autant plus grand que les donne´es issues de la
meˆme classe ont des valeurs proches et que les donne´es issues de classes diffe´rentes
sont bien se´pare´es. Cet algorithme est rapide, sa complexite´ est en O(N2D). Il n’y a
pas de recherche de sous-espace, ReliefF produit un score permettant d’ordonner les
caracte´ristiques selon le crite`re de pertinence de´fini ci-dessus.
2.2 Fisher
Le deuxie`me algorithme choisi repose sur l’analyse discriminante line´aire (LDA)
de Fisher. De fac¸on ge´ne´rale, un proble`me de discrimination line´aire, a` deux classes,
RNTI - C - 1
Se´lection de mode`le de textures
revient a` se´parer l’espace des donne´es en deux graˆce a` un hyperplan. Choisir la classe (a`
valeur dans −1,1) d’une donne´e consiste alors a` de´terminer de quel coˆte´ de l’hyperplan
elle se situe, ce qui se traduit sous la forme :
g(xi) = sign(w.xi + b)) (4)
xi ∈ RD,i = 1 . . . N,w ∈ RD.b ∈ R est appele´ le biais.
L’objectif de la LDA est de trouver une projection des donne´es sur une droite, qui
se´pare au mieux les donne´es, i.e. en maximisant le rapport des variances inter et intra
classes des projections. Lorsque l’on fait l’hypothe`se que les caracte´ristiques suivent,
sur chaque classe (+ et -), une distribution gaussienne N(µ(+),σ(+)) et N(µ(−),σ(−)),
et qu’elles sont de´corre´le´es, il vient :
wd =
(µ(+)d − µ(−)d )2
σ
(+)2
d + σ
(−)2
d
(5)
Le formule peut eˆtre e´tendue au cas multiclasse en conside´rant qu’il s’agit d’un ensemble
de proble`mes a` deux classes du type 1 contre tous. Nous utilisons l’implantation de
l’algorithme fournie par Spider [Weston et al., 2004].
2.3 SVM-RFE
Cet algorithme de se´lection est pre´sente´ dans [Guyon, 2002]. Il repose lui-aussi sur
l’estimation de poids relatifs a` l’optimisation d’un proble`me de discrimination line´aire,
ce proble`me e´tant re´solu a` l’aide d’une machine a` vecteurs de support (SVM).
2.3.1 Principe des SVM
Une pre´sentation claire et de´taille´e des SVM peut eˆtre obtenue notamment dans
[Cortes et Vapnik, 1995, Schoelkopf et Smola, 2002].
Si un ensemble de donne´es d’apprentissage est line´airement se´parable, alors le classi-
ficateur SVM maximise la marge de se´paration, ce qui revient a` re´soudre le proble`me
suivant :
minw,b||w||22 (6)
avec la contrainte
yi(w.xi + b) >= 1
Les vecteurs supports sont les donne´es xi qui ve´rifient :
yi(w.xi + b) = 1
Sous sa forme duale, le proble`me apparaˆıt comme quadratique:
maxα
N∑
i=1
αi − 12
N∑
i,j=1
αiαjyiyjxi.xj (7)
RNTI - C - 1
Campedel et Moulines
sous les contraintes
N∑
i=1
αiyi = 0,αi > 0,i = 1, . . . ,N
On a la relation :
wd =
∑
i
αiyixid
Les αi sont tous nuls excepte´s ceux correspondant aux vecteurs supports.
La robustesse des SVMs provient de l’ajout d’une contrainte de re´gularisation, sous la
forme :
minw,b||w||22 + C
N∑
i=1
i (8)
sous les contraintes
yi(w.xi + b) >= 1− i,i > 0,i = 1, . . . ,N
Nous utilisons dans notre e´tude l’implantion des SVMs appele´e libsvm version 2.5
[Chang et Lin, 2004] (C=1000). La plupart des proble`mes ne se contentent pas de deux
classes de donne´es. Nous avons choisi de conside´rer les proble`mes multi-classes comme
une accumulation de proble`mes a` deux classes (une contre toutes les autres). Il existe
d’autres versions multiclasses de SVM dont [Elisseeff, 2000], mais nous ne les avons
pas utilise´es dans cette e´tude. Dans notre cas, les poids finalement associe´s aux ca-
racte´ristiques sont moyenne´s sur l’ensemble des proble`mes 1-contre-tous.
2.3.2 Re´cursion
Il est montre´ dans [Guyon, 2002, Rakotomamonjy, 2003] que le couˆt de suppression
d’une caracte´ristique est de l’ordre de w2d. La proce´dure de se´lection est de´cre´mentale
et e´limine donc progressivement les caracte´ristiques de faible poids. L’algorithme est
de´compose´ en trois e´tapes :
Tant qu’il reste des caracte´ristiques,
– Entraˆıner le classificateur SVM (line´aire) ;
– Calcul des w2i ;
– Supprimer la (les) caracte´ristique(s) correspondant au(x) poids le(s) plus faible(s).
Nous utilisons l’implantation faite dans l’outil Spider. La proce´dure est grandement
acce´le´re´e lorsque plusieurs caracte´ristiques sont e´limine´es simultane´ment et lorsque
l’on stoppe la boucle d’e´limination de`s obtention du nombre de´sire´ de caracte´ristiques.
2.4 Minimisation de L0 (l0)
L’algorithme L0 pre´sente´ dans [Weston et al., 2003], utilise lui aussi les poids es-
time´s par un classificateur SVM. L’ide´e ge´ne´rale est cependant tre`s diffe´rente de SVM-
RFE, puisqu’il s’agit dans ce cas de favoriser la mise a` zero du plus grand nombre de
RNTI - C - 1
Se´lection de mode`le de textures
poids. Les auteurs proposent donc de minimiser la norme L0 des poids, i.e. de trouver
l’ensemble minimal de caracte´ristiques ayant un poids non nul.
minw||w||00 = minwcard(wi|wi = 0) (9)
Il est de´montre´ dans [Weston et al., 2003] que la minimisation de la norme L0 est
approche´e par :
minw
D∑
j=1
ln(+ |wj |)
Ce proble`me est re´solu par une proce´dure ite´rative (convergeant vers un minimum
local) :
– Initialisation des poids zi = 1,i = 1. . . . ,D
– Re´soudre le proble`me :
minw
D∑
j=1
|wj |
avec la contrainte yi(w.(xi ∗ z) + b) >= 1
– Mise a` jour des poids z = z ∗ w¯, w¯ e´tant la solution du proble`me pre´ce´dent.
La notation ∗ correspond au vecteur des produits terme a` terme :
t ∗ w = (t1w1,...,tDwD)
Finalement, les auteurs mettent en e´vidence l’efficacite´ de l’algorithme, lorsque l’on
remplace la norme L1 des poids par la norme L2, ce qui permet d’utiliser une SVM
pour re´soudre le proble`me interme´diaire.
Nous utilisons l’algorithme de´veloppe´ par les auteurs, dans l’environnement Spider.
3 Crite`res d’e´valuation
Afin de comparer les re´sultats des quatre algorithmes pre´sente´s ci-dessus, nous
avons choisi d’e´valuer les performances en terme d’erreur de classification a` l’aide de
trois algorithmes classiques (Knn, Fisher, SVM). En pratique, nous effectuons une va-
lidation croise´e : les quatre cinquie`mes des donne´es sont utilise´s pour la se´lection des
caracte´ristiques et l’apprentissage des classificateurs, la partie restante e´tant utilise´e
pour l’e´valuation. La performance est mesure´e par l’erreur de classification moyenne´e
sur les cinq ensembles (disjoints) de test.
Etant donne´s les algorithmes de se´lections utilise´s, nous conside´rons les trois classifi-
cateurs dont ils semblent les plus proches :
– K-voisins (’knn’) : le nombre de voisins utilise´ est fixe´ a` la partie entie`re de la
racine carre´e du nombre de donne´es d’apprentissage par classe (12 dans le cas
synthe´tique et 4 dans le cas des images de Brodatz).
– Classificateur de Fisher (’fisher’)
– SVM : nous utilisons le meˆme mode`le que pour les se´lections SVM-RFE et l0
(libsvm 2.5, noyau line´aire, C=1000).
RNTI - C - 1
Campedel et Moulines
4 Simulations
Les premie`res simulations concernent un proble`me purement synthe´tique, mettant
en e´vidence les avantages et inconve´nients des diffe´rentes proce´dures de se´lection. Les
suivantes appliquent deux proce´dures de se´lection rapides a` la se´lection automatique
de mode`les de texture.
4.1 Comparaison des performances de se´lection sur une base
synthe´tique
Nous testons tout d’abord notre proce´dure d’e´valuation sur un proble`me synthe´tique.
Les donne´es sont au nombre de 400, exprime´es sur 50 caracte´ristiques, tire´es uni-
forme´ment sur [0 1]. Seules les deux premie`res caracte´ristiques permettent une se´paration
line´aire parfaite des donne´es. Les dimensions 3 et 4 sont des versions faiblement bruite´es
des deux premie`res. Les dimensions 5 a` 8 sont des versions bruite´es des quatre premie`res.
Toutes les autres dimensions sont du bruit. Les e´valuations produisent les re´sultats de
la figure 1.
Diffe´rentes remarques peuvent eˆtre faites :
– La performance de classification obtenue par le classificateur SVM est toujours
meilleure, quel que soit l’algorithme de se´lection utilise´ en amont. Ceci est duˆ a`
sa capacite´ intrinse`que a` ge´rer les e´le´ments bruite´s.
– Les se´lections de deux caracte´ristiques parmi les cinquante ne sont pas correctes
dans le cas de Relieff et Fisher. Tous les indicateurs mettent en e´vidence la
supe´riorite´ de svm-rfe et l0, qui comme l’indique l’erreur quasi nulle du clas-
sificateur SVM, se´lectionnent les deux caracte´ristiques pertinentes ou bien leurs
versions faiblement bruite´es.
– Lorsque 8 caracte´ristiques sont se´lectionne´es, les indicateurs re´agissent de fac¸on
diffe´rente aux se´lections. Toutes les se´lections contiennent les deux dimensions
pertinentes, ce qui permet de comprendre pourquoi le classificateur SVM ob-
tient la meˆme performance quelle que soit la se´lection. Par contre, il semble que
svm-rfe et l0 pre´fe`rent se´lectionner des caracte´ristiques de bruit plutoˆt que des
caracte´ristiques redondantes, ce qui alte`re les performances de knn et fisher.
– Pour 25 caracte´ristiques se´lectionne´es, les performances sont e´quivalentes quelle
que soit la proce´dure de se´lection. Il est inte´ressant de constater que la pre´sence de
caracte´ristiques bruite´es alte`re les performances de classification, excepte´e celle
de fisher, qui ponde`re tre`s faiblement ces composantes.
– Les algorithmes svm-rfe et l0 ne produisent pas des e´valuations significativement
diffe´rentes excepte´ le cas de 8 se´lections. Cependant l0 est un algorithme beaucoup
plus lent qui, puisqu’il ponde`re ite´rativement les donne´es, peut ne plus converger
(nous l’avons limite´ a` quatre ite´rations).
RNTI - C - 1
Se´lection de mode`le de textures
1 1.5 2 2.5 3 3.5 4
0
0.05
0.1
0.15
E
rr
e
u
r 
m
o
y
e
n
n
e
Nombre de caracteristiques = 10
knn
fisher
svm
1 1.5 2 2.5 3 3.5 4
0
0.05
0.1
0.15
E
rr
e
u
r 
m
o
y
e
n
n
e
Nombre de caracteristiques = 20
1 1.5 2 2.5 3 3.5 4
0
0.05
0.1
0.15
E
rr
e
u
r 
m
o
y
e
n
n
e
Nombre de caracteristiques = 39
Fig. 1 – Valeurs moyennes et e´carts types (barres verticales) obtenus sur 5 tirages. A
gauche, le proble`me est synthe´tique, les me´thodes de se´lection sont de´signe´es par un
index correspondant a` : 1=relieff 2=fisher 3=svm-rfe 4=l0. A droite, se´lection sur les
images de Brodatz.
RNTI - C - 1
Campedel et Moulines
Fig. 2 – Se´lection ale´atoire de 20 images de la base de textures de Brodatz.
4.2 Application au traitement d’images de textures (Brodatz)
L’objectif de cette simulation n’est pas de rendre un verdict de´finitif sur le choix
des mode`les de textures. Il s’agit de de´crire une me´thodologie de se´lection automa-
tique. Bien souvent les experts ont des pre´fe´rences diffe´rentes quant au mode`le de
texture a` utiliser. Estimer simultane´ment tous ces mode`les introduit une redondance
pre´judiciable au niveau du stockage des caracte´ristiques comme au niveau de la per-
formance de classification. Nous mettons donc en e´vidence l’inte´reˆt d’une se´lection
automatique des caracte´ristiques, parmi un ensemble pre´se´lectionne´.
Comme base de travail nous avons choisi la base des images de texture de Brodatz.
Nous avons tire´ ale´atoirement 20 images parmi les 111 dont nous disposons. Ces
images, pre´sente´es figure 2, ont une taille initiale de 640x640. Nous les avons chacune
de´compose´es en 25 imagettes disjointes de taille 128x128. Chaque imagette est ensuite
de´crite par un vecteur de caracte´ristiques, re´sultant de la concate´nation de plusieurs
vecteurs de textures.
La litte´rature fait e´tat de nombreux travaux sur les textures, nous avons se´lectionne´
les coefficients d’Haralick, les Gabors et autres ondelettes, l’ensemble est re´sume´ dans le
tableau 4.2. Dans le cas de proce´dure de filtrage ou d’ondelettes, nous prenons arbitrai-
rement la moyenne et la variance des sorties de chaque sous-bande. Les caracte´ristiques
sont normalise´es (moyenne nulle et variance unite´) sur l’ensemble des 111 images.
RNTI - C - 1
Se´lection de mode`le de textures
Mode`le Nb De´tails
Haralick 78 [Haralick et al., 1973] Matrice de co-occurrence.
13 permiers coefficients obtenus
pour quatre orientations (0 π4 ,
π
2 et
3π
4 ) et distance d=1
+ moyennes et variances correspondantes.
Gabor 24 Filtrage sur 3 e´chelles de 0.1 a` 0.5 et 4 orientations
Steerable wavelet 48 [Simoncelli, 2001]
Contourlet 56 [Do et Vetterli, 2003]
Qmf 26 4 e´chelles
Tab. 1 – Description des diffe´rentes caracte´ristiques calcule´es pour chaque imagette
knn(k=4) fisher svm
m σ m σ m σ
tout 0.065 0.019 0.040 0.021 0.024 0.018
Haralick 0.045 0.015 0.046 0.023 0.016 0.017
Gabor 0.074 0.017 0.064 0.022 0.064 0.040
Steer 0.286 0.051 0.166 0.034 0.198 0.041
Contourlet 0.235 0.026 0.048 0.026 0.092 0.027
qmf 0.206 0.054 0.050 0.022 0.138 0.035
Tab. 2 – Performance de classification sur chaque mode`le
Nous pouvons tout d’abord comparer les performances de classification sur chaque
mode`le de texture. Le tableau 2 re´sume les moyennes et e´cart-types (m, σ) obtenus
en validation croise´e. Nous constatons que, parmi les caracte´ristiques que nous avons
initialement choisies 1, les coefficients d’Haralick permettent d’obtenir la meilleure per-
formance, quel que soit le classificateur utilise´. De plus cette performance est meilleure
que celle obtenue avec l’ensemble des descripteurs.
Nous appliquons maintenant les proce´dures de se´lection aux 78 caracte´ristiques
d’Haralick. Les re´sultats sont pre´sente´s figure 1, pour des ensembles de caracte´ristiques
de taille 10, 20 et 39. Nous constatons que la se´lection de 20 dimensions sur les 78 per-
met d’obtenir des performances de classification e´quivalentes. Par contre, une se´lection
de 10 de´grade les performances de classification.
Concernant la se´lection de 20, nous constatons par ailleurs que fisher se´lectionne
a` 90% les meˆmes caracte´ristiques d’un ensemble d’apprentissage sur l’autre, alors que
svm-rfe n’en conserve que 65%. La figure 4.2 pre´sente la re´partition des caracte´ristiques
se´lectionne´es sur les 13 types de coefficients, pour chacun des cinq tirages de la valida-
tion croise´e. On constate que relieff, svm-rfe et l0 sont beaucoup plus se´lectives sur le
1. Des parame`tres mieux choisis pour les autres mode`les de texture, en particulier les filtres de
Gabor, auraient sans doute pu permettre d’e´galer ces performances
RNTI - C - 1
Campedel et Moulines
1234567891011213
0
0.5
1
relieff
1234567891011213
0
0.5
1
1234567891011213
0
0.5
1
1234567891011213
0
0.5
1
1234567891011213
0
0.5
1
1234567891011213
0
0.5
1
fisher
1234567891011213
0
0.5
1
1234567891011213
0
0.5
1
1234567891011213
0
0.5
1
1234567891011213
0
0.5
1
1234567891011213
0
0.5
1
svm−rfe
1234567891011213
0
0.5
1
1234567891011213
0
0.5
1
1234567891011213
0
0.5
1
1234567891011213
0
0.5
1
1234567891011213
0
0.5
1
l0
1234567891011213
0
0.5
1
1234567891011213
0
0.5
1
1234567891011213
0
0.5
1
1234567891011213
0
0.5
1
tirage 1 
tirage 2 
tirage 3 
tirage 4 
tirage 5 
Fig. 3 – Re´partition des se´lections de 20 selon les 13 types de coefficients
type des donne´es et tendent a` e´changer des caracte´ristiques de meˆme cate´gorie, d’un
tirage sur l’autre. Sachant de par l’e´tude du cas synthe´tique que svm-rfe et l0 pre´fe`rent
e´liminer les caracte´ristiques redondantes, contrairement a` relieff et fisher qui pre´fe`rent
e´liminer les composantes non pertinentes, nous pouvons essayer d’identifier les unes et
les autres. Par exemple, la caracte´ristique de type 13 est fortement se´lectionne´e par
svm-rfe et l0 et tre`s peu par fisher voire pas du tout par relieff ; il s’agit probable-
ment d’une composante de type “bruit”. Similairement, la composante 5 n’est jamais
se´lectionne´e par svm-rfe ou l0 mais est conserve´e par relieff et fisher, ce qui nous indique
qu’elle fait partie vraisemblablement des caracte´ristiques redondantes. En outre, parmi
les 13 types de caracte´ristiques, certains sont conside´re´s comme inutiles par toutes
les proce´dures (type 8). Par ailleurs, les sous-ensembles de primitives se´lectionne´es in-
duisent des performances de classification SVM e´quivalentes, ce qui signifie qu’aucune
des me´thodes de se´lection n’a perdu d’information utile et que le nombre ide´al de
caracte´ristiques se situe entre 10 et 20.
5 Conclusion et perspectives
Nous avons montre´ dans cette e´tude la ne´cessite´ d’appliquer une proce´dure de
se´lection automatique de caracte´ristiques en vue d’une taˆche de classification. Nous
RNTI - C - 1
Se´lection de mode`le de textures
avons compare´ diffe´rents algorithmes de se´lection (supervise´s) re´cents a` l’aide des er-
reurs de classification induites. Nous avons montre´ leur efficacite´ a` l’aide d’un proble`me
synthe´tique ainsi que d’un proble`me de classification d’images de textures.
Nous pre´conisons l’usage d’une proce´dure de se´lection, non seulement pour re´duire l’es-
pace de stockage et ame´liorer les performances de classification, mais aussi pour justifier
le choix d’un mode`le donne´ de caracte´ristiques. Dans l’e´tude pre´sente´e ci-dessus, nous
avons applique´ cette strate´gie a` la se´lection de mode`les de textures.
Dans la plupart des syste`mes impliquant un grand nombre de donne´es et de ca-
racte´ristiques, les e´tiquettes associe´es aux donne´es ne sont pas connues. Nous nous
inte´ressons donc maintenant aux algorithmes de se´lection non supervise´s, qui exploitent
la capacite´ a` clusteriser des donne´es multivalue´es ainsi qu’aux heuristiques permettant
d’e´valuer ces algorithmes. Ces travaux sont mene´s, pour le CNES, dans le but de pro-
duire des outils de traitement automatique en vue de l’indexation de bases d’images
satellitaires de tre`s grande taille.
Re´fe´rences
[Blum et Langley, 1997] A. L. Blum et P. Langley. Selection of relevant features and
examples in machine learning. Artif. Intell., 97(1-2):245–271, 1997.
[Boland, 1998] M. Boland. Programmation en c des coefficients d’haralick. 1998.
[Chang et Lin, 2004] C.C. Chang et C.J. Lin. Libsvm 2.5. 2004.
[Cortes et Vapnik, 1995] C. Cortes et V. Vapnik. Support-vector networks. Mach.
Learn., 20(3):273–297, 1995.
[Do et Vetterli, 2003] M.N. Do et M. Vetterli. Contourlets. In Beyond Wavelets. Aca-
demic Press, 2003.
[Elisseeff, 2000] A. Elisseeff. Etude de la complexite´ et controˆle de la capacite´ des
syste`mes d’apprentissage : SVM multi-classe, re´seaux de re´gularisation et re´seaux de
neurones multicouches. PhD thesis, ENS Lyon, 2000.
[Guyon et Elisseeff, 2003] I. Guyon et A. Elisseeff. An introduction to feature and
variable selection. Journal of Machine Learning Research, 3:1157–1182, 2003.
[Guyon, 2002] I. Guyon. Gene selection for cancer classification using support vector
machines. Mach. Learn., 46:389–422, jan 2002.
[Haralick et al., 1973] R.M. Haralick, K. Shanmugam, et I. Dinstein. Textural features
for image classification. IEEE Transactions on Systems, Man, and Cybertinetics,
6:610–621, 1973.
[Kim et al., 2002] Y. S. Kim, W. N. Street, et F. Menczer. Evolutionary model selection
in unsupervised learning. Intelligent Data Analysis, 6:531–556, 2002.
[Kira et Rendell, 1992] K. Kira et L.A. Rendell. A practical approach to feature selec-
tion. pages 249–256, 1992.
[Kohavi et John, 1997] R. Kohavi et G. H. John. Wrappers for feature subset selection.
Artif. Intell., 97(1-2):273–324, 1997.
[Rakotomamonjy, 2003] A. Rakotomamonjy. Variable selection using svm-based crite-
ria. Journal of Machine Learning Research, 3:1357–1370, 2003.
RNTI - C - 1
Campedel et Moulines
[Robnik-Sikonja et Kononenko, 2003] M. Robnik-Sikonja et I. Kononenko. Theoretical
and empirical analysis of relieff and rrelieff. Mach. Learn., 53(1-2):23–69, 2003.
[Rui et al., 2001] Y. Rui, T.S. Huang, et S.F. Chang. Image retrieval : current tech-
niques, promising directions and open issues. Journal of Visual Communication and
Image Representation, 10:39–62, 2001.
[Schoelkopf et Smola, 2002] B. Schoelkopf et A. Smola. Learning with Kernels. 2002.
[Sebe et Lew, 2000] N. Sebe et M.S. Lew. Wavelet based texture classification. vo-
lume 3, 2000.
[Simoncelli, 2001] E.P. Simoncelli. Matlab tools for multi-scale image processing. 2001.
[Weston et al., 2003] J. Weston, A. Elisseeff, B. Scholkopf, et M. Tipping. Use of the
zero-norm with linear models and kernel methods. Journal of Machine Learning
Research, 3:1439–1461, 2003.
[Weston et al., 2004] J. Weston, A. Elisseeff, G. Bakir, et Fabian Sinz. The spider for
matlab - v1.4. 2004.
RNTI - C - 1
