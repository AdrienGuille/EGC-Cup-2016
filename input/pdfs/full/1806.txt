Partition BIC optimale de lâ€™espace
des preÂ´dicteurs
Gilbert Ritschard
âˆ—DeÂ´partement dâ€™eÂ´conomeÂ´trie, UniversiteÂ´ de Gene`ve
gilbert.ritschard@themes.unige.ch
ReÂ´sumeÂ´. Cet article traite du partitionnement optimal de lâ€™espace de
preÂ´dicteurs cateÂ´goriels dans le but de preÂ´dire la distribution a poste-
riori dâ€™une variable reÂ´ponse elle-meË†me cateÂ´gorielle. Cette partition op-
timale doit reÂ´pondre a` un double crite`re dâ€™ajustement et de simpliciteÂ´ que
prennent preÂ´ciseÂ´ment en compte les crite`res dâ€™information dâ€™Akaike (AIC)
ou bayeÂ´sien (BIC). Apre`s avoir montreÂ´ comment ces crite`res sâ€™appliquent
dans notre contexte, on sâ€™inteÂ´resse a` la recherche de la partition qui mi-
nimise le crite`re retenu. Lâ€™article propose une heuristique rudimentaire
et deÂ´montre son efficaciteÂ´ par une seÂ´rie de simulations qui comparent le
quasi optimum trouveÂ´ au vrai optimum. Plus que pour la partition elle-
meË†me, la connaissance de cet optimum sâ€™ave`re preÂ´cieuse pour juger du
potentiel dâ€™ameÂ´lioration dâ€™une partition, notamment celle fournie par un
algorithme dâ€™induction dâ€™arbre. Un exemple sur donneÂ´es reÂ´elles illustre ce
dernier point.
1 Introduction
En apprentissage superviseÂ´, des techniques comme lâ€™analyse discriminante, la reÂ´gres-
sion logistique multinomiale, les mode`les bayeÂ´siens ou les arbres de deÂ´cisions induits
de donneÂ´es (arbres dâ€™induction) apprennent la distribution a posteriori de la variable
a` preÂ´dire, lâ€™objectif eÂ´tant dâ€™affecter un cas avec profil x en termes de preÂ´dicteurs a` la
classe yi ayant la plus forte probabiliteÂ´ a posteriori p(Y =yi|x). La reÂ´gression logistique,
lâ€™analyse discriminante et les mode`les bayeÂ´siens par exemple, modeÂ´lisent la distribution
a posteriori sous forme dâ€™une fonction vectorielle continue de x. Par contraste, les arbres
dâ€™induction conduisent a` un ensemble fini de distributions, chaque distribution eÂ´tant
associeÂ´e a` une classe dâ€™une partition Â«appriseÂ» de lâ€™ensemble des profils x admissibles.
Nous nous placÂ¸ons dans ce dernier contexte et nous inteÂ´ressons a` la deÂ´termination de la
partition optimale. Nous examinons tout dâ€™abord les crite`res dâ€™optimaliteÂ´ qui peuvent
sâ€™aveÂ´rer pertinents. Parmi ceux-ci, nous porterons un inteÂ´reË†t particulier aux crite`res
dâ€™information du type AIC et BIC qui permettent dâ€™arbitrer entre qualiteÂ´ dâ€™ajuste-
ment et complexiteÂ´. Le calcul des AIC et BIC pour une partition quelconque se fait
par simple adaptation du principe de lâ€™arbre eÂ´tendu introduit dans Ritschard et Zighed
(2003, 2002) pour le cas des arbres.
La recherche de la partition optimale par exploration exhaustive des partitions
eÂ´tant de complexiteÂ´ non polynomiale, il convient de recourir a` des heuristiques. Pour
cette premie`re approche du proble`me, on envisage ici une proceÂ´dure ascendante dont
on examine les performances par une analyse de simulations. Lâ€™heuristique est rudi-
Patition BIC optimale
mentaire, mais sâ€™ave`re suffisamment performante pour traiter jusquâ€™a` une centaine de
profils diffeÂ´rents.
La porteÂ´e du concept meË†me de partition optimale est quelque peu limiteÂ´e en raisons
de possibles difficulteÂ´s dâ€™interpreÂ´tation. Contrairement aux partitions geÂ´neÂ´reÂ´es par les
arbres, la description dâ€™une partition quelconque peut neÂ´cessiter en effet des combinai-
sons souvent difficilement interpreÂ´tables de conditions. Lâ€™optimum fournit cependant
et dans tous les cas des indications preÂ´cieuses sur le potentiel dâ€™ameÂ´lioration quâ€™on peut
apporter a` une partition. Cet inteÂ´reË†t de la partition globalement optimale est illustreÂ´
par une eÂ´tude de la reÂ´ussite des eÂ´tudiants de premie`re anneÂ´e a` la FaculteÂ´ des sciences
eÂ´conomiques de Gene`ve.
Lâ€™article est organiseÂ´ comme suit. La section 2 introduit le cadre formel et les
notations. La section 3 preÂ´cise le concept de partition optimale et deÂ´finit formellement
les crite`res a` optimiser. La section 4 traite de la deÂ´termination de lâ€™optimum. On y
propose une heuristique dont on analyse empiriquement lâ€™efficaciteÂ´ avec des simulations.
La section 5 explicite les limites et lâ€™inteÂ´reË†t du concept de partition optimale qui est
illustreÂ´ a` la section 6. Enfin, la section 7 donne quelques pistes de recherche future.
2 Cadre formel et notations
On se place dans le cadre de lâ€™apprentissage superviseÂ´ avec une variable reÂ´ponse
Y et p preÂ´dicteurs x1, . . . , xp et une base de donneÂ´es dâ€™apprentissage de taille n. On
conside`re plus preÂ´ciseÂ´ment le cas ou` la variable a` preÂ´dire Y et les preÂ´dicteurs sont tous
cateÂ´goriels. On note ` le nombre de valeurs distinctes de Y , ck, le nombre de valeurs
distinctes du preÂ´dicteur xk, k = 1, . . . , p, et c â‰¤
âˆ
k ck le nombre de profils admissibles
x = (x1, . . . , xp).1
Si lâ€™objectif de lâ€™apprentissage est en re`gle geÂ´neÂ´rale la construction dâ€™un classifieur
f(x) qui attribue un et un seul eÂ´tat de la variable Y a` chaque profil x, les connaissances
rechercheÂ´es peuvent dans certains cas porter sur les probabiliteÂ´s des divers eÂ´tats de Y
conditionnellement aux valeurs x des preÂ´dicteurs. Ceci est en particulier le cas dans
les sciences de comportement (sociologie, sciences politiques, marketing, histoire, ...)
qui cherche a` deÂ´crire les meÂ´canismes qui reÂ´gissent les pheÂ´nome`nes eÂ´tudieÂ´s. Nous nous
placÂ¸ons dans ce contexte est consideÂ´rons donc le proble`me de la preÂ´diction de la distri-
bution de probabiliteÂ´ a posteriori de Y , câ€™est-a`-dire de p(Y |x) = (p1(x), . . . , p`(Y x)),
ou` lâ€™on note pi(x) la probabiliteÂ´ p(Y = yi|x).
Notons que de nombreuses techniques de classification sâ€™appuient de facÂ¸on plus ou
moins explicite sur la distribution a posteriori p(Y |x), la classification consistant a`
attribuer les cas a` la cateÂ´gorie la plus probable argmaxi pi(x) compte tenu de x. Câ€™est
le cas notamment de la reÂ´gression logistique, de lâ€™analyse discriminante lineÂ´aire ou
quadratique, des k plus proches voisins, des arbres et graphes dâ€™induction ou encore
des reÂ´seaux bayeÂ´siens. Cet aspect est en particulier bien mis en eÂ´vidence dans Hastie
et al. (2001).
Dans le cas de variables cateÂ´gorielles, les donneÂ´es dâ€™apprentissage peuvent eË†tre re-
preÂ´senteÂ´es de facÂ¸on syntheÂ´tique sous forme dâ€™une table de contingence T de taille `Ã— c
1Le croisement de tous les preÂ´dicteurs peut donner lieu a` des profils non admissibles dâ€™effectif
structurellement nul, par exemple (homme, enceinte). Ceci explique lâ€™ineÂ´galiteÂ´ utiliseÂ´e ici.
RNTI - 1
Gilbert Ritschard
croisant la variable reÂ´ponse y avec les profils x. Par exemple, la table 1 preÂ´sente un jeu
de 240 donneÂ´es utiliseÂ´es pour eÂ´tudier la distribution du statut marital selon le sexe et
le secteur dâ€™activiteÂ´.
homme femme
marieÂ´ primaire secondaire tertiaire primaire secondaire tertiaire total
non 50 40 6 0 14 10 120
oui 5 5 12 50 30 18 120
total 55 45 18 50 44 28 240
Tab. 1 â€“ Exemple de table de contingence T
Un eÂ´leÂ´ment de la table T est noteÂ´ nij et repreÂ´sente le nombre de cas avec profil
xj qui dans les donneÂ´es prennent la valeur yi de la variable reÂ´ponse. Les totaux des
lignes et des colonnes sont respectivement noteÂ´s niÂ· et nÂ·j . Les estimations du maximum
de vraisemblance pËœ(Y = yi|xj) = nij/nÂ·j , câ€™est-a`-dire les distributions colonnes de la
table T donnent lâ€™information la plus fine sur les distributions conditionnelles de la
variable reÂ´ponse au sein de lâ€™ensemble dâ€™apprentissage. Aucun degreÂ´ de liberteÂ´ nâ€™est
laisseÂ´ dans ces estimations qui, eÂ´tant alors entie`rement lieÂ´es a` lâ€™eÂ´chantillon peuvent
eË†tre tre`s instables lorsquâ€™on change dâ€™eÂ´chantillon dâ€™apprentissage. Pour obtenir des
estimations plus stables et donc plus pertinente en geÂ´neÂ´ralisation, il convient de gagner
des degreÂ´s de liberteÂ´ ce qui peut eË†tre fait en regroupant des colonnes ou si lâ€™on veut
en partitionnant lâ€™ensemble des profils x admissibles. Se pose alors naturellement la
question de lâ€™optimaliteÂ´ de la partition ainsi que de sa pertinence.
3 Le concept de partition optimale
On se propose ici de preÂ´ciser les proprieÂ´teÂ´s que lâ€™on attend de la partition chercheÂ´e
est plus formellement dâ€™introduire les crite`res quâ€™il sâ€™agira dâ€™optimiser.
Intuitivement, la partition chercheÂ´e doit
1. reÂ´duire autant que possible lâ€™incertitude quant a` la valeur prise par Y dans chaque
classe ;
2. avoir le plus petit nombre de classes pour assurer une meilleure stabiliteÂ´ des
estimations en laissant le plus de degreÂ´s de liberteÂ´ possibles.
De plus, en particulier lorsquâ€™on sâ€™inteÂ´resse plus a` la compreÂ´hension des relations
de deÂ´pendance quâ€™a` la classification, la partition devrait permettre une caracteÂ´risa-
tion aussi simple que possible des classes pour en faciliteÂ´ lâ€™interpreÂ´tation. Nous nous
concentrons dans un premier temps sur les points eÂ´numeÂ´reÂ´s ci-dessus et reviendrons
sur lâ€™aspect interpreÂ´tation a` la section 5.
La reÂ´duction de lâ€™incertitude ne peut eË†tre jugeÂ´e que par rapport aux donneÂ´es dâ€™ap-
prentissage. Selon le point 1, on attend donc de la partition quâ€™elle reproduise le mieux
possible les distributions colonne de la table T observeÂ´e, ce qui est un proble`me de
qualiteÂ´ dâ€™ajustement. Quant au point 2, il a trait a` la complexiteÂ´ de la partition qui
doit eË†tre le plus simple possible pour assurer la meilleure stabiliteÂ´ des distributions
RNTI - 1
Patition BIC optimale
estimeÂ´es. Ce dernier objectif sâ€™oppose au premier dans la mesure ou` tout affinement de
la partition ne peut que reÂ´duire lâ€™incertitude.
Mesure de la qualiteÂ´ dâ€™ajustement
Examinons tout dâ€™abord le proble`me de lâ€™ajustement. La qualiteÂ´ dâ€™ajustement des
distributions observeÂ´es (les colonnes de la table T) peut se mesurer selon le principe
du tableau eÂ´tendu deÂ´fini dans Ritschard et Zighed (2003) pour le cas particulier des
partitions produites par les arbres. Ce principe est le suivant.
Soit T la table cible. Pour une partition des profils (colonnes de T) en q < c classes,
on geÂ´ne`re la tableTa de dimension `Ã—q qui croise la variable reÂ´ponse y avec la partition.
Lâ€™objectif eÂ´tant de juger de la qualiteÂ´ de lâ€™ajustement de la table cible par cette table
reÂ´duite, on transforme cette dernie`re en une table eÂ´quivalente de meË†me dimension que
T. La transformation consiste a` ventiler chaque eÂ´leÂ´ment naik de T
a entre les colonnes qui
forment la k-e`me classe de la partition, la ventilation se faisant proportionnellement
aux freÂ´quences marginales des profils concerneÂ´s. On obtient ainsi la table preÂ´dite TË†
dâ€™eÂ´leÂ´ment geÂ´neÂ´rique
nË†ij =
nÂ·jâˆ‘
jâ€²âˆˆJk nÂ·jâ€²
naik (1)
ou` Jk est lâ€™ensemble des indices des colonnes de T qui sont regroupeÂ´es dans la meË†me
classe k de la partition. Pour lâ€™exemple du tableau 1, la partition{ {(hom,pri),(hom,sec)}, {(hom,ter),(fem,sec),(fem,ter)}, {(fem,pri)} }
conduit ainsi a` la table preÂ´dite TË† donneÂ´e au tableau 2.
homme femme
marieÂ´ primaire secondaire tertiaire primaire secondaire tertiaire total
non 49.5 40.5 6 0 14.67 9.33 120
oui 5.5 4.5 12 50 29.33 18.67 120
total 55 45 18 50 44 28 240
Tab. 2 â€“ Table preÂ´dite TË†
La qualiteÂ´ de lâ€™ajustement de T peut eË†tre eÂ´valueÂ´e par des statistiques de divergence
du khi-2 Cressie et Read (1984), en particulier par les statistiques X2 de Pearson ou
G2 du rapport de vraisemblance :
G2 = 2
âˆ‘`
i=1
câˆ‘
j=1
nij ln
(
nij
nË†ij
)
, X2 =
âˆ‘`
i=1
câˆ‘
j=1
(nij âˆ’ nË†ij)2
nË†ij
.
Sous lâ€™hypothe`se que le mode`le est correct, câ€™est-a`-dire que la partition modeÂ´lise cor-
rectement les distributions conditionnelles, et sous certaines conditions de reÂ´gulariteÂ´,
voir par exemple Bishop et al. (1975, chap. 14), ces statistiques suivent une meË†me dis-
tribution du khi-2. Nous avons montreÂ´ dans Ritschard et Zighed (2003) que les degreÂ´s
de liberteÂ´ sont dans ce cas (câˆ’ q)(`âˆ’ 1).
RNTI - 1
Gilbert Ritschard
La divergence entre les tableaux TË† et T des tableaux 2 et 1 est par exemple de
G2 = 0.23 (on a aussi X2 = 0.23), pour 3 degreÂ´s de liberteÂ´ ce qui donne un degreÂ´ de
signification de plus de 97% et indique un ajustement presque parfait.
On peut songer a` dâ€™autres indicateurs pour juger de lâ€™eÂ´cart entre les deux tableaux,
par exemple, une diffeÂ´rence simple ou normaliseÂ´e dâ€™entropie entre les deux tables. Lâ€™inteÂ´-
reË†t des statistiques du khi-2 est quâ€™elles permettent, lorsque les conditions de reÂ´gulariteÂ´
sont satisfaites, de tester la significativiteÂ´ statistique de la divergence.
Arbitrage avec la complexiteÂ´
La partition optimale du seul point de vue de la qualiteÂ´ de lâ€™ajustement est eÂ´videm-
ment la partition la plus fine qui preÂ´dit exactement la table cible. Comme mentionneÂ´
plus haut, il convient de tenir eÂ´galement compte de la taille de la partition. Une stra-
teÂ´gie peut ainsi consister a` chercher la partition de taille minimale qui assure une
deÂ´viance non statistiquement significative. Le proble`me avec cette approche est double
comme le souligne en particulier Raftery (1995). Dâ€™une part, lorsque n devient grand le
moindre eÂ´cart devient statistiquement significatif. Dâ€™autre part, de multiples mode`les
(il faut entendre partitions dans notre cas) ajustent de facÂ¸on satisfaisante la table cible.
On se trouve de`s lors confronteÂ´ a` une incertitude quant au bon mode`le. Kass et Raf-
tery (1995) ont montreÂ´ que la minimisation du crite`re BIC permet dans une approche
bayeÂ´sienne de minimiser lâ€™incertitude lieÂ´e au mode`le pour les donneÂ´es observeÂ´es. Ce
crite`re initialement introduit par Schwarz (1978), sâ€™exprime dans notre cas comme la
combinaison de la deÂ´viance G2 et dâ€™une peÂ´nalisation pour la complexiteÂ´ mesureÂ´e par
(q`âˆ’ q + c) (voir Ritschard et Zighed, 2003). Le crite`re AIC de Akaike (1983) est une
variante qui peÂ´nalise la complexiteÂ´ moins fortement et indeÂ´pendamment de n.
AIC = G2 + 2(q`âˆ’ q + c) et BIC = G2 + (q`âˆ’ q + c) log(n) .
La minimisation de lâ€™un ou lâ€™autre de ces crite`res reÂ´pond parfaitement a` notre
objectif dâ€™optimaliteÂ´ de la partition.2
4 DeÂ´termination de la partition optimale
Lâ€™exploration exhaustive de toutes les partitions est de complexiteÂ´ non polynomiale
(np-complet). Le nombre B(c) de partitions des c profils est donneÂ´ par la formule
iteÂ´rative de Bell (1938) B(c) =
âˆ‘câˆ’1
k=0
(
câˆ’1
k
)
B(k). La figure 1 montre clairement que ce
nombre explose totalement au dela` dâ€™une dizaine de profils.
Limite de lâ€™approche par les arbres
Parmi les diverses meÂ´thodes dâ€™apprentissage, les arbres dâ€™induction ont la particu-
lariteÂ´ de travailler avec un nombre fini de distributions a posteriori p(Y |x) par opposi-
tion avec des approches comme la reÂ´gression logistique ou lâ€™analyse discriminante qui
2Dans les situations classiques, le crite`re AIC est connu pour eË†tre biaiseÂ´. Par exemple, dans le
cadre des mode`les lineÂ´aires, AIC asymptotiquement seÂ´lectionne des mode`les plus complexes que le
vrai mode`le.
RNTI - 1
Patition BIC optimale
0 10 20 30 40 50
70000
60000
50000
40000
30000
20000
10000
0
nombre c de profils
partitions exploreÂ´es
exhaustif
pas a` pas
Fig. 1 â€“ Nombre de partitions exploreÂ´es par la proceÂ´dure exhaustive et borne supeÂ´rieure
de ce nombre pour lâ€™approche pas a` pas
impliquent des fonctions continues de x. Les arbres sont donc bien adapteÂ´s a` notre
contexte. Ils construisent les partitions de facÂ¸on descendante. En partant du nÅ“ud
initial constitueÂ´ de tous les profils, ils proce`dent par eÂ´clatements successifs des nÅ“uds
jusquâ€™a` ce quâ€™un crite`re dâ€™arreË†t soit atteint. Les eÂ´clatements successifs, câ€™est-a`-dire pour
chaque nÅ“ud le choix dâ€™un preÂ´dicteur et le partitionnement du nÅ“ud selon les modaliteÂ´s
de ce preÂ´dicteur, se font par optimisation dâ€™un crite`re local, par exemple la significati-
viteÂ´ dâ€™un khi-2 dans CHAID Kass (1980) ou le ratio de gain dans C4.5 Quinlan (1993).
 
 
 
 
 

G46
	 
 
 G46
  

 
 
	
 

 	

 

 
 
 
 
 
 

 

 
 
 
	 


Fig. 2 â€“ PreÂ´diction de la distribution du statut marital : une partition de lâ€™espace des
preÂ´dicteurs non reÂ´alisable avec un arbre
Dans lâ€™optique de deÂ´terminer la partition globalement optimale, on peut songer
a` remplacer le crite`re local par un crite`re global du type AIC ou BIC. Les arbres
preÂ´sentent cependant lâ€™inconveÂ´nient de ne pas pouvoir geÂ´neÂ´rer toutes les partitions et
donc de rater eÂ´ventuellement la partition globalement optimale. La figure 2 par exemple,
illustre une partition qui ne peut pas eË†tre obtenue avec un arbre, tandis que la figure 3
RNTI - 1
Gilbert Ritschard
 
 
 
 

 

G46

  

 
 G46
  

 
 
	
 

 	

 

 
 
 
 
 
 

 

 
 


Fig. 3 â€“ PreÂ´diction de la distribution du statut marital : une partition de lâ€™espace des
preÂ´dicteurs reÂ´alisable avec un arbre
caracteÂ´rise le type de partition produite par un arbre. On notera que la partition de
la figure 2 est preÂ´ciseÂ´ment celle qui donne lieu a` la table preÂ´dite TË† du tableau 2. Les
valeurs de AIC et BIC des deux partitions illustreÂ´es sont respectivement de 18.2 et 49.6
pour la partition de la figure 2 contre 20.2 et 55 pour celle de la figure 3. On a donc
ici un exemple de situation ou` lâ€™on ne peut pas atteindre la partition optimale avec un
arbre.
ProceÂ´dure pas a` pas arrie`re
Une solution alternative est de proceÂ´der par regroupements successifs deux a` deux
des classes en partant de la partition la plus fine jusquâ€™a` ce que le crite`re AIC ou BIC
ne puisse plus eË†tre reÂ´duit. Il sâ€™agit dâ€™une version simplifieÂ´e de lâ€™heuristique proposeÂ´e
dans Ritschard et al. (2001) et eÂ´tudieÂ´e dans Ritschard (2001) ou` lâ€™on explorait simul-
taneÂ´ment les regroupements en lignes et en colonnes. Les regroupements se font ici
uniquement sur les colonnes (profils) de la table cible T. En effet, des regroupements
sur la variable a` preÂ´dire modifieraient la nature des distributions a` preÂ´dire et rendrait
caduque la comparaison des AIC ou BIC.
Performance de lâ€™heuristique
La borne supeÂ´rieure du nombre de cas exploreÂ´s par lâ€™heuristique est 1+
âˆ‘c
i=2
(
i
2
)
=
1+ c(c
2âˆ’1)
6 et sa complexiteÂ´ est donc polynomiale en O(c
3). Câ€™est eÂ´videmment plus
complexe que les arbres, mais suffisant tant que le nombre de partitions admissibles c
nâ€™exce`de pas une centaine, contre 8 ou 9 pour la proceÂ´dure exhaustive. On peut voir
lâ€™eÂ´volution de cette borne supeÂ´rieure avec c dans la figure 1.
Pour juger de la capaciteÂ´ de lâ€™heuristique a` trouver la partition globalement opti-
male, nous avons proceÂ´deÂ´ par simulation. Une seÂ´ries de 200 tables de contingence de
n = 10â€²000 cas ont eÂ´teÂ´ geÂ´neÂ´reÂ´es aleÂ´atoirement. On a geÂ´neÂ´reÂ´ des tables de ` = 4 lignes
et c = 7 colonnes, le nombre 7 de colonnes eÂ´tant le plus grand qui permette dâ€™appli-
quer la proceÂ´dure exhaustive sur les 200 tables en un temps raisonnable. Pour chaque
table nous avons compareÂ´ la valeur du crite`re (AIC ou BIC) quasi-optimale trouveÂ´e
par lâ€™heuristique a` la valeur optimale deÂ´termineÂ´e avec la proceÂ´dure exhaustive.
RNTI - 1
Patition BIC optimale
En allouant les 10â€²000 cas entre les 4 Â· 7 = 28 cases du tableau selon une distribu-
tion uniforme, on geÂ´ne`re des tables caracteÂ´riseÂ´es par une absence totale de structure
pour lesquelles tout regroupement de profils donne lieu a` un deÂ´ficit dâ€™ajustement trop
important pour pouvoir eË†tre compenseÂ´ par la reÂ´duction de taille de la partition. De
facÂ¸on donc non surprenante, lâ€™heuristique a trouveÂ´ les BIC et AIC optimaux dans les
200 cas, la partition optimale eÂ´tant dans presque tous les cas la partition la plus fine, la
valeur moyenne des 200 crite`res optimaux eÂ´tant de 254.8 contre 257.8 pour la partition
la plus fine.
Pour introduire un peu de structure, nous avons proceÂ´deÂ´ a` une seconde seÂ´ries de
simulation en geÂ´neÂ´rant les tables selon des distributions uniformes conditionnelles em-
boË†Ä±teÂ´es : un pourcentage aleÂ´atoire entre 0 et 100% des cas est alloueÂ´ a` la premie`re ligne,
puis un pourcentage aleÂ´atoire des cas restant a` la seconde ligne et ainsi de suite jusquâ€™a`
la dernie`re ligne, le total de chaque ligne eÂ´tant ensuite reÂ´parti de la meË†me facÂ¸on dans
la ligne. On geÂ´ne`re ainsi des tables ou` les gros effectifs ont tendance a` se concentrer en
haut et a` gauche.
AIC BIC
Ecarts non nuls seulement :
proportion 6% 12.5%
maximum 1.55 8.79
moyenne 0.62 1.62
eÂ´cart type 0.44 1.73
asymeÂ´trie 0.48 0.979
Ensemble des eÂ´carts nuls et non nuls :
moyenne 0.04 0.20
eÂ´cart type 0.18 0.95
asymeÂ´trie 5.72 6.21
Ecarts relatifs : maximum 0.035 0.048
moyenne 0.013 0.009
Valeur initiale du crite`re 56 257.9
Moyenne des optima globaux 50.98 213.5
Tab. 3 â€“ Simulations : eÂ´carts entre optima et quasi-optima du AIC et du BIC
Le tableau 3 reÂ´sume les reÂ´sultats de ces simulations. On constate que si la proportion
dâ€™optima manqueÂ´s est significative avec respectivement 6% et 12.5%, les eÂ´carts entre la
solution quasi-optimale de lâ€™heuristique et lâ€™optimum global reste faible dans tous les cas
avec un eÂ´cart relatif maximal de 1.3% pour lâ€™AIC et de 4.8% pour le BIC. De meË†me,
les eÂ´carts moyens restent faibles en regard de la reÂ´duction moyenne (respectivement
5.02 et 44.4) de la valeur initiale du crite`re. Nous avons obtenus des reÂ´sultats tre`s
similaires, en fait meË†me leÂ´ge`rement moins bons, avec des tables 4Ã— 6. Ceci est plutoË†t
encourageant, dans la mesure ou` cela indique que ces performances ne semblent pas
devoir se deÂ´teÂ´riorer lorsque c augmente.
RNTI - 1
Gilbert Ritschard
5 PorteÂ´e et limites du concept de partition optimale
On a examineÂ´ jusquâ€™ici comment deÂ´finir formellement la partition optimale et les
possibiliteÂ´s et difficulteÂ´s que soule`vent sa deÂ´termination. Nous nous proposons mainte-
nant de revenir sur lâ€™aspect interpreÂ´tation en discutant brie`vement les enseignements
que nous apporte la connaissance de cet optimum global.
En premier lieu, il importe de preÂ´ciser que dans notre approche la complexiteÂ´ est
mesureÂ´e en termes de taille de la partition. Ceci nâ€™assure pas la simpliciteÂ´ de description
des classes comme lâ€™illustrent notamment les exemples des figures 2 et 3, la partition en
quatre de la seconde figure eÂ´tant plus facile a` deÂ´crire que celle en trois de la premie`re.
La difficulteÂ´ dans ce dernier cas tient au fait que lâ€™une des classes est deÂ´finie par une
alternative de conditions et non uniquement en termes de conjonctions de conditions
comme dans le cas des arbres.
Si cette difficulteÂ´ de deÂ´crire simplement la partition optimale limite la porteÂ´e du
concept de partition optimale, la connaissance de la valeur optimale du crite`re (AIC ou
BIC) fournit par contre une indication preÂ´cieuse pour juger de la qualiteÂ´ dâ€™une solution
produite par un arbre dâ€™induction. En effet, une solution proche de la valeur optimale
nous indiquera quâ€™on a peu de chances de pouvoir ameÂ´liorer les choses en jouant sur
les parame`tres de controË†le, tandis quâ€™un grand eÂ´cart par rapport a` la valeur optimale
pourra justifier des efforts dans ce sens. Dans cette optique nous suggeÂ´rons de calculer
les deux valeurs optimales AIC et BIC ainsi que la taille des partitions correspondantes.
6 Illustration
Afin dâ€™illustrer les enseignements apporteÂ´s par les AIC et BIC optimaux, nous
donnons quelques reÂ´sultats obtenus avec des donneÂ´es relatives aux 762 eÂ´tudiants qui
ont commenceÂ´ leur premie`re anneÂ´e dâ€™eÂ´tudes a` la FaculteÂ´ des sciences eÂ´conomiques et
sociales de Gene`ve en 1998. Il sâ€™agit de donneÂ´es administratives reÂ´unies par Petroff
et al. (2001). Lâ€™objectif eÂ´tait dâ€™eÂ´valuer les chances de respectivement reÂ´ussir, redoubler
ou eË†tre eÂ´limineÂ´ a` la fin de la premie`re anneÂ´e dâ€™eÂ´tudes. La figure 4 montre lâ€™arbre obtenu
avec la proceÂ´dure CHAID (Kass, 1980) impleÂ´menteÂ´e dans Answer Tree (SPSS, 2001).
Parmi une trentaine de preÂ´dicteurs potentiels, CHAID en a seÂ´lectionneÂ´ 5 dont deux
quantitatifs, lâ€™anneÂ´e dâ€™immatriculation a` lâ€™universiteÂ´ et lâ€™aË†ge a` lâ€™obtention du diploË†me
de lâ€™eÂ´cole secondaire. Les cinq variables avec les discreÂ´tisations et regroupements de
modaliteÂ´s proposeÂ´s par CHAID sont le type de diploË†me secondaire (3 modaliteÂ´s), lâ€™aË†ge
de son obtention (4), la date dâ€™immatriculation (2), le tronc commun choisi (2) et la
nationaliteÂ´ (2). La table cible deÂ´finie par ces variables contient 88 colonnes. Elle a 3
lignes correspondant aux 3 situations possibles de lâ€™eÂ´tudiant apre`s un an dâ€™eÂ´tude.
La valeur du AIC et du BIC pour la partition deÂ´finie par lâ€™arbre est donneÂ´e dans le
tableau 4. On donne eÂ´galement la taille de la partition, la deÂ´viance G2 avec ses degreÂ´s de
liberteÂ´ et son degreÂ´ de signification, ainsi que le pseudo R2 ajusteÂ´. Ces valeurs peuvent
eË†tre compareÂ´es a` celles de deux variantes, CHAID2 qui est CHAID sans lâ€™eÂ´clatement du
sommet 4 (nationa /âˆˆ {GE, hors Europe}) et CHAID3 sans lâ€™eÂ´clatement des sommets 4
et 5 (nationa âˆˆ {GE, hors Europe}). Le mode`le satureÂ´ correspond a` la partition la plus
fine et le mode`le dâ€™indeÂ´pendance au cas ou` tous les profils sont regroupeÂ´s en seul groupe.
RNTI - 1
Patition BIC optimale
pseudo
Mode`le q d G2 sig(G2) R2ajust AIC BIC
SatureÂ´ 88 0 0 1 1 528 1751.9
Meilleur AIC 14 148 17.4 1 .941 249.4 787.2
CHAID 9 158 177.9 0.133 .336 390.0 881.3
CHAID2 8 160 187.4 0.068 .309 395.4 877.5
CHAID3 7 162 195.2 0.038 .289 399.2 872.1
Meilleur BIC 6 164 75.2 1 .745 275.2 738.8
IndeÂ´pendance 1 174 295.1 0.000 0 475.8 892.3
Tab. 4 â€“ SES 98 : qualiteÂ´s dâ€™ajustement dâ€™un choix de mode`les
On constate tout dâ€™abord que CHAID et ses deux variantes ont des AIC ou BIC tre`s
voisins, sensiblement meilleurs que ceux du mode`le satureÂ´ et dans une moindre mesure
que ceux du mode`le dâ€™indeÂ´pendance. A priori il est difficile de dire si pour ameÂ´liorer
la partition il vaut mieux lâ€™affiner ou au contraire reÂ´duire sa taille. Câ€™est ici que les
valeurs des AIC et BIC optimaux sâ€™ave`rent utiles. Elles indiquent par exemple que
les deux options peuvent eË†tre envisageÂ´es. Le meilleur AIC correspond a` une partition
plus fine de 14 classes qui montre notamment un potentiel important dâ€™ameÂ´lioration
de la qualiteÂ´ dâ€™ajustement. Le meilleur BIC indique que lâ€™on peut atteindre une qualiteÂ´
comparable dâ€™ajustement avec une partition plus sommaire de 6 classes seulement. On
a dans tous les cas une indication forte quâ€™il est possible dâ€™ameÂ´liorer sensiblement la
qualiteÂ´ de la partition produite par CHAID. Cet exemple semble aussi confirmer une
bilan oct.99
dipl. second.regroup.
Adj. P-value=0.0000, Chi-square=50.7197, df=2
Ã©conomique;moderne,<missing>
AGEDIP
Adj. P-value=0.0090, Chi-square=11.0157, df=1
>20,<missing><=20
classic .latine;scientifique
AGEDIP
Adj. P-value=0.0067, Chi-square=14.6248, df=2
>19(18,19]<=18
Ã©tranger,autre;dipl. ing.
nationalitÃ© regoup.
Adj. P-value=0.0011, Chi-square=16.2820, df=1
GenÃ¨ve;hors Europe
tronc commun
Adj. P-value=0.0188, Chi-square=5.5181, df=1
sc.socialessc.Ã©con. + HEC
ch-al.+Tessin;Europe;Suisse Romande
date d'immatriculation
Adj. P-value=0.0072, Chi-square=9.2069, df=1
>97<=97
Page 1, 1
Tree 01 - BIL_99
Fig. 4 â€“ Bilan apre`s une anneÂ´e en SES : arbre CHAID
RNTI - 1
Gilbert Ritschard
tendance du AIC a` seÂ´lectionner un mode`le trop complexe.
7 Conclusion
Cet article preÂ´sente une premie`re approche assez rustre pour deÂ´terminer la partition
optimale dans une optique de preÂ´diction de la distribution a posteriori de la variable
reÂ´ponse. Lâ€™heuristique proposeÂ´e doit certainement pouvoir eË†tre ameÂ´lioreÂ´e et dâ€™autres
approches du type descendant notamment meÂ´riteraient eÂ´galement dâ€™eË†tre exploreÂ´es. Il
convient ici de mentionner en particulier les approches qui a` lâ€™instar de Sipina (Zighed
et Rakotomalala, 2000) geÂ´ne`rent des graphes dâ€™induction plutoË†t que des arbres en
autorisant des fusions comme celles illustreÂ´es a` la figure 2. On peut sâ€™attendre a` ce que
le couplage de la strateÂ´gie graphe dâ€™induction avec des crite`res du type AIC ou BIC
donnent des reÂ´sultats performants tant du point de vue du temps de calcul que des
possibiliteÂ´s dâ€™approcher la solution optimale.
ReÂ´feÂ´rences
Akaike, H. (1983). Information measures and model selection. Bulletin of the Interna-
tional Statistical Institue 50, 277â€“290.
Bell, E. T. (1938). The iterated exponential numbers. Ann. Math. 39, 539â€“557.
Bishop, Y. M. M., S. E. Fienberg, et P. W. Holland (1975). Discrete Multivariate
Analysis. Cambridge MA : MIT Press.
Cressie, N. et T. R. Read (1984). Multinomial goodness-of-fit tests. Journal of the
Royal Statistical Society 46, 440â€“464.
Hastie, T., R. Tibshirani, et J. Friedman (2001). The Elements of Statistical Learning.
New York : Springer.
Kass, G. V. (1980). An exploratory technique for investigating large quantities of
categorical data. Applied Statistics 29 (2), 119â€“127.
Kass, R. E. et A. E. Raftery (1995). Bayes factors. Journal of the American Statistical
Association 90 (430), 773â€“795.
Petroff, C., A.-M. Bettex, et A. Korffy (2001, Juin). ItineÂ´raires dâ€™eÂ´tudiants a` la faculteÂ´
des sciences eÂ´conomiques et sociales : le premier cycle. Technical report, UniversiteÂ´
de Gene`ve, FaculteÂ´ SES.
Quinlan, J. R. (1993). C4.5 : Programs for Machine Learning. San Mateo : Morgan
Kaufmann.
Raftery, A. E. (1995). Bayesian model selection in social research. In P. Marsden (Ed.),
Sociological Methodology, pp. 111â€“163. Washington, DC : The American Sociological
Association.
Ritschard, G. (2001). Performance dâ€™une heuristique dâ€™agreÂ´gation optimale bidimen-
sionnelle. Extraction des connaissances et apprentissage 1 (4), 185â€“196.
RNTI - 1
Patition BIC optimale
Ritschard, G. et D. A. Zighed (2002). QualiteÂ´ dâ€™ajustement dâ€™arbres dâ€™induction. Tech-
nical report, Groupe Gafo QualiteÂ´, CNRS, Paris. 16p.
Ritschard, G. et D. A. Zighed (2003). ModeÂ´lisation de tables de contingences par arbres
dâ€™induction. Revue des sciences et technologies de lâ€™information â€” ECA 17 (1â€“3),
381â€“392.
Ritschard, G., D. A. Zighed, et N. Nicoloyannis (2001). Maximisation de lâ€™association
par regroupement de lignes ou colonnes dâ€™un tableau croiseÂ´. Revue MatheÂ´matiques
Sciences Humaines 39 (154/155), 81â€“97.
Schwarz, G. (1978). Estimating the dimension of a model. The Annals of Statistics 6,
461â€“464.
SPSS (Ed.) (2001). Answer Tree 3.0 Userâ€™s Guide. Chicago : SPSS Inc.
Zighed, D. A. et R. Rakotomalala (2000). Graphes dâ€™induction : apprentissage et data
mining. Paris : Hermes Science Publications.
Summary
This paper is concerned with the partitioning of the predictor space best suited to
generate reliable estimates of class posteriors. This optimal partition has to face a
double goodness-of-fit and simplicity criteria. We thus focus on the Akaike (AIC)
and Bayesian (BIC) information criteria that specifically take these two aspects into
account. We show how they apply in our framework and then investigate how to reach
their optimal value. The paper provides a crude heuristic and studies its efficiency by
comparing the quasi optimum with the true optimum on a series of simulated tables.
The optimum provides useful insight on how much a partition, for instance the partition
provided by an induction tree algorithm, could be improved. This point is illustrated
with a real dataset.
RNTI - 1
