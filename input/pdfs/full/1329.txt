TUTORIEL
L’infe´rence baye´sienne pour l’analyse des
donne´es expe´rimentales
Bruno Lecoutre1
ERIS, Laboratoire de Mathe´matiques Raphae¨l Salem
UMR 6085 C.N.R.S. et Universite´ de Rouen
Avenue de l’Universite´, BP 12, 76801 Saint-Etienne-du-Rouvray
bruno.lecoutre@univ-rouen.fr
Internet : http ://www.univ-rouen.fr/LMRS/Persopage/Lecoutre/Eris
Re´sume´ Ce tutoriel se situe dans la ligne des articles pre´ce´demment publie´s dans
la Revue de Modulad : Lecoutre (1996b, 2005/1997, 2005) ; Lecoutre, Poitevineau
& Lecoutre (2005). Il s’appuie sur l’utilisation de programmes informatiques qui
ont e´galement fait l’objet d’une pre´sentation dans un nume´ro pre´ce´dent (Lecoutre
& Poitevineau, 2005). La motivation de ce tutoriel est avant tout me´thodologique,
et le choix du cadre baye´sien ne devrait pas paraˆıtre ide´ologique. Plus pre´cise´ment,
l’objectif est d’apporter aux questions essentielles souleve´es par l’analyse des donne´es
expe´rimentales des re´ponses mieux adapte´es que les tests de signification de l’hy-
pothe`se nulle. Base´es sur des de´finitions ope´rationnelles plus utiles que les proce´dures
traditionnelles (tests, intervalles de confiance), les me´thodes baye´siennes offrent une
souplesse conside´rable, en rendant tous les choix explicites. De plus, la philosophie
baye´sienne met en avant la ne´cessite´ de re´fle´chir sur l’information fournie par les
donne´es disponibles – “qu’est-ce que les donne´es ont a` dire ?” – au lieu d’appliquer
des proce´dures rituelles.
Des proce´dures baye´siennes de routine sont de´sormais faciles a` mettre en œuvre pour
toutes les situations courantes. Leurs re´sultats peuvent eˆtre pre´sente´s sous une forme
intuitivement se´duisante et facilement interpre´table. Elles ouvrent une nouvelle voie
prometteuse dans la me´thodologie statistique 1.
INTRODUCTION
La motivation me´thodologique
“The test provides neither the necessary nor the sufficient scope or type of
knowledge that basic scientific social research requires.” (Morrison & Henkel,
1969)
La motivation me´thodologique re´sulte de l’examen de l’e´tat actuel de l’utilisation
de l’infe´rence statistique dans la recherche expe´rimentale. Celle-ci est confronte´e a` une
situation paradoxale.
1Je remercie Jacques Poitevineau pour son aide dans la taˆche ingrate de relecture de ce texte. J’assume
l’entie`re responsabilite´ des fautes et erreurs qui peuvent subsister.
c© Revue MODULAD, 2006 -130- Nume´ro 35
Les tests ne re´pondent pas aux bonnes questions
D’une part, les tests de signification de l’hypothe`se nulle (en anglais, Null Hypothesis
Significance Tests, “NHST”) sont conside´re´s dans la plupart des publications scientifiques
comme une norme incontournable et apparaissent souvent comme une garantie de scienti-
ficite´. Mais, d’autre part, ces tests conduisent a` d’innombrables erreurs d’interpre´tations
et mauvais usages. Leur utilisation a d’ailleurs e´te´ explicitement proscrite par les scienti-
fiques les plus e´minents et les plus avertis, tant sur des arguments the´oriques que sur de
conside´rations me´thodologiques.
Pour interpre´ter leurs donne´es, les utilisateurs doivent recourir a` une synthe`se “na¨ıve”
des re´sultats des tests de signification avec d’autres informations, d’ou` un malaise qui va
grandissant. Pour re´pondre a` ce malaise, un processus de de´finition de nouvelles normes de
publication pour la recherche expe´rimentale a e´te´ engage´. C’est pourquoi l’e´poque actuelle
est une charnie`re cruciale.
Vers de nouvelles normes de publications
Des changements dans la fac¸on de rapporter les re´sultats expe´rimentaux sont de fait
de plus en plus exige´s par les revues expe´rimentales ceci dans tous les domaines. Ces
changements concernent tout particulie`rement la pre´sentation et l’interpre´tation de la
grandeur des effets (les “effect sizes”). Il s’agit de fournir des indicateurs de ces effets
ainsi que leurs estimations par intervalle (“interval estimates”), en plus ou a` la place des
tests.
En Psychologie par exemple, cette ne´cessite´ de changements a e´te´ rendue officielle par
l’American Psychological Association (APA, 2001). Les recommandations faites a` cette oc-
casion (voir Wilkinson et al., 1999) sont re´ve´latrices de ce que pourrait eˆtre l’e´volution des
pratiques. Mais, si on les examine en de´tail, elles apparaissent en fait a` la fois partiellement
redondantes et conceptuellement incohe´rentes. Ces recommandations ne peuvent en effet
qu’aboutir a` perpe´tuer des recettes et des rituels – calcul de puissance pour de´terminer les
effectifs, utilisation des “p-values” (on n’abandonne pas les tests), intervalles de confiance
(en plus des tests) – qui seraient combine´s sans fournir une re´elle pense´e statistique. On
peut craindre dans ces conditions que les utilisateurs de la statistique continuent a` se
focaliser sur la signification statistique du re´sultat – notamment en se demandant seule-
ment si l’intervalle de confiance contient la valeur de l’hypothe`se nulle – sans conside´rer
re´ellement l’information supple´mentaire apporte´e par cet intervalle.
“Consequently we automatically ask ourselves “won’t the Bayesian choice be
unavoidable ?” (Lecoutre et al., 2001)
Dans ces conditions, on ne peut que remettre en question le cadre conceptuel des
proce´dures d’infe´rence traditionnelles – c’est-a`-dire l’approche fre´quentiste – et nous de-
mander si l’approche baye´sienne ne sera pas toˆt ou tard incontournable.
Plan de l’expose´
La pre´sentation est organise´e en quatre parties.
Partie I - Les aspects conceptuels : Infe´rence fre´quentiste ou baye´sienne ? La
premie`re partie de ce tutoriel traitera des aspects conceptuels de base concernant les
c© Revue MODULAD, 2006 -131- Nume´ro 35
diffe´rences entre les approches fre´quentistes et baye´siennes. Je conclurai que pour l’ana-
lyse des donne´es expe´rimentales une approche baye´sienne “objective” est a` la fois de´sirable
et faisable. Dans ce cadre, je n’envisagerai donc qu’avec beaucoup de re´serves une ap-
proche “subjectiviste” ; j’e´carterai e´galement une conception prioritairement de´cisionnelle
de l’infe´rence statistique.
Partie II - La pratique : Quelques situations de base. L’objectif de la seconde
partie sera de de´montrer la faisabilite´ des me´thodes baye´siennes, a` partir d’un certain
nombre de situations de base. La pre´sentation sera essentiellement illustrative, et le moins
possible technique. Il s’agira d’introduire des proce´dures de routine a` partir de proble`mes
relativement simples d’infe´rence sur des proportions et des moyennes. On traitera a` la
fois la mise en œuvre pratique de ces proce´dures – a` l’aide de programmes informatiques
– et leurs apports conceptuels et me´thodologiques, tant pour l’analyse de donne´es que
pour la planification et la conduite des expe´riences. Dans chaque situation, les solutions
baye´siennnes seront mises en paralle`le avec les proce´dures fre´quentistes.
Je de´velopperai plus particulie`rement l’infe´rence sur des proportions. Les proble`mes de
comparaisons de moyennes – qui se pre´sentent traditionnellement en analyse de variance
– ont en effet e´te´ largement traite´s par ailleurs – notamment dans le cadre de ce que
nous appelons l’Analyse Baye´sienne des Comparaisons – et on pourra notamment se
rapporter pour comple´ter le pre´sent expose´ aux re´fe´rences suivantes : Lecoutre (1984,
1996a) ; Lecoutre et Poitevineau (2005) ; Lecoutre (2006).
Partie III - Les aspects techniques : Quelques outils de base. La troisie`me partie
sera technique. Il s’agira d’abord d’illustrer les principes des calculs formels ne´cessaires a`
l’infe´rence baye´sienne et de fournir quelques outils utiles pour ces calculs. On abordera
e´galement brie`vement des techniques de base d’inte´gration nume´rique – de´terministe ou
par simulation. Ces dernie`res techniques reveˆtent une importance de plus en plus grande
dans l’infe´rence baye´sienne (meˆme si elles ne sont pas limite´es a` celle-ci) ; elles permettent
en effet de re´soudre relativement facilement les proble`mes pratiques de calcul lie´s aux
situations les plus complexes. Une pre´sentation plus approfondie de´borderait le cadre du
pre´sent expose´ et serait plutoˆt l’objet d’un autre tutoriel.
Partie IV - Retour sur les aspects conceptuels : L’interface de l’infe´rence
fre´quentiste et de l’infe´rence baye´sienne. La quatrie`me partie s’adressera a` ceux
qui souhaitent approfondir les liens conceptuels et techniques entre les deux approches,
qui auront e´te´ mis en avant dans les diffe´rents exemples d’application.
En conclusion. Je reviendrai brie`vement sur les avantages de l’approche baye´sienne et
aborderai quelques the`mes “pour aller plus loin” et pre´parer a` d’autres lectures.
PARTIE I - LES ASPECTS
CONCEPTUELS :
INFE´RENCE FRE´QUENTISTE OU
BAYE´SIENNE?
c© Revue MODULAD, 2006 -132- Nume´ro 35
1 La probabilite´ et l’infe´rence statistique
De nos jours la probabilite´ a au moins deux de´finitions principales (de´ja` pre´sentes chez
Bernoulli, 1713).
1. La probabilite´ est la fre´quence sur le long terme de l’occurrence d’un
e´ve´nement, soit dans une suite d’essais re´pe´te´s, soit dans un ensemble de
syste`mes “identiquement” pre´pare´s 2.
C’est la conception fre´quentiste, qui semble faire de la probabilite´ une proprie´te´ observable
(“objective”), existant dans la nature inde´pendamment de nous.
2. La probabilite´ est une mesure du degre´ de croyance (ou de confiance) dans
l’occurrence d’un e´ve´nement ou dans la ve´racite´ d’une proposition.
C’est la conception baye´sienne. Il n’est souvent pas e´vident d’attribuer une probabilite´
fre´quentiste a` un e´ve´nement unique, puisque cela ne´cessite d’imaginer un ensemble de
re´fe´rence d’e´ve´nements ou une se´rie d’expe´riences re´pe´te´es afin d’obtenir des fre´quences
empiriques. Malheureusement, de tels ensembles sont rarement disponibles pour l’attribu-
tion des probabilite´s dans les proble`mes re´els. Par contraste la de´finition baye´sienne est
plus ge´ne´rale : il n’est pas conceptuellement proble´matique d’attribuer une probabilite´ a`
un e´ve´nement unique.
Les probabilite´s baye´siennes sont conside´re´es par certains comme le re´sultat d’une
appre´ciation subjective d’une situation par un observateur (Savage, 1954 ; de Finetti,
1974). Mais elle peuvent tout aussi bien servir a` de´crire une connaissance objective, en
particulier base´e sur des arguments de syme´trie ou sur des fre´quences.
On remarquera que la de´finition baye´sienne est en accord avec le sens du mot proba-
bilite´ dans le langage de tous les jours : la conception baye´sienne apparaˆıt donc beaucoup
plus proche de la fac¸on dont les gens raisonnent intuitivement en pre´sence d’incertitude
3.
1.1 Les termes du de´bat
“[. . .] whether the probabilities should only refer to data and be based on
frequency or whether they should also apply to hypotheses and be regarded
as measures of beliefs.” (Lindley, 1993)
2Dans une de´finition plus pre´cise, la probabilite´ est la valeur limite de la fre´quence dans une suite
infinie d’essais, mais c’est ici un point mineur.
3Pour ne prendre qu’un exemple, comment interpre´tez-vous l’indice de confiance (par exemple
4/5) figurant dans les bulletins me´te´orologiques fournis par me´te´o France ? Tous ceux que j’ai
interroge´s l’interpre`tent comme une probabilite´ baye´sienne : “il y a 4 chances sur 5 que la
pre´vision se re´alise”, alors que cet indice n’est pas du tout de´fini comme une telle probabi-
lite´ : voir http ://www.meteofrance.com/FR/glossaire/designation/1036 curieux view.jsp. On no-
tera que cette de´finition est re´serve´e aux “curieux”, ce qui favorise plus ou moins volontai-
rement l’interpre´tation baye´sienne. Il est inte´ressant a` ce propos de constater que le service
me´te´orologique d’Environnement Canada donne au contraire explicitement une de´finition baye´sienne
de la “probabilite´ de pre´cipitations”, de´finie comme “une estimation nume´rique subjective des
risques de pre´cipitations mesurables a` tout point du secteur vise´. Par exemple, si la probabi-
lite´ de pluie est de 40 p.100 pour aujourd’hui, il existe quatre chances sur 10 pour qu’il pleu-
ve” (http ://www.smc.ec.gc.ca/cd/brochures/probability f.cfm). Cela n’implique e´videmment pas que
cette estimation soit moins objective que l’indice de me´te´o France.
c© Revue MODULAD, 2006 -133- Nume´ro 35
L’infe´rence statistique fait typiquement intervenir a` la fois des quantite´s connues –
les donne´es observe´es – et des quantite´s inconnues – les parame`tres et les donne´es qui
n’ont pas e´te´ observe´es. Le de´bat se pose alors en ces termes : “est-ce que les probabilite´s
devraient seulement eˆtre relatives aux donne´es et eˆtre base´es sur des fre´quences ou est-ce
qu’elles doivent aussi d’appliquer aux parame`tres et eˆtre conside´re´es comme des mesures
de croyance ?”.
1.1.1 L’infe´rence fre´quentiste
Dans l’infe´rence fre´quentiste toutes les probabilite´s sont conditionnelles aux parame`tres
qui sont suppose´s connus. Cela conduit en particulier :
• aux tests de signification, dans lesquels la valeur d’au moins un parame`tre est fixe´e par
hypothe`se ;
• aux intervalles de confiance.
Mais les parame`tres ne peuvent pas et ne doivent pas eˆtre probabilise´s (des fre´quences
empiriques ne sont pas disponibles)
1.1.2 L’infe´rence baye´sienne
Dans l’infe´rence baye´sienne au contraire, les parame`tres peuvent aussi eˆtre probabi-
lise´s. Il en re´sulte des distributions de probabilite´ qui expriment notre incertitude :
• avant les observations (elle ne de´pendent pas des donne´es) : ce sont les probabilite´s
initiales ou (a priori) ;
• apre`s les observations (conditionnelles aux donne´es) : ce sont les probabilite´s re´vise´es,
finales ou a posteriori ;
• relatives a` des donne´es futures : ce sont les probabilite´s pre´dictives (avant ou apre`s les
observations).
Remarque sur la terminologie. Les appellations initiales et finales seront
pre´fe´re´es ici a` a priori et a posteriori qui renvoient davantage a` une conception
“subjective”. De meˆme l’appellation distribution (de probabilite´) sera pre´fe´re´e
a` loi qui e´voque une conception particulie`re du hasard et de la probabilite´.
2 Une illustration simple
Comme illustration simple, conside´rons la situation suivante. On suppose une po-
pulation finie d’effectif N = 20 avec une variable dichotomique “succe`s/e´chec” et une
proportion ϕ de succe`s qui est le parame`tre inconnu. Un e´chantillon de n = 5 observa-
tions – dont on supposera qu’il a e´te´ tire´ au sort sans remise – a e´te´ observe´, d’ou` les
donne´es connues :
0 0 0 1 0 n = 5 f = 1
5
Le raisonnement inductif est fondamentalement une ge´ne´ralisation d’une quantite´
connue – les donne´es – a` une quantite´ inconnue – ici le parame`tre ϕ.
c© Revue MODULAD, 2006 -134- Nume´ro 35
2.1 Solution fre´quentiste
Dans le cadre fre´quentiste nous n’avons pas de probabilite´s, et par conse´quent pas
d’infe´rence inductive possible.
De l’inconnu vers le connu
Aussi l’infe´rence fre´quentiste doit retourner la situation. Mais nous n’avons pas davan-
tage de probabilite´s. . . a` moins que nous ne fixions une valeur du parame`tre. Supposons
par exemple ϕ = 15/20 = 0.75. Nous obtenons alors des probabilite´s d’e´chantillonnage,
qui peuvent eˆtre de´finies comme des fre´quences mettant en jeu un tre`s grand nombre de
re´pe´titions imaginaires des observations. Nous pouvons obtenir ces fre´quences en simulant
un grand nombre de tirages sans remise de 5 boules dans une urne contenant 20 boules,
dont 15 d’une couleur et 5 d’une autre couleur. Mais il n’est pas ne´cessaire de recourir a`
une de´finition fre´quentiste pour obtenir les probabilite´s d’e´chantillonnage.
Ici il y a 15 504 e´chantillons diffe´rents possibles (dont un particulier a e´te´ observe´)
et les probabilite´s d’e´chantillonnage sont donne´es par une distribution Hyperge´ome´trique.
Le tableau ci-apre`s donne ces probabilite´s, ainsi que les fre´quences obtenues par deux
simulations, l’une de 10 000 tirages et l’autre de 1 000 000 de tirages.
ϕ = 15/20 = 0.75
Nombre de Nombres Probabilite´s Fre´quences
succe`s d’e´chantillons d’e´chantillonnage 104 tirages 106 tirages
f = 0/5 1/15 504 = 0.00006 0 0.00006
f = 1/5 75/15 504 = 0.0048 0.0054 0.0049
f = 2/5 1 050/15 504 = 0.0677 0.066 0.068
f = 3/5 4 550/15 504 = 0.2935 0.294 0.293
f = 4/5 6 825/15 504 = 0.4402 0.447 0.441
f = 5/5 3 003/15 504 = 0.1937 0.187 0.194
2.1.1 Test de signification
Ces probabilite´s d’e´chantillonnage sont utilise´es pour de´finir un test de significa-
tion. La valeur du parame`tre est fixe´e par l’hypothe`se nulle, par exemple H0 : ϕ =
0.75. Si ϕ = 0.75, on trouve dans seulement 0.49% des re´pe´titions (soit la proportion
0.0049=0.00006+0.0049) une valeur infe´rieure ou e´gale a` l’observation (f ≤ 1/5). Le
re´sultat est dit “significatif” (p = 0.0049) : sur la base des donne´es observe´es, l’hypothe`se
nulle est rejete´e (je n’entre pas ici dans la discussion “test unilate´ral/bilate´ral”, ni dans
le choix du “risque” α qui ne sont pas pertinents pour mon propos).
“A hypothesis that may be true may be rejected because it has not predicted
observable results that have not occurred.” (Jeffreys, 1961)
Mais, comme le soulignait ironiquement Jeffreys, cette conclusion est base´e sur la proba-
bilite´ des e´chantillons qui n’ont pas e´te´ observe´s.
Conside´rons un autre exemple d’hypothe`se nulle, H0 : ϕ = 0.50.
c© Revue MODULAD, 2006 -135- Nume´ro 35
ϕ = 10/20 = 0.50
Nombre de Nombres Probabilite´s
succe`s d’e´chantillons d’e´chantillonnage
f = 0/5 252/15 504 = 0.016
f = 1/5 2 100/15 504 = 0.135
f = 2/5 5 400/15 504 = 0.348
f = 3/5 5 400/15 504 = 0.348
f = 4/5 2 100/15 504 = 0.135
f = 5/5 252/15 504 = 0.016
Dans ce cas, si ϕ = 0.50, on trouve dans 15.2% des re´pe´titions (soit la proportion 0.0152
= 0.016+0.135) une valeur infe´rieure ou e´gale a` l’observation (f ≤ 1/5). Le re´sultat est
dit “non significatif” (p = 0.152) : sur la base des donne´es observe´es, l’hypothe`se nulle
n’est pas rejete´e A l’e´vidence cela ne prouve pas que ϕ = 0.50 !
2.1.2 Intervalle de confiance
Un intervalle de confiance peut eˆtre construit comme l’ensemble des valeurs possibles
du parame`tre qui ne sont pas rejete´es par les donne´es a` un seuil α fixe´. Par exemple, pour
α = 0.05, nous obtenons ici l’intervalle de confiance 95% :
[0.05, 0.60]
Comment interpre´ter la confiance ? L’interpre´tation est base´e sur l’e´nonce´ universel :
“Quelle que soit la valeur fixe´e du parame`tre, dans 95% (au moins) des re´pe´titions
l’intervalle qui serait calcule´ contiendrait cette valeur.”
Cette proprie´te´ peut eˆtre ve´rifie´e par exemple pour ϕ = 0.50 :
Re´pe´titions imaginaires des observations
Valeur Intervalle Probabilite´
observe´e de confiance d’e´chantillonnage
f = 0 (0/5) [0 , 0.45] 0.016
f = 0.20 (1/5) [0.05 , 0.60] 0.135∗
f = 0.40 (2/5) [0.10 , 0.75] 0.348∗
f = 0.60 (3/5) [0,15 , 0.90] 0.348∗
f = 0.80 (4/5) [0,20 , 0.95] 0.135∗
f = 1 (5/5) [0.25 , 1 ] 0.016∗
∗contient ϕ = 0.50
Ici dans 98.4% des re´pe´tions l’intervalle contient la valeur fixe´e ϕ = 0.50.
Mais cette interpre´tation est pour le moins e´trange puisqu’elle ne fait pas intervenir
les donne´es observe´es !
2.2 Solution baye´sienne
Du connu vers l’inconnu
c© Revue MODULAD, 2006 -136- Nume´ro 35
Revenons au raisonnement inductif, en partant des donne´es connues, et en adoptant le
point de vue baye´sien. Nous pouvons utiliser, en plus des probabilite´s d’e´chantillonnage,
des probabilite´s qui expriment notre incertitude sur toutes les valeurs possibles du pa-
rame`tre.
Dans l’infe´rence baye´sienne, nous conside´rons les probabilite´s fre´quentistes – non pas
d’e´chantillons imaginaires – mais des donne´es observe´es, ceci pour toutes les valeurs
possibles du parame`tre. C’est la fonction de vraisemblance Pr(f = 1/5 |ϕ), que l’on
notera encore v(ϕ | donne´es).
Pr(f = 1/5 |ϕ) = v(ϕ | donne´es)
↪→ Fonction de vraisemblance
ϕ = 0/20 → 0 ϕ = 10/20 → 0.135
ϕ = 1/20 → 0.250 ϕ = 11/20 → 0.089
ϕ = 2/20 → 0.395 ϕ = 12/20 → 0.054
ϕ = 3/20 → 0.461 ϕ = 13/20 → 0.029
ϕ = 4/20 → 0.470 ϕ = 14/20 → 0.014
ϕ = 5/20 → 0.440 ϕ = 15/20 → 0.005
ϕ = 6/20 → 0.387 ϕ = 16/20 → 0.001
ϕ = 7/20 → 0.323 ϕ = 17/20 → 0
ϕ = 8/20 → 0.255 ϕ = 18/20 → 0
ϕ = 9/20 → 0.192 ϕ = 19/20 → 0
ϕ = 20/20 → 0
2.2.1 Probabilite´s initiales
Nous choisissons des probabilite´s initiales avant les observations, par exemple
Pr(ϕ)
↪→ Probabilite´s initiales (avant les observations)
Pr(ϕ = 0/20) = 0.00000001 Pr(ϕ = 10/20) = 0.117
Pr(ϕ = 1/20) = 0.0000003 Pr(ϕ = 11/20) = 0.160
Pr(ϕ = 2/20) = 0.000005 Pr(ϕ = 12/20) = 0.180
Pr(ϕ = 3/20) = 0.00004 Pr(ϕ = 13/20) = 0.166
Pr(ϕ = 4/20) = 0.0003 Pr(ϕ = 14/20) = 0.124
Pr(ϕ = 5/20) = 0.001 Pr(ϕ = 15/20) = 0.075
Pr(ϕ = 6/20) = 0.005 Pr(ϕ = 16/20) = 0.035
Pr(ϕ = 7/20) = 0.015 Pr(ϕ = 17/20) = 0.012
Pr(ϕ = 8/20) = 0.035 Pr(ϕ = 18/20) = 0.003
Pr(ϕ = 9/20) = 0.071 Pr(ϕ = 19/20) = 0.0005
Pr(ϕ = 20/20) = 0.00004
2.2.2 Probabilite´s conjointes
Par un simple produit de la vraisemblance et des probabilite´s initiales, nous obtenons
les probabilite´s conjointes des valeurs du parame`tre et des donne´es
c© Revue MODULAD, 2006 -137- Nume´ro 35
Pr(ϕ et f = 1/5) = Pr(f = 1/5 |ϕ)× Pr(ϕ)
Produit : vraisemblance × probabilite´s initiales
↪→ Probabilite´s conjointes
Pr(ϕ = 0/20 et f = 1/5) = 0 Pr(ϕ = 10/20 et f = 1/5) = 0.016
Pr(ϕ = 1/20 et f = 1/5) = 0.00000008 Pr(ϕ = 11/20 et f = 1/5) = 0.014
Pr(ϕ = 2/20 et f = 1/5) = 0.000005 Pr(ϕ = 12/20 et f = 1/5) = 0.010
Pr(ϕ = 3/20 et f = 1/5) = 0.00002 Pr(ϕ = 13/20 et f = 1/5) = 0.005
Pr(ϕ = 4/20 et f = 1/5) = 0.0001 Pr(ϕ = 14/20 et f = 1/5) = 0.002
Pr(ϕ = 5/20 et f = 1/5) = 0.0004 Pr(ϕ = 15/20 et f = 1/5) = 0.0004
Pr(ϕ = 6/20 et f = 1/5) = 0.002 Pr(ϕ = 16/20 et f = 1/5) = 0.00003
Pr(ϕ = 7/20 et f = 1/5) = 0.005 Pr(ϕ = 17/20 et f = 1/5) = 0
Pr(ϕ = 8/20 et f = 1/5) = 0.009 Pr(ϕ = 18/20 et f = 1/5) = 0
Pr(ϕ = 9/20 et f = 1/5) = 0.014 Pr(ϕ = 19/20 et f = 1/5) = 0
Pr(ϕ = 20/20 et f = 1/5) = 0
2.2.3 Probabilite´s pre´dictives
La somme des probabilite´s conjointes donne la probabilite´ pre´dictive marginale des
donne´es, avant les observations
Pr(f = 1/5) =
∑
ϕ Pr(ϕ et f = 1/5) = 0.078
Somme des probabilite´s conjointes
↪→ Probabilite´ pre´dictive
Ce re´sultat est tre`s intuitif puisque la probabilite´ pre´dictive est une moyenne ponde´re´e de
la fonction de vraisemblance, les poids e´tant les probabilite´s initiales.
2.2.4 Probabilite´s finales
“Bayesian statistics is difficult in the sense that thinking is difficult.” (Berry,
1997)
Enfin nous calculons les probabilite´s finales apre`s les observations, par une simple
application de la de´finition des probabilite´s conditionnelles
Pr(ϕ | f = 1/5) = Pr(ϕ et f=1/5)
Pr(f=1/5)
Rapport : probabilite´ conjointe / probabilite´ pre´dictive
↪→ Probabilite´s finales (apre`s les observations)
Pr(ϕ = 0 | f = 1/5) = 0 Pr(ϕ = 0.50 | f = 1/5) = 0.205
Pr(ϕ = 0.05 | f = 1/5) = 0.000001 Pr(ϕ = 0.55 | f = 1/5) = 0.180
Pr(ϕ = 0.10 | f = 1/5) = 0.0006 Pr(ϕ = 0.60 | f = 1/5) = 0.128
Pr(ϕ = 0.15 | f = 1/5) = 0.0003 Pr(ϕ = 0.65 | f = 1/5) = 0.064
Pr(ϕ = 0.20 | f = 1/5) = 0.001 Pr(ϕ = 0.70 | f = 1/5) = 0.026
Pr(ϕ = 0.25 | f = 1/5) = 0.005 Pr(ϕ = 0.75 | f = 1/5) = 0.005
Pr(ϕ = 0.30 | f = 1/5) = 0.026 Pr(ϕ = 0.80 | f = 1/5) = 0.0004
Pr(ϕ = 0.35 | f = 1/5) = 0.064 Pr(ϕ = 0.85 | f = 1/5) = 0
Pr(ϕ = 0.40 | f = 1/5) = 0.115 Pr(ϕ = 0.90 | f = 1/5) = 0
Pr(ϕ = 0.45 | f = 1/5) = 0.179 Pr(ϕ = 0.95 | f = 1/5) = 0
Pr(ϕ = 1 | f = 1/5) = 0
c© Revue MODULAD, 2006 -138- Nume´ro 35
Les probabilite´s finales sont donc simplement proportionnelles au produit des proba-
bilite´s initiales et de la vraisemblance :
Pr(ϕ | donne´es) ∝ v(ϕ | donne´es)× Pr(ϕ)
Leur somme devant eˆtre e´gale a` 1 (par de´finition de la probabilite´), ce produit est “nor-
malise´” en divisant par la somme :
Pr(donne´es) =
∑
ϕ
v(ϕ | donne´es)× Pr(ϕ)
Dans le cas continu, les probabilite´s discre`tes sont remplace´es par des densite´s, par
exemple si ϕ peut prendre toutes les valeurs re´elles dans l’intervalle [0,1] :
p(ϕ | donne´es) ∝ v(ϕ | donne´es)× p(ϕ)
et la somme par une inte´grale :
p(donne´es) =
∫ 1
0
v(ϕ | donne´es)× p(ϕ) dϕ
Ceci se ge´ne´ralise directement au cas de plusieurs parame`tres.
3 Nouvelles difficulte´s avec les intervalles de confiance
Comme re´sultat d’un processus de´ja` bien engage´, les intervalles de confiance pour-
raient rapidement devenir une norme obligatoire dans les publications expe´rimentales. En
pratique, deux probabilite´s peuvent eˆtre associe´es de manie`re routinie`re a` un intervalle
d’estimation pour un parame`tre calcule´ a` partir des donne´es observe´es.
• La premie`re probabilite´ est “la proportion des intervalles qui contiennent le parame`tre
pour un grand nombre de re´pe´titions” ; elle est usuellement appele´e la probabilite´ de
couverture (ou de recouvrement) fre´quentiste.
• La seconde probabilite´ est la “probabilite´ baye´sienne que cet intervalle contienne le
parame`tre” (pour une certaine distribution initiale).
Dans l’approche fre´quentiste, il est interdit d’utiliser la seconde probabilite´, tandis
que dans l’approche baye´sienne, les deux probabilite´s sont valides.
Pour de nombreuses raisons dues a` leur conception fre´quentiste, les intervalles de
confiance peuvent difficilement apparaˆıtre comme “LA me´thode ultime”. En effet la raison
qui les rend attrayants re´sulte d’une incompre´hension fondamentale. Il est si e´trange
de traiter les donne´es comme ale´atoires meˆme apre`s avoir recueilli les observations que
l’interpre´tation fre´quentiste orthodoxe des intervalles de confiance n’a pas de sens pour la
plupart des utilisateurs. C’est indiscutablement l’interpre´tation baye´sienne (naturelle) des
intervalles de confiance qui les rend attrayants. Ironiquement cette interpre´tation he´re´tique
est encourage´e par la duplicite´ de la plupart des formateurs en statistique qui les tole`rent
et meˆme les utilisent. Par exemple, Pagano (1990, page 288), dans un ouvrage dont le
titre affiche l’objectif de faire comprendre la statistique (“understanding statistics. . .”),
de´crit un intervalle de confiance 95% comme un intervalle “such that the probability is
0.95 that the interval contains the population value”.
Sous une autre forme, on voit tre`s couramment des interpre´tations telles que “avec 5%
de risque de se tromper, on peut dire que pi est dans l’intervalle [0.27,0.42]”.
c© Revue MODULAD, 2006 -139- Nume´ro 35
D’autre auteurs affirment que l’interpre´tation fre´quentiste “correcte” qu’ils de´fendent
peut eˆtre exprime´e comme “nous pouvons eˆtre confiants a` 95% que le parame`tre est
contenu dans l’intervalle” ; par exemple Kirk (1982, page 43) e´nonce “we can be 95%
confident that the population mean is between 114.06 and 119.94”.
Il est difficile d’imaginer que les lecteurs puissent comprendre que “confiant” renvoie a`
une conception fre´quentiste de la probabilite´ !
“We [statisticians] will all be Bayesians in 2020, and then we can be a united
profession.” Lindley (in Smith, 1995, page 317))
La litte´rature est remplie d’interpre´tations baye´siennes des intervalles de confiance et
des tests de signification. Toutes les tentatives des fre´quentistes pour corriger ces “erre-
ments” se sont re´ve´le´es vaines : c’est un combat perdu d’avance. En fait la plupart utili-
sateurs de l’infe´rence statistique sont des baye´siens sans le savoir (Lecoutre, 1997/2005) !
4 L’approche baye´sienne “objective”
4.1 Ou` est l’objectivite´ ?
“A common misconception is that Bayesian analysis is a subjective theory ;
this is neither true historically nor in practice. The first Bayesians, Bayes (see
Bayes (1763)) and Laplace (see Laplace (1812)) performed Bayesian analysis
using a constant prior distribution for unknown parameters. . .” (Berger, 2004,
page 3)
L’infe´rence statistique fre´quentiste s’auto-proclame “objective” contrairement a` l’infe´rence
baye´sienne qui serait ne´cessairement “subjective”. Cette affirmation se trouve renforce´e
par certaines conceptions baye´siennes extre´mistes, dans lesquelles les opinions – et non
seulement les connaissances a priori – pourraient (devraient) eˆtre inte´gre´es dans l’infe´rence
scientifique. Il n’est donc pas e´tonnant que la critique la plus commune adresse´e par
les fre´quentistes a` l’approche baye´sienne soit la ne´cessite´ de probabilite´s initiales. Il est
e´videmment facile, dans l’exemple pre´ce´dent, de choisir des probabilite´s initiales quel-
conques – ce que j’ai fait a` titre d’illustration des calculs. Quelqu’un de mal intentionne´
pourra alors dire (a` juste titre ?) que l’on peut dans ce cas obtenir “ce que l’on veut”.
“But the primary aim of a scientific experiment is not to precipitate decisions,
but to make an appropriate adjustment in the degree to which one accepts,
or believes, the hypothesis or hypotheses being tested.” (Rozeboom, 1960, in
Morrison & Henkel, 1970, page 221)
Une autre difficulte´ vient de l’insistance de certains the´oriciens baye´siens a` vouloir
faire de´pendre l’infe´rence statistique de la “The´orie de la De´cision”. S’il peut eˆtre difficile
et sujet a` critique d’assigner les probabilite´s initiales, il est encore bien plus proble´matique
de choisir une fonction de couˆt.
La conse´quence de cette mise en avant des aspects subjectifs de l’infe´rence baye´sienne
et d’une approche de´cisionnelle, a e´te´ d’obscurcir sa contribution a` l’analyse des donne´es
expe´rimentales. En fait la de´finition baye´sienne peut parfaitement eˆtre utilise´e pour de´crire
une “connaissance objective”, en particulier base´e sur des arguments de syme´trie ou sur
des donne´es de fre´quences. Il ne s’agit pas d’affirmer qu’une analyse statistique peut eˆtre
c© Revue MODULAD, 2006 -140- Nume´ro 35
entie`rement objective : elle met ne´cessairement en jeu des e´le´ments subjectifs – notam-
ment le choix du mode`le – et comporte en fait une part de conventions. Mais l’infe´rence
statistique baye´sienne n’est pas moins objective que l’infe´rence fre´quentiste. C’est meˆme
le contraire dans de nombreux contextes.
4.2 L’infe´rence fiducio-baye´siennne
Il existe une voie, de plus en plus reconnue, qui vise a` concilier la the´orie baye´sienne
avec la conception fre´quentiste. Dans cette perspective, l’approche de´veloppe´e par Jef-
freys dans les anne´es trente (Jeffreys, 1961/1939) a un statut privilegie´. Dans la ligne de
Laplace (1986/1825), la philosophie de cette approche est de choisir les probabilite´s ini-
tiales en e´cartant toute connaissance e´ventuelle sur la valeur du parame`tre. En pratique,
ces probabilite´s initiales “non informatives” sont des distributions vagues qui, a priori ne
favorisent aucune valeur, aucune hypothe`se, particulie`re. En conse´quence elles laissent les
donne´es “parler pour elles-meˆmes”.
“1. A major goal of statistics (indeed science) is to find a completely coherent
objective Bayesian methodology for learning from data. This is exemplified by
the attitudes of Jeffreys (1961) and Jaynes (1999 [2003]).
2. Objective Bayesian analysis is the best method for objectively synthesizing
and communicating the uncertainties that arise in a specific scenario, but is
not necessarily coherent in a more general sense.
My general view is that 1) is not attainable ; 2) is often attainable and should
be done if possible.” (Berger, 2004, page 2)
Sous cette forme le paradigme baye´sien fournit, sinon des me´thodes objectives et
comple`tement cohe´rentes, au moins des me´thodes de re´fe´rence, pleinement justifie´es et
approprie´es pour la communication scientifique. En outre, dans les situations courantes
ou` l’on utilise traditionnellement les tests t, F ou χ2, ces me´thodes sont tre`s faciles a`
mettre en œuvre. Elles peuvent maintenant eˆtre utilise´es aussi aise´ment que ces tests,
tout en procurant des avantages conceptuels et me´thodologiques conside´rables.
“A widely accepted objective Bayes theory, which fiducial inference was inten-
ded to be, would be of immense theoretical and practical importance.” (Efron,
1998)
Dans le but de les promouvoir, il nous a semble´ important de leur donner un nom plus
explicite que standard, non informatives, de re´fe´rence, conventionnelles, etc. (Lecoutre,
Lecoutre & Poitevineau, 2001). Nous les appelons
fiducio-baye´siennes.
“The statistics profession, in general, hurts itself by not using attractive names
for its methodologies, and we should start systematically accepting the ‘ob-
jective Bayes’ name before it is co-opted by others.” (Berger, 2004, page 3)
Avec une motivation similaire, Berger, 2004 de´fend l’appellation
baye´siennes objectives.
c© Revue MODULAD, 2006 -141- Nume´ro 35
Dans ce qui suit j’utiliserai ces deux appellations, en e´vitant toutefois l’appellation
fiducio-baye´siennes dans le cas de l’infe´rence sur les proportions, pour lequel elle ne´cessite
une discussion particulie`re (qui est aborde´e dans la partie IV).
PARTIE II - LA PRATIQUE :
QUELQUES SITUATIONS DE BASE
Programmes informatiques. Les programmes informatiques utilise´s pour
la mise en œuvre des me´thodes sont regroupe´s dans le logiciel LePAC, qui
peut eˆtre te´le´charge´ a` l’adresse
http ://www.univ-rouen.fr/LMRS/Persopage/Lecoutre/Eris
On en trouvera une pre´sentation dans un nume´ro pre´ce´dent de la Revue de
Modulad (Lecoutre & Poitevineau, 2005). Dans ce qui suit, sont fournis des
e´crans (ou plus souvent des extraits d’e´crans) des programmes utilise´s. Ceux-ci
sont pre´ce´de´s du nom du programme utilise´
LesDistributions
LesProportions LeB-A-Baye´sien
LesMoyennes LesEffectifs
ainsi que d’un mode d’emploi pour obtenir les re´sultats pre´sente´s.
5 Infe´rence sur une proportion
L’objectif de ce premier exemple est de pre´senter une “transition en douceur” des
proce´dures fre´quentistes traditionnelles vers les proce´dures baye´siennes. Techniquement
simple, il permettra d’illustrer en de´tail la me´thodologie baye´sienne.
5.1 Le proble`me : Planification et conduite d’une expe´rimentation
Supposons la situation suivante. Un colle`gue enseignant “fre´quentiste” m’affirme avoir
de´veloppe´ une me´thode d’enseignement individuel de l’intervalle de confiance conduisant a`
un taux e´leve´ d’interpre´tations correctes. Nous convenons que sa me´thode est efficace si le
taux d’interpre´tations correctes (“succe`s”) ϕ apre`s l’enseignement est supe´rieur a` 0.85, et
qu’elle est inefficace si ce taux est infe´rieur a` 0.70. Ma probabilite´ a priori que la me´thode
soit inefficace est si e´leve´e que je pense qu’il n’est pas ne´cessaire de recueillir des donne´es.
Bien entendu mon colle`gue ne peut pas eˆtre convaincu par ce subjectivisme flagrant et
il propose de planifier une expe´rimentation dans le cadre fre´quentiste traditionnel de
Neyman-Pearson.
c© Revue MODULAD, 2006 -142- Nume´ro 35
5.2 Une solution fre´quentiste : Test binomial et test d’interrup-
tion stochastique
5.2.1 La planification de l’expe´rience
Conside´rant l’hypothe`se nulle H0 : ϕ = 0.70, il de´cide d’utiliser un test binomial
unilate´ral pour un e´chantillon de taille fixe´ avec des probabilite´s d’erreurs de Types I et
II respectivement e´gales a` α = 0.05 et β = 0.20, soit une puissance 1 − β = 0.80 pour
l’hypothe`se alternative Ha : ϕ = 0.85 (celle qu’il souhaite accepter !). Il correspond a` ces
conditions un effectif de l’e´chantillon n = 59, pour lequel le test binomial rejette H0 au
seuil 0.05 si le nombre de succe`s observe´ a est plus grand que 47.
En effet, pour un e´chantillon de taille n, la probabilite´ d’observer a succe`s est donne´e
par la distribution Binomiale
a|ϕ ∼ Bin(ϕ, n)
Pr(a|ϕ) = (na)ϕa(1− ϕ)n−a
soit la fonction de vraisemblance
v(ϕ | donne´es) ∝ ϕa(1− ϕ)n−a.
Pour n = 59 (que l’on trouve par ite´rations successives), on obtient :
Pr(a > 47 | H0 : ϕ = 0.70) = 0.035 < 0.05 (α)
Pr(a > 47 | Ha : ϕ = 0.85) = 0.834 > 0.80 (1− β)
LesDistributions
Dans LePAC activez le menu LesDistributions et le sous-menu Binomiale - Stan-
dard, ce qui affiche la feneˆtre pour la distribution Binomiale. Entrez dans les champs
approprie´s les parame`tres de la distribution :
• pour ϕ : 0.70 (ou simplement .7)
• pour n : 59
Se´lectionnez les boutons d’option
• Pr(X>x)
• probabilite´
Entrez dans le champ probabilite´ : 0.05 et appuyez sur touche “Entre´e” du clavier (ou
cliquez sur le bouton Calculer). Vous obtenez la premie`re figure ci-apre`s.
Pour la seconde figure, recommencez avec 0.85 pour ϕ et 0.80 pour la probabilite´.
Vous pouvez se´lectionner le nombre de de´cimales voulues.
Pour obtenir une probabilite´ associe´e a` une valeur donne´e, se´lectionnez le bouton d’option
• Limite
et entrez dans le champ limite la valeur dont vous voulez la probabilite´
c© Revue MODULAD, 2006 -143- Nume´ro 35
Il convient de noter qu’en raison du caracte`re discret de la distribution, le taux d’erreur
et la puissance re´els ne peuvent pas eˆtre e´gaux a` α et 1−β mais leur sont respectivement
infe´rieur et supe´rieur.
Je re´ussis a` convaincre mon colle`gue qu’il serait pre´fe´rable d’arreˆter l’expe´rimentation
avant son terme si sa me´thode se re´ve`le inefficace (compte tenu du fait que celle-ci ne´cessite
une enseignement individuel et est lourde a` mettre en œuvre). En conse´quence il planifie
une analyse interme´diaire apre`s l’inclusion de 20 sujets. Les notations sont re´sume´es dans
le tableau suivant
nombre de
effectif succe`s erreurs
Donne´es interme´diaires n1 = 20 a1 b1 = n1 − a1
Donne´es futures n2 = 39 a2 b2 = n2 − a2
Donne´es comple`tes n = 59 a = a1 + a2 b = n− a
5.2.2 Le test d’interruption stochastique et la puissance conditionnelle
Le cadre traditionnel de Neyman-Pearson ne´cessitant la spe´cification de toutes les
possibilite´s avant le recueil des donne´es, il pre´voit d’effectuer un “test d’interruption sto-
chastique” (stochastically curtailed test). L’interruption stochastique sugge`re de stopper
une expe´rience a` une e´tape interme´diaire quand l’information disponible de´termine le
re´sultat de l’expe´rience avec une probabilite´ e´leve´e, soit sous H0 soit sous Ha.
La puissance conditionnelle a` l’analyse interme´diaire est de´finie comme la probabi-
lite´, e´tant donne´ ϕ et les donne´es disponibles, que le test rejette H0 au terme pre´vu de
l’expe´rience.
(1) A l’analyse interme´diaire, l’expe´rience est interrompue et on rejette H0 si la puissance
conditionnelle a` la valeur spe´cifie´e par l’hypothe`se nulle est e´leve´e, disons supe´rieure a`
0.80. Dans notre exemple, meˆme si apre`s 20 observations on n’a observe´ que des succe`s
(a1 = 20) nous n’arreˆtons pas l’expe´rience, car la probabilite´ de rejeter H0 au terme pre´vu
– donne´e par la distribution Bin(0.70, 39) – est infe´rieure a` 0.80
Pr(a > 47 |H0 : ϕ = 0.70 and a1 = 20) = Pr(a2 > 27 |H0 : ϕ = 0.70) = 0.482 < 0.80
(2) De manie`re similaire, a` l’analyse interme´diaire, l’expe´rience est interrompue et on
accepte H0 si la puissance conditionnelle a` la valeur spe´cifie´e par l’hypothe`se alternative –
donne´e par la distribution Bin(0.85, 39) – est faible, disons infe´rieure a` 0.20. Par exemple,
si 12 succe`s sont observe´es apre`s 20 observations, cette re`gle sugge`re d’arreˆter l’expe´rience
et d’accepter l’hypothe`se nulle
Pr(a > 47 |Ha : ϕ = 0.85 and a1 = 12) = Pr(a2 > 35 |Ha : ϕ = 0.85) = 0.143 < 0.20
c© Revue MODULAD, 2006 -144- Nume´ro 35
Une critique a` l’adresse de cette proce´dure est qu’il ne semble gue`re pertinent de
conside´rer une pre´diction qui est base´e sur des hypothe`ses qui peuvent ne plus eˆtre plau-
sibles e´tant donne´ les donne´es disponibles. En fait la proce´dure ignore purement et sim-
plement la connaissance sur le parame`tre obtenue au moment de l’analyse interme´diaire.
5.3 Une solution hybride : la puissance pre´dictive
Pour re´pondre a` cette critique, de nombreux auteurs ont de´fendu l’ide´e de calculer la
puissance pre´dictive, c’est-a`-dire de moyenner la puissance conditionnelle sur toutes les
valeurs du parame`tre par un calcul baye´sien. Cela nous conduit a` une approche baye´sienne,
mais en gardant la proce´dure de test fre´quentiste pour l’analyse des donne´es.
Formellement, on utilise les donne´es disponibles a` l’analyse interme´diaire et la distribu-
tion finale de ϕ qui en re´sulte. La solution la plus simple est de choisir comme distribution
initiale une distribution conjugue´e
ϕ ∼ Beˆta (a0, b0)
L’avantage est que la distribution finale est e´galement une distribution Beˆta (ce qui
explique l’appellation “conjugue´e”). Les “poids” initiaux a0 et b0 s’ajoutent aux effectifs
observe´s a1 et b1, soit
ϕ | a1 ∼ Beˆta (a1 + a0, b1 + b0)
et la distribution pre´dictive, qui est un me´lange de distributions Binomiales, s’appelle
tout naturellement une distribution Beˆta-Binomiale
a2 | a1 ∼ Beˆta-Bin (a1 + a0, b1 + b0;n2)
Pour obtenir la puissance pre´dictive, on choisit une distribution initiale non informa-
tive. Celle-ci correspond a` des poids a0 et b0 faibles, compris entre 0 et 1
4. Ici, je retiendrai
la distribution initiale
ϕ ∼ Beˆta (0, 1)
un choix qui est cohe´rent avec la proce´dure de test utilise´e : j’y reviendrai plus loin.
Reprenons l’exemple traite´ ci-dessus en (1), soit n1 = 20 et a1 = 20. La probabilite´
pre´dictive de rejeter H0 au terme pre´vu (n = 59) prend explicitement en compte les
donne´es disponibles (aucune erreur n’a e´te´ observe´e). Elle est donne´e par la distribution
Beˆta-Bin (20, 1; 39) et est sans surprise largement supe´rieure a` la probabilite´ conditionnelle
a` la valeur spe´cifie´e par l’hypothe`se nulle (ϕ = 0.70)
Pr(a > 47 | a1 = 20) = Pr(a2 > 27 | a1 = 20) = 0.997 > 0.80
d’ou` la de´cision d’interrompre l’expe´rience et de rejeter H0.
LesDistributions
Dans LePAC activez le menu LesDistributions et le sous-menu Beˆta - Binomiale,
ce qui affiche la feneˆtre pour la distribution Beˆta-Binomiale (ou si la feneˆtre est de´ja` ou-
verte pour une autre distribution, cliquez sur le bouton correspondant a` cette distribution
pour la changer). Entrez dans les champs approprie´s les parame`tres de la distribution :
4La distribution Beˆta (a0, b0) n’est en toute rigueur de´finie que si a0 et b0 sont strictement positifs.
Lorque a0 ou b0 est nul, la densite´ est impropre (
∫ 1
0
p(ϕ)dϕ = +∞), mais cela n’empeˆche pas le calcul
de la densite´ finale qui sera, sauf cas particuliers, une densite´ propre. En tout e´tat de cause, il ne
s’agit que d’un proble`me the´orique, car en pratique, une distribution “propre” obtenue en remplac¸ant
0 par une valeur  tre`s petite ne fera aucune diffe´rence.
c© Revue MODULAD, 2006 -145- Nume´ro 35
• pour α : 20
• pour β : 1
• pour n : 59
Se´lectionnez les boutons d’option
• Pr(X>x)
• limite
Entrez dans le champ limite : 27 et appuyez sur touche “Entre´e” du clavier (ou cliquez
sur le bouton Calculer). Vous obtenez la figure ci-apre`s.
Cette probabilite´ pre´dictive est une moyenne ponde´re´e des probabilite´s conditionnelles
a` ϕ (les poids e´tant donne´s par la distribution finale)
Pr(a > 47 | a1 = 20 et ϕ) = Pr(a2 > 27 | a1 = 20 et ϕ)
dont quelques exemples sont
ϕ Pr(a > 47 | a1 = 20 et ϕ)
1 1
0.95 0.9999997
0.85 0.990
0.70 0.482
Cette approche de la puissance pre´dictive e´tant une approche hybride n’est pas tre`s
satisfaisante. En particulier elle ne nous donne pas une information baye´sienne directe
sur ϕ : la distribution finale n’est utilise´e que comme interme´diaire de calcul. Ce qui est
troublant est qu’une de´cision (accepter H0 ou accepter Ha) est prise a` l’analyse terminale
– ou e´ventuellement a` l’analyse interme´diaire – meˆme si la proportion observe´e est situe´e
dans la re´gion de non conclusion [0.70 , 0.85], auquel cas on n’a e´videmment rien prouve´
pour ces hypothe`ses.
Ce dont on a re´ellement besoin, c’est de pouvoir e´valuer a` toute e´tape de l’expe´rience
la probabilite´ des re´gions spe´cifie´es auxquelles on s’inte´resse et l’aptitude d’un e´chantillon
futur a` corroborer les re´sultats de´ja` obtenus. L’analyse baye´sienne traite directement ces
questions.
5.4 Solution baye´sienne
La me´thodologie baye´sienne nous permet d’obtenir les probabilite´s des re´gions spe´cifie´es,
ce qui apporte des re´ponses directes aux questions sur la grandeur des effets et n’a pas de
contrepartie fre´quentiste. Conside´rons un nouvel exemple d’analyse interme´diaire, avec 10
succe`s observe´es (n1 = 20 et a1 = 10).
c© Revue MODULAD, 2006 -146- Nume´ro 35
5.4.1 Evaluer la probabilite´ des re´gions spe´cifie´es
Choisissons la distribution initiale noninformative Beˆta (1/2, 1/2), qui donnera la “me´thode
baye´sienne objective” (je reviendrai e´galement sur ce choix plus loin) 5. Dans ce cas la
distribution finale est Beˆta (10.5, 10.5 et on obtient une probabilite´ e´leve´e (0.971) que la
me´thode d’enseignement soit inefficace (ϕ < 0.70).
Pr(ϕ < 0.70 | a1 = 10) Pr(0.70 < ϕ < 0.85 | a1 = 10 ) (Prϕ > 0.85 | a1 = 10 )
0.971 0.029 0.0001
L’utilisation de l’ordinateur re´soud les calculs ne´cessaires pour l’utilisation des distri-
butions baye´siennes. Cela donne a` l’utilisateur un moyen a` la fois intuitif et attrayant pour
comprendre les roˆles de la taille de l’e´chantillon, des donne´es et de la distribution initiale.
En particulier la distribution finale peut eˆtre visualise´e et explore´e interactivement.
LesProportions
Dans LePAC activez le menu LesBaye´siens et le sous-menu LesProportions, ce qui
affiche la feneˆtre pour l’infe´rence sur des proportions (par de´faut, c’est l’option 1 groupe
qui est active). Entrez dans les champs approprie´s les effectifs :
• pour 1 : 10
• pour 0 : 10
Entrez s’il y a lieu les parame`tres de la distribution initiale beˆta (mais c’est en principe
inutile car c’est l’option par de´faut) :
• pour 1 : 0.5 (que vous pouvez entrer comme 1/2)
• pour 0 : 0.5
Remarque : ces valeurs peuvent eˆtre affiche´es en cliquant sur le bouton 1/2.
Se´lectionnez les boutons d’option
• X<
• limite
Entrez dans le champ limite : 0.70 et se´lectionnez les de´cimales approprie´es : 2 pour la
limite et 3 pour la probabilite´. Cliquez sur le bouton Calculer et vous obtenez la figure
ci-apre`s.
5Dans ce cas, l’infe´rence baye´sienne sur ϕ effectue´e a` l’analyse interme´diaire ne prend pas explicite-
ment en compte la re`gle d’arreˆt (qui est cependant prise en compte dans le calcul de la probabilite´
pre´dictive). Dans le cadre fre´quentiste, il est habituel que les infe´rences interme´diaires soient modifie´es
pour tenir compte de la re`gle d’arreˆt. Ce point – qui pourrait apparaˆıtre comme un sujet de discorde
entre les deux approches – est aborde´ dans la partie IV.
c© Revue MODULAD, 2006 -147- Nume´ro 35
La probabilite´ associe´e a` une limite fixe´e, ou inversement les limites associe´es a` une
probabilite´ (ou garantie) donne´e (se´lectionnez le bouton d’option probabilite´), peuvent
eˆtre calcule´es.
5.4.2 Evaluer l’aptitude d’un e´chantillon futur a` corroborer les re´sultats de´ja`
obtenus
Pour re´sumer l’information obtenue quant a` la de´cision d’interrompre ou non l’expe´rience,
nous pouvons calculer la probabilite´ pre´dictive de confirmer la conclusion d’ineffica-
cite´. Si on souhaite une garantie d’au moins 0.95 pour la conclusion finale, c’est-a`-dire
Pr(ϕ < 0.70 | a) > 0.95, il faut que le nombre total de succe`s a soit infe´rieur a` 36 sur
59. Il s’agit donc, puisque l’on a de´ja` observe´ a1 = 10 succe`s, de calculer la probabilite´
pre´dictive d’observer dans les donne´es futures un nombre de succe`s a2 compris entre 0 et
25 sur 39.
Ici, sur la base des donne´es disponibles, il y a 87.3% de chances que cette conclusion
soit obtenue si l’expe´rience est mene´e a` son terme.
LesProportions
Effectuez s’il y a lieu les ope´rations de´crites pour la figure pre´ce´dente, puis cliquez sur le
bouton prediction.
Se´lectionnez le bouton d’option
• ensemble
Entrez dans le champ effectif supple´mentaire : 39 et se´lectionnez la garantie vou-
lue dans la liste de´roulante : 0.95. Cliquez sur le bouton Calculer et vous obtenez la
probabilite´ pre´dictive : 0.873. Cliquez sur le bouton de´tail pour obtenir la figure ci-apre`s.
c© Revue MODULAD, 2006 -148- Nume´ro 35
Le tableau ci-apre`s donne un re´sume´ des analyses pour l’exemple pre´ce´dent, ainsi que
pour un autre exemple plus favorable a` la me´thode d’enseignement.
c© Revue MODULAD, 2006 -149- Nume´ro 35
Distribution initiale Beˆta (1/2, 1/2)
Exemple 1 : n1 = 20 et a1 = 10
Infe´rence sur ϕ Probabilite´ pre´dictive (n = 59)
Probabilite´ finale Conclusion avec une garantie ≥ 0.95
Pr(ϕ < 0.70 | a1 = 10) ϕ < 0.70
0.971 0.873 (a < 36)
Pr(ϕ < 0.85 | a1 = 10) ϕ < 0.85
0.9999 0.9998 (a < 46)
Exemple 2 : n1 = 20 et a1 = 18
Infe´rence sur ϕ Probabilite´ pre´dictive (n = 59)
Probabilite´ finale Conclusion avec une garantie ≥ 0.95
Pr(ϕ > 0.70 | a1 = 10) ϕ > 0.70
0.982 0.939 (a > 46)
Pr(ϕ > 0.85 | a1 = 10) ϕ > 0.85
0.717 0.301 (a > 54)
5.4.3 Choisir l’effectif de l’e´chantillon
Les proce´dures pre´dictives sont aussi des outils adapte´s pour aider au choix de l’effectif
de l’e´chantillon. Supposons qu’en vue de planifier une expe´rience pour de´montrer l’effi-
cacite´ de la me´thode d’enseignement nous ayons re´alise´ une expe´rience pre´liminaire, par
exemple avec 10 sujets et que n’ayons observe´ que des succe`s. Dans ce cas la distribution
finale pour l’expe´rience pre´liminaire – en commenc¸ant avec la distribution non informative
Beˆta (1/2, 1/2) – est utilise´e comme distribution initiale. On obtient ici la probabilite´ finale
Pr(ϕ > 0.85) = 0.932.
LesProportions
Proce´dez comme pre´ce´demment pour l’infe´rence sur une proportion et entrez dans les
champs approprie´s les effectifs :
• pour 1 : 10
• pour 0 : 0
Entrez la distribution initiale beˆta
• pour 1 : 1/2
• pour 0 : 1/2
Se´lectionnez les boutons d’option
• X>
• limite
Entrez dans le champ limite : 0.85 pour obtenir la figure ci-apre`s (avec les de´cimales
approprie´es).
c© Revue MODULAD, 2006 -150- Nume´ro 35
Si on inte`gre les donne´es pre´liminaires dans l’analyse de l’expe´rience, la proce´dure est
exactement la meˆme que dans le cas de l’analyse interme´diaire ; on parle dans ce cas d’ap-
proche baye´sienne comple`te (“full Bayesian”). Mais la plupart temps, dans l’expe´rimentation,
on ne souhaite pas prendre en compte les donne´es pre´liminaires dans l’analyse de l’expe´rience,
et celle-ci sera donc effectue´e elle aussi avec la distribution initiale Beˆta (1/2, 1/2).
La proce´dure reste analogue : nous calculons la probabilite´ pre´dictive que dans l’e´chantillon
futur d’effectif n (et non pour l’ensemble des donne´es) la conclusion d’efficacite´ (ϕ > 0.85)
soit atteinte avec une garantie donne´e γ, d’ou` par exemple les probabilite´s pre´dictives sui-
vantes pour γ = 0.95 (avec entre parenthe`ses les valeurs de a qui remplissent la condition) :
n = 20 7→ 0.582 (a > 19)
n = 30 7→ 0.696 (a > 28)
n = 40 7→ 0.744 (a > 37)
n = 50 7→ 0.770 (a > 46)
n = 60 7→ 0.787 (a > 55)
n = 70 7→ 0.798 (a > 64)
n = 71 7→ 0.795 (a > 65)
n = 72 7→ 0.829 (a > 65)
Etc.
LesProportions
Effectuez s’il y a lieu les ope´rations de´crites pour la figure pre´ce´dente, puis cliquez sur
le bouton prediction.
Se´lectionnez le bouton d’option
• donne´es futures
Entrez dans le champ effectif supple´mentaire : 39 et se´lectionnez la garantie vou-
lue dans la liste de´roulante : 0.95. Cliquez sur le bouton Calculer et vous obtenez la
probabilite´ pre´dictive : 0.798 et la figure ci-apre`s.
Ainsi, sur la base des re´sultats pre´liminaires, il faut donc un effectif de l’ordre de 70
pour avoir a` peu pre`s 80% de chances de de´montrer l’efficacite´. On ne s’e´tonnera pas du
fait que les probabilite´s puissent ne pas eˆtre croissantes ; cela re´sulte du caracte`re discret
de la variable (il en est de meˆme pour la puissance).
5.5 Commentaires sur le choix de la distribution initiale non
informative
Beaucoup d’utilisateurs potentiels des me´thodes baye´siennes continuent de penser
qu’elles sont trop “subjectives” pour eˆtre scientifiquement acceptables. Pourtant les me´thodes
fre´quentistes sont pleines de conventions plus ou moins ad hoc. Ainsi le traditionnel seuil
c© Revue MODULAD, 2006 -151- Nume´ro 35
observe´ p (p value) du test est base´ sur les e´chantillons qui sont “plus extreˆmes” que les
donne´es observe´es (sous l’hypothe`se nulle). Mais, pour des donne´es discre`tes, cela de´pend
du fait que l’on inclut ou non les donne´es observe´es.
Supposons qu’a` l’analyse finale on observe 47 succe`s (n = 59 et a = 47), soit la valeur
au dela` de laquelle le test binomial rejette l’hypothe`se nulle H0 : ϕ = 0.70. On peut alors
calculer le seuil observe´ p suivant une des trois possibilite´s suivantes :
pinc = Pr(a ≥ 47 | H0 : ϕ = 0.70) = 0.066 [solution usuelle “incluante”]
⇒ H0 n’est pas rejete´e au seuil α = 0.05 (test “conservateur”)
pexc = Pr(a > 47 | H0 : ϕ = 0.70) = 0.035 [solution “excluante”]
⇒ H0 est rejete´e au seuil α = 0.05 (test “libe´ral”)
pmoyen = 1/2(pinc + pinc) = 0.051 [“p moyen”]
Dans la solutions usuelle la valeur observe´e est inclue et le test est “conservateur” :
la probabilite´ de rejeter H0, si elle est vraie, est infe´rieure a` α. Mais si la valeur observe´e
est exclue, le test devient “libe´ral” : la probabilite´ de rejeter H0, si elle est vraie, est
supe´rieure a` α. Une solution typique pour surmonter ce proble`me consiste a` conside´rer un
“p moyen” (mid-p value) (Routledge, 1994 ; Berry & Armitage, 1995), mais dans le cadre
fre´quentiste cette pratique a seulement des justifications ad hoc.
A l’e´vidence dans ce cas le choix d’une distribution initiale non informative implique
aussi des conventions. Mais le choix particulier d’une telle distribution initiale n’est ni
plus ni moins qu’une contrepartie exacte de l’arbitraire en jeu dans l’approche fre´quentiste
(Bernard, 1996). Ainsi, dans notre situation, diffe´rentes distributions ont e´te´ propose´es
pour une analyse baye´sienne objective (pour une discussion, voir par exemple Lee, 2004,
pages 79-81). La plupart appartiennent a` la famille des distributions Beˆta (a0, b0) avec des
valeurs de a0 et b0 comprises entre 0 et 1, en particulier
• Beˆta (1, 1) – qui est la distribution uniforme sur [0,1] (Laplace, 1774) ;
• Beˆta (0, 0) qui est une distribution impropre – mais qui correspond a` la distribution
uniforme pour log( ϕ
1−ϕ) (Lhoste, 1923 ; Haldane, 1948) ;
• Beˆta (1/2, 1/2) – qui correspond a` la distribution uniforme pour arcsinus(√pi) (Jeffreys,
1961 ; Perks, 1947) et qui est de´rive´e en utilisant la re`gle de Jeffreys dont on trouvera la
justification dans la partie IV.
5.5.1 Interpre´tation baye´sienne du seuil observe´
Pour notre proble`me, il existe dans cette famille deux distributions initiales extreˆmes –
Beˆta (0, 1) et Beˆta (1, 0) – qui sont respectivement la plus de´favorable et la plus favorable
par rapport a` l’hypothe`se nulle. Les seuils de signification observe´s associe´s aux solutions
incluante et excluante sont exactement les probabilite´s baye´siennes finales que ϕ soit plus
petit que 0.70 (la valeur spe´cifie´e parH0) respectivement associe´es a` ces deux distributions
initiales extreˆmes. La distribution initiale de Jeffreys Beˆta (1/2, 1/2) avec des poids e´gaux a`
1/2 est interme´daire et donne une probabilite´ proche du “p moyen”.
c© Revue MODULAD, 2006 -152- Nume´ro 35
Pr(ϕ < 0.70 | a = 47) = 0.066 = pinc
pour la distribution initiale ϕ ∼ Beˆta (0, 1) (la plus de´favorable a` H0)
soit la distribution finale ϕ | ∼ Beˆta (47, 13)
Pr(ϕ < 0.70 | a = 47) = 0.035 = pexc
pour la distribution initiale ϕ ∼ Beˆta (1, 0) (la plus favorable a` H0)
soit la distribution finale ϕ | ∼ Beˆta (48, 12)
Pr(ϕ >< 0.70 | a = 47) = 0.049 ≈ pmoyen
pour la distribution initiale ϕ ∼ Beˆta (1/2, 1/2)
soit la distribution finale ϕ | ∼ Beˆta (47.5, 12.5)
LesProportions
Proce´dez comme pre´ce´demment pour l’infe´rence surune proportion et entrez dans les
champs approprie´s les effectifs :
• pour 1 : 47
• pour 0 : 12
Entrez la distribution initiale beˆta
• pour 1 : 0
• pour 0 : 1
Remarque : ces valeurs peuvent eˆtre affiche´es en cliquant sur le bouton 0 1.
Se´lectionnez les boutons d’option
• X<
• limite
Entrez dans le champ limite : 0.70 pour obtenir la premie`re figure ci-apre`s (avec les
de´cimales approprie´es).
La seconde figure est obtenue pour la distribution initiale beˆta
• pour 1 : 1
• pour 0 : 0
La critique facile a` l’e´gard de l’approche baye´sienne concernant l’existence de diver-
gences quant au choix de la distribution non informative se retourne donc a` l’encontre de
l’approche fre´quentiste. La re´ponse des baye´siens ne devrait donc pas eˆtre de me´sestimer
l’impact du choix d’une distribution non informative particulie`re, comme cela est souvent
le cas
c© Revue MODULAD, 2006 -153- Nume´ro 35
“In fact, the [different non informative priors] do not differ enough to make
much difference with even a fairly small amount of data.” (Lee, 2004, page 81)
mais au contraire de l’accepter.
5.5.2 Intervalles de cre´dibilite´ baye´sien et taux de couverture fre´quentistes
Dans d’autres situations ou` nous ne nous inte´ressons pas a` des valeurs particulie`res,
nous pouvons conside´rer un intervalle (ou plus ge´ne´ralement une re´gion) d’estimation
pour ϕ. Dans le cadre baye´sien un tel intervalle est habituellement appele´ un intervalle
de cre´dibilite´ pour souligner la diffe´rence d’interpre´tation avec l’intervalle de confiance
fre´quentiste.
Intervalles “a` queues e´gales”
LesProportions
Proce´dez comme pre´ce´demment pour l’infe´rence surune proportion et entrez dans les
champs approprie´s les effectifs :
• pour 1 : 19
• pour 0 : 1
Entrez la distribution initiale beˆta
• pour 1 : 1/2
• pour 0 : 1/2
Se´lectionnez les boutons d’option
• <X<
• probabilite´
Entrez dans le champ probabilite´ : 0.95 pour obtenir la figure ci-apre`s (avec 4 de´cimales
pour la limite).
On trouve ici, pour les diffe´rentes distributions initiales conside´re´es les intervalles a`
95% pour les deux exemples suivants
n1 = 20, a1 = 19
Beˆta (0, 1) Beˆta (1, 1) Beˆta (1/2, 1/2) Beˆta (0, 0) Beˆta (1, 0)
[0.7513 , 0.9877] [0.7618 , 0.9883] [0.7892 , 0.9946] [0.8235 , 0.9987] [0.8316 , 0.9987]
n1 = 59, a1 = 32
Beˆta (0, 1) Beˆta (1, 1) Beˆta (1/2, 1/2) Beˆta (0, 0) Beˆta (1, 0)
[0.4075 , 0.6570] [0.4161 , 0.6633] [0.4158 , 0.6649] [0.4240 , 0.6728] [0.4240 , 0.6728]
Parmi ces distributions initiales, Beˆta (1, 0) donne les plus grandes limites et a les
proprie´te´s fre´quentistes suivantes : la proportion des e´chantillons pour lesquels la limite
supe´rieure est infe´rieure a` ϕ est plus petite que α/2 et la proportion des e´chantillons pour
c© Revue MODULAD, 2006 -154- Nume´ro 35
pour pour lesquels la limite infe´rieure est supe´rieure a` ϕ est plus grande que α/2. La distri-
bution Beˆta (0, 1) donne les plus petites limites et les proprie´te´s inverses. Par conse´quent,
conside´rer simultane´ment les limites de ces deux intervalles prote`ge l’utilisateur a` la fois
d’une acceptation et d’un rejet errone´s des hypothe`ses sur ϕ au seuil unilate´ral α/2.
Si l’on souhaite un seul intervalle pour re´sumer les re´sultats, ces proprie´te´s conduisent
a` privile´gier celui associe´ a` la distribution “interme´diaire” Beˆta (1/2, 1/2) (qui est la distri-
bution de Jeffreys). Effectivement cet intervalle a de tre`s bonnes proprie´te´s fre´quentistes
qui justifient pleinement le nom de “me´thode baye´sienne objective”. La probabilite´ de
couverture de cet intervalle est tre`s proche du seuil nominal, meˆme pour des e´chantillons
d’effectifs tre`s faibles. Il se compare favorablement a` la plupart des intervalles fre´quentistes
disponibles et est recommandable meˆme d’un point de vue fre´quentiste, comme l’ont
montre´ Brown, Cai et DasGupta (2001) (voir aussi Agresti & Min, 2005)
“We revisit the problem of interval estimation of a binomial proportion. . .We
begin by showing that the chaotic coverage properties of the Wald interval are
far more persistent than is appreciated. . .We recommend the Wilson interval or
the equal tailed Jeffreys prior interval for small n.” (Brown, Cai & DasGupta,
2001, page 101).
Intervalles “de plus haute densite´ finale”
Une approche qui a e´te´ souvent recommande´e par les baye´siens est de conside´rer l’in-
tervalle “de plus haute densite´ finale” (highest posterior density , en bref HPD). Pour un tel
intervalle (qui peut en fait, si la distribution n’est pas unimodale, eˆtre une re´union d’inter-
valles disjoints), la densite´ de probabilite´ est plus e´leve´e pour toute valeur a` l’inte´rieur de
l’intervalle que pour toute valeur exte´rieure. Ceci re´pond a` l’objectif d’obtenir l’intervalle
le plus court possible. Mais, sauf pour une distribution syme´trique, chacune des probabi-
lite´s late´rales sera diffe´rente de α/2. Cette proprie´te´ apparaˆıt inde´sirable pour l’analyse de
donne´es expe´rimentales ou` la plupart des questions sont, comme dans le pre´sent exemple
“unilate´rales”.
De plus un tel intervalle n’est pas invariant par transformation (excepte´ pour une
transformation line´aire), ce qui peut eˆtre conside´re´ avec Agresti et Min (2005, page 3)
comme “a fatal disadvantage”. Ainsi, pour les donne´es n = 59, a = 32 et la distribution
initiale Beˆta (1/2, 1/2), nous obtenons les intervalles de plus haute densite´ finale
[0.4167, 0.6658] pour ϕ et [0.7481, 2.1594] pour
ϕ
1− ϕ
avec les probabilite´s correspondantes :
Pr(ϕ < 0.4167) = 0.026 et Pr(
ϕ
1− ϕ < 0.7481) = 0.039
Pr(ϕ > 0.6658) = 0.024 et Pr(
ϕ
1− ϕ > 2.1594) = 0.011
Pour ces raisons, nous n’avons pas retenu ces intervalles de plus haute densite´ finale
dans nos programmes.
On remarquera en passant, a` propos de cet exemple qu’il est tout aussi facile d’obtenir
la distribution finale de ϕ
1−ϕ , qui est une distribution F de Fisher Snedecor. On trouve
l’intervalle de cre´dibilite´ 95% a` queues e´gales [0.712,1.984].
LesProportions
c© Revue MODULAD, 2006 -155- Nume´ro 35
Proce´dez comme pre´ce´demment pour l’infe´rence surune proportion, mais activez le bouton
d’option ϕ/(1− ϕ). Entrez dans les champs approprie´s les effectifs :
• pour 1 : 32
• pour 0 : 27
Entrez la distribution initiale beˆta
• pour 1 : 1/2
• pour 0 : 1/2
Se´lectionnez les boutons d’option
• <X<
• probabilite´
Entrez dans le champ probabilite´ : 0.95 pour obtenir la figure ci-apre`s (avec 3 de´cimales
pour la limite).
5.5.3 Distributions initiales “informatives”
L’utilisation de distributions initiales non informatives a manifestement un statut
privile´gie´ pour obtenir des e´nonce´s “a` usage public”. Cependant d’autres techniques
baye´siennes peuvent aussi avoir un roˆle important a` jouer dans la recherche expe´rimentale.
En particulier, elles sont ide´alement adapte´es pour combiner des informations provenant
de plusieurs sources, et par suite pour planifier une se´rie d’expe´riences. Des utilisations
plus ou moins re´alistes et plus ou moins convaincantes de ces techniques ont e´te´ propose´es.
Quand une analyse baye´sienne objective sugge`re une conclusion donne´e, diffe´rentes dis-
tributions a priori traduisant les re´sultats d’autres expe´riences ou des opinions plus ou
moins subjectives d’“experts”, soit sceptiques soit enthousiastes , peuvent eˆtre utilise´es
pour e´prouver la robustesse des conclusions (voir en particulier Spiegelhalter, Freedman
& Parmar, 1994).
On peut aussi conside´rer que la construction d’une distribution initiale a` partir d’opi-
nions d’“experts” du domaine peut eˆtre utile dans certaines e´tudes, mais cela ne´cessite
des techniques approprie´e (voir pour un exemple dans les essais cliniques Tan et al., 2003).
Il convient encore de mentionner le fait que les distributions pre´dictives sont e´galement
un outil utile pour construire une distribution initiale subjective, car il est souvent plus
facile d’exprimer une opinion relativement a` des donne´es attendues plutoˆt qu’a` des pa-
rame`tres.
L’utilisation de ces techniques pour l’analyse des donne´es expe´rimentales n’a cependant
pas assez e´te´ explore´e pour pouvoir re´ellement appre´cier leur apport, notamment dans le
cas ou` l’information a priori refle`te d’avantage une opinion qu’un connaissance re´elle.
Les exemples donne´s ci-apre`s doivent eˆtre vus comme des exercices pour mieux com-
prendre comment l’infe´rence baye´sienne permet de combiner des informations. Je laisse
au lecteur le soin d’exercer son esprit critique quant a` l’apport de ces me´thodes pour
l’analyse de donne´es expe´rimentales.
Distributions “sceptiques” et “enthousiastes”
c© Revue MODULAD, 2006 -156- Nume´ro 35
Reprenons l’exemple des donne´es n = 59, a = 32, pour laquelle la proce´dure baye´sienne
objective conduisait a` conclure que la me´thode d’enseignement e´tait inefficace (ϕ < 0.70).
Conside´rons a` titre d’illustration les deux distributions initiales, respectivement a priori
tre`s sceptique et tre`s enthousiaste envers la me´thode
ϕ ∼ β(20, 80) de moyenne 0.200 pour laquelle Pr(ϕ < 0.70) ≈ 1
ϕ ∼ β(98, 2) de moyenne 0.980 pour laquelle Pr(ϕ > 0.85) = 0.999998
Les distributions finales correspondantes sont respectivement
ϕ ∼ β(52, 107) de moyenne 0.327 pour laquelle Pr(ϕ < 0.70) ≈ 1
ϕ ∼ β(130, 29) de moyenne 0.818 pour laquelle Pr(ϕ > 0.85) = 0.143
La premie`re “renforce” bien entendu la conclusion d’inefficacite´. On peut le voir sur
la figure ci-apre`s, qui montre la distribution initiale (en noir) et la distribution finale
(en rouge) ; celle-ci peut eˆtre compare´e a` la distribution finale objective – pour l’initiale
Beˆta (1/2, 1/2) (en bleu).
LeB-A-Baye´sien
Dans LePAC activez le menu LeB-A-Baye´sien et le sous-menu e´chantillonnage Bi-
nomial, ce qui affiche la feneˆtre correspondante. Activez la case donne´es et entrez les
valeurs :
• pour 1 : 32
• pour 0 : 27
Entrez les parame`tres de la distribution initiale (par de´faut c’est l’option une seule
distribution qui est active) :
• pour 1 : 20
• pour 0 : 80
Activez la case finale / initiale Beˆta(1/2,1/2) pour obtenir la figure ci-apre`s. Les
courbes sont mises a` jour automatiquement a` chaque nouvelle entre´e ; au besoin, cliquez
sur le bouton calculer.
c© Revue MODULAD, 2006 -157- Nume´ro 35
Mais cette distribution initiale ne laissait “aucune chance” aux donne´es d’infirmer
l’opinion a priori, puisque meˆme si on observait 59 succe`s et 0 erreur, on aurait quand
meˆme
Pr(ϕ < 0.70) | a = 59) = 0.99999995
La seconde permet une conclusion beaucoup moins de´favorable a` la me´thode d’ensei-
gnement, comme le montre la figure suivante
LeB-A-Baye´sien
Dans la configuration de la figure pre´ce´dente, activez le deuxie`me bouton d’option de la
colonne une seule distribution et entrez les les parame`tres de la distribution initiale
(voir la figure ci-dessus) :
• pour 1 : 98
• pour 0 : 2
mais les donne´es ne permettent cependant pas de conclure a` son efficacite´
Pr(ϕ > 0.70 | a = 32) = 0.997 mais Pr(ϕ > 0.85 | a = 32) = 0.143
c© Revue MODULAD, 2006 -158- Nume´ro 35
Il est e´clairant d’examiner l’effet de la distribution initiale Beˆta (a0, b0) sur la moyenne
de la distribution finale. En posant n0 = a0 + b0, les rapports n0/(n0 + n) et n/(n0 + n)
repre´sentent les poids relatifs de la distribution initiale et des donne´es. La moyenne finale
peut eˆtre e´crite sous la forme
a0 + a
n0 + n
=
n0
n0 + n
× a0
n0
+
n
n0 + n
× a
n
Elle est donc e´gale a`
“poids relatif de l’initiale × moyenne initiale + poids relatif des donne´es × moyenne observe´e”
soit ici les moyenne finales
100/159× 0.200 + 59/159× 0.542 = 0.327 pour la distribution initiale ϕ ∼ β(20, 80)
100/159× 0.980 + 59/159× 0.542 = 0.818 pour la distribution initiale ϕ ∼ β(98, 2)
Me´langes de densite´s Beˆta
Une technique qui reste simple de mise en œuvre est d’utiliser une distribution initiale
dont la densite´ est un me´lange de densite´s de distributions Beˆta, la distribution finale
e´tant encore un tel me´lange.
Ceci peut avoir deux inte´reˆts, d’une part approcher une distribution initiale com-
plexe quelconque qui ne´cessiterait le recours a` des me´thodes d’inte´gration nume´rique,
d’autre part combiner diffe´rentes sources d’informations (ou diffe´rentes opinions). A titre
d’illustration, conside´rons pour les meˆmes donne´es un me´lange des deux distributions
pre´ce´dentes avec des poids e´gaux, soit
ϕ ∼ 1/2Beˆta (20, 80)⊕ 1/2Beˆta (98, 2)
ou` ⊕ signifie que c’est la densite´ de ϕ qui est un me´lange, soit symboliquement
p(ϕ) = 1/2 p
(
Beˆta (20, 80)
)
+ 1/2 p
(
Beˆta (98, 2)
)
Cette distribution ne doit pas eˆtre confondue avec celle d’une combinaison line´aire de deux
variables ayant des distributions Beˆta inde´pendantes (qui aurait une densite´ beaucoup
plus complexe).
La figure ci-apre`s montre la distribution initiale correspondante (en noir), qui est
bimodale, et la distribution finale (en rouge) ; celle-ci peut eˆtre compare´e a` la distribution
finale objective (en bleu).
LeB-A-Baye´sien
Dans la configuration de la figure pre´ce´dente, activez maintenant le bouton d’option
me´lange de densite´s Beˆta pour obtenir la figure ci-apre`s.
c© Revue MODULAD, 2006 -159- Nume´ro 35
En fait, dans ce cas, les donne´es n = 59, a = 32 permettent en quelque sorte de
trancher entre les deux distributions du me´lange puisque la distribution finale est
0.999999903Beˆta (52, 107)⊕ 0.000000097Beˆta (130, 29)
de sorte qu’elle est virtuellement confondue avec la distribution Beˆta (52, 107) associe´e a`
la distribution initiale Beˆta (20, 80) conside´re´e pre´ce´demment.
Avec 10 fois plus de donne´es, et la meˆme proportion observe´e de succe`s (n = 590,
a = 320), la distribution finale, que l’on peut voir sur la figure suivante serait prati-
quement indiscernable de la distribution Beˆta (340, 350) associe´e a` la distribution initiale
Beˆta (20, 80), mais elle se rapprocherait bien entendu de la solution objective.
LeB-A-Baye´sien
Dans la configuration de la figure pre´ce´dente, modifiez les donne´es :
• pour 1 : 320
• pour 0 : 270
Un autre exemple de me´langes
Lee (2004, page 59) donne un exemple sans doute plus re´aliste d’utilisation de me´langes.
Cet exemple est emprunte´ a` Diaconis et Ylvisaker (1985). On part de la constatation sui-
vante : quand on lance en l’air un grand nombre de fois une pie`ce de monnaie, on obtient
approximativement une proportion 1/2 de Face, mais lorsqu’on la fait tourner sur elle
meˆme on obtient des proportions telles que 1/3 ou 2/3. Admettant ce re´sultat, on peut
conside´rer qu’un me´lange de deux densite´s de distributions Beˆta de moyennes respectives
1/3 et 2/3 est un choix approprie´ pour la distribution initiale de la proportion ϕ de Face,
soit par exemple
ϕ ∼ 1/2Beˆta (10, 20)⊕ 1/2Beˆta (20, 10)
Si pour une pie`ce donne´e on fait n = 10 essais et si on observe a = 3 Face, la distribution
finale est
115
129
Beˆta (13, 27)⊕ 14
129
Beˆta (23, 17)
Elle a pour moyenne 0.352 et donne un intervalle de cre´dibilite´ 95%
[0.194, 0.633]
Pour comparaison, la distribution finale objective a pour moyenne 0.318 avec un intervalle
de cre´dibilite´ 95%
[0.093, 0.606]
Si on fait n = 100 essais et si on observe a = 30 Face, la distribution finale (de moyenne
0.308) est
c© Revue MODULAD, 2006 -160- Nume´ro 35
ϕ ∼ 0.9984Beˆta (40, 90)⊕ 0.0016Beˆta (50, 80)
L’intervalle de cre´dibilite´ 95% est
[0.232, 0.390]
qui est bien entendu dans ce cas beaucoup plus proche de celui obtenu pour la solution
objective
[0.217, 0.395]
On peut choisir des poids diffe´rents ou encore faire intervenir dans le me´lange une
troisie`me distribution Beˆta de moyenne 1/2, etc.
5.5.4 Remarques
Interpre´tation des poids du me´lange a` partir des probabilite´s pre´dictives
Le poid associe´ a` une distribution Beˆta du me´lange final est proportionnel au produit
du poids initial par la probabilite´ pre´dictive associe´e a` la distribution initiale Beˆta cor-
respondante. Reprenons l’exemple pre´ce´dent d’une distribution initiale 1/2Beˆta (10, 20)⊕
1/2Beˆta (20, 10) avec les observations n = 10 et a = 3. Les probabilite´s pre´dictives d’ob-
server a = 3 sont respectivement
Pr(a = 3) = 0.227632 pour la distribution initiale Beˆta (10, 20)
Pr(a = 3) = 0.027712 pour la distribution initiale Beˆta (20, 10)
Les poids du me´lange finale sont proportionnels a` 1/2 × 0.227632 et 1/2 × 0.027712 et on
ve´rifie que
0.227632
0.227632 + 0.027712
=
115
129
et
0.027712
0.227632 + 0.027712
=
14
129
Mode`le binomial ne´gatif
Les meˆmes proce´dures pour les parame`tres – faisant intervenir des distributions Beˆta
ou des me´langes – s’appliquent au mode`le binomial ne´gatif dans lequel on arreˆte l’expe´rience
quand on a observe´ un nombre fixe´ a` l’avance de succe`s ou d’e´checs (e´chantillonnage de
Pascal), l’effectif n e´tant une variable ale´atoire. On notera toutefois que la distribution
initiale de Jeffreys est diffe´rente (voir l’annexe A). La distribution d’e´chantillonnage e´tant
diffe´rente, la distribution pre´dictive est donc e´galement diffe´rente ; il s’agit dans ce cas
d’une distribution Beˆta-Pascal.
5.6 Le facteur de Bayes
Pour comple´ter la pre´sentation de cet exemple, j’introduirai le facteur de Bayes , meˆme
si l’utilisation de celui-ci rele`ve davantage d’une approche de´cisionnelle et pourra donc
apparaˆıtre plus approprie´e dans d’autres contextes.
Reprenons encore, pour l’expe´rience sur la me´thode d’enseignement, l’exemple des
donne´es n = 59, a = 32, avec la distribution initiale enthousiaste ϕ ∼ β(98, 2) et les
probabilite´s a priori Pr(ϕ > 0.85) = 0.99999810 (qu’on notera pi1) et donc Pr(ϕ <
0.85) = 0.00000190 (pi0). Les notations pi0 et pi1 sont usuelles car le facteur de Bayes est
ge´ne´ralement pre´sente´ comme une approche baye´sienne au tests d’hypothe`ses classiques ;
c© Revue MODULAD, 2006 -161- Nume´ro 35
dans ce cadre, pi0 et pi1 sont les probabilite´s de l’hypothe`se nulle H0 et de l’hypothe`se
alternative H1.
Il apparaˆıt alors assez naturel de conside´rer :
• le rapport de ces deux probabilite´s a priori, soit
pi0
pi1
=
Pr(ϕ < 0.85)
Pr(ϕ > 0.85)
= 0.0000019
qui est e´videmment ici tre`s faible ;
• et leur rapport a posteriori, soit
p0
p1
=
Pr(ϕ < 0.85 | a = 32)
Pr(ϕ > 0.85 | a = 32) =
0.8570
0.1430
= 5.99
qui est maintenant nettement supe´rieur a` 1.
On de´finira alors le facteur de Bayes (associe´ a` l’observation a) comme le rapport de
ces deux rapports
B(a) =
p0/p1
pi0/pi1
=
p0pi1
p1pi0
= 3154 986
ce qui “e´value donc la modification de la vraisemblance relative de l’hypothe`se nulle qui
est due aux observations” (Robert, 1992, page 166). Mais ceci n’est e´videmment qu’un
re´sume´ incomplet, qui ne peut remplacer l’information fournie par les probabilite´s finales.
Le facteur de Bayes s’applique de la meˆme manie`re a` des hypothe`ses H0 et H1 “non
comple´mentaires”, par exemple ici ϕ < 0.70 et ϕ > 0.85 ; mais l’interpre´tation est encore
plus proble´matique puisqu’on ignore la zone de “non conclusion” 0.70 < ϕ < 0.85.
Dans le cas particulier ou` H0 et H1 sont des hypothe`ses simples ϕ = ϕ0 et ϕ = ϕ1, le
facteur de Bayes est simplement le classique rapport de vraisemblance
B(a) =
p(ϕ0 | a) p(ϕ1)
p(ϕ1 | a) p(ϕ0) =
p(a |ϕ0)
p(a |ϕ1)
puisque p(ϕ0 | a) ∝ p(a |ϕ0) p(ϕ0) et p(ϕ1 | a) ∝ p(a |ϕ1) p(ϕ1).
On notera encore que dans le cas ou` H0 et H1 sont des hypothe`ses “comple´mentaires”
(donc p1 = 1− p0), comme dans l’exemple pre´ce´dent, on peut retrouver leurs probabilite´s
finales a` partir des probabilite´s initiales (pi1 = 1− pi0) et du rapport de Bayes, puisqu’on
ve´rifie facilement que
1
p0
= 1 +
1− pi0
pi0
1
B(a)
Pour une discussion de l’utilisation du facteur de Bayes en liaison avec la proble´matique
des tests d’hypothe`ses, on pourra consulter Robert (1992, pages 166-168).
6 Comparaison de deux proportions
Conceptuellement, les solutions pre´ce´dentes pour une proportion s’e´tendent imme´diatement
a` deux e´chantillons binomiaux inde´pendants, pourvu que les distributions initiales soient
e´galement inde´pendantes (Lecoutre, Grouin & Derzko, 1995). Nous illustrerons ces so-
lutions a` partir d’un mode`le plus complexe, qui conduit au meˆmes proce´dures pour les
parame`tres et permet d’illustrer la souplesse de l’approche baye´sienne.
c© Revue MODULAD, 2006 -162- Nume´ro 35
6.1 Le proble`me : Re`gle d’expe´rimentation “rejouez le gagnant”
Pour comparer deux traitements, dans le plan d’expe´rience usuel “en groupes inde´pen-
dants” les sujets sont affecte´s par tirage au sort a` chacun des deux traitements. Ceci
conduit a` deux groupes d’effectifs e´gaux (en contraignant un peu le tirage au sort). Pour
des conside´rations e´thiques, on peut pre´fe´rer un plan permettant d’attribuer le “meilleur”
traitement un plus grand nombre de fois. Comme on ne sait pas a priori de quel traite-
ment il s’agit ou qu’on ne veut pas faire intervenir une e´ventuelle connaissance dans la
planification de l’expe´rience, on peut utiliser une re`gle approprie´e base´e sur un processus
se´quentiel. Ainsi la re`gle “rejouez le gagnant” (play-the-winner), de´crite ci-apre`s, re´pond
a` cet objectif (Zelen, 1969).
Le premier sujet rec¸oit l’un des deux traitements, t1 ou t2, avec des probabilite´s
e´gales. Ensuite, si le sujet k − 1 a rec¸u un traitement t dont le re´sultat est
un “succe`s”, le sujet suivant k rec¸oit le meˆme traitement ; si au contraire le
re´sultat est “un e´chec”, le sujet k rec¸oit l’autre traitement.
La re`gle pre´suppose que le re´sultat du sujet k−1 est connu quand le sujet k est inclus,
mais elle pourrait eˆtre e´tendue pour tenir compte du cas ou` la re´ponse est diffe´re´e. En
de´pit de son de´terminisme apparent, cette re`gle est un processus stochastique, puisqu’elle
de´pend des probabilite´s de succe`s ϕ1 et ϕ2 de chacun des traitements.
Pour un total, suppose´ fixe´ a` l’avance, de n sujets, la se´quence des traitement attribue´s
(t1, t2 . . . tk, tk+1 . . . tn+1) contient toute l’information des donne´es. En effet tk+1 = tk
implique qu’on a observe´ un succe`s a` tk, tandis que tk+1 6= tk implique qu’on a observe´
un e´chec a` tk. La fonction de vraisemblance est donc simplement
v(ϕ1, ϕ2)|(t1, . . . tn+1) = 1/2ϕn111 (1− ϕ1)n10ϕn212 (1− ϕ2)n20
ou` ni1 (i = 1, 2) est le nombre de paires (tk, tk+1) e´gales a` (t
i, ti), de sorte que n11 et n21
sont les nombres respectifs de succe`s aux traitements t1 et t2 ; ni0 est le nombre de paires
(tk, tk+1) e´gales a` (t
i, tj), avec j 6= i, de sorte que n10 et n20 sont les nombres d’e´checs ; 1/2
est la probabilite´ de t1.
On peut voir que la fonction de vraisemblance est proportionnelle au produit des
fonctions de vraisemblance associe´es a` chacun de deux e´chantillons binomiaux, d’effectifs
respectifs n11 + n10 et n21 + n20 et de parame`tres ϕ1 et ϕ2. Elle est donc identique – a`
une constante multiplicative pre`s – a` celle associe´e a` la comparaison de deux proportions
binomiales inde´pendantes. Cependant, ici seul n = n11+n10+n21+n20 est fixe´, alors que
pour deux e´chantillons binomiaux n11 + n10 et nn21 + n20 sont tous les deux fixe´s.
6.2 Solutions fre´quentistes
Alors que, comme nous le verrons, les proce´dures baye´siennes sont les meˆmes que pour
deux e´chantillons binomiaux inde´pendantes, les proce´dures fre´quentistes sont diffe´rentes.
En effet, meˆme si les fonctions de vraisemblance sont proportionnelles, les probabilite´s
d’obtenir n11 succe`s au traitement t1 et n21 succe`s au traitement t2 avec la re`gle “rejouez le
gagnant” sont donne´es par des distributions beaucoup plus complexes que la distribution
Binomiale, qui en outre ne sont bien entendu pas inde´pendantes. En raison de cette
complexification, seules des proce´dures asymptotiques ont e´te´ propose´es ; elles ne sont
gue`re satisfaisantes en dehors d’e´chantillons d’effectif e´leve´.
c© Revue MODULAD, 2006 -163- Nume´ro 35
6.3 Solution baye´sienne
Dans le cadre baye´sien au contraire, puisque leurs fonctions de vraisemblance sont
proportionnelles, les proce´dures sur les parame`tres sont les meˆmes pour les deux mode`les,
bien que les probabilite´s d’e´chantillonnage soient tre`s diffe´rentes. Une solution simple et
usuelle suppose deux distributions initiales Beˆta inde´pendantes pour ϕ1 et ϕ2, respecti-
vement :
ϕ1 ∼ Beˆta (ν11, ν10) et ϕ2 ∼ Beˆta (ν21, ν20)
Les distributions finales marginales sont encore deux distributions Beˆta inde´pendantes :
ϕ1 | (t1, . . . tn+1) ∼ Beˆta (ν11+n11, ν10+n10) et ϕ2 | (t1, . . . tn+1) ∼ Beˆta (ν21+n21, ν20+n20)
6.3.1 Exemple nume´rique
Conside´rons a` titre d’illustration les re´sultats suivants pour une expe´rience avec n =
150 sujets. On remarquera que, par de´finition de la re`gle, les nombres d’e´checs (ici 20 et
21) ne peuvent diffe´rer que d’au plus une unite´.
succe`s e´checs
traitement t1 n11 = 74 n10 = 20 94
traitement t2 n21 = 35 n20 = 21 56
109 41 150
6.3.2 La simplicite´ conceptuelle des me´thodes baye´siennes objectives
Un e´nonce´ de probabilite´ conjoint est, dans un sens, le meilleur re´sume´ de la distri-
bution finale. Si nous adoptons la distribution initiale de Jeffreys (ν11 = ν10 = ν21 =
ν20 = 1/2), nous obtenons par exemple la probabilite´ finale conjointe (en omettant le
conditionnement par les donne´es pour simplifier l’e´criture) :
Pr(ϕ1 > 0.697 et ϕ2 < 0.743) = 0.95
qui se de´duit de
Pr(ϕ1 > 0.697) = Pr(ϕ2 > 0.743) =
√
0.95 = 0.974679
(obtenues comme dans le cas de l’infe´rence sur une proportion) en utilisant l’inde´pendance
des deux distributions finales
ϕ1 ∼ Beˆta (74.5, 20.5) et ϕ2 ∼ Beˆta (35.5, 21.5)
Cependant nous pouvons pre´fe´rer un e´nonce´ qui permet de comparer directement les
deux traitements. Ainsi nous avons
Pr(ϕ1 > ϕ2) = 0.984
De plus il est facile de conside´rer les principaux crite`res classiques pour comparer deux
proportions (diffe´rence, rapport, etc.). Dans le cadre fre´quentiste, chacun de ces crite`res
ne´cessite des proce´dures diffe´rentes. On sait en outre que dans le cas de deux e´chantillons
binomiaux inde´pendants il existe pour chacun d’eux une ple´thore de proce´dures6.
6De nouvelles proce´dures sont en outre re´gulie`rement propose´es. Certaines d’entre elles re´servent
d’ailleurs des surprises. C’est par exemple le cas des “new confidence intervals” de´veloppe´s par Zhou et
Qin (2004, 2005). Pour l’exemple d’effectifs observe´s pour deux groupoes inde´pendants (2,8) et (1,35),
les auteurs (Zhou & Qin, 2004, pages 108-109) donnent pour la diffe´rence ϕ1 −ϕ2 (avec les notations
c© Revue MODULAD, 2006 -164- Nume´ro 35
De meˆme qu’il existe une correspondance entre le seuil observe´ du test binomial et la
probabilite´ baye´sienne finale pour une distribution initiale approprie´e, on trouve e´galement
dans ce cas un lien avec les tests conditionnels de Fisher. Ceci sera illustre´ plus loin a`
propos d’une autre situation. Mais bien entendu ces proce´dures fre´quentistes ne seraient
pas applicables ici puisque la distribution d’e´chantillonnage n’est pas la meˆme.
Au contraire la solution baye´sienne est conceptuellement imme´diate. En effet la dis-
tribution de n’importe quel parame`tre de´rive´ peut eˆtre obtenue a` partir de la distribution
finale conjointe7. Le proble`me est seulement technique : il faut en ge´ne´ral recourir a` des
me´thodes d’inte´gration nume´rique. Par exemple nous trouvons les intervalles de credibilite´
95% (a` “queues e´gales”)
[+0.013,+0.312] pour ϕ1 − ϕ2
[1.02, 1.62] pour ϕ1
ϕ2
[1.07, 4.64] pour ϕ1/(1−ϕ1)
ϕ2/(1−ϕ2)
LesProportions
Dans LePAC activez le menu LesBaye´siens et le sous-menu LesProportions, ce qui af-
fiche la feneˆtre pour l’infe´rence sur des proportions. Activez le bouton d’option 2 groupes
inde´pendants. Entrez dans les champs approprie´s les effectifs :
• pour g1 : 74 et 20
• pour g2 : 35 et 21
Entrez s’il y a lieu les parame`tres de la distribution initiale beˆta – soit dans chaque cas
1/2 (mais c’est en principe inutile car c’est l’option par de´faut).
Se´lectionnez les boutons d’option
• δ = ϕ1− ϕ2
• <X<
• probabilite´
Entrez dans le champ probabilite´ : 0.95 pour obtenir la figure ci-apre`s (avec 3 de´cimales
pour la limite).
utilise´es ici) les intervalles de confiance 95% : [+0.005, +0.516] (pour leur “direct Edgeworth expansion
method”) et [−0.024, +0.544] (pour leur “transformation method”). Si on a la curiosite´ de calculer ces
meˆmes intervalles pour la diffe´rence oppose´e ϕ2−ϕ1, on a la surprise de ne pas trouver des intervalles
syme´triques, mais au contraire des intervalles largement diffe´rents : respectivement [−0.373, +0.138]
et [−0.401, +0.171] (Lecoutre & Faure, 2005). Les auteurs re´pondent que leur proce´dure peut eˆtre
modifie´e pour re´soudre ce proble`me (Zhou & Qin, 2007), mais cela ne fait que renforcer l’impression
d’“ad hocquerie” des me´thodes fre´quentistes
7“Reference priors”. Bernardo (1979) et Berger et Bernardo (1992) ont de´veloppe´ sous cette appella-
tion des distributions initiales qui visent a` fournir la distribution objective optimale pour un parame`tre
de´rive´ θ, quand celui-ci est le parame`tre d’inte´reˆt. Elles peuvent eˆtre regarde´es comme un raffinement
de la re`gle de Jeffreys. Cette solution pre´sente cependant un certain nombre d’inconve´nients (outre
l’introduction de calculs plus complexes) : elle ne´cessite d’utiliser des distributions initiales diffe´rentes
pour chaque parame`tre auquel on peut s’inte´resser et, surtout, en cherchant a` retrouver certaines
proprie´te´s des proce´dures fre´quentistes, elles peuvent confe´rer aux proce´dures baye´siennes des pro-
prie´te´s inde´sirables de ces proce´dures fre´quentistes. On notera d’ailleurs que, bien que pre´conisant ces
“reference priors”, Berger (2004) dans une illustration pratique des me´thodes baye´siennes subjectives
(diagnostic me´dical, qui est traite´ dans la section suivante) s’en tient a` la solution de Jeffreys
c© Revue MODULAD, 2006 -165- Nume´ro 35
On a bien entendu
Pr(ϕ1 − ϕ2 > 0) = Pr(ϕ1
ϕ2
> 1) = Pr
(ϕ1/(1− ϕ1)
ϕ2/(1− ϕ2) > 1
)
= Pr(ϕ1 > ϕ2) = 0.984
Par sa souplesse, l’approche baye´sienne est aussi bien approprie´e pour un objectif clai-
rement de´cisionnel (notamment se´lectionner le meilleur traitement) que pour l’estimation
(par exemple appre´cier la diffe´rence d’efficacite´ entre les deux traitements).
Comme dans le cas d’une proportion, pour la distribution initiale de Jeffreys les
me´thodes baye´siennes ont de tre`s bonnes proprie´te´s fre´quentistes de couverture (Lecoutre
& ElQasyr, 2005).
Comme pour une proportion, les proce´dures pre´dictives fournissent des solutions pour
choisir les effectifs ou prendre une de´cision d’arreˆter l’expe´rience avant son terme. Dans
le cas de deux e´chantillons binomiaux inde´pendants, les solutions sont une extension
imme´diate, les distributions pre´dictives pour deux e´chantillons futurs e´tant des distribu-
tions Beˆta-Binomiales inde´pendantes ; elles sont illustre´e dans Lecoutre, Derzko et Grouin
(1995). Dans le cas de la re`gle “rejouez le gagnant”, les techniques sont les meˆmes, mais
les distributions d’e´chantillonnage e´tant diffe´rentes, les distributions pre´dictives sont bien
entendu diffe´rentes (ElQasyr, 2006).
7 Une ge´ne´ralisation du mode`le binomial avec trois
proportions
7.1 Le proble`me : Diagnostic me´dical
Mossman & Berger (2001) donnent l’exemple du diagnostic d’une maladie M .
c© Revue MODULAD, 2006 -166- Nume´ro 35
On conside`re une population pour laquelle la probabilite´ de la maladie est ϕ0.
On utilise un test de diagnostic qui est positif [+] avec une probabilite´ ϕ1 si le
patient a la maladie et avec une probabilite´ ϕ2 si le patient n’a pas la maladie
Pr(M) = ϕ0 Pr(+|M) = ϕ1 Pr(+|¬M) = ϕ2
On en de´duit par le the´ore`me de Bayes la probabilite´ θ que le patient ait la maladie
sachant que le test est positif
Pr(M |+) = Pr(+|M)Pr(M)
Pr(+|M)Pr(M) + Pr(+|¬M)Pr(¬M) =
ϕ1ϕ0
ϕ1ϕ0 + ϕ2(1− ϕ0) = θ
Ge´ne´ralisant encore la situation de l’infe´rence sur une proportion binomiale, on sup-
pose que l’on dispose de donne´es inde´pendantes ai (i=0,1,2) ayant chacune une distribu-
tion Binomiale
ai|ϕi ∼ Bin(ϕi, ni)
7.2 Solutions fre´quentistes
Une des motivations des auteurs e´tait que les approches fre´quentistes pre´ce´demment
de´veloppe´es e´taient, soit difficiles a` appliquer, soit relativement peu performantes.
7.3 Solution baye´sienne
Au contraire la solution baye´sienne utilisant trois distribution initiales Beˆta inde´pendantes
pour les ϕi est conceptuellement tre`s simple. C’est une ge´ne´ralisation imme´diate de
l’infe´rence sur deux proportions binomiales. En particulier, pour la solution non infor-
mative de Jeffreys (trois distributions ϕi ∼ Beˆta (1/2, 1/2) inde´pendantes), la proce´dure est
tre`s performante d’un point de vue fre´quentiste.
“A great frequentist confidence procedure” (Berger, 2004)
On peut ainsi conclure ironiquement avec Berger que cette proce´dure est une “grande
proce´dure de confiance fre´quentiste”. De la distribution finale conjointe (encore trois dis-
tributions Beˆta inde´pendantes), on de´duit facilement par une me´thode nume´rique un
intervalle de cre´dibilite´ pour θ.
Ce proble`me a e´galement e´te´ traite´, dans un contexte diffe´rent, par Zaykin, Meng et
Ghosh (2004). Ceux-ci conside`rent, outre la solution pre´ce´dente, le cas le plus simple ou`
ϕ0 est une valeur donne´e, ainsi que le cas ou` la distribution de ϕ0 est une distribution
uniforme sur un intervalle fixe´ a priori (non re´vise´e par les donne´es).
7.3.1 Exemple nume´rique
Conside´rons les donne´es suivantes (Mosmann et Berger, 2001, page 505)
n0 = 30 a0 = 7 n1 = 20 a1 = 17 n2 = 40 a2 = 1
Pour la me´thode baye´sienne objective (Jeffreys), on obtient les distributions finales inde´pendantes
ϕ0 ϕ1 ϕ2
Beˆta (7.5, 23.5) Beˆta (17.5, 3.5) Beˆta (1.5, 39.5)
c© Revue MODULAD, 2006 -167- Nume´ro 35
Conditionnellement a` ϕ0, en remarquant que
θ =
1
1 + 1−ϕ0
ϕ0
ϕ2
ϕ1
on voit que le proble`me se rame`ne a` l’infe´rence traite´e sur le rapport de deux proportions
binomiales inde´pendantes traite´e dans la section pre´ce´dente. On a par exemple
Pr(θ < u |ϕ0) = Pr
(ϕ2
ϕ1
>
1− ϕ0
ϕ0
1− u
u
)
On obtient ainsi les intervalles pour diffe´rentes valeurs fixe´es de ϕ0, par exemple
ϕ0 = 0.15 ϕ0 = 0.20 ϕ0 = 0.25 ϕ0 = 0.30
[0.569, 0.982] [0.647, 0.987] [0.710, 0.990] [0.759, 0.992]
LesProportions
Dans LePAC activez le menu LesBaye´siens et le sous-menu LesProportions, ce qui af-
fiche la feneˆtre pour l’infe´rence sur des proportions. Activez le bouton d’option 2 groupes
inde´pendants. Entrez dans les champs approprie´s les effectifs :
• pour g1 : 17 et 3
• pour g2 : 1 et 39
Entrez s’il y a lieu les parame`tres de la distribution initiale beˆta – soit dans chaque cas
1/2 (mais c’est en principe inutile car c’est l’option par de´faut).
Se´lectionnez les boutons d’option
• ϑ[ϕ0] = ϕ0ϕ1/[ϕ0ϕ1 + (1− ϕ0ϕ2]
et entrez la valeur pour ϕ0 : 0.20
• <X<
• probabilite´
Entrez dans le champ probabilite´ : 0.95 pour obtenir la figure ci-apre`s (avec 3 de´cimales
pour la limite).
c© Revue MODULAD, 2006 -168- Nume´ro 35
La distribution finale de θ est un me´lange des distributions conditionnelles a` ϕ0. On
peut l’obtenir par simulation. En simulant un e´chantillon de 100 000 valeurs du triplet
(ϕ0, ϕ1, ϕ2) et par suite de θ, j’ai obtenu l’intervalle de cre´dibilite´ 95% (Mossman et
Berger avaient trouve´ [0.633, 0.990])
[0.632, 0.990]
Remplac¸ons maintenant la distribution finale de ϕ0 par la distribution uniforme sur
l’intervalle [0.111, 0.404], qui est l’intervalle de cre´dibilite´ 95% pour ϕ0 obtenu pour la
distribution finale pre´ce´dente Beˆta (7.5, 23.5). On obtient alors, toujours pour 100 000
simulations, l’intervalle re´ellement tre`s proche
[0.632, 0.991]
On peut e´galement constater que conditionnellement a` ϕ0 = 0.20 – qui est approxi-
mativement la moyenne 0.1974 de la distribution Beˆta (7.5, 23.5) – l’intervalle obtenu
[0.647, 0.987] est encore proche des pre´ce´dents.
8 Un mode`le multinomial pour un tableau 2× 2
8.1 Le proble`me : Etude d’un mode`le logique
Conside´rons un groupe de n sujets, avec deux ensembles d’attributs (ou variables)
binaires, respectivement note´s V = {v1, v0} et W = {w1, w0}. Pour fixer les ide´es,
supposons que W soit le fait qu’un individu soit de´ce´de´ d’une maladie cardiaque et que
V soit le fait qu’il ait eu ou non au pre´alable un infarctus du myocarde. Conside´rons
l’exemple suivant de “mode`le logique” (Lecoutre et Charron, 2000).
c© Revue MODULAD, 2006 -169- Nume´ro 35
Il existe une implication absolue (ou logique) v1 ⇒ w1 (par exemple) si tous
les individus ayant la modalite´ v1 ont aussi la modalite´ w1, alors que l’inverse
n’est pas ne´cessairement vrai.
Mais l’hypothe`se d’une implication absolue est de peu d’inte´reˆt en pratique,
puisqu’il suffit d’observer une seule fois l’e´ve´nement (v1, w0) pour la re´futer.
En conse´quence, nous devons conside´rer l’hypothe`se plus faible “v1 implique
dans la plupart des cas w1” (v1 ↪→ w1).
Le proble`me est d’e´valuer l’e´cart au mode`le logique d’une implication absolue qui
pre´dit que “la case [v1, w0] est vide”. Un indice d’e´cart peut eˆtre de´fini a` partir des
proportions des diffe´rentes cases
w1 w0
v1 ϕ11 ϕ10 ϕ1.
v0 ϕ01 ϕ00 ϕ0.
ϕ.1 ϕ.0 1
comme
ϕ10
ϕ1.ϕ.0
qui varie de 0 a` +∞
En fait il est plus usuel de conside´rer le comple´ment a` 1 de cet indice, qui sera note´
ηv1↪→w1 (et qui est donc a` proprement parler un indice d’ajustement du mode`le)
ηv1↪→w1 = 1− ϕ10
ϕ1.ϕ.0
(−∞ < ηv1↪→w1 < +1)
Cet indice a e´te´ utilise´ dans des contextes varie´s, avec diffe´rentes approches. Il peut eˆtre
vu notamment comme une mesure d’efficacite´ pre´dictive du mode`le pour pre´dire l’issue
de W e´tant donne´ v1.
La pre´diction est parfaite (il y a une implication absolue) quand ηv1↪→w1 = +1.
La pre´diction est d’autant plus efficace que ηv1↪→w1 est plus proche de +1.
En cas d’inde´pendance on a ηv1↪→w1 = 0.
Une valeur nulle ou ne´gative signifie que le mode`le est rejete´.
En conse´quence, pour pouvoir conclure a` l’efficacite´ pre´dictive du mode`le, nous de-
vons de´montrer que ηv1↪→w1 a une valeur proche de +1. On peut de´finir de la meˆme
manie`re les indices ηv1↪→w0, ηw1↪→v1 et ηw0↪→v0, ou encore caracte´riser l’e´quivalence entre
deux modalite´s. Il y a e´quivalence (absolue) entre v1 et w1 (par exemple) si ηv1↪→w1 = 1
et ηw1↪→v1 = 1 (“les cases [v1, w0] et [v0, w1] sont vides”) et on pourra prendre comme
indice d’ajustement au mode`le d’e´quivalence le minimum de ces deux indices.
Nous supposons ici un mode`le d’e´chantillonnage multinomial, soit pour un e´chantillon
d’effectif n la probabilite´ d’observer les effectifs nij
Pr(n11, n10, n01, n00|ϕ11, ϕ10, ϕ01, ϕ00) = n!
n11!n10!n01!n00!
ϕn1111 ϕ
n10
10 ϕ
n01
01 ϕ
n00
00
8.2 Solutions fre´quentistes
Pour construire un intervalle de confiance, on a propose´ des solutions asymptotiques
(par exemple, Fleiss, 1981), qui sont manifestement inapproprie´es pour les petits e´chantillons.
On a e´galement de´veloppe´ des solutions base´es sur le test conditionnel de Fisher (Copas et
c© Revue MODULAD, 2006 -170- Nume´ro 35
Loeber, 1990 ; Lecoutre et Charron, 2000). Ce test utilise la distribution d’e´chantillonnage
de n11 (par exemple). Un re´sultat classique est que cette distribution n11, e´tant donne´
les marges observe´es fixe´es, de´pend seulement du produit croise´ ρ = ϕ11ϕ00
ϕ10ϕ01
(voir Cox,
1970, page 4). On peut ainsi, a` partir de cette distribution, tester l’hypothe`se nulle ρ = ρ0
contre l’hypothe`se alternative ρ < ρ0 (ou contre ρ > ρ0) en utilisant la probabilite´ que
n11 de´passe la valeur observe´e (dans la direction approprie´e). On a donc une proce´dure
analogue au test binomial conside´re´ dans le cas de l’infe´rence sur une proportion, avec
de la meˆme manie`re la possibilite´ de de´finir une solution “incluante” et une solution
“excluante”. On obtient comme cas particulier le “test de permutation” de Fisher pour
l’hypothe`se nulle ρ = 1, c’est-a`-dire η11 = 0.
En inversant ce test conditionnel, on peut construire un intervalle de confiance pour
le produit croise´ ρ. On en de´duit un intervalle pour η11 en remplac¸ant ρ par ses limites
de confiance dans l’expression suivante qui donne η11 en fonction de ρ
η11 =
1 + (ρ− 1)(ϕ1. + ϕ.1 − ϕ1.ϕ.1 − [(1 + (ϕ1. + ϕ.1)(ρ− 1)2 − 4ϕ1.ϕ.1ρ(ρ− 1)]1/2
2(ρ− 1)ϕ.1(1− ϕ1.)
Malheureusement ces limites de´pendent des “vraies” marges ϕ.1 et ϕ1.. La proce`dure
la plus courante consiste a` simplement remplacer ces parame`tres parasites par leurs esti-
mateurs f.1 et f1.. Elle est nettement plus performante que les solutions asymptotiques,
mais n’est pas satisfaisante pour des valeurs extreˆmes des parame`tres. Meˆme si on peut
trouver des principes plus efficaces pour traiter les parame`tres parasites (par exemple,
Toecher, 1950 ; Rice, 1988), on se trouve ici confronte´ a` un e´ternel proble`me qui est bien
entendu comple`tement e´vite´ par l’approche baye´sienne.
8.3 Solution baye´sienne
La solution baye´sienne pour un mode`le d’e´chantillonnage multinomial est une ge´ne´ralisation
imme´diate du cas binomial. Choisissons une distribution initiale (conjugue´e) de Dirichlet,
qui est une ge´ne´ralisation multidimensionnelle de la distribution Beˆta
(ϕ11, ϕ10, ϕ01, ϕ00) ∼ Dirichlet (ν11, ν10, ν01, ν00)
La distribution finale est e´galement une distribution de Dirichlet dans laquelle les poids
initiaux sont simplement ajoute´s aux effectifs observe´s
(ϕ11, ϕ10, ϕ01, ϕ00)|donne´es ∼ Dirichlet (n11 + ν11, n10 + ν10, n01 + ν01, n00 + ν00)
En utilisant les proprie´te´s fondamentales de la distribution de Dirichlet (voir par
exemple Bernardo & Smith, 1994, page 135), la distribution finale du parame`tre de´rive´
η11 peut eˆtre caracte´rise´e comme une fonction de trois distributions Beˆta inde´pendantes.
X = ϕ10 | donne´es ∼ Beˆta (n10 + ν10, n11 + ν11 + n01 + ν01 + n00 + ν00)
Y =
ϕ00
1− ϕ10 =
ϕ00
1−X | donne´es ∼ Beˆta (n00 + ν00, n11 + ν11 + n01 + ν01)
Z =
ϕ11
1− ϕ10 − ϕ00 =
ϕ11
(1− Y )(1−X) | donne´es ∼ Beˆta (n11 + ν11, n01 + ν01)
c© Revue MODULAD, 2006 -171- Nume´ro 35
puisque
ηv1↪→w1 = 1− X
(X + Z(1− Y )(1−X)) (X + Y (1−X))
nous sommes ramene´s au meˆme proble`me technique que dans la situation pre´ce´dente du
diagnostic me´dical.
8.3.1 Exemple nume´rique : Etude de mortalite´
Conside´rons l’implication “Infarctus du myocarde ↪→ De´ce`s cardiaque avant deux ans”.
Pour des patients qui n’ont subi aucun traitement me´dical, on dispose des donne´es sui-
vantes relatives a` 340 patients “a` risque”
Patients non traite´s De´ce`s
oui non
Infarctus oui 20 72 92 [20/92=0.22]
du myocarde non 17 231 248 [17/248=0.07]
37 303 340
On remarquera que les proportions de de´ce`s sont assez faibles (heureusement !) – res-
pectivement 0.22 apre`s un infarctus et 0.07 sans infarctus – de sorte que l’effectif 72 dans
la case [oui,non] est en rapport e´leve´. En conse´quence des valeurs relativement faibles de
l’indice sont ici “cliniquement signifiantes”. Nous avons ici les valeurs observe´es de l’indice
pour l’implication “Infarctus ↪→ De´ce`s”(case [oui,non] vide) : Hv1↪→w1 = 0.12
pour l’implication “De´ce`s ↪→ Infarctus”(case [non,oui] vide) : Hw1↪→v1 = 0.37
La me´thode baye´sienne objective, avec la distribution initiale de JeffreysDirichlet (1/2, 1/2, 1/2, 1/2),
donne la distribution finale
(ϕ11, ϕ10, ϕ01, ϕ00)|donne´es ∼ Dirichlet (20.5, 72.5, 17.5, 231.5)
ce qui conduit aux intervalles de cre´dibilite´ suivants
“Infarctus ↪→ De´ce`s” : Pr(+0.06 < ηv1↪→w1 < +0.19) = 0.90
“De´ce`s ↪→ Infarctus” : Pr(+0.20 < ηw1↪→v1 < +0.54) = 0.90
Ces intervalles permettent de conclure a` l’existence d’une implication d’importance limite´e
et indiquent qu’en fait ici le de´ce`s est un meilleur pronostic de l’infarctus que l’inverse.
LesProportions
Dans LePAC activez le menu LesBaye´siens et le sous-menu LesProportions, ce qui
affiche la feneˆtre pour l’infe´rence sur des proportions. Activez le bouton d’option LesIm-
plications. Entrez dans les champs approprie´s les effectifs :
• pour v1 : 20 (w1) et 72 (w0)
• pour v0 : 17 (w1) et 231 (w0)
Entrez s’il y a lieu les parame`tres de la distribution initiale beˆta – soit dans chaque cas
1/2 (mais c’est en principe inutile car c’est l’option par de´faut).
Se´lectionnez les boutons d’option
• pour l’implication : v1 → w1 (c’est l’option par de´faut)
• pour l’e´nonce´ : < η <
• pour la courbe : Pr(X>x)
c© Revue MODULAD, 2006 -172- Nume´ro 35
• probabilite´
Entrez dans le champ probabilite´ : 0.90 pour obtenir la figure ci-apre`s (avec 3 de´cimales
pour la limite).
On dispose e´galement des donne´es suivantes relatives a` 357 patients ayant rec¸u un
traitement me´dical a` titre pre´ventif
Patients traite´s De´ce`s
oui non
Infarctus oui 1 78 79 [1/79=0.01]
du myocarde non 13 265 278 [13/278=0.05]
14 343 357
Dans ce cas on espe`re e´videmment que le traitement va re´duire le nombre de de´ce`s
apre`s infarctus. Ide´alement, s’il n’y avait aucun de´ce`s cardiaque chez les patients traite´s
apre`s un infarctus (case [oui,oui] vide), on aurait l’implication absolue “Infarctus ⇒ Non
de´ce`s”. On obtient les re´sultats suivants pour cette implication
“Infarctus ↪→ Non de´ce`s” : Hv1↪→w0 = +0.68 et Pr(−0.10 < ηv1↪→w0 < +0.94) = 0.90
qui montrent qu’ici, en de´pit d’une valeur observe´e nettement plus e´leve´e de l’indice, on
ne peut pas conclure a` l’existence d’une implication. La grande largeur de l’intervalle de
cre´dibilite´ indique que la pre´cision est mauvaise, ce qui est une conse´quence des tre`s faibles
proportions de de´ce`s observe´es. Bien entendu, on ne peut pas non plus conclure qu’il n’a
pas d’implication ou que l’implication est faible. On voit ici le danger qu’il y aurait a`
interpre´ter le re´sultat non significatif des “tests d’inde´pendance” usuels (le khi-deux par
exemple) en faveur de l’hypothe`se d’inde´pendance.
c© Revue MODULAD, 2006 -173- Nume´ro 35
8.3.2 Interpre´tation du seuil observe´ du test de permutation de Fisher
Profitons en pour illustrer la re´interpre´tation baye´sienne du test de permutation
(conditionnel aux marges). Pour le test unilate´ral usuel (solution “incluante”), l’hypothe`se
nulle H0 : ηv1↪→w0 = 0 n’est pas rejete´e, le seuil observe´ e´tant pinc = 0.145. On sait que
ce test est conservateur ; mais si on adopte la solution “excluante”, on obtient un seuil
nettement plus petit pexc = 0.028, ceci e´tant du a` la mauvaise pre´cision expe´rimentale.
Ge´ne´ralisant le cas d’une proportion, il existe deux distributions initiales non informatives
extreˆmes, qui donnent une interpre´tation e´clairante de ces seuils
Pr(ηv1↪→w0 < 0) = 0.145 = pinc
pour la distribution initiale Dirichlet (1, 0, 0, 1) (la plus de´favorable a` H0)
soit la distribution finale Dirichlet (2, 78, 13, 266)
Pr(ηv1↪→w0 < 0) = 0.028 = pexc
pour la distribution initiale Dirichlet (0, 1, 1, 0) (la plus favorable a` H0)
soit la distribution finale Dirichlet (1, 79, 14, 265)
Pr(ηv1↪→w0 < 0) = 0.072 ≈ pinc+pexc2 = 0.086
pour la distribution initiale Dirichlet (1/2, 1/2, 1/2, 1/2)
soit la distribution finale Dirichlet (1.5, 78.5, 13.5, 265.5)
LesProportions
Dans la configuration de la figure pre´ce´dente, entrez maintenant les donne´es :
• pour v1 : 1 (w1) et 78 (w0)
• pour v0 : 13 (w1) et 265 (w0)
Entrez la distribution initiale beˆta :
• pour v1 : 1 (w1) et 0 (w0)
• pour v0 : 0 (w1) et 1 (w0)
Se´lectionnez les boutons d’option
• pour l’implication : v1 → w0
• pour l’e´nonce´ : η <
• pour la courbe : Pr(X>x)
• limite
Entrez dans le champ limite : 0 pour obtenir la figure ci-apre`s (avec 3 de´cimales pour la
probabilite´).
c© Revue MODULAD, 2006 -174- Nume´ro 35
8.3.3 Avantages de l’infe´rence baye´sienne
Dans toutes les situations l’infe´rence baye´sienne traite de manie`re explicite et per-
formante le proble`me des parame`tres parasites. Elle prend explicitement en compte les
proble`mes lie´s au caracte`re discret de la distribution et a` la possibilite´ d’observer des
effectifs nuls graˆce la distribution initiale. Comme pour le cas d’une seule proportion,
le choix d’une distribution initiale non informative n’est ni plus ni moins arbitraire ou
subjective que les conventions de l’approche fre´quentiste.
En outre les probabilite´s de couverture des intervalles de cre´dibilite´ baye´siens se com-
parent favorablement a celles des intervalles de confiance fre´quentistes. Ainsi, une e´tude de
simulation (Lecoutre & Charron, 2000) montre que les deux taux d’erreurs fre´quentistes
associe´s aux deux distributions initiales non informatives extreˆmes encadrent toujours le
taux d’erreur recherche´. La me´thode baye´sienne objective correspondant a` la distribu-
tion initiale syme´trique interme´diaire entre ces deux extreˆmes a des proprie´te´s de cou-
verture remarquables. Naturellement l’e´cart entre ces diffe´rentes distributions initiales se
re´duit jusqu’a` disparaˆıtre quand la taille de l’e´chantillon augmente. En ce qui concerne les
proce´dures fre´quentistes, il apparaˆıt que les intervalles base´s sur l’approche conditionnelle
– avec les solutions incluante, excluante, et moyenne – sont moins performants que leurs
analogues baye´siens. En particulier les deux taux d’erreurs associe´s aux deux solutions
extreˆmes n’encadrent pas toujours le taux recherche´.
Il n’y a aucune difficulte´ a` e´tendre de manie`re imme´diate les proce´dures baye´siennes a`
toute autre situation faisant intervenir le mode`le multinomial. En particulier ici on obtient
tre`s facilement par simulation la distribution du minimum de deux indices pour e´tablir
l’e´quivalence entre deux modalite´s ; on peut aussi aise´ment effectuer une infe´rence pour
comparer les indices associe´s a` deux groupes inde´pendants (par exemple ici les patients
traite´s et non traite´s) ; etc.
9 Infe´rence sur une moyenne
Reprenons l’exemple me´dical utilise´ par Student (1908) dans son article originel sur
la proce´dure qui a e´te´ ensuite appele´e le “test t de Student”.
9.1 Le proble`me : L’exemple historique de Student
Etant donne´, pour chacun des n=10 patients, les heures de sommeil supple´mentaires
procure´es par l’utilisation de chacun des deux somnife`res “soporific [1]” et “soporific [2]”,
Student effectuait une infe´rence sur la diffe´rence des moyennes entre les deux somnife`res,
en construisant une nouvelle se´rie de donne´es obtenue “en soustrayant [1] de [2]”. Les dix
diffe´rences individuelles ainsi obtenues sont donne´es dans le tableau suivant.
+1.2 +2.4 +1.3 +1.3 0 +1.0 +1.8 +0.8 +4.6 +1.4 n = 10
c© Revue MODULAD, 2006 -175- Nume´ro 35
9.2 Solutions fre´quentistes : le test t usuel et l’intervalle de
confiance
Student calculait alors la moyenne +1.580 [d ] et l’e´cart-type (non corrige´) standard
1.167 [soit s = 1.230, corrige´ pour les degre´s de liberte´] de cette se´rie. Il concluait alors
a` partir de sa table de la “distribution t” : “the probability is .9985 or the odds are about
666 to 1 that 2 is the better soporific” (ce qui n’est certainement pas une formulation
fre´quentiste orthodoxe !). En termes modernes, nous calculons la statistique de test t
pour l’infe´rence sur une moyenne sous le mode`le normal t=+1.580/(1.230/
√
10)=+4.062
et nous trouvons le seuil unilate´ral punil = 0.0014 (9 dl), soit 1 − punil = 0.9986 qui
correspond a` la valeur “.9985” calcule´e par Student (les calculs e´tant effectue´s ici a` partir
des donne´es avec la pre´cision maximale).
Pour les ge´ne´ralisations ulte´rieures, il est commode d’introduire la notation b = 1/
√
n.
Nous obtenons alors l’intervalle de confiance 1−α a` partir du 100(1− α/2)-e`me percentile
de la distribution de Student a` q = n− 1 degre´s de liberte´
d± bst1−α/2q soit ici pour α = 0.05 l’intervalle [+0.70,+2.46]
avec b =
1√
n
= 0.316 q = n− 1 = 9 t0.9759 = +2.262
9.3 Solution fiducio-baye´sienne
Cet exemple historique de Student est une application typique de l’approche que nous
appelons “l’analyse spe´cifique” (Rouanet & lecoutre, 1983 ; Lecoutre, 1984, 2005, 2006 ; Le-
coutre et al., 2000). Les donne´es de base sont pour chacun des n=10 patients la diffe´rence
entre les heures de sommeil supple´mentaires obtenues par l’usage d’un somnife`re (“hyos-
cyamine hydobromide”), les heures de sommeil e´tant mesure´es avant et apre`s traitement
avec soit [1] “dextro hyoscyamine hydobromide” soit [2] “lævo hyoscyamine hydobromide”
(on notera que ces donne´es de base sont elles-meˆmes de´ja` des donne´es de´rive´es). L’analyse
de Student est un exemple typique d’infe´rence spe´cifique : elle est effectue´e directement
a` partir des donne´es de´rive´es pertinentes et ne met en jeu que l’infe´rence sur la moyenne
d’une distribution normale.
Nous pouvons appliquer aux donne´es pre´ce´dentes l’infe´rence baye´sienne e´le´mentaire
sur la moyenne, avec seulement deux parame`tres, la diffe´rence moyenne de la population δ
et la variance σ2. Ici d et s2 sont des statistiques conjointement exhaustives pour le couple
(δ, σ2) ; elles ont les distributions d’e´chantillonnage inde´pendantes respectives (avec les
notations b = 1/
√
n et q = n− 1 introduites pre´ce´demment)
d | δ, σ2 ∼ N(δ, b2σ2)
s2 | δ, σ2 ∼ σ2 χ2q
q
que l’on notera plus simplement s2 | δ, σ2 ∼ σ2ϕ2q
La traduction baye´sienne de l’exhaustivite´ est que la distribution finale ne de´pend que de
ces statistiques. En particulier, la distribution finale fiducio-baye´sienne (ou “baye´sienne
objective”) marginale de δ est une distribution t ge´ne´ralise´e. Elle est centre´e sur la
diffe´rence moyenne observe´e d = +1.580 et a pour facteur d’e´chelle e = bs = s/
√
n =
0.389. Cette distribution a le meˆme nombre de degre´s de liberte´ q = n− 1 = 9 que le test
t.
c© Revue MODULAD, 2006 -176- Nume´ro 35
Elle s’e´crit d+ etq, ou encore par analogie avec la distribution normale
δ | donne´es ∼ tq(d, e2) soit ici δ | donne´es ∼ δ | d, s2 ∼ t9(+1.580, 0.3892)
Il faut noter que cette distribution ne doit pas eˆtre confondue avec la distribution t
noncentre´e, familie`re aux utilisateurs de l’analyse de la puissance.
LesMoyennes
Dans LePAC activez le menu LesBaye´siens et le sous-menu LesMoyennes, ce qui
affiche la feneˆtre pour l’infe´rence sur des moyennes. Cliquez sur le bouton Exemples et
cliquez sur Student, ce qui affiche les valeurs pertinentes pour cet exemple dans une
feneˆtre infe´rence sur une moyenne. Cliquez sur le bouton calculer pour obtenir le
test de signification et diffe´rentes statistiques descriptives (voir le de´tail dans la liste
de´roulante t - degre´s de liberte´ : q=9). Puis cliquez sur le bouton ok pour obtenir la
figure ci-apre`s.
Le facteur d’e´chelle e est le de´nominateur de la statistique de test t usuelle, puisque
t = d/e (en supposant d 6= 0)
δ | donne´es ∼ δ | d, t ∼ tq
(
d,
(d
t
)2)
Par conse´quent, la distribution fiducio-baye´sienne de δ peut eˆtre directement de´rive´e de
d et de t=+4.062. Ce re´sultat met en e´vidence la proprie´te´ fondamentale de la statistique
de test t d’eˆtre un estimateur de la pre´cision expe´rimentale, conditionnellement a` la valeur
observe´e d. Plus pre´cise´ment, (d/t)2 estime la variance d’erreur d’e´chantillonnage 2 =
b2σ2 de d.
c© Revue MODULAD, 2006 -177- Nume´ro 35
9.4 Interpre´tation fiducio-baye´sienne du seuil unilate´ral
Le seuil unilate´ral punil du test t est exactement la probabilite´ fiducio-baye´sienne que la
vraie diffe´rence δ soit de signe oppose´ a` celui de la diffe´rence observe´e. Pour les donne´es de
Student (punil = 0.0014), il y a une probabilite´ finale 0.14% que la diffe´rence soit ne´gative
et la probabilite´ comple´mentaire 99.86% qu’elle soit positive.
Pr(δ < 0 | donne´es) = punil = 0.0014 et Pr(δ > 0 | donne´es) = 1− punil = 0.9986
Si l’e´nonce´ de Student “la probabilite´ est .9985 [. . .] que [2] est le meilleur somnife`re”
est interdit dans le cadre fre´quentiste, il est donc parfaitement justifie´ dans le cadre
fiducio-baye´sien.
LesMoyennes
Dans la situation de la figure pre´ce´dente, cliquez sur la courbe de l’effet δ, ce qui affiche
la “feneˆtre des e´nonce´s”.
Se´lectionnez le bouton d’option
• limite
Entrez dans le champ limite : 0 et appuyez sur touche “Entre´e” du clavier (ou cliquez
sur le bouton Calculer) pour obtenir la figure ci-apre`s (avec 4 de´cimales pour les proba-
bilite´s). Notez que l’on peut de´sactiver les cases a` cocher intervalle et ne´gligeable qui
ne sont pas pertinentes ici).
De plus cette interpre´tation met clairement en e´vidence les insuffisances me´thodologiques
des tests de signification. Il devient manifeste que le seuil observe´ en lui-meˆme ne dit rien
c© Revue MODULAD, 2006 -178- Nume´ro 35
sur la grandeur de δ. D’une part, un re´sultat, meˆme “hautement significatif” (punil “tre`s
petit”), permet seulement de conclure que δ a le meˆme signe que la diffe´rence observe´e d.
D’autre part, un re´sultat “non-significatif” n’est en toute rigueur qu’un constat d’igno-
rance, comme cela est illustre´ par l’interpre´tation fiducio-baye´sienne Pr(δ < 0) = Pr(δ >
0) = 1/2 d’un test “parfaitement non-significatif” (soit d = 0).
9.5 Interpre´tation fiducio-baye´sienne de l’intervalle de confiance
fre´quentiste
Il y a une probabilite´ (ou garantie) 95% que δ soit compris entre les limites (fixe´es)
de l’intervalle de confiance fre´quentiste – conditionnellement aux donne´es – soit ici entre
+0.70 et +2.46 heures
Pr(+0.70 < δ < +2.46 | donne´es) = 0.95
LesMoyennes
Dans la situation de la figure pre´ce´dente, se´lectionnez le bouton d’option
• garantie
et entrez dans le champ garantie : 0.95 (que vous pouvez se´lectionner dans la liste
de´roulante) pour obtenir la figure ci-apre`s (avec 2 de´cimales pour les limites). Activez si
besoin la case a` cocher intervalle.
9.6 Re´ponses baye´siennes directes aux questions sur la grandeur
des effets
Au dela` des re´interpre´tations des proce´dures fre´quentistes usuelles, d’autres e´nonce´s
baye´siens fournissent des re´ponses directes aux questions sur la grandeur des effets. Nous
pouvons calculer la probabilite´ que δ de´passe un temps de sommeil supple´mentaire fixe´,
plus aise´ a` interpre´ter, par exemple une heure
Pr(δ > +1 | donne´es) = 0.915
“Il y a une probabilite´ 91.5% que δ de´passe une heure”. Puisque l’unite´ de mesure est ici
signifiante, il est aise´ d’appre´cier la signification pratique de la grandeur de δ.
Pour re´sumer les re´sultats, on peut rapporter : “il y a une probabilite´ finale 91.5% que
la diffe´rence soit positive et grande (δ > +1), une probabilite´ 8.4% qu’elle soit positive
mais limite´e (0 < δ < +1), et une probabilite´ 0.14% qu’elle soit ne´gative”. Un tel e´nonce´
n’a pas d’e´quivalent fre´quentiste.
c© Revue MODULAD, 2006 -179- Nume´ro 35
LesMoyennes
Dans la situation de la figure pre´ce´dente, se´lectionnez le bouton d’option
• limite
et activez la case a` cocher deux limites.
Entrez dans les champs limite et deux limites : 0 et 1 pour obtenir la figure ci-apre`s
(avec 1 de´cimale pour les limites et 4 pour les probabilite´s).
9.7 La question de la re´plication des observations
Etant donne´ l’expe´rience re´alise´e, la distribution pre´dictive exprime notre e´tat de
connaissance sur des donne´es futures. Par exemple, que pouvons-nous dire de la valeur
de la diffe´rence d’ que nous observerions pour de nouvelles donne´es ? La distribution
pre´dictive pour d’ dans un e´chantillon futur d’effectif n’ est naturellement plus disperse´e
que la distribution de δ relative a` la population (ceci d’autant plus que l’effectif du nouvel
e´chantillon est plus petit). Ainsi la distribution fiducio-baye´sienne finale pre´dictive pour d’,
e´tant donne´ la valeur d observe´e dans les donne´es disponibles, est encore une distribution
t ge´ne´ralise´e (naturellement centre´e sur d) :
d’ ∼ tq(d, e2 + e’2) ou` e’ = s/
√
n’
En fait, l’incertitude sur δ conditionnellement aux donne´es disponibles (refle´te´e par e2)
s’ajoute a` l’incertitude sur les re´sultats de l’e´chantillon futur quand δ est connue (refle´te´e
par e’2). Par exemple, a` partir des donne´es de Student, la distribution pre´dictive pour
c© Revue MODULAD, 2006 -180- Nume´ro 35
une unite´ expe´rimentale future (n’ = 1) est d’ ∼ t9(+1.580, 1.2902). Ainsi, pour une unite´
expe´rimentale supple´mentaire, “il y a une probabilite´ 87.4% que la diffe´rence soit positive
et une probabilite´ 78.8% que la diffe´rence de´passe une demi-heure”.
LesMoyennes
Dans la situation de la figure pre´ce´dente, fermez la “feneˆtre des e´nonce´s” pour revenir a`
la “feneˆtre principale”.
Se´lectionnez le bouton d’option
• 1/b2 ∼ n
ce qui affiche l’effectif 10 au lieu de la constante b = 1/
√
10
Activez la case a` cocher donne´es futures et entrez dans le champ 1/b2 ∼ n pour les
donne´es futures l’effectif 1. Cliquez sur le bouton calculer pour obtenir la figure ci-apre`s.
Pour un e´chantillon futur de taille 10, soit une re´plique avec le meˆme effectif (e’ = e),
la distribution pre´dictive est d’ ∼ t9(+1.580, 0.5502).
On notera que l’on peut de meˆme obtenir la distribution pre´dictive relative a` la statis-
tique de test t ou aux limites de cre´dibilite´ fiducio-baye´siennes (soit encore les limites de
confiance fre´quentistes). Ceci met en jeu une nouvelle distribution appele´e K-prime (voir
Lecoutre, 1996a, 1999, 2001). Ces distributions permettent notamment de de´terminer
l’effectif ne´cessaire pour obtenir une conclusion voulue (par exemple δ > 0.5) avec une
garantie fixe´e.
LesMoyennes
Dans la situation de la figure pre´ce´dente, entrez maintenant pour les donne´es futures :
l’effectif n : 10
c© Revue MODULAD, 2006 -181- Nume´ro 35
les degre´s de liberte´ q : 9
ce que vous pouvez afficher directement en cliquant sur le bouton re´plique.
Se´lectionnez le bouton d’option
• Linf
et cliquez sur le bouton calculer pour obtenir la figure ci-apre`s.
On trouve ici pour la diffe´rence de l’e´chantillon futur : “une probabilite´ pre´dictive 0.991
qu’elle soit positive et une probabilite´ 0.959 qu’elle de´passe une demi-heure”.
LesMoyennes
Dans la situation de la figure pre´ce´dente, cliquez sur la courbe de l’effet donne´es futures
d, ce qui affiche la “feneˆtre des e´nonce´s”.
Se´lectionnez le bouton d’option
• limite
et activez la case a` cocher deux limites.
Entrez dans les champs limite et deux limites : 0 et 0.5 pour obtenir la figure ci-apre`s
(avec 1 de´cimale pour les limites et 3 pour les probabilite´s). La case a` cocher ne´gligeable
qui n’est pas pertinentes ici peut eˆtre de´sactive´e.
c© Revue MODULAD, 2006 -182- Nume´ro 35
On trouverait de meˆme pour la limite de cre´dibilite´ infe´rieure 0.95 : “une probabilite´
pre´dictive 0.893 qu’elle soit positive et une probabilite´ 0.715 qu’elle de´passe une demi-
heure”. Pour obtenir une probabilite´ pre´dictive 0.90 que la limite de´passe une demi-heure,
il faudrait un effectif n’ = 29. On notera qu’un “calcul de puissance” traditionnel utilisant
pour les parame`tres les donne´es de l’e´chantillon initial, soit δ = 1.580 et σ = 1.230 qui
seraient suppose´es des valeurs connues ne tiendrait pas compte de l’incertitude sur ces
valeurs ; on trouverait donc sans surprise que sous ces hypothe`ses un effectif n’ = 13 serait
suffisant pour obtenir une probabilite´ pre´dictive 0.90 que la limite de´passe une demi-heure.
LesEffectifs
Dans la situation de la figure pre´ce´dente, fermez la “feneˆtre des e´nonce´s” pour revenir a`
la “feneˆtre principale”. Cliquez sur le bouton LesEffectifs pour afficher la feneˆtre de ce
programme. L’information initiale est automatiquement affiche´e.
Se´lectionnez le bouton d’option effet notable Lγ >x (c’est l’option par de´faut) et entrez
la limite x : 1/2.
Entrez pour l’effectif n : 2 ; activez la case a` cocher a` et entrez l’effectif : 50 ; puis cliquez
sur le bouton calculer P pour obtenir la figure ci-apre`s. Les probabilite´s pour chaque
n sont affiche´es dans la liste de´roulante n→P. Par exemple, pour un effectif futur de
n = 27, on a une probabilite´ 0.894 d’obtenir, avec une garantie 0.95, la conclusion d’un
effet (“notable”) supe´rieur a` une demi-heure, soit L0.95 > 1/2.
c© Revue MODULAD, 2006 -183- Nume´ro 35
9.8 Autres analyses
On peut aussi facilement effectuer des infe´rences sur l’e´cart-type σ (ou sur la variance)
et sur la diffe´rence calibre´e ( ou standardise´e) δ
σ
(voir Lecoutre, 1996a), ou encore une
pre´diction sur l’analyse finale a` une e´tape interme´diaire (Lecoutre, 2001), etc.
Les meˆmes techniques peuvent eˆtre utilise´es avec une distribution initiale conjugue´e,
puisque la distribution finale est du meˆme type que la distribution fiducio-baye´sienne.
LesMoyennes
Dans la situation de la figure pre´ce´dente, fermez le programme LesEffectifs pour revenir
a` la “feneˆtre principale” du programme LesMoyennes (si besoin, activez ce programme,
cliquez sur le bouton Exemples puis se´lectionnez Student, ce qui affiche les valeurs
pertinentes pour cet exemple dans une feneˆtre infe´rence sur une moyenne. cliquez
ensuite sur le bouton ok).
Activez la case a` cocher distribution initiale (sur la meˆme ligne que observations et
entrez les valeurs approprie´es :
• pour l’effet d : 1/2
• pour 1/b2 ∼ n (activez s’il y a lieu cette option) : 1/2
• pour l’s : 1.97
• pour les degre´s de liberte´ q : 9
Activez les cases a` cocher distribution initiale (au dessus des courbes) et distribution
fiducio-baye´sienne et cliquez sur le bouton calculer pour obtenir la figure ci-apre`s.
c© Revue MODULAD, 2006 -184- Nume´ro 35
10 Infe´rence sur une combinaison line´aire de moyennes
Cet exemple e´tend de manie`re imme´diate les solutions pre´ce´dentes a` l’infe´rence sur une
combinaison line´aire de moyennes. On examine ici la compatibilite´ d’un mode`le d’ajuste-
ment polynomial avec les donne´es en analyse de variance.
10.1 Le proble`me : Evaluation du “0.05 cliff effect”
Rosenthal et Gaito ont re´alise´ une des premie`res expe´riences sur l’interpre´tation du
seuil observe´ d’un test de signification (Rosenthal & Gaito, 1963, 1964). Poitevineau &
Lecoutre (2001) ont effectue´ une re´plique de cette expe´rience aupre`s de 18 chercheurs en
psychologie. On demandait au chercheur de se placer dans la situation suivante : il avait
re´alise´ une expe´rience pour tester l’efficacite´ d’un traitement et avait effectue´ un test “t
de Student” pour groupes apparie´s avec un e´chantillon de n sujets. On lui demandait, en
fonction du seuil observe´ p, d’indiquer son degre´ de confiance en l’hypothe`se (alternative)
selon laquelle le traitement a re´ellement un effet. Chaque sujet re´pondait sur une e´chelle
de 0 a` 1 pour 24 cas pre´sente´s dans un ordre ale´atoire et correspondant a` douze valeurs
de p
0.001 0.01 0.03 0.05 0.07 0.10 0.15 0.20 0.30 0.50 0.70 0.90
et a` deux valeurs de n
10 100
c© Revue MODULAD, 2006 -185- Nume´ro 35
Dans l’expe´rience initiale, Rosenthal & Gaito rapportaient une “chute de confiance” (cliff
effect), c’est-a`-dire une forte diminution de la confiance de`s que p e´tait supe´rieur au seuil
fatidique 0.05.
10.2 Re´sultats nume´riques
Les courbes moyennes de la confiance en fonction du seuil p obtenues dans la re´plique
sont semblables a` celles de l’expe´rience de Rosenthal et Gaito.
Cependant les donne´es individuelles sont he´te´roge`nes. On peut facilement identifier
trois cate´gories distinctes de courbes :
(1) des courbes exponentielles de´croissantes ;
(2) des courbes line´aires ne´gatives ;
(3) des courbes en tout-ou-rien ;
et les 18 chercheurs peuvent en conse´quence eˆtre classe´s en trois groupes clairement dis-
tincts.
Le proble`me conside´re´ ici est celui de l’e´valuation de la “chute de confiance”. Nous de-
vons d’abord nous donner une de´finition explicite de l’absence de chute. Nous adopterons
la de´finition utilise´e par Nelson, Rosenthal et Rosnow (1986)
“The patterns of the parent means associated with the four consecutive p-values
.03, .05, .07, and .10 and the predicted means based on a second-degree poly-
nomial equation are the same”
Suivant cette de´finition, on conside`re le polynoˆme du second degre´ qui ajuste le mieux les
donne´es pour les quatre seuils conside´re´s (0.03, 0.05, 0.07, et 0.10). La moyenne quadra-
tique des re´sidus donne un indice d’ajustement (“goodness of fit”) pour e´valuer la chute
de confiance.
On obtient par exemple pour le groupe “exponentiel” les re´sultats suivants.
LesMoyennes
Dans LePAC activez le menu LesBaye´siens et le sous-menu LesMoyennes, ce qui
affiche la feneˆtre pour l’infe´rence sur des moyennes. Cliquez sur le bouton Donne´es pour
afficher l’e´diteur de donne´es. Se´lectionnez le nombre de groupes : 1 et le nombre
d’occasions (nombre de re´pe´titions pour chaque sujet) : 4. Entrez les donne´es pour
le groupe exponentiel que vous trouverez dans le tableau suivant (0.8625 0.7900 0.7200
0.5850, etc.) en les se´parant par des espaces ou un passage a` la ligne.
Cliquez ensuite sur le bouton calculer (vous pouvez enregistrer les donne´es si vous le
souhaitez) pour afficher la feneˆtre correspondant a` la structure S×0 avec les ststistiques
c© Revue MODULAD, 2006 -186- Nume´ro 35
pertinentes (moyennes, e´carts-types, covariances). Cliquez sur le bouton Re´gression ou`
sont affiche´es les moyennes observe´es.
Entrez les abscisses z pour la re´gression : respectivement 0.03, 0.05, 0.07, 0.10 pour
o1 a` o4. Se´lectionnez le bouton d’option :
• line´aire+quadratique
et cliquez sur le bouton calculer pour obtenir la figure ci-apre`s.
En cliquant sur le bouton ok re´siduelle vous obtenez les infe´rences sur l’effet δ pre´sente´es
plus loin.
Les tableaux ci-apre`s fournissent les donne´es individuelles (moyenne´es pour chaque p
sur les deux valeurs de n), ainsi que les moyennes observe´es et ajuste´es et les re´sidus pour
les trois groupes de sujets.
c© Revue MODULAD, 2006 -187- Nume´ro 35
groupe “exponentiel” (10 sujets)
p 0.03 0.05 0.07 0.10 contraste pertinent
0.8625 0.7900 0.7200 0.5850 +0.0024
0.9450 0.9250 0.9325 0.8725 +0.0086
0.4850 0.4500 0.1775 0.0400 −0.0501
0.6475 0.6400 0.4925 0.4400 −0.0301 d = −0.016
0.1900 0.1850 0.1400 0.1500 −0.0107 s = 0.023
0.4875 0.5000 0.2775 0.2225 −0.0503 e = s/√10 = 0.0074
0.4100 0.4850 0.4900 0.1400 +0.0158 t = d/e = −2.202
0.6500 0.5925 0.4200 0.3300 −0.0269
0.7300 0.7150 0.6675 0.5300 +0.0037
0.7200 0.7275 0.5900 0.4325 −0.0224
moyenne observe´e 0.613 0.601 0.491 0.374
moyenne ajuste´e 0.621 0.577 0.511 0.370
e´cart (re´sidu) −0.009 +0.024 −0.020 +0.005
groupe “line´aire” (4 sujets)
p 0.03 0.05 0.07 0.10 contraste pertinent
0.9025 0.8475 0.9125 0.7925 +0.0235 d = +0.007
0.8500 0.7950 0.6250 0.7150 −0.0073 s = 0.032
0.8500 0.7800 0.7800 0.6825 +0.0427 e = s/
√
4 = 0.016
0.9350 0.8725 0.9050 0.8300 +0.0256 t = d/e = +0.457
moyenne observe´e 0.884 0.824 0.806 0.755
moyenne ajuste´e 0.881 0.834 0.797 0.757
e´cart (re´sidu) +0.004 −0.011 +0.009 −0.002
groupe “tout-ou-rien” (4 sujets)
p 0.03 0.05 0.07 0.10 contraste pertinent
0.8275 0.8800 0.2475 0.0800 −0.1443 d = −0.159
0.2075 0.4050 0.1800 0.0200 −0.0677 s = 0.071
0.8625 0.8200 0 0 −0.1878 e = s/√4 = 0.036
1 1 0 0 −0.2358 t = d/e = −4.455
moyenne observe´e 0.724 0.776 0.107 0.025
moyenne ajuste´e 0.808 0.543 0.301 −0.019
e´cart (re´sidu) −0.083 +0.233 −0.194 +0.044
L’analyse de la comparaison re´siduelle conduit a` conside´rer le contraste cubique avec
des coefficients approprie´s
[+0.1310,−0.3668,+0.3057,−0.0699]
Nous avons par exemple pour le groupe “tout-ou-rien” l’effet observe´ associe´ au contraste
pre´ce´dent
d = 0.1310× 0.724− .3668× 0.776 + .3057× 0.107− .0699× 0.025 = −0.159
Par construction 0.159 est la moyenne quadratique des re´sidus
0.159 =
√
(−0.083)2 + (+0.233)2 + (−0.194)2 + (+0.044)2
4
= |d|
c© Revue MODULAD, 2006 -188- Nume´ro 35
On notera que les signes des coefficients ont e´te´ arbitrairement choisis de sorte qu’une
valeur de d ne´gative repre´sente une chute de confiance, une valeur positive traduisant au
contraire une augmentation.
La situation ge´ne´rale traite´e ici est l’infe´rence sur une combinaison line´aire de moyennes
δ. Nous avons deux objectifs distincts selon les groupes :
- pour les groupes “exponentiel” et “line´aire”, de´montrer que l’effet de chute est petit
(ne´gligeable) et donc montrer que δ est proche de ze´ro (|δ| < ) ;
- pour le groupe “tout-ou-rien”, de´montrer que l’effet de chute est grand (notable) et donc
montrer que δ est supe´rieur a` une valeur positive juge´e suffisante (δ > ’).
10.3 Solution fiducio-baye´sienne
A partir des donne´es individuelles constitue´es par le contraste pertinent (voir ta-
bleau 1), nous sommes ramene´s a` l’infe´rence sur une moyenne traite´e pre´ce´demment.
Nous en de´duisons les distributions fiducio-baye´siennes pour δ
Groupe exponentiel t ∼ t9(−0.016, 0.0072)
Groupe line´aire t ∼ t4(+0.007, 0.0162)
Groupe tout-ou-rien t ∼ t4(−0.159, 0.0362)
et les e´nonce´s pertinents sur l’effet de chute de confiance
• pour de´montrer que l’effet de chute est ne´gligeable
Groupe exponentiel (n = 10) Pr(|δ| < 0.030) = 0.95
Groupe line´aire (n = 4) Pr(|δ| < 0.052) = 0.95
• pour de´montrer que l’effet de chute est notable
Groupe tout-ou-rien (n = 4) Pr(δ < −0.075) = 0.95
Il est manifeste que le groupe minoritaire tout-ou-rien est largement responsable de
l’effet de chute moyen. La me´thodologie baye´sienne offre une grande souplesse en permet-
tant de choisir le type d’e´nonce´ le plus approprie´ au vu des donne´es. Un e´nonce´ particulier
sur un parame`tre n’est qu’une des fac¸ons possibles de re´sumer la distribution finale. Cela
la rend ide´alement adapte´e pour e´tendre une analyse de donne´es exploratoire.
Bien entendu, on pourrait calculer une probabilite´ conjointe relative aux trois groupes.
Cela pourrait notamment eˆtre approprie´ si l’on objectait que ces groupes ont e´te´ constitue´s
au vu des donne´es et que cela impose donc d’utiliser une me´thode de comparaison multiple.
Cela ne soule`ve pas de proble`me conceptuel, mais ne´cessite le recours a` une me´thode
d’inte´gration nume´rique (facile a` mettre en œuvre par simulation).
Ici encore, d’autres analyses sont faciles a` envisager.
PARTIE III - LES ASPECTS
TECHNIQUES :
QUELQUES OUTILS DE BASE
c© Revue MODULAD, 2006 -189- Nume´ro 35
11 De´rivation de la distribution finale
11.1 Echantillonnage binomial
Pour le mode`le binomial de parame`tre ϕ, pour un e´chantillon de taille n avec a succe`s
et b = n− a e´checs, la distribution d’e´chantillonnage est
Pr(a |ϕ) = n!
a!b!
ϕa(1− ϕ)b, 0 ≤ a ≤ n
et la vraisemblance est
v(ϕ | a) ∝ ϕa(1− ϕ)b
11.1.1 Distribution initiale Beˆta
La distribution initiale a pour densite´
p(ϕ) =
1
B(a0, b0)
ϕa0−1(1− ϕ)b0−1
ou` la fonction Beˆta comple`te B(a0, b0) est de´finie a` partir de la fonction Gamma
B(a0, b0) =
Γ(a0)Γ(b0)
Γ(a0 + b0)
De
∫ 1
0
p(ϕ)dϕ = 1, on de´duit l’inte´grale Beˆta qui servira pour de´river la distribution
pre´dictive ∫ 1
0
ϕu−1(1− ϕ)v−1dϕ = B(u, v)
Cette inte´grale permet e´galement de de´river les moments de la distribution Beˆta
Moy(ϕr) =
∫ 1
0
1
B(a0, b0)
ϕa0+r−1(1− ϕ)b0−1dϕ = B(a0 + r, b0)
B(a0, b0)
=
r−1∏
j=0
a0 + j
a0 + b0 + j
cette formule e´tant valide pour tout r re´el tel que r > −a0
La densite´ de la distribution finale est proportionnelle au produit v(ϕ | a)p(ϕ), soit
p(ϕ | a) ∝ ϕa0+a−1(1− ϕ)b0+b−1
Par comparaison avec les termes en ϕ de la densite´ initiale, on voit qu’il s’agit encore
d’une distribution Beˆta obtenue en remplac¸ant simplement a0 par a0 + a et b0 par b0 + b
soit
ϕ | a ∼ Beˆta (a1, b1) avec a1 = a0 + a et b1 = b0 + b
On peut voir que cette de´rivation est valide meˆme si la densite´ initiale est impropre
(a0 = 0 ou b0 = 0). La densite´ finale n’est impropre que si a1 = 0 ou b1 = 0.
11.1.2 Distribution initiale me´lange de densite´s Beˆta
Soit la distribution initiale λ01Beˆta (a
0
1, b
0
1)⊕ · · · ⊕ λ0JBeˆta (a0J , b0J) de densite´
p(ϕ) =
j=J∑
j=1
λ0j
B(a0j , b
0
j)
ϕa
0
j−1(1− ϕ)b0j−1
j=J∑
j=1
λ0j = 1
La densite´ de la distribution finale est proportionnelle au produit v(ϕ | a)p(ϕ), soit
c© Revue MODULAD, 2006 -190- Nume´ro 35
p(ϕ | a) ∝
j=J∑
j=1
λ0j
B(a0j , b
0
j)
ϕa
0
j+a−1(1− ϕ)b0j+b−1
Pour chaque j les termes en ϕ sont ceux de la distribution Beˆta (a0j + a, b
0
j + b), qui a
pour densite´
1
B(a0j + a, b
0
j + b)
ϕa
0
j+a−1(1− ϕ)b0j+b−1
On en de´duit donc que la distribution finale est le me´lange
λ1Beˆta (a
0
1 + a, b
0
1 + b)⊕ · · · ⊕ λJBeˆta (a0J + a, b0J + b)
avec
λj =
λ0j B(a
0
j + a, b
0
j + b)/B(a
0
j , b
0
j)∑k=J
k=1 λ
0
k B(a
0
k + a, b
0
k + b)/B(a
0
k, b
0
k)
11.2 Echantillonnage de Pascal
Pour le mode`le binomial ne´gatif (e´chantillonnage de Pascal) dans lequel on arreˆte
l’expe´rience quand on a observe´ un nombre fixe´ a` l’avance a de succe`s , c’est le nombre
d’observations n qui est une variable ale´atoire. Sa distribution d’e´chantillonnage s’e´crit
Pr(n |ϕ) = (n− 1)!
(a− 1)!(n− a)! ϕ
a(1− ϕ)n−a, n ≥ a
et la vraisemblance est encore
v(ϕ | a) ∝ ϕa(1− ϕ)n−a
d’ou` la meˆme proce´dure.
12 De´rivation de la distribution pre´dictive
12.1 Echantillonnage binomial
Pour la distribution initiale ϕ ∼ Beˆta (a0, b0), la distribution pre´dictive du nombre de
succe`s a pour un e´chantillon de taille n est
Pr(a) =
∫ 1
0
Pr(a |ϕ)p(ϕ)dϕ = (n− 1)!
(a− 1)!(n− a)!
1
B(a0, b0)
∫ 1
0
ϕa1(1− ϕ)b1dϕ1
d’ou`, en utilisant l’inte´grale Beˆta de´finie pre´ce´demmment, la distribution
Pr(a) =
n!
a!(n− a)!
B(a0 + a, b0 + b)
B(a0, b0)
, 0 ≤ a ≤ n
qui est la distribution Beˆta-binomiale, ou distribution de Po´lya.
12.2 Echantillonnage binomial ne´gatif
La distribution pre´dictive du nombre d’observations n pour un e´chantillon avec a
succe`s s’obtient de la meˆme manie`re. On a dans ce cas
Pr(n) =
(n− 1)!
(a− 1)!(n− a)!
B(a0 + a, b0 + n− a)
B(a0, b0)
, n ≥ a
qui est la distribution Beˆta-Pascal.
c© Revue MODULAD, 2006 -191- Nume´ro 35
13 Calcul des moments par me´lange – Espe´rance condi-
tionnelle
Les calculs par me´lange sont caracte´ristiques de l’infe´rence baye´sienne et fournissent
des principes ge´ne´raux de de´monstration. En particulier, il est souvent possible ainsi
d’expliciter les moments des distributions finales, ce qui fournira en particulier des ap-
proximations de ces distributions. Quand on doit recourir a` des me´thodes d’inte´gration
nume´rique, il sera utile de controˆler les re´sultats a` l’aide de ces approximations.
13.1 Exemple 1 – Moments de la distribution pre´dictive
Pour le mode`le binomial, on a la moyenne de la distribution d’e´chantillonnage (condi-
tionnelle a` ϕ)
Moy(a |ϕ) = nϕ
d’ou` la moyenne de la distribution pre´dictive
Moy(a) = nMoy(ϕ) =
na0
a0 + b0
On peut calculer de la meˆme manie`re les autres moments, par exemple
Moy(a2 |ϕ) = nϕ(nϕ+ 1− ϕ)
d’ou`
Moy(a2) =
n(n− 1)a0(a0 + 1)
(a0 + b0)(a0 + b0 + 1)
+
na0
a0 + b0
Etc.
13.2 Exemple 2 – Moments de la distribution du rapport τ =
ϕ1/ϕ2
Dans le cas de deux e´chantillons binomiaux inde´pendants (ou dans la re`gle “rejouez
le gagnant”), on est amene´ a` conside´rer deux distributions Beˆta inde´pendantes ϕ1 ∼
Beˆta (a1, b1) et ϕ2 ∼ Beˆta (a2, b2). Cherchons par exemple les moments du rapport τ =
ϕ1/ϕ2.
On a la distribution conditionnelle a` ϕ2
τ =
ϕ1
ϕ2
|ϕ2 ∼ 1
ϕ2
Beˆta (a1, b1) 0 < τ <
1
ϕ2
d’ou` les moments conditionnels qui se de´duisent des moments de la distribution Beˆta (a1, b1)
Moy(τ r |ϕ2) = B(a1 + r, b1)
B(a1, b1)
ϕ−r2
c© Revue MODULAD, 2006 -192- Nume´ro 35
et les moments voulus qui se de´duisent des moments de la distribution Beˆta (a2, b2)
Moy(τ r) =
B(a1 + r, b1)
B(a1, b1)
Moy(ϕ−r2 ) =
B(a1 + r, b1)
B(a1, b1)
B(a2 − r, b2)
B(a2, b2)
a2 > r
Ainsi, dans l’exemple conside´re´ pour la re`gle d’expe´rimentation “rejouez le gagnant”, on a
les deux distributions finales inde´pendantes ϕ1 ∼ Beˆta (74.5, 20.5) et ϕ2 ∼ Beˆta (35.5, 21.5),
d’ou` notamment
Moy(τ) =
a1
a1 + b1
a2 + b2 − 1
a2 − 1 = 1.2729
Moy(τ 2) =
a1 + 1
a1 + b1 + 1
a2 + b2 − 2
a2 − 2 Moy(τ) = 1.6436 d’ou` ety(τ) = 0.1525
14 Calcul des densite´s et fonctions de re´partitions
par me´lange
Le meˆme principe de me´lange s’applique aux densite´s et aux fonctions de re´partition.
14.1 Exemple 1 – De´rivation de la distribution du t de Student
Ainsi la distribution du t de Student est “classiquement” de´finie comme le rapport
t = x/y ou` x et y ont des distributions inde´pendantes, respectivement N(0, 1) et (χ2q/q)
1/2.
Plutoˆt que d’expliciter la distribution conjointe du couple (X, Y ) et d’effectuer un chan-
gement de variable, e´crivons
t | y ∼ N(0, 1
y
)
Nous en de´duisons directement
p(t) =
∫ +∞
0
p(t | y)p(y)dy
On peut ainsi (meˆme si le calcul est formellement e´quivalent) e´viter le calcul du Jacobien
lie´ a` un changement de variable et obtenir plus facilement des formules approprie´es. En
outre la de´finition de la distribution de Student comme me´lange est celle qui intervient
naturellement dans l’infe´rence baye´sienne.
Bien entendu les moments s’obtiennent encore par me´lange, par exemple
Moy(t2 | y) = y−2 d’ou` Moy(t2) = Moy(y−2) = q
q − 2 q > 2
On trouvera des de´monstrations de´taille´es et des applications a` d’autres distributions
dans Lecoutre (1996a, 2000).
c© Revue MODULAD, 2006 -193- Nume´ro 35
14.2 Exemple 2 – Infe´rence sur le rapport de deux distributions
Beˆta de parame`tres entiers
Soit ϕ1 et ϕ2 inde´pendamment distribue´es Beˆta (a1, n1− a1) et Beta(a2, n2− a2). On
suppose ai et ni > ai entiers positifs. On veut calculer P = Pr(
ϕ1
ϕ2
> u). Pour 0 < u ≤ 1,
on peut utiliser le re´sultat suivant
P =
a1−1∑
j=0
Γ(a2 + j)
Γ(a2)
Γ(n2)
Γ(n2 + j)
(n1−1
j
)
uj 2F1(j − n1 + 1, j + a2, j + n2, u) 0 < u ≤ 1
ou` 2F1(a, b, c, u) est la fonction hyperge´ome´trique
Pour u > 1, on peut calculer de la meˆme manie`re P = 1− Pr(ϕ2
ϕ1
> 1
u
).
Preuve
Conditionnellement a` ϕ2
Pr(
ϕ1
ϕ2
> u |ϕ2) = Pr
(
Beˆta (a1, n1 − a1) > uϕ2
)
= Pr
(
Bin(uϕ2, n1 − 1) < a1
)
ou` on utilise la relation fondamentale entre la fonction de re´partition de la distribution
Beˆta et celle de la distribution Binomiale : Pr(Beˆta (a, b) < ϕ) = Pr(Bin(ϕ, a+ b− 1) >
a− 1) (Johnson, Kotz & Kemp, 1992). On en de´duit
Pr(
ϕ1
ϕ2
> u |ϕ2) =
a1−1∑
j=0
Pr
(
Bin(n1 − 1, uϕ2) = j
)
=
a1−1∑
j=0
(n1−1
j
)
ujϕj2(1− uϕ2)n1−j−1
La probabilite´ marginale P = Pr(ϕ1
ϕ2
> u) s’obtient par le “me´lange” par la densite´
p(ϕ2) de la distribution Beˆta (a2, n2 − a2)
P =
a1−1∑
j=0
(n1−1j )u
j
∫ 1
0
ϕj2(1− uϕ2)n1−j−1p(ϕ2)dϕ2
dont on de´duit le re´sultat
P =
a1−1∑
j=0
(n1−1j )u
j Γ(n2)
Γ(a2)Γ(n2 − a2)
∫ 1
0
ϕj+a2−12 (1− ϕ2)n2−a2−1(1− uϕ2)n1−j−1dϕ2
=
a1−1∑
j=0
Γ(a2 + j)
Γ(a2)
Γ(n2)
Γ(n2 + j)
(n1−1j )u
j
2F1(j − n1 + 1, j + a2, j + n2, u)
Voir par exemple http://functions.wolfram.com/HypergeometricFunctions/Hypergeometric2F1/
pour la de´finition et les proprie´te´s de la fonction hyperge´ome´trique.
c© Revue MODULAD, 2006 -194- Nume´ro 35
15 Me´thodes nume´riques
Si les me´thodes baye´siennes reposent sur le principe ge´ne´ral selon lequel la densite´
finale est proportionnelle au produit de la densite´ initiale et de la vraisemblance
p(θ | donne´es) = c v(θ | donne´es) p(θ)
il n’y a e´videmment pas de moyen a` la fois simple et universel de “normaliser” ce produit,
c’est-a`-dire de trouver la constante c telle que
∫
p(θ | donne´es) dθ = 1.
En dehors des cas ou` l’on peut “identifier” une distribution connue – et conduisant
a` des calculs “faciles” 8 – il faut donc recourir a` des techniques d’inte´gration nume´rique,
me´thodes de´terministes classiques ou me´thodes de Monte-Carlo. Ce sont surtout ces
dernie`res qui ont rec¸u l’attention des statisticiens baye´siens, en raison de leur possibilite´
de traiter les proble`mes les plus complexes, meˆme (et surtout) quand le proble`me ne´cessite
de calculer une inte´grale de dimension e´leve´e. Il s’agit de simuler la distribution de proba-
bilite´ voulue, donc de programmer un algorithme qui ge´ne`re (pseudo) ale´atoirement des
valeurs distribue´es selon cette distribution. L’appellation de Monte-Carlo provient natu-
rellement de la roulette de son casino, conside´re´e comme un me´canisme type pour ge´ne´rer
des nombres au hasard. Ces me´thodes sont de plus en plus re´pandues et de nombreuses
variantes – plus ou moins sophistique´es selon la nature du proble`me – ont e´te´ mises au
point (voir notamment Tierney, 1994 ; Chib & Greenberg, 1995 ; Gilks, Richardson &
Spiegelhalter, 1996 ; Gamerman, 1997 ; Robert & Casella, 2004)). Elles peuvent eˆtre vir-
tuellement applique´es a` n’importe quelle analyse baye´sienne. L’inte´reˆt croissant pour ces
techniques – et leur roˆle de plus en plus important – est par exemple atteste´ par la place
(le chapitre 9) qui leur est maintenant consacre´e dans la troisie`me e´dition du livre de Lee
(2004). Pour le lecteur inte´resse´, ce chapitre pourra constituer un “tutoriel” de base.
Ici je donnerai simplement des exemples de techniques de simulations e´le´mentaires. Je
de´crirai aussi une me´thode (de´terministe) simple et efficace, mais souvent me´connue.
15.1 Des simulations e´le´mentaires
Conside´rons a` titre d’illustration le calcul de Pr(ϕ1
ϕ2
> u) dans l’exemple de la re`gle
d’expe´rimentation “rejouez le gagnant”. On a les deux distributions finales inde´pendantes
ϕ1 ∼ Beˆta (74.5, 20.5) et ϕ2 ∼ Beˆta (35.5, 21.5). Supposons que l’on veuille calculer
Pr(ϕ1
ϕ2
> 1.25). Il suffit de simuler un e´chantillon de taille N du couple (ϕ1, ϕ2), donc
d’effectuer N tirages selon la distribution conjointe. On en de´duira un e´chantillon de
n’importe quel parame`tre de´rive´ auquel on s’inte´resse – par exemple la diffe´rence, le rap-
port, la moyenne, le maximum, etc. – permettant de calculer une probabilite´ relative a` ce
parame`tre (et bien d’autres quantite´s).
On trouvera ci-apre`s un exemple de programme, e´crit dans un pseudo langage, ef-
fectuant le calcul de Pr(ϕ1
ϕ2
> 1.25). Il suffit de disposer d’une fonction rBeta(A,B) qui
retourne une valeur ale´atoire pour la distribution Beˆta (A,B). P est une approximation
de la probabilite´ cherche´e.
8Obtenir des formules explicites, comme dans l’exemple pre´ce´dent du rapport deux distributions
Beˆta ne re´soud pas ne´cessairement tous les proble`mes de calcul. Ainsi, le calcul de la fonction hy-
perge´ome´trique 2F1 ne´cessite lui-meˆme des me´thodes nume´riques. . . En outre, ces formules ne sont
valables que pour des entiers ; dans le cas de re´els, on peut encore obtenir des formules “explicites”
pour les densite´s, mais le calcul de la fonction de re´partition ne´cessite encore le calcul d’une inte´grale.
c© Revue MODULAD, 2006 -195- Nume´ro 35
N = 100000
A = 74.5 : B = 20.5 : C = 35.5 : D = 21.5
U = 1.25
I = 0
M1 = 0 : M2 = 0
Faire
X = rBeta(A,B)
Y = rBeta(C,D)
R = X/Y
Si R > U alors P = P+1
M1 = M1 + R
M2 = M2 + R∗R
I = I+1
Jusqu’a` ce que I > N
P = P/N
M1= M1/N
M2= M2/N
Pour N=100 000 tirages, j’ai trouve´ P≈ 0.523 (la valeur exacte avec 3 de´cimales e´tant
0.521). Pour donner une ide´e de la variabilite´, les valeurs obtenues par tranches successives
de 10 000 tirages e´taient les suivantes
0.524 0.523 0.518 0.519 0.524 0.529 0.529 0.514 0.521 0.531
Par comparaison, en effectuant 9 fois 100 000 autres tirages, j’ai obtenu successivement
0.520 0.521 0.522 0.519 0.521 0.522 0.520 0.520 0.518
On peut de cette manie`re obtenir les percentiles de la distribution. Par exemple, pour
calculer u tel que Pr(ϕ1
ϕ2
> u) = 0.95, la me´thode la plus simple consiste a` garder les
valeurs R calcule´es a` chaque tirage dans un tableau, puis d’ordonner ce tableau et de
prendre comme valeur approche´e la 0.05×N-ie`me valeur (la 50e`me pour N=10 000). Si
N est grand, ordonner le tableau peut eˆtre tre`s long, mais on peut alors trouver des
proce´dures plus efficaces. On peut e´videmment obtenir une figuration approche´e de la
densite´ de la distribution, de sa fonction de re´partition, etc. Cette figuration sera utile
pour appre´cier la plausibilite´ des re´sultats et de´tecter une anomalie e´ventuelle.
Il est e´galement utile, quand cela est possible de calculer des quantite´s qui peuvent
eˆtre ve´rifie´es inde´pendamment. Ainsi, dans le programme ci-dessus, j’ai inclus le calcul
approche´ des moments M1≈Moy(τ) et M2≈Moy(τ 2). Pour N=100 000 tirages, les valeurs
obtenues, Moy(τ) ≈ 1.2726 et ety(τ) ≈ 0.1523, sont tre`s proches des valeurs exactes
avec 4 de´cimales 1.2729 et 0.1525 calcule´es pre´ce´demment. C’est notamment dans les cas
particuliers ou` la densite´ des distributions en jeu n’est pas borne´e – par exemple une
distribution du type Beˆta (0.5, b) – que la me´thode doit eˆtre utilise´e avec pre´caution et
que de telles ve´rifications seront utiles.
La ge´ne´ralisation aux situations conside´re´es dans les sections “une ge´ne´ralisation du
mode`le binomial avec trois proportions” et “un mode`le multinomial pour le tableau 2×2”
est imme´diate.
c© Revue MODULAD, 2006 -196- Nume´ro 35
15.2 Une me´thode simple pour calculer certaines probabilite´s
Novick et Jackson (1974, pages 338-342), dans un livre malheureusement maintenant
difficile a` trouver, de´crivent une me´thode simple pour calculer la probabilite´ Pr(ϕ1−ϕ2 >
u) (avec les notations utilise´es ici). Cette me´thode est facilement ge´ne´ralisable ; reprenons
ainsi l’exemple pre´ce´dent du calcul de Pr(ϕ1
ϕ2
> 1.25). La situation est repre´sente´e dans
la figure ci-apre`s : il s’agit de calculer la probabilite´ du triangle supe´rieur de´limite´ par la
droite bleue d’e´quation ϕ1 = 1.25ϕ2.
On voit que cette probabilite´ peut eˆtre encadre´e :
• pour une majoration, par la somme des probabilite´s associe´es aux rectangles rouges ;
• pour une minoration, par la somme des probabilite´s associe´es aux rectangles limite´s a`
la base par les traits blancs.
La probabilite´ d’un rectangle est simplement le produit des probabilite´s marginales
donne´es par les distributions finales Beˆta inde´pendantes. On peut donc the´oriquement
approximer la probabilite´ cherche´e avec une pre´cision fixe´e a` l’avance.
Comme illustration (grossie`re), supposons que l’on “de´coupe” l’ensemble des valeurs
possibles de ϕ2 (l’axe des abcisses) – soit [0, 0.80] (0.80 = 1/1.25) – en 10 intervalles e´gaux
[x, y] (sur la figure il y en a 25). On calcule les probabilite´s des rectangles correspondants,
d’ou` les re´sultats suivants.
c© Revue MODULAD, 2006 -197- Nume´ro 35
majoration minoration
x y Pr(ϕ2 ∈ [x, y]) ×Pr(ϕ1 > 1.25x) = ×Pr(ϕ1 > 1.25y) =
0 0.08 0.0000 ×1.0000 = 0.0000 ×1.0000 = 0.0000
0.08 0.16 0.0000 ×1.0000 = 0.0000 ×1.0000 = 0.0000
0.16 0.24 0.0000 ×1.0000 = 0.0000 ×1.0000 = 0.0000
0.24 0.32 0.0000 ×1.0000 = 0.0000 ×1.0000 = 0.0000
0.32 0.40 0.0003 ×1.0000 = 0.0003 ×1.0000 = 0.0003
0.40 0.48 0.0144 ×1.0000 = 0.0144 ×0.9999 = 0.0144
0.48 0.56 0.1489 ×0.9999 = 0.1489 ×0.9706 = 0.1445
0.56 0.64 0.4335 ×0.9706 = 0.4207 ×0.3697 = 0.1603
0.64 0.72 0.3431 ×0.3697 = 0.1269 ×0.0006 = 0.0002
0.72 0.80 0.0586 ×0.0006 = 0.00003 ×0.0000 = 0.0000
somme 0.7113 0.3197
Compte tenu du tre`s petit nombre d’intervalles, on obtient sans surprise ici pour
la probabilite´ Pr(ϕ1
ϕ2
> 1.25) un encadrement tre`s large : [0.3197,0.7113], mais si on
retient la moyenne de ces deux probabilite´s (soit une interpolation line´aire), on trouve
une estimation de la probabilite´ (0.3197+0.7113)/2 = 0.516, qui est e´tonnamment proche
de la valeur exacte (avec 3 de´cimales) 0.521.
Cette me´thode est donc efficace et reste rapide meˆme si on augmente sensiblement le
nombre d’intervalles. Bien entendu, comme toute me´thode d’inte´gration nume´rique, elle
peut eˆtre raffine´e.
A partir de l’exemple pre´ce´dent, on voit imme´diatement une ame´lioration tre`s simple
a` apporter. On tronquera l’ensemble des valeurs possibles de ϕ2 de manie`re a` e´liminer
celles qui ne modifient pas la probabilite´ conjointe, pour une pre´cision donne´e que l’on
peut controˆler. Ainsi ici, si on se limite a` l’ensemble [0.32,0.80], on sait que l’erreur sur
la probabilite´ conjointe est infe´rieure a` Pr(ϕ2 ∈ [0, 0.32]) = 0.000001. En de´coupant
l’ensemble [0.32,0.80] en 1 000 intervalles, on obtient l’encadrement [0.5194,0.5221], d’ou`
la moyenne exacte avec 3 de´cimales 0.521 (si on n’avait pas tronque´ l’ensemble, on aurait
obtenu pour le meˆme nombre d’intervalles un encadrement moins pre´cis [0.5185,0.5229]).
On trouvera ci-apre`s un exemple de programme effectuant le calcul pre´ce´dent, e´crit
dans un pseudo langage. Il suffit de disposer d’une fonction Beta(X,A,B) qui retourne la
probabilite´ qu’une variable de distribution Beˆta (A,B) soit infe´rieure a` X. L’encadrement
cherche´ est [P1,P2].
c© Revue MODULAD, 2006 -198- Nume´ro 35
N = 1000
A = 74.5 : B = 20.5 : C = 35.5 : D = 21.5
U = 1.25
X = 0.32 : Y = 0.80
L = (Y-X) / N
P1 = 0 : P2 = 0
PY = 1 - Beta(U∗X,A,B)
Faire
XX = X + L
PX = Beta(XX,C,D) - Beta(X,C,D)
P2 = P2 + PX ∗ PY
PY = 1 - Beta(U∗XX,A,B)
P1 = P1 + PX ∗ PY
X = XX
Jusqu’a` ce que X > Y
Un raffinement utile consiste a` diviser l’ensemble des valeurs ϕ2 en un certain nombre
de zones en fonction de la forme de la densite´, et a` utiliser des intervalles de largeur
variable selon la zone. On peut e´galement envisager un autre type d’interpolation que
l’interpolation line´aire. Il peut eˆtre e´galement pre´fe´rable dans certains cas d’inverser le roˆle
de ϕ1 et de ϕ2. Etc. Comme pour les simulations, ce sont notamment les cas particuliers
ou` la densite´ de la distribution marginale n’est pas borne´e qui peuvent ne´cessiter de tels
raffinements.
Cette me´thode peut eˆtre aise´ment ge´ne´ralise´e. Elle peut encore eˆtre utilise´e pour une
fonction de trois parame`tres, comme dans les proble`mes “diagnostic me´dical” et “e´tude
d’un mode`le logique” – qui conduit a` calculer les probabilite´s de paralle´le´pipe`des rectangles
– avec des temps de calcul qui restent tre`s raisonnables.
PARTIE IV - RETOUR SUR LES
ASPECTS CONCEPTUELS
L’INTERFACE DE L’INFE´RENCE
FRE´QUENTISTE
ET DE L’INFE´RENCE BAYE´SIENNE
c© Revue MODULAD, 2006 -199- Nume´ro 35
16 Proprie´te´s fre´quentistes de l’infe´rence baye´sienne
sur une proportion : c’est simple !
16.1 Mode`le binomial
16.1.1 Un exemple typique
Le tableau ci-apre`s donne un exemple typique, avec ϕ = 0.50 et n = 10. Pour chaque
re´sultat possible f = a/n (0 ≤ a ≤ 10) le tableau donne :
• la probabilite´ d’e´chantillonnage p(f |ϕ = 0.50), donne´e par la distributionBin(0.50, 10) ;
• la probabilite´ cumule´e correspondante B(f) ;
• la probabilite´ baye´sienne finale Pr(ϕ < 0.50 | f) pour les trois distributions initiales
Beˆta (0, 1), Beˆta (1/2, 1/2), Beˆta (1, 0), d’ou` les distributions finale respectives
Beˆta (a, n− a+ 1) Beˆta (a+ 1/2, n− a+ 1/2) Beˆta (a+ 1, n− a)
Notons respectivement ces trois probabilite´s finales
Initiale Beˆta (0, 1) Beˆta (1/2, 1/2) Beˆta (1, 0)
Pr(ϕ < 0.50 | f) = Pr+(ϕ | f) Pr(ϕ | f) Pr−(ϕ | f)
Bien entendu
Pr+(ϕ | f) > Pr(ϕ | f) > Pr−(ϕ | f)
Remarque : on conside`re ici que les distribution Beˆta (a, 0) et Beˆta (0, a) sont
les distributions ponctuelles aux points 0 et 1.
ϕ = 0.50
f = a/n p(f |ϕ) B(f) Pr+(ϕ | f) Pr(ϕ | f) Pr−(ϕ | f)
0/10 0.00097656 0.00097656 1.00000000* 0.99983854* 0.99902344*
F− = 1/10 0.00976562 0.01074219 0.99902344* 0.99631011* 0.98925781*
F+ = 2/10 0.04394531 0.05468750 0.98925781* 0.97396339* 0.94531250
3/10 0.11718750 0.17187500 0.94531250 0.89798452 0.82812500
4/10 0.20507812 0.37695312 0.82812500 0.73517267 0.62304688
5/10 0.24609375 0.62304687 0.62304688 0.50000000 0.37695312
6/10 0.20507812 0.82812500 0.37695312 0.26482733 0.17187500
7/10 0.11718750 0.94531250 0.17187500 0.10201548 0.05468750
8/10 0.04394531 0.98925781 0.05468750 0.02603661 0.01074219
9/10 0.00976562 0.99902344 0.01074219 0.00368989 0.00097656
10/10 0.00097656 1.00000000 0.00097656 0.00016146 0
Beˆta (0, 1) Beˆta (1/2, 1/2) Beˆta (1, 0)
On peut observer dans ce tableau les re´sultats remarquables (et ge´ne´raux) suivants.
p(f |ϕ) = Pr+(ϕ | f)− Pr−(ϕ | f) [1]
est la conse´quence de la relation fondamentale entre les fonctions de re´partition des dis-
tributions Beˆta et Binomiale (voir Section pre´ce´dente).
Pr+(ϕ | f) = Pr−(ϕ | f − 1
n
) [2]
re´sulte du fait qu’il s’agit dans les deux cas de la meˆme distribution finale.
c© Revue MODULAD, 2006 -200- Nume´ro 35
Conside´rons maintenant le taux de couverture fre´quentiste (pour ϕ = 0.50) associe´ a`
la limite supe´rieure de l’intervalle unilate´ral de cre´dibilite´ 1 − α. Il y a couverture si la
limite est supe´rieure ou e´gale a` 0.50, donc si Pr(ϕ < 0.50 | f) ≤ 1 − α. Dans le tableau
les “erreurs” (non couverture) pour α = 0.05 sont indique´es par *.
Notons F− la plus grande valeur de f telle que Pr−(ϕ | f) ≥ 1 − α ; cette valeur est
donc telle que Pr+(ϕ | f + 1) = Pr−(ϕ | f) ≥ 1 − α. On a ici F− = 1/10. En raison de
[2] F+ = F− + 1
n
est la plus grande valeur de f telle que Pr+(ϕ | f) ≥ 1 − α. On a ici
F+ = 2/10.
En conse´quence le taux de couverture associe´ a` la distribution initiale Beˆta (1, 0) est
1−B(F−), et en raison de [1] et [2] on a simplement
B(F−) = Pr+(ϕ | 0)− Pr−(ϕ |F−) = 1− Pr−(ϕ |F−)
d’ou` le taux de couverture
1−B(F−) = Pr−(ϕ |F−) ≥ 1− α avec ici 1−B(1/10) = 0.98925781
De meˆme le taux de couverture associe´ a` la distribution initiale Beˆta (0, 1) est 1−B(F+)
1−B(F+) = Pr−(ϕ |F+) < 1− α avec ici 1−B(2/10) = 0.94531250
En conse´quence le taux de couverture associe´ a` la distribution initiale Beˆta (1/2, 1/2) ne
peut eˆtre que B(F−) ou B(F+). De plus ce re´sultat est vrai aussi pour toute distribution
initiale Beta(a0,b0) avec 0 ≤ a0 ≤ 1 et 0 ≤ b0 ≤ 1.
On a bien entendu des re´sultats analogues pour la limite infe´rieure, les roˆles des dis-
tributions Beˆta (0, 1) et Beˆta (1, 0) e´tant inverse´s.
16.1.2 En conclusion
La famille de distributions initiales Beˆta (a0, b0) avec 0 ≤ a0 ≤ 1 et 0 ≤ b0 ≤ 1
correspond a` une “zone d’ignorance” (Bernard, 1996). Il y a deux distributions “extreˆmes”,
Beˆta (1, 0) et Beˆta (0, 1), l’une assurant que le taux d’erreur fre´quentiste est toujours plus
petit que α et l’autre qu’il est toujours plus grand que α (le sens de l’ine´galite´ de´pendant
du fait que l’on conside`re la limite infe´rieure ou supe´rieure). Le taux de couverture associe´
aux autres distributions de la famille e´tant toujours e´gal a` l’un des deux taux associe´s a`
ces distributions extreˆmes (de´pendant de ϕ et n).
Comparons cette situation a` ce qui se passe dans le cas continu, par exemple pour
l’infe´rence sur la moyenne µ d’une distribution Normale N(µ, 1) a` partir d’un e´chantillon
de taille n. On a pour la moyenne observe´e la distribution d’e´chantillonnage Normale
N(µ, 1/n). On remarque que l’on a dans ce cas, pour une distribution initiale uniforme,
la distribution finale N(m, 1/n), d’ou` l’e´galite´ des densite´s
p(µ |m) = p(m |µ)
En fait, dans le cas de l’infe´rence sur une moyenne, la densite´ de la distribution
d’e´chantillonnage de la statistique m est une fonction syme´trique de m et du parame`tre
µ, ce que l’on peut voir intuitivement comme un argument de type fiduciaire justifiant le
choix de la distribution initiale uniforme. Dans le cas de l’infe´rence sur une proportion,
on ne peut pas avoir directement un tel argument de syme´trie puisque la statistique est
discre`te et le parame`tre continu, mais l’e´galite´ pre´ce´dente est remplace´e par
Pr+(ϕ | f)− Pr−(ϕ | f) = p(f |ϕ)
qui en constitue une extension naturelle.
c© Revue MODULAD, 2006 -201- Nume´ro 35
Ceci conduit a` conside´rer ici comme “probabilite´ fiducio-baye´sienne”, non pas une
seule valeur, mais un intervalle constitue´ par les deux probabilite´s associe´es aux deux
distributions extreˆmes. On rejoint ici la notion de probabilite´ impre´cise (voir pour les ap-
plications en infe´rence statistique Walley, 1996), comme conse´quence du caracte`re discret
de la distribution d’e´chantillonnage.
Ceci sugge`re encore que si l’on veut retenir une seule distribution “non informative”,
celle-ci doit eˆtre choisie comme “interme´diaire” entre Beˆta (1, 0) et Beˆta (0, 1). Un choix
privile´gie´ est alors Beˆta (1/2, 1/2) , qui est la solution de Jeffreys. C’est effectivement la
distribution initiale qui paraˆıt donner sur l’ensemble des valeurs de ϕ et de n le meilleur
taux de couverture fre´quentiste, meilleur que celui obtenu pour la plupart des me´thodes
fre´quentistes d’intervalles de confiance (Cai, 2005).
16.2 Mode`le binomial ne´gatif
On conside`re toujours l’infe´rence sur une proportion, mais a` partir d’un e´chantillon
dont le nombre de succe`s a est fixe´ avant l’expe´rience (on s’arreˆte de`s que ce nombre
est atteint). On a dans ce cas pour le nombre total d’observations n ≥ a la distribution
d’e´chantillonnage BinNeg(ϕ, a).
Remarque : la distribution d’e´chantillonnage Binomiale ne´gative est souvent
de´finie comme la distribution de b = n−a, le nombre d’e´checs observe´s quand
a est atteint.
16.2.1 Un exemple typique
Le tableau ci-apre`s donne un exemple typique, avec ϕ = 0.20 et a = 3. Pour chaque
re´sultat possible f = a/n (n ≥ 3) le tableau donne :
• la probabilite´ d’e´chantillonnage p(f |ϕ = 0.20), donne´e par la distributionBinNeg(0.20, 3) ;
• la probabilite´ cumule´e correspondante B(f) ;
• la probabilite´ baye´sienne finale Pr(ϕ > 0.20 | f) pour les quatre distributions initiales
Beˆta (1, 0), Beˆta (0, 0), Beˆta (0, 1/2), Beˆta (0, 1), soit les distributions finales respectives
Beˆta (a+ 1, n− a) Beˆta (a, n− a) Beˆta (a, n− a+ 1/2) Beˆta (a, n− a+ 1)
Notons maintenant les probabilite´s finales
Initiale Beˆta (0, 0) Beˆta (0, 1/2) Beˆta (0, 1)
Pr(ϕ < 0.50 | f) = Pr+(ϕ | f) Pr(ϕ | f) Pr−(ϕ | f)
Bien entendu
Pr+(ϕ | f) > Pr(ϕ | f) > Pr−(ϕ | f)
ϕ = 0.20
c© Revue MODULAD, 2006 -202- Nume´ro 35
f = a/n p(f |ϕ = 0.20) B(f) Pr+(ϕ | f) Pr(ϕ | f) Pr−(ϕ | f)
3/3 0.00800000 0.00800000 1.00000000* 1.00000000* 0.99728632* 0.99200000*
3/4 0.01920000 0.02720000 0.99840000* 0.99200000* 0.98386991* 0.97280000*
3/5 0.03072000 0.05792000 0.99328000* 0.97280000* 0.95882595* 0.94208000
3/6 0.04096000 0.09888000 0.98304000* 0.94208000 0.92276264 0.90112000
3/7 0.04915200 0.14803200 0.96665600* 0.90112000 0.87742592 0.85196800
3/8 0.05505024 0.20308224 0.94371840 0.85196800 0.82503681 0.79691776
3/9 0.05872026 0.26180250 0.91435827 0.79691776 0.76788506 0.73819750
3/10 0.06039798 0.32220047 0.87912612 0.73819750 0.70809554 0.67779953
3/11 0.06039798 0.38259845 0.83886080 0.67779953 0.64750882 0.61740155
3/12 0.05905580 0.44165425 0.79456895 0.61740155 0.58763489 0.55834575
3/13 0.05669357 0.49834782 0.74732431 0.55834575 0.52965171 0.50165218
3/14 0.05360119 0.55194901 0.69818988 0.50165218 0.47442964 0.44805099
3/15 0.05002778 0.60197679 0.64816210 0.44805099 0.42256891 0.39802321
3/16 0.04617949 0.64815628 0.59813433 0.39802321 0.37444215 0.35184372
3/17 0.04222125 0.69037753 0.54887620 0.35184372 0.33023683 0.30962247
3/18 0.03828060 0.72865812 0.50102546 0.30962247 0.28999475 0.27134188
3/19 0.03445254 0.76311066 0.45508874 0.27134188 0.25364706 0.23688934
3/20 0.03080462 0.79391528 0.41144886 0.23688934 0.22104429 0.20608472
3/21 0.02738189 0.82129717 0.37037603 0.20608472 0.19198125 0.17870283
3/22 0.02421135 0.84550852 0.33204139 0.17870283 0.16621725 0.15449148
etc.
Beˆta (1, 0) Beˆta (0, 0) Beˆta (0, 1/2) Beˆta (0, 1)
Conside´rons maintenant le taux de couverture fre´quentiste (pour ϕ = 0.20) associe´ a`
la limite infe´rieure de l’intervalle unilate´ral de cre´dibilite´ 1 − α. Il y a couverture si la
limite est infe´rieure ou e´gale a` 0.20, donc si Pr(ϕ > 0.20 | f) ≤ 1− α. Dans le tableau les
“erreurs” (non couverture) pour α = 0.05 sont indique´es par *.
16.2.2 En conclusion
On a clairement des re´sultats analogues a` ceux e´nonce´s pour le mode`le binomial. La
famille de distributions initiales Beˆta (a0, b0) avec 0 ≤ a0 ≤ 1 et 0 ≤ b0 ≤ 1 correspond
a` une “zone d’ignorance”. Les deux distributions “extreˆmes”, Beˆta (1, 0) et Beˆta (0, 1)
assurent encore, l’une que le taux d’erreur fre´quentiste est toujours plus petit que α et
l’autre qu’il est toujours plus grand que α (le sens de l’ine´galite´ de´pendant du fait que
l’on conside`re la limite infe´rieure ou supe´rieure).
On a encore pour le mode`le binomial ne´gatif une e´galite´ du type
Pr+(ϕ | f)− Pr−(ϕ | f) = p(f |ϕ)
mais dans ce cas Pr+ correspond a` la distribution initiale Beˆta (0, 0) et Pr− a` la distri-
bution initiale Beˆta (0, 1)
Ceci sugge`re que si l’on veut retenir une seule distribution “non informative”, celle-ci
doit eˆtre choisie comme “interme´diaire” entre Beˆta (0, 0) et Beˆta (0, 1). Un choix “natu-
rel” est alors Beˆta (0, 1/2), qui est la solution de Jeffreys. C’est effectivement la distribution
initiale qui paraˆıt donner sur l’ensemble des valeurs de a et de ϕ le meilleur taux de cou-
verture fre´quentiste, meilleur que celui obtenu pour la plupart des me´thodes fre´quentistes
d’intervalles de confiance (Cai, 2005).
c© Revue MODULAD, 2006 -203- Nume´ro 35
Notons encore que le taux de couverture associe´ a` la distribution Beˆta (0, 1/2) est
toujours e´gal a` l’un des deux taux associe´s aux distributions Beˆta (0, 0) et Beˆta (0, 1)
(de´pendant de ϕ et a), et non comme pour le mode`le binomial a` ceux associe´s aux deux
distributions extreˆmes.
16.3 Ge´ne´ralisation aux tableaux 2×2 et tests conditionnels “a`
la Fisher”
L’exemple “un mode`le multinomial pour le tableau 2 × 2” a permis d’illustrer la
re´interpre´tation baye´sienne du test de permutation de Fisher. Ceci constitue une extension
des re´sultats pre´ce´dents pour une proportion. On a la meˆme re´interpre´tation dans le cas
de deux groupes inde´pendants avec chacun une distribution d’e´chantillonnage Binomiale
ou chacun une distribution Binomiale ne´gative, ou encore pour un mode`le multinomial
ne´gatif . Illustrons la dans les deux premiers cas.
Conside´rons l’exemple du tableau de donne´es suivant, avec respectivement 3 et 2
observations et un succe`s observe´ dans chaque groupe.
1 0
g1 n11 = 1 n10 = 2 n1. = 3
g2 n21 = 1 n20 = 1 n2. = 2
n.1 = 2 n.0 = 3 n = 5
16.4 Le test conditionnel aux marges (test de permutation)
16.4.1 Cas binomial
Dans le cas binomial on retient l’un des effectifs – par exemple n11 – comme statistique
de test, et on calcule la proportion de tableaux possibles avec les meˆmes marges qui sont
“plus extreˆmes” que le tableau observe´. Il y a trois types de tableaux de donne´es possibles
0 3 3 1 2 3 2 1 3
2 0 2 1 1 2 0 2 2
2 3 5 2 3 5 2 3 5
1× 1 = 1 3× 2 = 6 3× 1 = 3
la dernie`re ligne indiquant le nombre de tableaux du type. Par exemple, pour le tableau
du milieu, avec 3 sujets dans le groupe 1 il y a 3 fac¸ons possibles d’avoir n11 = 1 et n12 = 2,
et avec 2 sujets dans le groupe 2 il y a 2 fac¸ons possibles d’avoir n21 = 1 et n22 = 1, donc
3× 2 = 6 tableaux de ce type.
Si on veut montrer que ϕ1 < ϕ2, le seuil observe´ du test unilate´ral (incluant) est la
proportion des tableaux pour lesquels n11 ≤ 1, soit
pinc = (1 + 6)/10 = 0.70
Si on exclut la valeur observe´e (soit n11 < 1) on obtient le seuil excluant
pexc = 1/10 = 0.10
Formellement, ces seuils sont donne´s par la distribution d’e´chantillonnage de n11 sous
l’hypothe`se nulle H0 : ϕ1 = ϕ2, conditionnellement aux marges, qui est une distribution
Hyperge´ome´trique
c© Revue MODULAD, 2006 -204- Nume´ro 35
n11 |n.1, n1., n.2, n2., [H0] ∼ Hyp (n , n.1 , n1.) soit ici Hyp (5, 2, 3)
d’ou`
pinc = Pr(Hyp (n , n.1 , n1.) ≤ n11) = 0.70 et pexc = Pr(Hyp (n , n.1 , n1.) < n11) = 0.10
16.4.2 Cas binomial ne´gatif
Dans le cas binomial ne´gatif on retient par exemple n1. comme statistique de test et
on calcule la proportion de tableaux possibles avec les meˆmes valeurs n, n11 et n21 (et
donc n.1 et n.0) qui sont “plus extreˆmes” que le tableau observe´. Il y a quatre types de
tableaux de donne´es possibles
1 0 1 1 1 2 1 2 3 1 3 4
1 3 4 1 2 3 1 1 2 1 0 1
2 3 5 2 3 5 2 3 5 2 3 5
1× 4 = 4 2× 3 = 6 3× 2 = 6 4× 1 = 4
la dernie`re ligne indiquant le nombre de tableaux du type. Dans ce cas, si on veut montrer
que ϕ1 < ϕ2, le seuil observe´ du test unilate´ral (incluant) est la proportion des tableaux
pour lesquels n1. ≥ 3, soit
pinc = (6 + 4)/20 = 0.50
Si on exclut la valeur observe´e (soit n1. > 3) on obtient le seuil excluant
pexc = 4/20 = 0.25
Formellement, ces seuils sont donne´s par la distribution d’e´chantillonnage de n1. sous
l’hypothe`se nulle H0 : ϕ1 = ϕ2, conditionnellement a` n, n11 et n21, qui est une distribution
Hyperge´ome´trique ne´gative
n1. |n, n11, n21, [H0] ∼ HypNEG (n , n11 , n21) soit ici HypNEG (5, 1, 1)
d’ou`
pinc = Pr(HypNEG (n , n11 , n21) ≥ n1.) = 0.50 et pexc = Pr(HypNEG (n , n11 , n21) > n1.) = 0.25
16.5 Re´interpre´tation baye´sienne
16.5.1 Cas binomial
Soit la distribution initiale ϕ1 ∼ Beˆta (ν11, ν10) et ϕ2 ∼ Beˆta (ν21, ν20) avec ϕ1 et ϕ2
inde´pendantes. On suppose que les (νij) sont des entiers positifs ou nuls. On a le re´sultat
suivant
Pr
(
ϕ1 > ϕ2 | (nij)
)
= Pr
(
Hyp (n+ν11+ν10+ν21+ν20−2 , n.1+ν11+ν21−1 , n1.+ν11+ν10−1) < n11+ν11
)
soit, si ν11 + ν10 = 1, ν11 + ν21 = 1 et ν21 + ν20 = 1
Pr
(
ϕ1 > ϕ2 | (nij)
)
= Pr
(
Hyp (n, n.1 , n1.) < n11 + ν11
)
c© Revue MODULAD, 2006 -205- Nume´ro 35
Par conse´quent, pour le cas binomial on a la re´interpre´tation du seuil
Pr
(
ϕ1 > ϕ2 | (nij)
)
= pinc = 0.70 si ν11 = ν20 = 1 et ν10 = ν21 = 0
Pr
(
ϕ1 > ϕ2 | (nij)
)
= pexc = 0.10 si ν11 = ν20 = 0 et ν10 = ν21 = 1
et, si l’on veut retenir une seule distribution “non informative”, ceci sugge`re comme choix
privile´gie´ la solution interme´diaire ν11 = ν10 = ν21 = ν20 = 1/2 , qui est la solution de
Jeffreys.
Le lien entre le seuil du test conditionnel et la probabilite´ baye´sienne finale Pr(ϕ1 >
ϕ2 | (nij)) re´sulte encore de la relation fondamentale entre les fonctions de re´partition des
distributions Beˆta et Binomiale. Il se de´montre “par me´lange”. Conditionnellement a` ϕ2,
on a
Pr
(
ϕ1 > ϕ2 |ϕ2, (nij)
)
= Pr
(
Beˆta (n11 + ν11, n10 + ν10) > ϕ2
)
= Pr
(
Bin (ϕ2 , n11 + ν11 + n10 + ν10 − 1) < n11 + ν11
)
=
Pr
(
Bin (ϕ2 , n1. + ν11 + ν10 − 1) < n11 + ν11
)
La probabilite´ marginale – me´lange de la probabilite´ binomiale par la distribution Beˆta (ν21, ν20)
– est une distribution Beˆta-Binomiale (voir la section “de´rivation de la distribution
pre´dictive”)
Pr
(
ϕ1 > ϕ2 | (nij)
)
= Pr
(
Beˆta-Bin (n21+ν21 , n20+ν20 ; n1.+ν11+ν10−1) < n11+ν11
)
et en utilisant une autre relation remarquable, entre la distribution Beˆta-Binomiale et la
distribution hyperge´ome´trique (Johnson, Kotz & Kemp, 1992).
Pr
(
Beˆta-Bin (a , b ; n) < u
)
= Pr
(
Hyp (a+ b+ n− 1 , a+ u− 1 , n) < u
)
on de´duit le re´sultat e´nonce´.
16.5.2 Cas binomial ne´gatif
Avec la meˆme distribution initiale que dans le cas pre´ce´dent, en utilisant une autre
relation, entre la distribution Beˆta-Binomiale et la distribution hyperge´ome´trique ne´gative
(Johnson, Kotz & Kemp, 1992).
Pr
(
Beˆta-Bin (a , b ; n) < u
)
= Pr
(
HypNEG (a+ b+ n , u , a) > n
)
on obtient
Pr
(
ϕ1 > ϕ2 | (nij)
)
= Pr
(
HypNEG (n+ν11+ν10+ν21+ν20−1 , n11+ν11 , n21+ν21) > n1.+ν11+ν10−1
)
soit, si ν11 = ν21 = 0 et ν10 + ν20 = 1,
Pr
(
ϕ1 > ϕ2 | (nij)
)
= Pr
(
HypNEG (n , n11 , n21) > n1. + ν10 − 1
)
Par conse´quent, pour le cas binomial ne´gatif on a la re´interpre´tation du seuil
c© Revue MODULAD, 2006 -206- Nume´ro 35
Pr
(
ϕ1 > ϕ2 | (nij)
)
= pinc = 0.50 si ν11 = ν21 = ν10 = 0 et ν20 = 1
Pr
(
ϕ1 > ϕ2 | (nij)
)
= pexc = 0.25 si ν11 = ν21 = ν20 = 0 et ν10 = 1
et, si l’on veut retenir une seule distribution “non informative”, ceci sugge`re comme choix
privile´gie´ la solution interme´diaire ν11 = ν21 = 0 et ν10 = ν20 = 1/2 , qui est la solution de
Jeffreys.
17 Re`gle de Jeffreys
17.1 Information de Fisher et distribution non informative de
Jeffreys
Les conside´rations pre´ce´dentes fournissent une justification intuitive de la distribu-
tion non informative de Jeffreys. La justification formelle est que celle-ci est base´e sur
l’information de Fisher (1922, 1925). Dans le cas d’un seul parame`tre – typiquement la
proportion ϕ, l’information de Fisher I(ϕ) apporte´e par un e´chantillon y est de´finie, a`
partir de la vraisemblance v(ϕ |y) comme
I(ϕ |y) = Eϕ
[( ∂
∂ϕ
log v(ϕ |y)
)2]
= −Eϕ
[ ∂2
∂2ϕ
log v(ϕ |y)
]
et la densite´ de la distribution de Jeffreys est proportionnelle a` sa racine carre´e
pJ(ϕ) ∝
√
I(ϕ)
17.2 Deux distributions initiales pour les e´chantillonnages bino-
mial et de Pascal
17.2.1 Echantillonnage binomial
v(ϕ |y) = v(ϕ | a) = n!
a!(n− a)! ϕ
a(1− ϕ)n−a
et
E(a |ϕ) = nϕ
On en de´duit
log v(ϕ | a) = a logϕ+ (n− a) log(1− ϕ) + k
ou` k est une constante, et
I(ϕ | a) = −E
(
− a
ϕ2
− n− a
1− ϕ2
)
=
n
ϕ
+
n
1− ϕ = nϕ
−1(1− ϕ)−1
donc
pJ(ϕ) ∝ ϕ−1/2(1− ϕ)−1/2 soit ϕ ∼ Beˆta (1/2, 1/2)
c© Revue MODULAD, 2006 -207- Nume´ro 35
17.2.2 Echantillonnage de Pascal (distribution Binomiale ne´gative)
v(ϕ |y) = v(ϕ |n) = (n− 1)!
(a− 1)!(n− a)! ϕ
a(1− ϕ)n−a, n ≥ a
et
E(n |ϕ) = a 1− ϕ
ϕ
On de´duit en proce´dant de la meˆme manie`re
I(ϕ |n) = nϕ−2(1− ϕ)−1
donc
pJ(ϕ) ∝ ϕ−1(1− ϕ)−1/2 soit ϕ ∼ Beˆta (0, 1/2)
18 Une ne´cessite´ pour les analyses interme´diaires :
concilier l’approche baye´sienne avec les desiderata
fre´quentistes
La plupart des expe´rimentateurs conside`rent que la possibilite´ dans un plan d’expe´rience
de s’arreˆter avant le terme pre´vu, en effectuant une analyse interme´diaire, ne doit pas eˆtre
ignore´e. La raison est que l’arreˆt peut induire un biais sur l’infe´rence qu’ils souhaitent ex-
plicitement corriger. Les proce´dures fre´quentistes introduisent pre´cise´ment une telle cor-
rection. C’est pourquoi de nombreux expe´rimentateurs sont de´sappointe´s par le fait que les
me´thodes baye´siennes, contrairement a` la pratique fre´quentiste, ignorent ge´ne´ralement ce
desiderata, au nom du principe de vraisemblance. En conse´quence, ceci constitue un frein
se´rieux a` l’utilisation des me´thodes baye´siennes dans l’analyse des donne´es expe´rimentales.
18.1 Les principes de vraisemblance et des re`gles d’arreˆt
“If the experiment is changed, then the expression of relative ignorance can
be expected to change correspondingly.” (Box & Tiao, 1992, page 46)
Box et Tiao (1992) ont discute´ le fait – mis en e´vidence dans la section pre´ce´dente – que
la re`gle de Jeffreys aboutit a` deux distributions initiales diffe´rentes pour les e´chantillonnages
binomial et de Pascal, bien que ces deux types d’expe´riences conduisent a` la meˆme
vraisemblance. Ils ont mis en avant l’ide´e que “l’ignorance” avant l’expe´rience est re-
lative au plan d’expe´rience et qu’une distribution non informative approprie´e doit donc
de´pendre du mode`le d’e´chantillonnage. Mais cela est contraire au “principe de vraisem-
blance” (conside´re´ comme une conse´quence du the´ore`me de Bayes), auquel la plupart des
baye´siens vouent une stricte obe´issance.
Principe de vraisemblance - “Si x1 et x2 sont tels qu’il existe une constante
c telle que, pour tout ϕ, v(ϕ|x1) =cv(ϕ|x2), ils apportent la meˆme information
sur ϕ et doivent conduire a` la meˆme infe´rence.” (adapte´ de Robert, 1992,
page 23)
Une conse´quence du principe de vraisemblance est le principe des re`gles d’arreˆt.
c© Revue MODULAD, 2006 -208- Nume´ro 35
Principe des re`gles d’arreˆt - “once the data have been obtained, the reasons
for stopping experimentation should have no bearing on the evidence reported
about unknown model parameters.” (Bayarri & Berger, 2004, page 77)
Ce principe affirme que l’on devrait faire la meˆme infe´rence si l’on s’arreˆte en ayant
observe´ a succe`s apre`s n (fixe´) observations (e´chantillonnage binomial) ou si l’on s’arreˆte
apre`s avoir effectue´ n observations pour obtenir a (fixe´) succe`s (e´chantillonnage de Pascal).
Ce sont la` deux exemples simples de re`gles d’arreˆt ; mais des re`gles plus complexes – qui
ont une grande importance en pratique – sont fournies pas les analyses interme´diaires
(voir l’exemple “Infe´rence sur une proportion”). Au nom de ces principes, les tentatives
pre´ce´dentes pour incorporer ces re`gles dans une distribution initiale objective (Ye, 1993)
ont e´te´ plus ou moins abandonne´es, ignorant les arguments avance´s par Box & Tiao.
18.2 Une nouvelle approche prometteuse
La plupart des expe´rimentateurs ne sont pas convaincus par ces principes. La situation
ne devrait cependant pas rester bloque´e, puique de Cristofaro (1996, 2004, 2006) a ouvert
la possibilite´ de concilier l’approche baye´sienne avec les desiderata fre´quentistes. Il argu-
mente que le plan expe´rimental (incluant la re`gle d’arreˆt) est ante´rieur a` l’information de
l’e´chantillon et que l’information sur le plan constitue une partie de l’e´vidence. Il en de´duit
que la formule de Bayes doit inte´grer cette information, et que par suite les principes de
vraisemblance et des re`gles d’arreˆt n’en sont plus une conse´quence automatique. Une ide´e
de base est de conside´rer que l’information du plan ignore´e dans la vraisemblance peut
eˆtre recouvre´e dans l’information de Fisher, et par suite dans la distribution initiale de
Jeffreys ; celle-ci trouve ainsi une le´gitimite´ nouvelle et apporte une re´ponse au proble`me
de l’e´vidence implicitement contenue dans le plan d’expe´rience. Dans ce cadre, nous pou-
vons obtenir une re´ponse baye´sienne cohe´rente et pleinement justifie´e au proble`me des
analyses interme´diaires.
Cette approche nouvelle a e´te´ de´veloppe´e par Bunouf (2006) dans le cas de l’infe´rence
sur une proportion avec analyses interme´diaires. Elle apparaˆıt prometteuse et offre des
avantages de´cisifs, a` la fois d’un point de vue baye´sien et d’un point de vue fre´quentiste
(Bunouf & Lecoutre, 2006).
REMARQUES FINALES
ET QUELQUES THE`MES POUR ALLER
PLUS LOIN
Le moment semble venu de parvenir a` des proce´dures d’analyse des donne´es expe´rimentales
qui permettent de reme´dier de manie`re constructive aux mauvais usages des tests de si-
gnification usuels. Il y a inde´niablement une reconnaissance grandissante que l’infe´rence
baye´sienne peut eˆtre ide´alement adapte´e a` cet objectif. Elle satisfait les demandes des
scientifiques : proce´dures objectives (incluant les seuils p traditionnels) ; proce´dures sur
les grandeurs des effets (allant au dela` des seuils p) ; proce´dures pour planifier et conduire
les expe´riences.
c© Revue MODULAD, 2006 -209- Nume´ro 35
Alors, pourquoi les scientifiques, et en particulier les expe´rimentateurs, alors qu’ils
apparaissent re´ellement souhaiter un autre type d’infe´rence statistique, semblent sou-
vent re´ticents a` mettre en pratique les proce´dures baye´siennes ? Dans un papier parti-
culie`rement lucide Winkler e´crivait il y a plus de 30 ans :
“this state of affairs appears to be due to a combination of factors including
philosophical conviction, tradition, statistical training, lack of ‘availability’,
computational difficulties, reporting difficulties, and perceived resistance by
journal editors.” (Winkler, 1974, page 129)
ajoutant que si on laissait de coˆte´ les aspects philosophiques, aucun de ces arguments
n’e´tait re´ellement de´terminant. Cette analyse n’en reste pas moins d’actualite´ ; on peut
simplement ajouter qu’un nouvel obstacle important en pratique est que les logiciels statis-
tiques standard qui sont de nos jours largement utilise´s continuent a` ignorer les me´thodes
baye´siennnes.
“We [statisticians] will all be Bayesians in 2020, and then we can be a united
profession.” (Lindley, in Smith, 1995, page 317)
En fait nous sommes vraisemblablement dans une pe´riode cruciale, car la masse des
travaux the´oriques sur l’infe´rence baye´siennes qui ont e´te´ effectue´s donne lieu a` un nombre
sans cesse croissant d’applications. L’un des facteurs de´cisifs pourrait eˆtre le re´cent “draft
guidance document” de l’US Food and Drug Administration (FDA, 2006). Ce document,
qui discute “the least burdensome way of addressing the relevant issues related to the
use of Bayesian statistics in medical device clinical trials”, ouvre la possibilite´ pour
les expe´rimentateurs (au moins dans le domaine des essais cliniques) d’eˆtre re´ellement
baye´siens en pratique.
18.3 Quelques avantages de l’infe´rence baye´sienne
18.3.1 Une meilleure compre´hension des proce´dures fre´quentistes
“Students [exposed to a Bayesian approach] come to understand the frequen-
tist concepts of confidence intervals and P values better than do students
exposed only to a frequentist approach. (Berry, 1997)
Les me´thodes baye´siennes objectives permettent aux utilisateurs de surmonter des dif-
ficulte´s usuelles rencontre´es avec approche fre´quentiste. En particulier, il est tre`s naturel
pour eux d’utiliser les interpre´tations baye´siennes des tests de signification et des inter-
valles de confiance dans le langage des probabilite´s sur les parame`tres inconnus. En retour
les mauvais usages et les abus des tests de signification de l’hypothe`se nulle sont beau-
coup mieux compris. En particulier les utilisateurs des me´thodes baye´siennes deviennent
tre`s vite avertis du fait que les re´sultats non significatifs ne peuvent pas eˆtre interpre´te´s
comme “preuve d’absence d’effet.”
18.3.2 Combiner diffe´rentes sources d’information
Une analyse de donne´es expe´rimentales devraient toujours inclure une analyse baye´sienne
objective pour exprimer l’apport propre des donne´es – ce que les donne´es ont a` dire –
inde´pendendamment de toute information exte´rieure. Cependant, des “a priori informa-
tifs” ont aussi un roˆle important a` jouer. Ils peuvent aider a` raffiner l’infe´rence et a`
appre´cier la sensibilite´ des conclusions vis–a`-vis d’informations supple´mentaires.
c© Revue MODULAD, 2006 -210- Nume´ro 35
“an objective scientific report is a report of the whole prior-to-posterior map-
ping of a relevant range of prior probability distributions, keyed to meaningful
uncertainty interpretations.” (Dickey, page 135)
En regard du besoin d’objectivite´ des scientifiques, on pourrait meˆme argumenter sur
la ne´cessite´ d’explorer l’impact de diffe´rentes distributions initiales pertinentes.
Les techniques baye´siennes informatives sont ide´alement adapte´es pour combiner les
informations des donne´es d’une expe´rience avec celles d’autres e´tudes, et par suite pour
planifier une se´rie d’expe´riences. Des utilisations plus ou moins convaincantes ont e´te´
propose´es. Par exemple, Irony et Pennello (2001) discutent la manie`re d’introduire ces
techniques dans les essais cliniques en me´decine.
De fac¸on ide´ale, quand une “bonne information initiale” est disponible, elle peut
(doit ?) eˆtre utilise´e pour obtenir la meˆme conclusion qu’une “analyse baye´sienne ob-
jective”, mais avec un plus petit e´chantillon de donne´es. Naturellement, cela supppose
une connaissance re´elle base´e sur des donne´es plutoˆt que des opinions d’experts, qui sont
ge´ne´ralement sujettes a` controverses. Cependant mon opinion est que l’utilisation de ces
techniques doit eˆtre plus syste´matiquement explore´e avant de pouvoir appre´cier ce que
devrait eˆtre leur contribution pre´cise a` l’analyse des donne´es expe´rimentales.
18.3.3 Les probabilite´s pre´dictives : Un outil tre`s se´duisant
“An essential aspect of the process of evaluating design strategies is the ability
to calculate predictive probabilities of potential results.” (Berry, 1991, page 81)
Un apport majeur du paradigme baye´sienne est la facilite´ de faire des pre´dictions sur
des observations futures. L’ide´e pre´dictive est centrale dans les e´tudes expe´rimentales, car
“the essence of science is replication : a scientist should always be concer-
ned about what would happen if he or another scientist were to repeat his
experiment.” (Guttman, 1983)
Les proce´dures baye´siennes pre´dictives permettent aux utilisateurs de re´pondre a` des
questions essentielles telles que : “quel doit eˆtre l’effectif de l’expe´rience pour avoir des
chances raisonnables de de´montrer la conclusion recherche´e ?” ; “a` partir des donne´es ac-
tuellement disponibles, quelles sont les chances que le re´sultat final permette de conclure,
ou au contraire ne le permette pas ?” Ces questions sont non conditionnelles en ce qu’elles
ne´cessitent de conside´rer toutes les valeurs possibles des parame`tres. Tandis que la pra-
tique fre´quentiste traditionnelles ne traite pas ces questions, les probabilite´s predictives
leur donnent des re´ponses directes et naturelles.
En particulier, a` partir d’une e´tude pilote, les probabilite´s pre´dictives sur les limites
de cre´dibilite´ sont un re´sume´ particule`rement utiles pour aider au choix de la taille
de l’e´chantillon d’une expe´rience (pour un paralle`le entre les me´thodes baye´siennes et
fre´quentistes, voir Inoue, Berry & Parmigiani, 2005).
L’approche pre´dictive est une me´thode tre`s se´duisante (Baum, Houghton & Abrams,
1989) pour aider a` la de´cision d’interrompre une expe´rience a` une e´tape interme´diaire.
D’une part, une probabilite´ pre´dictive faible que l’expe´rience soit une re´ussite peut eˆtre
utilise´e comme une re`gle pour abandonner l’expe´rience (“pour futilite´”). D’autre part,
une probabilite´ pre´dictive suffisamment e´leve´e sugge`re d’interrompre l’expe´rience avant
son terme (“pour succe`s”).
c© Revue MODULAD, 2006 -211- Nume´ro 35
Les probabilite´s pre´dictives sont aussi un outil important pour traiter les donne´es
manquantes. Les analyses interme´diaires reviennent d’ailleurs a` e´valuer des donne´es man-
quantes. Le cas de donne´es de survie censure´es est particulie`rement illustratif. Au mo-
ment d’une analyse interme´diaire les donne´es disponibles sont divise´es en trois cate´gories :
(1) les patients inclus pour lesquels l’e´ve´nement auquel on s’inte´resse a de´ja` e´te´ observe´ ;
(2) les patients inclus de´finitivement censure´s ; (3) les patients inclus pour lesquels la
pe´riode d’observation maximale n’est pas encore atteinte. En conse´quence les donne´es
manquantes a` pre´dire concernent respectivement les patients de cette dernie`re cate´gorie
pour lesquels nous avont une information partielle et les futurs patients dont l’inclusion
est planifie´e pour lesquels nous n’avons pas d’information directe. L’approche baye´sienne
traite cette situation de manie`re directe et efficace (Lecoutre, Mabika & Derzko, 2002).
On peut encore souligner le fait que les distributions pre´dictives sont e´galement un outil
utile pour construire une distribution initiale subjective, du fait qu’il est ge´ne´ralement plus
facile d’exprimer une opinion relative a` des donne´es.
18.4 Calculs baye´siens et logiciels statistiques
Il y a actuellement de plus en plus d’applications de l’infe´rence baye´sienne a` ge´ne´raux
l’analyse des donne´es expe´rimentales. Mais un obstacle a` une utilisation routinie`re des
me´thodes baye´siennes objectives est l’absence de logiciels ge´ne´raux faciles d’utilisation
et conviviaux qui seraient une contrepartie des logiciels fre´quentistes standard. On peut
espe´rer que cet obstacle sera leve´ dans le futur.
Quelques programmes ont e´te´ de´veloppe´s dans le but d’enseigner l’infe´rence baye´sienne
e´le´mentaire : voir notamment First Bayes (O’Hagan, 1996) et un ensemble demacros pour
Minitab (Albert, 1996). Les logiciels que nous avons de´veloppe´s – et illustre´s en partie
ici – ont une perspective plus ambitieuse. En particulier PAC est une programme ge´ne´ral
d’analyse de variance qui inclut a` la fois les pratiques fre´quentistes traditionnelles (tests de
signification, intervalles de confiance) et des proce´dures baye´siennes de routine (initiales
non informatives et conjugue´es). Ces proce´dures sont applicables a` des plans d’expe´rience
ge´neraux (en particulier, plans a` mesures re´pe´te´es), e´quilibre´s ou de´se´quilibre´s, avec des
donne´es univarie´es ou multivarie´es, et des covariables.
A un niveau plus avance´ et plus ge´ne´ral, WinBUGS (une partie du “BUGS project”)
est un logiciel ge´ne´ral souple et efficace. Son objectif de´clare´ et de rendre la pratique des
me´thodes MCMC (Monte Carlo par Chaˆınes de Markov) disponibles aux statisticiens. Il
contribue inde´niablement a` l’utilisation croissante de l’infe´rence baye´sienne pour des appli-
cations re´elles. Il peut eˆtre gratuitement te´le´charge´ a` l’adresse Internet : http ://www.mrc-
bsu.cam.ac.uk/bugs/welcome.shtml. Cependant, il peut eˆtre difficilement recommande´ a`
des de´butants s’ils ne sont pas fortement motive´s.
18.5 Quelques the`mes pour aller plus loin
Il n’est pas dans mon intention de donner ici une liste de the`mes exhaustive, mais
seulement de pre´senter quelques domaines de recherche qui me semblent particulie`rement
importants pour le de´veloppement me´thodologique de l’analyse baye´sienne objective pour
l’analyse des donne´es expe´rimentales.
c© Revue MODULAD, 2006 -212- Nume´ro 35
18.5.1 L’interface des infe´rences fre´quentiste et baye´sienne
Meˆme si ce tutoriel de´fend l’ide´e que l’approche baye´sienne doit eˆtre privile´gie´e,
cela devrait nous inviter a` ne pas radicaliser l’opposition entre les infe´rences baye´sienne
et fre´quentiste, mais plutoˆt a` conside´rer leur interface. Bayarri et Berger (2004) font
une pre´sentation particulie`rement inte´ressante de cette interface. Ils mettent en avant le
fait que l’argument fre´quentiste traditionnel, qui met en jeu “des re´pe´titions du meˆme
proble`me avec diffe´rentes donne´es” ne correspond pas a` ce qui est fait en pratique. En
conse´quence c’est “un principe fre´quentiste-baye´sien conjoint” qui est pertinent : une
proce´dure donne´e (par exemple un intervalle de confiance 95% pour une moyenne sous
le mode`le Normal) est en pratique utilise´ sur “une se´rie de diffe´rents proble`mes met-
tant en jeu une se´rie de diffe´rentes moyennes de distributions Normales avec une se´rie
correspondante de donne´es” (page 60).
Plus ge´ne´ralement, ils passent en revue les questions actuelles pour une synthe`se
baye´sienne-fre´quentiste dans une perspective me´thodologique. Leur conclusion, qui semble
raisonnable, est d’espe´rer une unification me´thodologique, mais pas une unification phi-
losophique.
“Philosophical unification of the Bayesian and frequentist positions is not li-
kely, nor desirable, since each illuminates a different aspect of statistical infe-
rence. We can hope, however, that we will eventually have a general methodo-
logical unification, with both Bayesians and frequentists agreeing on a body
of standard statistical procedures for general use”. (Bayarri and Berger, 2004,
page 78)
Dans cette perspective, un domaine de recherche actif a pour objectif de trouver des
“probability matching priors” pour lequels les probabilite´s finales de certains ensembles
spe´cifie´s sont e´gales (au moins approximatevement) a` leur probabilite´s de couverture :
voir Fraser, et al., 2003 ; Sweeting, 2005.
On notera encore, qu’en relevant le de´fi d’une unification me´thodologique, Berger
(2003) discute “the conditional frequentist approach to testing”, dont il argue qu’elle four-
nit pre´cise´ment (du moins en ce qui concerne les tests d’hypothe`ses) la base d’une unifi-
cation me´thodologique des approches de Fisher, Jeffreys et Neyman.
18.5.2 Echangeabilite´ et mode`les hie´rarchiques
Sans entrer dans le de´tail, des e´ve´nements ale´atoires sont e´changeables “si nous attri-
buons la meˆme probabilite´ a` une assertion sur n’importe quel nombre donne´ d’entre eux”
(de Finetti, 1972, page 213). C’est une notion cle´ de l’infe´rence statistique. Par exemple
des sujets futurs doivent eˆtre suppose´s e´changeables avec les sujets qui ont de´ja` e´te´ ob-
serve´s pour rendre les probabilite´s pre´dictives raisonnables. De meˆme, des expe´riences
semblables doivent eˆtre suppose´s e´changeables pour une inte´gration cohe´rente des infor-
mations.
La notion d’e´changeabilite´ est tre`s importante et utile dans le cadre baye´sien. En
utilisant la spe´cification de distribution initiales a` diffe´rents niveaux, elle permet une
mode´lisation souple de dispositifs expe´rimentaux lie´s au moyen de mode`les hie´rarchiques
(Bernardo, 1996).
“If a sequence of observations is judged to be exchangeable, then any subset
of them must be regarded as a random sample from some model, and there
c© Revue MODULAD, 2006 -213- Nume´ro 35
exist a prior distribution on the parameter of such model, hence requiring a
Bayesian approach.” (Bernardo, 1996, page 5)
Les mode`les hie´rarchiques sont importants pour utiliser de manie`re approprie´e les
donne´es d’expe´riences multicentriques. Ils ont aussi particulie`rement adapte´s pour les
me´ta-analyses ou` nous avons des donne´es d’un certain nombre d’e´tudes pertinentes qui
peuvent eˆtre e´changeables a` certains niveaux mais pas a` d’autres (Dumouchel, 1990).
Dans tous les cas, le proble`me peut eˆtre de´compose´ en une se´rie de mode`les conditionnels
plus simples, en utilisant la me´thodologie baye´sienne hie´rarchique (Good, 1980).
RE´FE´RENCES
References
Agresti, A. & Min, Y. (2005). Frequentist performance of Bayesian confidence intervals
for comparing proportions in 2× 2 contingency tables. Biometrics 61, 515–523.
Albert, J. (1996). Bayesian Computation Using Minitab. Wadsworth Publishing Company,
Belmont.
American Psychological Association (2001). Publication Manual of the American Psycho-
logical Association (5e`me e´dition). Author, Washington, DC.
Baum, M., Houghton, J., & Abrams, K. R. (1989). Early stopping rules : clinical pers-
pectives and ethical considerations. Statistics in Medicine 13, 1459–1469.
Bayarri, M. J. & Berger, J. O. (2004). The interplay of Bayesian and frequentist analysis.
Statistical Science 19, 58–80.
Bayes (1763). Essay towards solving a problem in the doctrine of chances. Philosophical
Transactions of the Royal Society of London 53, 370–418. [Reproduit dans Biometrika
45, 293–315 (1958)]
Berger, J. O. (2003). Could Fisher, Jeffreys and Neyman have agreed on testing ? [with
discussion]. Statistical Science 18, 1–32.
Berger, J. (2004). The case for objective Bayesian analysis. Bayesian Analysis 1, 1–17.
Berger, J. O. & Bernardo, J. M. (1992). On the development of reference priors [with
discussion]. In J. M. Bernardo, J. O. Berger, A. P. Dawid, & A. F. M. Smith (Eds.),
Bayesian statistics 4. Proceedings of the Fourth Valencia International Meeting, 35–60.
Oxford Univ. Press, Oxford, England.
Bernard, J.-M. (1996). Bayesian interpretation of frequentist procedures for a Bernoulli
process. The American Statistician 50, 7–13.
Bernardo, J. M. (1979). Reference posterior distributions for Bayesian inference [with
discussion]. Journal of the Royal Statistical Society, Series B, Methodological 41, 113–
147.
Bernardo, J. M. (1996). The concept of exchangeability and its applications. Far East
Journal of Mathematical Sciences 4, 111–121.
Bernardo, J. & Smith, A. F. M. (1994). Bayesian Theory . John Wiley & Sons, New York.
c© Revue MODULAD, 2006 -214- Nume´ro 35
Bernoulli, J. (1713). Ars Conjectandi, (English translation by Bing Sung as Technical
report No. 2 of the Department of Statistics of Harvard University, February 12, 1966),
Basel, Switzerland.
Berry, D. A. (1991). Experimental design for drug development : a Bayesian approach.
Journal of Biopharmaceutical Statististics 1, 81-101.
Berry, D. A. (1997). Teaching elementary Bayesian statistics with real applications in
science. The American Statistician 51, 241–246.
Berry, G. & Armitage, P. (1995). Mid-P confidence intervals : a brief review. The Statis-
tician 44, 417–423.
Box, G. E. P. & Tiao, G. C. (1973). Bayesian Inference in Statistical Analysis. Reading,
Addison Wesley, MA.
Brown, L. D., Cai, T., & DasGupta, A. (2001). Interval estimation for a binomial propor-
tion [with discussion]. Statistical Science 16, 101–133.
Bunouf, P. (2006). Lois Baye´siennes a Priori dans un Plan Binomial Se´quentiel, The`se
de doctorat en mathe´matiques, Universite´ de Rouen.
Bunouf P. & Lecoutre B. (2006). Bayesian priors in sequential binomial design. Comptes
Rendus de L’Acade´mie des Sciences Paris, Se´rie I 343, 339–344.
Cai, T. (2005). One-sided confidence intervals in discrete distributions. Journal of Statis-
tical Planning and Inference 131, 63–88.
Chib, S & Greenberg, E. (1995). Understanding the Metropolis-Hastings algorithm. Ame-
rican Statistician 49, 327–335.
Copas, J. B. & Loeber, R. (1990). Relative improvement over chance (RIOC) for 2 × 2
tables. British Journal of Mathematical and Statistical Psychology 43, 293–307.
Cox, D. R. (1970). The Analysis of Binary Data. Methuen, Londres.
de Cristofaro, R. (1996). L’influence du plan d’e´chantillonnage dans l’infe´rence statistique.
Journal de la Socie´te´ Statistique de Paris 137 23–34.
de Cristofaro, R. (2004). On the foundations of likelihood principle. Journal of Statistical
Planning and Inference 126 401–411.
de Cristofaro, R. (2006). Foundations of the ‘Objective Bayesian Inference’. First Sympo-
sium on Philosophy, History and Methodology of ERROR. Virginia Tech., Blacksburg
VA.
Dickey J. M. (1986). Discussion of Racine, A., Grieve, A. P., Flu¨hler, H. & Smith, A.
F. M., Bayesian methods in practice : Experiences in the pharmaceutical industry.
Applied Statistics 35, 93–150.
Diaconis, P. & Ylvisaker, D. (1985). Quantifying prior opinion. In J. M. Bernardo, D. V.
Lindley & A. F. M. Smith (Eds.), Bayesian Statistics 2, 133–156. North-Holland,
Amsterdam.
Dumouchel, W. (1990). Bayesian meta-analysis. In D. Berry (Ed.), Statistical Methodology
in Pharmaceutical Science, 509–529. Marcel-Dekker, New York.
Efron, B. (1998). R.A. Fisher in the 21st century [with discussion]. Statistical Science 13,
95–122.
ElQasyr, K. (2006). THe`se de doctorat de mathe´matiques en cours. Universite´ de Rouen.
FDA (2006). Guidance for the use of Bayesian statistics in medical device, draft guidance
for industry and FDA staff, U.S. Department of Health and Human Services, Food
c© Revue MODULAD, 2006 -215- Nume´ro 35
and Drug Administration, Center for Devices and Radiological Health, Rockville MD.
http ://www.fda.gov/cdrh/osb/guidance/1601.html.
de Finetti, B. (1972). Probability, Induction and Statistics : The art of guessing. John
Wiley & Sons, Londres.
de Finetti, B. (1974). Theory of probability, vol.1. John Wiley & Sons, New York.
Fisher, R. A. (1922). On the mathematical foundations of theoretical statistics. Philoso-
phical Transactions of the Royal Society, Series A 222, 309–368.
Fisher, R. A. (1925). Theory of statistical estimation. Proceedings of the Cambridge Phi-
losophic Society, 22, 700–725.
Fleiss, J. L. (1981). Statistical Methods for Rates and Proportions (2e`me e´dition). John
Wiley & Sons, New York.
Fraser, D. A. S., Reid, N., Wong, A. & Yi, G. Y. (2003). Direct Bayes for interest para-
meters. In J. M. Bernardo, M. J. Bayarri, J. O. Berger, A. P. Dawid, D. Heckerman,
A. F. M. Smith, & M. West (Eds.), Bayesian Statistics 7, 529–534. Oxford University
Press, Oxford, England.
Gamerman, D. (1997). Markov chain Monte Carlo : Stochastic simulation for Bayesian
inference. Chapman & Hall, Londres.
Gilks, W. R., Richardson, S., & Spiegelhalter, D. J. (1996). Markov Chain Monte Carlo
in Practice. Chapman & Hall, Londres.
Good, I. J. (1980). Some history of the hierarchical Bayesian methodology. In J. M. Ber-
nardo, M. H. DeGroot, D. V. Lindley, & A. F. M. Smith (Eds.), Bayesian Statistics,
489–519. Valencia University Press, Valencia. Oxford University Press, Oxford, En-
gland.
Guttman, L. (1983). What is not what in statistics ? The Statistician 26, 81–107.
Haldane, J. B. S. (1948). The precision of observed values of small frequencies. Biometrika
35, 297–300.
Inoue, L. Y. T., Berry, D. A., & Parmigiani, G. (2005). Relationship between Bayesian
and frequentist sample size determination. The American Statistician 59, 79–87.
Irony, T. Z. & Pennello, G. A. (2001). Choosing an appropriate prior for Bayesian medical
device trials in the regulatory setting. In American Statistical Association 2001 Procee-
dings of the Biopharmaceutical Section. American Statistical Association, Alexandria,
VA.
Jaynes, E. T. (2003). Probability Theory : The Logic of Science (Edited by G. L. Bret-
thorst), Cambridge University Press, Cambridge.
Jeffreys, H. (1961). Theory of Probability (3e`me e´dition). Clarendon, Oxford (1st edition :
1939).
Johnson, Kotz, & Kemp, (1992). Univariate Discrete Distributions, 2e`me e´dition. John
Wiley and Sons.
Kirk, R. E. (1982). Experimental Design. Procedures for the Behavioral Sciences. Brooks
/Cole, Pacific Grove, CA.
Laplace, P.-S (1774). Me´moire sur la probabilite´ des causes par les e´ve´nements. Savants
E´tranges 6, 621–656 [publie´ en anglais : Memoir on the probability of the causes of
events, Statistical Science 1, 364–378 (1986)].
Laplace, P.-S (1812). The´orie Analytique des Probabilite´s. Courcier, Paris.
c© Revue MODULAD, 2006 -216- Nume´ro 35
Laplace, P.-S. (1986/1825). Essai Philosophique sur les Probabilite´s (Reproduction de la
5e`me e´dition, 1825). Christian Bourgois, Paris.
Lecoutre, B. (1984). L’Analyse Baye´sienne des Comparaisons. Presses Universitaires de
Lille, Lille.
Lecoutre, B. (1996). Traitement statistique des donne´es expe´rimentales : des pratiques
traditionnelles aux pratiques baye´siennes. Avec programmes Windows par B. Lecoutre
et J. Poitevineau. DECISIA Editions, Levallois-Perret.
Lecoutre, B. (1996). Au dela` du test de signification ou l’infe´rence statistique sans tables
(a` la suite d’Alain Morineau. La Revue de Modulad 17, 98–100.
Lecoutre, B. (1997/2005). Et si vous e´tiez un baye´sien “qui s’ignore” ? La Revue de Mo-
dulad 18, 81–87. Re´e´dition (comple´te´e) : La Revue de Modulad 32, 92–105.
Lecoutre, B. (1999). Two useful distributions for Bayesian predictive procedures under
normal models. Journal of Statistical Planning and Inference 77, 93–105.
Lecoutre, B. (2000). From significance tests to fiducial Bayesian inference. In H. Rouanet,
J.-M. Bernard, M.-C. Bert, B. Lecoutre, M.-P. Lecoutre, & & B. Le Roux, New ways in
statistical methodology : From significance tests to Bayesian inference (2e`me e´dition.),
123–157. Peter Lang, Bern, SW.
Lecoutre, B. (2001). Bayesian predictive procedure for designing and monitoring expe-
riments. In Bayesian Methods with Applications to Science, Policy and Official Sta-
tistics. Office for Official Publications of the European Communities, Luxembourg,
301–310.
Lecoutre, B. (2005). Former les e´tudiants et les chercheurs aux me´thodes baye´siennes pour
l’analyse des donne´es expe´rimentales. La Revue de Modulad 33, 85–107.
Lecoutre, B. (2006). Training students and researchers in Bayesian methods for experi-
mental data analysis. Journal of Data Science 4, 207–232.
Lecoutre, B. & Charron, C. (2000). Bayesian procedures for prediction analysis of impli-
cation hypotheses in 2× 2 contingency tables. Journal of Educational and Behavioral
Statistics 25, 185–201.
Lecoutre, B., Derzko, G., & Grouin, J.-M. (1995). Bayesian predictive approach for infe-
rence about proportions. Statistics in Medicine 14, 1057–1063.
Lecoutre, B. & ElQasyr, K. (2005). Play-the-winner rule in clinical trials : models for
adaptative designs and Bayesian methods. In J. Janssen & P. Lenca (Eds.), Applied
Stochastic Models and Data Analysis Conference 2005 Proceedings, Part X. Health,
1039–1050. ENST Bretagne, Brest.
Lecoutre, B. & Faure, S. (2007). A note on new confidence intervals for the difference
between two proportions based on an Edgeworth expansion. Journal of Statistical
Planning and Inference 137, 355–356.
Lecoutre, B., Lecoutre, M.-P., & Poitevineau, J. (2001). Uses, abuses and misuses of signi-
ficance tests in the scientific community : won’t the Bayesian choice be unavoidable ?
International Statistical Review 69, 399–418.
Lecoutre, B., Mabika, B., Derzko, G. (2002). Assessment and monitoring in clinical trials
when survival curves have distinct shapes in two groups : a Bayesian approach with
Weibull modeling. Statistics in Medicine 21, 663–674.
Lecoutre, B. & Poitevineau, J. (1992). PAC (Programme d’Analyse des Comparaisons) :
Guide d’utilisation et manuel de re´fe´rence. CISIA-CERESTA, Montreuil.
Lecoutre, B. & Poitevineau, J. (2005). Le logiciel “LePAC”. La Revue de Modulad 33.
c© Revue MODULAD, 2006 -217- Nume´ro 35
Lecoutre, B., Poitevineau, J., Derzko, G., & Grouin, J.-M. (2000). De´sirabilite´ et faisabilite´
des me´thodes baye´siennes en analyse de variance : application a` des plans d’expe´rience
complexes utilise´s dans les essais cliniques. In I. Albert & B. Asselain (Eds.), Biome´trie
et Me´thodes baye´siennes 14, Socie´te´ Franc¸aise de Biome´trie, Paris, 1–23.
Lecoutre, B., Poitevineau, J., & Lecoutre, M.-P. (2005). Une raison pour ne pas aban-
donner les tests de signification de l’hypothe`se nulle / A reason why not to ban Null
Hypothesis S/ignificance Tests. La Revue de Modulad 33, 243–253.
Lecoutre, M.-P. (2000). And... What about the researcher’s point of view. In H. Rouanet,
J.-M. Bernard, M.-C. Bert, B. Lecoutre, M.-P. Lecoutre, & B. Le Roux, New ways in
statistical methodology : From significance tests to Bayesian inference (2e`me e´dition.),
65–95. Peter Lang, Bern, SW.
Lecoutre, M.-P., Poitevineau, J., & Lecoutre, B. (2003). Even statisticians are not immune
to misinterpretations of Null Hypothesis Significance Tests. International Journal of
Psychology 38, 37–45.
Lee, P. (2004). Bayesian Statistics : An Introduction (3rd edition). Oxford University
Press, New York.
Lhoste, E. (1923). Le Calcul des probabilite´s applique´ l’artillerie, lois de probabilite´ a
priori. Revue d’artillerie 91.
Lindley, D. V. (1993). The analysis of experimental data : The appreciation of tea and
wine. Teaching Statistics 15, 22–25.
Morrison, D.E. & Henkel, R.E. (1969). Significance tests reconsidered. The American
Sociologist 4, 131–140.
Mossman, D. & Berger, J. (2001). Intervals for post-test probabilities : a comparison of
five methods. Medical Decision Making 21, 498–507.
Nelson, N., Rosenthal, R., & Rosnow, R. L. (1986). Interpretation of significance levels
and effect sizes by psychological researchers. American Psychologist 41, 1299–1301.
Novick, M. R., & Jackson, P. H. (1974). Statistical Methods for Educational and Psycho-
logical Research. McGraw-Hill, NewYork.
O’Hagan, A. (1996). First Bayes [Teaching package for elementary Bayesian Statistics].
http ://www.tonyohagan.co.uk/1b/.
Pagano, R. R. (1990). Understanding statistics in the behavioral sciences (3e`me e´dition).
West, St. Paul, MN.
Perks, W. (1947). Some observations on inverse probability including a new indifference
rule. Journal of the Institute of Actuaries 73, 285–312.
Poitevineau, J., & Lecoutre, B. (2001). The interpretation of significance levels by psy-
chological researchers : The .05-cliff effect may be overstated. Psychonomic Bulletin
and Review 8, 847–850.
Rice, W. R. (1988). A new probability model for determining exact P value for 2 × 2
contingency tables. Biometrics 44, 1–22.
Robert, C. P. (1992). L’Analyse Statistique Baye´sienne. Economica, Paris.
Robert, C. P. & Casella, G. (2004). Monte Carlo Statistical Methods. Springer, New York.
Rosenthal, R. & Gaito, J. (1963). The interpretation of levels of significance by psycholo-
gical researchers. Journal of Psychology 55, 33–38.
Rosenthal, R. & Gaito, J. (1964). Further evidence for the cliff effect in the interpretation
of levels of significance. Psychological Reports 15, 570.
c© Revue MODULAD, 2006 -218- Nume´ro 35
Rouanet, H. & Lecoutre, B. (1983). Specific inference in ANOVA : From significance tests
to Bayesian procedures. British Journal of Mathematical and Statistical Psychology
36, 252–268.
Routledge, R. D. (1994). Practicing safe statistics with the mid-p∗. The Canadian Journal
of Statistics 22, 103–110.
Rozeboom, W. W (1960). The fallacy of the null hypothesis significance test. Psychological
Bulletin 57, 416–428.
Savage, L. (1954). The Foundations of Statistical Inference. John Wiley & Sons, New
York.
Smith, A. (1995). A conversation with Dennis Lindley. Statistical Science 10, 305–319.
Spiegelhalter, D. J., Freedman, L. S., & Parmar, M. K. B. (1994). Bayesian approaches
to randomized trials. Journal of the Royal Statistical Society, Series A 157, 357–416.
Student (1908). The probable error of a mean. Biometrika 6, 1–25.
Sweeting, T. J. (2005). On the implementation of local probability matching priors for
interest parameters. Biometrika 92, 47–57.
Tan, S. B., Chung, Y. F. A. , Tai, B. C., Cheung, Y. B., & Machin, D. (2003). Elicitation
of prior distributions for a phase III randomized controlled trial of adjuvant therapy
with surgery for hepatocellular carcinoma. Controlled Clinical Trials 24, 110–21.
Tierney, L. (1994). Markov chains for exploring posterior distributions [with discussion].
The Annals of Statistics 21, 1701–1762.
Toecher, K. D. (1950). Extension of the Neyman-Pearson theory of tests to discontinuous
variables. Biometrika 37, 130–144.
Walley, P. (1996). Inferences from multinomial data : learning about a bag of marbles
[with discussion]. Journal of the Royal Statistical Society B 58, 3–57.
Wilkinson, L. and Task Force on Statistical Inference, APA Board of Scientific Affairs
(1999). Statistical Methods in Psychology Journals : Guidelines and Explanations.
American Psychologist 54, 594–604.
Winkler, R. L. (1974). Statistical analysis : theory versus practice. In The Concept of
Probability in Psychological Experiments, Ed. C.-A.S. Stae¨l Von Holstein, 127–140. D.
Reidel, Dordrecht, Pays-Bas.
Ye, K. (1993). Reference priors when the stopping rule depends on the parameter of
interest. Journal of the American Statistical Association 88, 360–363.
Zaykin, D. V., Meng, Z, & Ghosh, S. K. (2004). Interval estimation of genetic susceptibility
for retrospective case-control studies. BMC Genetics 5 :9, 1–11.
Zelen, M. (1969). Play the winner rule and the controlled clinical trial. Journal of the
American Statistical Association 64, 131–146, 1969.
Zhou, X.-H. & Qin, G. (2004). New intervals for the difference between two independent
binomial proportions. Journal of Statistical Planning and Inference 123, 97–115.
Zhou, X.-H. & Qin, G. (2005). A new confidence interval for the difference between two
binomial proportions of paired data. Journal of Statistical Planning and Inference 128,
527–542.
Zhou, X.-H. & Qin, G. (2007). A supplement to : “A new confidence interval for the
difference between two binomial proportions of paired data”. Journal of Statistical
Planning and Inference 137, 357–358.
c© Revue MODULAD, 2006 -219- Nume´ro 35
