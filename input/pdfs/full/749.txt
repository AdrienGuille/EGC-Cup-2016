MIXMOD : un logiciel de classification
supervise´e et non supervise´e pour donne´es
quantitatives et qualitatives
Florent Langrognet
Laboratoire de Mathe´matiques de Besanc¸on
UMR6623, CNRS & Universite´ de Franche-Comte´
16, route de Gray, 25030 Besanc¸on, France
Re´sume´ MIXMOD, logiciel de classification supervise´e et non supervise´e, traite
des donne´es multidimensionnelles en utilisant la richesse des mode`les de me´langes.
Il propose de nombreuses fonctionnalite´s (large palette de mode`les gaussiens et mul-
tinomiaux, d’algorithmes, de crite`res de se´lection, ...) et repose sur une architecture
particulie`rement adapte´e pour atteindre un haut niveau de performance (temps de
calcul et robustesse). MIXMOD est te´le´charge´ environ 250 fois par mois, et il est
utilise´ dans des situations tre`s diverses a` la fois dans le milieu de la recherche et, pour
une part croissante, par des utilisateurs novices. Des e´volutions sont re´gulie`rement
propose´es pour re´pondre aux demandes des utilisateurs et inte´grer les re´sultats de
la recherche.
Keywords : classification des donne´es, logiciel, mode`les de me´langes.
1 Introduction
Par leur flexibilite´, les mode`les finis de distributions de probabilite´ sont tre`s utiles pour
mode´liser une grande varie´te´ de phe´nome`nes ale´atoires et sont naturellement conside´re´s
comme un outil de choix pour traiter des proble´matiques de classification supervise´e et
non supervise´e. Utilisant ce cadre de travail, le logiciel MIXMOD est un logiciel adapte´
a` de nombreuses situations, y compris dans des situations complexes. Il peut eˆtre utilise´
dans les environnements Scilab et Matlab et est disponible, sous licence GNU GPL, pour
les syste`mes d’exploitation Linux et Windows.
Ce article ne vise pas a` remplacer le guide de l’utilisateur ni la documentation statistique
que l’on peut trouver sur le site web de´die´ a` MIXMOD. Il a pour but de pre´senter ce logiciel
(son historique, son architecture, les diffe´rentes fac¸ons de l’utiliser) et de montrer, sur des
exemples concrets, ses principales fonctionnalite´s et l’inte´reˆt d’utiliser un tel logiciel dans
des situations diverses (donne´es quantitatives ou qualitatives par exemple).
2 Fiche d’identite´
2.1 Historique
Le projet MIXMOD est ne´ en 2001 avec pour objectif de de´velopper un outil efficace,
rapide et robuste pour traiter des proble´matiques de classification de donne´es en utili-
sant les mode`les de me´lange (voir [11]). Sous l’impulsion des quatre auteurs principaux
c© Revue MODULAD, 2009 -23- Nume´ro 40
Fig. 1 – Pages ’Home’ et ’Download’ du site web consacre´ a` MIXMOD.
(C. Biernacki, professeur a` l’universite´ de Lille1, G. Celeux, directeur de recherche a` l’IN-
RIA, G. Govaert, professeur a` l’Universite´ Technologique de Compie`gne et F. Langrognet,
inge´nieur de recherche CNRS), les diffe´rentes versions de MIXMOD se sont succe´de´es a`
un rythme d’environ 2 sorties par an. Il s’agissait d’inte´grer des e´volutions fonctionnelles,
des ame´liorations en terme de rapidite´ de calcul ou de meilleures outils graphiques (pour
une utilisation dans les environnements Scilab et Matlab notamment).
– De´c. 2001 : MIXMOD 1.0 ;
– Fe´v. 2007 : MIXMOD 2.0 (traitement des donne´es qualitatives par mode`les multi-
nomiaux) ;
– Mai 2008 : MIXMOD 2.1 (traitement des donne´es quantitatives de grandes dimen-
sions par mode`les spe´cifiques (HDDA)) ;
– Fe´v. 2009 : MIXMOD 2.1.1.
2.2 Distribution
Le site web MIXMOD (www-math.univ-fcomte.fr/mixmod/ et prochaˆınement www.mixmod.org),
consacre´ au logiciel propose diffe´rentes rubriques (en anglais et en franc¸ais) :
– Te´le´chargement des diffe´rents packages (versions binaire, source pour windows et
linux) ;
– Documentations. Trois types de documentations sont disponibles :
– documentations pour l’utilisateur final : userguide et quickstart ;
– documentation statistique ;
– documentation pour le de´veloppement ;
– Bugs ;
– News ;
– FAQ ;
– . . .
Ce site web connaˆıt depuis 2001 un nombre croissant de visites et de te´le´chargements
(aujourd’hui, on compte environ 600 visites et 250 te´le´chargements par mois).
MIXMOD est distribue´ sous licence GNU GPL (donc avec le code source) autorisant les
c© Revue MODULAD, 2009 -24- Nume´ro 40
utilisateurs qui le souhaitent a` adapter le logiciel a` leurs besoins spe´cifiques. Ce type de
licence est particulie`rement adapte´ au domaine de la recherche et a, sans doute, favorise´
l’essor de MIXMOD qui a pu ainsi eˆtre utilise´ et mis a` l’e´preuve dans des conditions tre`s
diverses (type de donne´es, taille des e´chantillons, ...). Cependant, dans certaines situa-
tions particulie`res, la licence GNU GPL n’est pas adapte´e. Dans ce cas et sur demande,
MIXMOD peut eˆtre distribue´ sous une autre licence (dans le cadre d’une inte´gration dans
un logiciel dont la licence n’est pas GNU GPL par exemple).
Les 5 instituts de recherche implique´s soutiennent le de´veloppement de MIXMOD,
avec, entre autres, des de´poˆts a` l’APP (Agence pour la Protection des Programmes), un
soutien financier pour le recrutement d’inge´nieurs en CDD et de stagiaires et d’autres
actions de valorisation.
Une rencontre MIXMOD est organise´e tous les 2 ans, lieu privile´gie´ d’e´changes entre
utilisateurs et de´veloppeurs. La dernie`re rencontre MIXMOD qui s’est de´roule´e a` Lille
en de´cembre 2008 a rassemble´ une cinquantaine de personnes et a permis de nouer des
contacts tre`s enrichissants.
3 Une architecture logicielle adapte´e aux utilisateurs
et aux utilisations
Historiquement MIXMOD s’est d’abord adresse´ aux spe´cialistes de la classification
en leur proposant un outil parame´trable dans un environnement de travail adapte´ a` leurs
besoins et leurs habitudes. C’est donc naturellement que des outils pour utiliser MIXMOD
dans les environnements Scilab et Matlab ont e´te´ de´veloppe´s. Ainsi, de`s 2002, MIXMOD
est utilisable a` travers ces logiciels graˆce a` :
– une interface graphique (pour Scilab et Matlab),
– des fonctions de´die´es (pour Scilab et Matlab). Parmi ces fonctions, la fonction mix-
modView permet de visualiser graphiquement les donne´es et les re´sultats issus de
MIXMOD (voir captures d’e´cran : Fig. 2).
Ainsi, deux offres comple´mentaires sont propose´es re´pondant aux besoins des utili-
sateurs : l’interface graphique pour l’utilisateur standard et les fonctions de´die´es pour
l’utilisateur souhaitant parame´trer plus finement les options de MIXMOD.
L’architecture de MIXMOD (cf. Fig. 3) est donc organise´e autour de sa bibliothe`que
de calcul (plus de 30000 lignes de C++) particulie`rement optimise´e pour atteindre de
hautes performances en terme de temps de calcul. Un effort constant est engage´ en ce
sens depuis 2001 et chaque nouveau de´veloppement est re´alise´ en tenant compte de cet
objectif. Les fonctions pour Scilab et Matlab repre´sentent, quant a` elles, environ 20000
lignes de code.
Depuis 2001, MIXMOD s’est de plus en plus ouvert a` des utilisateurs novices (non
experts en statistiques) souhaitant disposer d’un outil puissant pour le traitement de leurs
proble´matiques de classification. Ces utilisateurs ont naturellement recours aux interfaces
graphiques sous Scilab et Matlab mais, pour un nombre croissant d’entre eux, le fait que
MIXMOD ne dispose pas de sa propre interface graphique est perc¸u comme un frein a` son
utilisation. Une re´flexion a donc e´te´ engage´e en ce sens et le de´veloppement d’une interface
graphique inde´pendante de Scilab et Matlab a de´bute´ en 2008 (voir section Perspectives).
c© Revue MODULAD, 2009 -25- Nume´ro 40
Fig. 2 – Captures d’e´cran de la fonction mixmodView (visualisation des re´sultats dans
les environnements Scilab et Matlab.)
Fig. 3 – Architecture logicielle de MIXMOD organise´e autour du noyau de calcul.
c© Revue MODULAD, 2009 -26- Nume´ro 40
4 Principales fonctionnalite´s
Le but de cet article n’est pas de de´crire de manie`re exhaustive l’ensemble des fonc-
tionnalite´s et des possibilite´s de MIXMOD qui sont de´crites (avec leurs fondements
mathe´matiques) dans la documentation de l’utilisateur, la documentation statistique
(toutes deux disponibles sur le site web de MIXMOD) ou dans les articles [3] et [2].
Il s’agit de citer les principales fonctionnalite´s dont certaines seront plus de´taille´es dans
la section Illustrations :
– Des mode`les parcimonieux pour mode´liser finement :
– 14 mode`les gaussiens pour le traitement des donne´es quantitatives base´s sur la
de´composition en valeurs singulie`res des matrices de variance (voir [9]).
– 8 mode`les spe´cifiques pour le traitement des donne´es quantitatives en grande
dimension (voir [5]).
– 5 mode`les multinomiaux pour le traitement des donne´es qualitatives base´s sur
une reparame´trisation de la distribution de Bernoulli (voir [7]).
– Des algorithmes pour maximiser la vraisemblance (ou la vraisemblance comple´te´e) :
EM, SEM, CEM, M (voir [10], [6], [8]).
– 6 modes d’initialisation et la possibilite´ de chaˆıner des algorithmes pour essayer
d’atteindre le maximum global de la vraisemblance.
– 4 crite`res de se´lection de mode`les
– BIC (Bayesian Information Criterion)
– ICL (Integrated Completed likelihood)
– NEC (Normalized Entropy Criterion)
– CV (Cross Validation)
– Ponde´ration des individus.
– . . .
5 Illustrations
Le but de cette section est de montrer l’inte´reˆt de MIXMOD et son utilisation dans
les environnements Scilab et Matlab sur deux exemples concrets.
5.1 Classification non supervise´e sur donne´es quantitatives
5.1.1 Donne´es et proble´matiques
Le premier exemple concerne une proble´matique de classification non supervise´e sur
un jeu de donne´es quantitatives en dimension 2 (cf. Fig 4).
On suppose ici que l’on connaˆıt le nombre de classes (3) et que l’on dispose d’informations
sur la dispersion des classes (variances de meˆme orientation et volumes libres) et leurs
proportions (e´gales) permettant d’utiliser le mode`le gaussien [pkλkC].
L’objectif est ici de :
– classer les individus,
– caracte´riser les 3 classes.
c© Revue MODULAD, 2009 -27- Nume´ro 40
Fig. 4 – Jeu de donne´es de la premie`re illustation : 300 individus en dimension 2.
5.1.2 Une premie`re utilisation de MIXMOD
Dans l’environnement Scilab (ou Mtalb), on peut utiliser MIXMOD a` l’aide de l’in-
terface graphique ou, ce qui sera montre´ ici, via les fonctions de´die´es : mixmod.sci et
mixmodView.sci. Les seules entre´es obligatoires de la fonction mixmod sont les donne´es
et le nombre de classes. La sortie de cette fonction sert ensuite a` la fonction mixmodView
qui permet de visualiser les re´sultats graphiquement.
Ainsi, les commandes :
data = read(’mesDonnees.dat’, 300, 2) ;
out = mixmod(data, 3) ;
permettent de re´aliser une classification des donne´es en 3 groupes.
L’ensemble des re´sultats est disponible dans la variable out que l’on utilisera ensuite pour
visualiser (cf. Fig. 5) :
– les individus classe´s par groupe (cf. Fig. 5 (a) obtenue graˆce a` la commande mix-
modView(out, [1 2], class)) ;
– les courbes d’iso-densite´s de chaque classe (cf. Fig. 5 (b) obtenue graˆce a` la com-
mandemixmodView(out, [1 2], ’isoDensityComponent’)) ;
– la densite´ du me´lange (cf. Fig. 5 (c) obtenue graˆce a` la commandemixmodView(out,
[1 2], ’densityMixture’)).
Les proportions associe´es a` chacune des classes sont respectivement de 0.5, 0.4 et 0.1.
Ainsi, l’utilisation de la fonction mixmod avec les options par de´faut permet d’obtenir
une re´ponse a` la proble´matique : une classification des donne´es et une caracte´risation des
classes.
5.1.3 Comment obtient-on ces re´sultats ?
A ce stade, une des premie`res questions qui se pose est de savoir comment on obtient
ces re´sultats, autrement dit, quelles sont les valeurs par de´faut de MIXMOD? Parmi les
options de MIXMOD, on peut citer ici la possibilite´ de mettre en concurrence plusieurs
mode`les et de se´lectionner le meilleur mode`le graˆce a` l’un des crite`res propose´s. Cette
possibilite´ ne sera pas e´tudie´e ici car, le mode`le gaussien et le nombre de classes font
c© Revue MODULAD, 2009 -28- Nume´ro 40
(a) (b) (c)
Fig. 5 – Visualisation des re´sultats avec la fonction mixmodView.
partie des hypothe`ses (mode`le [pkλkC] et 3 classes).
En revanche, la notion de strate´gie sera de´taille´e. Une strate´gie, au sens de MIXMOD,
repre´sente la description des e´tapes choisies pour mener a` bien une classification. Elle est
constitue´e :
– d’une me´thode d’initialisation,
– d’une succession d’algorithmes (au moins un) avec, pour chacun, une re`gle d’arreˆt.
Concernant les me´thodes d’initialisation, on dispose des possibilite´s suivantes :
– si on dispose d’une information a priori :
– me´thode ’USER’ si l’information concerne l’estimation des parame`tres du mode`le
(dispose t-on d’une information sur les proportions, les moyennes, les disper-
sions ?),
– me´thode ’USER PARTITION ’ si on a une connaissance partielle de certains la-
bels (par exemple les individus x et y appartiennent a` la meˆme classe).
– si on ne dispose pas d’information a priori :
– me´thode RANDOM : meilleure configuration (au sens maximum de la vraisem-
blance) de n tirages au hasard d’individus pour initialiser les centres (par de´faut
n = 5),
– me´thode SMALL EM : meilleure configuration de n tirages au hasard suivis de
m ite´rations le l’algorithme EM (avec m <= 10 et le nombre total d’ite´rations de
EM durant l’initialisation = 50),
– me´thode SEM : meilleure configuration parmi les n e´tapes de l’algorithme SEM
apre`s tirage au hasard (n = 500 par de´faut),
– me´thode CEM : meilleure configuration de n tirages au hasard suivis de m
ite´rations de CEM (n = 10 et m = 50 par de´faut).
Les re`gles d’arreˆt des algorithmes disponibles sont :
– apre`s un nombre donne´ d’ite´rations (pour EM, SEM et CEM).
– a` la stationnarite´ de la vraisemblance (pour EM) ou de la vraisemblance comple´te´e
(pour CEM). Cette possibilite´ n’est e´videmment pas offerte pour SEM.
– apre`s un nombre donne´ d’ite´rations ou a` la stationnarite´ de la vraisemblance (pour
EM) ou de la vraisemblance (comple´te´e pour CEM).
c© Revue MODULAD, 2009 -29- Nume´ro 40
Enfin, il est possible de chaˆıner plusieurs algorithmes.
Ainsi, il est par exemple possible d’appliquer la strate´gie suivante :
– initialisation par SMALL EM
– 100 ite´rations de SEM
– ite´rations de EM jusqu’a` la stationnarite´ de la vraisemblance.
Les valeurs de la strate´gie par de´faut de MIXMOD sont :
– initialisation par RANDOM
– algorithme EM arreˆte´ apre`s 200 ite´rations ou a` la stationnarite´ de la vraisemblance.
5.1.4 Algorithmes de type EM et initialisations
Les algorithmes de type EM sont de puissants outils pour maximiser la vraisemblance
mais pre´sentent quelques de´fauts bien connus (voir [1]) comme :
– une forte de´pendance vis a` vis de l’initialisation,
– une convergence vers un maximum local.
La large palette d’outils dont dispose l’utilisateur dans MIXMOD (me´thodes d’initialisa-
tion et algorithmes) sont tre`s pre´cieux pour e´viter les e´cueils des algorithmes de type EM.
Afin d’illustrer les proble`mes potentiels lie´s a` l’utilisation de ce type d’algorithme, on
propose l’e´tude du sce´nario suivant : on tire au hasard (seulement une fois) 3 individus
afin d’initialiser les centres des 3 classes puis on lance l’algorithme EM (jusqu’a` la sta-
tionnarite´ de la vraisemblance).
Impact de l’initialisation sur la vitesse de convergence
Cette initialisation par tirage au hasard peut tout d’abord avoir un effet non ne´gligeable
sur la vitesse de converge de l’algorithme.
Les deux initialisations (cf. Fig. 6 (a) et Fig. 7 (a)) re´alise´es me`nent au meˆme re´sultat
(meˆme classification, meˆmes parame`tres et meˆme valeur de vraisemblance) mais avec des
vitesses de convergence diffe´rentes. Dans la premie`re situation (cf. Fig. 6 (a)), les 3 indivi-
dus tire´s au hasard sont a` la fois relativement e´loigne´s les uns des autres et suffisamment
proches des centres des classes que l’on recherche pour permettre a` l’algorithme de conver-
ger tre`s rapidement (cf. Fig. 6 (c)) vers la solution de´crite par la figure 6 (b). Dans la
seconde situation (cf. Fig. 7 (a)), les 3 individus tire´s au hasard, bien que relativement
proches les uns des autres, permettent a` l’algorithme de converger vers la meˆme solution
(cf. Fig. 7 (b)) mais nettement plus lentement (cf. Fig. 7 (c)).
Impact de l’initialisation sur la convergence (vers des maxima diffe´rents)
La situation peut eˆtre encore plus de´favorable avec une initialisation au hasard : dans la
troisie`me situation (cf. Fig. 8 (a)), les individus tire´s au hasard sont tre`s proches les uns
des autres et l’algorithme EM converge vers une autre solution (cf. Fig. 8 (b)).
La comparaison des valeurs de la vraisemblance permet cependant de conside´rer cette
dernie`re solution comme e´tant moins satisfaisante mais cette situation est une illustration
de la convergence de l’algorithme EM vers un minimum local.
Les outils disponibles dans MIXMOD pour e´viter ces situations sont donc pre´cieux pour
e´viter les maxima locaux.
c© Revue MODULAD, 2009 -30- Nume´ro 40
(a) (b) (c)
Fig. 6 – Premie`re initialisation (a) menant a` la solution (b) en 10 ite´rations (c)
(LogV raisemblance = −1539).
(a) (b) (c)
Fig. 7 – Deuxie`me initialisation (a) menant a` la solution (b) en 80 ite´rations (c)
(LogV raisemblance = −1539).
(a) (b) (c)
Fig. 8 – Troisie`me initialisation (a) menant a` la solution (b) en 150 ite´rations (c)
(LogV raisemblance = −1539).
c© Revue MODULAD, 2009 -31- Nume´ro 40
Fig. 9 – Mesures morphologiques des oiseaux.
variable nombre de valeurs
niveaux de re´ponse
sexe 2 maˆle, femelle
sourcils 5 absent, . . . tre`s prononce´
collier 6 absent, . . . continu
ze´brures 3 absent, peu , pre´sence forte
sous-caudales 5 blanc, noir, noir&blanc, noir&BLANC, NOIR&blanc
liseret 4 absent, . . . , beaucoup
Tab. 1 – Nombre de niveaux de re´ponse des six variables de´crivant chaque oiseau.
5.2 Classification supervise´e sur donne´es qualitatives
5.2.1 Donne´es et proble´matiques
Le jeu de donne´es concerne ici des oiseaux (puffins) sur lesquels six mesures morpho-
logiques ont e´te´ effectue´es (cf. Fig. 9). Chaque individu (un oiseau) est donc de´crit par 6
variables qualitatives dont le nombre de niveaux de re´ponse est repre´sente´ dans le tableau
1.
On dipose d’un e´chantillon d’apprentissage de 69 individus re´partis en 2 classes (les sous-
espe`ces dichrous et lherminieri) et l’objectif est de trouver une re`gle de classement pour
connaˆıtre la sous-espe`ce de tout nouvel individu.
Les outils de visualisation des donne´es MIXMOD disponibles sous Scilab et Matlab
permettent par exemple de re´aliser des graphiques de type barplots en dimension 1 (cf.
Fig. 10 (a)) ou en dimension 2 (cf. Fig. 10 (b)) et scatterplots en dimension 2 (cf. Fig. 11
(a)) ou en dimension 3 (cf. Fig. 11 (b)).
c© Revue MODULAD, 2009 -32- Nume´ro 40
(a) (b)
Fig. 10 – Repre´sentation des donne´es par histogrammes sur l’axe [2] (a) et sur les axes
[1 2] (b).
(a) (b)
Fig. 11 – Repre´sentation des donne´es dans le premier plan de l’ACM (a) et sur les trois
premiers axes de l’ACM (b).
c© Revue MODULAD, 2009 -33- Nume´ro 40
(a) (b)
Fig. 12 – Parame`tres estime´s (a) et leur vue synthe´tique (b).
5.2.2 Re`gle de classement
La premie`re e´tape d’une classification supervise´e consiste a` chercher une re`gle de clas-
sement sur la base de l’e´chantillon d’apprentissage. Autrement dit, il s’agit d’appliquer
la fonction M disponible dans MIXMOD permettant l’estimation du maximum de vrai-
semblance des parame`tres du me´lange (avec le mode`le multinomial par de´faut, le plus
ge´ne´ral, [pkε
jh
k ]). Ceci s’effectue aise´ment avec MIXMOD dans les environnements Scilab
ou Matlab que ce soit avec les fonctions de´die´es ou l’interface graphique.
Les parame`tres estime´s sont repre´sente´s sur la figure 12 (a) et graphiquement (avec la
fonction mixmodView) sur la figure 12 (b).
Rappel : le terme αjhk repre´sente la probabilite´ que la variable x
j prenne la modalite´ h
lorsque l’individu x = (x1, . . . , xd) appartient a` la classe k.
A ce stade, il convient d’e´valuer la re`gle de classement obtenue, ce qui peut eˆtre re´alise´
par (au moins) deux crite`res :
– taux de reclassement par Validation Croise´e : 97.0% (67 individus bien reclasse´s sur
les 69).
– taux de reclassement par MAP (Maximum A Posteriori) : 98.5% (68 individus bien
reclasse´s sur les 69).
Le reclassement par MAP e´tant plus optimiste que celui par validation Croise´e, son taux
est donc, sans surprise, supe´rieur a` celui par Validation Croise´e. Quoiqu’il en soit, ces taux
sont suffisamment e´leve´s pour accorder de la cre´dibilite´ a` l’estimation des parame`tres et,
ce faisant, a` la re`gle de classement obtenue.
5.2.3 Classement d’un nouvel individu
La deuxie`me e´tape d’une classification supervise´e consiste a` appliquer la re`gle de clas-
sement obtenue sur de nouveaux individus pour les classer.
Ici, il s’agit de trouver la sous-espe`ce (la classe) d’un nouvel individu, un oiseau, pour
lequel on ne dispose que des 6 mesures morphologiques ayant pour valeurs (1, 3, 1, 1,
c© Revue MODULAD, 2009 -34- Nume´ro 40
Fig. 13 – Echantillon d’apprentissage et nouvel individu a` classer.
5, 2). Repre´sente´ dans le premier plan de l’ACM (cf. Fig. 13), ce nouvel individu paraˆıt
difficile a` classer visuellement. Mais en appliquant la re`gle de classement, on obtient des
probabilite´s d’appartenance respectivement de 0.06 et 0.94, ne laissant gue`re de doute a`
l’affectation de cet oiseau dans la deuxie`me sous-espe`ce.
5.2.4 Mode`les parcimonieux
Comme dans le cas de donne´es quantitatives, MIXMOD dispose pour des donne´es
qualitatives de mode`les parcimonieux permettant de proposer, sous le controˆle de crite`res,
des mode`les plus simples (avec moins de parame`tres a` estimer) en imposant des contraintes
raisonnables sur les parame`tres pk et αk.
Ceci passe par une reparame´trisation du parame`tre αk (voir [7]) en faisant apparaˆıtre un
centre et une dispersion :
∀k, j : (αj1k , . . . , αjmjk ) −→ (aj1k , . . . , ajmjk , εj1k , . . . , εjmjk )
– centre : ajhk =
{
1 si h = argmaxh α
jh
k
0 sinon
– dispersion : εjhk =
{
1− αjhk si ajhk = 1
αjhk si a
jh
k = 0.
Ainsi, comme pour les mode`les gaussiens, on peut de´finir 5 (ou 10 si l’on conside`re
que les proportions peuvent eˆtre libres ou e´gales) mode`les parcimonieux en imposant des
contraintes sur le terme de dispersion εjhk (cf. Tab. 2).
Il est alors inte´ressant de noter le nombre de parame`tres libres (ou degre´ de liberte´
(dl)) de chaque mode`le (cf. Tab. 3) :
– en fonction de K (le nombre de classes), d (le nombre de variables de´crivant chaque
individu) et de mj (nombre de niveaux de re´ponse de chaque variable),
– pour l’exemple traite´( k = 2, d = 6 et mj = (2, 5, 6, 3, 5, 4)).
On voit alors clairement l’inte´reˆt de proposer de tels mode`les permettant (quand cela
est possible) de choisir un mode`le beaucoup plus simple, en particulier lorsque l’on dispose
c© Revue MODULAD, 2009 -35- Nume´ro 40
mode`le la dispersion peut de´pendre de . . . dispersions identiques pour . . .
[ε] rien toutes les classes, variables et tous les niv. de re´ponse
[εk] classes toutes les variables et tous les niveaux de re´ponse
[εj] variables toutes les classes et tous les niveaux de re´ponse
[εjk] classes et variables tous les niveaux de re´ponse
[εjhk ] classes, variables et niveaux de re´ponse dispersions totalement libres
Tab. 2 – Les 5 mode`les multinomiaux et leurs contraintes.
mode`le dl Exemple (oiseaux)
[pε] 1 1
[pεk] K 2
[pεj] d 6
[pεjk] Kd 12
[pεjhk ] K
∑d
j=1(mj − 1) 38
Tab. 3 – Les 5 mode`les multinomiaux et leurs contraintes (ajouter K−1 pour les mode`les
a` proportions libres).
de peu d’individus par rapport au nombre de parame`tres a` estimer.
5.2.5 Choix de mode`les
On peut appliquer alors la fonction M sur l’e´chantillon d’apprentissage avec chacun
des 10 mode`les de´crits ci-dessus. Cette fonction donne, par exemple, les parame`tres de´crits
dans la figure 14 pour les mode`les [pε] (a) et [pεk] (b).
Ayant ainsi obtenu une estimation des parame`tres pour les 10 mode`les conside´re´s, il
reste a` choisir le bon mode`le (voir [4]). Ceci peut eˆtre re´alise´ graˆce aux crite`res disponibles
dans MIXMOD.
A titre d’illustration les crite`res CV et BIC ont e´te´ utilise´s et les re´sultats sont repre´sente´s
dans le tableau 4. Ainsi, le crite`re CV se´lectionnera le mode`le [pεjhk ], alors que le crite`re
BIC se´lectionnera le mode`le [pεjk].
[pε] [pεk] [pε
j] [pεjk] [pε
jh
k ] [pkε] [pkεk] [pkε
j] [pkε
j
k] [pkε
jh
k ]
LL -344 -329 -311 -281 -239 -344 -329 -311 -281 -239
CV 87.0% 88.5% 84.1% 92.8% 97.0% 87.0% 85.5% 85.5% 92.8% 97.0%
BIC 693 667 649 613 640 697 671 653 617 645
Tab. 4 – Valeurs de la LogVraisemblance, des crite`res BIC (a` minimiser) et CV(taux de
bon reclassement a` maximiser) pour les 10 mode`les.
c© Revue MODULAD, 2009 -36- Nume´ro 40
(a) (b)
Fig. 14 – Parame`tres estime´s pour les mode`les [pε] (a) et [pεk] (b).
individu hauteur poids sexe
1 172.5 66.3 1
2 167.1 54.1 2
...
...
...
...
Tab. 5 – Donne´es mixtes.
6 Perspectives
MIXMOD est, depuis 2001, un logiciel en pleine e´volution. Il inte`gre re´gulie`rement
d’une part de nouvelles fonctionnalite´s incluant les derniers re´sultats de la recherche et
re´pondant aux attentes des utilisateurs, et d’autre part, des e´volutions informatiques
ame´liorant les performances et rendant le logiciel plus convivial. Les prochaines e´volutions
envisage´es concerneront aussi de nouvelles fonctionnalite´s et des e´volutions informatiques.
6.1 De Nouvelles fonctionnalite´s
Parmi les prochaines fonctionnalite´s que MIXMOD proposera, on peut citer :
– Inte´gration des mode`les spe´cifiques a` la grande dimension (mode`les HD) dans le
cadre de la classification non supervise´e (voir [5]) ;
– Traitement des donne´es mixtes (quantitatives et qualitatives) avec des mode`les
spe´cifiques.
De telles donne´es sont assez courantes, comme dans l’exemple illustre´ dans le tableau
5 (individus caracte´rise´s par la hauteur, le poids et le sexe) ;
– Traitement des donne´es bruite´es en inte´grant une classe (de bruit) supple´mentaire
destine´e a` accueillir tout individu conside´re´ comme e´tant du bruit.
Ainsi, sur un jeu de donne´es entache´ de bruit comme repre´sente´ dans la figure 15
(a), il sera possible de re´aliser une classification non supervise´e faisant apparaˆıtre
les trois classes re´elles et la classe de bruit (cf. Fig. 15 (b)).
c© Revue MODULAD, 2009 -37- Nume´ro 40
(a) (b)
Fig. 15 – Classification non supervise´e sur un jeu de donne´es bruite´es (a) faisant ap-
paraˆıtre une classe de bruit (graphique du bas de (b)).
6.2 Des e´volutions informatiques
De nombreuses ame´liorations et e´volutions informatiques sont programme´es pour les
prochains mois :
– Ame´lioration des performances.
Ce travail de fond permet a` MIXMOD d’eˆtre un logiciel capable de traiter de tre`s
gros jeux de donne´es dans des temps raisonnables. Graˆce a` des outils de profiling
(cachegrind, valgrind), une e´tude pre´cise est re´alise´e afin de connaˆıtre les fonctions
et les portions de code les plus gourmandes en temps de calcul et ainsi d’optimiser
celles-ci le cas e´che´ant.
– Evolutions dans l’utilisation de MIXMOD :
– Simplifier l’utilisation des fonctions de´die´es a` MIXMOD pour Scilab et Matlab.
– Proposer une fonction MIXMOD pour le logiciel R.
– Cre´er des communaute´s MIXMOD/SCILAB et MIXMOD/MATLAB, MIXMOD/R
pour comple´ter l’e´ventail d’outils autour de MIXMOD.
– De´velopper une interface graphique MIXMOD inde´pendante de tout autre logiciel.
6.2.1 Une nouvelle interface graphique
Ce de´veloppement permettra aux utilisateurs d’avoir acce`s a` MIXMOD sans recourir a`
l’utilisation de logiciel tiers (Scilab, Matlab ou R) et re´pondra ainsi a` une ve´ritable attente
de nombreux utilisateurs (et utilisateurs potentiels) pour lesquels l’obligation d’utiliser des
tels logiciels est un frein. Ceci n’impliquera pas l’abandon des fonctions disponibles pour
ces logiciels car elles repre´sentent un grand inte´reˆt pour d’autres utilisateurs.
Le travail de conception et de de´veloppement a de´ja` commence´ et, on attend une premie`re
c© Revue MODULAD, 2009 -38- Nume´ro 40
Fig. 16 – Prochaine interface graphique MIXMOD.
version de cette interface MIXMOD inde´pendante de tout autre logiciel pour le de´but de
l’anne´e 2010. Des captures d’e´cran re´alise´es sur le prototype de´ja` de´veloppe´ (cf. Fig. 16)
donne les contours de ce que sera probablement cette interface.
Re´fe´rences
[1] Biernacki, C., Celeux, G., Govaert, G., 2003. Choosing starting values for the EM
algorithm for getting the highest likelihood in multivariate gaussian mixture models.
Computational Statistics and Data Analysis 41, 561–575.
[2] Biernacki, C., Celeux, G., Echenim, A., Govaert, G., Langrognet, F., 2007. Le logiciel
MIXMOD d’analyse de me´lange pour la classification et l’analyse discriminante. La
Revue de Modulad 35, 25–44.
[3] Biernacki, C., Celeux, A., Govaert, G., Langrognet, F., 2006. Model-Based Cluster
and Discriminant Analysis with the MIXMOD Software. Computational Statistics
and Data Analysis, vol. 51/2, 587–600.
[4] Biernacki, C., Govaert, G., 1999. Choosing models in model-based clustering and dis-
criminant analysis. J. Statis. Comput. Simul. 64, 49–71.
[5] Bouveyron C., Girard S. and Schmid C., 2007. High Dimensional Discriminant Ana-
lysis. Communications in Statistics : Theory and Methods, vol. 36, 2607–2623.
[6] Celeux, G., Diebolt, J., 1985. The SEM algorithm : A probabilistic teacher algorithm
derived from the EM algorithm for the mixture problem. Computational Statistics
Quarterly 2, 73–82.
c© Revue MODULAD, 2009 -39- Nume´ro 40
[7] Celeux, G., Govaert, G., 1991. Clustering Criteria for Discrete Data and Latent Class
Models. Journal of Classification, vol. 8, 157–176.
[8] Celeux, G., Govaert, G., 1992. A classification EM algorithm for clustering and two
stochastic versions. Computational Statistics and Data Analysis 14 (3), 315–332.
[9] Celeux, G., Govaert, G., 1995. Gaussian parsimonious clustering models. Pattern Re-
cognition 28 (5), 781–793.
[10] McLachlan, G. J., Krishnan, K., 1997. The EM Algorithm and Extensions. Wiley,
New York.
[11] McLachlan, G. J., Peel, D., 2000. Finite Mixture Models. Wiley, New York.
c© Revue MODULAD, 2009 -40- Nume´ro 40
