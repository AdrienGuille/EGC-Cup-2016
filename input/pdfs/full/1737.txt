Recherche cibleÂ´e de documents sur le web
Amar-Djalil MEZAOUR
LRI, UniversiteÂ´ Paris Sud, 91405 Orsay Cedex
mezaour@lri.fr, http://www.lri.fr/mezaour
ReÂ´sumeÂ´. Les langages de requeË†tes mots-cleÂ´s pour le web manquent souvent
de preÂ´cision lorsquâ€™il sâ€™agit de rechercher des documents particuliers difficile-
ment caracteÂ´risables par de simples mots-cleÂ´s (exemple : des cours java ou des
photos de formule 1). Nous proposons un langage multi-crite`res de type attribut-
valeur pour augmenter la preÂ´cision de la recherche de documents sur le web.
Nous avons expeÂ´rimentalement montreÂ´ le gain de preÂ´cision de la recherche de
documents baseÂ´ sur ce langage.
1 Introduction
De par sa croissance et son deÂ´veloppement, le web repreÂ´sente aujourdâ€™hui une source im-
portante de donneÂ´es heÂ´teÂ´roge`nes (news, articles, photos, videÂ´os...). Les informations y sont
stockeÂ´es sous forme de documents identifieÂ´s dâ€™une manie`re unique par urls et relieÂ´s entre eux
par des liens hypertextes. Rechercher ou consulter une information particulie`re consiste a` re-
trouver les urls des documents susceptibles de la contenir. Les moteurs de recherche ont eÂ´teÂ´
deÂ´veloppeÂ´s pour offrir aux utilisateurs des outils simples, mais neÂ´anmoins puissants, pour re-
chercher des documents sur le web. Un moteur de recherche (ex Google [Google, 2003]  )
se deÂ´compose grossie`rement en deux parties : un index web et un langage de requeË†tes utili-
sateur. Lâ€™index peut eË†tre vu comme un immense entrepoË†t de donneÂ´es ou` les documents webs
sont stockeÂ´s et indexeÂ´s par mots cleÂ´s apre`s avoir eÂ´teÂ´ rapatrieÂ´s par un robot explorateur. Un
langage de requeË†tes mots-cleÂ´s est proposeÂ´ aux utilisateurs pour interroger lâ€™index et acceÂ´der
aux documents web quâ€™il contient. Pour cela, lâ€™utilisateur speÂ´cifie une requeË†te dans laquelle il
preÂ´cise lâ€™ensemble des mots-cleÂ´s caracteÂ´risant, selon lui, le ou les documents a` rechercher. Cet
ensemble de mots cleÂ´s est soumis a` lâ€™index afin de retrouver les urls de documents contenant
le plus dâ€™occurences de ces mots. Les reÂ´ponses renvoyeÂ´es sont geÂ´neÂ´ralement tre`s nombreuses,
peu preÂ´cises et ne correspondent pas neÂ´cessairement aux pages souhaiteÂ´es par lâ€™utilisateur. Il
y a a` cela deux raisons majeures. Dâ€™une part, le pouvoir expressif des requeË†tes dâ€™un langage
mots-cleÂ´s ne permet pas de cerner avec exactitude les pages souhaiteÂ´es. En effet, une requeË†te
mots-cleÂ´s est limiteÂ´e a` la speÂ´cification des mots pertinents que doivent contenir les pages pour
eË†tre consideÂ´reÂ´es comme reÂ´ponses, sans autre possibiliteÂ´ de deÂ´crire dâ€™autres caracteÂ´ristiques
dâ€™une page. Ainsi, pour la recherche de documents a` faible contenu textuel (exemple : images,
pdf  ) ou pour la recherche de documents caracteÂ´risables autrement que par des mots cleÂ´s
(exemple : cours java ou c++), les requeË†tes mots-cleÂ´s se montrent inapproprieÂ´es. Dâ€™autre part,
lâ€™approche meË†me qui conside`re toute page contenant les mots cleÂ´s fournis dans une requeË†te
comme pertinente, sans tenir compte de la localisation de leur preÂ´sence ni de la structure du
document ni de son contexte accentue dâ€™avantage lâ€™impreÂ´cision des reÂ´ponses. Par exemple,
pour une recherche de documents de cours en c++, lâ€™utilisateur soumet naÄ±Â¨vement la requeË†te
 cours c++  a` un moteur de recherche sans autres alternatives pour deÂ´crire des cours c++.
Le moteur de recherche renvoie en reÂ´ponses quelques cours c++ mais aussi des documents
Recherche cibleÂ´e sur le web
deÂ´crivant lâ€™emploi du temps des cours c++ dispenseÂ´s dans une universiteÂ´ ou les urls des fo-
rums traitant de c++. Dans cet article, nous montrons quâ€™une facÂ¸on dâ€™augmenter la preÂ´cision
de la recherche sur le web consiste a` cibler la recherche de mots-cleÂ´s en tenant compte de la
structure de la page (ex son titre) ainsi que de son contexte (les liens entrant et sortant des
pages voisines dans le graphe du web). Cette recherche mots-cleÂ´s cibleÂ´e est combineÂ´e, a` lâ€™aide
dâ€™opeÂ´rateurs logiques, avec dâ€™autres crite`res concernant le type du document, son url   . Nous
avons pour cela deÂ´fini et implanteÂ´ un langage de requeË†tes multi-crite`res dont nous avons eÂ´valueÂ´
expeÂ´rimentalement la preÂ´cision.
Dans la section suivante, nous preÂ´sentons un eÂ´tat de lâ€™art des travaux existants lieÂ´s a` la
recherche de documents sur le web. La section 3 est consacreÂ´e a` la deÂ´finition de la syntaxe et
la seÂ´mantique des requeË†tes du langage que nous proposons. Nos expeÂ´rimentations (protocole
expeÂ´rimental et eÂ´valuations) sont deÂ´tailleÂ´es dans la section 4 de lâ€™article. Nous terminons par
quelques perspectives dâ€™utilisation de notre langage de requeË†tes.
2 Â´Etat de lâ€™art
Lesmoteurs de recherche reposent dans leur majoriteÂ´ sur des langagesmots-cleÂ´s exeÂ´cutables
sur de gros index de pages web. Pour reÂ´pondre a` une requeË†te mots-cleÂ´s , un moteur de re-
cherche regroupe dans ses reÂ´ponses les pages posseÂ´dant le plus dâ€™occurences des mots de 
dans leur contenu (indiffeÂ´remmentde la localisation de ces mots). Un affinement suppleÂ´mentaire
est appliqueÂ´ a` lâ€™aide de syste`mes de classement (PageRanking [Brin et Page, 1998], source &
authority [Kleinberg, 1999]) pour preÂ´senter en prioriteÂ´ les reÂ´ponses jugeÂ´es les plus inteÂ´ressantes.
Les pages pertinentes ne figurent pas neÂ´cessairement en grand nombre parmi ces reÂ´ponses.
Ceci sâ€™explique par une caracteÂ´risation insuffisante des pages souhaiteÂ´es par simple mots-cleÂ´s
sans tenir compte du contexte, de lâ€™environnement, du type et de la structure dâ€™un document.
Google propose, en plus de sa recherche mots-cleÂ´s classique, une option de recherche avanceÂ´e
qui permet a` un utilisateur de cibler sa requeË†te sur des parties bien preÂ´cises dâ€™une page. Avec
cette option, le pouvoir expressif dâ€™une requeË†tes est accru en permettant de cibler diffeÂ´rentes
parties dâ€™une page (titre, mots de lâ€™url  ). Lâ€™utilisateur ne peut cependant pas combiner plu-
sieurs requeË†tes sur diffeÂ´rentes parties dâ€™une page (cibler le titre et lâ€™url en meË†me temps par
exemple).
Dâ€™autres approches proposent dâ€™accroÄ±Ë†tre la preÂ´cision des langages requeË†tes mots-cleÂ´s en
enrichissant leurs requeË†tes par de nouveauxmots-cleÂ´s infeÂ´reÂ´s dâ€™ontologies (speÂ´cifiques a` un do-
maine ou geÂ´neÂ´rales de type WordNet [Felbaum, 1998, Voorhees, 1998]). Les nouveaux mots-
cleÂ´s ajouteÂ´s repreÂ´sentent souvent des synonymes ou des geÂ´neÂ´ralisations (en terme de concepts)
possibles des mots-cleÂ´s de la requeË†te initiale conformeÂ´ment aux ontologies utiliseÂ´es. THESUs
[Halkidi et al., octobre 2002] illustre parfaitement cette approche en combinant WordNet et
une ontologie du domaine. Les auteurs ont montreÂ´ dans une expeÂ´rimentation sur le domaine
de la technologie que leur syste`me est deux fois plus preÂ´cis que Google sur les meË†mes requeË†tes.
Pour augmenter la preÂ´cision, dâ€™autres travaux preÂ´conisent lâ€™ameÂ´lioration de la qualiteÂ´ des
documents contenus dans la collection sur laquelle vont porter les requeË†tes. Deux ameÂ´liorations
possibles ont eÂ´teÂ´ proposeÂ´es : nâ€™inclure dans la collection que les pages populaires (les mieux
classeÂ´es) ou restreindre le domaine des documents a` un the`me fixeÂ´. Dans le premier cas de
figure, Junghoo Cho et al [Cho et al., 1998] ont montreÂ´ que rapatrier prioritairement les pages
ayant un PageRank eÂ´leveÂ´ augmentait consideÂ´rablement la qualiteÂ´ des documents de la collec-
tion. De ce fait, les reÂ´ponses a` une requeË†te poseÂ´e sur une telle collection sont de qualiteÂ´ (Pa-
geRank eÂ´leveÂ´) et ont de fortes chances de correspondre aux souhaits de lâ€™utilisateur. Dans le
RNTI - E - 2
Mezaour
deuxie`me cas de figure (fixer un the`me preÂ´cis), deux techniquesmajeures ont eÂ´teÂ´ eÂ´tudieÂ´es : lâ€™ex-
ploration cibleÂ´e du web (focused crawling [Diligenti et al., 2000, Rennie et McCallum, 1999])
et lâ€™exploration intelligente (intelligent crawling [Aggarwal et al., 2001]).
Lâ€™exploration cibleÂ´e du web consiste a` restreindre lâ€™espace dâ€™exploration du web pour
ne rapatrier que les documents jugeÂ´s en rapport avec la theÂ´matique fixeÂ´e. Pour cela, une
strateÂ´gie seÂ´lective dâ€™exploration du web, du type  le meilleur dâ€™abord , est mise en place
pour suivre en prioriteÂ´ les liens jugeÂ´s prometteurs (menant rapidement vers beaucoup de do-
cuments pertinents). Cette strateÂ´gie repose sur une fonction discriminante 

qui a` partir
des mots apparaissant dans le voisinage dâ€™un lien estime lâ€™inteÂ´reË†t de le suivre. Cette fonc-
tion 

est construite a` la suite dâ€™un processus dâ€™apprentissage a` partir dâ€™un eÂ´chantillon
du graphe du web repreÂ´sentatif des documents de la theÂ´matique fixeÂ´e. Par exemple, dans
[Rennie et McCallum, 1999], les auteurs se sont inteÂ´resseÂ´s a` la construction dâ€™un moteur de
recherche CORA [whizbang, 2001], speÂ´cialiseÂ´ dans les papiers scientifiques en ligne. Ils ont
eÂ´laboreÂ´ une fonction dâ€™estimation de lâ€™inteÂ´reË†t dâ€™un lien en combinant deux techniques dâ€™ap-
prentissage (apprentissage par renforcement et classifieur bayeÂ´sien) sur un eÂ´chantillon du graphe
du web. Dans ce meË†me domaine, les travaux de Diligenti & al. [Diligenti et al., 2000] ont
servi de base pour le deÂ´veloppement du moteur de recherche CiteSeer [CiteSeer, 2003]. Leur
approche consiste a` utiliser un classifieur bayeÂ´sien pour apprendre a` estimer la distance qui
seÂ´pare le document courant dâ€™un ou plusieurs eÂ´ventuels documents pertinents. Leur strateÂ´gie
dâ€™exploration privileÂ´gie les liens sortants dâ€™un document jugeÂ´ proche de documents pertinents.
Le focused crawling est une alternative bien adapteÂ´e a` la probleÂ´matique de la recherche cibleÂ´e
de documents sur le web mais reste assez lourde a` mettre en Å“uvre. En effet, les techniques
dâ€™apprentissage, sur lesquelles lâ€™exploration seÂ´lective repose, neÂ´cessitent un eÂ´chantillon conte-
nant suffisammment de documents repreÂ´sentatifs du domaine pour atteindre des performances
acceptables. Ce type dâ€™eÂ´chantillons nâ€™est pas toujours eÂ´vident a` construire et neÂ´cessite une
lourde intervention humaine dans le processus dâ€™eÂ´tiquetage manuel des documents pertinents.
Lâ€™exploration intelligente (Intelligent Crawling) a eÂ´teÂ´ proposeÂ´e par Charu C. Aggarwal
& al dans leurs travaux [Aggarwal et al., 2001]. Cette approche ne neÂ´cessite aucun apprentis-
sage au preÂ´alable. Partant de certains points de deÂ´part, un robot  intelligent  apprend au fur
et a` mesure de son exploration a` privileÂ´gier les liens prometteurs. Cet apprentissage progres-
sif repose sur une fonction discriminante qui eÂ´value chaque page rapatrieÂ´e. Par exemple, la
veÂ´rification de la preÂ´sence dâ€™une liste de mots preÂ´deÂ´finis peut servir de fonction discriminante.
Ainsi, a` chaque nouvelle page rapatrieÂ´e et eÂ´valueÂ´e par la fonction discriminante, une combi-
naison de mesures statistiques est calculeÂ´e pour toutes les pages candidates (liens non encore
suivis). Seule la page candidate totalisant un score de combinaison eÂ´leveÂ´ est rapatrieÂ´e. Les
mesures statistiques utiliseÂ´es dans cette approche traduisent en valeurs numeÂ´riques plusieurs
aspects et caracteÂ´ristiques du graphe du web exploreÂ´ jusque la`. Par exemple, une des mesures
que les auteurs ont utiliseÂ´ consiste a` traduire en un score la probabiliteÂ´ pour quâ€™une page can-
didate, pointeÂ´e par un certain nombre de pages pertinentes (eÂ´valueÂ´es a` vrai par la fonction
discriminante), soit elle aussi une page pertinente et donc inteÂ´ressante a` rapatrier. Cette mesure
eÂ´volue a` chaque eÂ´tape de lâ€™exploration et deÂ´pend du nombre de pages pertinentes rapatrieÂ´es
au total. Lâ€™exploration intelligente posse`de un avantage certain sur lâ€™exploration cibleÂ´e car elle
reÂ´duit les couË†ts dâ€™apprentissage initiaux (pas de graphe dâ€™apprentissage ni dâ€™eÂ´tiquetage humain
a priori). Cependant, lâ€™efficaciteÂ´ dâ€™une telle approche deÂ´pend essentiellement de la fiabiliteÂ´ de
la fonction discriminante a` discriminer entre pages pertinentes et pages non pertinentes.
RNTI - E - 2
Recherche cibleÂ´e sur le web
En reÂ´sumeÂ´, la cleÂ´ de la recherche cibleÂ´e de documents sur le web reÂ´side dans la capaciteÂ´ de
caracteÂ´riser clairement et facilement les pages dâ€™inteÂ´reË†t pour pouvoir, par la suite, les distinguer
sans ambiguÄ±Â¨teÂ´ des pages non pertinentes et a` moindre couË†t. Dans ce sens, nous proposons un
langage de requeË†tes deÂ´claratif qui permet de caracteÂ´riser les pages souhaiteÂ´es dâ€™une manie`re
plus fine que les moteurs de recherche actuels.
3 Notre langage de requeË†tes
Nous avons deÂ´fini un langage de requeË†tes de type attribut-valeur qui permet a` un utilisa-
teur de combiner, a` lâ€™aide dâ€™opeÂ´rateurs logiques, plusieurs crite`res pour caracteÂ´riser les pages
qui lâ€™inteÂ´ressent. Chaque crite`re speÂ´cifieÂ´ dans une requeË†te permet de cibler la recherche de ses
valeurs (mots-cleÂ´s) sur une partie bien deÂ´termineÂ´e de la structure dâ€™une page (exemple : son
titre, le voisinage de ses liens sortants   ) ou de caracteÂ´riser une proprieÂ´teÂ´ particulie`re dâ€™une
page (exemple : son url, type mime  ). En utilisant les opeÂ´rateurs logiques de conjonction et
de disjonction, il est possible de combiner les crite`res preÂ´ceÂ´dents de manie`re a` cibler a` la fois
le type de la page (html, ps, pdf, jpg  ) avec : certaines proprieÂ´teÂ´s de lâ€™url dâ€™une page, des ca-
racteÂ´ristiques de certaines de ses parties cleÂ´s (titre, voisinage de liens sortants ou entrants   ).
Toute requeË†te de notre langage est construite a` partir de la combinaison logique de requeË†tes
atomiques. Une requeË†te atomique est une requeË†te mots-cleÂ´s de type  attribut = valeurs  ou`
les attributs sont fixeÂ´s. Les diffeÂ´rentes requeË†tes atomiques que nous consideÂ´rons sont :
    

     

: ou` chaque  

est une chaÄ±Ë†ne de caracte`res pouvant conte-
nir plusieurs mots seÂ´pareÂ´s par le caracte`re blanc. Une telle requeË†te est eÂ´valueÂ´e a`   	 sur une
page 
 si et seulement si tous les mots apparaissant dans au moins une des chaÄ±Ë†nes de caracte`res
 

sont contenus dans le titre de cette page 
 dans lâ€™ordre dans lequel ils sont deÂ´clareÂ´s dans
 

. Le titre dâ€™une page, lorsquâ€™il existe, est repeÂ´reÂ´ par le contenu des balises title ou
h1 ou meta name=â€titleâ€.
Exemple : Soit la requeË†te atomique 

titre de la page eÂ´valuation de 

 page title = cours java, introduction a` java  cours de licence en java   
java cours introductif  
 		  
 

     
 

: Les types  


doivent eË†tre conformes au standard deÂ´fini
pour les types mime de documents sur le web du langage html. La requeË†te est eÂ´valueÂ´e a`   	
sur une page 
 si le type mime de 
 correspond a` lâ€™un des types speÂ´cifieÂ´s dans la liste des  


.
Exemple : Soit 

: type de la page eÂ´valuation de 

mime = application/postscript, application/pdf document pdf   
document postscript   
document html  
  	   

     

: Cette requeË†te est eÂ´valueÂ´e a`   	 sur une page

 si et seulement sâ€™il existe une page pâ€™ ayant un lien pointant vers la page 
 et telle que la
requeË†te 
  	    

      

soit eÂ´valueÂ´e a`   	 sur 
 .
   

     

: Cette requeË†te est eÂ´valueÂ´e a`   	 sur une page 
 si et seulement si
tous les mots dâ€™un des  

apparaissent (en respectant leur ordre dans ce meË†me  

) dans les
tokens de lâ€™url de 
.
Exemple : Soit 

: url de la page eÂ´valuation de 

url = univ cours java http://www.infres.enst.fr/Ëœcharon/coursJava/  
http://www.univ-reunion.fr/Ëœcourdier/cours/java   
RNTI - E - 2
Mezaour
 	   

     

: Cette requeË†te permet de cibler les mots apparaissant
dans le voisinage des liens entrants dâ€™une page. Nous avons deÂ´fini le voisinage dâ€™un lien comme
eÂ´tant : les mots de son ancre, les tokens de lâ€™url a` laquelle il fait reÂ´feÂ´rence ainsi que les 10 mots
preÂ´ceÂ´dant et suivant le lien (avant le taga href et apre`s le tag fermant a. Cette requeË†te
est eÂ´valueÂ´e a`   	 sur une page 
 si et seulement sâ€™il existe un lien  pointant vers 
 tel quâ€™il
existe  

pour qui tous ses mots soient preÂ´sents (dans leur ordre dans  

) dans le voisinage
de .
    

     

: Cette requeË†te permet de cibler les mots apparaissant
dans le voisinage des liens sortants dâ€™une page. Cette requeË†te est eÂ´valueÂ´e de la meË†me manie`re
que la requeË†te preÂ´ceÂ´dente sauf quâ€™elle porte sur les liens meË†me dâ€™une page.
    	   :
ou`    		 est une restriction de cardinaliteÂ´ de la forme atleast[] ou atmost[].
Cette requeË†te permet de contraindre la longueur dâ€™une url. Nous avons deÂ´fini la longueur dâ€™une
url comme eÂ´tant le nombre de â€™/â€™ quâ€™elle contient.
Exemple : url length = atmost[2] url de la page eÂ´valuation de 

nous a eÂ´teÂ´ utile pour caracteÂ´riser http://www.gofast.com   
la notion de page dâ€™accueil. http://www.yahoo.fr/tourisme  
Dans la suite, nous noterons     le graphe des pages web sur lequel nous eÂ´valuons
les requeË†tes de notre langage ou`  est lâ€™ensemble des nÅ“uds (pages webs) du graphe  et 
lâ€™ensemble des arcs (liens hypertexte) reliant les pages de lâ€™ensemble  entre-elles.
La seÂ´mantique 


associeÂ´e a` une requeË†te atomique 

est deÂ´finie par lâ€™ensemble des reÂ´ponses
issues de lâ€™eÂ´valuation de 

sur les ensembles  et  :



   
  
    	 

est eÂ´valueÂ´e a`   	 sur 


Pour lâ€™eÂ´valuation des requeË†tes atomiques, nous avons implanteÂ´ en java un programme qui,
pour chaque page de  , apparie le contenu de la section cibleÂ´e par la requeË†te atomique 

aux expressions reÂ´gulie`res geÂ´neÂ´reÂ´es a` partir des valeurs contenues dans 

et conformeÂ´ment
a` la syntaxe unix/java/perl. La geÂ´neÂ´ration dâ€™expressions reÂ´gulie`res est obtenue en remplacÂ¸ant
les caracte`res blancs (seÂ´parant les mots dâ€™une valeur  

) par .* (ce qui signifie que les
mots sont rechercheÂ´s dans leur ordre dans  

indeÂ´pendamment des caracte`res qui puissent se
trouver entre eux). Il est possible dâ€™ajouter, aux attributs fixeÂ´s de notre langage (voir section
3), dâ€™autres attributs de`s lors quâ€™ils soient eÂ´valuables sur le graphe .
Une requeË†te conjonctive dans notre langage est une conjonction de requeË†tes atomiques sans
reÂ´peÂ´tition dâ€™attributs et ayant un et un seul attribut relatif au type mime. La seÂ´mantique dâ€™une
conjonction de requeË†tes atomiques    

	    	 


est deÂ´finie par : 









Une requeË†te disjonctive dans notre langage est une disjonction de conjonctions de requeË†tes
atomiques. La seÂ´mantique de   

     

est deÂ´finie par : 








Exemple : Soit la requeË†te suivante pour rechercher des cours java au format pdf, ps ou html
(mime=application/pdf,application/postscript) (incoming links=cours java,introduction java) 
(url=univ java,enseignement java)  (mime=text/html)  (url=univ cours java) 
(outgoing links=sommaire,intro) (page title=introduction java)  (incoming links=cours java)
RNTI - E - 2
Recherche cibleÂ´e sur le web
4 Â´Evaluation expeÂ´rimentale de notre langage
Afin dâ€™eÂ´valuer notre langage de requeË†tes, nous avons effectueÂ´ diffeÂ´rents tests en suivant
un protocole expeÂ´rimental speÂ´cifiant lâ€™eÂ´chantillon de requeË†tes a` tester, le corpus de pages web
pour lâ€™eÂ´valuation et les mesures de qualiteÂ´ du langage.
4.1 Lâ€™eÂ´chantillon de requeË†tes testeÂ´es
Les requeË†tes, que nous avons testeÂ´es, portent sur la recherche de documents speÂ´cifiques
dans  domaines diffeÂ´rents : des documents de cours en informatique en francÂ¸ais, des pages
dâ€™accueil de services touristiques en francÂ¸ais et des photos de formule 1. En nous mettant a` la
place dâ€™un utilisateur expeÂ´rimenteÂ´ recherchant de tels documents, nous avons manuellement
eÂ´laboreÂ´  requeË†tes diffeÂ´rentes reÂ´parties comme suit :  requeË†tes pour les documents de cours
en informatique,  requeË†tes pour les documents de tourisme et  requeË†tes pour les photos de
formule 1. Dans un premier temps et pour chaque domaine, les diffeÂ´rentes requeË†tes testeÂ´es
ont eÂ´teÂ´ obtenues par lâ€™eÂ´laboration dâ€™une requeË†te que nous appelons :  requ eË†te initiale . Dans
cette requeË†te, le roË†le de lâ€™utilisateur expeÂ´rimenteÂ´ a consisteÂ´ a` choisir : les attributs a` cibler, les
valeurs mots-cleÂ´s a` renseigner pour chaque attribut retenu et la combinaison logique a` former
sous forme de disjonctions de conjonctions dâ€™attributs. Les requeË†tes initiales des trois domaines
sont donneÂ´es dans le tableau Tab.1. Les requeË†tes initiales exploitent la richesse de notre lan-
gage de requeË†tes pour speÂ´cifier le plus preÂ´ciseÂ´ment possible les documents a` rechercher dans
chaque domaine. Lâ€™eÂ´laboration de ces trois requeË†tes permet de mettre en eÂ´vidence le pouvoir
dâ€™expression de notre langage. Par la suite, les autres requeË†tes du domaine sont geÂ´neÂ´reÂ´es par
variation de la requeË†te initiale et sont identifieÂ´es par  variation   de la requeË†te initiale. Dans
une variation  dâ€™une requeË†te initiale,  requeË†tes atomiques de toutes les conjonctions de
sont relaxeÂ´es pour obtenir une autre requeË†te moins restrictive que la requeË†te initiale.
Soit 

	    	 

une conjonction quelconque dâ€™une requeË†te initiale . Relaxer  requeË†tes
atomiques de cette conjonction ou`   consiste a` remplacer cette conjonction par la disjonc-
tion des  

conjonctions possibles suivantes : 


	    	 


. Pour des raisons de coheÂ´rence
seÂ´mantique, la requeË†te atomique relative au type mime dâ€™une page nâ€™est pas relaxable. Elle doit
neÂ´cessairement eË†tre combineÂ´e (par conjonction) avec au moins une autre requeË†te atomique. En
conseÂ´quence, il ne peut y avoir de variations  pour     .
Par ailleurs, et de par leur construction, chaque variation  dâ€™une requeË†te  est moins restric-
tive et donc moins preÂ´cise que la requeË†te initiale . De plus, une variation  de  est plus
restrictive (donc plus preÂ´cise) quâ€™une variation  	  de. Les diffeÂ´rentes variations des trois
requeË†tes initiales de chaque domaine dâ€™expeÂ´rimentation ont eÂ´teÂ´ deÂ´finies et eÂ´valueÂ´es dans le but
de mesurer, dâ€™une part, lâ€™inteÂ´reË†t des combinaisons logiques (plus preÂ´ciseÂ´ment la pertinence des
conjonctions de requeË†tes atomiques) et de pouvoir, dâ€™autre part, mettre en eÂ´vidence le gain en
preÂ´cision. Ce gain est montreÂ´ dans le tableau Tab.3.
4.2 Corpus des pages eÂ´valueÂ´es
Pour eÂ´valuer nos requeË†tes, nous avons eÂ´teÂ´ confronteÂ´s au proble`me du choix du graphe de
pages web a` construire. Pour des raisons de limitation de capaciteÂ´ de stockage et de temps
dâ€™exploration du web, nous ne pouvons pas eÂ´valuer nos requeË†tes sur tout le web (ou du moins
sur un index eÂ´quivalent en taille a` celui de Google). Nous avons alors eÂ´tudieÂ´ dâ€™autres alterna-
tives moins couË†teuses et mieux adapteÂ´es a` nos moyens mateÂ´riels. Nous avons identifieÂ´ deux
possibiliteÂ´s diffeÂ´rentes : construire un graphe de manie`re aleÂ´atoire ou construire  graphes
RNTI - E - 2
Mezaour
Pages dâ€™accueil de services touristiques
(URL = voyage,tourisme,sejour,reservation billet 	 	 	)  (page title = agence tourisme,tour
operateur,office tourisme,compagnie aerienne,vol charter 	 	 	)  (Incoming Links = agence tourisme,
tour operateur,achat reservation billets,vol regulier,voyage discount	 	 	) (Outgoing Links = reservez,
vol,sejour,contact 	 	 	)  (MIME = text/html)  (url length = atmost[2])
Documents de cours en informatique
(url = cours cpp,cours slide	 	 	) (page title = cours informatique,cours algo	 	 	)  (Incoming Links
= cours algo,cours info 	 	 	)  (Outgoing Links = introduction,sommaire	 	 	) (MIME = text/html)

(Incoming Links = cours reseaux,cours â€™iaâ€™,support cours informatique, documentation cours) 
(URL = cours ia,univ  cours,info cours 	 	 	)  (MIME = application/postscript,application/pdf 	 	 	)

(title Incoming Page = cours informatique,documentation cours,notes de cours,cours algo 	 	 	) 
(MIME = application/ppt,text/htm,application/pdf 	 	 	)  (URL = cours â€™bdâ€™, sld 	 	 	)
Photos de formule 1
(page title = photo gallery â€™f1â€™,schumacher picture,montoya picture 	 	 	)  (URL = photo â€™f1â€™
coulthard picture,villeneuve picture 	 	 	)  (Incoming Links = photo formule 1,image formule 1,
grand prix photo 	 	 	)  (Outgoing Links = suivant,precedent, previous	 	 	)  (MIME = text/htm)

(URL = f1 photo,image f1,grand prix photo,gallerie f1 	 	 	)  (Incoming Links = formula one pic,
f1 picture,formula one gallery 	 	 	)  (MIME = image)

(URL = photo ferrari f1,photo mac laren f1,ralf picture 	 	 	)  (title Incoming Page = formula one
gallery,photo ferrari â€™f1â€™ 	 	 	)  (MIME = image,text/htm)
TAB. 1 â€“ Les 3 requeË†tes initiales dâ€™expeÂ´rimentation
theÂ´matiques en rapport avec les  domaines fixeÂ´s dans la section preÂ´ceÂ´dente. La premie`re
possibiliteÂ´ est incontestablement la plus triviale a` mettre en Å“uvre. Cependant, elle preÂ´sente un
inconveÂ´nient majeur : aucune garantie dâ€™avoir des pages pertinentes dans le lot aleÂ´atoire. Ceci
peut engendrer un biais dans les reÂ´sultats des eÂ´valuations. Nous avons donc retenu la deuxie`me
possibiliteÂ´ : construire  graphes theÂ´matiques.
Pour construire nos  graphes theÂ´matiques, nous avons utiliseÂ´ Google pour recueillir, dans
un premier temps, des urls en rapport avec les  theÂ´matiques fixeÂ´es. Certaines de ces urls sont
pertinentes dâ€™autres ne le sont pas. Toutes ces urls sont rapatrieÂ´es et stockeÂ´es en local formant
 graphes de pages (un graphe par domaine). En moyenne, les ensembles des sommets de
ces graphes totalisent une taille dâ€™environ 


 sommets (pages) (voir le tableau Tab.2). Par
la suite, notre robot-explorateur a exploreÂ´ le web pour eÂ´tendre les  graphes preÂ´ceÂ´dents aux
pages reÂ´feÂ´renceÂ´es par les liens sortants des pages donneÂ´es par Google. Nous avons choisi de
parameÂ´trer notre robot de sorte quâ€™il ne suive que les liens sortant des pages les plus pertinentes.
La pertinence de ces pages est deÂ´termineÂ´e par le classement des urls de ces pages dans la liste
des reÂ´ponses Google. `A la fin de cette premie`re eÂ´tape, nous obtenons un niveau suppleÂ´mentaire
pour chaque graphe theÂ´matique a` construire. Ce niveau correspond a` lâ€™extension des meilleures
reÂ´ponses de Google dâ€™un pas. Le processus dâ€™extension des graphes est reÂ´peÂ´teÂ´ 
 fois donnant
un graphe final par domaine de profondeur 
 ou` chaque niveau est construit comme suit :
â€“ le niveau zeÂ´ro contient les pages dont les urls sont fournies par Google en reÂ´ponses a` nos
requeË†tes theÂ´matiques ;
RNTI - E - 2
Recherche cibleÂ´e sur le web
â€“ le niveau  est constitueÂ´ de lâ€™extension des pages les plus pertinentes du niveau 
 ;
â€“ Les niveaux 	   	  
 sont construits a` partir des pages issues du crawling semi-
exhaustif du web a` partir des liens sortants du niveau 	  . Afin de satisfaire les
contraintes imposeÂ´es par nos moyens mateÂ´riels, nous avons deÂ´fini un facteur de bran-
chement  variable pour reÂ´duire le nombre de liens a` suivre par page.
Les choix, que nous avons retenus pour la construction de nos graphes theÂ´matiques, nous
garantissent la preÂ´sence dâ€™un nombre suffisant de pages pertinentes pour valider les mesures de
qualiteÂ´ (voir section 4.3) des eÂ´valuations de nos requeË†tes. La justification de ces choix repose
sur deux hypothe`ses. Dâ€™une part, nous consideÂ´rons Google comme suffisamment puissant et
fiable pour fournir des urls de qualiteÂ´. Cette qualiteÂ´ est particulie`rement confirmeÂ´e lorsquâ€™il
sâ€™agit des pages bien classeÂ´es dans les reÂ´ponses [Brin et Page, 1998]. Dâ€™autre part, lâ€™exten-
sion des meilleures reÂ´ponses de Google par crawling pour inclure plus de pages pertinentes
sâ€™appuie sur les travaux montrant que le web est theÂ´matiquement connexe [Kleinberg, 1999,
Brin et Page, 1998, Diligenti et al., 2000]. En effet, une page pertinente pointe souvent sur
dâ€™autres pages pertinentes traitant du meË†me the`me. Suivre les liens dâ€™une telle page augmente
la chance dâ€™inclure des pages pertinentes dans le graphe theÂ´matique.
Soit la requeË†te initiale dâ€™un des trois domaines fixeÂ´s. Le graphe de tests     associeÂ´
a` ce domaine est construit suivant les eÂ´tapes deÂ´crites ci-dessous :
â€“ Au deÂ´part, un ensemble de requeË†tes Google est constitueÂ´ a` partir des requeË†tes atomiques
contenues dans la requeË†te . Seules les requeË†tes atomiques exeÂ´cutables par Google
avanceÂ´ sont retenues et sont : 
  	 ,  , 		  	 ,  	  	 . Pour
chaque occurence de lâ€™une de ces dernie`res requeË†tes dans, nous soumettons toutes ses
valeurs a` Google avanceÂ´. En reÂ´ponses, nous reÂ´cupeÂ´rons au maximum 

 urls (limite de
lâ€™API Google) par valeur soumise.
Exemple : Soit  la requeË†te suivante : (page title = cours java , cours c++)  (url = univ java
, cours cpp). La syntaxe de la requeË†te Google avanceÂ´ envoyeÂ´e est : (allintitle: cours java) OR
(allintitle: cours c++) OR (allinurl: univ java) OR (allinurl: cours cpp).
Nous avons retenu toutes les urls fournies et leur classement (pagerank) associeÂ´ obtenant
ainsi un ensemble initial dâ€™urls. Les urls de cet ensemble sont rapatrieÂ´es et sauvegardeÂ´es
dans une base de donneÂ´es MySql suivant un scheÂ´ma que nous avons deÂ´fini et qui nous
permet dâ€™eÂ´valuer les attributs de nos requeË†tes. Les informations dâ€™une page que nous
avons gardeÂ´es dans notre base sont : son titre, son url, son type mime, lâ€™ancre et le voi-
sinage de ses liens sortants et lorsque cela est possible lâ€™ancre et le voisinage des liens
qui pointent vers cette pages. Les tuples de notre base de donneÂ´es MySql constituent une
sous-partie de notre ensemble de tests  .
â€“ Pour construire le graphe, nous avons choisi dâ€™eÂ´tendre les deux meilleures urls par va-
leur soumise. Pour cela, nous avons concÂ¸u un robot explorateur en java qui parcours
le web suivant la strateÂ´gie  profondeur dâ€™abord . Le robot admet en entreÂ´e deux pa-
rame`tres : les urls de deÂ´part (dans notre cas les deux meilleures urls par valeur sou-
mise), la profondeur maximale a` atteindre (10 dans nos expeÂ´rimentations). Pour limiter
lâ€™espace dâ€™exploration, le facteur de branchement que nous avons deÂ´fini est le suivant :
facteur de branchement par page   

. Ce facteur nous a permis de ne retenir que
 liens, choisis aleÂ´atoirement parmi tous les liens dâ€™une page dâ€™un niveau 	   	  
.
RNTI - E - 2
Mezaour
â€“ La taille du graphe construit pour chaque domaine est donneÂ´ dans le tableau Tab.2.
requeË†te # reÂ´ponses Google # pages   # liens suivis 
cours informatiques en ligne 	 	 			
annuaire de documents de tourisme 	 		 		
	
photos de formule 1 			 		
 				

TAB. 2 â€“ Taille du graphe pour chaque requeË†te test
4.3 Mesures de qualiteÂ´
Nous avons retenu deuxmesures pour eÂ´valuer la qualiteÂ´ des reÂ´ponses obtenues : La preÂ´cision
et la couverture. La preÂ´cision est la proportion de pages reÂ´ellement pertinentes parmi les pages
reÂ´ponses de la requeË†te (eÂ´valueÂ´es a`   	). La couverture est le taux de pages reÂ´ellement perti-
nentes des reÂ´ponses de la requeË†te parmi les pages pertinentes du graphe  .
Soient  lâ€™ensemble de pages de tests, la requeË†te a` eÂ´valuer et  lâ€™ensemble des reÂ´ponses
issues de lâ€™eÂ´valuation de sur . La modaliteÂ´ de pertinence nous permet de diviser chacun des
ensembles preÂ´ceÂ´dents en deux sous-ensembles de pages reÂ´ellement pertinentes ( 	) et pages
non-pertinentes ( 	) :    	   	,    	   	. La preÂ´cision et la couverture se
deÂ´finissent alors par :
preÂ´cision  
	

 
couverture 

	


	

La taille du graphe de tests (voir Tab.2) et des reÂ´ponses retourneÂ´es lors des eÂ´valuations eÂ´tant im-
portantes, nous avons eu recours a` des techniques dâ€™eÂ´chantillonnage pour estimer la preÂ´cision
et la couverture. Nous avons constitueÂ´, a` chaque eÂ´valuation, un eÂ´chantillon aleÂ´atoire de 


pages et nous lâ€™avons manuellement eÂ´tiqueteÂ´ en pertinent ou pas (estimation de  	 ). Nous
avons fait de meË†me pour estimer la proportion des pages pertinentes contenues dans  ( 	 )
Nous voulons pouvoir estimer le gain de preÂ´cision dâ€™une requeË†te de notre langage face a`
Google (Google classique et Google avanceÂ´). La diffeÂ´rence du pouvoir dâ€™expression entre
notre langage de requeË†tess et celui de Google (classique ou avanceÂ´) fait que nous ne pou-
vons pas eÂ´crire une requeË†te exeÂ´cutable par Google qui soit eÂ´quivalente a` une requeË†te de notre
langage. En effet, nos requeË†tes initiales de tests et leurs variations sont des combinaisons lo-
giques de requeË†tes atomiques. Or, Google, dans sa version classique, ne permet pas de cibler
les parties dâ€™une page contrairement a` une requeË†te WeQueL. Dans sa version avanceÂ´, Google
permet seulement de cibler des parties particulie`res dâ€™une page sans pouvoir les combiner. En
conseÂ´quence et pour chaque domaine, nous avons deÂ´fini plusieurs requeË†tes Google compa-
rables a` nos requeË†tes de tests construites comme suit :
â€“ une requeË†te classique correspondant a` lâ€™union de toutes les valeurs mots-cleÂ´s apparais-
sant dans les diffeÂ´rentes requeË†tes atomiques de la requeË†te initiale ;
â€“ autant de requeË†tes Google avanceÂ´ que de requeË†tes atomiques exeÂ´cutables par Google
avanceÂ´ dans la requeË†te initiale .
De cette manie`re, les comparaisons de nos requeË†tes avec Google mettent en avant deux qua-
liteÂ´s essentielles de notre langage : lâ€™efficaciteÂ´ des requeË†tes cibleÂ´es sur des parties particulie`res
RNTI - E - 2
Recherche cibleÂ´e sur le web
de pages (comparaison avec Google classique) et le gain en preÂ´cision par combinaison logique
de requeË†tes atomiques (comparaison avec Google avanceÂ´ et avec les diffeÂ´rentes variations).
La couverture de Google est calculeÂ´e a` partir du taux de pages pertinentes que couvrent les
reÂ´ponses Google sur notre graphe de tests  . De meË†me que pour les requeË†tes de notre lan-
gage, nous estimons par eÂ´chantillonnage la preÂ´cision et la couverture des reÂ´sultats des requeË†tes
Google (avanceÂ´ et classique). Les reÂ´sultats de ces estimations sont donneÂ´es dans le tableau
Tab.3. Dans ces tableaux, nous ne faisons apparaÄ±Ë†tre dans la ligne  Google avanceÂ´  que la
meilleure preÂ´cision et la meilleure couverture issues des eÂ´valuations des requeË†tes  Google
avanceÂ´  testeÂ´es.
5 ReÂ´sultats expeÂ´rimentaux
Nous avons eÂ´teÂ´ extreË†mement restrictifs dans nos eÂ´tiquetages manuels. Par exemple, les do-
cuments qui en soi ne sont pas pertinents mais font reÂ´feÂ´rence a` des documents pertinents sont
eÂ´tiqueteÂ´s comme non pertinents. Seuls les documents ayant un contenu en rapport direct avec
les theÂ´matiques fixeÂ´es sont eÂ´tiqueteÂ´s a` pertinent. Ceci explique en partie les faibles scores de
preÂ´cision de Google et de certaines de nos variations. Les reÂ´sultats obtenus sur les trois the`mes
fixeÂ´s sont reÂ´sumeÂ´s dans le tableau Tab.3. Il apparaÄ±Ë†t tre`s clairement des deux premie`res lignes
cours informatiques annuaire de tourisme photos de formule 1
requeË†te preÂ´cision couverture preÂ´cision couverture preÂ´cision couverture
Google classique 9,00% 6,68% 10,00% 7,29% 9,00% 22,99%
Google avanceÂ´ 26,00% 5,82% 21,00% 4,14% 32,00% 9,47%
requeË†te initiale 71,00% 11,16% 100,00% 2,30% 65,53% 9,44%
variation 1 56,00% 56,57% 29,29% 10,56% 41,00% 36,11%
variation 2 65,00% 63,31% 8,00% 21,74% 36,00% 35,99%
variation 3 10,00% 100% 7,00% 61,56% 8,00% 93,01%
variation 4 # # 2,00% 100% # #
TAB. 3 â€“ ReÂ´sultats expeÂ´rimentaux
de chaque tableau (reÂ´sultats de Google) quâ€™une requeË†te cibleÂ´e est plus preÂ´cise quâ€™une requeË†te
classique portant sur tout le contenu dâ€™une page web. Pour les requeË†tes cibleÂ´e Google, nous
avons eÂ´valueÂ´ a` chaque fois trois possibiliteÂ´s quâ€™offrait Google avanceÂ´ : le titre, lâ€™url et puis les
liens entrants. Nous nâ€™avons retenu que la meilleure eÂ´valuation.Les requeË†tes sur les liens en-
trants ont donneÂ´ les reÂ´sultats les plus bas. Ces derniers reÂ´sultats sont pratiquement eÂ´quivalents
aux reÂ´sultats des requeË†tes classiques. Par contre, les requeË†tes Google cibleÂ´es sur le titre ou sur
lâ€™url ont atteint des preÂ´cisions eÂ´quivalentes, sensiblement plus importantes que les preÂ´cisions
des requeË†tes classiques.
En analysant les reÂ´sultats des lignes Google avanceÂ´ et nos requeË†tes initiales, nous remarquons
quâ€™une requeË†te de notre langage est en moyenne trois fois plus preÂ´cise que Google avanceÂ´
(avec les meË†mes mots-cleÂ´s, voir protocole expeÂ´rimental dans la section 4.3). Ceci montre
expeÂ´rimentalement lâ€™inteÂ´reË†t et le gain en preÂ´cision dâ€™une requeË†te combinant plusieurs crite`res
diffeÂ´rents. Nous pouvons ainsi conclure quâ€™une requeË†te de notre langage est plus expressive
quâ€™une requeË†te mots-cleÂ´s et permet de mieux cerner les documents a` rechercher.
En comparant les reÂ´sultats de lâ€™eÂ´valuation de chacune de nos requeË†tes aux reÂ´sultats des va-
riations qui leur correspondent, nous remarquons que la preÂ´cision deÂ´croÄ±Ë†t au fur et a` mesure
RNTI - E - 2
Mezaour
que lâ€™on relaË†che les contraintes dâ€™eÂ´valuation (câ€™est-a`-dire moins de crite`res par conjonction).
Ceci met en eÂ´vidence lâ€™apport en preÂ´cision des combinaisons par opeÂ´rateurs logiques (plus
preÂ´ciseÂ´ment la conjonction de plusieurs crite`res a` la fois). En effet, une conjonction faisant
intervenir plusieurs crite`res a` la fois permet une speÂ´cification plus riche et plus fine des docu-
ments a` rechercher quâ€™une conjonction qui fait intervenir moins de crite`res.
Cependant, la couverture des requeË†tes de notre langage est assez faible au vu des documents
pertinents dans notre ensemble de tests. Ceci sâ€™explique par notre meÂ´thode dâ€™eÂ´valuation qui
consiste a` nâ€™apparier que les mots fixeÂ´s dans les requeË†tes. Il est eÂ´vident que lâ€™eÂ´valuation de
nos requeË†tes passe a` coË†teÂ´ des documents pertinents ne contenant pas les termes de la requeË†te
mais des synonymes eÂ´quivalents par exemple. De plus, le concepteur de la requeË†te, aussi
expeÂ´rimenteÂ´ quâ€™il soit, ne peut renseigner de manie`re exhaustive sa requeË†te. Une possible
ameÂ´lioration consiste donc a` enrichir la requeË†te initiale par les synonymes des mots des va-
leurs de chaque requeË†te atomique (utiliserWordNet ou une ontologie). Il est eÂ´galement possible
dâ€™avoir recours a` des techniques dâ€™apprentissage pour deÂ´duire de nouveaux mots pertinents ne
figurant pas dans la requeË†te initiale.
6 Conclusion et perspectives
Dans cet article, nous avons preÂ´senteÂ´ un langage de requeË†tes pour cibler de manie`re plus
efficace les pages pertinentes a` rechercher. Nous avons illustreÂ´ son prouvoir dâ€™expression par
des exemples de requeË†tes pour rechercher trois types de documents (cours informatique, do-
cuments de tourisme, photos de f1). Nous avons, par ailleurs, montreÂ´ expeÂ´rimentalement que
notre langage est significativement plus preÂ´cis que Google sur des requeË†tes comparables.
Notre langage est en cours dâ€™utilisation dans le projet  eDot  [eDot, 2002] comme outil dâ€™aide
a` la creÂ´ation dâ€™entrepoË†ts de donneÂ´es theÂ´matiques. Le projet  eDot  (EntrepoË†ts de DonneÂ´es
Ouverts sur la Toile) consiste a` deÂ´velopper un entrepoË†t de donneÂ´es alimenteÂ´ a` partir du web
et contenant les documents traitant du risque alimentaire. Dans ce projet, nous utilisons la
puissance dâ€™expressiviteÂ´ et la preÂ´cision de notre langage pour deÂ´finir et speÂ´cifier les besoins
de lâ€™entrepoË†t en terme de pages web en eÂ´laborant une requeË†te caracteÂ´ristique. Contrairement
aux requeË†tes theÂ´matiques de cet article, la requeË†te caracteÂ´ristique dâ€™ eDot  a eÂ´teÂ´ eÂ´laboreÂ´e
de manie`re semi-automatique en sâ€™appuyant sur une ontologie du domaine et un ensemble de
pages exemples fournies par un expert.
Nous eÂ´tudions eÂ´galement dans le projet  eDot  le comportement de notre langage comme
outil de filtrage de pages web. Les pages web a` filtrer sont rapatrieÂ´es par le crawler de Xyleme
[Xyleme, 2002]. Ce crawler a eÂ´teÂ´ parameÂ´treÂ´ de manie`re a` ce quâ€™il ne rapatrie que les pages
contenant les mots cleÂ´s de lâ€™ontologie utiliseÂ´e (Sym Previous) et cela indeÂ´pendamment de leur
localisation dans la page. Ceci constitue un premier filtrage du web. La requeË†te caracteÂ´ristique
aura donc pour but de cibler les mots-cleÂ´s de lâ€™ontologie sur certaines parties dâ€™une page et
dâ€™estimer par la suite la preÂ´cision des reÂ´sultats obtenus. En fonction des reÂ´sultats que nous
obtiendrons, nous pourrons avoir recours a` un crawling intelligent pour rapatrier directement
du web les pages jugeÂ´es pertinentes et augmenter par conseÂ´quent la couverture de lâ€™entrepoË†t.
ReÂ´feÂ´rences
[Aggarwal et al., 2001] Charu C. Aggarwal, Fatima Al-Garawi, et Philip S. Yu. Intelligent
crawling on the world wide web with arbitrary predicates. In World Wide Web, pages 96â€“
RNTI - E - 2
Recherche cibleÂ´e sur le web
105, 2001.
[Brin et Page, 1998] SergeyBrin et Lawrence Page. The anatomy of a large-scale hypertextual
Web search engine. Computer Networks and ISDN Systems, 30(1â€“7):107â€“117, 1998.
[Cho et al., 1998] Junghoo Cho, Hector GarcÄ±Â´a-Molina, et Lawrence Page. Efficient crawling
through URL ordering. Computer Networks and ISDN Systems, 30(1â€“7):161â€“172, 1998.
[CiteSeer, 2003] CiteSeer. http://citeseer.nj.nec.com/cs, 2003.
[Diligenti et al., 2000] Michelangelo Diligenti, Frans Coetzee, Steve Lawrence, C. Lee Giles,
et Marco Gori. Focused crawling using context graphs. In 26th International Conference on
Very Large Databases, VLDB 2000, pages 527â€“534, Cairo, Egypt, 10â€“14 September 2000.
[eDot, 2002] eDot. EntrepoË†ts de donneÂ´es ouverts sur la toile : http://www-
rocq.inria.fr/verso/gemo/projects/edot.pdf, 2002.
[Felbaum, 1998] C. Felbaum, editor. WordNet: an electronic lexical database. Boston: MIT
Press, 1998.
[Google, 2003] Google. http://www.google.com, 2003.
[Halkidi et al., octobre 2002] Maria Halkidi, Benjamin Nguyen, Iraklis Varlamis, et Michalis
Vazirgiannis. Organising web documents into thematic subsets using an ontology (THE-
SUS). In Actes eÂ´lectroniques des Journees Web Semantique, Paris, octobre 2002.
[Kleinberg, 1999] Jon M. Kleinberg. Authoritative sources in a hyperlinked environment.
Journal of the ACM, 46(5):604â€“632, 1999.
[Rennie et McCallum, 1999] Jason Rennie et Andrew Kachites McCallum. Using reinforce-
ment learning to spider the web efficiently. In Proc. 16th International Conf. on Machine
Learning, pages 335â€“343. Morgan Kaufmann, San Francisco, CA, 1999.
[Voorhees, 1998] EM. Voorhees. WordNet: An Electronic Lexical Database and some of its
Applications, chapter 12: Using WordNet for Text Retrieval. MIT Press, Christiane Fell-
Baum editor, 1998.
[whizbang, 2001] whizbang. Cora version 2.0 : Computer science research paper search en-
gine, 2001. http://cora.whizbang.com.
[Xyleme, 2002] Xyleme. http://www.xyleme.com/, 2002.
Summary
Keyword-based web query languages suffer from a lack of precision when searching for a
precise kind of documents. Indeed, some documents cannot be simply characterized by a list
of keywords (e.g. on-line java courses or pictures of formula one). We propose a multi-criteria
query langage for a better characterization of documents. The aim is to increase the precision
of document retrieval on the web. In our experiments, we show the gain in accuracy in web
document searching using our language.
RNTI - E - 2
