©Revue MODULAD 2010 17 Numéro 41 
Optimisation pour plans d’expériences combinés à 
base des règles de lecture des cartes de contrôle 
Optimization for combined experimentations plans 
on the basis of control charts reading rules 
Abdellah AIT OUAHMAN1, Aomar IBOURK2, *Abdelhakim 
RHARRASSI 3 
1ENSA-Marrakech ouahman@ucam.ac.ma;  
2Université Cadi Ayyad, Faculté de droit- Marrakech aibourk@yahoo.fr; 
3DEG -ET/BEFRA- Marrakech, rharrassi1@yahoo.fr. 
 
Résumé :  
 
Les plans d’expériences forment un outil de pré-optimisation puissant. Ils sont souvent sous -
exploités en industrie non électrique ou chimique à cause du contraste qualité des résultats - 
coût d’expérimentation et la difficulté de modélisation. Nous montrerons que le coût 
d’expérimentation n’est pas nécessairement déterminé par le nombre d’expériences. Il peut 
être exclusivement dû au nombre de variations de niveaux subits  par les entrées. Nous 
proposons dans ce cas, une méthode simple pour réduire le prix d’expérimentation sans passer 
par les aliases:  Il suffit d'attribuer convenablement  les  facteurs aux colonnes de la matrice 
des expériences. De plus,  nous présentons une approche pratique pour la conception du 
modèle mathématique à optimiser,  en se référant aux règles de lecture des cartes de contrôle.  
Ceci, dans le cas de plusieurs plans d’expériences simultanés. 
 
Mots-clés: PLAN D’EXPERIENCES, OPTIMISATION, CAPABILITE, REGLES 
DE LECTURE DES  CARTES  DE CONTROLE. 
 
Abstract :  
 
The experimental design method constitutes a powerful tool of pre-optimization. It is very 
often under-exploited in non electric industry and non chemical industry because of the 
contrast between the quality of result and experimentation cost. We will demonstrate that the 
experimentation cost is not necessarily determined by the number of experimentations.  It 
may be exclusively due to the number of levels’ variations applied to the inputs. We suggest 
in this case a simple method to reduce the cost without using aliases: We attribute 
appropriately factors to experimentation matrix columns. In addition, we present a practical 
approach of mathematical models conception by using control charts reading rules. This in the 
case of many simultaneous experimentations plans. 
 
Keywords: THE EXPERIMENTAL DESIGN METHOD, OPTIMIZATION, 
CAPABILITY, CONTROL CHARTS READING RULES. 
 
 
 
 
©Revue MODULAD 2010 18 Numéro 41 
1. Introduction  
 
Dans une ambiance de concurrence âpre, les entreprises sont soumises à des exigences de 
qualité de plus en plus rudes. D’où la nécessité de la mise à niveau des systèmes de 
production.  Ceci n’est pas toujours facile pour les processus de fabrication complexes. La 
situation  devient  ardue lorsque le produit fabriqué est lui-même composé de plusieurs sous-
produits, possédant chacun des seuils de tolérance- contraintes en valeurs atteintes-, tel que le 
cas qui nous intéresse : le granulat 10/14. Les plans d’expériences, peuvent constituer un outil 
capable de répondre à toutes ces exigences. Ils désignent une méthodologie pour la 
caractérisation comportementale d’un système, basée sur la modification et la mesure des 
variables propres au dispositif considéré [1]. La difficulté réside dans le travail de conception 
et de modélisation des programmes à optimiser et dans la minimisation du coût 
d'expérimentation. Dans cet article, à partir de  la comparaison des changements de niveaux 
dans les matrices d'expériences d'un plan fractionnaire 23-1  et un plan complet 23, nous 
montrerons que dans notre cas, le coût d'expérimentation est le même et que la réduction du 
coût vient d'une attribution convenable des facteurs aux colonnes. De plus, la méthode de 
conception que nous présentons est à base de la répartition des cartes de contrôle en des zones 
de confiances et d'autres de dérives.  L’étude revêt un intérêt particulièrement intéressant du 
fait que le granulat dénommé entre dans la construction des routes et des autoroutes pour 
lesquelles  les standards sont de plus en plus aigus.           
 
2. Champ d’étude  
 
C'est un processus de fabrication de  granulats. Il  est schématisé par la figure1 ci-après. Les 
machines Primaire, Secondaire et Tertiaire forment les sources de variations. Les chemins 
suivis par les cailloux concassés sont T-G1-T1-C1-TN-T7-C3-T11 pour les cailloux de petite 
taille  et T-G1-T1-C1-TN-T4- C2-T6-TF-T5-T4-T8-T7-C3-T11 pour ceux  de grande taille. 
 
 
 
Figure 1 : Processus de fabrication du granulat 10/14 
 
Le granulat produit est formé de trois granularités principales 10, 12,5 et 14. La détermination 
de la proportion de chacune se fait par l’essai granulométrique conformément à la norme 
NFP–560 de l’Afnor. On prépare deux échantillons: L’un de masse M1h qu’on sèche à l’étuve 
T2 
GNB 
Sable 
10/14 
Type 2 GNA 
T1 
T7 
T8 
T6 T4 
T5 
T12 
T11 
T10 
T13 
Trémie : T 
Crible + Vibrateur : C 
Machine primaire : G1  
Machine secondaire : TN    
Machine tertiaire: TF   
Cyclone : Cy 
Convoyeur : 
C1 
 
C2 
 
C3 
 
TN 
 
TF 
 
G1 
 
T 
Cy 
Stock de granulat 
Stock de sable 
Légende : 
©Revue MODULAD 2010 19 Numéro 41 
pour la détermination de la masse sèche M1s. L’autre de masse  Mh pour l’essai. La masse 
sèche de l’échantillon soumis à l’essai est: Ms = (M1s * Mh)/ M1h .       (1)                                                                    
On verse le matériau après l’avoir lavé et séché dans une colonne de tamis classés dans 
l’ordre décroissant des mailles. On agite la colonne puis on prend un à un les tamis en 
commençant par celui qui a la plus grande ouverture. On pèse son  refus,  soit R1 sa masse. On 
refait la même chose avec le tamis suivant. On ajoute la masse du  refus précédent et on pèse 
l’ensemble; Soit R2 la masse des deux refus cumulés. On procède de la même manière pour 
les tamis qui restent  pour  déterminer R
 3, R4 …..Rn. A la fin, on pèse le tamisât s’il y en, soit 
Tn sa masse. Les masses des différents refus cumulés Ri  sont rapportées à Ms. Le pourcentage 
du tamisât correspondant au refus Ri est : 100 -  (100 * Ri / Ms).       (2)  
 
En résumé, nous sommes en présence d’un processus formé de trois machines, produisant le 
granulat 10/14, lui-même formé de trois granularités 10, 12,5 et 14. Le processus doit être 
capable de répondre aux spécifications de qualité internes (Six sigma) et externes  (Limites de 
spécifications imposées par le centre de contrôle des travaux publiques (CCTP)). Ces 
dernières sont inscrites dans le tableau 1 suivant :  
 
Tableau1. Les limites de spécifications des granularités du produit 10/14 
 
Granularité 14 12,5 10 
Limite inférieure de spécification LIS 85 50 1 
Limite supérieure de spécification LSS 99 70 15 
 
3. Stratégie d’optimisation  
                                                                                                                    
L’objectif assigné au départ à notre étude est d’instaurer un contrôle préventif de la qualité.  
Avant cela, une étude de Capabilité est nécessaire pour voir si le processus est en mesure de 
reproduire en respectant les tolérances imposées. Il suffit que l’une des granularités 10, 12,5 
ou 14 soit inadéquate pour rejeter la totalité du produit.  .                                              
D’après L’Afnor  : « Un processus sera déclaré apte, s'il a démontré pour les caractéristiques 
sélectionnées, qu'il était capable de produire pendant une période suffisamment longue, avec 
un taux théorique de non-conformité inférieur aux exigences internes à l'entreprise ou 
contractuelles. Ce taux est fréquemment fixé à 0,27% (méthode Six sigma) ». Pour des 
procédés industriels, généralement dans l’approximation d’une loi normale, on opte  pour les 
indices Cps, Cpi, Cpk  et Cp  (respectivement, indice de capabilité supérieure, de  capabilité 
inférieure, de décentrage  et de dispersion). Cp, le plus utilisé, a pour but de vérifier si la 
dispersion de la caractéristique observée est plus ou moins grande par rapport à l’intervalle de 
tolérance. Il doit être au moins égal à 1,3, alors que Cpk doit être supérieur ou égal à 1 [2].    
6
LSS LISCp
σ
−
=
 
                                                          ),min( CpiCpsCpk =              (3) 
                                                
min(( ) / 3 , ( ) / 3 )Cpk LSS LISµ σ µ σ= − −
                                                                        
µ  et σ  sont la moyenne et l’écart type de l’échantillon.                                                  
Les performances évoquées ne sont pas atteintes dans notre cas comme le montre la figure 2 
suivante et les résultats inscrits en dessous. Le processus n'est pas capable vis-à-vis de la 
granularité 10. IL  doit être mis à niveau. Nous choisissons la méthode des plans 
d’expériences MPE. 
  
 
 
 
 
 
©Revue MODULAD 2010 20 Numéro 41 
 
 
 
 
 
 
 
 
    
                              
 
 
 
 
 
 
 
        
 
 
Figure 2 : Etude de la Capabilité pour la granularité 10 
 
Le but de notre recherche est de  déterminer les longueurs optimaux pour les réglages des 
machines Primaires (X1), Secondaire (X2)  et Tertiaire  (X3) qui conduiront à une production 
dans les normes imposées, mais de plus optimale. En fait, grâce à un dispositif hydraulique ou 
un système vis écrou, l’ouverture entre les cônes d’une machine -responsable de la qualité de 
concassage-  peut être réglée entre L min  et  L max. Nous attribuons à Xi : 
-1, lorsque la machine correspondante  est au niveau supérieur de réglage (L=L max) ; 
+1, lorsque la machine correspondante  est au niveau inférieur de réglage (L=L min). 
X1, X2 et X3 constituent donc les facteurs de chacun des plans d’expériences et le 
regroupement de leur intervalle de variation définit le domaine d’étude.  
Le dispositif aura trois sorties ou réponses qui sont :  
• Y14 est le pourcentage passant au tamis de la granularité 14 ; 
• Y12.5 est celui relatif à la granularité 12.5 ; 
• Y10 est celui de la granularité 10. 
                                                   
Figure 3 : Le processus a trois entrées et trois sorties 
 
Les intervalles entre les limites de spécifications LSS et LIS des trois granularités formeront 
l’espace expérimental. Un autre espace expérimental plus ou moins grand est obtenu à partir 
des limites supérieures et inférieures de contrôle LSC et LIC à plus ou moins trois écarts types 
de la moyenne, comme le recommande la méthode Six Sigma.  
X1 
X2 
X3 
   Y14 
Y12 ,5 
Y10 
©Revue MODULAD 2010 21 Numéro 41 
Vu   la sensibilité de notre étude (satisfaire les conditions sur les trois granularités en même 
temps), nous devons effectuer suffisamment d’expériences. Nous adoptons donc des plans 
factoriels complets 23. En fait, le choix d’un plan fractionnaire 23-1 réduisant le nombre 
d’expériences à 4 au lieu de 8, n’est pas vraiment intéressant dans notre cas : La machine 
Primaire et la machine Secondaire sont successivement  les  plus difficiles à serrer (+1) ou à 
desserrer (-1). Pour la première un desserrage dure environ 45 min et  nécessite un effectif de 
quatre ouvriers. C’est donc  le réglage subit par ces deux machines qui détermine le coût 
d’expérimentation. Or, avec un plan fractionnaire 23-1, On est obligé de prendre X1 pour la 
machine Primaire et X2 pour la Secondaire, puisqu’on sait par expérience que ce sont ces deux 
machines qui déterminent en premier lieu la qualité du produit.  Si on aliase les deux facteurs 
X1 , X2 et on prend l’interaction X1X2 comme 3 éme facteur ; conformément au tableau 2 ci-
après, La machine primaire change d’état une seule fois (passage de -1 à 1) alors que      l’ état 
de la machine secondaire varie 3 fois (de -1 à +1, puis de +1 à -1 et enfin de -1 à +1), ce qui 
est exactement le nombre de changements d’états  lors de l’utilisation d’un plan complet, 
comme l’affirme le tableau 3, à condition bien sûr, de respecter l’ordre standard de succession 
des expériences, dit de Yates, et de ne pas choisir un ordre aléatoire. C’est le choix judicieux 
des colonnes correspondantes à chaque machine qui baissera le coût des expériences. Il faut 
donc affecter la 5éme colonne du tableau 3 à la machine Primaire,  la 4éme colonne à la machine 
Secondaire  et la 3éme colonne à la machine Tertiaire. De plus les effets calculés dans des 
plans factoriels fractionnaires sont aliasés. Ils ne traduisent  pas directement l’effet des 
facteurs considérés individuellement mais d'ensembles de facteurs et d’interactions. Il est 
donc parfois impossible conclure de façon sûre sur l’effet d’un facteur [3]. Ce qui ne nous 
arrange guère.  
  
Tableau 2: Matrice d’expériences pour un plan fractionnaire 23-1 
                                                                                         
X2 X1 X3 = X2.X1 
-1 -1 +1 
+1 -1 -1 
-1 +1 -1 
+1 +1 +1 
 
Nous aurons donc, trois plans d’expériences complets 23 combinés. Un pour chaque 
granularité. Pour simplifier l’étude nous les traiterons en même temps (tableau 3). 
 
Tableau 3: Plans d’expériences complets pour les trois réponses 
 
Ordre de Yates Moy X 3 X 2 X 1 X3X2 X3X1 X2X1 Y 14 Y12.5 Y10 
1 +1 -1 -1 -1 +1 +1 +1 95 61,0 8 
2 +1 +1 -1 -1 -1 -1 +1 94 59,5 9 
3 +1 -1 +1 -1 -1 +1 -1 93 56,0 11 
4 +1 +1 -1 -1 -1 -1 +1 91 52,0 12 
5 +1 -1 -1 +1 +1 -1 -1 86 49,0 13 
6 +1 +1 -1 +1 -1 +1 -1 84 47,0 14 
7 +1 -1 +1 +1 -1 -1 +1 79 46,5 16 
8 +1 +1 +1 +1 +1 +1 +1 77 43,0 18 
Niv+1 8cm 6cm 4cm Valeurs non codées 
Niv -1 12cm 9cm 6cm 
 
©Revue MODULAD 2010 22 Numéro 41 
Les colonnes Y14, Y12,5 et Y10 représentent les valeurs obtenues expérimentalement pour 
chacune des combinaisons de réglages correspondantes.                                                      
XiXj représente l’interaction entre Xi  et Xj. Nous avons volontairement fait omission de 
l’interaction d’ordre trois X1X2X3 afin de pouvoir effectuer les tests statistiques (plus loin).  Le 
modèle mathématique sous forme vectorielle s’écrit : Y= X.a+ e. Y est le vecteur des 
réponses, a est celui des coefficients, X est la matrice de calcul du modèle et e est le vecteur 
d’écart. Nous devons à présent déterminer les coefficients ia  du modèle postulé qui s’écrit 
dans notre cas comme suit, à condition de négliger le vecteur d’écart : 
210.321310.311210.21310.3210.2110.110.010
25.12.32135.3112125.12.2135.12.325.12.215.12.15.12.05.12
214.321314.311214.21314.3214.2114.114.014
3
3
3
XXaXXaXXaXaXaXaaY
XXaXXaXXaXaXaXaaY
XXaXXaXXaXaXaXaaY
++++++=
++++++=
++++++=
 (4)     
Pour chacune des réponses, les estimations des coefficients du modèle sont généralement 
données par la matrice Â telle que  Â = ( tXX )-1XYrep. C’est une matrice optimale au sens          
d’Hadamard (variabilité minimale), puisque tXX=nIn. Ainsi, on a Â= (XYrep)/n. Avec n est le 
nombre d’expériences, In est la matrice identité d’ordre n et Yrep est le vecteur des réponses 
expérimentales [4]. Une méthode pratique, pour calculer chacun des coefficients consiste à 
faire la moyenne des produits, élément à  élément de la colonne des réponses et celle du 
facteur se rapportant au coefficient cherché. Les a0.ij correspondent aux colonnes moyennes.  
Nous donnons par la suite deux exemples de calcul:                                            
625,28)18161413121198(
375,878)7779848691939495(
10.1
14.0
=++++−−−−=
=+++++++=
a
a
                                                               
Un premier modèle mathématique peut être construit:  
23131232110
23123215,12
23131232114
125,0125,0125,0625,0625,1625,2625,12
5,075,0375,1375,2375,575,51
125,0125,0125,1875,0375,2875,5375,87
XXXXXXXXXY
XXXXXXXY
XXXXXXXXXY
++++++=
−+−−−=
−−−−−−=
   (5)       
 
La technique du screening permet de déterminer, parmi un ensemble initial de facteurs, les 
éléments influents. Il s’agit donc d’un procédé de sélection ou de criblage [5] [6]. En effet le 
test de Student permet d’alléger le modèle mathématique en éliminant les facteurs et les 
interactions qui n’ont pas de conséquence significative sur la réponse. Dans un deuxième 
temps, on accomplit le test de Fisher-Snedecor afin de valider le modèle ajusté (Test de la 
variance): « D’une façon générale, en matière de régression, le principe de l’analyse de la 
variance est de subdiviser la variation totale en une composante factorielle relative à 
l’équation de régression ou au modèle utilisé, et une composante expérimentale, la première 
devant être testée par rapport à la deuxième. »[7]. Le test de Fisher-Snedecor  permet de 
comparer  deux variances, l’une due au modèle mathématique et l’autre résiduelle, en tenant 
compte du degré de liberté de chacune d’elle. On utilise pour cela, la loi statistique dite de 
Fisher (ou loi F). Ceci dans l’hypothèse de distributions normales.                                                   
Le premier Test (de Student), dit de signification des effets, fait intervenir les résidus ei. C’est 
la différence entre la valeur expérimentale de la réponse et la valeur calculée à partir du 
modèle. On peut alors évaluer un estimateur de la variance due aux résidus. Il est donné par : 
s
2
 = (∑ei2)/(n-p), où p est le nombre de coefficients du modèle (y compris la constante). On 
montre que tous les effets ont la même variance donnée par: si2 = s2/n.                                                                  
s
2
 ne peut être calculée pour un plan saturé, où on tient compte de toutes les interactions, dans 
ce cas on aurait n = p, c’est pourquoi nous avons négligé l’interaction d’ordre3.                                                                                                                                    
Pour chaque facteur on calcule le rapport ti de la valeur absolue de  coefficient correspondant 
par la variance commune : ti=│ai│/si . Pour un risque donné α, et pour  υ= n-p  degrés de 
liberté,  on lit dans sur la  table de Student la valeur tcrt. Si ti < tcrt (α,υ), L’effet correspondant 
©Revue MODULAD 2010 23 Numéro 41 
n’est pas signifiant.                                                                                                                          
Dans notre cas, un risque de 5% et υ = n-p = 8-7 =1, impliquent tcrt =.  12,71. Pour la 
granularité 12,5, un logiciel SPC1 donne les résultats notés dans le tableau 4 suivant : 
 
Tableau 4 : Test de signification pour la granularité 12,5 
 
Terme Effet Coeff si ti tcrit 
constante  51,75 0,125 414 12,71 
X3 -2,750   -1,375    0,125 -11 12,71 
X2 -4,750   -2,375  0,125 -19 12,71 
X1 -10,750  -5,375    0,125 -43 12,71 
X3*X1 -1 -0,5 0,125 -4 12,71 
X3*X1 0 0 0,125 0 12,71 
X2*X1 1,5 0,75 0,125 6 12,71 
 
Seuls la constante, l’effet de X2 et X1 sont signifiants puisque les ti correspondantes sont 
supérieures à la valeur critique. Seulement, dans ce cas précis, nous retenons X3 puisque  
t3=11 est proche de tcrit.                                                                                                         
Après cette étape, le modèle mathématique pour l’ensemble des sorties se réduit à : 
12
'
10
123
'
5.12
12
'
14
625,2625,1625,12
375,5375,2375,175,51
875,5375,2375,87
XXY
XXXY
XXY
++=
−−−=
−−=
    (6)                                                                                 
Pour le test F, On notera par la suite Yi les réponses observées lors de la réalisation des 
expériences, Yiest les réponses estimées à l'aide du modèle, et Ymoy la moyenne des réponses.                                                                                  
Soit  SCEL la somme des carrés des écarts dus à la liaison : ∑ −= 2)( YmoyYSCEL esti  ;         
Le carré moyen associé à SCEL est : / 1CML SCEL p= − , il représente l’erreur due au 
modèle .                                                                                                                                                 
Soit 2s  l’erreur résiduelle. Si 2/obsF CML s=  est supérieur à un Fcrt lu sur la table de Fisher-
Snedecor, pour un risque donné et avec 11 −= pυ et pn −=2υ degrés de liberté, le modèle 
est ratifié.  Ceci est le cas de notre modèle réduit tout entier pour un risque de 5% (Tableau 5). 
 
Tableau 5: Test de Fisher pour les trois réponses du processus 
 
Sorties DL effets DL Résidus SCEL CML s2 Fobs Fcrt 
'
14Y
 
2 5 321,50 160,625 3,325 48.31 5,79 
'
 12.5Y
 
3 4 291,375 97,125 1,656 58,64 6,59 
'
 10Y
 
2 5 76,250 38,125 0,875 52,59 5,79 
 
 
Le système d’équation ainsi obtenu est linéaire, Nous ambitionnons l’utilisation de la 
programmation linéaire. Pour cela :                                                                                       
- Il faut  que les variables soient de décision  positives. Nous allons donc opérer le 
changement de variable suivant : 1+= ii Xt . Ainsi  2011 ≤≤⇒≤≤− ii tX  ;                                          
- L’entreprise a tout intérêt à exploiter les cailloux concassés à fond.  Il faut favoriser la 
granularité 14 par rapport aux autres. La sortie lui correspondante constituera l’objectif ;          
                                                 
1
 : contrôle statistique des processus 
©Revue MODULAD 2010 24 Numéro 41 
- Les granularités 12,5 et 10 serviront pour la conception des contraintes du programme. Nous 
nous référons aux performances souhaitées  de la carte de contrôle pour moyennes X . Elle est 
généralement  utilisée dans ce genre d’application en adjonction  avec la carte pour 
étendue R . Les règles de lecture lui correspondantes sont : 
1. un point hors des limites à 3σ± . 
2.  9 points consécutifs d’un seul coté de la ligne centrale. 
3.  6 points consécutifs en ordre croissant ou décroissant. 
4.  14 points consécutifs qui augmentent et diminuent alternativement. 
5.  2 points sur 3 points consécutifs  hors des limites à σ2± . 
6.  4 points sur 5 points consécutifs hors des limites à 1σ± . 
7.  15 points consécutifs dans les limites à 1σ±  . 
8.  8 points consécutifs en dehors des limites à σ1± . 
Cette carte se présente comme le montre la figure 4 suivante: 
 
 
 
                                       Figure 4 : Présentation d’une carte de contrôle 
 
Pour la granularité 12,5, LSS=70 et LIS=50, nous prenons comme ligne centrale de la carte 
LC=60 pour que le processus soit centré. En outre, de nos jours, les grandes entreprises  
imposent Cp=1,67, soit 35=Cp . Cela veut dire que, si la ligne supérieure de contrôle LSC 
doit se trouver à trois écart-types )(3 XLCLSC σ+=  de LC, selon Six Sigma; la limite 
supérieure de spécification doit se trouver à cinq écarts types )(5 XLCLSS σ+= . Dans ces 
conditions, nous devons avoir LSC= 60 + 3(LSS-LC) /5 = 66.  De plus, selon les règles de 
lecture, il suffit d’avoir 2 points sur 3 hors des limites à )(2 Xσ± (règle 5) ou 4 points 
consécutifs sur 5 hors des limites à )(1 Xσ± (règle 6), pour que le processus soit déclaré en 
dérive. Il faut donc cerner les points entre les lignes à )(1 Xσ± , soit à )5/)(60( LCLSS −± , 
donc entre 58 et 62. Cela comporte un risque (regle7 : 15 points consécutifs entre les limites 
à )(1 Xσ± )  mais il est minimal par rapport à ceux des règles citées auparavant.                                                                                 
Un raisonnement similaire, en tenant pour ligne centrale 7=LC , montre que la granularité 10 
doit être cernée entre 5,6 et 8,4.     
 LSS 
         LSC=LC +3σ  
           LC+2σ 
        LC+1σ 
 
     LC-1σ 
   LC-2σ 
     LSC=LC -3σ  
    LIS 
Ligne centrale LC 
©Revue MODULAD 2010 25 Numéro 41 
Toutes ces considérations conduisent au programme linéaire suivant : 
 
1 2
1 2 3
1
2
3
1 2 3
1 2 3
1 1
1 2
  95, 625 -  5,875 - 2,375
/     
, , 0
2
2
2
60,875 5,375 2,375 1.375 62
60,875 5,375 2,375 1.375 58
8,375 2,625 1,625 8, 4
8,375 2,625 1,625 5, 6
Max z t t
S C
t t t
t
t
t
t t t
t t t
t t
t t
=
>
 <
 <

<

− − − <

− − − >

− − <

− − >
 
 
Les contraintes ne sont pas de même sens, ce programme peut être résolu par la méthode de 
Fourrier. L’utilisation d’un logiciel de programmation linéaire donne les résultats suivants: 
1 2 3 95.62500,  0,  0  0.            Z t t et t= = = =                                                                  
,10 1 −=⇒= Xt i Ceci implique toutes les machines doivent être à la limite supérieure.Ainsi:                                       
- La production de  la granularité 14 sera de 95,625% ;                                                                      
- Celle de  la granularité 12,5 sera de 60,875% ;                                                                           
- Pour  la granularité 10 aura 8,375%.                                                                                      
Les deux derniers passants aux tamis s’inscrivent parfaitement entre les limites choisies.                  
Une question pertinente se pose quant à la granularité 14. Avec une production aussi grande, 
une carte de contrôle ne signalera-t-elle pas une dérive ? On peut y remédier en prenant 
comme ligne centrale LC=95. Puisque  LSS=99 on prendra LIS=91 au lieu de 85 afin de 
centrer le processus. Les lignes à )(1 Xσ± se trouveront à 95,8 et 94,2. z = 95,625, se trouve 
entre ces deux limites et  ne sera pas interprétée comme une dérive.  
 
4. Conclusion   
   
Dans cet article, nous avons montré que la diminution du coût d’expérimentation, dans des 
cas précis, surtout lorsqu'il s'agit de processus composés de machines à réglage difficile et 
onéreux, peut être obtenue par une attribution des colonnes de la matrice d’expérimentation 
aux facteurs adéquats. Ce prix n'est pas automatiquement une conséquence du nombre 
d'expériences. Nous ne serons pas dans ce genre de  cas, obligé d'utiliser les aliases. Les  
résultats seront donc,  plus précis.                                                                                                                    
En outre, nous nous sommes basés sur les règles de lecture de la carte de contrôle pour la 
moyenne afin de formaliser le programme à optimiser. Nous avons réparti ces cartes en 
différentes parties pour pouvoir garder les sorties du processus dans la zone de non dérives. 
Cette stratégie peut être généralisée à toutes les applications multi-plans d’expériences 
similaires. Bien sûr, la répartition peut changer pour certaines cartes de contrôle telle que la 
carte Cusum par exemple. De plus, il faut choisir la méthode d’optimisation propice au 
modèle mathématique réduit (programmation linéaire ou non linéaire, heuristique…). Enfin, 
nous avons travaillé sur un cas réel, un processus de concassage, et nous avons montré 
l’apport de la MPE jointe avec les méthodes de la recherche opérationnelle dans le 
maximisation de la production et  dans le respect total des standards de la qualité. 
14
12.5 12.5 12.5
12.5 12.5 12.5
10 10 10
10 10
 Z
0
2
/
           
10
i
i
Max Y
t
t
Y LC
S C
Y LC
Y LC
Y LC
σ
σ
σ
σ
=
>
 <
 < +

> − ⇒
 < +

< −
©Revue MODULAD 2010 26 Numéro 41 
   
 
5. Bibliographie 
 
[1] STEPHANE VIVIER," Stratégies d’optimisation par la méthode des plans d’expériences 
et application aux dispositifs électrotechniques modélisés par éléments finis", Thèse de 
doctorat à l’école Centrale de Lille, (2002) 
[2] MONTGOMERY D. C, PANAGOS, M., ET R. G. HEIKES, " Economic Design of 
Control Charts for Two Manufacturing Process Models ", Naval research logistics quarterly, 
Vol. 32. N. 4, (1985) 
[3] JEAN L GOUPY, "Les plans d’expériences " Revue Modulad N 34, (2006)                                 
[4] DANIEL BENOIST, YVES TOURBIER, SANDRINE GERMAIN TOURBIER'' Plans 
d’expériences : construction et analyse", Edition Lavoisier – Tec & Doc, (1994) 
[5] PAUL SCHIMMERLING, JEAN-CLAUDE SISSON ET  ALI ZAIDI, " Pratique des 
plans d’expériences ", Editions  Lavoisier Tec & Doc, (1998) 
[6] J,L GOUPY, " Etude comparative des plans d’expériences " , Revue de statistique 
appliquée, Tome 38 N0 4, p5-44 ; (1990) 
[7] JEAN-JACQUES DROESBEKE, JEANNE FINE, GILBERT SAPORTA,"Plans 
d’expériences - Applications à l’entreprise", Edition  Technip, (1997). 
  
