L'ANALYSE  DISCRIMINANTE  
OUTIL DE CONTROLE QUALITE EN FABRICATION 
 
Thierry CEMBRZYNSKI 
RENAULT SA 
Direction de la Validation des Processus Industriels 
Exploitation Statistique des Données Service 60225 
Quai de Stalingrad 
Boulogne Billancourt 
Dans le cadre du contrôle en fabrication et plus particulièrement de la maîtrise 
statistique des processus, nous avons construit une méthode fondée sur l'analyse 
discriminante permettant, au fur et à mesure de l'obtention des mesures processus, la 
détection des dérives de performance Qualité en trois niveaux : 
Bon - Moyen - Mauvais 
Cet algorithme qui requiert un traitement informatique pour les calculs, n'est pas une 
« recette de cuisine », car il a été pensé pour la maîtrise de la variabilité des 
processus et construit de manière à fournir en temps quasi réel des résultats 
graphiques très simples à interpréter et parfaitement compatibles avec la formation 
des opérateurs en atelier. 
Notre objectif est de mettre à la disposition du plus grand nombre « l'outil 
supplémentaire » de la Qualité Totale qui doit permettre d'atteindre le « zéro défaut 
statistique » ; à cette fin cet article n'est volontairement pas théorique et s'articule 
autour d'un exemple détaillé dont le lecteur trouvera en annexe tous les programmes 
SAS (® SAS Institute Inc, Cary USA) ainsi que les données. 
 36
Introduction  
Une approche traditionnelle de la fabrication consiste à compter sur la production 
pour fabriquer le produit et sur le contrôle qualité pour inspecter le produit et repérer 
les articles ne satisfaisant pas aux spécifications. 
Nous sommes alors en présence d'une stratégie de correction. C'est un gaspillage car 
on perd du temps et des matières premières pour des produits qui ne sont pas 
toujours utilisables ; de plus, l'inspection après l'événement est peu économique car 
elle est coûteuse, peu fiable, et le gaspillage a déjà été produit. Il est beaucoup plus 
judicieux d'éviter le gaspillage en ne produisant pas de produits inutilisables. Il faut 
alors mettre en place une stratégie de prévention. C'est l'objet de la Maîtrise 
Statistique des Processus (MSP ou SPC chez les Anglo-Saxons) où l'on cherche à 
améliorer la qualité des produits en agissant sur les facteurs de variabilité des 
processus de production (manuels et ou automatisés), par la mise en œuvre de 
méthodes avancées d'analyses statistiques comme l'analyse discriminante. 
Une remarque s'impose alors. Dans cet article, nous avons choisi de laisser de côté le 
contrôle classique portant sur une seule variable (monodimensionnel) car les 
méthodes sont bien connues et relativement simples à mettre en œuvre (carte de 
contrôle,...) pour nous placer dans le cas plus complexe mais fréquent du contrôle 
concernant de nombreuses variables (multidimensionnel) qui peuvent être corrélées 
entre elles, et, éventuellement de nature différente (qualitatives et quantitatives). 
Renault possède déjà un acquis ; en collaboration avec la direction de l'Ingénérie 
Véhicule et la direction des Fabrications nous avons développé et mis en exploitation 
en peinture à l'usine de Sandouville; un logiciel temps réel d'alerte et de diagnostic 
sur la chaîne de la Safrane. Un autre logiciel développé par P. Fogel est quant à lui 
en exploitation dans les principales usines de montage (Sandouville, Douai, Flins) 
pour le suivi de l'emboutissage. 
Nous suivrons le plan suivant dans cet article: 
Dans une première partie, après quelques définitions de base sur le contrôle du 
processus, nous ferons un rappel succinct sur l'analyse discriminante, puis nous 
décrirons l'objectif, les enjeux, et sa mise en œuvre en MSP, pour terminer par son 
paramétrage et sa validation. 
Dans une seconde partie, le lecteur trouvera une illustration de la méthode sur un 
exemple dont nous fournirons les données et les programmes. 
1.  Contrôle du Processus et Analyse Discriminante 
 37
1.1. Le contrôle du processus : définition de base. 
Le contrôle du processus peut se présenter comme un système d'information avec 
retour dont les principaux éléments sont les suivants: 
• Le processus : par processus, nous entendons la combinaison complète dite des 
5M dont le travail en commun a pour résultat le produit : la main d'œuvre, les 
machines, les matières, le milieu et la méthode ; on y rajoute parfois la mesure. 
• Renseignement sur la performance : on peut apprendre beaucoup sur la 
performance réelle du processus en étudiant la qualité du produit, autrement dit; 
ses défauts, ceux-ci sont généralement réunis sur un support qu'on appelle la carte 
de contrôle. Si elle est interprétée correctement, elle permet de montrer, s'il est 
nécessaire d'intervenir pour corriger le processus, quand on constate une 
dégradation de la qualité du produit, c'est-à-dire quand on détecte une rupture de 
la performance qualité du processus. 
• Intervention sur le processus : elle est orientée sur le futur, car ce sont des 
mesures prises (selon la nécessité) pour empêcher la dégradation totale ou 
partielle du processus. Ces mesures peuvent consister en des changements sur les 
moyens, dans les matières... Bien évidemment les effets des actions sur le 
processus menées par les fabricants doivent aussi être contrôlés pour vérifier si 
elles ont permis de retrouver un régime normal. 
1.2. L'Analyse Discriminante 
On désigne sous le nom d'analyse discriminante une famille de techniques destinées 
à décrire et à classer (affecter à des classes pré-existantes) des individus caractérisés 
par un nombre important de variables numériques. 
L'origine de cette méthode remonte aux travaux de Fisher (1936) et de Mahalanobis 
(1936). 
L'analyse factorielle discriminante est une méthode à la fois descriptive et prédictive 
dont les exemples les plus classiques appartiennent sans doute au domaine médical. 
Certains diagnostics ou certaines interventions ayant été réalisés sur un ensemble de 
patients caractérisés par une série d'analyses et d'examens, on se propose de faire un 
diagnostic ou de décider une intervention sur un nouveau patient ayant subi les 
mêmes analyses et examens. L'analyse discriminante tentera à partir de ces dernières 
informations et de leur réseau d'inter-relations de prévoir le diagnostic le plus 
probable ou l'intervention la plus favorable. 
 38
Remarque : La méthode utilisée ici est une Analyse Canonique Discriminante et non 
une analyse factorielle discriminante classique; cela génère de fait des différences 
dont il convient de préciser l'origine. Sans entrer dans le détail, il s'agit ainsi d'un cas 
particulier de l'analyse canonique entre un groupe de variables quantitatives (ici les 
variables processus) et une variable qualitative (ici la variable niveau de qualité).  
La méthode proposée s'apparente fortement à une Analyse en Composantes 
Principales dans la mesure où il s'agit de « résumer » l'inertie inter-classes de la 
même manière que l'ACP résume l'inertie totale, et que les plans « factoriels » 
produits s'interprètent en terme de distance euclidienne usuelle. 
La méthode proposée est aussi un cas particulier de l'analyse de la variance 
multivariée dans la mesure où l'on discrimine non pas directement les niveaux (bon, 
moyen, mauvais), mais les différences entre les niveaux (bon - mauvais, moyen - 
mauvais), étant entendu qu'une contrainte géométrique existe entre les classes ; en 
effet, si Xi,k désigne l'indicatrice d'appartenance de l'individu i à l'une des classes k 
(k=bon, moyen, mauvais), alors X
k =
∑
1
3
i,k = 1. Cela explique alors pourquoi il n'y a 
que deux (k-1) composantes canoniques discriminantes contre trois (k) pour l'analyse 
factorielle discriminante classique de Fisher. 
D'un point de vue plus « mathématique », on dispose de N individus ou observations 
décrites par un ensemble de p variables (x1, x2,...xp) réparties en q classes définies a 
priori par la variable Y nominale à q modalités 
L'analyse discriminante se propose dans un premier temps de séparer au mieux les q 
classes à l'aide des p variables explicatives. Dans un deuxième temps, elle cherche à 
résoudre le problème de l'affectation d'individus nouveaux, caractérisés par les 
mêmes p variables, à certaines classes (1,..,q) déjà identifiées sur l'échantillon des N 
individus (appelé échantillon d'apprentissage). 
On distingue donc deux démarches successives, l'une d'ordre descriptif, l'autre 
d'ordre décisionnel : 
• Chercher les fonctions linéaires discriminantes sur l'échantillon d'apprentissage de 
taille N qui sont les combinaisons linéaires des variables explicatives                 
(x1, x2,...xp), dont les valeurs séparent au mieux les q classes. 
• Connaître la classe d'affectation de n nouveaux individus également décrits par les 
p variables explicatives explicatives (x1, x2,...xp), mais dont on ignore la classe 
 39
d'appartenance. Il s'agit ici d'un problème de classement dans des classes 
préexistantes. 
L'application de l'analyse discriminante au contrôle qualité est facile à imaginer, c'est 
de prévoir la qualité d'un produit et donc de prédire la performance du processus à 
partir de mesures externes. Elle est alors particulièrement appréciable pour les 
processus de fabrication où le retour d'information du contrôle qualité est tardif 
(longue manipulation, stockage intermédiaire...) ou à faible échantillonnage (contrôle 
destructif).  
Les variables explicatives (x1, x2,...xp) explicatives seront des paramètres du 
processus pris dans les 5M et mesurés, la variable à expliquer y, un niveau de 
performance qualité (Bon, Moyen, Mauvais). 
L'analyse discriminante est alors un outil de la MSP qui correspond à une évolution 
du contrôle du mode curatif au mode préventif. Dès la sortie de fabrication on estime 
le niveau de qualité du produit Ye=F(X) en fonction des mesures externes prises sur 
le processus X (x1, x2,...xp); le contrôle qualité final Y permet alors de valider les 
prévisions Ye par comparaison (comptage des erreurs d'affectation du modèle 
discriminant) et de le recalculer régulièrement en fonction des nouvelles données qui 
alimentent alors l'échantillon d'apprentissage, permettant ainsi d'affiner le modèle. 
La mise en œuvre doit être « simple et amusante » pour être utilisable par le plus 
grand nombre, comme l'a demandé M. Jouslin de Noray vice-président du MFQ à la 
Société des Ingénieurs de l'Automobile en novembre 1995 ; en particulier il faut que 
l'interprétation des résultats soit élémentaire et naturellement compatible avec la 
formation des opérateurs. 
A cette fin, pour le contrôle qualité, il convient d'associer au plan factoriel 
discriminant, une représentation de l'affectation aux classes Ye sous une forme 
familière aux fabricants (une carte de contrôle par exemple) et naturellement la 
fabrication se doit d'intervenir dès qu'un saut apparaît. 
2. Un exemple  
Soit un processus de fabrication où sont mesurées sur chaque unité i produite p=3 
variables processus (x1, x2, x3)i (pression, température, hygrométrie) et sur lequel on 
cumule au contrôle qualité final, le nombre de défauts y i = def i. 
La variable y est alors qualitative discrète et suit une loi de Poisson [M. Chambon 
82]. 
 40
Très généralement en MSP, les variables, pression, température et hygrométrie sont 
suivies par cartes de contrôle (aux mesures), la variable y par une carte de contrôle 
aux attributs de type C (on supposera sans restriction que les unités i sont de même 
taille N). 
L'atelier a collecté un tableau de données (X + Y) comportant 120 unités 
d'apprentissage et un tableau (X' + Y') comportant 22 unités supplémentaires pour 
comparer les estimations calculées Y'e à la réalité Y'. 
Pour mettre en œuvre l'Analyse Discriminante nous allons : 
• lire les 120 unités d'apprentissage X 
• coder la variable de défaut Y en trois classes : bon, moyen, mauvais ; cette phase 
est cruciale, et conditionne naturellement les résultats finaux du modèle 
• représenter la variable Y codée dans l'espace(x1, x2, x3) 
• calculer les fonctions discriminantes F et représenter dans le plan factoriel 
discriminant les 120 unités 
• lire les données de l'unité X' et les classer Y'e = F (X') 
• représenter les ruptures de performance qualité multidimensionnelles, la carte de 
contrôle de prédiction de la qualité du produit et comparer ses prévisions Y'e à la 
réalité Y' (connue pour la validation). 
2.1. Lecture des données d'apprentissage (Annexe 1). 
Le fichier des données MODULAD est composé de 120 unités comportant le numéro 
de l'unité, les p=3 variables explicatives press, temps, hygr et la variable à expliquer 
y=def. On trouve 3 enregistrements par ligne dans le fichier de données. 
Le programme LITDON.SAS lit les données MODULAD et crée un tableau SAS 
permanent : BASE.DONNEES. 
2.2. Codage de la variable de défaut Y en trois classes (Annexes 2,3). 
Le programme carte_c_def.sas effectue une analyse de la distribution de la variable 
y=def (PROC UNIVARIATE) qui souligne une distribution  bimodale de C  =9.13. 
On peut alors construire la carte de contrôle aux attributs de type C de la variable def 
dont les limites de contrôle supérieure (LSC) et inférieure (LIC) sont alors : 
LSC = C + 3 C  = 18,19 
LIC = C − 3 C  = 0,06. 
 41
Ces limites de contrôle normalisées (NF X06-031) correspondent à un intervalle de 
confiance Poissonien (pour une loi de Poisson μ=σ2 [CHAMBON 82]) à 3 écarts-
types (99.7% de confiance) autour de la moyenne (μ=C ) . 
Toute unité yi au delà de la limite supérieure donc représentant au moins 19 défauts 
est « hors contrôle », en se limitant à cette règle d'interprétation de la carte de 
contrôle, on remarque une période anormalement défavorable dans l'intervalle (90 - 
104), mais aucune « anormalement favorable » (en dessous de LIC). 
Si l'on souhaite un codage en trois niveaux de performance (bon, moyen, mauvais), 
les limites de contrôle LIC, LSC se révèlent trop sévères (probabilité α = 0.3 % de 
les franchir), les effectifs des classes extrêmes « bonnes » et « mauvaises » seraient 
trop faibles pour être représentatifs. C'est pourquoi il est indispensable que 
l'utilisateur, à l'examen de la carte de contrôle aux attributs du nombre de défauts 
(variable def), définisse lui-même ses trois niveaux; ce qui revient d'un point de vue 
opérationnel à définir une zone technologiquement inacceptable (niveau mauvais) et 
une zone d'amélioration cible (niveau bon). 
Le programme codage_def.sas effectue le codage désiré pour cet exemple. 
Les niveaux fixés par l'utilisateur à partir de l'étude de distribution de la variable déf 
(PROC UNIVARIATE du programme carte_c_def-sas) sont dans cet exemple : 
Bon déf. ≤ 7 défauts (Q50 = 7 = médiane) 
Moyen : 7 < déf. < 18 défauts (P90 = 17,5 Percentile à 90 %) 
Mauvais : 18 ≤ déf. (c'est presque la LSC dans ce cas). 
Cela permet alors de rechercher l'explication des zones favorables et fortement 
défavorables tout en conservant des effectifs suffisants pour l'analyse discriminante. 
 
2.3. Représentation des classes dans l'espace des mesures processus (Annexe 4). 
Le programme visu_classe_3D_mesures.sas effectue une représentation des classes 
de défaut dans l'espace des mesures physiques (pression, température, hygrométrie); 
cette représentation est facultative pour la méthode. 
Un symbole coloré est associé à chaque classe pour la représentation graphique : 
Bon Etoile verte 
Moyen Drapeau orange 
Mauvais Croix rouge 
L'objet de l'analyse canonique discriminante est de séparer au mieux ces classes de 
défaut. 
 42
2.4. Calcul des fonctions discriminantes (Annexes 5,6). 
Nous ne présenterons pas le principe du calcul, le lecteur se reportera à des ouvrages 
spécialisés [LEB MOR PIR 1995 p 255]. 
La procédure SAS CANDISC effectue une analyse discriminante canonique et 
recherche les q-1 composantes factorielles qui séparent au mieux les q classes. 
Le programme discrim_classe.sas effectue l'AD c'est-à-dire calcule les fonctions 
discriminantes et les stocke dans le tableau SAS permanent : BASE.FONCDISC : 
CAN1 = 0,1599 HYGR* + 0,8629  PRES* + 0,9527  TEMP* 
CAN2 = 0,1423 HYGR* + 0,1155  PRES* - 0,675 TEMP* 
où HYGR* désigne la variable HYGR centrée réduite. 
Le coefficient de corrélation canonique (cosinus entre le groupe de variables 
explicatives et la variable à discriminer) est ρ2= 0,58, sans être réellement mauvais, 
il reste relativement moyen et sous entend que le modèle peut donner des réponses 
inexactes (erreur d'affectation), que l'on peut quantifier sur le tableau de 
contingence : Ye * Y (affecté * réel). 
La première valeur propre 1.397 expliquant 99,6% de l'inertie souligne que la 
décision porte quasiment sur la seule première composante CAN1. 
La représentation graphique des 120 unités de l'échantillon d'apprentissage 
(programme visu_plan_disc.sas) permet d'imaginer la nature des erreurs 
d'affectation. 
Les observations « moyennes » sont situées entre les « bonnes »et les « mauvaises ». 
Très visiblement une unité sera bonne si CAN1 (i) < 0 et mauvais si CAN1(i)> 2. 
Les autres centres de gravité des classes sont repérés sur le plan par BON, MOYEN, 
MAUVAIS et serviront pour l'affectation des données supplémentaires; il sont 
stockés par le programme dans le tableau sas BASE.NIVEAUX. 
Il est assez rare que la décision d'affectation ne porte que sur la première 
composante, bien qu'elle extrait dans cet exemple 99,6% de l'information, c'est 
pourquoi nous avons tout de même bâti la procédure normale d'affectation fondée sur 
les deux composantes discriminantes, par souci de généralité. 
2.5. Lecture et affectation des observations supplémentaires (Annexe 7). 
Les fonctions discriminantes étant construites à partir de l'échantillon 
d'apprentissage, il faut maintenant utiliser la modélisation pour la prédiction. 
A cette fin le programme affect_classe_sas.sas : 
 43
• lit les données supplémentaires à classer X' (modulad.test) dont, en principe on ne 
dispose pas de la variable y'=def que l'on cherche précisémment à prévoir; 
• affecte aux classes connues a priori et dont les centres de gravité calculés sur les 
données d'apprentissage sont stockés dans le tableau sas BASE.NIVEAUX. 
Le programme utilise la PROC SCORE pour calculer les valeurs des fonctions 
discriminantes après centrage et réduction (BASE.FONCDISC contient les 
moyennes et variance des données d'apprentissage), et l'algorithme des Nuées 
Dynamiques [DIDAY et Coll 1979] pour effectuer le classement des observations 
supplémentaires (PROC FASTCLUS)à leur plus proche centre de gravité selon la 
distance Euclidienne usuelle. La variable CLUSTER contenue dans le tableau SAS 
BASE.NEWPOINT est la valeur Y'e.  
Il peut apparaître surprenant d'utiliser un algorithme de Nuées Dynamiques pour 
affecter les individus aux classes, mais le plan « factoriel discriminant » produit 
s'interprète de la même manière que le plan factoriel des individus que produirait une 
Analyse en Composantes Principales classique; dès lors un individu sera affecté à la 
classe dont le centre de gravité lui est le plus proche; informatiquement SAS propose 
dans ses procédures un algorithme programmé (FASTCLUS) dont on peut imposer 
les noyaux (SEED=BASE.NIVEAUX), il s'agit de l'utiliser une fois (MAXITER=1) 
pour être le plus efficace possible mais en interdisant le recalcul des noyaux à chaque 
affectation (REPLACE = NONE). 
NB : En appliquant la procédure affect_classe.sas aux données d'apprentissage X 
on obtient alors Ye que l'on peut comparer à Y (véritable classe) pour étudier les 
erreurs d'affectation. 
Le listing affect_classe.lst issu de la PROC PRINT montre le contenu de 
BASE.NEWPOINT, les unités 121-127 sont affectées à la classe 1 (bon), ce qui ne 
semble pas incohérent à l'égard de la variable def, de même pour les unités (128-135) 
affectées à la classe 3 (mauvais); on a donc une rupture multidimensionnelle de 
performance qualité entre les unités 127 et 128. Il faut maintenant présenter ces 
résultats d'une manière transparente pour l'utilisateur. 
2.6. Représentation des ruptures de performance Qualité (Annexes 8 et 9) 
Le programme carte_multi_discr.sas représente graphiquement les observations 
supplémentaires en fonction des variables discriminantes CAN1 et CAN2; une 
annotation SAS permet de représenter les premières unités de chaque niveau de 
performance ainsi que les ruptures multidimensionnelles (fig: ruptures). 
 44
Cette représentation multidimensionnelle présente l'avantage de pouvoir suivre la 
trajectoire des unités dans le plan discriminant ce qui peut être précieux pour mettre 
en évidence des dérives lentes de la performances du processus, en revanche cette 
représentation n'est pas très parlante pour des opérateurs en atelier. 
Il convient d'associer la carte de contrôle prédite de la performance qualité du 
processus (CLUSTER en fonction de N° d'unité) sur laquelle nous avons superposé 
la variable y=def (qui sont normalement inconnus). On remarque que les unités (132-
135) auraient dû être affectées à la classe 2 (moyenne) mais qu'aucun de ces points 
n'a été affecté à la classe 1 (bon). Ce résultat est largement favorable, le modèle 
ayant pour but de séparer au mieux les classes « bon » et « mauvais ». 
Le modèle discriminant est satisfaisant pour le contrôle qualité dans la mesure où il 
ne commet pas d'erreur d'affectation « grave », c'est-à-dire d'affecter des unités 
« mauvaises » à la classe « bonne » et vice -versa. 
3. Conclusion. 
Nous avons proposé un outil pour le contrôle qualité multidimensionnel permettant 
une analyse d'impact prévisionnel de la variabilité sur la performance qualité. Cet 
outil est très visuel, mais requiert un traitement informatique et ne saurait donc être 
appliqué qu'à des processus instrumentés en temps réel, pour lesquels on 
souhaiterait : 
• faire du pilotage industriel, 
• faire de la simulation et de l'optimisation linéaire (SIMPLEXE) pour « dérégler » 
volontairement le processus à partir des prévisions du modèle, afin de chercher 
des nominaux optimaux. 
Bibliographie : 
[CHAMBON 82] μ = σ2  Rapport Interne RENAULT 1982 
 [DIDAY et coll 79] Optimisation en classification automatique, INRIA 1979 
 [LEB MOR PIR 96] Statistique Exploratoire Multidimensionnelle  
Lebart Morineau Piron 1995 










