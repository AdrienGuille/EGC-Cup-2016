TUTORIEL
Lâ€™infeÂ´rence bayeÂ´sienne pour lâ€™analyse des
donneÂ´es expeÂ´rimentales
Bruno Lecoutre1
ERIS, Laboratoire de MatheÂ´matiques RaphaeÂ¨l Salem
UMR 6085 C.N.R.S. et UniversiteÂ´ de Rouen
Avenue de lâ€™UniversiteÂ´, BP 12, 76801 Saint-Etienne-du-Rouvray
bruno.lecoutre@univ-rouen.fr
Internet : http ://www.univ-rouen.fr/LMRS/Persopage/Lecoutre/Eris
ReÂ´sumeÂ´ Ce tutoriel se situe dans la ligne des articles preÂ´ceÂ´demment publieÂ´s dans
la Revue de Modulad : Lecoutre (1996b, 2005/1997, 2005) ; Lecoutre, Poitevineau
& Lecoutre (2005). Il sâ€™appuie sur lâ€™utilisation de programmes informatiques qui
ont eÂ´galement fait lâ€™objet dâ€™une preÂ´sentation dans un numeÂ´ro preÂ´ceÂ´dent (Lecoutre
& Poitevineau, 2005). La motivation de ce tutoriel est avant tout meÂ´thodologique,
et le choix du cadre bayeÂ´sien ne devrait pas paraË†Ä±tre ideÂ´ologique. Plus preÂ´ciseÂ´ment,
lâ€™objectif est dâ€™apporter aux questions essentielles souleveÂ´es par lâ€™analyse des donneÂ´es
expeÂ´rimentales des reÂ´ponses mieux adapteÂ´es que les tests de signification de lâ€™hy-
pothe`se nulle. BaseÂ´es sur des deÂ´finitions opeÂ´rationnelles plus utiles que les proceÂ´dures
traditionnelles (tests, intervalles de confiance), les meÂ´thodes bayeÂ´siennes offrent une
souplesse consideÂ´rable, en rendant tous les choix explicites. De plus, la philosophie
bayeÂ´sienne met en avant la neÂ´cessiteÂ´ de reÂ´fleÂ´chir sur lâ€™information fournie par les
donneÂ´es disponibles â€“ â€œquâ€™est-ce que les donneÂ´es ont a` dire ?â€ â€“ au lieu dâ€™appliquer
des proceÂ´dures rituelles.
Des proceÂ´dures bayeÂ´siennes de routine sont deÂ´sormais faciles a` mettre en Å“uvre pour
toutes les situations courantes. Leurs reÂ´sultats peuvent eË†tre preÂ´senteÂ´s sous une forme
intuitivement seÂ´duisante et facilement interpreÂ´table. Elles ouvrent une nouvelle voie
prometteuse dans la meÂ´thodologie statistique 1.
INTRODUCTION
La motivation meÂ´thodologique
â€œThe test provides neither the necessary nor the sufficient scope or type of
knowledge that basic scientific social research requires.â€ (Morrison & Henkel,
1969)
La motivation meÂ´thodologique reÂ´sulte de lâ€™examen de lâ€™eÂ´tat actuel de lâ€™utilisation
de lâ€™infeÂ´rence statistique dans la recherche expeÂ´rimentale. Celle-ci est confronteÂ´e a` une
situation paradoxale.
1Je remercie Jacques Poitevineau pour son aide dans la taË†che ingrate de relecture de ce texte. Jâ€™assume
lâ€™entie`re responsabiliteÂ´ des fautes et erreurs qui peuvent subsister.
cÂ© Revue MODULAD, 2006 -130- NumeÂ´ro 35
Les tests ne reÂ´pondent pas aux bonnes questions
Dâ€™une part, les tests de signification de lâ€™hypothe`se nulle (en anglais, Null Hypothesis
Significance Tests, â€œNHSTâ€) sont consideÂ´reÂ´s dans la plupart des publications scientifiques
comme une norme incontournable et apparaissent souvent comme une garantie de scienti-
ficiteÂ´. Mais, dâ€™autre part, ces tests conduisent a` dâ€™innombrables erreurs dâ€™interpreÂ´tations
et mauvais usages. Leur utilisation a dâ€™ailleurs eÂ´teÂ´ explicitement proscrite par les scienti-
fiques les plus eÂ´minents et les plus avertis, tant sur des arguments theÂ´oriques que sur de
consideÂ´rations meÂ´thodologiques.
Pour interpreÂ´ter leurs donneÂ´es, les utilisateurs doivent recourir a` une synthe`se â€œnaÂ¨Ä±veâ€
des reÂ´sultats des tests de signification avec dâ€™autres informations, dâ€™ou` un malaise qui va
grandissant. Pour reÂ´pondre a` ce malaise, un processus de deÂ´finition de nouvelles normes de
publication pour la recherche expeÂ´rimentale a eÂ´teÂ´ engageÂ´. Câ€™est pourquoi lâ€™eÂ´poque actuelle
est une charnie`re cruciale.
Vers de nouvelles normes de publications
Des changements dans la facÂ¸on de rapporter les reÂ´sultats expeÂ´rimentaux sont de fait
de plus en plus exigeÂ´s par les revues expeÂ´rimentales ceci dans tous les domaines. Ces
changements concernent tout particulie`rement la preÂ´sentation et lâ€™interpreÂ´tation de la
grandeur des effets (les â€œeffect sizesâ€). Il sâ€™agit de fournir des indicateurs de ces effets
ainsi que leurs estimations par intervalle (â€œinterval estimatesâ€), en plus ou a` la place des
tests.
En Psychologie par exemple, cette neÂ´cessiteÂ´ de changements a eÂ´teÂ´ rendue officielle par
lâ€™American Psychological Association (APA, 2001). Les recommandations faites a` cette oc-
casion (voir Wilkinson et al., 1999) sont reÂ´veÂ´latrices de ce que pourrait eË†tre lâ€™eÂ´volution des
pratiques. Mais, si on les examine en deÂ´tail, elles apparaissent en fait a` la fois partiellement
redondantes et conceptuellement incoheÂ´rentes. Ces recommandations ne peuvent en effet
quâ€™aboutir a` perpeÂ´tuer des recettes et des rituels â€“ calcul de puissance pour deÂ´terminer les
effectifs, utilisation des â€œp-valuesâ€ (on nâ€™abandonne pas les tests), intervalles de confiance
(en plus des tests) â€“ qui seraient combineÂ´s sans fournir une reÂ´elle penseÂ´e statistique. On
peut craindre dans ces conditions que les utilisateurs de la statistique continuent a` se
focaliser sur la signification statistique du reÂ´sultat â€“ notamment en se demandant seule-
ment si lâ€™intervalle de confiance contient la valeur de lâ€™hypothe`se nulle â€“ sans consideÂ´rer
reÂ´ellement lâ€™information suppleÂ´mentaire apporteÂ´e par cet intervalle.
â€œConsequently we automatically ask ourselves â€œwonâ€™t the Bayesian choice be
unavoidable ?â€ (Lecoutre et al., 2001)
Dans ces conditions, on ne peut que remettre en question le cadre conceptuel des
proceÂ´dures dâ€™infeÂ´rence traditionnelles â€“ câ€™est-a`-dire lâ€™approche freÂ´quentiste â€“ et nous de-
mander si lâ€™approche bayeÂ´sienne ne sera pas toË†t ou tard incontournable.
Plan de lâ€™exposeÂ´
La preÂ´sentation est organiseÂ´e en quatre parties.
Partie I - Les aspects conceptuels : InfeÂ´rence freÂ´quentiste ou bayeÂ´sienne ? La
premie`re partie de ce tutoriel traitera des aspects conceptuels de base concernant les
cÂ© Revue MODULAD, 2006 -131- NumeÂ´ro 35
diffeÂ´rences entre les approches freÂ´quentistes et bayeÂ´siennes. Je conclurai que pour lâ€™ana-
lyse des donneÂ´es expeÂ´rimentales une approche bayeÂ´sienne â€œobjectiveâ€ est a` la fois deÂ´sirable
et faisable. Dans ce cadre, je nâ€™envisagerai donc quâ€™avec beaucoup de reÂ´serves une ap-
proche â€œsubjectivisteâ€ ; jâ€™eÂ´carterai eÂ´galement une conception prioritairement deÂ´cisionnelle
de lâ€™infeÂ´rence statistique.
Partie II - La pratique : Quelques situations de base. Lâ€™objectif de la seconde
partie sera de deÂ´montrer la faisabiliteÂ´ des meÂ´thodes bayeÂ´siennes, a` partir dâ€™un certain
nombre de situations de base. La preÂ´sentation sera essentiellement illustrative, et le moins
possible technique. Il sâ€™agira dâ€™introduire des proceÂ´dures de routine a` partir de proble`mes
relativement simples dâ€™infeÂ´rence sur des proportions et des moyennes. On traitera a` la
fois la mise en Å“uvre pratique de ces proceÂ´dures â€“ a` lâ€™aide de programmes informatiques
â€“ et leurs apports conceptuels et meÂ´thodologiques, tant pour lâ€™analyse de donneÂ´es que
pour la planification et la conduite des expeÂ´riences. Dans chaque situation, les solutions
bayeÂ´siennnes seront mises en paralle`le avec les proceÂ´dures freÂ´quentistes.
Je deÂ´velopperai plus particulie`rement lâ€™infeÂ´rence sur des proportions. Les proble`mes de
comparaisons de moyennes â€“ qui se preÂ´sentent traditionnellement en analyse de variance
â€“ ont en effet eÂ´teÂ´ largement traiteÂ´s par ailleurs â€“ notamment dans le cadre de ce que
nous appelons lâ€™Analyse BayeÂ´sienne des Comparaisons â€“ et on pourra notamment se
rapporter pour compleÂ´ter le preÂ´sent exposeÂ´ aux reÂ´feÂ´rences suivantes : Lecoutre (1984,
1996a) ; Lecoutre et Poitevineau (2005) ; Lecoutre (2006).
Partie III - Les aspects techniques : Quelques outils de base. La troisie`me partie
sera technique. Il sâ€™agira dâ€™abord dâ€™illustrer les principes des calculs formels neÂ´cessaires a`
lâ€™infeÂ´rence bayeÂ´sienne et de fournir quelques outils utiles pour ces calculs. On abordera
eÂ´galement brie`vement des techniques de base dâ€™inteÂ´gration numeÂ´rique â€“ deÂ´terministe ou
par simulation. Ces dernie`res techniques reveË†tent une importance de plus en plus grande
dans lâ€™infeÂ´rence bayeÂ´sienne (meË†me si elles ne sont pas limiteÂ´es a` celle-ci) ; elles permettent
en effet de reÂ´soudre relativement facilement les proble`mes pratiques de calcul lieÂ´s aux
situations les plus complexes. Une preÂ´sentation plus approfondie deÂ´borderait le cadre du
preÂ´sent exposeÂ´ et serait plutoË†t lâ€™objet dâ€™un autre tutoriel.
Partie IV - Retour sur les aspects conceptuels : Lâ€™interface de lâ€™infeÂ´rence
freÂ´quentiste et de lâ€™infeÂ´rence bayeÂ´sienne. La quatrie`me partie sâ€™adressera a` ceux
qui souhaitent approfondir les liens conceptuels et techniques entre les deux approches,
qui auront eÂ´teÂ´ mis en avant dans les diffeÂ´rents exemples dâ€™application.
En conclusion. Je reviendrai brie`vement sur les avantages de lâ€™approche bayeÂ´sienne et
aborderai quelques the`mes â€œpour aller plus loinâ€ et preÂ´parer a` dâ€™autres lectures.
PARTIE I - LES ASPECTS
CONCEPTUELS :
INFEÂ´RENCE FREÂ´QUENTISTE OU
BAYEÂ´SIENNE?
cÂ© Revue MODULAD, 2006 -132- NumeÂ´ro 35
1 La probabiliteÂ´ et lâ€™infeÂ´rence statistique
De nos jours la probabiliteÂ´ a au moins deux deÂ´finitions principales (deÂ´ja` preÂ´sentes chez
Bernoulli, 1713).
1. La probabiliteÂ´ est la freÂ´quence sur le long terme de lâ€™occurrence dâ€™un
eÂ´veÂ´nement, soit dans une suite dâ€™essais reÂ´peÂ´teÂ´s, soit dans un ensemble de
syste`mes â€œidentiquementâ€ preÂ´pareÂ´s 2.
Câ€™est la conception freÂ´quentiste, qui semble faire de la probabiliteÂ´ une proprieÂ´teÂ´ observable
(â€œobjectiveâ€), existant dans la nature indeÂ´pendamment de nous.
2. La probabiliteÂ´ est une mesure du degreÂ´ de croyance (ou de confiance) dans
lâ€™occurrence dâ€™un eÂ´veÂ´nement ou dans la veÂ´raciteÂ´ dâ€™une proposition.
Câ€™est la conception bayeÂ´sienne. Il nâ€™est souvent pas eÂ´vident dâ€™attribuer une probabiliteÂ´
freÂ´quentiste a` un eÂ´veÂ´nement unique, puisque cela neÂ´cessite dâ€™imaginer un ensemble de
reÂ´feÂ´rence dâ€™eÂ´veÂ´nements ou une seÂ´rie dâ€™expeÂ´riences reÂ´peÂ´teÂ´es afin dâ€™obtenir des freÂ´quences
empiriques. Malheureusement, de tels ensembles sont rarement disponibles pour lâ€™attribu-
tion des probabiliteÂ´s dans les proble`mes reÂ´els. Par contraste la deÂ´finition bayeÂ´sienne est
plus geÂ´neÂ´rale : il nâ€™est pas conceptuellement probleÂ´matique dâ€™attribuer une probabiliteÂ´ a`
un eÂ´veÂ´nement unique.
Les probabiliteÂ´s bayeÂ´siennes sont consideÂ´reÂ´es par certains comme le reÂ´sultat dâ€™une
appreÂ´ciation subjective dâ€™une situation par un observateur (Savage, 1954 ; de Finetti,
1974). Mais elle peuvent tout aussi bien servir a` deÂ´crire une connaissance objective, en
particulier baseÂ´e sur des arguments de symeÂ´trie ou sur des freÂ´quences.
On remarquera que la deÂ´finition bayeÂ´sienne est en accord avec le sens du mot proba-
biliteÂ´ dans le langage de tous les jours : la conception bayeÂ´sienne apparaË†Ä±t donc beaucoup
plus proche de la facÂ¸on dont les gens raisonnent intuitivement en preÂ´sence dâ€™incertitude
3.
1.1 Les termes du deÂ´bat
â€œ[. . .] whether the probabilities should only refer to data and be based on
frequency or whether they should also apply to hypotheses and be regarded
as measures of beliefs.â€ (Lindley, 1993)
2Dans une deÂ´finition plus preÂ´cise, la probabiliteÂ´ est la valeur limite de la freÂ´quence dans une suite
infinie dâ€™essais, mais câ€™est ici un point mineur.
3Pour ne prendre quâ€™un exemple, comment interpreÂ´tez-vous lâ€™indice de confiance (par exemple
4/5) figurant dans les bulletins meÂ´teÂ´orologiques fournis par meÂ´teÂ´o France ? Tous ceux que jâ€™ai
interrogeÂ´s lâ€™interpre`tent comme une probabiliteÂ´ bayeÂ´sienne : â€œil y a 4 chances sur 5 que la
preÂ´vision se reÂ´aliseâ€, alors que cet indice nâ€™est pas du tout deÂ´fini comme une telle probabi-
liteÂ´ : voir http ://www.meteofrance.com/FR/glossaire/designation/1036 curieux view.jsp. On no-
tera que cette deÂ´finition est reÂ´serveÂ´e aux â€œcurieuxâ€, ce qui favorise plus ou moins volontai-
rement lâ€™interpreÂ´tation bayeÂ´sienne. Il est inteÂ´ressant a` ce propos de constater que le service
meÂ´teÂ´orologique dâ€™Environnement Canada donne au contraire explicitement une deÂ´finition bayeÂ´sienne
de la â€œprobabiliteÂ´ de preÂ´cipitationsâ€, deÂ´finie comme â€œune estimation numeÂ´rique subjective des
risques de preÂ´cipitations mesurables a` tout point du secteur viseÂ´. Par exemple, si la probabi-
liteÂ´ de pluie est de 40 p.100 pour aujourdâ€™hui, il existe quatre chances sur 10 pour quâ€™il pleu-
veâ€ (http ://www.smc.ec.gc.ca/cd/brochures/probability f.cfm). Cela nâ€™implique eÂ´videmment pas que
cette estimation soit moins objective que lâ€™indice de meÂ´teÂ´o France.
cÂ© Revue MODULAD, 2006 -133- NumeÂ´ro 35
Lâ€™infeÂ´rence statistique fait typiquement intervenir a` la fois des quantiteÂ´s connues â€“
les donneÂ´es observeÂ´es â€“ et des quantiteÂ´s inconnues â€“ les parame`tres et les donneÂ´es qui
nâ€™ont pas eÂ´teÂ´ observeÂ´es. Le deÂ´bat se pose alors en ces termes : â€œest-ce que les probabiliteÂ´s
devraient seulement eË†tre relatives aux donneÂ´es et eË†tre baseÂ´es sur des freÂ´quences ou est-ce
quâ€™elles doivent aussi dâ€™appliquer aux parame`tres et eË†tre consideÂ´reÂ´es comme des mesures
de croyance ?â€.
1.1.1 Lâ€™infeÂ´rence freÂ´quentiste
Dans lâ€™infeÂ´rence freÂ´quentiste toutes les probabiliteÂ´s sont conditionnelles aux parame`tres
qui sont supposeÂ´s connus. Cela conduit en particulier :
â€¢ aux tests de signification, dans lesquels la valeur dâ€™au moins un parame`tre est fixeÂ´e par
hypothe`se ;
â€¢ aux intervalles de confiance.
Mais les parame`tres ne peuvent pas et ne doivent pas eË†tre probabiliseÂ´s (des freÂ´quences
empiriques ne sont pas disponibles)
1.1.2 Lâ€™infeÂ´rence bayeÂ´sienne
Dans lâ€™infeÂ´rence bayeÂ´sienne au contraire, les parame`tres peuvent aussi eË†tre probabi-
liseÂ´s. Il en reÂ´sulte des distributions de probabiliteÂ´ qui expriment notre incertitude :
â€¢ avant les observations (elle ne deÂ´pendent pas des donneÂ´es) : ce sont les probabiliteÂ´s
initiales ou (a priori) ;
â€¢ apre`s les observations (conditionnelles aux donneÂ´es) : ce sont les probabiliteÂ´s reÂ´viseÂ´es,
finales ou a posteriori ;
â€¢ relatives a` des donneÂ´es futures : ce sont les probabiliteÂ´s preÂ´dictives (avant ou apre`s les
observations).
Remarque sur la terminologie. Les appellations initiales et finales seront
preÂ´feÂ´reÂ´es ici a` a priori et a posteriori qui renvoient davantage a` une conception
â€œsubjectiveâ€. De meË†me lâ€™appellation distribution (de probabiliteÂ´) sera preÂ´feÂ´reÂ´e
a` loi qui eÂ´voque une conception particulie`re du hasard et de la probabiliteÂ´.
2 Une illustration simple
Comme illustration simple, consideÂ´rons la situation suivante. On suppose une po-
pulation finie dâ€™effectif N = 20 avec une variable dichotomique â€œsucce`s/eÂ´checâ€ et une
proportion Ï• de succe`s qui est le parame`tre inconnu. Un eÂ´chantillon de n = 5 observa-
tions â€“ dont on supposera quâ€™il a eÂ´teÂ´ tireÂ´ au sort sans remise â€“ a eÂ´teÂ´ observeÂ´, dâ€™ou` les
donneÂ´es connues :
0 0 0 1 0 n = 5 f = 1
5
Le raisonnement inductif est fondamentalement une geÂ´neÂ´ralisation dâ€™une quantiteÂ´
connue â€“ les donneÂ´es â€“ a` une quantiteÂ´ inconnue â€“ ici le parame`tre Ï•.
cÂ© Revue MODULAD, 2006 -134- NumeÂ´ro 35
2.1 Solution freÂ´quentiste
Dans le cadre freÂ´quentiste nous nâ€™avons pas de probabiliteÂ´s, et par conseÂ´quent pas
dâ€™infeÂ´rence inductive possible.
De lâ€™inconnu vers le connu
Aussi lâ€™infeÂ´rence freÂ´quentiste doit retourner la situation. Mais nous nâ€™avons pas davan-
tage de probabiliteÂ´s. . . a` moins que nous ne fixions une valeur du parame`tre. Supposons
par exemple Ï• = 15/20 = 0.75. Nous obtenons alors des probabiliteÂ´s dâ€™eÂ´chantillonnage,
qui peuvent eË†tre deÂ´finies comme des freÂ´quences mettant en jeu un tre`s grand nombre de
reÂ´peÂ´titions imaginaires des observations. Nous pouvons obtenir ces freÂ´quences en simulant
un grand nombre de tirages sans remise de 5 boules dans une urne contenant 20 boules,
dont 15 dâ€™une couleur et 5 dâ€™une autre couleur. Mais il nâ€™est pas neÂ´cessaire de recourir a`
une deÂ´finition freÂ´quentiste pour obtenir les probabiliteÂ´s dâ€™eÂ´chantillonnage.
Ici il y a 15 504 eÂ´chantillons diffeÂ´rents possibles (dont un particulier a eÂ´teÂ´ observeÂ´)
et les probabiliteÂ´s dâ€™eÂ´chantillonnage sont donneÂ´es par une distribution HypergeÂ´omeÂ´trique.
Le tableau ci-apre`s donne ces probabiliteÂ´s, ainsi que les freÂ´quences obtenues par deux
simulations, lâ€™une de 10 000 tirages et lâ€™autre de 1 000 000 de tirages.
Ï• = 15/20 = 0.75
Nombre de Nombres ProbabiliteÂ´s FreÂ´quences
succe`s dâ€™eÂ´chantillons dâ€™eÂ´chantillonnage 104 tirages 106 tirages
f = 0/5 1/15 504 = 0.00006 0 0.00006
f = 1/5 75/15 504 = 0.0048 0.0054 0.0049
f = 2/5 1 050/15 504 = 0.0677 0.066 0.068
f = 3/5 4 550/15 504 = 0.2935 0.294 0.293
f = 4/5 6 825/15 504 = 0.4402 0.447 0.441
f = 5/5 3 003/15 504 = 0.1937 0.187 0.194
2.1.1 Test de signification
Ces probabiliteÂ´s dâ€™eÂ´chantillonnage sont utiliseÂ´es pour deÂ´finir un test de significa-
tion. La valeur du parame`tre est fixeÂ´e par lâ€™hypothe`se nulle, par exemple H0 : Ï• =
0.75. Si Ï• = 0.75, on trouve dans seulement 0.49% des reÂ´peÂ´titions (soit la proportion
0.0049=0.00006+0.0049) une valeur infeÂ´rieure ou eÂ´gale a` lâ€™observation (f â‰¤ 1/5). Le
reÂ´sultat est dit â€œsignificatifâ€ (p = 0.0049) : sur la base des donneÂ´es observeÂ´es, lâ€™hypothe`se
nulle est rejeteÂ´e (je nâ€™entre pas ici dans la discussion â€œtest unilateÂ´ral/bilateÂ´ralâ€, ni dans
le choix du â€œrisqueâ€ Î± qui ne sont pas pertinents pour mon propos).
â€œA hypothesis that may be true may be rejected because it has not predicted
observable results that have not occurred.â€ (Jeffreys, 1961)
Mais, comme le soulignait ironiquement Jeffreys, cette conclusion est baseÂ´e sur la proba-
biliteÂ´ des eÂ´chantillons qui nâ€™ont pas eÂ´teÂ´ observeÂ´s.
ConsideÂ´rons un autre exemple dâ€™hypothe`se nulle, H0 : Ï• = 0.50.
cÂ© Revue MODULAD, 2006 -135- NumeÂ´ro 35
Ï• = 10/20 = 0.50
Nombre de Nombres ProbabiliteÂ´s
succe`s dâ€™eÂ´chantillons dâ€™eÂ´chantillonnage
f = 0/5 252/15 504 = 0.016
f = 1/5 2 100/15 504 = 0.135
f = 2/5 5 400/15 504 = 0.348
f = 3/5 5 400/15 504 = 0.348
f = 4/5 2 100/15 504 = 0.135
f = 5/5 252/15 504 = 0.016
Dans ce cas, si Ï• = 0.50, on trouve dans 15.2% des reÂ´peÂ´titions (soit la proportion 0.0152
= 0.016+0.135) une valeur infeÂ´rieure ou eÂ´gale a` lâ€™observation (f â‰¤ 1/5). Le reÂ´sultat est
dit â€œnon significatifâ€ (p = 0.152) : sur la base des donneÂ´es observeÂ´es, lâ€™hypothe`se nulle
nâ€™est pas rejeteÂ´e A lâ€™eÂ´vidence cela ne prouve pas que Ï• = 0.50 !
2.1.2 Intervalle de confiance
Un intervalle de confiance peut eË†tre construit comme lâ€™ensemble des valeurs possibles
du parame`tre qui ne sont pas rejeteÂ´es par les donneÂ´es a` un seuil Î± fixeÂ´. Par exemple, pour
Î± = 0.05, nous obtenons ici lâ€™intervalle de confiance 95% :
[0.05, 0.60]
Comment interpreÂ´ter la confiance ? Lâ€™interpreÂ´tation est baseÂ´e sur lâ€™eÂ´nonceÂ´ universel :
â€œQuelle que soit la valeur fixeÂ´e du parame`tre, dans 95% (au moins) des reÂ´peÂ´titions
lâ€™intervalle qui serait calculeÂ´ contiendrait cette valeur.â€
Cette proprieÂ´teÂ´ peut eË†tre veÂ´rifieÂ´e par exemple pour Ï• = 0.50 :
ReÂ´peÂ´titions imaginaires des observations
Valeur Intervalle ProbabiliteÂ´
observeÂ´e de confiance dâ€™eÂ´chantillonnage
f = 0 (0/5) [0 , 0.45] 0.016
f = 0.20 (1/5) [0.05 , 0.60] 0.135âˆ—
f = 0.40 (2/5) [0.10 , 0.75] 0.348âˆ—
f = 0.60 (3/5) [0,15 , 0.90] 0.348âˆ—
f = 0.80 (4/5) [0,20 , 0.95] 0.135âˆ—
f = 1 (5/5) [0.25 , 1 ] 0.016âˆ—
âˆ—contient Ï• = 0.50
Ici dans 98.4% des reÂ´peÂ´tions lâ€™intervalle contient la valeur fixeÂ´e Ï• = 0.50.
Mais cette interpreÂ´tation est pour le moins eÂ´trange puisquâ€™elle ne fait pas intervenir
les donneÂ´es observeÂ´es !
2.2 Solution bayeÂ´sienne
Du connu vers lâ€™inconnu
cÂ© Revue MODULAD, 2006 -136- NumeÂ´ro 35
Revenons au raisonnement inductif, en partant des donneÂ´es connues, et en adoptant le
point de vue bayeÂ´sien. Nous pouvons utiliser, en plus des probabiliteÂ´s dâ€™eÂ´chantillonnage,
des probabiliteÂ´s qui expriment notre incertitude sur toutes les valeurs possibles du pa-
rame`tre.
Dans lâ€™infeÂ´rence bayeÂ´sienne, nous consideÂ´rons les probabiliteÂ´s freÂ´quentistes â€“ non pas
dâ€™eÂ´chantillons imaginaires â€“ mais des donneÂ´es observeÂ´es, ceci pour toutes les valeurs
possibles du parame`tre. Câ€™est la fonction de vraisemblance Pr(f = 1/5 |Ï•), que lâ€™on
notera encore v(Ï• | donneÂ´es).
Pr(f = 1/5 |Ï•) = v(Ï• | donneÂ´es)
â†ªâ†’ Fonction de vraisemblance
Ï• = 0/20 â†’ 0 Ï• = 10/20 â†’ 0.135
Ï• = 1/20 â†’ 0.250 Ï• = 11/20 â†’ 0.089
Ï• = 2/20 â†’ 0.395 Ï• = 12/20 â†’ 0.054
Ï• = 3/20 â†’ 0.461 Ï• = 13/20 â†’ 0.029
Ï• = 4/20 â†’ 0.470 Ï• = 14/20 â†’ 0.014
Ï• = 5/20 â†’ 0.440 Ï• = 15/20 â†’ 0.005
Ï• = 6/20 â†’ 0.387 Ï• = 16/20 â†’ 0.001
Ï• = 7/20 â†’ 0.323 Ï• = 17/20 â†’ 0
Ï• = 8/20 â†’ 0.255 Ï• = 18/20 â†’ 0
Ï• = 9/20 â†’ 0.192 Ï• = 19/20 â†’ 0
Ï• = 20/20 â†’ 0
2.2.1 ProbabiliteÂ´s initiales
Nous choisissons des probabiliteÂ´s initiales avant les observations, par exemple
Pr(Ï•)
â†ªâ†’ ProbabiliteÂ´s initiales (avant les observations)
Pr(Ï• = 0/20) = 0.00000001 Pr(Ï• = 10/20) = 0.117
Pr(Ï• = 1/20) = 0.0000003 Pr(Ï• = 11/20) = 0.160
Pr(Ï• = 2/20) = 0.000005 Pr(Ï• = 12/20) = 0.180
Pr(Ï• = 3/20) = 0.00004 Pr(Ï• = 13/20) = 0.166
Pr(Ï• = 4/20) = 0.0003 Pr(Ï• = 14/20) = 0.124
Pr(Ï• = 5/20) = 0.001 Pr(Ï• = 15/20) = 0.075
Pr(Ï• = 6/20) = 0.005 Pr(Ï• = 16/20) = 0.035
Pr(Ï• = 7/20) = 0.015 Pr(Ï• = 17/20) = 0.012
Pr(Ï• = 8/20) = 0.035 Pr(Ï• = 18/20) = 0.003
Pr(Ï• = 9/20) = 0.071 Pr(Ï• = 19/20) = 0.0005
Pr(Ï• = 20/20) = 0.00004
2.2.2 ProbabiliteÂ´s conjointes
Par un simple produit de la vraisemblance et des probabiliteÂ´s initiales, nous obtenons
les probabiliteÂ´s conjointes des valeurs du parame`tre et des donneÂ´es
cÂ© Revue MODULAD, 2006 -137- NumeÂ´ro 35
Pr(Ï• et f = 1/5) = Pr(f = 1/5 |Ï•)Ã— Pr(Ï•)
Produit : vraisemblance Ã— probabiliteÂ´s initiales
â†ªâ†’ ProbabiliteÂ´s conjointes
Pr(Ï• = 0/20 et f = 1/5) = 0 Pr(Ï• = 10/20 et f = 1/5) = 0.016
Pr(Ï• = 1/20 et f = 1/5) = 0.00000008 Pr(Ï• = 11/20 et f = 1/5) = 0.014
Pr(Ï• = 2/20 et f = 1/5) = 0.000005 Pr(Ï• = 12/20 et f = 1/5) = 0.010
Pr(Ï• = 3/20 et f = 1/5) = 0.00002 Pr(Ï• = 13/20 et f = 1/5) = 0.005
Pr(Ï• = 4/20 et f = 1/5) = 0.0001 Pr(Ï• = 14/20 et f = 1/5) = 0.002
Pr(Ï• = 5/20 et f = 1/5) = 0.0004 Pr(Ï• = 15/20 et f = 1/5) = 0.0004
Pr(Ï• = 6/20 et f = 1/5) = 0.002 Pr(Ï• = 16/20 et f = 1/5) = 0.00003
Pr(Ï• = 7/20 et f = 1/5) = 0.005 Pr(Ï• = 17/20 et f = 1/5) = 0
Pr(Ï• = 8/20 et f = 1/5) = 0.009 Pr(Ï• = 18/20 et f = 1/5) = 0
Pr(Ï• = 9/20 et f = 1/5) = 0.014 Pr(Ï• = 19/20 et f = 1/5) = 0
Pr(Ï• = 20/20 et f = 1/5) = 0
2.2.3 ProbabiliteÂ´s preÂ´dictives
La somme des probabiliteÂ´s conjointes donne la probabiliteÂ´ preÂ´dictive marginale des
donneÂ´es, avant les observations
Pr(f = 1/5) =
âˆ‘
Ï• Pr(Ï• et f = 1/5) = 0.078
Somme des probabiliteÂ´s conjointes
â†ªâ†’ ProbabiliteÂ´ preÂ´dictive
Ce reÂ´sultat est tre`s intuitif puisque la probabiliteÂ´ preÂ´dictive est une moyenne pondeÂ´reÂ´e de
la fonction de vraisemblance, les poids eÂ´tant les probabiliteÂ´s initiales.
2.2.4 ProbabiliteÂ´s finales
â€œBayesian statistics is difficult in the sense that thinking is difficult.â€ (Berry,
1997)
Enfin nous calculons les probabiliteÂ´s finales apre`s les observations, par une simple
application de la deÂ´finition des probabiliteÂ´s conditionnelles
Pr(Ï• | f = 1/5) = Pr(Ï• et f=1/5)
Pr(f=1/5)
Rapport : probabiliteÂ´ conjointe / probabiliteÂ´ preÂ´dictive
â†ªâ†’ ProbabiliteÂ´s finales (apre`s les observations)
Pr(Ï• = 0 | f = 1/5) = 0 Pr(Ï• = 0.50 | f = 1/5) = 0.205
Pr(Ï• = 0.05 | f = 1/5) = 0.000001 Pr(Ï• = 0.55 | f = 1/5) = 0.180
Pr(Ï• = 0.10 | f = 1/5) = 0.0006 Pr(Ï• = 0.60 | f = 1/5) = 0.128
Pr(Ï• = 0.15 | f = 1/5) = 0.0003 Pr(Ï• = 0.65 | f = 1/5) = 0.064
Pr(Ï• = 0.20 | f = 1/5) = 0.001 Pr(Ï• = 0.70 | f = 1/5) = 0.026
Pr(Ï• = 0.25 | f = 1/5) = 0.005 Pr(Ï• = 0.75 | f = 1/5) = 0.005
Pr(Ï• = 0.30 | f = 1/5) = 0.026 Pr(Ï• = 0.80 | f = 1/5) = 0.0004
Pr(Ï• = 0.35 | f = 1/5) = 0.064 Pr(Ï• = 0.85 | f = 1/5) = 0
Pr(Ï• = 0.40 | f = 1/5) = 0.115 Pr(Ï• = 0.90 | f = 1/5) = 0
Pr(Ï• = 0.45 | f = 1/5) = 0.179 Pr(Ï• = 0.95 | f = 1/5) = 0
Pr(Ï• = 1 | f = 1/5) = 0
cÂ© Revue MODULAD, 2006 -138- NumeÂ´ro 35
Les probabiliteÂ´s finales sont donc simplement proportionnelles au produit des proba-
biliteÂ´s initiales et de la vraisemblance :
Pr(Ï• | donneÂ´es) âˆ v(Ï• | donneÂ´es)Ã— Pr(Ï•)
Leur somme devant eË†tre eÂ´gale a` 1 (par deÂ´finition de la probabiliteÂ´), ce produit est â€œnor-
maliseÂ´â€ en divisant par la somme :
Pr(donneÂ´es) =
âˆ‘
Ï•
v(Ï• | donneÂ´es)Ã— Pr(Ï•)
Dans le cas continu, les probabiliteÂ´s discre`tes sont remplaceÂ´es par des densiteÂ´s, par
exemple si Ï• peut prendre toutes les valeurs reÂ´elles dans lâ€™intervalle [0,1] :
p(Ï• | donneÂ´es) âˆ v(Ï• | donneÂ´es)Ã— p(Ï•)
et la somme par une inteÂ´grale :
p(donneÂ´es) =
âˆ« 1
0
v(Ï• | donneÂ´es)Ã— p(Ï•) dÏ•
Ceci se geÂ´neÂ´ralise directement au cas de plusieurs parame`tres.
3 Nouvelles difficulteÂ´s avec les intervalles de confiance
Comme reÂ´sultat dâ€™un processus deÂ´ja` bien engageÂ´, les intervalles de confiance pour-
raient rapidement devenir une norme obligatoire dans les publications expeÂ´rimentales. En
pratique, deux probabiliteÂ´s peuvent eË†tre associeÂ´es de manie`re routinie`re a` un intervalle
dâ€™estimation pour un parame`tre calculeÂ´ a` partir des donneÂ´es observeÂ´es.
â€¢ La premie`re probabiliteÂ´ est â€œla proportion des intervalles qui contiennent le parame`tre
pour un grand nombre de reÂ´peÂ´titionsâ€ ; elle est usuellement appeleÂ´e la probabiliteÂ´ de
couverture (ou de recouvrement) freÂ´quentiste.
â€¢ La seconde probabiliteÂ´ est la â€œprobabiliteÂ´ bayeÂ´sienne que cet intervalle contienne le
parame`treâ€ (pour une certaine distribution initiale).
Dans lâ€™approche freÂ´quentiste, il est interdit dâ€™utiliser la seconde probabiliteÂ´, tandis
que dans lâ€™approche bayeÂ´sienne, les deux probabiliteÂ´s sont valides.
Pour de nombreuses raisons dues a` leur conception freÂ´quentiste, les intervalles de
confiance peuvent difficilement apparaË†Ä±tre comme â€œLA meÂ´thode ultimeâ€. En effet la raison
qui les rend attrayants reÂ´sulte dâ€™une incompreÂ´hension fondamentale. Il est si eÂ´trange
de traiter les donneÂ´es comme aleÂ´atoires meË†me apre`s avoir recueilli les observations que
lâ€™interpreÂ´tation freÂ´quentiste orthodoxe des intervalles de confiance nâ€™a pas de sens pour la
plupart des utilisateurs. Câ€™est indiscutablement lâ€™interpreÂ´tation bayeÂ´sienne (naturelle) des
intervalles de confiance qui les rend attrayants. Ironiquement cette interpreÂ´tation heÂ´reÂ´tique
est encourageÂ´e par la dupliciteÂ´ de la plupart des formateurs en statistique qui les tole`rent
et meË†me les utilisent. Par exemple, Pagano (1990, page 288), dans un ouvrage dont le
titre affiche lâ€™objectif de faire comprendre la statistique (â€œunderstanding statistics. . .â€),
deÂ´crit un intervalle de confiance 95% comme un intervalle â€œsuch that the probability is
0.95 that the interval contains the population valueâ€.
Sous une autre forme, on voit tre`s couramment des interpreÂ´tations telles que â€œavec 5%
de risque de se tromper, on peut dire que pi est dans lâ€™intervalle [0.27,0.42]â€.
cÂ© Revue MODULAD, 2006 -139- NumeÂ´ro 35
Dâ€™autre auteurs affirment que lâ€™interpreÂ´tation freÂ´quentiste â€œcorrecteâ€ quâ€™ils deÂ´fendent
peut eË†tre exprimeÂ´e comme â€œnous pouvons eË†tre confiants a` 95% que le parame`tre est
contenu dans lâ€™intervalleâ€ ; par exemple Kirk (1982, page 43) eÂ´nonce â€œwe can be 95%
confident that the population mean is between 114.06 and 119.94â€.
Il est difficile dâ€™imaginer que les lecteurs puissent comprendre que â€œconfiantâ€ renvoie a`
une conception freÂ´quentiste de la probabiliteÂ´ !
â€œWe [statisticians] will all be Bayesians in 2020, and then we can be a united
profession.â€ Lindley (in Smith, 1995, page 317))
La litteÂ´rature est remplie dâ€™interpreÂ´tations bayeÂ´siennes des intervalles de confiance et
des tests de signification. Toutes les tentatives des freÂ´quentistes pour corriger ces â€œerre-
mentsâ€ se sont reÂ´veÂ´leÂ´es vaines : câ€™est un combat perdu dâ€™avance. En fait la plupart utili-
sateurs de lâ€™infeÂ´rence statistique sont des bayeÂ´siens sans le savoir (Lecoutre, 1997/2005) !
4 Lâ€™approche bayeÂ´sienne â€œobjectiveâ€
4.1 Ou` est lâ€™objectiviteÂ´ ?
â€œA common misconception is that Bayesian analysis is a subjective theory ;
this is neither true historically nor in practice. The first Bayesians, Bayes (see
Bayes (1763)) and Laplace (see Laplace (1812)) performed Bayesian analysis
using a constant prior distribution for unknown parameters. . .â€ (Berger, 2004,
page 3)
Lâ€™infeÂ´rence statistique freÂ´quentiste sâ€™auto-proclame â€œobjectiveâ€ contrairement a` lâ€™infeÂ´rence
bayeÂ´sienne qui serait neÂ´cessairement â€œsubjectiveâ€. Cette affirmation se trouve renforceÂ´e
par certaines conceptions bayeÂ´siennes extreÂ´mistes, dans lesquelles les opinions â€“ et non
seulement les connaissances a priori â€“ pourraient (devraient) eË†tre inteÂ´greÂ´es dans lâ€™infeÂ´rence
scientifique. Il nâ€™est donc pas eÂ´tonnant que la critique la plus commune adresseÂ´e par
les freÂ´quentistes a` lâ€™approche bayeÂ´sienne soit la neÂ´cessiteÂ´ de probabiliteÂ´s initiales. Il est
eÂ´videmment facile, dans lâ€™exemple preÂ´ceÂ´dent, de choisir des probabiliteÂ´s initiales quel-
conques â€“ ce que jâ€™ai fait a` titre dâ€™illustration des calculs. Quelquâ€™un de mal intentionneÂ´
pourra alors dire (a` juste titre ?) que lâ€™on peut dans ce cas obtenir â€œce que lâ€™on veutâ€.
â€œBut the primary aim of a scientific experiment is not to precipitate decisions,
but to make an appropriate adjustment in the degree to which one accepts,
or believes, the hypothesis or hypotheses being tested.â€ (Rozeboom, 1960, in
Morrison & Henkel, 1970, page 221)
Une autre difficulteÂ´ vient de lâ€™insistance de certains theÂ´oriciens bayeÂ´siens a` vouloir
faire deÂ´pendre lâ€™infeÂ´rence statistique de la â€œTheÂ´orie de la DeÂ´cisionâ€. Sâ€™il peut eË†tre difficile
et sujet a` critique dâ€™assigner les probabiliteÂ´s initiales, il est encore bien plus probleÂ´matique
de choisir une fonction de couË†t.
La conseÂ´quence de cette mise en avant des aspects subjectifs de lâ€™infeÂ´rence bayeÂ´sienne
et dâ€™une approche deÂ´cisionnelle, a eÂ´teÂ´ dâ€™obscurcir sa contribution a` lâ€™analyse des donneÂ´es
expeÂ´rimentales. En fait la deÂ´finition bayeÂ´sienne peut parfaitement eË†tre utiliseÂ´e pour deÂ´crire
une â€œconnaissance objectiveâ€, en particulier baseÂ´e sur des arguments de symeÂ´trie ou sur
des donneÂ´es de freÂ´quences. Il ne sâ€™agit pas dâ€™affirmer quâ€™une analyse statistique peut eË†tre
cÂ© Revue MODULAD, 2006 -140- NumeÂ´ro 35
entie`rement objective : elle met neÂ´cessairement en jeu des eÂ´leÂ´ments subjectifs â€“ notam-
ment le choix du mode`le â€“ et comporte en fait une part de conventions. Mais lâ€™infeÂ´rence
statistique bayeÂ´sienne nâ€™est pas moins objective que lâ€™infeÂ´rence freÂ´quentiste. Câ€™est meË†me
le contraire dans de nombreux contextes.
4.2 Lâ€™infeÂ´rence fiducio-bayeÂ´siennne
Il existe une voie, de plus en plus reconnue, qui vise a` concilier la theÂ´orie bayeÂ´sienne
avec la conception freÂ´quentiste. Dans cette perspective, lâ€™approche deÂ´veloppeÂ´e par Jef-
freys dans les anneÂ´es trente (Jeffreys, 1961/1939) a un statut privilegieÂ´. Dans la ligne de
Laplace (1986/1825), la philosophie de cette approche est de choisir les probabiliteÂ´s ini-
tiales en eÂ´cartant toute connaissance eÂ´ventuelle sur la valeur du parame`tre. En pratique,
ces probabiliteÂ´s initiales â€œnon informativesâ€ sont des distributions vagues qui, a priori ne
favorisent aucune valeur, aucune hypothe`se, particulie`re. En conseÂ´quence elles laissent les
donneÂ´es â€œparler pour elles-meË†mesâ€.
â€œ1. A major goal of statistics (indeed science) is to find a completely coherent
objective Bayesian methodology for learning from data. This is exemplified by
the attitudes of Jeffreys (1961) and Jaynes (1999 [2003]).
2. Objective Bayesian analysis is the best method for objectively synthesizing
and communicating the uncertainties that arise in a specific scenario, but is
not necessarily coherent in a more general sense.
My general view is that 1) is not attainable ; 2) is often attainable and should
be done if possible.â€ (Berger, 2004, page 2)
Sous cette forme le paradigme bayeÂ´sien fournit, sinon des meÂ´thodes objectives et
comple`tement coheÂ´rentes, au moins des meÂ´thodes de reÂ´feÂ´rence, pleinement justifieÂ´es et
approprieÂ´es pour la communication scientifique. En outre, dans les situations courantes
ou` lâ€™on utilise traditionnellement les tests t, F ou Ï‡2, ces meÂ´thodes sont tre`s faciles a`
mettre en Å“uvre. Elles peuvent maintenant eË†tre utiliseÂ´es aussi aiseÂ´ment que ces tests,
tout en procurant des avantages conceptuels et meÂ´thodologiques consideÂ´rables.
â€œA widely accepted objective Bayes theory, which fiducial inference was inten-
ded to be, would be of immense theoretical and practical importance.â€ (Efron,
1998)
Dans le but de les promouvoir, il nous a sembleÂ´ important de leur donner un nom plus
explicite que standard, non informatives, de reÂ´feÂ´rence, conventionnelles, etc. (Lecoutre,
Lecoutre & Poitevineau, 2001). Nous les appelons
fiducio-bayeÂ´siennes.
â€œThe statistics profession, in general, hurts itself by not using attractive names
for its methodologies, and we should start systematically accepting the â€˜ob-
jective Bayesâ€™ name before it is co-opted by others.â€ (Berger, 2004, page 3)
Avec une motivation similaire, Berger, 2004 deÂ´fend lâ€™appellation
bayeÂ´siennes objectives.
cÂ© Revue MODULAD, 2006 -141- NumeÂ´ro 35
Dans ce qui suit jâ€™utiliserai ces deux appellations, en eÂ´vitant toutefois lâ€™appellation
fiducio-bayeÂ´siennes dans le cas de lâ€™infeÂ´rence sur les proportions, pour lequel elle neÂ´cessite
une discussion particulie`re (qui est abordeÂ´e dans la partie IV).
PARTIE II - LA PRATIQUE :
QUELQUES SITUATIONS DE BASE
Programmes informatiques. Les programmes informatiques utiliseÂ´s pour
la mise en Å“uvre des meÂ´thodes sont regroupeÂ´s dans le logiciel LePAC, qui
peut eË†tre teÂ´leÂ´chargeÂ´ a` lâ€™adresse
http ://www.univ-rouen.fr/LMRS/Persopage/Lecoutre/Eris
On en trouvera une preÂ´sentation dans un numeÂ´ro preÂ´ceÂ´dent de la Revue de
Modulad (Lecoutre & Poitevineau, 2005). Dans ce qui suit, sont fournis des
eÂ´crans (ou plus souvent des extraits dâ€™eÂ´crans) des programmes utiliseÂ´s. Ceux-ci
sont preÂ´ceÂ´deÂ´s du nom du programme utiliseÂ´
LesDistributions
LesProportions LeB-A-BayeÂ´sien
LesMoyennes LesEffectifs
ainsi que dâ€™un mode dâ€™emploi pour obtenir les reÂ´sultats preÂ´senteÂ´s.
5 InfeÂ´rence sur une proportion
Lâ€™objectif de ce premier exemple est de preÂ´senter une â€œtransition en douceurâ€ des
proceÂ´dures freÂ´quentistes traditionnelles vers les proceÂ´dures bayeÂ´siennes. Techniquement
simple, il permettra dâ€™illustrer en deÂ´tail la meÂ´thodologie bayeÂ´sienne.
5.1 Le proble`me : Planification et conduite dâ€™une expeÂ´rimentation
Supposons la situation suivante. Un colle`gue enseignant â€œfreÂ´quentisteâ€ mâ€™affirme avoir
deÂ´veloppeÂ´ une meÂ´thode dâ€™enseignement individuel de lâ€™intervalle de confiance conduisant a`
un taux eÂ´leveÂ´ dâ€™interpreÂ´tations correctes. Nous convenons que sa meÂ´thode est efficace si le
taux dâ€™interpreÂ´tations correctes (â€œsucce`sâ€) Ï• apre`s lâ€™enseignement est supeÂ´rieur a` 0.85, et
quâ€™elle est inefficace si ce taux est infeÂ´rieur a` 0.70. Ma probabiliteÂ´ a priori que la meÂ´thode
soit inefficace est si eÂ´leveÂ´e que je pense quâ€™il nâ€™est pas neÂ´cessaire de recueillir des donneÂ´es.
Bien entendu mon colle`gue ne peut pas eË†tre convaincu par ce subjectivisme flagrant et
il propose de planifier une expeÂ´rimentation dans le cadre freÂ´quentiste traditionnel de
Neyman-Pearson.
cÂ© Revue MODULAD, 2006 -142- NumeÂ´ro 35
5.2 Une solution freÂ´quentiste : Test binomial et test dâ€™interrup-
tion stochastique
5.2.1 La planification de lâ€™expeÂ´rience
ConsideÂ´rant lâ€™hypothe`se nulle H0 : Ï• = 0.70, il deÂ´cide dâ€™utiliser un test binomial
unilateÂ´ral pour un eÂ´chantillon de taille fixeÂ´ avec des probabiliteÂ´s dâ€™erreurs de Types I et
II respectivement eÂ´gales a` Î± = 0.05 et Î² = 0.20, soit une puissance 1 âˆ’ Î² = 0.80 pour
lâ€™hypothe`se alternative Ha : Ï• = 0.85 (celle quâ€™il souhaite accepter !). Il correspond a` ces
conditions un effectif de lâ€™eÂ´chantillon n = 59, pour lequel le test binomial rejette H0 au
seuil 0.05 si le nombre de succe`s observeÂ´ a est plus grand que 47.
En effet, pour un eÂ´chantillon de taille n, la probabiliteÂ´ dâ€™observer a succe`s est donneÂ´e
par la distribution Binomiale
a|Ï• âˆ¼ Bin(Ï•, n)
Pr(a|Ï•) = (na)Ï•a(1âˆ’ Ï•)nâˆ’a
soit la fonction de vraisemblance
v(Ï• | donneÂ´es) âˆ Ï•a(1âˆ’ Ï•)nâˆ’a.
Pour n = 59 (que lâ€™on trouve par iteÂ´rations successives), on obtient :
Pr(a > 47 | H0 : Ï• = 0.70) = 0.035 < 0.05 (Î±)
Pr(a > 47 | Ha : Ï• = 0.85) = 0.834 > 0.80 (1âˆ’ Î²)
LesDistributions
Dans LePAC activez le menu LesDistributions et le sous-menu Binomiale - Stan-
dard, ce qui affiche la feneË†tre pour la distribution Binomiale. Entrez dans les champs
approprieÂ´s les parame`tres de la distribution :
â€¢ pour Ï• : 0.70 (ou simplement .7)
â€¢ pour n : 59
SeÂ´lectionnez les boutons dâ€™option
â€¢ Pr(X>x)
â€¢ probabiliteÂ´
Entrez dans le champ probabiliteÂ´ : 0.05 et appuyez sur touche â€œEntreÂ´eâ€ du clavier (ou
cliquez sur le bouton Calculer). Vous obtenez la premie`re figure ci-apre`s.
Pour la seconde figure, recommencez avec 0.85 pour Ï• et 0.80 pour la probabiliteÂ´.
Vous pouvez seÂ´lectionner le nombre de deÂ´cimales voulues.
Pour obtenir une probabiliteÂ´ associeÂ´e a` une valeur donneÂ´e, seÂ´lectionnez le bouton dâ€™option
â€¢ Limite
et entrez dans le champ limite la valeur dont vous voulez la probabiliteÂ´
cÂ© Revue MODULAD, 2006 -143- NumeÂ´ro 35
Il convient de noter quâ€™en raison du caracte`re discret de la distribution, le taux dâ€™erreur
et la puissance reÂ´els ne peuvent pas eË†tre eÂ´gaux a` Î± et 1âˆ’Î² mais leur sont respectivement
infeÂ´rieur et supeÂ´rieur.
Je reÂ´ussis a` convaincre mon colle`gue quâ€™il serait preÂ´feÂ´rable dâ€™arreË†ter lâ€™expeÂ´rimentation
avant son terme si sa meÂ´thode se reÂ´ve`le inefficace (compte tenu du fait que celle-ci neÂ´cessite
une enseignement individuel et est lourde a` mettre en Å“uvre). En conseÂ´quence il planifie
une analyse intermeÂ´diaire apre`s lâ€™inclusion de 20 sujets. Les notations sont reÂ´sumeÂ´es dans
le tableau suivant
nombre de
effectif succe`s erreurs
DonneÂ´es intermeÂ´diaires n1 = 20 a1 b1 = n1 âˆ’ a1
DonneÂ´es futures n2 = 39 a2 b2 = n2 âˆ’ a2
DonneÂ´es comple`tes n = 59 a = a1 + a2 b = nâˆ’ a
5.2.2 Le test dâ€™interruption stochastique et la puissance conditionnelle
Le cadre traditionnel de Neyman-Pearson neÂ´cessitant la speÂ´cification de toutes les
possibiliteÂ´s avant le recueil des donneÂ´es, il preÂ´voit dâ€™effectuer un â€œtest dâ€™interruption sto-
chastiqueâ€ (stochastically curtailed test). Lâ€™interruption stochastique sugge`re de stopper
une expeÂ´rience a` une eÂ´tape intermeÂ´diaire quand lâ€™information disponible deÂ´termine le
reÂ´sultat de lâ€™expeÂ´rience avec une probabiliteÂ´ eÂ´leveÂ´e, soit sous H0 soit sous Ha.
La puissance conditionnelle a` lâ€™analyse intermeÂ´diaire est deÂ´finie comme la probabi-
liteÂ´, eÂ´tant donneÂ´ Ï• et les donneÂ´es disponibles, que le test rejette H0 au terme preÂ´vu de
lâ€™expeÂ´rience.
(1) A lâ€™analyse intermeÂ´diaire, lâ€™expeÂ´rience est interrompue et on rejette H0 si la puissance
conditionnelle a` la valeur speÂ´cifieÂ´e par lâ€™hypothe`se nulle est eÂ´leveÂ´e, disons supeÂ´rieure a`
0.80. Dans notre exemple, meË†me si apre`s 20 observations on nâ€™a observeÂ´ que des succe`s
(a1 = 20) nous nâ€™arreË†tons pas lâ€™expeÂ´rience, car la probabiliteÂ´ de rejeter H0 au terme preÂ´vu
â€“ donneÂ´e par la distribution Bin(0.70, 39) â€“ est infeÂ´rieure a` 0.80
Pr(a > 47 |H0 : Ï• = 0.70 and a1 = 20) = Pr(a2 > 27 |H0 : Ï• = 0.70) = 0.482 < 0.80
(2) De manie`re similaire, a` lâ€™analyse intermeÂ´diaire, lâ€™expeÂ´rience est interrompue et on
accepte H0 si la puissance conditionnelle a` la valeur speÂ´cifieÂ´e par lâ€™hypothe`se alternative â€“
donneÂ´e par la distribution Bin(0.85, 39) â€“ est faible, disons infeÂ´rieure a` 0.20. Par exemple,
si 12 succe`s sont observeÂ´es apre`s 20 observations, cette re`gle sugge`re dâ€™arreË†ter lâ€™expeÂ´rience
et dâ€™accepter lâ€™hypothe`se nulle
Pr(a > 47 |Ha : Ï• = 0.85 and a1 = 12) = Pr(a2 > 35 |Ha : Ï• = 0.85) = 0.143 < 0.20
cÂ© Revue MODULAD, 2006 -144- NumeÂ´ro 35
Une critique a` lâ€™adresse de cette proceÂ´dure est quâ€™il ne semble gue`re pertinent de
consideÂ´rer une preÂ´diction qui est baseÂ´e sur des hypothe`ses qui peuvent ne plus eË†tre plau-
sibles eÂ´tant donneÂ´ les donneÂ´es disponibles. En fait la proceÂ´dure ignore purement et sim-
plement la connaissance sur le parame`tre obtenue au moment de lâ€™analyse intermeÂ´diaire.
5.3 Une solution hybride : la puissance preÂ´dictive
Pour reÂ´pondre a` cette critique, de nombreux auteurs ont deÂ´fendu lâ€™ideÂ´e de calculer la
puissance preÂ´dictive, câ€™est-a`-dire de moyenner la puissance conditionnelle sur toutes les
valeurs du parame`tre par un calcul bayeÂ´sien. Cela nous conduit a` une approche bayeÂ´sienne,
mais en gardant la proceÂ´dure de test freÂ´quentiste pour lâ€™analyse des donneÂ´es.
Formellement, on utilise les donneÂ´es disponibles a` lâ€™analyse intermeÂ´diaire et la distribu-
tion finale de Ï• qui en reÂ´sulte. La solution la plus simple est de choisir comme distribution
initiale une distribution conjugueÂ´e
Ï• âˆ¼ BeË†ta (a0, b0)
Lâ€™avantage est que la distribution finale est eÂ´galement une distribution BeË†ta (ce qui
explique lâ€™appellation â€œconjugueÂ´eâ€). Les â€œpoidsâ€ initiaux a0 et b0 sâ€™ajoutent aux effectifs
observeÂ´s a1 et b1, soit
Ï• | a1 âˆ¼ BeË†ta (a1 + a0, b1 + b0)
et la distribution preÂ´dictive, qui est un meÂ´lange de distributions Binomiales, sâ€™appelle
tout naturellement une distribution BeË†ta-Binomiale
a2 | a1 âˆ¼ BeË†ta-Bin (a1 + a0, b1 + b0;n2)
Pour obtenir la puissance preÂ´dictive, on choisit une distribution initiale non informa-
tive. Celle-ci correspond a` des poids a0 et b0 faibles, compris entre 0 et 1
4. Ici, je retiendrai
la distribution initiale
Ï• âˆ¼ BeË†ta (0, 1)
un choix qui est coheÂ´rent avec la proceÂ´dure de test utiliseÂ´e : jâ€™y reviendrai plus loin.
Reprenons lâ€™exemple traiteÂ´ ci-dessus en (1), soit n1 = 20 et a1 = 20. La probabiliteÂ´
preÂ´dictive de rejeter H0 au terme preÂ´vu (n = 59) prend explicitement en compte les
donneÂ´es disponibles (aucune erreur nâ€™a eÂ´teÂ´ observeÂ´e). Elle est donneÂ´e par la distribution
BeË†ta-Bin (20, 1; 39) et est sans surprise largement supeÂ´rieure a` la probabiliteÂ´ conditionnelle
a` la valeur speÂ´cifieÂ´e par lâ€™hypothe`se nulle (Ï• = 0.70)
Pr(a > 47 | a1 = 20) = Pr(a2 > 27 | a1 = 20) = 0.997 > 0.80
dâ€™ou` la deÂ´cision dâ€™interrompre lâ€™expeÂ´rience et de rejeter H0.
LesDistributions
Dans LePAC activez le menu LesDistributions et le sous-menu BeË†ta - Binomiale,
ce qui affiche la feneË†tre pour la distribution BeË†ta-Binomiale (ou si la feneË†tre est deÂ´ja` ou-
verte pour une autre distribution, cliquez sur le bouton correspondant a` cette distribution
pour la changer). Entrez dans les champs approprieÂ´s les parame`tres de la distribution :
4La distribution BeË†ta (a0, b0) nâ€™est en toute rigueur deÂ´finie que si a0 et b0 sont strictement positifs.
Lorque a0 ou b0 est nul, la densiteÂ´ est impropre (
âˆ« 1
0
p(Ï•)dÏ• = +âˆ), mais cela nâ€™empeË†che pas le calcul
de la densiteÂ´ finale qui sera, sauf cas particuliers, une densiteÂ´ propre. En tout eÂ´tat de cause, il ne
sâ€™agit que dâ€™un proble`me theÂ´orique, car en pratique, une distribution â€œpropreâ€ obtenue en remplacÂ¸ant
0 par une valeur  tre`s petite ne fera aucune diffeÂ´rence.
cÂ© Revue MODULAD, 2006 -145- NumeÂ´ro 35
â€¢ pour Î± : 20
â€¢ pour Î² : 1
â€¢ pour n : 59
SeÂ´lectionnez les boutons dâ€™option
â€¢ Pr(X>x)
â€¢ limite
Entrez dans le champ limite : 27 et appuyez sur touche â€œEntreÂ´eâ€ du clavier (ou cliquez
sur le bouton Calculer). Vous obtenez la figure ci-apre`s.
Cette probabiliteÂ´ preÂ´dictive est une moyenne pondeÂ´reÂ´e des probabiliteÂ´s conditionnelles
a` Ï• (les poids eÂ´tant donneÂ´s par la distribution finale)
Pr(a > 47 | a1 = 20 et Ï•) = Pr(a2 > 27 | a1 = 20 et Ï•)
dont quelques exemples sont
Ï• Pr(a > 47 | a1 = 20 et Ï•)
1 1
0.95 0.9999997
0.85 0.990
0.70 0.482
Cette approche de la puissance preÂ´dictive eÂ´tant une approche hybride nâ€™est pas tre`s
satisfaisante. En particulier elle ne nous donne pas une information bayeÂ´sienne directe
sur Ï• : la distribution finale nâ€™est utiliseÂ´e que comme intermeÂ´diaire de calcul. Ce qui est
troublant est quâ€™une deÂ´cision (accepter H0 ou accepter Ha) est prise a` lâ€™analyse terminale
â€“ ou eÂ´ventuellement a` lâ€™analyse intermeÂ´diaire â€“ meË†me si la proportion observeÂ´e est situeÂ´e
dans la reÂ´gion de non conclusion [0.70 , 0.85], auquel cas on nâ€™a eÂ´videmment rien prouveÂ´
pour ces hypothe`ses.
Ce dont on a reÂ´ellement besoin, câ€™est de pouvoir eÂ´valuer a` toute eÂ´tape de lâ€™expeÂ´rience
la probabiliteÂ´ des reÂ´gions speÂ´cifieÂ´es auxquelles on sâ€™inteÂ´resse et lâ€™aptitude dâ€™un eÂ´chantillon
futur a` corroborer les reÂ´sultats deÂ´ja` obtenus. Lâ€™analyse bayeÂ´sienne traite directement ces
questions.
5.4 Solution bayeÂ´sienne
La meÂ´thodologie bayeÂ´sienne nous permet dâ€™obtenir les probabiliteÂ´s des reÂ´gions speÂ´cifieÂ´es,
ce qui apporte des reÂ´ponses directes aux questions sur la grandeur des effets et nâ€™a pas de
contrepartie freÂ´quentiste. ConsideÂ´rons un nouvel exemple dâ€™analyse intermeÂ´diaire, avec 10
succe`s observeÂ´es (n1 = 20 et a1 = 10).
cÂ© Revue MODULAD, 2006 -146- NumeÂ´ro 35
5.4.1 Evaluer la probabiliteÂ´ des reÂ´gions speÂ´cifieÂ´es
Choisissons la distribution initiale noninformative BeË†ta (1/2, 1/2), qui donnera la â€œmeÂ´thode
bayeÂ´sienne objectiveâ€ (je reviendrai eÂ´galement sur ce choix plus loin) 5. Dans ce cas la
distribution finale est BeË†ta (10.5, 10.5 et on obtient une probabiliteÂ´ eÂ´leveÂ´e (0.971) que la
meÂ´thode dâ€™enseignement soit inefficace (Ï• < 0.70).
Pr(Ï• < 0.70 | a1 = 10) Pr(0.70 < Ï• < 0.85 | a1 = 10 ) (PrÏ• > 0.85 | a1 = 10 )
0.971 0.029 0.0001
Lâ€™utilisation de lâ€™ordinateur reÂ´soud les calculs neÂ´cessaires pour lâ€™utilisation des distri-
butions bayeÂ´siennes. Cela donne a` lâ€™utilisateur un moyen a` la fois intuitif et attrayant pour
comprendre les roË†les de la taille de lâ€™eÂ´chantillon, des donneÂ´es et de la distribution initiale.
En particulier la distribution finale peut eË†tre visualiseÂ´e et exploreÂ´e interactivement.
LesProportions
Dans LePAC activez le menu LesBayeÂ´siens et le sous-menu LesProportions, ce qui
affiche la feneË†tre pour lâ€™infeÂ´rence sur des proportions (par deÂ´faut, câ€™est lâ€™option 1 groupe
qui est active). Entrez dans les champs approprieÂ´s les effectifs :
â€¢ pour 1 : 10
â€¢ pour 0 : 10
Entrez sâ€™il y a lieu les parame`tres de la distribution initiale beË†ta (mais câ€™est en principe
inutile car câ€™est lâ€™option par deÂ´faut) :
â€¢ pour 1 : 0.5 (que vous pouvez entrer comme 1/2)
â€¢ pour 0 : 0.5
Remarque : ces valeurs peuvent eË†tre afficheÂ´es en cliquant sur le bouton 1/2.
SeÂ´lectionnez les boutons dâ€™option
â€¢ X<
â€¢ limite
Entrez dans le champ limite : 0.70 et seÂ´lectionnez les deÂ´cimales approprieÂ´es : 2 pour la
limite et 3 pour la probabiliteÂ´. Cliquez sur le bouton Calculer et vous obtenez la figure
ci-apre`s.
5Dans ce cas, lâ€™infeÂ´rence bayeÂ´sienne sur Ï• effectueÂ´e a` lâ€™analyse intermeÂ´diaire ne prend pas explicite-
ment en compte la re`gle dâ€™arreË†t (qui est cependant prise en compte dans le calcul de la probabiliteÂ´
preÂ´dictive). Dans le cadre freÂ´quentiste, il est habituel que les infeÂ´rences intermeÂ´diaires soient modifieÂ´es
pour tenir compte de la re`gle dâ€™arreË†t. Ce point â€“ qui pourrait apparaË†Ä±tre comme un sujet de discorde
entre les deux approches â€“ est abordeÂ´ dans la partie IV.
cÂ© Revue MODULAD, 2006 -147- NumeÂ´ro 35
La probabiliteÂ´ associeÂ´e a` une limite fixeÂ´e, ou inversement les limites associeÂ´es a` une
probabiliteÂ´ (ou garantie) donneÂ´e (seÂ´lectionnez le bouton dâ€™option probabiliteÂ´), peuvent
eË†tre calculeÂ´es.
5.4.2 Evaluer lâ€™aptitude dâ€™un eÂ´chantillon futur a` corroborer les reÂ´sultats deÂ´ja`
obtenus
Pour reÂ´sumer lâ€™information obtenue quant a` la deÂ´cision dâ€™interrompre ou non lâ€™expeÂ´rience,
nous pouvons calculer la probabiliteÂ´ preÂ´dictive de confirmer la conclusion dâ€™ineffica-
citeÂ´. Si on souhaite une garantie dâ€™au moins 0.95 pour la conclusion finale, câ€™est-a`-dire
Pr(Ï• < 0.70 | a) > 0.95, il faut que le nombre total de succe`s a soit infeÂ´rieur a` 36 sur
59. Il sâ€™agit donc, puisque lâ€™on a deÂ´ja` observeÂ´ a1 = 10 succe`s, de calculer la probabiliteÂ´
preÂ´dictive dâ€™observer dans les donneÂ´es futures un nombre de succe`s a2 compris entre 0 et
25 sur 39.
Ici, sur la base des donneÂ´es disponibles, il y a 87.3% de chances que cette conclusion
soit obtenue si lâ€™expeÂ´rience est meneÂ´e a` son terme.
LesProportions
Effectuez sâ€™il y a lieu les opeÂ´rations deÂ´crites pour la figure preÂ´ceÂ´dente, puis cliquez sur le
bouton prediction.
SeÂ´lectionnez le bouton dâ€™option
â€¢ ensemble
Entrez dans le champ effectif suppleÂ´mentaire : 39 et seÂ´lectionnez la garantie vou-
lue dans la liste deÂ´roulante : 0.95. Cliquez sur le bouton Calculer et vous obtenez la
probabiliteÂ´ preÂ´dictive : 0.873. Cliquez sur le bouton deÂ´tail pour obtenir la figure ci-apre`s.
cÂ© Revue MODULAD, 2006 -148- NumeÂ´ro 35
Le tableau ci-apre`s donne un reÂ´sumeÂ´ des analyses pour lâ€™exemple preÂ´ceÂ´dent, ainsi que
pour un autre exemple plus favorable a` la meÂ´thode dâ€™enseignement.
cÂ© Revue MODULAD, 2006 -149- NumeÂ´ro 35
Distribution initiale BeË†ta (1/2, 1/2)
Exemple 1 : n1 = 20 et a1 = 10
InfeÂ´rence sur Ï• ProbabiliteÂ´ preÂ´dictive (n = 59)
ProbabiliteÂ´ finale Conclusion avec une garantie â‰¥ 0.95
Pr(Ï• < 0.70 | a1 = 10) Ï• < 0.70
0.971 0.873 (a < 36)
Pr(Ï• < 0.85 | a1 = 10) Ï• < 0.85
0.9999 0.9998 (a < 46)
Exemple 2 : n1 = 20 et a1 = 18
InfeÂ´rence sur Ï• ProbabiliteÂ´ preÂ´dictive (n = 59)
ProbabiliteÂ´ finale Conclusion avec une garantie â‰¥ 0.95
Pr(Ï• > 0.70 | a1 = 10) Ï• > 0.70
0.982 0.939 (a > 46)
Pr(Ï• > 0.85 | a1 = 10) Ï• > 0.85
0.717 0.301 (a > 54)
5.4.3 Choisir lâ€™effectif de lâ€™eÂ´chantillon
Les proceÂ´dures preÂ´dictives sont aussi des outils adapteÂ´s pour aider au choix de lâ€™effectif
de lâ€™eÂ´chantillon. Supposons quâ€™en vue de planifier une expeÂ´rience pour deÂ´montrer lâ€™effi-
caciteÂ´ de la meÂ´thode dâ€™enseignement nous ayons reÂ´aliseÂ´ une expeÂ´rience preÂ´liminaire, par
exemple avec 10 sujets et que nâ€™ayons observeÂ´ que des succe`s. Dans ce cas la distribution
finale pour lâ€™expeÂ´rience preÂ´liminaire â€“ en commencÂ¸ant avec la distribution non informative
BeË†ta (1/2, 1/2) â€“ est utiliseÂ´e comme distribution initiale. On obtient ici la probabiliteÂ´ finale
Pr(Ï• > 0.85) = 0.932.
LesProportions
ProceÂ´dez comme preÂ´ceÂ´demment pour lâ€™infeÂ´rence sur une proportion et entrez dans les
champs approprieÂ´s les effectifs :
â€¢ pour 1 : 10
â€¢ pour 0 : 0
Entrez la distribution initiale beË†ta
â€¢ pour 1 : 1/2
â€¢ pour 0 : 1/2
SeÂ´lectionnez les boutons dâ€™option
â€¢ X>
â€¢ limite
Entrez dans le champ limite : 0.85 pour obtenir la figure ci-apre`s (avec les deÂ´cimales
approprieÂ´es).
cÂ© Revue MODULAD, 2006 -150- NumeÂ´ro 35
Si on inte`gre les donneÂ´es preÂ´liminaires dans lâ€™analyse de lâ€™expeÂ´rience, la proceÂ´dure est
exactement la meË†me que dans le cas de lâ€™analyse intermeÂ´diaire ; on parle dans ce cas dâ€™ap-
proche bayeÂ´sienne comple`te (â€œfull Bayesianâ€). Mais la plupart temps, dans lâ€™expeÂ´rimentation,
on ne souhaite pas prendre en compte les donneÂ´es preÂ´liminaires dans lâ€™analyse de lâ€™expeÂ´rience,
et celle-ci sera donc effectueÂ´e elle aussi avec la distribution initiale BeË†ta (1/2, 1/2).
La proceÂ´dure reste analogue : nous calculons la probabiliteÂ´ preÂ´dictive que dans lâ€™eÂ´chantillon
futur dâ€™effectif n (et non pour lâ€™ensemble des donneÂ´es) la conclusion dâ€™efficaciteÂ´ (Ï• > 0.85)
soit atteinte avec une garantie donneÂ´e Î³, dâ€™ou` par exemple les probabiliteÂ´s preÂ´dictives sui-
vantes pour Î³ = 0.95 (avec entre parenthe`ses les valeurs de a qui remplissent la condition) :
n = 20 7â†’ 0.582 (a > 19)
n = 30 7â†’ 0.696 (a > 28)
n = 40 7â†’ 0.744 (a > 37)
n = 50 7â†’ 0.770 (a > 46)
n = 60 7â†’ 0.787 (a > 55)
n = 70 7â†’ 0.798 (a > 64)
n = 71 7â†’ 0.795 (a > 65)
n = 72 7â†’ 0.829 (a > 65)
Etc.
LesProportions
Effectuez sâ€™il y a lieu les opeÂ´rations deÂ´crites pour la figure preÂ´ceÂ´dente, puis cliquez sur
le bouton prediction.
SeÂ´lectionnez le bouton dâ€™option
â€¢ donneÂ´es futures
Entrez dans le champ effectif suppleÂ´mentaire : 39 et seÂ´lectionnez la garantie vou-
lue dans la liste deÂ´roulante : 0.95. Cliquez sur le bouton Calculer et vous obtenez la
probabiliteÂ´ preÂ´dictive : 0.798 et la figure ci-apre`s.
Ainsi, sur la base des reÂ´sultats preÂ´liminaires, il faut donc un effectif de lâ€™ordre de 70
pour avoir a` peu pre`s 80% de chances de deÂ´montrer lâ€™efficaciteÂ´. On ne sâ€™eÂ´tonnera pas du
fait que les probabiliteÂ´s puissent ne pas eË†tre croissantes ; cela reÂ´sulte du caracte`re discret
de la variable (il en est de meË†me pour la puissance).
5.5 Commentaires sur le choix de la distribution initiale non
informative
Beaucoup dâ€™utilisateurs potentiels des meÂ´thodes bayeÂ´siennes continuent de penser
quâ€™elles sont trop â€œsubjectivesâ€ pour eË†tre scientifiquement acceptables. Pourtant les meÂ´thodes
freÂ´quentistes sont pleines de conventions plus ou moins ad hoc. Ainsi le traditionnel seuil
cÂ© Revue MODULAD, 2006 -151- NumeÂ´ro 35
observeÂ´ p (p value) du test est baseÂ´ sur les eÂ´chantillons qui sont â€œplus extreË†mesâ€ que les
donneÂ´es observeÂ´es (sous lâ€™hypothe`se nulle). Mais, pour des donneÂ´es discre`tes, cela deÂ´pend
du fait que lâ€™on inclut ou non les donneÂ´es observeÂ´es.
Supposons quâ€™a` lâ€™analyse finale on observe 47 succe`s (n = 59 et a = 47), soit la valeur
au dela` de laquelle le test binomial rejette lâ€™hypothe`se nulle H0 : Ï• = 0.70. On peut alors
calculer le seuil observeÂ´ p suivant une des trois possibiliteÂ´s suivantes :
pinc = Pr(a â‰¥ 47 | H0 : Ï• = 0.70) = 0.066 [solution usuelle â€œincluanteâ€]
â‡’ H0 nâ€™est pas rejeteÂ´e au seuil Î± = 0.05 (test â€œconservateurâ€)
pexc = Pr(a > 47 | H0 : Ï• = 0.70) = 0.035 [solution â€œexcluanteâ€]
â‡’ H0 est rejeteÂ´e au seuil Î± = 0.05 (test â€œlibeÂ´ralâ€)
pmoyen = 1/2(pinc + pinc) = 0.051 [â€œp moyenâ€]
Dans la solutions usuelle la valeur observeÂ´e est inclue et le test est â€œconservateurâ€ :
la probabiliteÂ´ de rejeter H0, si elle est vraie, est infeÂ´rieure a` Î±. Mais si la valeur observeÂ´e
est exclue, le test devient â€œlibeÂ´ralâ€ : la probabiliteÂ´ de rejeter H0, si elle est vraie, est
supeÂ´rieure a` Î±. Une solution typique pour surmonter ce proble`me consiste a` consideÂ´rer un
â€œp moyenâ€ (mid-p value) (Routledge, 1994 ; Berry & Armitage, 1995), mais dans le cadre
freÂ´quentiste cette pratique a seulement des justifications ad hoc.
A lâ€™eÂ´vidence dans ce cas le choix dâ€™une distribution initiale non informative implique
aussi des conventions. Mais le choix particulier dâ€™une telle distribution initiale nâ€™est ni
plus ni moins quâ€™une contrepartie exacte de lâ€™arbitraire en jeu dans lâ€™approche freÂ´quentiste
(Bernard, 1996). Ainsi, dans notre situation, diffeÂ´rentes distributions ont eÂ´teÂ´ proposeÂ´es
pour une analyse bayeÂ´sienne objective (pour une discussion, voir par exemple Lee, 2004,
pages 79-81). La plupart appartiennent a` la famille des distributions BeË†ta (a0, b0) avec des
valeurs de a0 et b0 comprises entre 0 et 1, en particulier
â€¢ BeË†ta (1, 1) â€“ qui est la distribution uniforme sur [0,1] (Laplace, 1774) ;
â€¢ BeË†ta (0, 0) qui est une distribution impropre â€“ mais qui correspond a` la distribution
uniforme pour log( Ï•
1âˆ’Ï•) (Lhoste, 1923 ; Haldane, 1948) ;
â€¢ BeË†ta (1/2, 1/2) â€“ qui correspond a` la distribution uniforme pour arcsinus(âˆšpi) (Jeffreys,
1961 ; Perks, 1947) et qui est deÂ´riveÂ´e en utilisant la re`gle de Jeffreys dont on trouvera la
justification dans la partie IV.
5.5.1 InterpreÂ´tation bayeÂ´sienne du seuil observeÂ´
Pour notre proble`me, il existe dans cette famille deux distributions initiales extreË†mes â€“
BeË†ta (0, 1) et BeË†ta (1, 0) â€“ qui sont respectivement la plus deÂ´favorable et la plus favorable
par rapport a` lâ€™hypothe`se nulle. Les seuils de signification observeÂ´s associeÂ´s aux solutions
incluante et excluante sont exactement les probabiliteÂ´s bayeÂ´siennes finales que Ï• soit plus
petit que 0.70 (la valeur speÂ´cifieÂ´e parH0) respectivement associeÂ´es a` ces deux distributions
initiales extreË†mes. La distribution initiale de Jeffreys BeË†ta (1/2, 1/2) avec des poids eÂ´gaux a`
1/2 est intermeÂ´daire et donne une probabiliteÂ´ proche du â€œp moyenâ€.
cÂ© Revue MODULAD, 2006 -152- NumeÂ´ro 35
Pr(Ï• < 0.70 | a = 47) = 0.066 = pinc
pour la distribution initiale Ï• âˆ¼ BeË†ta (0, 1) (la plus deÂ´favorable a` H0)
soit la distribution finale Ï• | âˆ¼ BeË†ta (47, 13)
Pr(Ï• < 0.70 | a = 47) = 0.035 = pexc
pour la distribution initiale Ï• âˆ¼ BeË†ta (1, 0) (la plus favorable a` H0)
soit la distribution finale Ï• | âˆ¼ BeË†ta (48, 12)
Pr(Ï• >< 0.70 | a = 47) = 0.049 â‰ˆ pmoyen
pour la distribution initiale Ï• âˆ¼ BeË†ta (1/2, 1/2)
soit la distribution finale Ï• | âˆ¼ BeË†ta (47.5, 12.5)
LesProportions
ProceÂ´dez comme preÂ´ceÂ´demment pour lâ€™infeÂ´rence surune proportion et entrez dans les
champs approprieÂ´s les effectifs :
â€¢ pour 1 : 47
â€¢ pour 0 : 12
Entrez la distribution initiale beË†ta
â€¢ pour 1 : 0
â€¢ pour 0 : 1
Remarque : ces valeurs peuvent eË†tre afficheÂ´es en cliquant sur le bouton 0 1.
SeÂ´lectionnez les boutons dâ€™option
â€¢ X<
â€¢ limite
Entrez dans le champ limite : 0.70 pour obtenir la premie`re figure ci-apre`s (avec les
deÂ´cimales approprieÂ´es).
La seconde figure est obtenue pour la distribution initiale beË†ta
â€¢ pour 1 : 1
â€¢ pour 0 : 0
La critique facile a` lâ€™eÂ´gard de lâ€™approche bayeÂ´sienne concernant lâ€™existence de diver-
gences quant au choix de la distribution non informative se retourne donc a` lâ€™encontre de
lâ€™approche freÂ´quentiste. La reÂ´ponse des bayeÂ´siens ne devrait donc pas eË†tre de meÂ´sestimer
lâ€™impact du choix dâ€™une distribution non informative particulie`re, comme cela est souvent
le cas
cÂ© Revue MODULAD, 2006 -153- NumeÂ´ro 35
â€œIn fact, the [different non informative priors] do not differ enough to make
much difference with even a fairly small amount of data.â€ (Lee, 2004, page 81)
mais au contraire de lâ€™accepter.
5.5.2 Intervalles de creÂ´dibiliteÂ´ bayeÂ´sien et taux de couverture freÂ´quentistes
Dans dâ€™autres situations ou` nous ne nous inteÂ´ressons pas a` des valeurs particulie`res,
nous pouvons consideÂ´rer un intervalle (ou plus geÂ´neÂ´ralement une reÂ´gion) dâ€™estimation
pour Ï•. Dans le cadre bayeÂ´sien un tel intervalle est habituellement appeleÂ´ un intervalle
de creÂ´dibiliteÂ´ pour souligner la diffeÂ´rence dâ€™interpreÂ´tation avec lâ€™intervalle de confiance
freÂ´quentiste.
Intervalles â€œa` queues eÂ´galesâ€
LesProportions
ProceÂ´dez comme preÂ´ceÂ´demment pour lâ€™infeÂ´rence surune proportion et entrez dans les
champs approprieÂ´s les effectifs :
â€¢ pour 1 : 19
â€¢ pour 0 : 1
Entrez la distribution initiale beË†ta
â€¢ pour 1 : 1/2
â€¢ pour 0 : 1/2
SeÂ´lectionnez les boutons dâ€™option
â€¢ <X<
â€¢ probabiliteÂ´
Entrez dans le champ probabiliteÂ´ : 0.95 pour obtenir la figure ci-apre`s (avec 4 deÂ´cimales
pour la limite).
On trouve ici, pour les diffeÂ´rentes distributions initiales consideÂ´reÂ´es les intervalles a`
95% pour les deux exemples suivants
n1 = 20, a1 = 19
BeË†ta (0, 1) BeË†ta (1, 1) BeË†ta (1/2, 1/2) BeË†ta (0, 0) BeË†ta (1, 0)
[0.7513 , 0.9877] [0.7618 , 0.9883] [0.7892 , 0.9946] [0.8235 , 0.9987] [0.8316 , 0.9987]
n1 = 59, a1 = 32
BeË†ta (0, 1) BeË†ta (1, 1) BeË†ta (1/2, 1/2) BeË†ta (0, 0) BeË†ta (1, 0)
[0.4075 , 0.6570] [0.4161 , 0.6633] [0.4158 , 0.6649] [0.4240 , 0.6728] [0.4240 , 0.6728]
Parmi ces distributions initiales, BeË†ta (1, 0) donne les plus grandes limites et a les
proprieÂ´teÂ´s freÂ´quentistes suivantes : la proportion des eÂ´chantillons pour lesquels la limite
supeÂ´rieure est infeÂ´rieure a` Ï• est plus petite que Î±/2 et la proportion des eÂ´chantillons pour
cÂ© Revue MODULAD, 2006 -154- NumeÂ´ro 35
pour pour lesquels la limite infeÂ´rieure est supeÂ´rieure a` Ï• est plus grande que Î±/2. La distri-
bution BeË†ta (0, 1) donne les plus petites limites et les proprieÂ´teÂ´s inverses. Par conseÂ´quent,
consideÂ´rer simultaneÂ´ment les limites de ces deux intervalles prote`ge lâ€™utilisateur a` la fois
dâ€™une acceptation et dâ€™un rejet erroneÂ´s des hypothe`ses sur Ï• au seuil unilateÂ´ral Î±/2.
Si lâ€™on souhaite un seul intervalle pour reÂ´sumer les reÂ´sultats, ces proprieÂ´teÂ´s conduisent
a` privileÂ´gier celui associeÂ´ a` la distribution â€œintermeÂ´diaireâ€ BeË†ta (1/2, 1/2) (qui est la distri-
bution de Jeffreys). Effectivement cet intervalle a de tre`s bonnes proprieÂ´teÂ´s freÂ´quentistes
qui justifient pleinement le nom de â€œmeÂ´thode bayeÂ´sienne objectiveâ€. La probabiliteÂ´ de
couverture de cet intervalle est tre`s proche du seuil nominal, meË†me pour des eÂ´chantillons
dâ€™effectifs tre`s faibles. Il se compare favorablement a` la plupart des intervalles freÂ´quentistes
disponibles et est recommandable meË†me dâ€™un point de vue freÂ´quentiste, comme lâ€™ont
montreÂ´ Brown, Cai et DasGupta (2001) (voir aussi Agresti & Min, 2005)
â€œWe revisit the problem of interval estimation of a binomial proportion. . .We
begin by showing that the chaotic coverage properties of the Wald interval are
far more persistent than is appreciated. . .We recommend the Wilson interval or
the equal tailed Jeffreys prior interval for small n.â€ (Brown, Cai & DasGupta,
2001, page 101).
Intervalles â€œde plus haute densiteÂ´ finaleâ€
Une approche qui a eÂ´teÂ´ souvent recommandeÂ´e par les bayeÂ´siens est de consideÂ´rer lâ€™in-
tervalle â€œde plus haute densiteÂ´ finaleâ€ (highest posterior density , en bref HPD). Pour un tel
intervalle (qui peut en fait, si la distribution nâ€™est pas unimodale, eË†tre une reÂ´union dâ€™inter-
valles disjoints), la densiteÂ´ de probabiliteÂ´ est plus eÂ´leveÂ´e pour toute valeur a` lâ€™inteÂ´rieur de
lâ€™intervalle que pour toute valeur exteÂ´rieure. Ceci reÂ´pond a` lâ€™objectif dâ€™obtenir lâ€™intervalle
le plus court possible. Mais, sauf pour une distribution symeÂ´trique, chacune des probabi-
liteÂ´s lateÂ´rales sera diffeÂ´rente de Î±/2. Cette proprieÂ´teÂ´ apparaË†Ä±t indeÂ´sirable pour lâ€™analyse de
donneÂ´es expeÂ´rimentales ou` la plupart des questions sont, comme dans le preÂ´sent exemple
â€œunilateÂ´ralesâ€.
De plus un tel intervalle nâ€™est pas invariant par transformation (excepteÂ´ pour une
transformation lineÂ´aire), ce qui peut eË†tre consideÂ´reÂ´ avec Agresti et Min (2005, page 3)
comme â€œa fatal disadvantageâ€. Ainsi, pour les donneÂ´es n = 59, a = 32 et la distribution
initiale BeË†ta (1/2, 1/2), nous obtenons les intervalles de plus haute densiteÂ´ finale
[0.4167, 0.6658] pour Ï• et [0.7481, 2.1594] pour
Ï•
1âˆ’ Ï•
avec les probabiliteÂ´s correspondantes :
Pr(Ï• < 0.4167) = 0.026 et Pr(
Ï•
1âˆ’ Ï• < 0.7481) = 0.039
Pr(Ï• > 0.6658) = 0.024 et Pr(
Ï•
1âˆ’ Ï• > 2.1594) = 0.011
Pour ces raisons, nous nâ€™avons pas retenu ces intervalles de plus haute densiteÂ´ finale
dans nos programmes.
On remarquera en passant, a` propos de cet exemple quâ€™il est tout aussi facile dâ€™obtenir
la distribution finale de Ï•
1âˆ’Ï• , qui est une distribution F de Fisher Snedecor. On trouve
lâ€™intervalle de creÂ´dibiliteÂ´ 95% a` queues eÂ´gales [0.712,1.984].
LesProportions
cÂ© Revue MODULAD, 2006 -155- NumeÂ´ro 35
ProceÂ´dez comme preÂ´ceÂ´demment pour lâ€™infeÂ´rence surune proportion, mais activez le bouton
dâ€™option Ï•/(1âˆ’ Ï•). Entrez dans les champs approprieÂ´s les effectifs :
â€¢ pour 1 : 32
â€¢ pour 0 : 27
Entrez la distribution initiale beË†ta
â€¢ pour 1 : 1/2
â€¢ pour 0 : 1/2
SeÂ´lectionnez les boutons dâ€™option
â€¢ <X<
â€¢ probabiliteÂ´
Entrez dans le champ probabiliteÂ´ : 0.95 pour obtenir la figure ci-apre`s (avec 3 deÂ´cimales
pour la limite).
5.5.3 Distributions initiales â€œinformativesâ€
Lâ€™utilisation de distributions initiales non informatives a manifestement un statut
privileÂ´gieÂ´ pour obtenir des eÂ´nonceÂ´s â€œa` usage publicâ€. Cependant dâ€™autres techniques
bayeÂ´siennes peuvent aussi avoir un roË†le important a` jouer dans la recherche expeÂ´rimentale.
En particulier, elles sont ideÂ´alement adapteÂ´es pour combiner des informations provenant
de plusieurs sources, et par suite pour planifier une seÂ´rie dâ€™expeÂ´riences. Des utilisations
plus ou moins reÂ´alistes et plus ou moins convaincantes de ces techniques ont eÂ´teÂ´ proposeÂ´es.
Quand une analyse bayeÂ´sienne objective sugge`re une conclusion donneÂ´e, diffeÂ´rentes dis-
tributions a priori traduisant les reÂ´sultats dâ€™autres expeÂ´riences ou des opinions plus ou
moins subjectives dâ€™â€œexpertsâ€, soit sceptiques soit enthousiastes , peuvent eË†tre utiliseÂ´es
pour eÂ´prouver la robustesse des conclusions (voir en particulier Spiegelhalter, Freedman
& Parmar, 1994).
On peut aussi consideÂ´rer que la construction dâ€™une distribution initiale a` partir dâ€™opi-
nions dâ€™â€œexpertsâ€ du domaine peut eË†tre utile dans certaines eÂ´tudes, mais cela neÂ´cessite
des techniques approprieÂ´e (voir pour un exemple dans les essais cliniques Tan et al., 2003).
Il convient encore de mentionner le fait que les distributions preÂ´dictives sont eÂ´galement
un outil utile pour construire une distribution initiale subjective, car il est souvent plus
facile dâ€™exprimer une opinion relativement a` des donneÂ´es attendues plutoË†t quâ€™a` des pa-
rame`tres.
Lâ€™utilisation de ces techniques pour lâ€™analyse des donneÂ´es expeÂ´rimentales nâ€™a cependant
pas assez eÂ´teÂ´ exploreÂ´e pour pouvoir reÂ´ellement appreÂ´cier leur apport, notamment dans le
cas ou` lâ€™information a priori refle`te dâ€™avantage une opinion quâ€™un connaissance reÂ´elle.
Les exemples donneÂ´s ci-apre`s doivent eË†tre vus comme des exercices pour mieux com-
prendre comment lâ€™infeÂ´rence bayeÂ´sienne permet de combiner des informations. Je laisse
au lecteur le soin dâ€™exercer son esprit critique quant a` lâ€™apport de ces meÂ´thodes pour
lâ€™analyse de donneÂ´es expeÂ´rimentales.
Distributions â€œsceptiquesâ€ et â€œenthousiastesâ€
cÂ© Revue MODULAD, 2006 -156- NumeÂ´ro 35
Reprenons lâ€™exemple des donneÂ´es n = 59, a = 32, pour laquelle la proceÂ´dure bayeÂ´sienne
objective conduisait a` conclure que la meÂ´thode dâ€™enseignement eÂ´tait inefficace (Ï• < 0.70).
ConsideÂ´rons a` titre dâ€™illustration les deux distributions initiales, respectivement a priori
tre`s sceptique et tre`s enthousiaste envers la meÂ´thode
Ï• âˆ¼ Î²(20, 80) de moyenne 0.200 pour laquelle Pr(Ï• < 0.70) â‰ˆ 1
Ï• âˆ¼ Î²(98, 2) de moyenne 0.980 pour laquelle Pr(Ï• > 0.85) = 0.999998
Les distributions finales correspondantes sont respectivement
Ï• âˆ¼ Î²(52, 107) de moyenne 0.327 pour laquelle Pr(Ï• < 0.70) â‰ˆ 1
Ï• âˆ¼ Î²(130, 29) de moyenne 0.818 pour laquelle Pr(Ï• > 0.85) = 0.143
La premie`re â€œrenforceâ€ bien entendu la conclusion dâ€™inefficaciteÂ´. On peut le voir sur
la figure ci-apre`s, qui montre la distribution initiale (en noir) et la distribution finale
(en rouge) ; celle-ci peut eË†tre compareÂ´e a` la distribution finale objective â€“ pour lâ€™initiale
BeË†ta (1/2, 1/2) (en bleu).
LeB-A-BayeÂ´sien
Dans LePAC activez le menu LeB-A-BayeÂ´sien et le sous-menu eÂ´chantillonnage Bi-
nomial, ce qui affiche la feneË†tre correspondante. Activez la case donneÂ´es et entrez les
valeurs :
â€¢ pour 1 : 32
â€¢ pour 0 : 27
Entrez les parame`tres de la distribution initiale (par deÂ´faut câ€™est lâ€™option une seule
distribution qui est active) :
â€¢ pour 1 : 20
â€¢ pour 0 : 80
Activez la case finale / initiale BeË†ta(1/2,1/2) pour obtenir la figure ci-apre`s. Les
courbes sont mises a` jour automatiquement a` chaque nouvelle entreÂ´e ; au besoin, cliquez
sur le bouton calculer.
cÂ© Revue MODULAD, 2006 -157- NumeÂ´ro 35
Mais cette distribution initiale ne laissait â€œaucune chanceâ€ aux donneÂ´es dâ€™infirmer
lâ€™opinion a priori, puisque meË†me si on observait 59 succe`s et 0 erreur, on aurait quand
meË†me
Pr(Ï• < 0.70) | a = 59) = 0.99999995
La seconde permet une conclusion beaucoup moins deÂ´favorable a` la meÂ´thode dâ€™ensei-
gnement, comme le montre la figure suivante
LeB-A-BayeÂ´sien
Dans la configuration de la figure preÂ´ceÂ´dente, activez le deuxie`me bouton dâ€™option de la
colonne une seule distribution et entrez les les parame`tres de la distribution initiale
(voir la figure ci-dessus) :
â€¢ pour 1 : 98
â€¢ pour 0 : 2
mais les donneÂ´es ne permettent cependant pas de conclure a` son efficaciteÂ´
Pr(Ï• > 0.70 | a = 32) = 0.997 mais Pr(Ï• > 0.85 | a = 32) = 0.143
cÂ© Revue MODULAD, 2006 -158- NumeÂ´ro 35
Il est eÂ´clairant dâ€™examiner lâ€™effet de la distribution initiale BeË†ta (a0, b0) sur la moyenne
de la distribution finale. En posant n0 = a0 + b0, les rapports n0/(n0 + n) et n/(n0 + n)
repreÂ´sentent les poids relatifs de la distribution initiale et des donneÂ´es. La moyenne finale
peut eË†tre eÂ´crite sous la forme
a0 + a
n0 + n
=
n0
n0 + n
Ã— a0
n0
+
n
n0 + n
Ã— a
n
Elle est donc eÂ´gale a`
â€œpoids relatif de lâ€™initiale Ã— moyenne initiale + poids relatif des donneÂ´es Ã— moyenne observeÂ´eâ€
soit ici les moyenne finales
100/159Ã— 0.200 + 59/159Ã— 0.542 = 0.327 pour la distribution initiale Ï• âˆ¼ Î²(20, 80)
100/159Ã— 0.980 + 59/159Ã— 0.542 = 0.818 pour la distribution initiale Ï• âˆ¼ Î²(98, 2)
MeÂ´langes de densiteÂ´s BeË†ta
Une technique qui reste simple de mise en Å“uvre est dâ€™utiliser une distribution initiale
dont la densiteÂ´ est un meÂ´lange de densiteÂ´s de distributions BeË†ta, la distribution finale
eÂ´tant encore un tel meÂ´lange.
Ceci peut avoir deux inteÂ´reË†ts, dâ€™une part approcher une distribution initiale com-
plexe quelconque qui neÂ´cessiterait le recours a` des meÂ´thodes dâ€™inteÂ´gration numeÂ´rique,
dâ€™autre part combiner diffeÂ´rentes sources dâ€™informations (ou diffeÂ´rentes opinions). A titre
dâ€™illustration, consideÂ´rons pour les meË†mes donneÂ´es un meÂ´lange des deux distributions
preÂ´ceÂ´dentes avec des poids eÂ´gaux, soit
Ï• âˆ¼ 1/2BeË†ta (20, 80)âŠ• 1/2BeË†ta (98, 2)
ou` âŠ• signifie que câ€™est la densiteÂ´ de Ï• qui est un meÂ´lange, soit symboliquement
p(Ï•) = 1/2 p
(
BeË†ta (20, 80)
)
+ 1/2 p
(
BeË†ta (98, 2)
)
Cette distribution ne doit pas eË†tre confondue avec celle dâ€™une combinaison lineÂ´aire de deux
variables ayant des distributions BeË†ta indeÂ´pendantes (qui aurait une densiteÂ´ beaucoup
plus complexe).
La figure ci-apre`s montre la distribution initiale correspondante (en noir), qui est
bimodale, et la distribution finale (en rouge) ; celle-ci peut eË†tre compareÂ´e a` la distribution
finale objective (en bleu).
LeB-A-BayeÂ´sien
Dans la configuration de la figure preÂ´ceÂ´dente, activez maintenant le bouton dâ€™option
meÂ´lange de densiteÂ´s BeË†ta pour obtenir la figure ci-apre`s.
cÂ© Revue MODULAD, 2006 -159- NumeÂ´ro 35
En fait, dans ce cas, les donneÂ´es n = 59, a = 32 permettent en quelque sorte de
trancher entre les deux distributions du meÂ´lange puisque la distribution finale est
0.999999903BeË†ta (52, 107)âŠ• 0.000000097BeË†ta (130, 29)
de sorte quâ€™elle est virtuellement confondue avec la distribution BeË†ta (52, 107) associeÂ´e a`
la distribution initiale BeË†ta (20, 80) consideÂ´reÂ´e preÂ´ceÂ´demment.
Avec 10 fois plus de donneÂ´es, et la meË†me proportion observeÂ´e de succe`s (n = 590,
a = 320), la distribution finale, que lâ€™on peut voir sur la figure suivante serait prati-
quement indiscernable de la distribution BeË†ta (340, 350) associeÂ´e a` la distribution initiale
BeË†ta (20, 80), mais elle se rapprocherait bien entendu de la solution objective.
LeB-A-BayeÂ´sien
Dans la configuration de la figure preÂ´ceÂ´dente, modifiez les donneÂ´es :
â€¢ pour 1 : 320
â€¢ pour 0 : 270
Un autre exemple de meÂ´langes
Lee (2004, page 59) donne un exemple sans doute plus reÂ´aliste dâ€™utilisation de meÂ´langes.
Cet exemple est emprunteÂ´ a` Diaconis et Ylvisaker (1985). On part de la constatation sui-
vante : quand on lance en lâ€™air un grand nombre de fois une pie`ce de monnaie, on obtient
approximativement une proportion 1/2 de Face, mais lorsquâ€™on la fait tourner sur elle
meË†me on obtient des proportions telles que 1/3 ou 2/3. Admettant ce reÂ´sultat, on peut
consideÂ´rer quâ€™un meÂ´lange de deux densiteÂ´s de distributions BeË†ta de moyennes respectives
1/3 et 2/3 est un choix approprieÂ´ pour la distribution initiale de la proportion Ï• de Face,
soit par exemple
Ï• âˆ¼ 1/2BeË†ta (10, 20)âŠ• 1/2BeË†ta (20, 10)
Si pour une pie`ce donneÂ´e on fait n = 10 essais et si on observe a = 3 Face, la distribution
finale est
115
129
BeË†ta (13, 27)âŠ• 14
129
BeË†ta (23, 17)
Elle a pour moyenne 0.352 et donne un intervalle de creÂ´dibiliteÂ´ 95%
[0.194, 0.633]
Pour comparaison, la distribution finale objective a pour moyenne 0.318 avec un intervalle
de creÂ´dibiliteÂ´ 95%
[0.093, 0.606]
Si on fait n = 100 essais et si on observe a = 30 Face, la distribution finale (de moyenne
0.308) est
cÂ© Revue MODULAD, 2006 -160- NumeÂ´ro 35
Ï• âˆ¼ 0.9984BeË†ta (40, 90)âŠ• 0.0016BeË†ta (50, 80)
Lâ€™intervalle de creÂ´dibiliteÂ´ 95% est
[0.232, 0.390]
qui est bien entendu dans ce cas beaucoup plus proche de celui obtenu pour la solution
objective
[0.217, 0.395]
On peut choisir des poids diffeÂ´rents ou encore faire intervenir dans le meÂ´lange une
troisie`me distribution BeË†ta de moyenne 1/2, etc.
5.5.4 Remarques
InterpreÂ´tation des poids du meÂ´lange a` partir des probabiliteÂ´s preÂ´dictives
Le poid associeÂ´ a` une distribution BeË†ta du meÂ´lange final est proportionnel au produit
du poids initial par la probabiliteÂ´ preÂ´dictive associeÂ´e a` la distribution initiale BeË†ta cor-
respondante. Reprenons lâ€™exemple preÂ´ceÂ´dent dâ€™une distribution initiale 1/2BeË†ta (10, 20)âŠ•
1/2BeË†ta (20, 10) avec les observations n = 10 et a = 3. Les probabiliteÂ´s preÂ´dictives dâ€™ob-
server a = 3 sont respectivement
Pr(a = 3) = 0.227632 pour la distribution initiale BeË†ta (10, 20)
Pr(a = 3) = 0.027712 pour la distribution initiale BeË†ta (20, 10)
Les poids du meÂ´lange finale sont proportionnels a` 1/2 Ã— 0.227632 et 1/2 Ã— 0.027712 et on
veÂ´rifie que
0.227632
0.227632 + 0.027712
=
115
129
et
0.027712
0.227632 + 0.027712
=
14
129
Mode`le binomial neÂ´gatif
Les meË†mes proceÂ´dures pour les parame`tres â€“ faisant intervenir des distributions BeË†ta
ou des meÂ´langes â€“ sâ€™appliquent au mode`le binomial neÂ´gatif dans lequel on arreË†te lâ€™expeÂ´rience
quand on a observeÂ´ un nombre fixeÂ´ a` lâ€™avance de succe`s ou dâ€™eÂ´checs (eÂ´chantillonnage de
Pascal), lâ€™effectif n eÂ´tant une variable aleÂ´atoire. On notera toutefois que la distribution
initiale de Jeffreys est diffeÂ´rente (voir lâ€™annexe A). La distribution dâ€™eÂ´chantillonnage eÂ´tant
diffeÂ´rente, la distribution preÂ´dictive est donc eÂ´galement diffeÂ´rente ; il sâ€™agit dans ce cas
dâ€™une distribution BeË†ta-Pascal.
5.6 Le facteur de Bayes
Pour compleÂ´ter la preÂ´sentation de cet exemple, jâ€™introduirai le facteur de Bayes , meË†me
si lâ€™utilisation de celui-ci rele`ve davantage dâ€™une approche deÂ´cisionnelle et pourra donc
apparaË†Ä±tre plus approprieÂ´e dans dâ€™autres contextes.
Reprenons encore, pour lâ€™expeÂ´rience sur la meÂ´thode dâ€™enseignement, lâ€™exemple des
donneÂ´es n = 59, a = 32, avec la distribution initiale enthousiaste Ï• âˆ¼ Î²(98, 2) et les
probabiliteÂ´s a priori Pr(Ï• > 0.85) = 0.99999810 (quâ€™on notera pi1) et donc Pr(Ï• <
0.85) = 0.00000190 (pi0). Les notations pi0 et pi1 sont usuelles car le facteur de Bayes est
geÂ´neÂ´ralement preÂ´senteÂ´ comme une approche bayeÂ´sienne au tests dâ€™hypothe`ses classiques ;
cÂ© Revue MODULAD, 2006 -161- NumeÂ´ro 35
dans ce cadre, pi0 et pi1 sont les probabiliteÂ´s de lâ€™hypothe`se nulle H0 et de lâ€™hypothe`se
alternative H1.
Il apparaË†Ä±t alors assez naturel de consideÂ´rer :
â€¢ le rapport de ces deux probabiliteÂ´s a priori, soit
pi0
pi1
=
Pr(Ï• < 0.85)
Pr(Ï• > 0.85)
= 0.0000019
qui est eÂ´videmment ici tre`s faible ;
â€¢ et leur rapport a posteriori, soit
p0
p1
=
Pr(Ï• < 0.85 | a = 32)
Pr(Ï• > 0.85 | a = 32) =
0.8570
0.1430
= 5.99
qui est maintenant nettement supeÂ´rieur a` 1.
On deÂ´finira alors le facteur de Bayes (associeÂ´ a` lâ€™observation a) comme le rapport de
ces deux rapports
B(a) =
p0/p1
pi0/pi1
=
p0pi1
p1pi0
= 3154 986
ce qui â€œeÂ´value donc la modification de la vraisemblance relative de lâ€™hypothe`se nulle qui
est due aux observationsâ€ (Robert, 1992, page 166). Mais ceci nâ€™est eÂ´videmment quâ€™un
reÂ´sumeÂ´ incomplet, qui ne peut remplacer lâ€™information fournie par les probabiliteÂ´s finales.
Le facteur de Bayes sâ€™applique de la meË†me manie`re a` des hypothe`ses H0 et H1 â€œnon
compleÂ´mentairesâ€, par exemple ici Ï• < 0.70 et Ï• > 0.85 ; mais lâ€™interpreÂ´tation est encore
plus probleÂ´matique puisquâ€™on ignore la zone de â€œnon conclusionâ€ 0.70 < Ï• < 0.85.
Dans le cas particulier ou` H0 et H1 sont des hypothe`ses simples Ï• = Ï•0 et Ï• = Ï•1, le
facteur de Bayes est simplement le classique rapport de vraisemblance
B(a) =
p(Ï•0 | a) p(Ï•1)
p(Ï•1 | a) p(Ï•0) =
p(a |Ï•0)
p(a |Ï•1)
puisque p(Ï•0 | a) âˆ p(a |Ï•0) p(Ï•0) et p(Ï•1 | a) âˆ p(a |Ï•1) p(Ï•1).
On notera encore que dans le cas ou` H0 et H1 sont des hypothe`ses â€œcompleÂ´mentairesâ€
(donc p1 = 1âˆ’ p0), comme dans lâ€™exemple preÂ´ceÂ´dent, on peut retrouver leurs probabiliteÂ´s
finales a` partir des probabiliteÂ´s initiales (pi1 = 1âˆ’ pi0) et du rapport de Bayes, puisquâ€™on
veÂ´rifie facilement que
1
p0
= 1 +
1âˆ’ pi0
pi0
1
B(a)
Pour une discussion de lâ€™utilisation du facteur de Bayes en liaison avec la probleÂ´matique
des tests dâ€™hypothe`ses, on pourra consulter Robert (1992, pages 166-168).
6 Comparaison de deux proportions
Conceptuellement, les solutions preÂ´ceÂ´dentes pour une proportion sâ€™eÂ´tendent immeÂ´diatement
a` deux eÂ´chantillons binomiaux indeÂ´pendants, pourvu que les distributions initiales soient
eÂ´galement indeÂ´pendantes (Lecoutre, Grouin & Derzko, 1995). Nous illustrerons ces so-
lutions a` partir dâ€™un mode`le plus complexe, qui conduit au meË†mes proceÂ´dures pour les
parame`tres et permet dâ€™illustrer la souplesse de lâ€™approche bayeÂ´sienne.
cÂ© Revue MODULAD, 2006 -162- NumeÂ´ro 35
6.1 Le proble`me : Re`gle dâ€™expeÂ´rimentation â€œrejouez le gagnantâ€
Pour comparer deux traitements, dans le plan dâ€™expeÂ´rience usuel â€œen groupes indeÂ´pen-
dantsâ€ les sujets sont affecteÂ´s par tirage au sort a` chacun des deux traitements. Ceci
conduit a` deux groupes dâ€™effectifs eÂ´gaux (en contraignant un peu le tirage au sort). Pour
des consideÂ´rations eÂ´thiques, on peut preÂ´feÂ´rer un plan permettant dâ€™attribuer le â€œmeilleurâ€
traitement un plus grand nombre de fois. Comme on ne sait pas a priori de quel traite-
ment il sâ€™agit ou quâ€™on ne veut pas faire intervenir une eÂ´ventuelle connaissance dans la
planification de lâ€™expeÂ´rience, on peut utiliser une re`gle approprieÂ´e baseÂ´e sur un processus
seÂ´quentiel. Ainsi la re`gle â€œrejouez le gagnantâ€ (play-the-winner), deÂ´crite ci-apre`s, reÂ´pond
a` cet objectif (Zelen, 1969).
Le premier sujet recÂ¸oit lâ€™un des deux traitements, t1 ou t2, avec des probabiliteÂ´s
eÂ´gales. Ensuite, si le sujet k âˆ’ 1 a recÂ¸u un traitement t dont le reÂ´sultat est
un â€œsucce`sâ€, le sujet suivant k recÂ¸oit le meË†me traitement ; si au contraire le
reÂ´sultat est â€œun eÂ´checâ€, le sujet k recÂ¸oit lâ€™autre traitement.
La re`gle preÂ´suppose que le reÂ´sultat du sujet kâˆ’1 est connu quand le sujet k est inclus,
mais elle pourrait eË†tre eÂ´tendue pour tenir compte du cas ou` la reÂ´ponse est diffeÂ´reÂ´e. En
deÂ´pit de son deÂ´terminisme apparent, cette re`gle est un processus stochastique, puisquâ€™elle
deÂ´pend des probabiliteÂ´s de succe`s Ï•1 et Ï•2 de chacun des traitements.
Pour un total, supposeÂ´ fixeÂ´ a` lâ€™avance, de n sujets, la seÂ´quence des traitement attribueÂ´s
(t1, t2 . . . tk, tk+1 . . . tn+1) contient toute lâ€™information des donneÂ´es. En effet tk+1 = tk
implique quâ€™on a observeÂ´ un succe`s a` tk, tandis que tk+1 6= tk implique quâ€™on a observeÂ´
un eÂ´chec a` tk. La fonction de vraisemblance est donc simplement
v(Ï•1, Ï•2)|(t1, . . . tn+1) = 1/2Ï•n111 (1âˆ’ Ï•1)n10Ï•n212 (1âˆ’ Ï•2)n20
ou` ni1 (i = 1, 2) est le nombre de paires (tk, tk+1) eÂ´gales a` (t
i, ti), de sorte que n11 et n21
sont les nombres respectifs de succe`s aux traitements t1 et t2 ; ni0 est le nombre de paires
(tk, tk+1) eÂ´gales a` (t
i, tj), avec j 6= i, de sorte que n10 et n20 sont les nombres dâ€™eÂ´checs ; 1/2
est la probabiliteÂ´ de t1.
On peut voir que la fonction de vraisemblance est proportionnelle au produit des
fonctions de vraisemblance associeÂ´es a` chacun de deux eÂ´chantillons binomiaux, dâ€™effectifs
respectifs n11 + n10 et n21 + n20 et de parame`tres Ï•1 et Ï•2. Elle est donc identique â€“ a`
une constante multiplicative pre`s â€“ a` celle associeÂ´e a` la comparaison de deux proportions
binomiales indeÂ´pendantes. Cependant, ici seul n = n11+n10+n21+n20 est fixeÂ´, alors que
pour deux eÂ´chantillons binomiaux n11 + n10 et nn21 + n20 sont tous les deux fixeÂ´s.
6.2 Solutions freÂ´quentistes
Alors que, comme nous le verrons, les proceÂ´dures bayeÂ´siennes sont les meË†mes que pour
deux eÂ´chantillons binomiaux indeÂ´pendantes, les proceÂ´dures freÂ´quentistes sont diffeÂ´rentes.
En effet, meË†me si les fonctions de vraisemblance sont proportionnelles, les probabiliteÂ´s
dâ€™obtenir n11 succe`s au traitement t1 et n21 succe`s au traitement t2 avec la re`gle â€œrejouez le
gagnantâ€ sont donneÂ´es par des distributions beaucoup plus complexes que la distribution
Binomiale, qui en outre ne sont bien entendu pas indeÂ´pendantes. En raison de cette
complexification, seules des proceÂ´dures asymptotiques ont eÂ´teÂ´ proposeÂ´es ; elles ne sont
gue`re satisfaisantes en dehors dâ€™eÂ´chantillons dâ€™effectif eÂ´leveÂ´.
cÂ© Revue MODULAD, 2006 -163- NumeÂ´ro 35
6.3 Solution bayeÂ´sienne
Dans le cadre bayeÂ´sien au contraire, puisque leurs fonctions de vraisemblance sont
proportionnelles, les proceÂ´dures sur les parame`tres sont les meË†mes pour les deux mode`les,
bien que les probabiliteÂ´s dâ€™eÂ´chantillonnage soient tre`s diffeÂ´rentes. Une solution simple et
usuelle suppose deux distributions initiales BeË†ta indeÂ´pendantes pour Ï•1 et Ï•2, respecti-
vement :
Ï•1 âˆ¼ BeË†ta (Î½11, Î½10) et Ï•2 âˆ¼ BeË†ta (Î½21, Î½20)
Les distributions finales marginales sont encore deux distributions BeË†ta indeÂ´pendantes :
Ï•1 | (t1, . . . tn+1) âˆ¼ BeË†ta (Î½11+n11, Î½10+n10) et Ï•2 | (t1, . . . tn+1) âˆ¼ BeË†ta (Î½21+n21, Î½20+n20)
6.3.1 Exemple numeÂ´rique
ConsideÂ´rons a` titre dâ€™illustration les reÂ´sultats suivants pour une expeÂ´rience avec n =
150 sujets. On remarquera que, par deÂ´finition de la re`gle, les nombres dâ€™eÂ´checs (ici 20 et
21) ne peuvent diffeÂ´rer que dâ€™au plus une uniteÂ´.
succe`s eÂ´checs
traitement t1 n11 = 74 n10 = 20 94
traitement t2 n21 = 35 n20 = 21 56
109 41 150
6.3.2 La simpliciteÂ´ conceptuelle des meÂ´thodes bayeÂ´siennes objectives
Un eÂ´nonceÂ´ de probabiliteÂ´ conjoint est, dans un sens, le meilleur reÂ´sumeÂ´ de la distri-
bution finale. Si nous adoptons la distribution initiale de Jeffreys (Î½11 = Î½10 = Î½21 =
Î½20 = 1/2), nous obtenons par exemple la probabiliteÂ´ finale conjointe (en omettant le
conditionnement par les donneÂ´es pour simplifier lâ€™eÂ´criture) :
Pr(Ï•1 > 0.697 et Ï•2 < 0.743) = 0.95
qui se deÂ´duit de
Pr(Ï•1 > 0.697) = Pr(Ï•2 > 0.743) =
âˆš
0.95 = 0.974679
(obtenues comme dans le cas de lâ€™infeÂ´rence sur une proportion) en utilisant lâ€™indeÂ´pendance
des deux distributions finales
Ï•1 âˆ¼ BeË†ta (74.5, 20.5) et Ï•2 âˆ¼ BeË†ta (35.5, 21.5)
Cependant nous pouvons preÂ´feÂ´rer un eÂ´nonceÂ´ qui permet de comparer directement les
deux traitements. Ainsi nous avons
Pr(Ï•1 > Ï•2) = 0.984
De plus il est facile de consideÂ´rer les principaux crite`res classiques pour comparer deux
proportions (diffeÂ´rence, rapport, etc.). Dans le cadre freÂ´quentiste, chacun de ces crite`res
neÂ´cessite des proceÂ´dures diffeÂ´rentes. On sait en outre que dans le cas de deux eÂ´chantillons
binomiaux indeÂ´pendants il existe pour chacun dâ€™eux une pleÂ´thore de proceÂ´dures6.
6De nouvelles proceÂ´dures sont en outre reÂ´gulie`rement proposeÂ´es. Certaines dâ€™entre elles reÂ´servent
dâ€™ailleurs des surprises. Câ€™est par exemple le cas des â€œnew confidence intervalsâ€ deÂ´veloppeÂ´s par Zhou et
Qin (2004, 2005). Pour lâ€™exemple dâ€™effectifs observeÂ´s pour deux groupoes indeÂ´pendants (2,8) et (1,35),
les auteurs (Zhou & Qin, 2004, pages 108-109) donnent pour la diffeÂ´rence Ï•1 âˆ’Ï•2 (avec les notations
cÂ© Revue MODULAD, 2006 -164- NumeÂ´ro 35
De meË†me quâ€™il existe une correspondance entre le seuil observeÂ´ du test binomial et la
probabiliteÂ´ bayeÂ´sienne finale pour une distribution initiale approprieÂ´e, on trouve eÂ´galement
dans ce cas un lien avec les tests conditionnels de Fisher. Ceci sera illustreÂ´ plus loin a`
propos dâ€™une autre situation. Mais bien entendu ces proceÂ´dures freÂ´quentistes ne seraient
pas applicables ici puisque la distribution dâ€™eÂ´chantillonnage nâ€™est pas la meË†me.
Au contraire la solution bayeÂ´sienne est conceptuellement immeÂ´diate. En effet la dis-
tribution de nâ€™importe quel parame`tre deÂ´riveÂ´ peut eË†tre obtenue a` partir de la distribution
finale conjointe7. Le proble`me est seulement technique : il faut en geÂ´neÂ´ral recourir a` des
meÂ´thodes dâ€™inteÂ´gration numeÂ´rique. Par exemple nous trouvons les intervalles de credibiliteÂ´
95% (a` â€œqueues eÂ´galesâ€)
[+0.013,+0.312] pour Ï•1 âˆ’ Ï•2
[1.02, 1.62] pour Ï•1
Ï•2
[1.07, 4.64] pour Ï•1/(1âˆ’Ï•1)
Ï•2/(1âˆ’Ï•2)
LesProportions
Dans LePAC activez le menu LesBayeÂ´siens et le sous-menu LesProportions, ce qui af-
fiche la feneË†tre pour lâ€™infeÂ´rence sur des proportions. Activez le bouton dâ€™option 2 groupes
indeÂ´pendants. Entrez dans les champs approprieÂ´s les effectifs :
â€¢ pour g1 : 74 et 20
â€¢ pour g2 : 35 et 21
Entrez sâ€™il y a lieu les parame`tres de la distribution initiale beË†ta â€“ soit dans chaque cas
1/2 (mais câ€™est en principe inutile car câ€™est lâ€™option par deÂ´faut).
SeÂ´lectionnez les boutons dâ€™option
â€¢ Î´ = Ï•1âˆ’ Ï•2
â€¢ <X<
â€¢ probabiliteÂ´
Entrez dans le champ probabiliteÂ´ : 0.95 pour obtenir la figure ci-apre`s (avec 3 deÂ´cimales
pour la limite).
utiliseÂ´es ici) les intervalles de confiance 95% : [+0.005, +0.516] (pour leur â€œdirect Edgeworth expansion
methodâ€) et [âˆ’0.024, +0.544] (pour leur â€œtransformation methodâ€). Si on a la curiositeÂ´ de calculer ces
meË†mes intervalles pour la diffeÂ´rence opposeÂ´e Ï•2âˆ’Ï•1, on a la surprise de ne pas trouver des intervalles
symeÂ´triques, mais au contraire des intervalles largement diffeÂ´rents : respectivement [âˆ’0.373, +0.138]
et [âˆ’0.401, +0.171] (Lecoutre & Faure, 2005). Les auteurs reÂ´pondent que leur proceÂ´dure peut eË†tre
modifieÂ´e pour reÂ´soudre ce proble`me (Zhou & Qin, 2007), mais cela ne fait que renforcer lâ€™impression
dâ€™â€œad hocquerieâ€ des meÂ´thodes freÂ´quentistes
7â€œReference priorsâ€. Bernardo (1979) et Berger et Bernardo (1992) ont deÂ´veloppeÂ´ sous cette appella-
tion des distributions initiales qui visent a` fournir la distribution objective optimale pour un parame`tre
deÂ´riveÂ´ Î¸, quand celui-ci est le parame`tre dâ€™inteÂ´reË†t. Elles peuvent eË†tre regardeÂ´es comme un raffinement
de la re`gle de Jeffreys. Cette solution preÂ´sente cependant un certain nombre dâ€™inconveÂ´nients (outre
lâ€™introduction de calculs plus complexes) : elle neÂ´cessite dâ€™utiliser des distributions initiales diffeÂ´rentes
pour chaque parame`tre auquel on peut sâ€™inteÂ´resser et, surtout, en cherchant a` retrouver certaines
proprieÂ´teÂ´s des proceÂ´dures freÂ´quentistes, elles peuvent confeÂ´rer aux proceÂ´dures bayeÂ´siennes des pro-
prieÂ´teÂ´s indeÂ´sirables de ces proceÂ´dures freÂ´quentistes. On notera dâ€™ailleurs que, bien que preÂ´conisant ces
â€œreference priorsâ€, Berger (2004) dans une illustration pratique des meÂ´thodes bayeÂ´siennes subjectives
(diagnostic meÂ´dical, qui est traiteÂ´ dans la section suivante) sâ€™en tient a` la solution de Jeffreys
cÂ© Revue MODULAD, 2006 -165- NumeÂ´ro 35
On a bien entendu
Pr(Ï•1 âˆ’ Ï•2 > 0) = Pr(Ï•1
Ï•2
> 1) = Pr
(Ï•1/(1âˆ’ Ï•1)
Ï•2/(1âˆ’ Ï•2) > 1
)
= Pr(Ï•1 > Ï•2) = 0.984
Par sa souplesse, lâ€™approche bayeÂ´sienne est aussi bien approprieÂ´e pour un objectif clai-
rement deÂ´cisionnel (notamment seÂ´lectionner le meilleur traitement) que pour lâ€™estimation
(par exemple appreÂ´cier la diffeÂ´rence dâ€™efficaciteÂ´ entre les deux traitements).
Comme dans le cas dâ€™une proportion, pour la distribution initiale de Jeffreys les
meÂ´thodes bayeÂ´siennes ont de tre`s bonnes proprieÂ´teÂ´s freÂ´quentistes de couverture (Lecoutre
& ElQasyr, 2005).
Comme pour une proportion, les proceÂ´dures preÂ´dictives fournissent des solutions pour
choisir les effectifs ou prendre une deÂ´cision dâ€™arreË†ter lâ€™expeÂ´rience avant son terme. Dans
le cas de deux eÂ´chantillons binomiaux indeÂ´pendants, les solutions sont une extension
immeÂ´diate, les distributions preÂ´dictives pour deux eÂ´chantillons futurs eÂ´tant des distribu-
tions BeË†ta-Binomiales indeÂ´pendantes ; elles sont illustreÂ´e dans Lecoutre, Derzko et Grouin
(1995). Dans le cas de la re`gle â€œrejouez le gagnantâ€, les techniques sont les meË†mes, mais
les distributions dâ€™eÂ´chantillonnage eÂ´tant diffeÂ´rentes, les distributions preÂ´dictives sont bien
entendu diffeÂ´rentes (ElQasyr, 2006).
7 Une geÂ´neÂ´ralisation du mode`le binomial avec trois
proportions
7.1 Le proble`me : Diagnostic meÂ´dical
Mossman & Berger (2001) donnent lâ€™exemple du diagnostic dâ€™une maladie M .
cÂ© Revue MODULAD, 2006 -166- NumeÂ´ro 35
On conside`re une population pour laquelle la probabiliteÂ´ de la maladie est Ï•0.
On utilise un test de diagnostic qui est positif [+] avec une probabiliteÂ´ Ï•1 si le
patient a la maladie et avec une probabiliteÂ´ Ï•2 si le patient nâ€™a pas la maladie
Pr(M) = Ï•0 Pr(+|M) = Ï•1 Pr(+|Â¬M) = Ï•2
On en deÂ´duit par le theÂ´ore`me de Bayes la probabiliteÂ´ Î¸ que le patient ait la maladie
sachant que le test est positif
Pr(M |+) = Pr(+|M)Pr(M)
Pr(+|M)Pr(M) + Pr(+|Â¬M)Pr(Â¬M) =
Ï•1Ï•0
Ï•1Ï•0 + Ï•2(1âˆ’ Ï•0) = Î¸
GeÂ´neÂ´ralisant encore la situation de lâ€™infeÂ´rence sur une proportion binomiale, on sup-
pose que lâ€™on dispose de donneÂ´es indeÂ´pendantes ai (i=0,1,2) ayant chacune une distribu-
tion Binomiale
ai|Ï•i âˆ¼ Bin(Ï•i, ni)
7.2 Solutions freÂ´quentistes
Une des motivations des auteurs eÂ´tait que les approches freÂ´quentistes preÂ´ceÂ´demment
deÂ´veloppeÂ´es eÂ´taient, soit difficiles a` appliquer, soit relativement peu performantes.
7.3 Solution bayeÂ´sienne
Au contraire la solution bayeÂ´sienne utilisant trois distribution initiales BeË†ta indeÂ´pendantes
pour les Ï•i est conceptuellement tre`s simple. Câ€™est une geÂ´neÂ´ralisation immeÂ´diate de
lâ€™infeÂ´rence sur deux proportions binomiales. En particulier, pour la solution non infor-
mative de Jeffreys (trois distributions Ï•i âˆ¼ BeË†ta (1/2, 1/2) indeÂ´pendantes), la proceÂ´dure est
tre`s performante dâ€™un point de vue freÂ´quentiste.
â€œA great frequentist confidence procedureâ€ (Berger, 2004)
On peut ainsi conclure ironiquement avec Berger que cette proceÂ´dure est une â€œgrande
proceÂ´dure de confiance freÂ´quentisteâ€. De la distribution finale conjointe (encore trois dis-
tributions BeË†ta indeÂ´pendantes), on deÂ´duit facilement par une meÂ´thode numeÂ´rique un
intervalle de creÂ´dibiliteÂ´ pour Î¸.
Ce proble`me a eÂ´galement eÂ´teÂ´ traiteÂ´, dans un contexte diffeÂ´rent, par Zaykin, Meng et
Ghosh (2004). Ceux-ci conside`rent, outre la solution preÂ´ceÂ´dente, le cas le plus simple ou`
Ï•0 est une valeur donneÂ´e, ainsi que le cas ou` la distribution de Ï•0 est une distribution
uniforme sur un intervalle fixeÂ´ a priori (non reÂ´viseÂ´e par les donneÂ´es).
7.3.1 Exemple numeÂ´rique
ConsideÂ´rons les donneÂ´es suivantes (Mosmann et Berger, 2001, page 505)
n0 = 30 a0 = 7 n1 = 20 a1 = 17 n2 = 40 a2 = 1
Pour la meÂ´thode bayeÂ´sienne objective (Jeffreys), on obtient les distributions finales indeÂ´pendantes
Ï•0 Ï•1 Ï•2
BeË†ta (7.5, 23.5) BeË†ta (17.5, 3.5) BeË†ta (1.5, 39.5)
cÂ© Revue MODULAD, 2006 -167- NumeÂ´ro 35
Conditionnellement a` Ï•0, en remarquant que
Î¸ =
1
1 + 1âˆ’Ï•0
Ï•0
Ï•2
Ï•1
on voit que le proble`me se rame`ne a` lâ€™infeÂ´rence traiteÂ´e sur le rapport de deux proportions
binomiales indeÂ´pendantes traiteÂ´e dans la section preÂ´ceÂ´dente. On a par exemple
Pr(Î¸ < u |Ï•0) = Pr
(Ï•2
Ï•1
>
1âˆ’ Ï•0
Ï•0
1âˆ’ u
u
)
On obtient ainsi les intervalles pour diffeÂ´rentes valeurs fixeÂ´es de Ï•0, par exemple
Ï•0 = 0.15 Ï•0 = 0.20 Ï•0 = 0.25 Ï•0 = 0.30
[0.569, 0.982] [0.647, 0.987] [0.710, 0.990] [0.759, 0.992]
LesProportions
Dans LePAC activez le menu LesBayeÂ´siens et le sous-menu LesProportions, ce qui af-
fiche la feneË†tre pour lâ€™infeÂ´rence sur des proportions. Activez le bouton dâ€™option 2 groupes
indeÂ´pendants. Entrez dans les champs approprieÂ´s les effectifs :
â€¢ pour g1 : 17 et 3
â€¢ pour g2 : 1 et 39
Entrez sâ€™il y a lieu les parame`tres de la distribution initiale beË†ta â€“ soit dans chaque cas
1/2 (mais câ€™est en principe inutile car câ€™est lâ€™option par deÂ´faut).
SeÂ´lectionnez les boutons dâ€™option
â€¢ Ï‘[Ï•0] = Ï•0Ï•1/[Ï•0Ï•1 + (1âˆ’ Ï•0Ï•2]
et entrez la valeur pour Ï•0 : 0.20
â€¢ <X<
â€¢ probabiliteÂ´
Entrez dans le champ probabiliteÂ´ : 0.95 pour obtenir la figure ci-apre`s (avec 3 deÂ´cimales
pour la limite).
cÂ© Revue MODULAD, 2006 -168- NumeÂ´ro 35
La distribution finale de Î¸ est un meÂ´lange des distributions conditionnelles a` Ï•0. On
peut lâ€™obtenir par simulation. En simulant un eÂ´chantillon de 100 000 valeurs du triplet
(Ï•0, Ï•1, Ï•2) et par suite de Î¸, jâ€™ai obtenu lâ€™intervalle de creÂ´dibiliteÂ´ 95% (Mossman et
Berger avaient trouveÂ´ [0.633, 0.990])
[0.632, 0.990]
RemplacÂ¸ons maintenant la distribution finale de Ï•0 par la distribution uniforme sur
lâ€™intervalle [0.111, 0.404], qui est lâ€™intervalle de creÂ´dibiliteÂ´ 95% pour Ï•0 obtenu pour la
distribution finale preÂ´ceÂ´dente BeË†ta (7.5, 23.5). On obtient alors, toujours pour 100 000
simulations, lâ€™intervalle reÂ´ellement tre`s proche
[0.632, 0.991]
On peut eÂ´galement constater que conditionnellement a` Ï•0 = 0.20 â€“ qui est approxi-
mativement la moyenne 0.1974 de la distribution BeË†ta (7.5, 23.5) â€“ lâ€™intervalle obtenu
[0.647, 0.987] est encore proche des preÂ´ceÂ´dents.
8 Un mode`le multinomial pour un tableau 2Ã— 2
8.1 Le proble`me : Etude dâ€™un mode`le logique
ConsideÂ´rons un groupe de n sujets, avec deux ensembles dâ€™attributs (ou variables)
binaires, respectivement noteÂ´s V = {v1, v0} et W = {w1, w0}. Pour fixer les ideÂ´es,
supposons que W soit le fait quâ€™un individu soit deÂ´ceÂ´deÂ´ dâ€™une maladie cardiaque et que
V soit le fait quâ€™il ait eu ou non au preÂ´alable un infarctus du myocarde. ConsideÂ´rons
lâ€™exemple suivant de â€œmode`le logiqueâ€ (Lecoutre et Charron, 2000).
cÂ© Revue MODULAD, 2006 -169- NumeÂ´ro 35
Il existe une implication absolue (ou logique) v1 â‡’ w1 (par exemple) si tous
les individus ayant la modaliteÂ´ v1 ont aussi la modaliteÂ´ w1, alors que lâ€™inverse
nâ€™est pas neÂ´cessairement vrai.
Mais lâ€™hypothe`se dâ€™une implication absolue est de peu dâ€™inteÂ´reË†t en pratique,
puisquâ€™il suffit dâ€™observer une seule fois lâ€™eÂ´veÂ´nement (v1, w0) pour la reÂ´futer.
En conseÂ´quence, nous devons consideÂ´rer lâ€™hypothe`se plus faible â€œv1 implique
dans la plupart des cas w1â€ (v1 â†ªâ†’ w1).
Le proble`me est dâ€™eÂ´valuer lâ€™eÂ´cart au mode`le logique dâ€™une implication absolue qui
preÂ´dit que â€œla case [v1, w0] est videâ€. Un indice dâ€™eÂ´cart peut eË†tre deÂ´fini a` partir des
proportions des diffeÂ´rentes cases
w1 w0
v1 Ï•11 Ï•10 Ï•1.
v0 Ï•01 Ï•00 Ï•0.
Ï•.1 Ï•.0 1
comme
Ï•10
Ï•1.Ï•.0
qui varie de 0 a` +âˆ
En fait il est plus usuel de consideÂ´rer le compleÂ´ment a` 1 de cet indice, qui sera noteÂ´
Î·v1â†ªâ†’w1 (et qui est donc a` proprement parler un indice dâ€™ajustement du mode`le)
Î·v1â†ªâ†’w1 = 1âˆ’ Ï•10
Ï•1.Ï•.0
(âˆ’âˆ < Î·v1â†ªâ†’w1 < +1)
Cet indice a eÂ´teÂ´ utiliseÂ´ dans des contextes varieÂ´s, avec diffeÂ´rentes approches. Il peut eË†tre
vu notamment comme une mesure dâ€™efficaciteÂ´ preÂ´dictive du mode`le pour preÂ´dire lâ€™issue
de W eÂ´tant donneÂ´ v1.
La preÂ´diction est parfaite (il y a une implication absolue) quand Î·v1â†ªâ†’w1 = +1.
La preÂ´diction est dâ€™autant plus efficace que Î·v1â†ªâ†’w1 est plus proche de +1.
En cas dâ€™indeÂ´pendance on a Î·v1â†ªâ†’w1 = 0.
Une valeur nulle ou neÂ´gative signifie que le mode`le est rejeteÂ´.
En conseÂ´quence, pour pouvoir conclure a` lâ€™efficaciteÂ´ preÂ´dictive du mode`le, nous de-
vons deÂ´montrer que Î·v1â†ªâ†’w1 a une valeur proche de +1. On peut deÂ´finir de la meË†me
manie`re les indices Î·v1â†ªâ†’w0, Î·w1â†ªâ†’v1 et Î·w0â†ªâ†’v0, ou encore caracteÂ´riser lâ€™eÂ´quivalence entre
deux modaliteÂ´s. Il y a eÂ´quivalence (absolue) entre v1 et w1 (par exemple) si Î·v1â†ªâ†’w1 = 1
et Î·w1â†ªâ†’v1 = 1 (â€œles cases [v1, w0] et [v0, w1] sont videsâ€) et on pourra prendre comme
indice dâ€™ajustement au mode`le dâ€™eÂ´quivalence le minimum de ces deux indices.
Nous supposons ici un mode`le dâ€™eÂ´chantillonnage multinomial, soit pour un eÂ´chantillon
dâ€™effectif n la probabiliteÂ´ dâ€™observer les effectifs nij
Pr(n11, n10, n01, n00|Ï•11, Ï•10, Ï•01, Ï•00) = n!
n11!n10!n01!n00!
Ï•n1111 Ï•
n10
10 Ï•
n01
01 Ï•
n00
00
8.2 Solutions freÂ´quentistes
Pour construire un intervalle de confiance, on a proposeÂ´ des solutions asymptotiques
(par exemple, Fleiss, 1981), qui sont manifestement inapproprieÂ´es pour les petits eÂ´chantillons.
On a eÂ´galement deÂ´veloppeÂ´ des solutions baseÂ´es sur le test conditionnel de Fisher (Copas et
cÂ© Revue MODULAD, 2006 -170- NumeÂ´ro 35
Loeber, 1990 ; Lecoutre et Charron, 2000). Ce test utilise la distribution dâ€™eÂ´chantillonnage
de n11 (par exemple). Un reÂ´sultat classique est que cette distribution n11, eÂ´tant donneÂ´
les marges observeÂ´es fixeÂ´es, deÂ´pend seulement du produit croiseÂ´ Ï = Ï•11Ï•00
Ï•10Ï•01
(voir Cox,
1970, page 4). On peut ainsi, a` partir de cette distribution, tester lâ€™hypothe`se nulle Ï = Ï0
contre lâ€™hypothe`se alternative Ï < Ï0 (ou contre Ï > Ï0) en utilisant la probabiliteÂ´ que
n11 deÂ´passe la valeur observeÂ´e (dans la direction approprieÂ´e). On a donc une proceÂ´dure
analogue au test binomial consideÂ´reÂ´ dans le cas de lâ€™infeÂ´rence sur une proportion, avec
de la meË†me manie`re la possibiliteÂ´ de deÂ´finir une solution â€œincluanteâ€ et une solution
â€œexcluanteâ€. On obtient comme cas particulier le â€œtest de permutationâ€ de Fisher pour
lâ€™hypothe`se nulle Ï = 1, câ€™est-a`-dire Î·11 = 0.
En inversant ce test conditionnel, on peut construire un intervalle de confiance pour
le produit croiseÂ´ Ï. On en deÂ´duit un intervalle pour Î·11 en remplacÂ¸ant Ï par ses limites
de confiance dans lâ€™expression suivante qui donne Î·11 en fonction de Ï
Î·11 =
1 + (Ïâˆ’ 1)(Ï•1. + Ï•.1 âˆ’ Ï•1.Ï•.1 âˆ’ [(1 + (Ï•1. + Ï•.1)(Ïâˆ’ 1)2 âˆ’ 4Ï•1.Ï•.1Ï(Ïâˆ’ 1)]1/2
2(Ïâˆ’ 1)Ï•.1(1âˆ’ Ï•1.)
Malheureusement ces limites deÂ´pendent des â€œvraiesâ€ marges Ï•.1 et Ï•1.. La proce`dure
la plus courante consiste a` simplement remplacer ces parame`tres parasites par leurs esti-
mateurs f.1 et f1.. Elle est nettement plus performante que les solutions asymptotiques,
mais nâ€™est pas satisfaisante pour des valeurs extreË†mes des parame`tres. MeË†me si on peut
trouver des principes plus efficaces pour traiter les parame`tres parasites (par exemple,
Toecher, 1950 ; Rice, 1988), on se trouve ici confronteÂ´ a` un eÂ´ternel proble`me qui est bien
entendu comple`tement eÂ´viteÂ´ par lâ€™approche bayeÂ´sienne.
8.3 Solution bayeÂ´sienne
La solution bayeÂ´sienne pour un mode`le dâ€™eÂ´chantillonnage multinomial est une geÂ´neÂ´ralisation
immeÂ´diate du cas binomial. Choisissons une distribution initiale (conjugueÂ´e) de Dirichlet,
qui est une geÂ´neÂ´ralisation multidimensionnelle de la distribution BeË†ta
(Ï•11, Ï•10, Ï•01, Ï•00) âˆ¼ Dirichlet (Î½11, Î½10, Î½01, Î½00)
La distribution finale est eÂ´galement une distribution de Dirichlet dans laquelle les poids
initiaux sont simplement ajouteÂ´s aux effectifs observeÂ´s
(Ï•11, Ï•10, Ï•01, Ï•00)|donneÂ´es âˆ¼ Dirichlet (n11 + Î½11, n10 + Î½10, n01 + Î½01, n00 + Î½00)
En utilisant les proprieÂ´teÂ´s fondamentales de la distribution de Dirichlet (voir par
exemple Bernardo & Smith, 1994, page 135), la distribution finale du parame`tre deÂ´riveÂ´
Î·11 peut eË†tre caracteÂ´riseÂ´e comme une fonction de trois distributions BeË†ta indeÂ´pendantes.
X = Ï•10 | donneÂ´es âˆ¼ BeË†ta (n10 + Î½10, n11 + Î½11 + n01 + Î½01 + n00 + Î½00)
Y =
Ï•00
1âˆ’ Ï•10 =
Ï•00
1âˆ’X | donneÂ´es âˆ¼ BeË†ta (n00 + Î½00, n11 + Î½11 + n01 + Î½01)
Z =
Ï•11
1âˆ’ Ï•10 âˆ’ Ï•00 =
Ï•11
(1âˆ’ Y )(1âˆ’X) | donneÂ´es âˆ¼ BeË†ta (n11 + Î½11, n01 + Î½01)
cÂ© Revue MODULAD, 2006 -171- NumeÂ´ro 35
puisque
Î·v1â†ªâ†’w1 = 1âˆ’ X
(X + Z(1âˆ’ Y )(1âˆ’X)) (X + Y (1âˆ’X))
nous sommes rameneÂ´s au meË†me proble`me technique que dans la situation preÂ´ceÂ´dente du
diagnostic meÂ´dical.
8.3.1 Exemple numeÂ´rique : Etude de mortaliteÂ´
ConsideÂ´rons lâ€™implication â€œInfarctus du myocarde â†ªâ†’ DeÂ´ce`s cardiaque avant deux ansâ€.
Pour des patients qui nâ€™ont subi aucun traitement meÂ´dical, on dispose des donneÂ´es sui-
vantes relatives a` 340 patients â€œa` risqueâ€
Patients non traiteÂ´s DeÂ´ce`s
oui non
Infarctus oui 20 72 92 [20/92=0.22]
du myocarde non 17 231 248 [17/248=0.07]
37 303 340
On remarquera que les proportions de deÂ´ce`s sont assez faibles (heureusement !) â€“ res-
pectivement 0.22 apre`s un infarctus et 0.07 sans infarctus â€“ de sorte que lâ€™effectif 72 dans
la case [oui,non] est en rapport eÂ´leveÂ´. En conseÂ´quence des valeurs relativement faibles de
lâ€™indice sont ici â€œcliniquement signifiantesâ€. Nous avons ici les valeurs observeÂ´es de lâ€™indice
pour lâ€™implication â€œInfarctus â†ªâ†’ DeÂ´ce`sâ€(case [oui,non] vide) : Hv1â†ªâ†’w1 = 0.12
pour lâ€™implication â€œDeÂ´ce`s â†ªâ†’ Infarctusâ€(case [non,oui] vide) : Hw1â†ªâ†’v1 = 0.37
La meÂ´thode bayeÂ´sienne objective, avec la distribution initiale de JeffreysDirichlet (1/2, 1/2, 1/2, 1/2),
donne la distribution finale
(Ï•11, Ï•10, Ï•01, Ï•00)|donneÂ´es âˆ¼ Dirichlet (20.5, 72.5, 17.5, 231.5)
ce qui conduit aux intervalles de creÂ´dibiliteÂ´ suivants
â€œInfarctus â†ªâ†’ DeÂ´ce`sâ€ : Pr(+0.06 < Î·v1â†ªâ†’w1 < +0.19) = 0.90
â€œDeÂ´ce`s â†ªâ†’ Infarctusâ€ : Pr(+0.20 < Î·w1â†ªâ†’v1 < +0.54) = 0.90
Ces intervalles permettent de conclure a` lâ€™existence dâ€™une implication dâ€™importance limiteÂ´e
et indiquent quâ€™en fait ici le deÂ´ce`s est un meilleur pronostic de lâ€™infarctus que lâ€™inverse.
LesProportions
Dans LePAC activez le menu LesBayeÂ´siens et le sous-menu LesProportions, ce qui
affiche la feneË†tre pour lâ€™infeÂ´rence sur des proportions. Activez le bouton dâ€™option LesIm-
plications. Entrez dans les champs approprieÂ´s les effectifs :
â€¢ pour v1 : 20 (w1) et 72 (w0)
â€¢ pour v0 : 17 (w1) et 231 (w0)
Entrez sâ€™il y a lieu les parame`tres de la distribution initiale beË†ta â€“ soit dans chaque cas
1/2 (mais câ€™est en principe inutile car câ€™est lâ€™option par deÂ´faut).
SeÂ´lectionnez les boutons dâ€™option
â€¢ pour lâ€™implication : v1 â†’ w1 (câ€™est lâ€™option par deÂ´faut)
â€¢ pour lâ€™eÂ´nonceÂ´ : < Î· <
â€¢ pour la courbe : Pr(X>x)
cÂ© Revue MODULAD, 2006 -172- NumeÂ´ro 35
â€¢ probabiliteÂ´
Entrez dans le champ probabiliteÂ´ : 0.90 pour obtenir la figure ci-apre`s (avec 3 deÂ´cimales
pour la limite).
On dispose eÂ´galement des donneÂ´es suivantes relatives a` 357 patients ayant recÂ¸u un
traitement meÂ´dical a` titre preÂ´ventif
Patients traiteÂ´s DeÂ´ce`s
oui non
Infarctus oui 1 78 79 [1/79=0.01]
du myocarde non 13 265 278 [13/278=0.05]
14 343 357
Dans ce cas on espe`re eÂ´videmment que le traitement va reÂ´duire le nombre de deÂ´ce`s
apre`s infarctus. IdeÂ´alement, sâ€™il nâ€™y avait aucun deÂ´ce`s cardiaque chez les patients traiteÂ´s
apre`s un infarctus (case [oui,oui] vide), on aurait lâ€™implication absolue â€œInfarctus â‡’ Non
deÂ´ce`sâ€. On obtient les reÂ´sultats suivants pour cette implication
â€œInfarctus â†ªâ†’ Non deÂ´ce`sâ€ : Hv1â†ªâ†’w0 = +0.68 et Pr(âˆ’0.10 < Î·v1â†ªâ†’w0 < +0.94) = 0.90
qui montrent quâ€™ici, en deÂ´pit dâ€™une valeur observeÂ´e nettement plus eÂ´leveÂ´e de lâ€™indice, on
ne peut pas conclure a` lâ€™existence dâ€™une implication. La grande largeur de lâ€™intervalle de
creÂ´dibiliteÂ´ indique que la preÂ´cision est mauvaise, ce qui est une conseÂ´quence des tre`s faibles
proportions de deÂ´ce`s observeÂ´es. Bien entendu, on ne peut pas non plus conclure quâ€™il nâ€™a
pas dâ€™implication ou que lâ€™implication est faible. On voit ici le danger quâ€™il y aurait a`
interpreÂ´ter le reÂ´sultat non significatif des â€œtests dâ€™indeÂ´pendanceâ€ usuels (le khi-deux par
exemple) en faveur de lâ€™hypothe`se dâ€™indeÂ´pendance.
cÂ© Revue MODULAD, 2006 -173- NumeÂ´ro 35
8.3.2 InterpreÂ´tation du seuil observeÂ´ du test de permutation de Fisher
Profitons en pour illustrer la reÂ´interpreÂ´tation bayeÂ´sienne du test de permutation
(conditionnel aux marges). Pour le test unilateÂ´ral usuel (solution â€œincluanteâ€), lâ€™hypothe`se
nulle H0 : Î·v1â†ªâ†’w0 = 0 nâ€™est pas rejeteÂ´e, le seuil observeÂ´ eÂ´tant pinc = 0.145. On sait que
ce test est conservateur ; mais si on adopte la solution â€œexcluanteâ€, on obtient un seuil
nettement plus petit pexc = 0.028, ceci eÂ´tant du a` la mauvaise preÂ´cision expeÂ´rimentale.
GeÂ´neÂ´ralisant le cas dâ€™une proportion, il existe deux distributions initiales non informatives
extreË†mes, qui donnent une interpreÂ´tation eÂ´clairante de ces seuils
Pr(Î·v1â†ªâ†’w0 < 0) = 0.145 = pinc
pour la distribution initiale Dirichlet (1, 0, 0, 1) (la plus deÂ´favorable a` H0)
soit la distribution finale Dirichlet (2, 78, 13, 266)
Pr(Î·v1â†ªâ†’w0 < 0) = 0.028 = pexc
pour la distribution initiale Dirichlet (0, 1, 1, 0) (la plus favorable a` H0)
soit la distribution finale Dirichlet (1, 79, 14, 265)
Pr(Î·v1â†ªâ†’w0 < 0) = 0.072 â‰ˆ pinc+pexc2 = 0.086
pour la distribution initiale Dirichlet (1/2, 1/2, 1/2, 1/2)
soit la distribution finale Dirichlet (1.5, 78.5, 13.5, 265.5)
LesProportions
Dans la configuration de la figure preÂ´ceÂ´dente, entrez maintenant les donneÂ´es :
â€¢ pour v1 : 1 (w1) et 78 (w0)
â€¢ pour v0 : 13 (w1) et 265 (w0)
Entrez la distribution initiale beË†ta :
â€¢ pour v1 : 1 (w1) et 0 (w0)
â€¢ pour v0 : 0 (w1) et 1 (w0)
SeÂ´lectionnez les boutons dâ€™option
â€¢ pour lâ€™implication : v1 â†’ w0
â€¢ pour lâ€™eÂ´nonceÂ´ : Î· <
â€¢ pour la courbe : Pr(X>x)
â€¢ limite
Entrez dans le champ limite : 0 pour obtenir la figure ci-apre`s (avec 3 deÂ´cimales pour la
probabiliteÂ´).
cÂ© Revue MODULAD, 2006 -174- NumeÂ´ro 35
8.3.3 Avantages de lâ€™infeÂ´rence bayeÂ´sienne
Dans toutes les situations lâ€™infeÂ´rence bayeÂ´sienne traite de manie`re explicite et per-
formante le proble`me des parame`tres parasites. Elle prend explicitement en compte les
proble`mes lieÂ´s au caracte`re discret de la distribution et a` la possibiliteÂ´ dâ€™observer des
effectifs nuls graË†ce la distribution initiale. Comme pour le cas dâ€™une seule proportion,
le choix dâ€™une distribution initiale non informative nâ€™est ni plus ni moins arbitraire ou
subjective que les conventions de lâ€™approche freÂ´quentiste.
En outre les probabiliteÂ´s de couverture des intervalles de creÂ´dibiliteÂ´ bayeÂ´siens se com-
parent favorablement a celles des intervalles de confiance freÂ´quentistes. Ainsi, une eÂ´tude de
simulation (Lecoutre & Charron, 2000) montre que les deux taux dâ€™erreurs freÂ´quentistes
associeÂ´s aux deux distributions initiales non informatives extreË†mes encadrent toujours le
taux dâ€™erreur rechercheÂ´. La meÂ´thode bayeÂ´sienne objective correspondant a` la distribu-
tion initiale symeÂ´trique intermeÂ´diaire entre ces deux extreË†mes a des proprieÂ´teÂ´s de cou-
verture remarquables. Naturellement lâ€™eÂ´cart entre ces diffeÂ´rentes distributions initiales se
reÂ´duit jusquâ€™a` disparaË†Ä±tre quand la taille de lâ€™eÂ´chantillon augmente. En ce qui concerne les
proceÂ´dures freÂ´quentistes, il apparaË†Ä±t que les intervalles baseÂ´s sur lâ€™approche conditionnelle
â€“ avec les solutions incluante, excluante, et moyenne â€“ sont moins performants que leurs
analogues bayeÂ´siens. En particulier les deux taux dâ€™erreurs associeÂ´s aux deux solutions
extreË†mes nâ€™encadrent pas toujours le taux rechercheÂ´.
Il nâ€™y a aucune difficulteÂ´ a` eÂ´tendre de manie`re immeÂ´diate les proceÂ´dures bayeÂ´siennes a`
toute autre situation faisant intervenir le mode`le multinomial. En particulier ici on obtient
tre`s facilement par simulation la distribution du minimum de deux indices pour eÂ´tablir
lâ€™eÂ´quivalence entre deux modaliteÂ´s ; on peut aussi aiseÂ´ment effectuer une infeÂ´rence pour
comparer les indices associeÂ´s a` deux groupes indeÂ´pendants (par exemple ici les patients
traiteÂ´s et non traiteÂ´s) ; etc.
9 InfeÂ´rence sur une moyenne
Reprenons lâ€™exemple meÂ´dical utiliseÂ´ par Student (1908) dans son article originel sur
la proceÂ´dure qui a eÂ´teÂ´ ensuite appeleÂ´e le â€œtest t de Studentâ€.
9.1 Le proble`me : Lâ€™exemple historique de Student
Etant donneÂ´, pour chacun des n=10 patients, les heures de sommeil suppleÂ´mentaires
procureÂ´es par lâ€™utilisation de chacun des deux somnife`res â€œsoporific [1]â€ et â€œsoporific [2]â€,
Student effectuait une infeÂ´rence sur la diffeÂ´rence des moyennes entre les deux somnife`res,
en construisant une nouvelle seÂ´rie de donneÂ´es obtenue â€œen soustrayant [1] de [2]â€. Les dix
diffeÂ´rences individuelles ainsi obtenues sont donneÂ´es dans le tableau suivant.
+1.2 +2.4 +1.3 +1.3 0 +1.0 +1.8 +0.8 +4.6 +1.4 n = 10
cÂ© Revue MODULAD, 2006 -175- NumeÂ´ro 35
9.2 Solutions freÂ´quentistes : le test t usuel et lâ€™intervalle de
confiance
Student calculait alors la moyenne +1.580 [d ] et lâ€™eÂ´cart-type (non corrigeÂ´) standard
1.167 [soit s = 1.230, corrigeÂ´ pour les degreÂ´s de liberteÂ´] de cette seÂ´rie. Il concluait alors
a` partir de sa table de la â€œdistribution tâ€ : â€œthe probability is .9985 or the odds are about
666 to 1 that 2 is the better soporificâ€ (ce qui nâ€™est certainement pas une formulation
freÂ´quentiste orthodoxe !). En termes modernes, nous calculons la statistique de test t
pour lâ€™infeÂ´rence sur une moyenne sous le mode`le normal t=+1.580/(1.230/
âˆš
10)=+4.062
et nous trouvons le seuil unilateÂ´ral punil = 0.0014 (9 dl), soit 1 âˆ’ punil = 0.9986 qui
correspond a` la valeur â€œ.9985â€ calculeÂ´e par Student (les calculs eÂ´tant effectueÂ´s ici a` partir
des donneÂ´es avec la preÂ´cision maximale).
Pour les geÂ´neÂ´ralisations ulteÂ´rieures, il est commode dâ€™introduire la notation b = 1/
âˆš
n.
Nous obtenons alors lâ€™intervalle de confiance 1âˆ’Î± a` partir du 100(1âˆ’ Î±/2)-e`me percentile
de la distribution de Student a` q = nâˆ’ 1 degreÂ´s de liberteÂ´
dÂ± bst1âˆ’Î±/2q soit ici pour Î± = 0.05 lâ€™intervalle [+0.70,+2.46]
avec b =
1âˆš
n
= 0.316 q = nâˆ’ 1 = 9 t0.9759 = +2.262
9.3 Solution fiducio-bayeÂ´sienne
Cet exemple historique de Student est une application typique de lâ€™approche que nous
appelons â€œlâ€™analyse speÂ´cifiqueâ€ (Rouanet & lecoutre, 1983 ; Lecoutre, 1984, 2005, 2006 ; Le-
coutre et al., 2000). Les donneÂ´es de base sont pour chacun des n=10 patients la diffeÂ´rence
entre les heures de sommeil suppleÂ´mentaires obtenues par lâ€™usage dâ€™un somnife`re (â€œhyos-
cyamine hydobromideâ€), les heures de sommeil eÂ´tant mesureÂ´es avant et apre`s traitement
avec soit [1] â€œdextro hyoscyamine hydobromideâ€ soit [2] â€œlÃ¦vo hyoscyamine hydobromideâ€
(on notera que ces donneÂ´es de base sont elles-meË†mes deÂ´ja` des donneÂ´es deÂ´riveÂ´es). Lâ€™analyse
de Student est un exemple typique dâ€™infeÂ´rence speÂ´cifique : elle est effectueÂ´e directement
a` partir des donneÂ´es deÂ´riveÂ´es pertinentes et ne met en jeu que lâ€™infeÂ´rence sur la moyenne
dâ€™une distribution normale.
Nous pouvons appliquer aux donneÂ´es preÂ´ceÂ´dentes lâ€™infeÂ´rence bayeÂ´sienne eÂ´leÂ´mentaire
sur la moyenne, avec seulement deux parame`tres, la diffeÂ´rence moyenne de la population Î´
et la variance Ïƒ2. Ici d et s2 sont des statistiques conjointement exhaustives pour le couple
(Î´, Ïƒ2) ; elles ont les distributions dâ€™eÂ´chantillonnage indeÂ´pendantes respectives (avec les
notations b = 1/
âˆš
n et q = nâˆ’ 1 introduites preÂ´ceÂ´demment)
d | Î´, Ïƒ2 âˆ¼ N(Î´, b2Ïƒ2)
s2 | Î´, Ïƒ2 âˆ¼ Ïƒ2 Ï‡2q
q
que lâ€™on notera plus simplement s2 | Î´, Ïƒ2 âˆ¼ Ïƒ2Ï•2q
La traduction bayeÂ´sienne de lâ€™exhaustiviteÂ´ est que la distribution finale ne deÂ´pend que de
ces statistiques. En particulier, la distribution finale fiducio-bayeÂ´sienne (ou â€œbayeÂ´sienne
objectiveâ€) marginale de Î´ est une distribution t geÂ´neÂ´raliseÂ´e. Elle est centreÂ´e sur la
diffeÂ´rence moyenne observeÂ´e d = +1.580 et a pour facteur dâ€™eÂ´chelle e = bs = s/
âˆš
n =
0.389. Cette distribution a le meË†me nombre de degreÂ´s de liberteÂ´ q = nâˆ’ 1 = 9 que le test
t.
cÂ© Revue MODULAD, 2006 -176- NumeÂ´ro 35
Elle sâ€™eÂ´crit d+ etq, ou encore par analogie avec la distribution normale
Î´ | donneÂ´es âˆ¼ tq(d, e2) soit ici Î´ | donneÂ´es âˆ¼ Î´ | d, s2 âˆ¼ t9(+1.580, 0.3892)
Il faut noter que cette distribution ne doit pas eË†tre confondue avec la distribution t
noncentreÂ´e, familie`re aux utilisateurs de lâ€™analyse de la puissance.
LesMoyennes
Dans LePAC activez le menu LesBayeÂ´siens et le sous-menu LesMoyennes, ce qui
affiche la feneË†tre pour lâ€™infeÂ´rence sur des moyennes. Cliquez sur le bouton Exemples et
cliquez sur Student, ce qui affiche les valeurs pertinentes pour cet exemple dans une
feneË†tre infeÂ´rence sur une moyenne. Cliquez sur le bouton calculer pour obtenir le
test de signification et diffeÂ´rentes statistiques descriptives (voir le deÂ´tail dans la liste
deÂ´roulante t - degreÂ´s de liberteÂ´ : q=9). Puis cliquez sur le bouton ok pour obtenir la
figure ci-apre`s.
Le facteur dâ€™eÂ´chelle e est le deÂ´nominateur de la statistique de test t usuelle, puisque
t = d/e (en supposant d 6= 0)
Î´ | donneÂ´es âˆ¼ Î´ | d, t âˆ¼ tq
(
d,
(d
t
)2)
Par conseÂ´quent, la distribution fiducio-bayeÂ´sienne de Î´ peut eË†tre directement deÂ´riveÂ´e de
d et de t=+4.062. Ce reÂ´sultat met en eÂ´vidence la proprieÂ´teÂ´ fondamentale de la statistique
de test t dâ€™eË†tre un estimateur de la preÂ´cision expeÂ´rimentale, conditionnellement a` la valeur
observeÂ´e d. Plus preÂ´ciseÂ´ment, (d/t)2 estime la variance dâ€™erreur dâ€™eÂ´chantillonnage 2 =
b2Ïƒ2 de d.
cÂ© Revue MODULAD, 2006 -177- NumeÂ´ro 35
9.4 InterpreÂ´tation fiducio-bayeÂ´sienne du seuil unilateÂ´ral
Le seuil unilateÂ´ral punil du test t est exactement la probabiliteÂ´ fiducio-bayeÂ´sienne que la
vraie diffeÂ´rence Î´ soit de signe opposeÂ´ a` celui de la diffeÂ´rence observeÂ´e. Pour les donneÂ´es de
Student (punil = 0.0014), il y a une probabiliteÂ´ finale 0.14% que la diffeÂ´rence soit neÂ´gative
et la probabiliteÂ´ compleÂ´mentaire 99.86% quâ€™elle soit positive.
Pr(Î´ < 0 | donneÂ´es) = punil = 0.0014 et Pr(Î´ > 0 | donneÂ´es) = 1âˆ’ punil = 0.9986
Si lâ€™eÂ´nonceÂ´ de Student â€œla probabiliteÂ´ est .9985 [. . .] que [2] est le meilleur somnife`reâ€
est interdit dans le cadre freÂ´quentiste, il est donc parfaitement justifieÂ´ dans le cadre
fiducio-bayeÂ´sien.
LesMoyennes
Dans la situation de la figure preÂ´ceÂ´dente, cliquez sur la courbe de lâ€™effet Î´, ce qui affiche
la â€œfeneË†tre des eÂ´nonceÂ´sâ€.
SeÂ´lectionnez le bouton dâ€™option
â€¢ limite
Entrez dans le champ limite : 0 et appuyez sur touche â€œEntreÂ´eâ€ du clavier (ou cliquez
sur le bouton Calculer) pour obtenir la figure ci-apre`s (avec 4 deÂ´cimales pour les proba-
biliteÂ´s). Notez que lâ€™on peut deÂ´sactiver les cases a` cocher intervalle et neÂ´gligeable qui
ne sont pas pertinentes ici).
De plus cette interpreÂ´tation met clairement en eÂ´vidence les insuffisances meÂ´thodologiques
des tests de signification. Il devient manifeste que le seuil observeÂ´ en lui-meË†me ne dit rien
cÂ© Revue MODULAD, 2006 -178- NumeÂ´ro 35
sur la grandeur de Î´. Dâ€™une part, un reÂ´sultat, meË†me â€œhautement significatifâ€ (punil â€œtre`s
petitâ€), permet seulement de conclure que Î´ a le meË†me signe que la diffeÂ´rence observeÂ´e d.
Dâ€™autre part, un reÂ´sultat â€œnon-significatifâ€ nâ€™est en toute rigueur quâ€™un constat dâ€™igno-
rance, comme cela est illustreÂ´ par lâ€™interpreÂ´tation fiducio-bayeÂ´sienne Pr(Î´ < 0) = Pr(Î´ >
0) = 1/2 dâ€™un test â€œparfaitement non-significatifâ€ (soit d = 0).
9.5 InterpreÂ´tation fiducio-bayeÂ´sienne de lâ€™intervalle de confiance
freÂ´quentiste
Il y a une probabiliteÂ´ (ou garantie) 95% que Î´ soit compris entre les limites (fixeÂ´es)
de lâ€™intervalle de confiance freÂ´quentiste â€“ conditionnellement aux donneÂ´es â€“ soit ici entre
+0.70 et +2.46 heures
Pr(+0.70 < Î´ < +2.46 | donneÂ´es) = 0.95
LesMoyennes
Dans la situation de la figure preÂ´ceÂ´dente, seÂ´lectionnez le bouton dâ€™option
â€¢ garantie
et entrez dans le champ garantie : 0.95 (que vous pouvez seÂ´lectionner dans la liste
deÂ´roulante) pour obtenir la figure ci-apre`s (avec 2 deÂ´cimales pour les limites). Activez si
besoin la case a` cocher intervalle.
9.6 ReÂ´ponses bayeÂ´siennes directes aux questions sur la grandeur
des effets
Au dela` des reÂ´interpreÂ´tations des proceÂ´dures freÂ´quentistes usuelles, dâ€™autres eÂ´nonceÂ´s
bayeÂ´siens fournissent des reÂ´ponses directes aux questions sur la grandeur des effets. Nous
pouvons calculer la probabiliteÂ´ que Î´ deÂ´passe un temps de sommeil suppleÂ´mentaire fixeÂ´,
plus aiseÂ´ a` interpreÂ´ter, par exemple une heure
Pr(Î´ > +1 | donneÂ´es) = 0.915
â€œIl y a une probabiliteÂ´ 91.5% que Î´ deÂ´passe une heureâ€. Puisque lâ€™uniteÂ´ de mesure est ici
signifiante, il est aiseÂ´ dâ€™appreÂ´cier la signification pratique de la grandeur de Î´.
Pour reÂ´sumer les reÂ´sultats, on peut rapporter : â€œil y a une probabiliteÂ´ finale 91.5% que
la diffeÂ´rence soit positive et grande (Î´ > +1), une probabiliteÂ´ 8.4% quâ€™elle soit positive
mais limiteÂ´e (0 < Î´ < +1), et une probabiliteÂ´ 0.14% quâ€™elle soit neÂ´gativeâ€. Un tel eÂ´nonceÂ´
nâ€™a pas dâ€™eÂ´quivalent freÂ´quentiste.
cÂ© Revue MODULAD, 2006 -179- NumeÂ´ro 35
LesMoyennes
Dans la situation de la figure preÂ´ceÂ´dente, seÂ´lectionnez le bouton dâ€™option
â€¢ limite
et activez la case a` cocher deux limites.
Entrez dans les champs limite et deux limites : 0 et 1 pour obtenir la figure ci-apre`s
(avec 1 deÂ´cimale pour les limites et 4 pour les probabiliteÂ´s).
9.7 La question de la reÂ´plication des observations
Etant donneÂ´ lâ€™expeÂ´rience reÂ´aliseÂ´e, la distribution preÂ´dictive exprime notre eÂ´tat de
connaissance sur des donneÂ´es futures. Par exemple, que pouvons-nous dire de la valeur
de la diffeÂ´rence dâ€™ que nous observerions pour de nouvelles donneÂ´es ? La distribution
preÂ´dictive pour dâ€™ dans un eÂ´chantillon futur dâ€™effectif nâ€™ est naturellement plus disperseÂ´e
que la distribution de Î´ relative a` la population (ceci dâ€™autant plus que lâ€™effectif du nouvel
eÂ´chantillon est plus petit). Ainsi la distribution fiducio-bayeÂ´sienne finale preÂ´dictive pour dâ€™,
eÂ´tant donneÂ´ la valeur d observeÂ´e dans les donneÂ´es disponibles, est encore une distribution
t geÂ´neÂ´raliseÂ´e (naturellement centreÂ´e sur d) :
dâ€™ âˆ¼ tq(d, e2 + eâ€™2) ou` eâ€™ = s/
âˆš
nâ€™
En fait, lâ€™incertitude sur Î´ conditionnellement aux donneÂ´es disponibles (refleÂ´teÂ´e par e2)
sâ€™ajoute a` lâ€™incertitude sur les reÂ´sultats de lâ€™eÂ´chantillon futur quand Î´ est connue (refleÂ´teÂ´e
par eâ€™2). Par exemple, a` partir des donneÂ´es de Student, la distribution preÂ´dictive pour
cÂ© Revue MODULAD, 2006 -180- NumeÂ´ro 35
une uniteÂ´ expeÂ´rimentale future (nâ€™ = 1) est dâ€™ âˆ¼ t9(+1.580, 1.2902). Ainsi, pour une uniteÂ´
expeÂ´rimentale suppleÂ´mentaire, â€œil y a une probabiliteÂ´ 87.4% que la diffeÂ´rence soit positive
et une probabiliteÂ´ 78.8% que la diffeÂ´rence deÂ´passe une demi-heureâ€.
LesMoyennes
Dans la situation de la figure preÂ´ceÂ´dente, fermez la â€œfeneË†tre des eÂ´nonceÂ´sâ€ pour revenir a`
la â€œfeneË†tre principaleâ€.
SeÂ´lectionnez le bouton dâ€™option
â€¢ 1/b2 âˆ¼ n
ce qui affiche lâ€™effectif 10 au lieu de la constante b = 1/
âˆš
10
Activez la case a` cocher donneÂ´es futures et entrez dans le champ 1/b2 âˆ¼ n pour les
donneÂ´es futures lâ€™effectif 1. Cliquez sur le bouton calculer pour obtenir la figure ci-apre`s.
Pour un eÂ´chantillon futur de taille 10, soit une reÂ´plique avec le meË†me effectif (eâ€™ = e),
la distribution preÂ´dictive est dâ€™ âˆ¼ t9(+1.580, 0.5502).
On notera que lâ€™on peut de meË†me obtenir la distribution preÂ´dictive relative a` la statis-
tique de test t ou aux limites de creÂ´dibiliteÂ´ fiducio-bayeÂ´siennes (soit encore les limites de
confiance freÂ´quentistes). Ceci met en jeu une nouvelle distribution appeleÂ´e K-prime (voir
Lecoutre, 1996a, 1999, 2001). Ces distributions permettent notamment de deÂ´terminer
lâ€™effectif neÂ´cessaire pour obtenir une conclusion voulue (par exemple Î´ > 0.5) avec une
garantie fixeÂ´e.
LesMoyennes
Dans la situation de la figure preÂ´ceÂ´dente, entrez maintenant pour les donneÂ´es futures :
lâ€™effectif n : 10
cÂ© Revue MODULAD, 2006 -181- NumeÂ´ro 35
les degreÂ´s de liberteÂ´ q : 9
ce que vous pouvez afficher directement en cliquant sur le bouton reÂ´plique.
SeÂ´lectionnez le bouton dâ€™option
â€¢ Linf
et cliquez sur le bouton calculer pour obtenir la figure ci-apre`s.
On trouve ici pour la diffeÂ´rence de lâ€™eÂ´chantillon futur : â€œune probabiliteÂ´ preÂ´dictive 0.991
quâ€™elle soit positive et une probabiliteÂ´ 0.959 quâ€™elle deÂ´passe une demi-heureâ€.
LesMoyennes
Dans la situation de la figure preÂ´ceÂ´dente, cliquez sur la courbe de lâ€™effet donneÂ´es futures
d, ce qui affiche la â€œfeneË†tre des eÂ´nonceÂ´sâ€.
SeÂ´lectionnez le bouton dâ€™option
â€¢ limite
et activez la case a` cocher deux limites.
Entrez dans les champs limite et deux limites : 0 et 0.5 pour obtenir la figure ci-apre`s
(avec 1 deÂ´cimale pour les limites et 3 pour les probabiliteÂ´s). La case a` cocher neÂ´gligeable
qui nâ€™est pas pertinentes ici peut eË†tre deÂ´sactiveÂ´e.
cÂ© Revue MODULAD, 2006 -182- NumeÂ´ro 35
On trouverait de meË†me pour la limite de creÂ´dibiliteÂ´ infeÂ´rieure 0.95 : â€œune probabiliteÂ´
preÂ´dictive 0.893 quâ€™elle soit positive et une probabiliteÂ´ 0.715 quâ€™elle deÂ´passe une demi-
heureâ€. Pour obtenir une probabiliteÂ´ preÂ´dictive 0.90 que la limite deÂ´passe une demi-heure,
il faudrait un effectif nâ€™ = 29. On notera quâ€™un â€œcalcul de puissanceâ€ traditionnel utilisant
pour les parame`tres les donneÂ´es de lâ€™eÂ´chantillon initial, soit Î´ = 1.580 et Ïƒ = 1.230 qui
seraient supposeÂ´es des valeurs connues ne tiendrait pas compte de lâ€™incertitude sur ces
valeurs ; on trouverait donc sans surprise que sous ces hypothe`ses un effectif nâ€™ = 13 serait
suffisant pour obtenir une probabiliteÂ´ preÂ´dictive 0.90 que la limite deÂ´passe une demi-heure.
LesEffectifs
Dans la situation de la figure preÂ´ceÂ´dente, fermez la â€œfeneË†tre des eÂ´nonceÂ´sâ€ pour revenir a`
la â€œfeneË†tre principaleâ€. Cliquez sur le bouton LesEffectifs pour afficher la feneË†tre de ce
programme. Lâ€™information initiale est automatiquement afficheÂ´e.
SeÂ´lectionnez le bouton dâ€™option effet notable LÎ³ >x (câ€™est lâ€™option par deÂ´faut) et entrez
la limite x : 1/2.
Entrez pour lâ€™effectif n : 2 ; activez la case a` cocher a` et entrez lâ€™effectif : 50 ; puis cliquez
sur le bouton calculer P pour obtenir la figure ci-apre`s. Les probabiliteÂ´s pour chaque
n sont afficheÂ´es dans la liste deÂ´roulante nâ†’P. Par exemple, pour un effectif futur de
n = 27, on a une probabiliteÂ´ 0.894 dâ€™obtenir, avec une garantie 0.95, la conclusion dâ€™un
effet (â€œnotableâ€) supeÂ´rieur a` une demi-heure, soit L0.95 > 1/2.
cÂ© Revue MODULAD, 2006 -183- NumeÂ´ro 35
9.8 Autres analyses
On peut aussi facilement effectuer des infeÂ´rences sur lâ€™eÂ´cart-type Ïƒ (ou sur la variance)
et sur la diffeÂ´rence calibreÂ´e ( ou standardiseÂ´e) Î´
Ïƒ
(voir Lecoutre, 1996a), ou encore une
preÂ´diction sur lâ€™analyse finale a` une eÂ´tape intermeÂ´diaire (Lecoutre, 2001), etc.
Les meË†mes techniques peuvent eË†tre utiliseÂ´es avec une distribution initiale conjugueÂ´e,
puisque la distribution finale est du meË†me type que la distribution fiducio-bayeÂ´sienne.
LesMoyennes
Dans la situation de la figure preÂ´ceÂ´dente, fermez le programme LesEffectifs pour revenir
a` la â€œfeneË†tre principaleâ€ du programme LesMoyennes (si besoin, activez ce programme,
cliquez sur le bouton Exemples puis seÂ´lectionnez Student, ce qui affiche les valeurs
pertinentes pour cet exemple dans une feneË†tre infeÂ´rence sur une moyenne. cliquez
ensuite sur le bouton ok).
Activez la case a` cocher distribution initiale (sur la meË†me ligne que observations et
entrez les valeurs approprieÂ´es :
â€¢ pour lâ€™effet d : 1/2
â€¢ pour 1/b2 âˆ¼ n (activez sâ€™il y a lieu cette option) : 1/2
â€¢ pour lâ€™s : 1.97
â€¢ pour les degreÂ´s de liberteÂ´ q : 9
Activez les cases a` cocher distribution initiale (au dessus des courbes) et distribution
fiducio-bayeÂ´sienne et cliquez sur le bouton calculer pour obtenir la figure ci-apre`s.
cÂ© Revue MODULAD, 2006 -184- NumeÂ´ro 35
10 InfeÂ´rence sur une combinaison lineÂ´aire de moyennes
Cet exemple eÂ´tend de manie`re immeÂ´diate les solutions preÂ´ceÂ´dentes a` lâ€™infeÂ´rence sur une
combinaison lineÂ´aire de moyennes. On examine ici la compatibiliteÂ´ dâ€™un mode`le dâ€™ajuste-
ment polynomial avec les donneÂ´es en analyse de variance.
10.1 Le proble`me : Evaluation du â€œ0.05 cliff effectâ€
Rosenthal et Gaito ont reÂ´aliseÂ´ une des premie`res expeÂ´riences sur lâ€™interpreÂ´tation du
seuil observeÂ´ dâ€™un test de signification (Rosenthal & Gaito, 1963, 1964). Poitevineau &
Lecoutre (2001) ont effectueÂ´ une reÂ´plique de cette expeÂ´rience aupre`s de 18 chercheurs en
psychologie. On demandait au chercheur de se placer dans la situation suivante : il avait
reÂ´aliseÂ´ une expeÂ´rience pour tester lâ€™efficaciteÂ´ dâ€™un traitement et avait effectueÂ´ un test â€œt
de Studentâ€ pour groupes apparieÂ´s avec un eÂ´chantillon de n sujets. On lui demandait, en
fonction du seuil observeÂ´ p, dâ€™indiquer son degreÂ´ de confiance en lâ€™hypothe`se (alternative)
selon laquelle le traitement a reÂ´ellement un effet. Chaque sujet reÂ´pondait sur une eÂ´chelle
de 0 a` 1 pour 24 cas preÂ´senteÂ´s dans un ordre aleÂ´atoire et correspondant a` douze valeurs
de p
0.001 0.01 0.03 0.05 0.07 0.10 0.15 0.20 0.30 0.50 0.70 0.90
et a` deux valeurs de n
10 100
cÂ© Revue MODULAD, 2006 -185- NumeÂ´ro 35
Dans lâ€™expeÂ´rience initiale, Rosenthal & Gaito rapportaient une â€œchute de confianceâ€ (cliff
effect), câ€™est-a`-dire une forte diminution de la confiance de`s que p eÂ´tait supeÂ´rieur au seuil
fatidique 0.05.
10.2 ReÂ´sultats numeÂ´riques
Les courbes moyennes de la confiance en fonction du seuil p obtenues dans la reÂ´plique
sont semblables a` celles de lâ€™expeÂ´rience de Rosenthal et Gaito.
Cependant les donneÂ´es individuelles sont heÂ´teÂ´roge`nes. On peut facilement identifier
trois cateÂ´gories distinctes de courbes :
(1) des courbes exponentielles deÂ´croissantes ;
(2) des courbes lineÂ´aires neÂ´gatives ;
(3) des courbes en tout-ou-rien ;
et les 18 chercheurs peuvent en conseÂ´quence eË†tre classeÂ´s en trois groupes clairement dis-
tincts.
Le proble`me consideÂ´reÂ´ ici est celui de lâ€™eÂ´valuation de la â€œchute de confianceâ€. Nous de-
vons dâ€™abord nous donner une deÂ´finition explicite de lâ€™absence de chute. Nous adopterons
la deÂ´finition utiliseÂ´e par Nelson, Rosenthal et Rosnow (1986)
â€œThe patterns of the parent means associated with the four consecutive p-values
.03, .05, .07, and .10 and the predicted means based on a second-degree poly-
nomial equation are the sameâ€
Suivant cette deÂ´finition, on conside`re le polynoË†me du second degreÂ´ qui ajuste le mieux les
donneÂ´es pour les quatre seuils consideÂ´reÂ´s (0.03, 0.05, 0.07, et 0.10). La moyenne quadra-
tique des reÂ´sidus donne un indice dâ€™ajustement (â€œgoodness of fitâ€) pour eÂ´valuer la chute
de confiance.
On obtient par exemple pour le groupe â€œexponentielâ€ les reÂ´sultats suivants.
LesMoyennes
Dans LePAC activez le menu LesBayeÂ´siens et le sous-menu LesMoyennes, ce qui
affiche la feneË†tre pour lâ€™infeÂ´rence sur des moyennes. Cliquez sur le bouton DonneÂ´es pour
afficher lâ€™eÂ´diteur de donneÂ´es. SeÂ´lectionnez le nombre de groupes : 1 et le nombre
dâ€™occasions (nombre de reÂ´peÂ´titions pour chaque sujet) : 4. Entrez les donneÂ´es pour
le groupe exponentiel que vous trouverez dans le tableau suivant (0.8625 0.7900 0.7200
0.5850, etc.) en les seÂ´parant par des espaces ou un passage a` la ligne.
Cliquez ensuite sur le bouton calculer (vous pouvez enregistrer les donneÂ´es si vous le
souhaitez) pour afficher la feneË†tre correspondant a` la structure SÃ—0 avec les ststistiques
cÂ© Revue MODULAD, 2006 -186- NumeÂ´ro 35
pertinentes (moyennes, eÂ´carts-types, covariances). Cliquez sur le bouton ReÂ´gression ou`
sont afficheÂ´es les moyennes observeÂ´es.
Entrez les abscisses z pour la reÂ´gression : respectivement 0.03, 0.05, 0.07, 0.10 pour
o1 a` o4. SeÂ´lectionnez le bouton dâ€™option :
â€¢ lineÂ´aire+quadratique
et cliquez sur le bouton calculer pour obtenir la figure ci-apre`s.
En cliquant sur le bouton ok reÂ´siduelle vous obtenez les infeÂ´rences sur lâ€™effet Î´ preÂ´senteÂ´es
plus loin.
Les tableaux ci-apre`s fournissent les donneÂ´es individuelles (moyenneÂ´es pour chaque p
sur les deux valeurs de n), ainsi que les moyennes observeÂ´es et ajusteÂ´es et les reÂ´sidus pour
les trois groupes de sujets.
cÂ© Revue MODULAD, 2006 -187- NumeÂ´ro 35
groupe â€œexponentielâ€ (10 sujets)
p 0.03 0.05 0.07 0.10 contraste pertinent
0.8625 0.7900 0.7200 0.5850 +0.0024
0.9450 0.9250 0.9325 0.8725 +0.0086
0.4850 0.4500 0.1775 0.0400 âˆ’0.0501
0.6475 0.6400 0.4925 0.4400 âˆ’0.0301 d = âˆ’0.016
0.1900 0.1850 0.1400 0.1500 âˆ’0.0107 s = 0.023
0.4875 0.5000 0.2775 0.2225 âˆ’0.0503 e = s/âˆš10 = 0.0074
0.4100 0.4850 0.4900 0.1400 +0.0158 t = d/e = âˆ’2.202
0.6500 0.5925 0.4200 0.3300 âˆ’0.0269
0.7300 0.7150 0.6675 0.5300 +0.0037
0.7200 0.7275 0.5900 0.4325 âˆ’0.0224
moyenne observeÂ´e 0.613 0.601 0.491 0.374
moyenne ajusteÂ´e 0.621 0.577 0.511 0.370
eÂ´cart (reÂ´sidu) âˆ’0.009 +0.024 âˆ’0.020 +0.005
groupe â€œlineÂ´aireâ€ (4 sujets)
p 0.03 0.05 0.07 0.10 contraste pertinent
0.9025 0.8475 0.9125 0.7925 +0.0235 d = +0.007
0.8500 0.7950 0.6250 0.7150 âˆ’0.0073 s = 0.032
0.8500 0.7800 0.7800 0.6825 +0.0427 e = s/
âˆš
4 = 0.016
0.9350 0.8725 0.9050 0.8300 +0.0256 t = d/e = +0.457
moyenne observeÂ´e 0.884 0.824 0.806 0.755
moyenne ajusteÂ´e 0.881 0.834 0.797 0.757
eÂ´cart (reÂ´sidu) +0.004 âˆ’0.011 +0.009 âˆ’0.002
groupe â€œtout-ou-rienâ€ (4 sujets)
p 0.03 0.05 0.07 0.10 contraste pertinent
0.8275 0.8800 0.2475 0.0800 âˆ’0.1443 d = âˆ’0.159
0.2075 0.4050 0.1800 0.0200 âˆ’0.0677 s = 0.071
0.8625 0.8200 0 0 âˆ’0.1878 e = s/âˆš4 = 0.036
1 1 0 0 âˆ’0.2358 t = d/e = âˆ’4.455
moyenne observeÂ´e 0.724 0.776 0.107 0.025
moyenne ajusteÂ´e 0.808 0.543 0.301 âˆ’0.019
eÂ´cart (reÂ´sidu) âˆ’0.083 +0.233 âˆ’0.194 +0.044
Lâ€™analyse de la comparaison reÂ´siduelle conduit a` consideÂ´rer le contraste cubique avec
des coefficients approprieÂ´s
[+0.1310,âˆ’0.3668,+0.3057,âˆ’0.0699]
Nous avons par exemple pour le groupe â€œtout-ou-rienâ€ lâ€™effet observeÂ´ associeÂ´ au contraste
preÂ´ceÂ´dent
d = 0.1310Ã— 0.724âˆ’ .3668Ã— 0.776 + .3057Ã— 0.107âˆ’ .0699Ã— 0.025 = âˆ’0.159
Par construction 0.159 est la moyenne quadratique des reÂ´sidus
0.159 =
âˆš
(âˆ’0.083)2 + (+0.233)2 + (âˆ’0.194)2 + (+0.044)2
4
= |d|
cÂ© Revue MODULAD, 2006 -188- NumeÂ´ro 35
On notera que les signes des coefficients ont eÂ´teÂ´ arbitrairement choisis de sorte quâ€™une
valeur de d neÂ´gative repreÂ´sente une chute de confiance, une valeur positive traduisant au
contraire une augmentation.
La situation geÂ´neÂ´rale traiteÂ´e ici est lâ€™infeÂ´rence sur une combinaison lineÂ´aire de moyennes
Î´. Nous avons deux objectifs distincts selon les groupes :
- pour les groupes â€œexponentielâ€ et â€œlineÂ´aireâ€, deÂ´montrer que lâ€™effet de chute est petit
(neÂ´gligeable) et donc montrer que Î´ est proche de zeÂ´ro (|Î´| < ) ;
- pour le groupe â€œtout-ou-rienâ€, deÂ´montrer que lâ€™effet de chute est grand (notable) et donc
montrer que Î´ est supeÂ´rieur a` une valeur positive jugeÂ´e suffisante (Î´ > â€™).
10.3 Solution fiducio-bayeÂ´sienne
A partir des donneÂ´es individuelles constitueÂ´es par le contraste pertinent (voir ta-
bleau 1), nous sommes rameneÂ´s a` lâ€™infeÂ´rence sur une moyenne traiteÂ´e preÂ´ceÂ´demment.
Nous en deÂ´duisons les distributions fiducio-bayeÂ´siennes pour Î´
Groupe exponentiel t âˆ¼ t9(âˆ’0.016, 0.0072)
Groupe lineÂ´aire t âˆ¼ t4(+0.007, 0.0162)
Groupe tout-ou-rien t âˆ¼ t4(âˆ’0.159, 0.0362)
et les eÂ´nonceÂ´s pertinents sur lâ€™effet de chute de confiance
â€¢ pour deÂ´montrer que lâ€™effet de chute est neÂ´gligeable
Groupe exponentiel (n = 10) Pr(|Î´| < 0.030) = 0.95
Groupe lineÂ´aire (n = 4) Pr(|Î´| < 0.052) = 0.95
â€¢ pour deÂ´montrer que lâ€™effet de chute est notable
Groupe tout-ou-rien (n = 4) Pr(Î´ < âˆ’0.075) = 0.95
Il est manifeste que le groupe minoritaire tout-ou-rien est largement responsable de
lâ€™effet de chute moyen. La meÂ´thodologie bayeÂ´sienne offre une grande souplesse en permet-
tant de choisir le type dâ€™eÂ´nonceÂ´ le plus approprieÂ´ au vu des donneÂ´es. Un eÂ´nonceÂ´ particulier
sur un parame`tre nâ€™est quâ€™une des facÂ¸ons possibles de reÂ´sumer la distribution finale. Cela
la rend ideÂ´alement adapteÂ´e pour eÂ´tendre une analyse de donneÂ´es exploratoire.
Bien entendu, on pourrait calculer une probabiliteÂ´ conjointe relative aux trois groupes.
Cela pourrait notamment eË†tre approprieÂ´ si lâ€™on objectait que ces groupes ont eÂ´teÂ´ constitueÂ´s
au vu des donneÂ´es et que cela impose donc dâ€™utiliser une meÂ´thode de comparaison multiple.
Cela ne soule`ve pas de proble`me conceptuel, mais neÂ´cessite le recours a` une meÂ´thode
dâ€™inteÂ´gration numeÂ´rique (facile a` mettre en Å“uvre par simulation).
Ici encore, dâ€™autres analyses sont faciles a` envisager.
PARTIE III - LES ASPECTS
TECHNIQUES :
QUELQUES OUTILS DE BASE
cÂ© Revue MODULAD, 2006 -189- NumeÂ´ro 35
11 DeÂ´rivation de la distribution finale
11.1 Echantillonnage binomial
Pour le mode`le binomial de parame`tre Ï•, pour un eÂ´chantillon de taille n avec a succe`s
et b = nâˆ’ a eÂ´checs, la distribution dâ€™eÂ´chantillonnage est
Pr(a |Ï•) = n!
a!b!
Ï•a(1âˆ’ Ï•)b, 0 â‰¤ a â‰¤ n
et la vraisemblance est
v(Ï• | a) âˆ Ï•a(1âˆ’ Ï•)b
11.1.1 Distribution initiale BeË†ta
La distribution initiale a pour densiteÂ´
p(Ï•) =
1
B(a0, b0)
Ï•a0âˆ’1(1âˆ’ Ï•)b0âˆ’1
ou` la fonction BeË†ta comple`te B(a0, b0) est deÂ´finie a` partir de la fonction Gamma
B(a0, b0) =
Î“(a0)Î“(b0)
Î“(a0 + b0)
De
âˆ« 1
0
p(Ï•)dÏ• = 1, on deÂ´duit lâ€™inteÂ´grale BeË†ta qui servira pour deÂ´river la distribution
preÂ´dictive âˆ« 1
0
Ï•uâˆ’1(1âˆ’ Ï•)vâˆ’1dÏ• = B(u, v)
Cette inteÂ´grale permet eÂ´galement de deÂ´river les moments de la distribution BeË†ta
Moy(Ï•r) =
âˆ« 1
0
1
B(a0, b0)
Ï•a0+râˆ’1(1âˆ’ Ï•)b0âˆ’1dÏ• = B(a0 + r, b0)
B(a0, b0)
=
râˆ’1âˆ
j=0
a0 + j
a0 + b0 + j
cette formule eÂ´tant valide pour tout r reÂ´el tel que r > âˆ’a0
La densiteÂ´ de la distribution finale est proportionnelle au produit v(Ï• | a)p(Ï•), soit
p(Ï• | a) âˆ Ï•a0+aâˆ’1(1âˆ’ Ï•)b0+bâˆ’1
Par comparaison avec les termes en Ï• de la densiteÂ´ initiale, on voit quâ€™il sâ€™agit encore
dâ€™une distribution BeË†ta obtenue en remplacÂ¸ant simplement a0 par a0 + a et b0 par b0 + b
soit
Ï• | a âˆ¼ BeË†ta (a1, b1) avec a1 = a0 + a et b1 = b0 + b
On peut voir que cette deÂ´rivation est valide meË†me si la densiteÂ´ initiale est impropre
(a0 = 0 ou b0 = 0). La densiteÂ´ finale nâ€™est impropre que si a1 = 0 ou b1 = 0.
11.1.2 Distribution initiale meÂ´lange de densiteÂ´s BeË†ta
Soit la distribution initiale Î»01BeË†ta (a
0
1, b
0
1)âŠ• Â· Â· Â· âŠ• Î»0JBeË†ta (a0J , b0J) de densiteÂ´
p(Ï•) =
j=Jâˆ‘
j=1
Î»0j
B(a0j , b
0
j)
Ï•a
0
jâˆ’1(1âˆ’ Ï•)b0jâˆ’1
j=Jâˆ‘
j=1
Î»0j = 1
La densiteÂ´ de la distribution finale est proportionnelle au produit v(Ï• | a)p(Ï•), soit
cÂ© Revue MODULAD, 2006 -190- NumeÂ´ro 35
p(Ï• | a) âˆ
j=Jâˆ‘
j=1
Î»0j
B(a0j , b
0
j)
Ï•a
0
j+aâˆ’1(1âˆ’ Ï•)b0j+bâˆ’1
Pour chaque j les termes en Ï• sont ceux de la distribution BeË†ta (a0j + a, b
0
j + b), qui a
pour densiteÂ´
1
B(a0j + a, b
0
j + b)
Ï•a
0
j+aâˆ’1(1âˆ’ Ï•)b0j+bâˆ’1
On en deÂ´duit donc que la distribution finale est le meÂ´lange
Î»1BeË†ta (a
0
1 + a, b
0
1 + b)âŠ• Â· Â· Â· âŠ• Î»JBeË†ta (a0J + a, b0J + b)
avec
Î»j =
Î»0j B(a
0
j + a, b
0
j + b)/B(a
0
j , b
0
j)âˆ‘k=J
k=1 Î»
0
k B(a
0
k + a, b
0
k + b)/B(a
0
k, b
0
k)
11.2 Echantillonnage de Pascal
Pour le mode`le binomial neÂ´gatif (eÂ´chantillonnage de Pascal) dans lequel on arreË†te
lâ€™expeÂ´rience quand on a observeÂ´ un nombre fixeÂ´ a` lâ€™avance a de succe`s , câ€™est le nombre
dâ€™observations n qui est une variable aleÂ´atoire. Sa distribution dâ€™eÂ´chantillonnage sâ€™eÂ´crit
Pr(n |Ï•) = (nâˆ’ 1)!
(aâˆ’ 1)!(nâˆ’ a)! Ï•
a(1âˆ’ Ï•)nâˆ’a, n â‰¥ a
et la vraisemblance est encore
v(Ï• | a) âˆ Ï•a(1âˆ’ Ï•)nâˆ’a
dâ€™ou` la meË†me proceÂ´dure.
12 DeÂ´rivation de la distribution preÂ´dictive
12.1 Echantillonnage binomial
Pour la distribution initiale Ï• âˆ¼ BeË†ta (a0, b0), la distribution preÂ´dictive du nombre de
succe`s a pour un eÂ´chantillon de taille n est
Pr(a) =
âˆ« 1
0
Pr(a |Ï•)p(Ï•)dÏ• = (nâˆ’ 1)!
(aâˆ’ 1)!(nâˆ’ a)!
1
B(a0, b0)
âˆ« 1
0
Ï•a1(1âˆ’ Ï•)b1dÏ•1
dâ€™ou`, en utilisant lâ€™inteÂ´grale BeË†ta deÂ´finie preÂ´ceÂ´demmment, la distribution
Pr(a) =
n!
a!(nâˆ’ a)!
B(a0 + a, b0 + b)
B(a0, b0)
, 0 â‰¤ a â‰¤ n
qui est la distribution BeË†ta-binomiale, ou distribution de PoÂ´lya.
12.2 Echantillonnage binomial neÂ´gatif
La distribution preÂ´dictive du nombre dâ€™observations n pour un eÂ´chantillon avec a
succe`s sâ€™obtient de la meË†me manie`re. On a dans ce cas
Pr(n) =
(nâˆ’ 1)!
(aâˆ’ 1)!(nâˆ’ a)!
B(a0 + a, b0 + nâˆ’ a)
B(a0, b0)
, n â‰¥ a
qui est la distribution BeË†ta-Pascal.
cÂ© Revue MODULAD, 2006 -191- NumeÂ´ro 35
13 Calcul des moments par meÂ´lange â€“ EspeÂ´rance condi-
tionnelle
Les calculs par meÂ´lange sont caracteÂ´ristiques de lâ€™infeÂ´rence bayeÂ´sienne et fournissent
des principes geÂ´neÂ´raux de deÂ´monstration. En particulier, il est souvent possible ainsi
dâ€™expliciter les moments des distributions finales, ce qui fournira en particulier des ap-
proximations de ces distributions. Quand on doit recourir a` des meÂ´thodes dâ€™inteÂ´gration
numeÂ´rique, il sera utile de controË†ler les reÂ´sultats a` lâ€™aide de ces approximations.
13.1 Exemple 1 â€“ Moments de la distribution preÂ´dictive
Pour le mode`le binomial, on a la moyenne de la distribution dâ€™eÂ´chantillonnage (condi-
tionnelle a` Ï•)
Moy(a |Ï•) = nÏ•
dâ€™ou` la moyenne de la distribution preÂ´dictive
Moy(a) = nMoy(Ï•) =
na0
a0 + b0
On peut calculer de la meË†me manie`re les autres moments, par exemple
Moy(a2 |Ï•) = nÏ•(nÏ•+ 1âˆ’ Ï•)
dâ€™ou`
Moy(a2) =
n(nâˆ’ 1)a0(a0 + 1)
(a0 + b0)(a0 + b0 + 1)
+
na0
a0 + b0
Etc.
13.2 Exemple 2 â€“ Moments de la distribution du rapport Ï„ =
Ï•1/Ï•2
Dans le cas de deux eÂ´chantillons binomiaux indeÂ´pendants (ou dans la re`gle â€œrejouez
le gagnantâ€), on est ameneÂ´ a` consideÂ´rer deux distributions BeË†ta indeÂ´pendantes Ï•1 âˆ¼
BeË†ta (a1, b1) et Ï•2 âˆ¼ BeË†ta (a2, b2). Cherchons par exemple les moments du rapport Ï„ =
Ï•1/Ï•2.
On a la distribution conditionnelle a` Ï•2
Ï„ =
Ï•1
Ï•2
|Ï•2 âˆ¼ 1
Ï•2
BeË†ta (a1, b1) 0 < Ï„ <
1
Ï•2
dâ€™ou` les moments conditionnels qui se deÂ´duisent des moments de la distribution BeË†ta (a1, b1)
Moy(Ï„ r |Ï•2) = B(a1 + r, b1)
B(a1, b1)
Ï•âˆ’r2
cÂ© Revue MODULAD, 2006 -192- NumeÂ´ro 35
et les moments voulus qui se deÂ´duisent des moments de la distribution BeË†ta (a2, b2)
Moy(Ï„ r) =
B(a1 + r, b1)
B(a1, b1)
Moy(Ï•âˆ’r2 ) =
B(a1 + r, b1)
B(a1, b1)
B(a2 âˆ’ r, b2)
B(a2, b2)
a2 > r
Ainsi, dans lâ€™exemple consideÂ´reÂ´ pour la re`gle dâ€™expeÂ´rimentation â€œrejouez le gagnantâ€, on a
les deux distributions finales indeÂ´pendantes Ï•1 âˆ¼ BeË†ta (74.5, 20.5) et Ï•2 âˆ¼ BeË†ta (35.5, 21.5),
dâ€™ou` notamment
Moy(Ï„) =
a1
a1 + b1
a2 + b2 âˆ’ 1
a2 âˆ’ 1 = 1.2729
Moy(Ï„ 2) =
a1 + 1
a1 + b1 + 1
a2 + b2 âˆ’ 2
a2 âˆ’ 2 Moy(Ï„) = 1.6436 dâ€™ou` ety(Ï„) = 0.1525
14 Calcul des densiteÂ´s et fonctions de reÂ´partitions
par meÂ´lange
Le meË†me principe de meÂ´lange sâ€™applique aux densiteÂ´s et aux fonctions de reÂ´partition.
14.1 Exemple 1 â€“ DeÂ´rivation de la distribution du t de Student
Ainsi la distribution du t de Student est â€œclassiquementâ€ deÂ´finie comme le rapport
t = x/y ou` x et y ont des distributions indeÂ´pendantes, respectivement N(0, 1) et (Ï‡2q/q)
1/2.
PlutoË†t que dâ€™expliciter la distribution conjointe du couple (X, Y ) et dâ€™effectuer un chan-
gement de variable, eÂ´crivons
t | y âˆ¼ N(0, 1
y
)
Nous en deÂ´duisons directement
p(t) =
âˆ« +âˆ
0
p(t | y)p(y)dy
On peut ainsi (meË†me si le calcul est formellement eÂ´quivalent) eÂ´viter le calcul du Jacobien
lieÂ´ a` un changement de variable et obtenir plus facilement des formules approprieÂ´es. En
outre la deÂ´finition de la distribution de Student comme meÂ´lange est celle qui intervient
naturellement dans lâ€™infeÂ´rence bayeÂ´sienne.
Bien entendu les moments sâ€™obtiennent encore par meÂ´lange, par exemple
Moy(t2 | y) = yâˆ’2 dâ€™ou` Moy(t2) = Moy(yâˆ’2) = q
q âˆ’ 2 q > 2
On trouvera des deÂ´monstrations deÂ´tailleÂ´es et des applications a` dâ€™autres distributions
dans Lecoutre (1996a, 2000).
cÂ© Revue MODULAD, 2006 -193- NumeÂ´ro 35
14.2 Exemple 2 â€“ InfeÂ´rence sur le rapport de deux distributions
BeË†ta de parame`tres entiers
Soit Ï•1 et Ï•2 indeÂ´pendamment distribueÂ´es BeË†ta (a1, n1âˆ’ a1) et Beta(a2, n2âˆ’ a2). On
suppose ai et ni > ai entiers positifs. On veut calculer P = Pr(
Ï•1
Ï•2
> u). Pour 0 < u â‰¤ 1,
on peut utiliser le reÂ´sultat suivant
P =
a1âˆ’1âˆ‘
j=0
Î“(a2 + j)
Î“(a2)
Î“(n2)
Î“(n2 + j)
(n1âˆ’1
j
)
uj 2F1(j âˆ’ n1 + 1, j + a2, j + n2, u) 0 < u â‰¤ 1
ou` 2F1(a, b, c, u) est la fonction hypergeÂ´omeÂ´trique
Pour u > 1, on peut calculer de la meË†me manie`re P = 1âˆ’ Pr(Ï•2
Ï•1
> 1
u
).
Preuve
Conditionnellement a` Ï•2
Pr(
Ï•1
Ï•2
> u |Ï•2) = Pr
(
BeË†ta (a1, n1 âˆ’ a1) > uÏ•2
)
= Pr
(
Bin(uÏ•2, n1 âˆ’ 1) < a1
)
ou` on utilise la relation fondamentale entre la fonction de reÂ´partition de la distribution
BeË†ta et celle de la distribution Binomiale : Pr(BeË†ta (a, b) < Ï•) = Pr(Bin(Ï•, a+ bâˆ’ 1) >
aâˆ’ 1) (Johnson, Kotz & Kemp, 1992). On en deÂ´duit
Pr(
Ï•1
Ï•2
> u |Ï•2) =
a1âˆ’1âˆ‘
j=0
Pr
(
Bin(n1 âˆ’ 1, uÏ•2) = j
)
=
a1âˆ’1âˆ‘
j=0
(n1âˆ’1
j
)
ujÏ•j2(1âˆ’ uÏ•2)n1âˆ’jâˆ’1
La probabiliteÂ´ marginale P = Pr(Ï•1
Ï•2
> u) sâ€™obtient par le â€œmeÂ´langeâ€ par la densiteÂ´
p(Ï•2) de la distribution BeË†ta (a2, n2 âˆ’ a2)
P =
a1âˆ’1âˆ‘
j=0
(n1âˆ’1j )u
j
âˆ« 1
0
Ï•j2(1âˆ’ uÏ•2)n1âˆ’jâˆ’1p(Ï•2)dÏ•2
dont on deÂ´duit le reÂ´sultat
P =
a1âˆ’1âˆ‘
j=0
(n1âˆ’1j )u
j Î“(n2)
Î“(a2)Î“(n2 âˆ’ a2)
âˆ« 1
0
Ï•j+a2âˆ’12 (1âˆ’ Ï•2)n2âˆ’a2âˆ’1(1âˆ’ uÏ•2)n1âˆ’jâˆ’1dÏ•2
=
a1âˆ’1âˆ‘
j=0
Î“(a2 + j)
Î“(a2)
Î“(n2)
Î“(n2 + j)
(n1âˆ’1j )u
j
2F1(j âˆ’ n1 + 1, j + a2, j + n2, u)
Voir par exemple http://functions.wolfram.com/HypergeometricFunctions/Hypergeometric2F1/
pour la deÂ´finition et les proprieÂ´teÂ´s de la fonction hypergeÂ´omeÂ´trique.
cÂ© Revue MODULAD, 2006 -194- NumeÂ´ro 35
15 MeÂ´thodes numeÂ´riques
Si les meÂ´thodes bayeÂ´siennes reposent sur le principe geÂ´neÂ´ral selon lequel la densiteÂ´
finale est proportionnelle au produit de la densiteÂ´ initiale et de la vraisemblance
p(Î¸ | donneÂ´es) = c v(Î¸ | donneÂ´es) p(Î¸)
il nâ€™y a eÂ´videmment pas de moyen a` la fois simple et universel de â€œnormaliserâ€ ce produit,
câ€™est-a`-dire de trouver la constante c telle que
âˆ«
p(Î¸ | donneÂ´es) dÎ¸ = 1.
En dehors des cas ou` lâ€™on peut â€œidentifierâ€ une distribution connue â€“ et conduisant
a` des calculs â€œfacilesâ€ 8 â€“ il faut donc recourir a` des techniques dâ€™inteÂ´gration numeÂ´rique,
meÂ´thodes deÂ´terministes classiques ou meÂ´thodes de Monte-Carlo. Ce sont surtout ces
dernie`res qui ont recÂ¸u lâ€™attention des statisticiens bayeÂ´siens, en raison de leur possibiliteÂ´
de traiter les proble`mes les plus complexes, meË†me (et surtout) quand le proble`me neÂ´cessite
de calculer une inteÂ´grale de dimension eÂ´leveÂ´e. Il sâ€™agit de simuler la distribution de proba-
biliteÂ´ voulue, donc de programmer un algorithme qui geÂ´ne`re (pseudo) aleÂ´atoirement des
valeurs distribueÂ´es selon cette distribution. Lâ€™appellation de Monte-Carlo provient natu-
rellement de la roulette de son casino, consideÂ´reÂ´e comme un meÂ´canisme type pour geÂ´neÂ´rer
des nombres au hasard. Ces meÂ´thodes sont de plus en plus reÂ´pandues et de nombreuses
variantes â€“ plus ou moins sophistiqueÂ´es selon la nature du proble`me â€“ ont eÂ´teÂ´ mises au
point (voir notamment Tierney, 1994 ; Chib & Greenberg, 1995 ; Gilks, Richardson &
Spiegelhalter, 1996 ; Gamerman, 1997 ; Robert & Casella, 2004)). Elles peuvent eË†tre vir-
tuellement appliqueÂ´es a` nâ€™importe quelle analyse bayeÂ´sienne. Lâ€™inteÂ´reË†t croissant pour ces
techniques â€“ et leur roË†le de plus en plus important â€“ est par exemple attesteÂ´ par la place
(le chapitre 9) qui leur est maintenant consacreÂ´e dans la troisie`me eÂ´dition du livre de Lee
(2004). Pour le lecteur inteÂ´resseÂ´, ce chapitre pourra constituer un â€œtutorielâ€ de base.
Ici je donnerai simplement des exemples de techniques de simulations eÂ´leÂ´mentaires. Je
deÂ´crirai aussi une meÂ´thode (deÂ´terministe) simple et efficace, mais souvent meÂ´connue.
15.1 Des simulations eÂ´leÂ´mentaires
ConsideÂ´rons a` titre dâ€™illustration le calcul de Pr(Ï•1
Ï•2
> u) dans lâ€™exemple de la re`gle
dâ€™expeÂ´rimentation â€œrejouez le gagnantâ€. On a les deux distributions finales indeÂ´pendantes
Ï•1 âˆ¼ BeË†ta (74.5, 20.5) et Ï•2 âˆ¼ BeË†ta (35.5, 21.5). Supposons que lâ€™on veuille calculer
Pr(Ï•1
Ï•2
> 1.25). Il suffit de simuler un eÂ´chantillon de taille N du couple (Ï•1, Ï•2), donc
dâ€™effectuer N tirages selon la distribution conjointe. On en deÂ´duira un eÂ´chantillon de
nâ€™importe quel parame`tre deÂ´riveÂ´ auquel on sâ€™inteÂ´resse â€“ par exemple la diffeÂ´rence, le rap-
port, la moyenne, le maximum, etc. â€“ permettant de calculer une probabiliteÂ´ relative a` ce
parame`tre (et bien dâ€™autres quantiteÂ´s).
On trouvera ci-apre`s un exemple de programme, eÂ´crit dans un pseudo langage, ef-
fectuant le calcul de Pr(Ï•1
Ï•2
> 1.25). Il suffit de disposer dâ€™une fonction rBeta(A,B) qui
retourne une valeur aleÂ´atoire pour la distribution BeË†ta (A,B). P est une approximation
de la probabiliteÂ´ chercheÂ´e.
8Obtenir des formules explicites, comme dans lâ€™exemple preÂ´ceÂ´dent du rapport deux distributions
BeË†ta ne reÂ´soud pas neÂ´cessairement tous les proble`mes de calcul. Ainsi, le calcul de la fonction hy-
pergeÂ´omeÂ´trique 2F1 neÂ´cessite lui-meË†me des meÂ´thodes numeÂ´riques. . . En outre, ces formules ne sont
valables que pour des entiers ; dans le cas de reÂ´els, on peut encore obtenir des formules â€œexplicitesâ€
pour les densiteÂ´s, mais le calcul de la fonction de reÂ´partition neÂ´cessite encore le calcul dâ€™une inteÂ´grale.
cÂ© Revue MODULAD, 2006 -195- NumeÂ´ro 35
N = 100000
A = 74.5 : B = 20.5 : C = 35.5 : D = 21.5
U = 1.25
I = 0
M1 = 0 : M2 = 0
Faire
X = rBeta(A,B)
Y = rBeta(C,D)
R = X/Y
Si R > U alors P = P+1
M1 = M1 + R
M2 = M2 + Râˆ—R
I = I+1
Jusquâ€™a` ce que I > N
P = P/N
M1= M1/N
M2= M2/N
Pour N=100 000 tirages, jâ€™ai trouveÂ´ Pâ‰ˆ 0.523 (la valeur exacte avec 3 deÂ´cimales eÂ´tant
0.521). Pour donner une ideÂ´e de la variabiliteÂ´, les valeurs obtenues par tranches successives
de 10 000 tirages eÂ´taient les suivantes
0.524 0.523 0.518 0.519 0.524 0.529 0.529 0.514 0.521 0.531
Par comparaison, en effectuant 9 fois 100 000 autres tirages, jâ€™ai obtenu successivement
0.520 0.521 0.522 0.519 0.521 0.522 0.520 0.520 0.518
On peut de cette manie`re obtenir les percentiles de la distribution. Par exemple, pour
calculer u tel que Pr(Ï•1
Ï•2
> u) = 0.95, la meÂ´thode la plus simple consiste a` garder les
valeurs R calculeÂ´es a` chaque tirage dans un tableau, puis dâ€™ordonner ce tableau et de
prendre comme valeur approcheÂ´e la 0.05Ã—N-ie`me valeur (la 50e`me pour N=10 000). Si
N est grand, ordonner le tableau peut eË†tre tre`s long, mais on peut alors trouver des
proceÂ´dures plus efficaces. On peut eÂ´videmment obtenir une figuration approcheÂ´e de la
densiteÂ´ de la distribution, de sa fonction de reÂ´partition, etc. Cette figuration sera utile
pour appreÂ´cier la plausibiliteÂ´ des reÂ´sultats et deÂ´tecter une anomalie eÂ´ventuelle.
Il est eÂ´galement utile, quand cela est possible de calculer des quantiteÂ´s qui peuvent
eË†tre veÂ´rifieÂ´es indeÂ´pendamment. Ainsi, dans le programme ci-dessus, jâ€™ai inclus le calcul
approcheÂ´ des moments M1â‰ˆMoy(Ï„) et M2â‰ˆMoy(Ï„ 2). Pour N=100 000 tirages, les valeurs
obtenues, Moy(Ï„) â‰ˆ 1.2726 et ety(Ï„) â‰ˆ 0.1523, sont tre`s proches des valeurs exactes
avec 4 deÂ´cimales 1.2729 et 0.1525 calculeÂ´es preÂ´ceÂ´demment. Câ€™est notamment dans les cas
particuliers ou` la densiteÂ´ des distributions en jeu nâ€™est pas borneÂ´e â€“ par exemple une
distribution du type BeË†ta (0.5, b) â€“ que la meÂ´thode doit eË†tre utiliseÂ´e avec preÂ´caution et
que de telles veÂ´rifications seront utiles.
La geÂ´neÂ´ralisation aux situations consideÂ´reÂ´es dans les sections â€œune geÂ´neÂ´ralisation du
mode`le binomial avec trois proportionsâ€ et â€œun mode`le multinomial pour le tableau 2Ã—2â€
est immeÂ´diate.
cÂ© Revue MODULAD, 2006 -196- NumeÂ´ro 35
15.2 Une meÂ´thode simple pour calculer certaines probabiliteÂ´s
Novick et Jackson (1974, pages 338-342), dans un livre malheureusement maintenant
difficile a` trouver, deÂ´crivent une meÂ´thode simple pour calculer la probabiliteÂ´ Pr(Ï•1âˆ’Ï•2 >
u) (avec les notations utiliseÂ´es ici). Cette meÂ´thode est facilement geÂ´neÂ´ralisable ; reprenons
ainsi lâ€™exemple preÂ´ceÂ´dent du calcul de Pr(Ï•1
Ï•2
> 1.25). La situation est repreÂ´senteÂ´e dans
la figure ci-apre`s : il sâ€™agit de calculer la probabiliteÂ´ du triangle supeÂ´rieur deÂ´limiteÂ´ par la
droite bleue dâ€™eÂ´quation Ï•1 = 1.25Ï•2.
On voit que cette probabiliteÂ´ peut eË†tre encadreÂ´e :
â€¢ pour une majoration, par la somme des probabiliteÂ´s associeÂ´es aux rectangles rouges ;
â€¢ pour une minoration, par la somme des probabiliteÂ´s associeÂ´es aux rectangles limiteÂ´s a`
la base par les traits blancs.
La probabiliteÂ´ dâ€™un rectangle est simplement le produit des probabiliteÂ´s marginales
donneÂ´es par les distributions finales BeË†ta indeÂ´pendantes. On peut donc theÂ´oriquement
approximer la probabiliteÂ´ chercheÂ´e avec une preÂ´cision fixeÂ´e a` lâ€™avance.
Comme illustration (grossie`re), supposons que lâ€™on â€œdeÂ´coupeâ€ lâ€™ensemble des valeurs
possibles de Ï•2 (lâ€™axe des abcisses) â€“ soit [0, 0.80] (0.80 = 1/1.25) â€“ en 10 intervalles eÂ´gaux
[x, y] (sur la figure il y en a 25). On calcule les probabiliteÂ´s des rectangles correspondants,
dâ€™ou` les reÂ´sultats suivants.
cÂ© Revue MODULAD, 2006 -197- NumeÂ´ro 35
majoration minoration
x y Pr(Ï•2 âˆˆ [x, y]) Ã—Pr(Ï•1 > 1.25x) = Ã—Pr(Ï•1 > 1.25y) =
0 0.08 0.0000 Ã—1.0000 = 0.0000 Ã—1.0000 = 0.0000
0.08 0.16 0.0000 Ã—1.0000 = 0.0000 Ã—1.0000 = 0.0000
0.16 0.24 0.0000 Ã—1.0000 = 0.0000 Ã—1.0000 = 0.0000
0.24 0.32 0.0000 Ã—1.0000 = 0.0000 Ã—1.0000 = 0.0000
0.32 0.40 0.0003 Ã—1.0000 = 0.0003 Ã—1.0000 = 0.0003
0.40 0.48 0.0144 Ã—1.0000 = 0.0144 Ã—0.9999 = 0.0144
0.48 0.56 0.1489 Ã—0.9999 = 0.1489 Ã—0.9706 = 0.1445
0.56 0.64 0.4335 Ã—0.9706 = 0.4207 Ã—0.3697 = 0.1603
0.64 0.72 0.3431 Ã—0.3697 = 0.1269 Ã—0.0006 = 0.0002
0.72 0.80 0.0586 Ã—0.0006 = 0.00003 Ã—0.0000 = 0.0000
somme 0.7113 0.3197
Compte tenu du tre`s petit nombre dâ€™intervalles, on obtient sans surprise ici pour
la probabiliteÂ´ Pr(Ï•1
Ï•2
> 1.25) un encadrement tre`s large : [0.3197,0.7113], mais si on
retient la moyenne de ces deux probabiliteÂ´s (soit une interpolation lineÂ´aire), on trouve
une estimation de la probabiliteÂ´ (0.3197+0.7113)/2 = 0.516, qui est eÂ´tonnamment proche
de la valeur exacte (avec 3 deÂ´cimales) 0.521.
Cette meÂ´thode est donc efficace et reste rapide meË†me si on augmente sensiblement le
nombre dâ€™intervalles. Bien entendu, comme toute meÂ´thode dâ€™inteÂ´gration numeÂ´rique, elle
peut eË†tre raffineÂ´e.
A partir de lâ€™exemple preÂ´ceÂ´dent, on voit immeÂ´diatement une ameÂ´lioration tre`s simple
a` apporter. On tronquera lâ€™ensemble des valeurs possibles de Ï•2 de manie`re a` eÂ´liminer
celles qui ne modifient pas la probabiliteÂ´ conjointe, pour une preÂ´cision donneÂ´e que lâ€™on
peut controË†ler. Ainsi ici, si on se limite a` lâ€™ensemble [0.32,0.80], on sait que lâ€™erreur sur
la probabiliteÂ´ conjointe est infeÂ´rieure a` Pr(Ï•2 âˆˆ [0, 0.32]) = 0.000001. En deÂ´coupant
lâ€™ensemble [0.32,0.80] en 1 000 intervalles, on obtient lâ€™encadrement [0.5194,0.5221], dâ€™ou`
la moyenne exacte avec 3 deÂ´cimales 0.521 (si on nâ€™avait pas tronqueÂ´ lâ€™ensemble, on aurait
obtenu pour le meË†me nombre dâ€™intervalles un encadrement moins preÂ´cis [0.5185,0.5229]).
On trouvera ci-apre`s un exemple de programme effectuant le calcul preÂ´ceÂ´dent, eÂ´crit
dans un pseudo langage. Il suffit de disposer dâ€™une fonction Beta(X,A,B) qui retourne la
probabiliteÂ´ quâ€™une variable de distribution BeË†ta (A,B) soit infeÂ´rieure a` X. Lâ€™encadrement
chercheÂ´ est [P1,P2].
cÂ© Revue MODULAD, 2006 -198- NumeÂ´ro 35
N = 1000
A = 74.5 : B = 20.5 : C = 35.5 : D = 21.5
U = 1.25
X = 0.32 : Y = 0.80
L = (Y-X) / N
P1 = 0 : P2 = 0
PY = 1 - Beta(Uâˆ—X,A,B)
Faire
XX = X + L
PX = Beta(XX,C,D) - Beta(X,C,D)
P2 = P2 + PX âˆ— PY
PY = 1 - Beta(Uâˆ—XX,A,B)
P1 = P1 + PX âˆ— PY
X = XX
Jusquâ€™a` ce que X > Y
Un raffinement utile consiste a` diviser lâ€™ensemble des valeurs Ï•2 en un certain nombre
de zones en fonction de la forme de la densiteÂ´, et a` utiliser des intervalles de largeur
variable selon la zone. On peut eÂ´galement envisager un autre type dâ€™interpolation que
lâ€™interpolation lineÂ´aire. Il peut eË†tre eÂ´galement preÂ´feÂ´rable dans certains cas dâ€™inverser le roË†le
de Ï•1 et de Ï•2. Etc. Comme pour les simulations, ce sont notamment les cas particuliers
ou` la densiteÂ´ de la distribution marginale nâ€™est pas borneÂ´e qui peuvent neÂ´cessiter de tels
raffinements.
Cette meÂ´thode peut eË†tre aiseÂ´ment geÂ´neÂ´raliseÂ´e. Elle peut encore eË†tre utiliseÂ´e pour une
fonction de trois parame`tres, comme dans les proble`mes â€œdiagnostic meÂ´dicalâ€ et â€œeÂ´tude
dâ€™un mode`le logiqueâ€ â€“ qui conduit a` calculer les probabiliteÂ´s de paralleÂ´leÂ´pipe`des rectangles
â€“ avec des temps de calcul qui restent tre`s raisonnables.
PARTIE IV - RETOUR SUR LES
ASPECTS CONCEPTUELS
Lâ€™INTERFACE DE Lâ€™INFEÂ´RENCE
FREÂ´QUENTISTE
ET DE Lâ€™INFEÂ´RENCE BAYEÂ´SIENNE
cÂ© Revue MODULAD, 2006 -199- NumeÂ´ro 35
16 ProprieÂ´teÂ´s freÂ´quentistes de lâ€™infeÂ´rence bayeÂ´sienne
sur une proportion : câ€™est simple !
16.1 Mode`le binomial
16.1.1 Un exemple typique
Le tableau ci-apre`s donne un exemple typique, avec Ï• = 0.50 et n = 10. Pour chaque
reÂ´sultat possible f = a/n (0 â‰¤ a â‰¤ 10) le tableau donne :
â€¢ la probabiliteÂ´ dâ€™eÂ´chantillonnage p(f |Ï• = 0.50), donneÂ´e par la distributionBin(0.50, 10) ;
â€¢ la probabiliteÂ´ cumuleÂ´e correspondante B(f) ;
â€¢ la probabiliteÂ´ bayeÂ´sienne finale Pr(Ï• < 0.50 | f) pour les trois distributions initiales
BeË†ta (0, 1), BeË†ta (1/2, 1/2), BeË†ta (1, 0), dâ€™ou` les distributions finale respectives
BeË†ta (a, nâˆ’ a+ 1) BeË†ta (a+ 1/2, nâˆ’ a+ 1/2) BeË†ta (a+ 1, nâˆ’ a)
Notons respectivement ces trois probabiliteÂ´s finales
Initiale BeË†ta (0, 1) BeË†ta (1/2, 1/2) BeË†ta (1, 0)
Pr(Ï• < 0.50 | f) = Pr+(Ï• | f) Pr(Ï• | f) Prâˆ’(Ï• | f)
Bien entendu
Pr+(Ï• | f) > Pr(Ï• | f) > Prâˆ’(Ï• | f)
Remarque : on conside`re ici que les distribution BeË†ta (a, 0) et BeË†ta (0, a) sont
les distributions ponctuelles aux points 0 et 1.
Ï• = 0.50
f = a/n p(f |Ï•) B(f) Pr+(Ï• | f) Pr(Ï• | f) Prâˆ’(Ï• | f)
0/10 0.00097656 0.00097656 1.00000000* 0.99983854* 0.99902344*
Fâˆ’ = 1/10 0.00976562 0.01074219 0.99902344* 0.99631011* 0.98925781*
F+ = 2/10 0.04394531 0.05468750 0.98925781* 0.97396339* 0.94531250
3/10 0.11718750 0.17187500 0.94531250 0.89798452 0.82812500
4/10 0.20507812 0.37695312 0.82812500 0.73517267 0.62304688
5/10 0.24609375 0.62304687 0.62304688 0.50000000 0.37695312
6/10 0.20507812 0.82812500 0.37695312 0.26482733 0.17187500
7/10 0.11718750 0.94531250 0.17187500 0.10201548 0.05468750
8/10 0.04394531 0.98925781 0.05468750 0.02603661 0.01074219
9/10 0.00976562 0.99902344 0.01074219 0.00368989 0.00097656
10/10 0.00097656 1.00000000 0.00097656 0.00016146 0
BeË†ta (0, 1) BeË†ta (1/2, 1/2) BeË†ta (1, 0)
On peut observer dans ce tableau les reÂ´sultats remarquables (et geÂ´neÂ´raux) suivants.
p(f |Ï•) = Pr+(Ï• | f)âˆ’ Prâˆ’(Ï• | f) [1]
est la conseÂ´quence de la relation fondamentale entre les fonctions de reÂ´partition des dis-
tributions BeË†ta et Binomiale (voir Section preÂ´ceÂ´dente).
Pr+(Ï• | f) = Prâˆ’(Ï• | f âˆ’ 1
n
) [2]
reÂ´sulte du fait quâ€™il sâ€™agit dans les deux cas de la meË†me distribution finale.
cÂ© Revue MODULAD, 2006 -200- NumeÂ´ro 35
ConsideÂ´rons maintenant le taux de couverture freÂ´quentiste (pour Ï• = 0.50) associeÂ´ a`
la limite supeÂ´rieure de lâ€™intervalle unilateÂ´ral de creÂ´dibiliteÂ´ 1 âˆ’ Î±. Il y a couverture si la
limite est supeÂ´rieure ou eÂ´gale a` 0.50, donc si Pr(Ï• < 0.50 | f) â‰¤ 1 âˆ’ Î±. Dans le tableau
les â€œerreursâ€ (non couverture) pour Î± = 0.05 sont indiqueÂ´es par *.
Notons Fâˆ’ la plus grande valeur de f telle que Prâˆ’(Ï• | f) â‰¥ 1 âˆ’ Î± ; cette valeur est
donc telle que Pr+(Ï• | f + 1) = Prâˆ’(Ï• | f) â‰¥ 1 âˆ’ Î±. On a ici Fâˆ’ = 1/10. En raison de
[2] F+ = Fâˆ’ + 1
n
est la plus grande valeur de f telle que Pr+(Ï• | f) â‰¥ 1 âˆ’ Î±. On a ici
F+ = 2/10.
En conseÂ´quence le taux de couverture associeÂ´ a` la distribution initiale BeË†ta (1, 0) est
1âˆ’B(Fâˆ’), et en raison de [1] et [2] on a simplement
B(Fâˆ’) = Pr+(Ï• | 0)âˆ’ Prâˆ’(Ï• |Fâˆ’) = 1âˆ’ Prâˆ’(Ï• |Fâˆ’)
dâ€™ou` le taux de couverture
1âˆ’B(Fâˆ’) = Prâˆ’(Ï• |Fâˆ’) â‰¥ 1âˆ’ Î± avec ici 1âˆ’B(1/10) = 0.98925781
De meË†me le taux de couverture associeÂ´ a` la distribution initiale BeË†ta (0, 1) est 1âˆ’B(F+)
1âˆ’B(F+) = Prâˆ’(Ï• |F+) < 1âˆ’ Î± avec ici 1âˆ’B(2/10) = 0.94531250
En conseÂ´quence le taux de couverture associeÂ´ a` la distribution initiale BeË†ta (1/2, 1/2) ne
peut eË†tre que B(Fâˆ’) ou B(F+). De plus ce reÂ´sultat est vrai aussi pour toute distribution
initiale Beta(a0,b0) avec 0 â‰¤ a0 â‰¤ 1 et 0 â‰¤ b0 â‰¤ 1.
On a bien entendu des reÂ´sultats analogues pour la limite infeÂ´rieure, les roË†les des dis-
tributions BeË†ta (0, 1) et BeË†ta (1, 0) eÂ´tant inverseÂ´s.
16.1.2 En conclusion
La famille de distributions initiales BeË†ta (a0, b0) avec 0 â‰¤ a0 â‰¤ 1 et 0 â‰¤ b0 â‰¤ 1
correspond a` une â€œzone dâ€™ignoranceâ€ (Bernard, 1996). Il y a deux distributions â€œextreË†mesâ€,
BeË†ta (1, 0) et BeË†ta (0, 1), lâ€™une assurant que le taux dâ€™erreur freÂ´quentiste est toujours plus
petit que Î± et lâ€™autre quâ€™il est toujours plus grand que Î± (le sens de lâ€™ineÂ´galiteÂ´ deÂ´pendant
du fait que lâ€™on conside`re la limite infeÂ´rieure ou supeÂ´rieure). Le taux de couverture associeÂ´
aux autres distributions de la famille eÂ´tant toujours eÂ´gal a` lâ€™un des deux taux associeÂ´s a`
ces distributions extreË†mes (deÂ´pendant de Ï• et n).
Comparons cette situation a` ce qui se passe dans le cas continu, par exemple pour
lâ€™infeÂ´rence sur la moyenne Âµ dâ€™une distribution Normale N(Âµ, 1) a` partir dâ€™un eÂ´chantillon
de taille n. On a pour la moyenne observeÂ´e la distribution dâ€™eÂ´chantillonnage Normale
N(Âµ, 1/n). On remarque que lâ€™on a dans ce cas, pour une distribution initiale uniforme,
la distribution finale N(m, 1/n), dâ€™ou` lâ€™eÂ´galiteÂ´ des densiteÂ´s
p(Âµ |m) = p(m |Âµ)
En fait, dans le cas de lâ€™infeÂ´rence sur une moyenne, la densiteÂ´ de la distribution
dâ€™eÂ´chantillonnage de la statistique m est une fonction symeÂ´trique de m et du parame`tre
Âµ, ce que lâ€™on peut voir intuitivement comme un argument de type fiduciaire justifiant le
choix de la distribution initiale uniforme. Dans le cas de lâ€™infeÂ´rence sur une proportion,
on ne peut pas avoir directement un tel argument de symeÂ´trie puisque la statistique est
discre`te et le parame`tre continu, mais lâ€™eÂ´galiteÂ´ preÂ´ceÂ´dente est remplaceÂ´e par
Pr+(Ï• | f)âˆ’ Prâˆ’(Ï• | f) = p(f |Ï•)
qui en constitue une extension naturelle.
cÂ© Revue MODULAD, 2006 -201- NumeÂ´ro 35
Ceci conduit a` consideÂ´rer ici comme â€œprobabiliteÂ´ fiducio-bayeÂ´sienneâ€, non pas une
seule valeur, mais un intervalle constitueÂ´ par les deux probabiliteÂ´s associeÂ´es aux deux
distributions extreË†mes. On rejoint ici la notion de probabiliteÂ´ impreÂ´cise (voir pour les ap-
plications en infeÂ´rence statistique Walley, 1996), comme conseÂ´quence du caracte`re discret
de la distribution dâ€™eÂ´chantillonnage.
Ceci sugge`re encore que si lâ€™on veut retenir une seule distribution â€œnon informativeâ€,
celle-ci doit eË†tre choisie comme â€œintermeÂ´diaireâ€ entre BeË†ta (1, 0) et BeË†ta (0, 1). Un choix
privileÂ´gieÂ´ est alors BeË†ta (1/2, 1/2) , qui est la solution de Jeffreys. Câ€™est effectivement la
distribution initiale qui paraË†Ä±t donner sur lâ€™ensemble des valeurs de Ï• et de n le meilleur
taux de couverture freÂ´quentiste, meilleur que celui obtenu pour la plupart des meÂ´thodes
freÂ´quentistes dâ€™intervalles de confiance (Cai, 2005).
16.2 Mode`le binomial neÂ´gatif
On conside`re toujours lâ€™infeÂ´rence sur une proportion, mais a` partir dâ€™un eÂ´chantillon
dont le nombre de succe`s a est fixeÂ´ avant lâ€™expeÂ´rience (on sâ€™arreË†te de`s que ce nombre
est atteint). On a dans ce cas pour le nombre total dâ€™observations n â‰¥ a la distribution
dâ€™eÂ´chantillonnage BinNeg(Ï•, a).
Remarque : la distribution dâ€™eÂ´chantillonnage Binomiale neÂ´gative est souvent
deÂ´finie comme la distribution de b = nâˆ’a, le nombre dâ€™eÂ´checs observeÂ´s quand
a est atteint.
16.2.1 Un exemple typique
Le tableau ci-apre`s donne un exemple typique, avec Ï• = 0.20 et a = 3. Pour chaque
reÂ´sultat possible f = a/n (n â‰¥ 3) le tableau donne :
â€¢ la probabiliteÂ´ dâ€™eÂ´chantillonnage p(f |Ï• = 0.20), donneÂ´e par la distributionBinNeg(0.20, 3) ;
â€¢ la probabiliteÂ´ cumuleÂ´e correspondante B(f) ;
â€¢ la probabiliteÂ´ bayeÂ´sienne finale Pr(Ï• > 0.20 | f) pour les quatre distributions initiales
BeË†ta (1, 0), BeË†ta (0, 0), BeË†ta (0, 1/2), BeË†ta (0, 1), soit les distributions finales respectives
BeË†ta (a+ 1, nâˆ’ a) BeË†ta (a, nâˆ’ a) BeË†ta (a, nâˆ’ a+ 1/2) BeË†ta (a, nâˆ’ a+ 1)
Notons maintenant les probabiliteÂ´s finales
Initiale BeË†ta (0, 0) BeË†ta (0, 1/2) BeË†ta (0, 1)
Pr(Ï• < 0.50 | f) = Pr+(Ï• | f) Pr(Ï• | f) Prâˆ’(Ï• | f)
Bien entendu
Pr+(Ï• | f) > Pr(Ï• | f) > Prâˆ’(Ï• | f)
Ï• = 0.20
cÂ© Revue MODULAD, 2006 -202- NumeÂ´ro 35
f = a/n p(f |Ï• = 0.20) B(f) Pr+(Ï• | f) Pr(Ï• | f) Prâˆ’(Ï• | f)
3/3 0.00800000 0.00800000 1.00000000* 1.00000000* 0.99728632* 0.99200000*
3/4 0.01920000 0.02720000 0.99840000* 0.99200000* 0.98386991* 0.97280000*
3/5 0.03072000 0.05792000 0.99328000* 0.97280000* 0.95882595* 0.94208000
3/6 0.04096000 0.09888000 0.98304000* 0.94208000 0.92276264 0.90112000
3/7 0.04915200 0.14803200 0.96665600* 0.90112000 0.87742592 0.85196800
3/8 0.05505024 0.20308224 0.94371840 0.85196800 0.82503681 0.79691776
3/9 0.05872026 0.26180250 0.91435827 0.79691776 0.76788506 0.73819750
3/10 0.06039798 0.32220047 0.87912612 0.73819750 0.70809554 0.67779953
3/11 0.06039798 0.38259845 0.83886080 0.67779953 0.64750882 0.61740155
3/12 0.05905580 0.44165425 0.79456895 0.61740155 0.58763489 0.55834575
3/13 0.05669357 0.49834782 0.74732431 0.55834575 0.52965171 0.50165218
3/14 0.05360119 0.55194901 0.69818988 0.50165218 0.47442964 0.44805099
3/15 0.05002778 0.60197679 0.64816210 0.44805099 0.42256891 0.39802321
3/16 0.04617949 0.64815628 0.59813433 0.39802321 0.37444215 0.35184372
3/17 0.04222125 0.69037753 0.54887620 0.35184372 0.33023683 0.30962247
3/18 0.03828060 0.72865812 0.50102546 0.30962247 0.28999475 0.27134188
3/19 0.03445254 0.76311066 0.45508874 0.27134188 0.25364706 0.23688934
3/20 0.03080462 0.79391528 0.41144886 0.23688934 0.22104429 0.20608472
3/21 0.02738189 0.82129717 0.37037603 0.20608472 0.19198125 0.17870283
3/22 0.02421135 0.84550852 0.33204139 0.17870283 0.16621725 0.15449148
etc.
BeË†ta (1, 0) BeË†ta (0, 0) BeË†ta (0, 1/2) BeË†ta (0, 1)
ConsideÂ´rons maintenant le taux de couverture freÂ´quentiste (pour Ï• = 0.20) associeÂ´ a`
la limite infeÂ´rieure de lâ€™intervalle unilateÂ´ral de creÂ´dibiliteÂ´ 1 âˆ’ Î±. Il y a couverture si la
limite est infeÂ´rieure ou eÂ´gale a` 0.20, donc si Pr(Ï• > 0.20 | f) â‰¤ 1âˆ’ Î±. Dans le tableau les
â€œerreursâ€ (non couverture) pour Î± = 0.05 sont indiqueÂ´es par *.
16.2.2 En conclusion
On a clairement des reÂ´sultats analogues a` ceux eÂ´nonceÂ´s pour le mode`le binomial. La
famille de distributions initiales BeË†ta (a0, b0) avec 0 â‰¤ a0 â‰¤ 1 et 0 â‰¤ b0 â‰¤ 1 correspond
a` une â€œzone dâ€™ignoranceâ€. Les deux distributions â€œextreË†mesâ€, BeË†ta (1, 0) et BeË†ta (0, 1)
assurent encore, lâ€™une que le taux dâ€™erreur freÂ´quentiste est toujours plus petit que Î± et
lâ€™autre quâ€™il est toujours plus grand que Î± (le sens de lâ€™ineÂ´galiteÂ´ deÂ´pendant du fait que
lâ€™on conside`re la limite infeÂ´rieure ou supeÂ´rieure).
On a encore pour le mode`le binomial neÂ´gatif une eÂ´galiteÂ´ du type
Pr+(Ï• | f)âˆ’ Prâˆ’(Ï• | f) = p(f |Ï•)
mais dans ce cas Pr+ correspond a` la distribution initiale BeË†ta (0, 0) et Prâˆ’ a` la distri-
bution initiale BeË†ta (0, 1)
Ceci sugge`re que si lâ€™on veut retenir une seule distribution â€œnon informativeâ€, celle-ci
doit eË†tre choisie comme â€œintermeÂ´diaireâ€ entre BeË†ta (0, 0) et BeË†ta (0, 1). Un choix â€œnatu-
relâ€ est alors BeË†ta (0, 1/2), qui est la solution de Jeffreys. Câ€™est effectivement la distribution
initiale qui paraË†Ä±t donner sur lâ€™ensemble des valeurs de a et de Ï• le meilleur taux de cou-
verture freÂ´quentiste, meilleur que celui obtenu pour la plupart des meÂ´thodes freÂ´quentistes
dâ€™intervalles de confiance (Cai, 2005).
cÂ© Revue MODULAD, 2006 -203- NumeÂ´ro 35
Notons encore que le taux de couverture associeÂ´ a` la distribution BeË†ta (0, 1/2) est
toujours eÂ´gal a` lâ€™un des deux taux associeÂ´s aux distributions BeË†ta (0, 0) et BeË†ta (0, 1)
(deÂ´pendant de Ï• et a), et non comme pour le mode`le binomial a` ceux associeÂ´s aux deux
distributions extreË†mes.
16.3 GeÂ´neÂ´ralisation aux tableaux 2Ã—2 et tests conditionnels â€œa`
la Fisherâ€
Lâ€™exemple â€œun mode`le multinomial pour le tableau 2 Ã— 2â€ a permis dâ€™illustrer la
reÂ´interpreÂ´tation bayeÂ´sienne du test de permutation de Fisher. Ceci constitue une extension
des reÂ´sultats preÂ´ceÂ´dents pour une proportion. On a la meË†me reÂ´interpreÂ´tation dans le cas
de deux groupes indeÂ´pendants avec chacun une distribution dâ€™eÂ´chantillonnage Binomiale
ou chacun une distribution Binomiale neÂ´gative, ou encore pour un mode`le multinomial
neÂ´gatif . Illustrons la dans les deux premiers cas.
ConsideÂ´rons lâ€™exemple du tableau de donneÂ´es suivant, avec respectivement 3 et 2
observations et un succe`s observeÂ´ dans chaque groupe.
1 0
g1 n11 = 1 n10 = 2 n1. = 3
g2 n21 = 1 n20 = 1 n2. = 2
n.1 = 2 n.0 = 3 n = 5
16.4 Le test conditionnel aux marges (test de permutation)
16.4.1 Cas binomial
Dans le cas binomial on retient lâ€™un des effectifs â€“ par exemple n11 â€“ comme statistique
de test, et on calcule la proportion de tableaux possibles avec les meË†mes marges qui sont
â€œplus extreË†mesâ€ que le tableau observeÂ´. Il y a trois types de tableaux de donneÂ´es possibles
0 3 3 1 2 3 2 1 3
2 0 2 1 1 2 0 2 2
2 3 5 2 3 5 2 3 5
1Ã— 1 = 1 3Ã— 2 = 6 3Ã— 1 = 3
la dernie`re ligne indiquant le nombre de tableaux du type. Par exemple, pour le tableau
du milieu, avec 3 sujets dans le groupe 1 il y a 3 facÂ¸ons possibles dâ€™avoir n11 = 1 et n12 = 2,
et avec 2 sujets dans le groupe 2 il y a 2 facÂ¸ons possibles dâ€™avoir n21 = 1 et n22 = 1, donc
3Ã— 2 = 6 tableaux de ce type.
Si on veut montrer que Ï•1 < Ï•2, le seuil observeÂ´ du test unilateÂ´ral (incluant) est la
proportion des tableaux pour lesquels n11 â‰¤ 1, soit
pinc = (1 + 6)/10 = 0.70
Si on exclut la valeur observeÂ´e (soit n11 < 1) on obtient le seuil excluant
pexc = 1/10 = 0.10
Formellement, ces seuils sont donneÂ´s par la distribution dâ€™eÂ´chantillonnage de n11 sous
lâ€™hypothe`se nulle H0 : Ï•1 = Ï•2, conditionnellement aux marges, qui est une distribution
HypergeÂ´omeÂ´trique
cÂ© Revue MODULAD, 2006 -204- NumeÂ´ro 35
n11 |n.1, n1., n.2, n2., [H0] âˆ¼ Hyp (n , n.1 , n1.) soit ici Hyp (5, 2, 3)
dâ€™ou`
pinc = Pr(Hyp (n , n.1 , n1.) â‰¤ n11) = 0.70 et pexc = Pr(Hyp (n , n.1 , n1.) < n11) = 0.10
16.4.2 Cas binomial neÂ´gatif
Dans le cas binomial neÂ´gatif on retient par exemple n1. comme statistique de test et
on calcule la proportion de tableaux possibles avec les meË†mes valeurs n, n11 et n21 (et
donc n.1 et n.0) qui sont â€œplus extreË†mesâ€ que le tableau observeÂ´. Il y a quatre types de
tableaux de donneÂ´es possibles
1 0 1 1 1 2 1 2 3 1 3 4
1 3 4 1 2 3 1 1 2 1 0 1
2 3 5 2 3 5 2 3 5 2 3 5
1Ã— 4 = 4 2Ã— 3 = 6 3Ã— 2 = 6 4Ã— 1 = 4
la dernie`re ligne indiquant le nombre de tableaux du type. Dans ce cas, si on veut montrer
que Ï•1 < Ï•2, le seuil observeÂ´ du test unilateÂ´ral (incluant) est la proportion des tableaux
pour lesquels n1. â‰¥ 3, soit
pinc = (6 + 4)/20 = 0.50
Si on exclut la valeur observeÂ´e (soit n1. > 3) on obtient le seuil excluant
pexc = 4/20 = 0.25
Formellement, ces seuils sont donneÂ´s par la distribution dâ€™eÂ´chantillonnage de n1. sous
lâ€™hypothe`se nulle H0 : Ï•1 = Ï•2, conditionnellement a` n, n11 et n21, qui est une distribution
HypergeÂ´omeÂ´trique neÂ´gative
n1. |n, n11, n21, [H0] âˆ¼ HypNEG (n , n11 , n21) soit ici HypNEG (5, 1, 1)
dâ€™ou`
pinc = Pr(HypNEG (n , n11 , n21) â‰¥ n1.) = 0.50 et pexc = Pr(HypNEG (n , n11 , n21) > n1.) = 0.25
16.5 ReÂ´interpreÂ´tation bayeÂ´sienne
16.5.1 Cas binomial
Soit la distribution initiale Ï•1 âˆ¼ BeË†ta (Î½11, Î½10) et Ï•2 âˆ¼ BeË†ta (Î½21, Î½20) avec Ï•1 et Ï•2
indeÂ´pendantes. On suppose que les (Î½ij) sont des entiers positifs ou nuls. On a le reÂ´sultat
suivant
Pr
(
Ï•1 > Ï•2 | (nij)
)
= Pr
(
Hyp (n+Î½11+Î½10+Î½21+Î½20âˆ’2 , n.1+Î½11+Î½21âˆ’1 , n1.+Î½11+Î½10âˆ’1) < n11+Î½11
)
soit, si Î½11 + Î½10 = 1, Î½11 + Î½21 = 1 et Î½21 + Î½20 = 1
Pr
(
Ï•1 > Ï•2 | (nij)
)
= Pr
(
Hyp (n, n.1 , n1.) < n11 + Î½11
)
cÂ© Revue MODULAD, 2006 -205- NumeÂ´ro 35
Par conseÂ´quent, pour le cas binomial on a la reÂ´interpreÂ´tation du seuil
Pr
(
Ï•1 > Ï•2 | (nij)
)
= pinc = 0.70 si Î½11 = Î½20 = 1 et Î½10 = Î½21 = 0
Pr
(
Ï•1 > Ï•2 | (nij)
)
= pexc = 0.10 si Î½11 = Î½20 = 0 et Î½10 = Î½21 = 1
et, si lâ€™on veut retenir une seule distribution â€œnon informativeâ€, ceci sugge`re comme choix
privileÂ´gieÂ´ la solution intermeÂ´diaire Î½11 = Î½10 = Î½21 = Î½20 = 1/2 , qui est la solution de
Jeffreys.
Le lien entre le seuil du test conditionnel et la probabiliteÂ´ bayeÂ´sienne finale Pr(Ï•1 >
Ï•2 | (nij)) reÂ´sulte encore de la relation fondamentale entre les fonctions de reÂ´partition des
distributions BeË†ta et Binomiale. Il se deÂ´montre â€œpar meÂ´langeâ€. Conditionnellement a` Ï•2,
on a
Pr
(
Ï•1 > Ï•2 |Ï•2, (nij)
)
= Pr
(
BeË†ta (n11 + Î½11, n10 + Î½10) > Ï•2
)
= Pr
(
Bin (Ï•2 , n11 + Î½11 + n10 + Î½10 âˆ’ 1) < n11 + Î½11
)
=
Pr
(
Bin (Ï•2 , n1. + Î½11 + Î½10 âˆ’ 1) < n11 + Î½11
)
La probabiliteÂ´ marginale â€“ meÂ´lange de la probabiliteÂ´ binomiale par la distribution BeË†ta (Î½21, Î½20)
â€“ est une distribution BeË†ta-Binomiale (voir la section â€œdeÂ´rivation de la distribution
preÂ´dictiveâ€)
Pr
(
Ï•1 > Ï•2 | (nij)
)
= Pr
(
BeË†ta-Bin (n21+Î½21 , n20+Î½20 ; n1.+Î½11+Î½10âˆ’1) < n11+Î½11
)
et en utilisant une autre relation remarquable, entre la distribution BeË†ta-Binomiale et la
distribution hypergeÂ´omeÂ´trique (Johnson, Kotz & Kemp, 1992).
Pr
(
BeË†ta-Bin (a , b ; n) < u
)
= Pr
(
Hyp (a+ b+ nâˆ’ 1 , a+ uâˆ’ 1 , n) < u
)
on deÂ´duit le reÂ´sultat eÂ´nonceÂ´.
16.5.2 Cas binomial neÂ´gatif
Avec la meË†me distribution initiale que dans le cas preÂ´ceÂ´dent, en utilisant une autre
relation, entre la distribution BeË†ta-Binomiale et la distribution hypergeÂ´omeÂ´trique neÂ´gative
(Johnson, Kotz & Kemp, 1992).
Pr
(
BeË†ta-Bin (a , b ; n) < u
)
= Pr
(
HypNEG (a+ b+ n , u , a) > n
)
on obtient
Pr
(
Ï•1 > Ï•2 | (nij)
)
= Pr
(
HypNEG (n+Î½11+Î½10+Î½21+Î½20âˆ’1 , n11+Î½11 , n21+Î½21) > n1.+Î½11+Î½10âˆ’1
)
soit, si Î½11 = Î½21 = 0 et Î½10 + Î½20 = 1,
Pr
(
Ï•1 > Ï•2 | (nij)
)
= Pr
(
HypNEG (n , n11 , n21) > n1. + Î½10 âˆ’ 1
)
Par conseÂ´quent, pour le cas binomial neÂ´gatif on a la reÂ´interpreÂ´tation du seuil
cÂ© Revue MODULAD, 2006 -206- NumeÂ´ro 35
Pr
(
Ï•1 > Ï•2 | (nij)
)
= pinc = 0.50 si Î½11 = Î½21 = Î½10 = 0 et Î½20 = 1
Pr
(
Ï•1 > Ï•2 | (nij)
)
= pexc = 0.25 si Î½11 = Î½21 = Î½20 = 0 et Î½10 = 1
et, si lâ€™on veut retenir une seule distribution â€œnon informativeâ€, ceci sugge`re comme choix
privileÂ´gieÂ´ la solution intermeÂ´diaire Î½11 = Î½21 = 0 et Î½10 = Î½20 = 1/2 , qui est la solution de
Jeffreys.
17 Re`gle de Jeffreys
17.1 Information de Fisher et distribution non informative de
Jeffreys
Les consideÂ´rations preÂ´ceÂ´dentes fournissent une justification intuitive de la distribu-
tion non informative de Jeffreys. La justification formelle est que celle-ci est baseÂ´e sur
lâ€™information de Fisher (1922, 1925). Dans le cas dâ€™un seul parame`tre â€“ typiquement la
proportion Ï•, lâ€™information de Fisher I(Ï•) apporteÂ´e par un eÂ´chantillon y est deÂ´finie, a`
partir de la vraisemblance v(Ï• |y) comme
I(Ï• |y) = EÏ•
[( âˆ‚
âˆ‚Ï•
log v(Ï• |y)
)2]
= âˆ’EÏ•
[ âˆ‚2
âˆ‚2Ï•
log v(Ï• |y)
]
et la densiteÂ´ de la distribution de Jeffreys est proportionnelle a` sa racine carreÂ´e
pJ(Ï•) âˆ
âˆš
I(Ï•)
17.2 Deux distributions initiales pour les eÂ´chantillonnages bino-
mial et de Pascal
17.2.1 Echantillonnage binomial
v(Ï• |y) = v(Ï• | a) = n!
a!(nâˆ’ a)! Ï•
a(1âˆ’ Ï•)nâˆ’a
et
E(a |Ï•) = nÏ•
On en deÂ´duit
log v(Ï• | a) = a logÏ•+ (nâˆ’ a) log(1âˆ’ Ï•) + k
ou` k est une constante, et
I(Ï• | a) = âˆ’E
(
âˆ’ a
Ï•2
âˆ’ nâˆ’ a
1âˆ’ Ï•2
)
=
n
Ï•
+
n
1âˆ’ Ï• = nÏ•
âˆ’1(1âˆ’ Ï•)âˆ’1
donc
pJ(Ï•) âˆ Ï•âˆ’1/2(1âˆ’ Ï•)âˆ’1/2 soit Ï• âˆ¼ BeË†ta (1/2, 1/2)
cÂ© Revue MODULAD, 2006 -207- NumeÂ´ro 35
17.2.2 Echantillonnage de Pascal (distribution Binomiale neÂ´gative)
v(Ï• |y) = v(Ï• |n) = (nâˆ’ 1)!
(aâˆ’ 1)!(nâˆ’ a)! Ï•
a(1âˆ’ Ï•)nâˆ’a, n â‰¥ a
et
E(n |Ï•) = a 1âˆ’ Ï•
Ï•
On deÂ´duit en proceÂ´dant de la meË†me manie`re
I(Ï• |n) = nÏ•âˆ’2(1âˆ’ Ï•)âˆ’1
donc
pJ(Ï•) âˆ Ï•âˆ’1(1âˆ’ Ï•)âˆ’1/2 soit Ï• âˆ¼ BeË†ta (0, 1/2)
18 Une neÂ´cessiteÂ´ pour les analyses intermeÂ´diaires :
concilier lâ€™approche bayeÂ´sienne avec les desiderata
freÂ´quentistes
La plupart des expeÂ´rimentateurs conside`rent que la possibiliteÂ´ dans un plan dâ€™expeÂ´rience
de sâ€™arreË†ter avant le terme preÂ´vu, en effectuant une analyse intermeÂ´diaire, ne doit pas eË†tre
ignoreÂ´e. La raison est que lâ€™arreË†t peut induire un biais sur lâ€™infeÂ´rence quâ€™ils souhaitent ex-
plicitement corriger. Les proceÂ´dures freÂ´quentistes introduisent preÂ´ciseÂ´ment une telle cor-
rection. Câ€™est pourquoi de nombreux expeÂ´rimentateurs sont deÂ´sappointeÂ´s par le fait que les
meÂ´thodes bayeÂ´siennes, contrairement a` la pratique freÂ´quentiste, ignorent geÂ´neÂ´ralement ce
desiderata, au nom du principe de vraisemblance. En conseÂ´quence, ceci constitue un frein
seÂ´rieux a` lâ€™utilisation des meÂ´thodes bayeÂ´siennes dans lâ€™analyse des donneÂ´es expeÂ´rimentales.
18.1 Les principes de vraisemblance et des re`gles dâ€™arreË†t
â€œIf the experiment is changed, then the expression of relative ignorance can
be expected to change correspondingly.â€ (Box & Tiao, 1992, page 46)
Box et Tiao (1992) ont discuteÂ´ le fait â€“ mis en eÂ´vidence dans la section preÂ´ceÂ´dente â€“ que
la re`gle de Jeffreys aboutit a` deux distributions initiales diffeÂ´rentes pour les eÂ´chantillonnages
binomial et de Pascal, bien que ces deux types dâ€™expeÂ´riences conduisent a` la meË†me
vraisemblance. Ils ont mis en avant lâ€™ideÂ´e que â€œlâ€™ignoranceâ€ avant lâ€™expeÂ´rience est re-
lative au plan dâ€™expeÂ´rience et quâ€™une distribution non informative approprieÂ´e doit donc
deÂ´pendre du mode`le dâ€™eÂ´chantillonnage. Mais cela est contraire au â€œprincipe de vraisem-
blanceâ€ (consideÂ´reÂ´ comme une conseÂ´quence du theÂ´ore`me de Bayes), auquel la plupart des
bayeÂ´siens vouent une stricte obeÂ´issance.
Principe de vraisemblance - â€œSi x1 et x2 sont tels quâ€™il existe une constante
c telle que, pour tout Ï•, v(Ï•|x1) =cv(Ï•|x2), ils apportent la meË†me information
sur Ï• et doivent conduire a` la meË†me infeÂ´rence.â€ (adapteÂ´ de Robert, 1992,
page 23)
Une conseÂ´quence du principe de vraisemblance est le principe des re`gles dâ€™arreË†t.
cÂ© Revue MODULAD, 2006 -208- NumeÂ´ro 35
Principe des re`gles dâ€™arreË†t - â€œonce the data have been obtained, the reasons
for stopping experimentation should have no bearing on the evidence reported
about unknown model parameters.â€ (Bayarri & Berger, 2004, page 77)
Ce principe affirme que lâ€™on devrait faire la meË†me infeÂ´rence si lâ€™on sâ€™arreË†te en ayant
observeÂ´ a succe`s apre`s n (fixeÂ´) observations (eÂ´chantillonnage binomial) ou si lâ€™on sâ€™arreË†te
apre`s avoir effectueÂ´ n observations pour obtenir a (fixeÂ´) succe`s (eÂ´chantillonnage de Pascal).
Ce sont la` deux exemples simples de re`gles dâ€™arreË†t ; mais des re`gles plus complexes â€“ qui
ont une grande importance en pratique â€“ sont fournies pas les analyses intermeÂ´diaires
(voir lâ€™exemple â€œInfeÂ´rence sur une proportionâ€). Au nom de ces principes, les tentatives
preÂ´ceÂ´dentes pour incorporer ces re`gles dans une distribution initiale objective (Ye, 1993)
ont eÂ´teÂ´ plus ou moins abandonneÂ´es, ignorant les arguments avanceÂ´s par Box & Tiao.
18.2 Une nouvelle approche prometteuse
La plupart des expeÂ´rimentateurs ne sont pas convaincus par ces principes. La situation
ne devrait cependant pas rester bloqueÂ´e, puique de Cristofaro (1996, 2004, 2006) a ouvert
la possibiliteÂ´ de concilier lâ€™approche bayeÂ´sienne avec les desiderata freÂ´quentistes. Il argu-
mente que le plan expeÂ´rimental (incluant la re`gle dâ€™arreË†t) est anteÂ´rieur a` lâ€™information de
lâ€™eÂ´chantillon et que lâ€™information sur le plan constitue une partie de lâ€™eÂ´vidence. Il en deÂ´duit
que la formule de Bayes doit inteÂ´grer cette information, et que par suite les principes de
vraisemblance et des re`gles dâ€™arreË†t nâ€™en sont plus une conseÂ´quence automatique. Une ideÂ´e
de base est de consideÂ´rer que lâ€™information du plan ignoreÂ´e dans la vraisemblance peut
eË†tre recouvreÂ´e dans lâ€™information de Fisher, et par suite dans la distribution initiale de
Jeffreys ; celle-ci trouve ainsi une leÂ´gitimiteÂ´ nouvelle et apporte une reÂ´ponse au proble`me
de lâ€™eÂ´vidence implicitement contenue dans le plan dâ€™expeÂ´rience. Dans ce cadre, nous pou-
vons obtenir une reÂ´ponse bayeÂ´sienne coheÂ´rente et pleinement justifieÂ´e au proble`me des
analyses intermeÂ´diaires.
Cette approche nouvelle a eÂ´teÂ´ deÂ´veloppeÂ´e par Bunouf (2006) dans le cas de lâ€™infeÂ´rence
sur une proportion avec analyses intermeÂ´diaires. Elle apparaË†Ä±t prometteuse et offre des
avantages deÂ´cisifs, a` la fois dâ€™un point de vue bayeÂ´sien et dâ€™un point de vue freÂ´quentiste
(Bunouf & Lecoutre, 2006).
REMARQUES FINALES
ET QUELQUES THE`MES POUR ALLER
PLUS LOIN
Le moment semble venu de parvenir a` des proceÂ´dures dâ€™analyse des donneÂ´es expeÂ´rimentales
qui permettent de remeÂ´dier de manie`re constructive aux mauvais usages des tests de si-
gnification usuels. Il y a indeÂ´niablement une reconnaissance grandissante que lâ€™infeÂ´rence
bayeÂ´sienne peut eË†tre ideÂ´alement adapteÂ´e a` cet objectif. Elle satisfait les demandes des
scientifiques : proceÂ´dures objectives (incluant les seuils p traditionnels) ; proceÂ´dures sur
les grandeurs des effets (allant au dela` des seuils p) ; proceÂ´dures pour planifier et conduire
les expeÂ´riences.
cÂ© Revue MODULAD, 2006 -209- NumeÂ´ro 35
Alors, pourquoi les scientifiques, et en particulier les expeÂ´rimentateurs, alors quâ€™ils
apparaissent reÂ´ellement souhaiter un autre type dâ€™infeÂ´rence statistique, semblent sou-
vent reÂ´ticents a` mettre en pratique les proceÂ´dures bayeÂ´siennes ? Dans un papier parti-
culie`rement lucide Winkler eÂ´crivait il y a plus de 30 ans :
â€œthis state of affairs appears to be due to a combination of factors including
philosophical conviction, tradition, statistical training, lack of â€˜availabilityâ€™,
computational difficulties, reporting difficulties, and perceived resistance by
journal editors.â€ (Winkler, 1974, page 129)
ajoutant que si on laissait de coË†teÂ´ les aspects philosophiques, aucun de ces arguments
nâ€™eÂ´tait reÂ´ellement deÂ´terminant. Cette analyse nâ€™en reste pas moins dâ€™actualiteÂ´ ; on peut
simplement ajouter quâ€™un nouvel obstacle important en pratique est que les logiciels statis-
tiques standard qui sont de nos jours largement utiliseÂ´s continuent a` ignorer les meÂ´thodes
bayeÂ´siennnes.
â€œWe [statisticians] will all be Bayesians in 2020, and then we can be a united
profession.â€ (Lindley, in Smith, 1995, page 317)
En fait nous sommes vraisemblablement dans une peÂ´riode cruciale, car la masse des
travaux theÂ´oriques sur lâ€™infeÂ´rence bayeÂ´siennes qui ont eÂ´teÂ´ effectueÂ´s donne lieu a` un nombre
sans cesse croissant dâ€™applications. Lâ€™un des facteurs deÂ´cisifs pourrait eË†tre le reÂ´cent â€œdraft
guidance documentâ€ de lâ€™US Food and Drug Administration (FDA, 2006). Ce document,
qui discute â€œthe least burdensome way of addressing the relevant issues related to the
use of Bayesian statistics in medical device clinical trialsâ€, ouvre la possibiliteÂ´ pour
les expeÂ´rimentateurs (au moins dans le domaine des essais cliniques) dâ€™eË†tre reÂ´ellement
bayeÂ´siens en pratique.
18.3 Quelques avantages de lâ€™infeÂ´rence bayeÂ´sienne
18.3.1 Une meilleure compreÂ´hension des proceÂ´dures freÂ´quentistes
â€œStudents [exposed to a Bayesian approach] come to understand the frequen-
tist concepts of confidence intervals and P values better than do students
exposed only to a frequentist approach. (Berry, 1997)
Les meÂ´thodes bayeÂ´siennes objectives permettent aux utilisateurs de surmonter des dif-
ficulteÂ´s usuelles rencontreÂ´es avec approche freÂ´quentiste. En particulier, il est tre`s naturel
pour eux dâ€™utiliser les interpreÂ´tations bayeÂ´siennes des tests de signification et des inter-
valles de confiance dans le langage des probabiliteÂ´s sur les parame`tres inconnus. En retour
les mauvais usages et les abus des tests de signification de lâ€™hypothe`se nulle sont beau-
coup mieux compris. En particulier les utilisateurs des meÂ´thodes bayeÂ´siennes deviennent
tre`s vite avertis du fait que les reÂ´sultats non significatifs ne peuvent pas eË†tre interpreÂ´teÂ´s
comme â€œpreuve dâ€™absence dâ€™effet.â€
18.3.2 Combiner diffeÂ´rentes sources dâ€™information
Une analyse de donneÂ´es expeÂ´rimentales devraient toujours inclure une analyse bayeÂ´sienne
objective pour exprimer lâ€™apport propre des donneÂ´es â€“ ce que les donneÂ´es ont a` dire â€“
indeÂ´pendendamment de toute information exteÂ´rieure. Cependant, des â€œa priori informa-
tifsâ€ ont aussi un roË†le important a` jouer. Ils peuvent aider a` raffiner lâ€™infeÂ´rence et a`
appreÂ´cier la sensibiliteÂ´ des conclusions visâ€“a`-vis dâ€™informations suppleÂ´mentaires.
cÂ© Revue MODULAD, 2006 -210- NumeÂ´ro 35
â€œan objective scientific report is a report of the whole prior-to-posterior map-
ping of a relevant range of prior probability distributions, keyed to meaningful
uncertainty interpretations.â€ (Dickey, page 135)
En regard du besoin dâ€™objectiviteÂ´ des scientifiques, on pourrait meË†me argumenter sur
la neÂ´cessiteÂ´ dâ€™explorer lâ€™impact de diffeÂ´rentes distributions initiales pertinentes.
Les techniques bayeÂ´siennes informatives sont ideÂ´alement adapteÂ´es pour combiner les
informations des donneÂ´es dâ€™une expeÂ´rience avec celles dâ€™autres eÂ´tudes, et par suite pour
planifier une seÂ´rie dâ€™expeÂ´riences. Des utilisations plus ou moins convaincantes ont eÂ´teÂ´
proposeÂ´es. Par exemple, Irony et Pennello (2001) discutent la manie`re dâ€™introduire ces
techniques dans les essais cliniques en meÂ´decine.
De facÂ¸on ideÂ´ale, quand une â€œbonne information initialeâ€ est disponible, elle peut
(doit ?) eË†tre utiliseÂ´e pour obtenir la meË†me conclusion quâ€™une â€œanalyse bayeÂ´sienne ob-
jectiveâ€, mais avec un plus petit eÂ´chantillon de donneÂ´es. Naturellement, cela supppose
une connaissance reÂ´elle baseÂ´e sur des donneÂ´es plutoË†t que des opinions dâ€™experts, qui sont
geÂ´neÂ´ralement sujettes a` controverses. Cependant mon opinion est que lâ€™utilisation de ces
techniques doit eË†tre plus systeÂ´matiquement exploreÂ´e avant de pouvoir appreÂ´cier ce que
devrait eË†tre leur contribution preÂ´cise a` lâ€™analyse des donneÂ´es expeÂ´rimentales.
18.3.3 Les probabiliteÂ´s preÂ´dictives : Un outil tre`s seÂ´duisant
â€œAn essential aspect of the process of evaluating design strategies is the ability
to calculate predictive probabilities of potential results.â€ (Berry, 1991, page 81)
Un apport majeur du paradigme bayeÂ´sienne est la faciliteÂ´ de faire des preÂ´dictions sur
des observations futures. Lâ€™ideÂ´e preÂ´dictive est centrale dans les eÂ´tudes expeÂ´rimentales, car
â€œthe essence of science is replication : a scientist should always be concer-
ned about what would happen if he or another scientist were to repeat his
experiment.â€ (Guttman, 1983)
Les proceÂ´dures bayeÂ´siennes preÂ´dictives permettent aux utilisateurs de reÂ´pondre a` des
questions essentielles telles que : â€œquel doit eË†tre lâ€™effectif de lâ€™expeÂ´rience pour avoir des
chances raisonnables de deÂ´montrer la conclusion rechercheÂ´e ?â€ ; â€œa` partir des donneÂ´es ac-
tuellement disponibles, quelles sont les chances que le reÂ´sultat final permette de conclure,
ou au contraire ne le permette pas ?â€ Ces questions sont non conditionnelles en ce quâ€™elles
neÂ´cessitent de consideÂ´rer toutes les valeurs possibles des parame`tres. Tandis que la pra-
tique freÂ´quentiste traditionnelles ne traite pas ces questions, les probabiliteÂ´s predictives
leur donnent des reÂ´ponses directes et naturelles.
En particulier, a` partir dâ€™une eÂ´tude pilote, les probabiliteÂ´s preÂ´dictives sur les limites
de creÂ´dibiliteÂ´ sont un reÂ´sumeÂ´ particule`rement utiles pour aider au choix de la taille
de lâ€™eÂ´chantillon dâ€™une expeÂ´rience (pour un paralle`le entre les meÂ´thodes bayeÂ´siennes et
freÂ´quentistes, voir Inoue, Berry & Parmigiani, 2005).
Lâ€™approche preÂ´dictive est une meÂ´thode tre`s seÂ´duisante (Baum, Houghton & Abrams,
1989) pour aider a` la deÂ´cision dâ€™interrompre une expeÂ´rience a` une eÂ´tape intermeÂ´diaire.
Dâ€™une part, une probabiliteÂ´ preÂ´dictive faible que lâ€™expeÂ´rience soit une reÂ´ussite peut eË†tre
utiliseÂ´e comme une re`gle pour abandonner lâ€™expeÂ´rience (â€œpour futiliteÂ´â€). Dâ€™autre part,
une probabiliteÂ´ preÂ´dictive suffisamment eÂ´leveÂ´e sugge`re dâ€™interrompre lâ€™expeÂ´rience avant
son terme (â€œpour succe`sâ€).
cÂ© Revue MODULAD, 2006 -211- NumeÂ´ro 35
Les probabiliteÂ´s preÂ´dictives sont aussi un outil important pour traiter les donneÂ´es
manquantes. Les analyses intermeÂ´diaires reviennent dâ€™ailleurs a` eÂ´valuer des donneÂ´es man-
quantes. Le cas de donneÂ´es de survie censureÂ´es est particulie`rement illustratif. Au mo-
ment dâ€™une analyse intermeÂ´diaire les donneÂ´es disponibles sont diviseÂ´es en trois cateÂ´gories :
(1) les patients inclus pour lesquels lâ€™eÂ´veÂ´nement auquel on sâ€™inteÂ´resse a deÂ´ja` eÂ´teÂ´ observeÂ´ ;
(2) les patients inclus deÂ´finitivement censureÂ´s ; (3) les patients inclus pour lesquels la
peÂ´riode dâ€™observation maximale nâ€™est pas encore atteinte. En conseÂ´quence les donneÂ´es
manquantes a` preÂ´dire concernent respectivement les patients de cette dernie`re cateÂ´gorie
pour lesquels nous avont une information partielle et les futurs patients dont lâ€™inclusion
est planifieÂ´e pour lesquels nous nâ€™avons pas dâ€™information directe. Lâ€™approche bayeÂ´sienne
traite cette situation de manie`re directe et efficace (Lecoutre, Mabika & Derzko, 2002).
On peut encore souligner le fait que les distributions preÂ´dictives sont eÂ´galement un outil
utile pour construire une distribution initiale subjective, du fait quâ€™il est geÂ´neÂ´ralement plus
facile dâ€™exprimer une opinion relative a` des donneÂ´es.
18.4 Calculs bayeÂ´siens et logiciels statistiques
Il y a actuellement de plus en plus dâ€™applications de lâ€™infeÂ´rence bayeÂ´sienne a` geÂ´neÂ´raux
lâ€™analyse des donneÂ´es expeÂ´rimentales. Mais un obstacle a` une utilisation routinie`re des
meÂ´thodes bayeÂ´siennes objectives est lâ€™absence de logiciels geÂ´neÂ´raux faciles dâ€™utilisation
et conviviaux qui seraient une contrepartie des logiciels freÂ´quentistes standard. On peut
espeÂ´rer que cet obstacle sera leveÂ´ dans le futur.
Quelques programmes ont eÂ´teÂ´ deÂ´veloppeÂ´s dans le but dâ€™enseigner lâ€™infeÂ´rence bayeÂ´sienne
eÂ´leÂ´mentaire : voir notamment First Bayes (Oâ€™Hagan, 1996) et un ensemble demacros pour
Minitab (Albert, 1996). Les logiciels que nous avons deÂ´veloppeÂ´s â€“ et illustreÂ´s en partie
ici â€“ ont une perspective plus ambitieuse. En particulier PAC est une programme geÂ´neÂ´ral
dâ€™analyse de variance qui inclut a` la fois les pratiques freÂ´quentistes traditionnelles (tests de
signification, intervalles de confiance) et des proceÂ´dures bayeÂ´siennes de routine (initiales
non informatives et conjugueÂ´es). Ces proceÂ´dures sont applicables a` des plans dâ€™expeÂ´rience
geÂ´neraux (en particulier, plans a` mesures reÂ´peÂ´teÂ´es), eÂ´quilibreÂ´s ou deÂ´seÂ´quilibreÂ´s, avec des
donneÂ´es univarieÂ´es ou multivarieÂ´es, et des covariables.
A un niveau plus avanceÂ´ et plus geÂ´neÂ´ral, WinBUGS (une partie du â€œBUGS projectâ€)
est un logiciel geÂ´neÂ´ral souple et efficace. Son objectif deÂ´clareÂ´ et de rendre la pratique des
meÂ´thodes MCMC (Monte Carlo par ChaË†Ä±nes de Markov) disponibles aux statisticiens. Il
contribue indeÂ´niablement a` lâ€™utilisation croissante de lâ€™infeÂ´rence bayeÂ´sienne pour des appli-
cations reÂ´elles. Il peut eË†tre gratuitement teÂ´leÂ´chargeÂ´ a` lâ€™adresse Internet : http ://www.mrc-
bsu.cam.ac.uk/bugs/welcome.shtml. Cependant, il peut eË†tre difficilement recommandeÂ´ a`
des deÂ´butants sâ€™ils ne sont pas fortement motiveÂ´s.
18.5 Quelques the`mes pour aller plus loin
Il nâ€™est pas dans mon intention de donner ici une liste de the`mes exhaustive, mais
seulement de preÂ´senter quelques domaines de recherche qui me semblent particulie`rement
importants pour le deÂ´veloppement meÂ´thodologique de lâ€™analyse bayeÂ´sienne objective pour
lâ€™analyse des donneÂ´es expeÂ´rimentales.
cÂ© Revue MODULAD, 2006 -212- NumeÂ´ro 35
18.5.1 Lâ€™interface des infeÂ´rences freÂ´quentiste et bayeÂ´sienne
MeË†me si ce tutoriel deÂ´fend lâ€™ideÂ´e que lâ€™approche bayeÂ´sienne doit eË†tre privileÂ´gieÂ´e,
cela devrait nous inviter a` ne pas radicaliser lâ€™opposition entre les infeÂ´rences bayeÂ´sienne
et freÂ´quentiste, mais plutoË†t a` consideÂ´rer leur interface. Bayarri et Berger (2004) font
une preÂ´sentation particulie`rement inteÂ´ressante de cette interface. Ils mettent en avant le
fait que lâ€™argument freÂ´quentiste traditionnel, qui met en jeu â€œdes reÂ´peÂ´titions du meË†me
proble`me avec diffeÂ´rentes donneÂ´esâ€ ne correspond pas a` ce qui est fait en pratique. En
conseÂ´quence câ€™est â€œun principe freÂ´quentiste-bayeÂ´sien conjointâ€ qui est pertinent : une
proceÂ´dure donneÂ´e (par exemple un intervalle de confiance 95% pour une moyenne sous
le mode`le Normal) est en pratique utiliseÂ´ sur â€œune seÂ´rie de diffeÂ´rents proble`mes met-
tant en jeu une seÂ´rie de diffeÂ´rentes moyennes de distributions Normales avec une seÂ´rie
correspondante de donneÂ´esâ€ (page 60).
Plus geÂ´neÂ´ralement, ils passent en revue les questions actuelles pour une synthe`se
bayeÂ´sienne-freÂ´quentiste dans une perspective meÂ´thodologique. Leur conclusion, qui semble
raisonnable, est dâ€™espeÂ´rer une unification meÂ´thodologique, mais pas une unification phi-
losophique.
â€œPhilosophical unification of the Bayesian and frequentist positions is not li-
kely, nor desirable, since each illuminates a different aspect of statistical infe-
rence. We can hope, however, that we will eventually have a general methodo-
logical unification, with both Bayesians and frequentists agreeing on a body
of standard statistical procedures for general useâ€. (Bayarri and Berger, 2004,
page 78)
Dans cette perspective, un domaine de recherche actif a pour objectif de trouver des
â€œprobability matching priorsâ€ pour lequels les probabiliteÂ´s finales de certains ensembles
speÂ´cifieÂ´s sont eÂ´gales (au moins approximatevement) a` leur probabiliteÂ´s de couverture :
voir Fraser, et al., 2003 ; Sweeting, 2005.
On notera encore, quâ€™en relevant le deÂ´fi dâ€™une unification meÂ´thodologique, Berger
(2003) discute â€œthe conditional frequentist approach to testingâ€, dont il argue quâ€™elle four-
nit preÂ´ciseÂ´ment (du moins en ce qui concerne les tests dâ€™hypothe`ses) la base dâ€™une unifi-
cation meÂ´thodologique des approches de Fisher, Jeffreys et Neyman.
18.5.2 EchangeabiliteÂ´ et mode`les hieÂ´rarchiques
Sans entrer dans le deÂ´tail, des eÂ´veÂ´nements aleÂ´atoires sont eÂ´changeables â€œsi nous attri-
buons la meË†me probabiliteÂ´ a` une assertion sur nâ€™importe quel nombre donneÂ´ dâ€™entre euxâ€
(de Finetti, 1972, page 213). Câ€™est une notion cleÂ´ de lâ€™infeÂ´rence statistique. Par exemple
des sujets futurs doivent eË†tre supposeÂ´s eÂ´changeables avec les sujets qui ont deÂ´ja` eÂ´teÂ´ ob-
serveÂ´s pour rendre les probabiliteÂ´s preÂ´dictives raisonnables. De meË†me, des expeÂ´riences
semblables doivent eË†tre supposeÂ´s eÂ´changeables pour une inteÂ´gration coheÂ´rente des infor-
mations.
La notion dâ€™eÂ´changeabiliteÂ´ est tre`s importante et utile dans le cadre bayeÂ´sien. En
utilisant la speÂ´cification de distribution initiales a` diffeÂ´rents niveaux, elle permet une
modeÂ´lisation souple de dispositifs expeÂ´rimentaux lieÂ´s au moyen de mode`les hieÂ´rarchiques
(Bernardo, 1996).
â€œIf a sequence of observations is judged to be exchangeable, then any subset
of them must be regarded as a random sample from some model, and there
cÂ© Revue MODULAD, 2006 -213- NumeÂ´ro 35
exist a prior distribution on the parameter of such model, hence requiring a
Bayesian approach.â€ (Bernardo, 1996, page 5)
Les mode`les hieÂ´rarchiques sont importants pour utiliser de manie`re approprieÂ´e les
donneÂ´es dâ€™expeÂ´riences multicentriques. Ils ont aussi particulie`rement adapteÂ´s pour les
meÂ´ta-analyses ou` nous avons des donneÂ´es dâ€™un certain nombre dâ€™eÂ´tudes pertinentes qui
peuvent eË†tre eÂ´changeables a` certains niveaux mais pas a` dâ€™autres (Dumouchel, 1990).
Dans tous les cas, le proble`me peut eË†tre deÂ´composeÂ´ en une seÂ´rie de mode`les conditionnels
plus simples, en utilisant la meÂ´thodologie bayeÂ´sienne hieÂ´rarchique (Good, 1980).
REÂ´FEÂ´RENCES
References
Agresti, A. & Min, Y. (2005). Frequentist performance of Bayesian confidence intervals
for comparing proportions in 2Ã— 2 contingency tables. Biometrics 61, 515â€“523.
Albert, J. (1996). Bayesian Computation Using Minitab. Wadsworth Publishing Company,
Belmont.
American Psychological Association (2001). Publication Manual of the American Psycho-
logical Association (5e`me eÂ´dition). Author, Washington, DC.
Baum, M., Houghton, J., & Abrams, K. R. (1989). Early stopping rules : clinical pers-
pectives and ethical considerations. Statistics in Medicine 13, 1459â€“1469.
Bayarri, M. J. & Berger, J. O. (2004). The interplay of Bayesian and frequentist analysis.
Statistical Science 19, 58â€“80.
Bayes (1763). Essay towards solving a problem in the doctrine of chances. Philosophical
Transactions of the Royal Society of London 53, 370â€“418. [Reproduit dans Biometrika
45, 293â€“315 (1958)]
Berger, J. O. (2003). Could Fisher, Jeffreys and Neyman have agreed on testing ? [with
discussion]. Statistical Science 18, 1â€“32.
Berger, J. (2004). The case for objective Bayesian analysis. Bayesian Analysis 1, 1â€“17.
Berger, J. O. & Bernardo, J. M. (1992). On the development of reference priors [with
discussion]. In J. M. Bernardo, J. O. Berger, A. P. Dawid, & A. F. M. Smith (Eds.),
Bayesian statistics 4. Proceedings of the Fourth Valencia International Meeting, 35â€“60.
Oxford Univ. Press, Oxford, England.
Bernard, J.-M. (1996). Bayesian interpretation of frequentist procedures for a Bernoulli
process. The American Statistician 50, 7â€“13.
Bernardo, J. M. (1979). Reference posterior distributions for Bayesian inference [with
discussion]. Journal of the Royal Statistical Society, Series B, Methodological 41, 113â€“
147.
Bernardo, J. M. (1996). The concept of exchangeability and its applications. Far East
Journal of Mathematical Sciences 4, 111â€“121.
Bernardo, J. & Smith, A. F. M. (1994). Bayesian Theory . John Wiley & Sons, New York.
cÂ© Revue MODULAD, 2006 -214- NumeÂ´ro 35
Bernoulli, J. (1713). Ars Conjectandi, (English translation by Bing Sung as Technical
report No. 2 of the Department of Statistics of Harvard University, February 12, 1966),
Basel, Switzerland.
Berry, D. A. (1991). Experimental design for drug development : a Bayesian approach.
Journal of Biopharmaceutical Statististics 1, 81-101.
Berry, D. A. (1997). Teaching elementary Bayesian statistics with real applications in
science. The American Statistician 51, 241â€“246.
Berry, G. & Armitage, P. (1995). Mid-P confidence intervals : a brief review. The Statis-
tician 44, 417â€“423.
Box, G. E. P. & Tiao, G. C. (1973). Bayesian Inference in Statistical Analysis. Reading,
Addison Wesley, MA.
Brown, L. D., Cai, T., & DasGupta, A. (2001). Interval estimation for a binomial propor-
tion [with discussion]. Statistical Science 16, 101â€“133.
Bunouf, P. (2006). Lois BayeÂ´siennes a Priori dans un Plan Binomial SeÂ´quentiel, The`se
de doctorat en matheÂ´matiques, UniversiteÂ´ de Rouen.
Bunouf P. & Lecoutre B. (2006). Bayesian priors in sequential binomial design. Comptes
Rendus de Lâ€™AcadeÂ´mie des Sciences Paris, SeÂ´rie I 343, 339â€“344.
Cai, T. (2005). One-sided confidence intervals in discrete distributions. Journal of Statis-
tical Planning and Inference 131, 63â€“88.
Chib, S & Greenberg, E. (1995). Understanding the Metropolis-Hastings algorithm. Ame-
rican Statistician 49, 327â€“335.
Copas, J. B. & Loeber, R. (1990). Relative improvement over chance (RIOC) for 2 Ã— 2
tables. British Journal of Mathematical and Statistical Psychology 43, 293â€“307.
Cox, D. R. (1970). The Analysis of Binary Data. Methuen, Londres.
de Cristofaro, R. (1996). Lâ€™influence du plan dâ€™eÂ´chantillonnage dans lâ€™infeÂ´rence statistique.
Journal de la SocieÂ´teÂ´ Statistique de Paris 137 23â€“34.
de Cristofaro, R. (2004). On the foundations of likelihood principle. Journal of Statistical
Planning and Inference 126 401â€“411.
de Cristofaro, R. (2006). Foundations of the â€˜Objective Bayesian Inferenceâ€™. First Sympo-
sium on Philosophy, History and Methodology of ERROR. Virginia Tech., Blacksburg
VA.
Dickey J. M. (1986). Discussion of Racine, A., Grieve, A. P., FluÂ¨hler, H. & Smith, A.
F. M., Bayesian methods in practice : Experiences in the pharmaceutical industry.
Applied Statistics 35, 93â€“150.
Diaconis, P. & Ylvisaker, D. (1985). Quantifying prior opinion. In J. M. Bernardo, D. V.
Lindley & A. F. M. Smith (Eds.), Bayesian Statistics 2, 133â€“156. North-Holland,
Amsterdam.
Dumouchel, W. (1990). Bayesian meta-analysis. In D. Berry (Ed.), Statistical Methodology
in Pharmaceutical Science, 509â€“529. Marcel-Dekker, New York.
Efron, B. (1998). R.A. Fisher in the 21st century [with discussion]. Statistical Science 13,
95â€“122.
ElQasyr, K. (2006). THe`se de doctorat de matheÂ´matiques en cours. UniversiteÂ´ de Rouen.
FDA (2006). Guidance for the use of Bayesian statistics in medical device, draft guidance
for industry and FDA staff, U.S. Department of Health and Human Services, Food
cÂ© Revue MODULAD, 2006 -215- NumeÂ´ro 35
and Drug Administration, Center for Devices and Radiological Health, Rockville MD.
http ://www.fda.gov/cdrh/osb/guidance/1601.html.
de Finetti, B. (1972). Probability, Induction and Statistics : The art of guessing. John
Wiley & Sons, Londres.
de Finetti, B. (1974). Theory of probability, vol.1. John Wiley & Sons, New York.
Fisher, R. A. (1922). On the mathematical foundations of theoretical statistics. Philoso-
phical Transactions of the Royal Society, Series A 222, 309â€“368.
Fisher, R. A. (1925). Theory of statistical estimation. Proceedings of the Cambridge Phi-
losophic Society, 22, 700â€“725.
Fleiss, J. L. (1981). Statistical Methods for Rates and Proportions (2e`me eÂ´dition). John
Wiley & Sons, New York.
Fraser, D. A. S., Reid, N., Wong, A. & Yi, G. Y. (2003). Direct Bayes for interest para-
meters. In J. M. Bernardo, M. J. Bayarri, J. O. Berger, A. P. Dawid, D. Heckerman,
A. F. M. Smith, & M. West (Eds.), Bayesian Statistics 7, 529â€“534. Oxford University
Press, Oxford, England.
Gamerman, D. (1997). Markov chain Monte Carlo : Stochastic simulation for Bayesian
inference. Chapman & Hall, Londres.
Gilks, W. R., Richardson, S., & Spiegelhalter, D. J. (1996). Markov Chain Monte Carlo
in Practice. Chapman & Hall, Londres.
Good, I. J. (1980). Some history of the hierarchical Bayesian methodology. In J. M. Ber-
nardo, M. H. DeGroot, D. V. Lindley, & A. F. M. Smith (Eds.), Bayesian Statistics,
489â€“519. Valencia University Press, Valencia. Oxford University Press, Oxford, En-
gland.
Guttman, L. (1983). What is not what in statistics ? The Statistician 26, 81â€“107.
Haldane, J. B. S. (1948). The precision of observed values of small frequencies. Biometrika
35, 297â€“300.
Inoue, L. Y. T., Berry, D. A., & Parmigiani, G. (2005). Relationship between Bayesian
and frequentist sample size determination. The American Statistician 59, 79â€“87.
Irony, T. Z. & Pennello, G. A. (2001). Choosing an appropriate prior for Bayesian medical
device trials in the regulatory setting. In American Statistical Association 2001 Procee-
dings of the Biopharmaceutical Section. American Statistical Association, Alexandria,
VA.
Jaynes, E. T. (2003). Probability Theory : The Logic of Science (Edited by G. L. Bret-
thorst), Cambridge University Press, Cambridge.
Jeffreys, H. (1961). Theory of Probability (3e`me eÂ´dition). Clarendon, Oxford (1st edition :
1939).
Johnson, Kotz, & Kemp, (1992). Univariate Discrete Distributions, 2e`me eÂ´dition. John
Wiley and Sons.
Kirk, R. E. (1982). Experimental Design. Procedures for the Behavioral Sciences. Brooks
/Cole, Pacific Grove, CA.
Laplace, P.-S (1774). MeÂ´moire sur la probabiliteÂ´ des causes par les eÂ´veÂ´nements. Savants
EÂ´tranges 6, 621â€“656 [publieÂ´ en anglais : Memoir on the probability of the causes of
events, Statistical Science 1, 364â€“378 (1986)].
Laplace, P.-S (1812). TheÂ´orie Analytique des ProbabiliteÂ´s. Courcier, Paris.
cÂ© Revue MODULAD, 2006 -216- NumeÂ´ro 35
Laplace, P.-S. (1986/1825). Essai Philosophique sur les ProbabiliteÂ´s (Reproduction de la
5e`me eÂ´dition, 1825). Christian Bourgois, Paris.
Lecoutre, B. (1984). Lâ€™Analyse BayeÂ´sienne des Comparaisons. Presses Universitaires de
Lille, Lille.
Lecoutre, B. (1996). Traitement statistique des donneÂ´es expeÂ´rimentales : des pratiques
traditionnelles aux pratiques bayeÂ´siennes. Avec programmes Windows par B. Lecoutre
et J. Poitevineau. DECISIA Editions, Levallois-Perret.
Lecoutre, B. (1996). Au dela` du test de signification ou lâ€™infeÂ´rence statistique sans tables
(a` la suite dâ€™Alain Morineau. La Revue de Modulad 17, 98â€“100.
Lecoutre, B. (1997/2005). Et si vous eÂ´tiez un bayeÂ´sien â€œqui sâ€™ignoreâ€ ? La Revue de Mo-
dulad 18, 81â€“87. ReÂ´eÂ´dition (compleÂ´teÂ´e) : La Revue de Modulad 32, 92â€“105.
Lecoutre, B. (1999). Two useful distributions for Bayesian predictive procedures under
normal models. Journal of Statistical Planning and Inference 77, 93â€“105.
Lecoutre, B. (2000). From significance tests to fiducial Bayesian inference. In H. Rouanet,
J.-M. Bernard, M.-C. Bert, B. Lecoutre, M.-P. Lecoutre, & & B. Le Roux, New ways in
statistical methodology : From significance tests to Bayesian inference (2e`me eÂ´dition.),
123â€“157. Peter Lang, Bern, SW.
Lecoutre, B. (2001). Bayesian predictive procedure for designing and monitoring expe-
riments. In Bayesian Methods with Applications to Science, Policy and Official Sta-
tistics. Office for Official Publications of the European Communities, Luxembourg,
301â€“310.
Lecoutre, B. (2005). Former les eÂ´tudiants et les chercheurs aux meÂ´thodes bayeÂ´siennes pour
lâ€™analyse des donneÂ´es expeÂ´rimentales. La Revue de Modulad 33, 85â€“107.
Lecoutre, B. (2006). Training students and researchers in Bayesian methods for experi-
mental data analysis. Journal of Data Science 4, 207â€“232.
Lecoutre, B. & Charron, C. (2000). Bayesian procedures for prediction analysis of impli-
cation hypotheses in 2Ã— 2 contingency tables. Journal of Educational and Behavioral
Statistics 25, 185â€“201.
Lecoutre, B., Derzko, G., & Grouin, J.-M. (1995). Bayesian predictive approach for infe-
rence about proportions. Statistics in Medicine 14, 1057â€“1063.
Lecoutre, B. & ElQasyr, K. (2005). Play-the-winner rule in clinical trials : models for
adaptative designs and Bayesian methods. In J. Janssen & P. Lenca (Eds.), Applied
Stochastic Models and Data Analysis Conference 2005 Proceedings, Part X. Health,
1039â€“1050. ENST Bretagne, Brest.
Lecoutre, B. & Faure, S. (2007). A note on new confidence intervals for the difference
between two proportions based on an Edgeworth expansion. Journal of Statistical
Planning and Inference 137, 355â€“356.
Lecoutre, B., Lecoutre, M.-P., & Poitevineau, J. (2001). Uses, abuses and misuses of signi-
ficance tests in the scientific community : wonâ€™t the Bayesian choice be unavoidable ?
International Statistical Review 69, 399â€“418.
Lecoutre, B., Mabika, B., Derzko, G. (2002). Assessment and monitoring in clinical trials
when survival curves have distinct shapes in two groups : a Bayesian approach with
Weibull modeling. Statistics in Medicine 21, 663â€“674.
Lecoutre, B. & Poitevineau, J. (1992). PAC (Programme dâ€™Analyse des Comparaisons) :
Guide dâ€™utilisation et manuel de reÂ´feÂ´rence. CISIA-CERESTA, Montreuil.
Lecoutre, B. & Poitevineau, J. (2005). Le logiciel â€œLePACâ€. La Revue de Modulad 33.
cÂ© Revue MODULAD, 2006 -217- NumeÂ´ro 35
Lecoutre, B., Poitevineau, J., Derzko, G., & Grouin, J.-M. (2000). DeÂ´sirabiliteÂ´ et faisabiliteÂ´
des meÂ´thodes bayeÂ´siennes en analyse de variance : application a` des plans dâ€™expeÂ´rience
complexes utiliseÂ´s dans les essais cliniques. In I. Albert & B. Asselain (Eds.), BiomeÂ´trie
et MeÂ´thodes bayeÂ´siennes 14, SocieÂ´teÂ´ FrancÂ¸aise de BiomeÂ´trie, Paris, 1â€“23.
Lecoutre, B., Poitevineau, J., & Lecoutre, M.-P. (2005). Une raison pour ne pas aban-
donner les tests de signification de lâ€™hypothe`se nulle / A reason why not to ban Null
Hypothesis S/ignificance Tests. La Revue de Modulad 33, 243â€“253.
Lecoutre, M.-P. (2000). And... What about the researcherâ€™s point of view. In H. Rouanet,
J.-M. Bernard, M.-C. Bert, B. Lecoutre, M.-P. Lecoutre, & B. Le Roux, New ways in
statistical methodology : From significance tests to Bayesian inference (2e`me eÂ´dition.),
65â€“95. Peter Lang, Bern, SW.
Lecoutre, M.-P., Poitevineau, J., & Lecoutre, B. (2003). Even statisticians are not immune
to misinterpretations of Null Hypothesis Significance Tests. International Journal of
Psychology 38, 37â€“45.
Lee, P. (2004). Bayesian Statistics : An Introduction (3rd edition). Oxford University
Press, New York.
Lhoste, E. (1923). Le Calcul des probabiliteÂ´s appliqueÂ´ lâ€™artillerie, lois de probabiliteÂ´ a
priori. Revue dâ€™artillerie 91.
Lindley, D. V. (1993). The analysis of experimental data : The appreciation of tea and
wine. Teaching Statistics 15, 22â€“25.
Morrison, D.E. & Henkel, R.E. (1969). Significance tests reconsidered. The American
Sociologist 4, 131â€“140.
Mossman, D. & Berger, J. (2001). Intervals for post-test probabilities : a comparison of
five methods. Medical Decision Making 21, 498â€“507.
Nelson, N., Rosenthal, R., & Rosnow, R. L. (1986). Interpretation of significance levels
and effect sizes by psychological researchers. American Psychologist 41, 1299â€“1301.
Novick, M. R., & Jackson, P. H. (1974). Statistical Methods for Educational and Psycho-
logical Research. McGraw-Hill, NewYork.
Oâ€™Hagan, A. (1996). First Bayes [Teaching package for elementary Bayesian Statistics].
http ://www.tonyohagan.co.uk/1b/.
Pagano, R. R. (1990). Understanding statistics in the behavioral sciences (3e`me eÂ´dition).
West, St. Paul, MN.
Perks, W. (1947). Some observations on inverse probability including a new indifference
rule. Journal of the Institute of Actuaries 73, 285â€“312.
Poitevineau, J., & Lecoutre, B. (2001). The interpretation of significance levels by psy-
chological researchers : The .05-cliff effect may be overstated. Psychonomic Bulletin
and Review 8, 847â€“850.
Rice, W. R. (1988). A new probability model for determining exact P value for 2 Ã— 2
contingency tables. Biometrics 44, 1â€“22.
Robert, C. P. (1992). Lâ€™Analyse Statistique BayeÂ´sienne. Economica, Paris.
Robert, C. P. & Casella, G. (2004). Monte Carlo Statistical Methods. Springer, New York.
Rosenthal, R. & Gaito, J. (1963). The interpretation of levels of significance by psycholo-
gical researchers. Journal of Psychology 55, 33â€“38.
Rosenthal, R. & Gaito, J. (1964). Further evidence for the cliff effect in the interpretation
of levels of significance. Psychological Reports 15, 570.
cÂ© Revue MODULAD, 2006 -218- NumeÂ´ro 35
Rouanet, H. & Lecoutre, B. (1983). Specific inference in ANOVA : From significance tests
to Bayesian procedures. British Journal of Mathematical and Statistical Psychology
36, 252â€“268.
Routledge, R. D. (1994). Practicing safe statistics with the mid-pâˆ—. The Canadian Journal
of Statistics 22, 103â€“110.
Rozeboom, W. W (1960). The fallacy of the null hypothesis significance test. Psychological
Bulletin 57, 416â€“428.
Savage, L. (1954). The Foundations of Statistical Inference. John Wiley & Sons, New
York.
Smith, A. (1995). A conversation with Dennis Lindley. Statistical Science 10, 305â€“319.
Spiegelhalter, D. J., Freedman, L. S., & Parmar, M. K. B. (1994). Bayesian approaches
to randomized trials. Journal of the Royal Statistical Society, Series A 157, 357â€“416.
Student (1908). The probable error of a mean. Biometrika 6, 1â€“25.
Sweeting, T. J. (2005). On the implementation of local probability matching priors for
interest parameters. Biometrika 92, 47â€“57.
Tan, S. B., Chung, Y. F. A. , Tai, B. C., Cheung, Y. B., & Machin, D. (2003). Elicitation
of prior distributions for a phase III randomized controlled trial of adjuvant therapy
with surgery for hepatocellular carcinoma. Controlled Clinical Trials 24, 110â€“21.
Tierney, L. (1994). Markov chains for exploring posterior distributions [with discussion].
The Annals of Statistics 21, 1701â€“1762.
Toecher, K. D. (1950). Extension of the Neyman-Pearson theory of tests to discontinuous
variables. Biometrika 37, 130â€“144.
Walley, P. (1996). Inferences from multinomial data : learning about a bag of marbles
[with discussion]. Journal of the Royal Statistical Society B 58, 3â€“57.
Wilkinson, L. and Task Force on Statistical Inference, APA Board of Scientific Affairs
(1999). Statistical Methods in Psychology Journals : Guidelines and Explanations.
American Psychologist 54, 594â€“604.
Winkler, R. L. (1974). Statistical analysis : theory versus practice. In The Concept of
Probability in Psychological Experiments, Ed. C.-A.S. StaeÂ¨l Von Holstein, 127â€“140. D.
Reidel, Dordrecht, Pays-Bas.
Ye, K. (1993). Reference priors when the stopping rule depends on the parameter of
interest. Journal of the American Statistical Association 88, 360â€“363.
Zaykin, D. V., Meng, Z, & Ghosh, S. K. (2004). Interval estimation of genetic susceptibility
for retrospective case-control studies. BMC Genetics 5 :9, 1â€“11.
Zelen, M. (1969). Play the winner rule and the controlled clinical trial. Journal of the
American Statistical Association 64, 131â€“146, 1969.
Zhou, X.-H. & Qin, G. (2004). New intervals for the difference between two independent
binomial proportions. Journal of Statistical Planning and Inference 123, 97â€“115.
Zhou, X.-H. & Qin, G. (2005). A new confidence interval for the difference between two
binomial proportions of paired data. Journal of Statistical Planning and Inference 128,
527â€“542.
Zhou, X.-H. & Qin, G. (2007). A supplement to : â€œA new confidence interval for the
difference between two binomial proportions of paired dataâ€. Journal of Statistical
Planning and Inference 137, 357â€“358.
cÂ© Revue MODULAD, 2006 -219- NumeÂ´ro 35
