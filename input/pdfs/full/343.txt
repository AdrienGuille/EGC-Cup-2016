Bien cube, les donn√©es textuelles peuvent s‚Äôagr√©ger !
Sandra Bringay‚àó,‚àó‚àó, Anne Laurent‚àó,
Pascal Poncelet‚àó, Mathieu Roche‚àó, Maguelonne Teisseire‚àó,‚àó‚àó‚àó
‚àóLIRMM ‚Äì CNRS, 161 rue Ada, Montpellier, France
{bringay,laurent,poncelet,mroche,teisseire}@lirmm.fr
‚àó‚àóUniv. Montpellier 3
‚àó‚àó‚àóCEMAGREF ‚Äì UMR TETIS, maguelonne.teisseire@cemagref.fr
R√©sum√©. La masse des donn√©es aujourd‚Äôhui disponibles engendre des besoins
croissants de m√©thodes d√©cisionnelles adapt√©es aux donn√©es trait√©es. Ainsi, r√©-
cemment de nouvelles approches fond√©es sur des cubes de textes sont apparues
pour pouvoir analyser et extraire de la connaissance √† partir de documents. L‚Äôori-
ginalit√© de ces cubes est d‚Äô√©tendre les approches traditionnelles des entrep√¥ts et
des technologies OLAP √† des contenus textuels. Dans cet article, nous nous int√©-
ressons √† deux nouvelles fonctions d‚Äôagr√©gation. La premi√®re propose une nou-
velle mesure de TF -IDF adaptative permettant de tenir compte des hi√©rarchies
associ√©es aux dimensions. La seconde est une agr√©gation dynamique permet-
tant de faire √©merger des groupements correspondant √† une situation r√©elle. Les
exp√©riences men√©es sur des donn√©es issues du serveur HAL d‚Äôune universit√©
confirment l‚Äôint√©r√™t de nos propositions.
1 Introduction
Avec le d√©veloppement de l‚ÄôInternet, de plus en plus de documents textuels sont dispo-
nibles. Extraire de la connaissance ou analyser et interroger de tels volumes de donn√©es est un
enjeu important et de nombreux travaux de recherche se sont int√©ress√©s √† ces probl√©matiques.
Ainsi, par exemple, les travaux men√©s autour de la fouille de textes ont propos√© de nouvelles
approches pour classer automatiquement des documents (Sebastiani (2002)), rechercher les
nouvelles tendances (Saga et al. (2009)) ou extraire de l‚Äôinformation dans des donn√©es tex-
tuelles (Chang et al. (2006)). Plus r√©cemment, de nouvelles approches fond√©es sur des cubes
de textes proposent d‚Äôutiliser les technologies OLAP pour analyser et extraire de la connais-
sance. L‚Äôun des avantages de ces approches est notamment de pouvoir utiliser des op√©rateurs
comme Roll-Up ou Drill-Down pour naviguer au travers des hi√©rarchies et ainsi agr√©ger les
donn√©es en fonction des requ√™tes utilisateurs.
De mani√®re √† illustrer les probl√©matiques que nous √©tudions dans cet article, consid√©rons,
par exemple, les documents extraits de d√©p√™ches concernant le virus de la grippeA(H1N1). En
√©tudiant les diff√©rents articles, il est ais√© de constater que plusieurs cat√©gories de documents
peuvent appara√Ætre : articles sur le vaccin, articles sur de nouveaux cas d√©clar√©s, articles sur
les recommandations ou m√™me articles g√©n√©raux. Dans un processus d‚Äôaide √† la d√©cision, si
nous d√©sirons retrouver les mots caract√©ristiques de chaque cat√©gorie, nous pouvons utiliser
RNTI-E-19- 585 -
Bien cube, les donn√©es textuelles peuvent s‚Äôagr√©ger !
des entrep√¥ts de donn√©es. Dans un tel contexte, il est indispensable d‚Äôextraire pour chacune
des cat√©gories les termes les plus repr√©sentatifs en tenant compte du fait qu‚Äôil peut exister
une hi√©rarchie entre les diff√©rentes cat√©gories (c-√†-d. la cat√©gorie "vaccin" peut √™tre divis√©e
en "vaccin en Europe", "vaccin en Asie", "vaccin aux Etats-Unis", etc). Dans cet exemple,
nous consid√©rons qu‚Äôil existe une hi√©rarchie disponible. Toutefois une telle connaissance n‚Äôest
pas forc√©ment ais√©e √† obtenir et sa d√©finition n‚Äôest pas toujours caract√©ristique d‚Äôune r√©alit√©.
Par exemple, pourquoi √©tablir une distinction entre "vaccin en Europe" et "vaccin aux Etats
Unis" ? Cette distinction est d‚Äôautant plus complexe √† effectuer lorsque l‚Äôutilisateur ne sait pas
au pr√©alable qu‚Äôil peut exister dans les documents des sp√©cificit√©s propres aux r√©gions.
Dans cet article, notre contribution est double. D‚Äôune part, nous proposons un nouveau
mod√®le de donn√©es qui permet de construire un entrep√¥t de donn√©es textuelles afin de r√©pondre
ais√©ment aux demandes des d√©cideurs via des requ√™tes OLAP en tenant compte des hi√©rarchies
existantes. D‚Äôautre part, nous √©tendons ce mod√®le √† la d√©finition automatique de dimensions
g√©n√©r√©es √† partir des documents √©tudi√©s sur lesquels le d√©cideur pourra √©galement naviguer.
Le reste de l‚Äôarticle est organis√© de la mani√®re suivante. Dans la section 2, nous pr√©sentons
notre probl√©matique √† partir d‚Äôune base exemple qui illustrera les diff√©rents concepts introduits.
Dans la section 3, nous d√©crivons les travaux ant√©rieurs li√©s √† ce contexte. La section 4 d√©taille
notre proposition. Les exp√©rimentations men√©es sont d√©crites dans la section 5. Enfin nous
concluons cet article en pr√©sentant quelques perspectives.
2 Probl√©matique
FIG. 1 ‚Äì La hi√©rarchie associ√©e √† l‚ÄôEnseignement.
Supposons que nous ayons une hi√©rarchie li√©e aux enseignements d√©finie de la mani√®re
suivante : des enseignants appartiennent √† une composante et une universit√© est compos√©e de
plusieurs composantes (UFR, IUT, etc). La figure 1 d√©crit une telle repr√©sentation dans la-
quelle Comp1 est compos√©e de quatre enseignants, Comp2 est compos√©e de deux enseignants
et les deux composantes appartiennent √† une m√™me Universit√© Univ1. Sur cette figure, les dif-
f√©rentes descriptions de cours (documents textuels) associ√©es aux enseignants sont √©galement
repr√©sent√©es. Nous pouvons ainsi constater sur la figure que l‚Äôenseignant e1 est attach√© seul
√† la description d1 d‚Äôun cours alors que l‚Äôenseignant e2 enseigne avec un autre intervenant
d‚Äôune autre composante (enseignant e5) pour effectuer le cours d3. Nous consid√©rons par la
suite qu‚Äôun document propre √† un enseignement est d√©crit par un ensemble de mots-cl√©s. Par
exemple, le document d5 est d√©crit par les mots-cl√©s m15, m16, m17, m18 et m19. Le tableau
1 d√©crit les diff√©rentes caract√©ristiques des enseignements.
RNTI-E-19 - 586 -
S. Bringay et al
Doc. enseignant composante Univ. Liste de mots cl√©s
d1 e1 Comp1 Univ1 {m1,m2,m3,m4,m5}
d2
e2 Comp1 Univ1 {m6,m7,m8,m9,m10}
e3 Comp1 Univ1
d3
e2 Comp1 Univ1 {m6,m7,m8,m11,m12}
e5 Comp2 Univ1
d4
e2 Comp1 Univ1 {m6,m13,m14,m11,m10}
e4 Comp1 Univ1
d5
e5 Comp2 Univ1 {m15,m16,m17,m18,m19}
e6 Comp2 Univ1
TAB. 1 ‚Äì Liste de mots cl√©s, d‚Äôenseignants et des composantes par document
Rappelons que le but de nos travaux est de proposer des mots-cl√©s repr√©sentatifs en fonction
des diff√©rents niveaux de hi√©rarchies existants (enseignant, composante, etc) dans un contexte
d‚Äôentrep√¥t de donn√©es. Ces mots-cl√©s seront pr√©sents dans les cellules de l‚Äôentrep√¥t.
De mani√®re classique, nous pouvons regrouper les enseignants suivant les composantes en
appliquant la hi√©rarchie existante. Ceci permet de s√©lectionner les mots les plus discriminants
√† mettre en relief pour le d√©cideur. Ainsi, si nous prenons le niveau "enseignant", nous pou-
vons constater par exemple que pour le d√©cideur les mots repr√©sentatifs pour l‚Äôenseignant e2
sont : m6, m7, m8, m9, m10, m11, m12, m13 et m14. Par contre si nous nous int√©ressons au
niveau "composantes", nous constatons que les mots repr√©sentatifs diff√®rent. Ainsi, notre pre-
mi√®re contribution dans cet article est d‚Äôutiliser et d‚Äôadapter des mesures issues du domaine de
la Recherche d‚ÄôInformation dans un contexte d‚Äôentrep√¥t de donn√©es. Ces mesures proposent
d‚Äôutiliser les connaissances li√©es √† une organisation hi√©rarchique existante afin de s√©lectionner
les mots-cl√©s les plus discriminants en fonction du niveau de la hi√©rarchie interrog√©e.
Consid√©rons √† nouveau les diff√©rents mots utilis√©s dans les documents. Si nous examinons
l‚Äôenseignant e1 qui appartient √† Comp1, nous pouvons constater qu‚Äôil ne partage aucun de ses
enseignements avec les membres de sa composante alors que e2 et e5, de composantes diff√©-
rentes, partagent par contre des enseignements. Notre objectif dans la seconde contribution de
cet article est de faire √©merger ce type de comportement et donc de permettre au d√©cideur de
conna√Ætre les regroupements r√©els des enseignants ind√©pendamment de toute hi√©rarchie exis-
tante.
3 Travaux Ant√©rieurs
Les entrep√¥ts de donn√©es ont √©t√© introduits au d√©but des ann√©es 1990 (Codd et al. (1993))
pour r√©pondre aux besoins grandissants des d√©cideurs. Ceux-ci souhaitaient alors √™tre munis
de bases de donn√©es non pas d√©di√©es au stockage robuste de leurs donn√©es pour r√©pondre
√† des requ√™tes simples et r√©p√©titives (bases de donn√©es transactionnelles) mais plut√¥t √† une
repr√©sentation de leurs donn√©es en vue de prendre les meilleures d√©cisions et r√©pondre √† des
requ√™tes non r√©p√©titives et plus complexes. Le mod√®le multidimensionnel a alors √©t√© propos√©
pour r√©pondre √† ce besoin, et permet d‚Äô√©tudier un ensemble d‚Äôindicateurs (ou mesures) en
fonction de plusieurs dimensions, chaque dimension pouvant √™tre munie d‚Äôune ou plusieurs
RNTI-E-19- 587 -
Bien cube, les donn√©es textuelles peuvent s‚Äôagr√©ger !
hi√©rarchies. Les op√©rateurs OLAP permettent de naviguer de mani√®re intuitive dans de telles
donn√©es multidimensionnelles (par exemple pour visualiser les donn√©es √† diff√©rents niveaux
de hi√©rarchies).
Quelques travaux r√©cents se sont int√©ress√©s √† int√©grer les donn√©es textuelles dans un contexte
d‚Äôentrep√¥t de donn√©es. Dans ce cadre, des m√©thodes d‚Äôagr√©gation adapt√©es aux donn√©es tex-
tuelles ont √©t√© propos√©es. Par exemple, les travaux de Keith et al. (2005) proposent d‚Äôutiliser
des approches de TALN (Traitement Automatique du Langage Naturel) pour agr√©ger les mots
ayant la m√™me racine ou les m√™mes lemmes (connaissances morpho-syntaxiques). Les auteurs
proposent √©galement de rassembler les mots sur la base de classifications s√©mantiques g√©n√©ra-
listes existantes (WordNet et Roget). Outre l‚Äôutilisation de connaissances morpho-syntaxiques
et s√©mantiques pour agr√©ger les donn√©es textuelles, d‚Äôautres travaux utilisent des approches
num√©riques issues du domaine de la Recherche d‚ÄôInformation (RI) pour agr√©ger les donn√©es
textuelles (Pujolle et al. (2008); Lin et al. (2008); P√©rez-Mart√≠nez et al. (2008)). Ainsi, Lin
et al. (2008) agr√®ge les documents sur la base des mots-cl√©s pr√©sents dans ces derniers en uti-
lisant une hi√©rarchie s√©mantique des mots pr√©sents dans l‚Äôentrep√¥t et des mesures issues de la
RI. De telles m√©thodes issues de la RI sont aussi utilis√©es dans les travaux de P√©rez-Mart√≠nez
et al. (2008) qui consistent √† prendre en compte une dimension "contexte" et "pertinence" pour
construire un entrep√¥t de donn√©es textuelles appel√© R-Cube. Certaines approches proposent
d‚Äôajouter une nouvelle dimension sp√©cifique. Par exemple, dans (Zhang et al. (2009)) les au-
teurs ajoutent une dimension ‚Äôtopic‚Äô et appliquent l‚Äôapproche PLSA (Hofmann (1999)) pour
extraire les th√®mes repr√©sentatifs des documents dans cette nouvelle dimension. Enfin, Pu-
jolle et al. (2008) proposent d‚Äôagr√©ger des parties de documents afin d‚Äôoffrir au d√©cideur des
mots-cl√©s caract√©ristiques propres √† cette agr√©gation. Dans ce cadre, les auteurs utilisent une
premi√®re fonction pour s√©lectionner les mots-cl√©s les plus significatifs en utilisant la mesure
TF -IDF classique issue du domaine de la RI. L‚Äôobjectif de nos travaux est assez similaire √†
cette derni√®re approche. Toutefois, nous souhaitons √©tendre la prise en compte de la hi√©rarchie
dans les documents rendus aux d√©cideurs. En d‚Äôautres termes, nous souhaitons ne retourner que
les mots-cl√©s significatifs par rapport √† un niveau donn√©. Par exemple, dans le cas des mots-cl√©s
significatifs, leur agr√©gation Avg-Kw qui utilise un TF -IDF ne permet de conna√Ætre que les
mots significatifs pour des chercheurs mais ne permet pas de prendre en compte une hi√©rarchie
existante. Pujolle et al. (2008) proposent √©galement d‚Äôutiliser une ontologie l√©g√®re. Toutefois,
l√† aussi, l‚Äôobjectif est diff√©rent car ils s‚Äôint√©ressent √† la repr√©sentation de mots g√©n√©riques par
rapport aux mots du domaine. Dans notre cas, nous souhaitons extraire les mots cl√©s signifi-
catifs par rapport √† une hi√©rarchie existante. En outre, nous souhaitons pouvoir effectuer des
regroupements significatifs pour le d√©cideur m√™me s‚Äôil n‚Äôexiste pas de hi√©rarchie fixe d√©finie.
4 Contribution
Dans cette section nous pr√©sentons notre approche. Dans un premier temps, nous d√©crivons
le mod√®le de donn√©es utilis√©. Nous pr√©sentons ensuite l‚Äôagr√©gation adaptative selon le niveau
existant puis l‚Äôagr√©gation dynamique. Pour chacune de ces approches nous pr√©sentons tout
d‚Äôabord le principe g√©n√©ral puis nous explicitons sa mise en ≈ìuvre.
RNTI-E-19 - 588 -
S. Bringay et al
4.1 Le mod√®le de donn√©es
Dans cette section, nous d√©finissons un mod√®le de donn√©es pour repr√©senter les cubes de
textes. Une table de faits F est d√©finie sur le sch√©ma D = {T, . . . , Tn,M} o√π Ti (i = 1, .., n)
correspondent aux dimensions (P√©rez-Mart√≠nez et al. (2008)) etM correspond √† une mesure.
Les diff√©rentes mesures utilis√©es sont d√©crites dans les sections suivantes. Chaque dimension
Ti est d√©finie sur un domaine D = dom(Ti) partitionn√© en un ensemble de cat√©gories (ou
niveaux de granularit√©) Cj . On a donc D = ‚à™jCj . D doit √™tre muni d‚Äôun ordre partiel D
permettant de comparer les valeurs du domaine D. Chaque cat√©gorie repr√©sente les valeurs
associ√©es √† un niveau de granularit√©. Nous notons e ‚àà D pour pr√©ciser que e est une valeur
de dimension de D, s‚Äôil existe une cat√©gorie Cj ‚äÜ D telle que e ‚àà ‚à™jCj . Notons que deux
cat√©gories particuli√®res sont distingu√©es et sont pr√©sentes sur toutes les dimensions :‚ä•D etD
‚àà CD correspondant respectivement au niveau de plus fine et de plus forte granularit√©. Dans
le cadre de notre approche, l‚Äôordre partiel d√©fini sur les domaines des dimensions correspond
√† l‚Äôinclusion ensembliste des mots cl√©s associ√©s aux valeurs de dimension consid√©r√©es. Ainsi,
soient deux valeurs e1, e2 ‚àà ‚à™jCj , on a e1 D e2 si e1 est logiquement contenu dans e2.
Par exemple, la dimension Enseignement de la figure 1 poss√®de les cat√©gories ‚ä•enseignement
= Enseignant ‚â§ Composante ‚â§ Universite ‚â§ enseignement. Les valeurs de dimen-
sions sont dom(Enseignement) = {e1, e2, e3, Comp1, Comp2, Univ1, ...} r√©parties dans
ces cat√©gories (niveaux de granularit√©) de la mani√®re suivante : Enseignant = {e1, e2, e3},
Composante = {Comp1, Comp2}, Univ = {Univ1, ...}. L‚Äôordre partiel D sur les va-
leurs des dimensions peut bien entendu √™tre g√©n√©ralis√© aux cat√©gories : pour C1, C2 ‚àà CD,
on a alors C1 ‚â§D C2 si ‚àÉe1 ‚àà C1, e2 ‚àà C2 tels que e1 D e2. Par exemple, nous
avons : e1 D Comp1 D Univ1 D . La prise en compte de hi√©rarchie dynamique
est telle que toutes les cat√©gories de cette dimension doivent respecter l‚Äôordre partiel d√©fini.
Notre mod√®le permet de prendre en compte diff√©rentes dimensions (e.g. le temps tel que :
‚ä•temps = mois ‚â§ semestre ‚â§ ann√©e ‚â§ temps) et bien entendu une dimension corres-
pondant aux diff√©rentes informations extraites des documents. Cette dimension est d√©finie de
la mani√®re suivante : il n‚Äôexiste pas de hi√©rarchie sur cette dimension et chaque valeur cor-
respond aux mots-cl√©s associ√©s aux documents. Ainsi, pour un enseignant donn√©, le contenu
d‚Äôune cellule correspond √† la fr√©quence d‚Äôapparition d‚Äôun mot dans un document. Par exemple
pour l‚Äôenseignant e1 elle peut contenir la fr√©quence d‚Äôapparition du motm1.
4.2 Agr√©gation Adaptative selon le niveau hi√©rarchique
4.2.1 Pr√©sentation g√©n√©rale
Dans nos travaux, nous nous appuyons sur une hi√©rarchie originale adapt√©e aux donn√©es
textuelles. Dans cette hi√©rarchie, les n≈ìuds sont les √©l√©ments que nous souhaitons agr√©ger et
les feuilles sont les descripteurs (mots-cl√©s) de ces √©l√©ments. Pour chaque agr√©gation, le but
que nous nous fixons est de s√©lectionner les descripteurs pertinents. Cette s√©lection d√©pendra
du niveau et des n≈ìuds que nous d√©sirons agr√©ger. Nous proposons dans ce cas une mesure
fond√©e sur la mesure TF-IDF bien connue en Recherche d‚ÄôInformation. Nous montrerons dans
la section 4.2.2 de quelle mani√®re nous avons adapt√© cette mesure √† la probl√©matique des
entrep√¥ts de donn√©es. Notre approche s‚Äôappuie sur l‚Äôutilisation d‚Äôune hi√©rarchie du domaine,
ce qui est relativement classique dans la litt√©rature (voir section 3). Cependant, l‚Äôoriginalit√© de
RNTI-E-19- 589 -
Bien cube, les donn√©es textuelles peuvent s‚Äôagr√©ger !
notre approche r√©side dans la m√©thode d‚Äôagr√©gation qui d√©pend du niveau trait√©, d‚Äôo√π le nom
d‚Äôagr√©gation adaptative. Ainsi, d‚Äôun niveau √† l‚Äôautre les descripteurs pertinents extraits pour
caract√©riser une cellule de notre entrep√¥t peuvent se r√©v√©ler extr√™mement diff√©rents.
En reprenant l‚Äôexemple que nous avons d√©crit en section 2, les mots-cl√©s pour d√©crire un
IUT (par exemple, le mot-cl√© "R√©seaux") n‚Äôest pas toujours adapt√© pour discriminer les ensei-
gnements effectu√©s par les intervenants dans une telle composante. En d‚Äôautres termes, un tel
mot-cl√© est caract√©ristique pour d√©crire un IUT sp√©cialis√© par rapport √† diff√©rentes composantes
mais ne permet pas de discriminer les cours d‚Äôun IUT "R√©seaux et T√©l√©communication". De
la m√™me mani√®re, en utilisant une hi√©rarchie de laboratoires (laboratoire, √©quipe, chercheur)
un terme tr√®s discriminant pour d√©crire une √©quipe (par exemple, le terme ‚Äôdata-mining‚Äô) n‚Äôest
pas n√©cessairement pertinent pour distinguer les membres d‚Äôune √©quipe de fouille de donn√©es.
4.2.2 M√©thode mise en ≈ìuvre
Dans notre processus, la premi√®re √©tape consiste √† fusionner chaque feuille correspondant
aux attentes de l‚Äôutilisateur. Ceci revient √† fusionner les mots (de mani√®re bool√©enne et/ou fr√©-
quentielle) des diff√©rents documents. Le but de cette √©tape est de lister tous les mots situ√©s
dans les documents correspondant √† un niveau donn√© (par exemple, "enseignant", "compo-
sante", "Universit√©"). Si l‚Äôutilisateur souhaite axer sa recherche au niveau de l‚Äôenseignant e, les
mots-cl√©s des articles √©crits par e forment le vecteur de cet enseignant. Nous pouvons appliquer
ce m√™me principe au niveau des composantes (Roll-up).
√Ä titre d‚Äôexemple, en nous appuyant sur la figure 1 et le tableau 1, e2 est associ√© aux
documents d2 et d3. Nous construisons alors un espace vectoriel dont la dimension correspond
au nombre de mots rencontr√©s (ou s√©lectionn√©s) dans l‚Äôensemble des documents. Le processus
appliqu√© est illustr√© dans le tableau 2 qui repr√©sente les vecteurs de documents de mani√®re
bool√©enne et fr√©quentielle.
Repr√©sentation bool√©enne
Mots d2 d3 d4 ens. e2
m1 0 0 0 0
m2 0 0 0 0
...
m6 1 1 1 1
m7 1 1 0 1
m8 1 1 0 1
m9 1 0 0 1
m10 1 0 1 1
m11 0 1 1 1
m12 0 1 0 1
...
m19 0 0 0 0
Repr√©sentation fr√©quentielle
Mots d2 d3 d4 ens. e2
m1 0 0 0 0
m2 0 0 0 0
...
m6 fr
2
6 fr
3
6 fr
4
6 fr
2
6 + fr
3
6 + fr
4
6
m7 fr
2
7 fr
3
7 0 fr
2
7 + fr
3
7
m8 fr
2
8 fr
3
8 0 fr
2
8 + fr
3
8
m9 fr
2
9 0 0 fr
2
9
m10 fr
2
10 0 fr
4
10 fr
2
10 + fr
4
10
m11 0 fr311 fr
4
11 fr
3
11 + fr
4
11
m12 0 fr312 0 fr
3
12
...
m19 0 0 0 0
TAB. 2 ‚Äì Vecteur de mots cl√©s relatif √† l‚Äôenseignant e2
√Ä partir des vecteurs constitu√©s, nous s√©lectionnons les termes les plus discriminants par
rapport au niveau d‚Äô√©l√©ments souhait√©s (par exemple, les enseignants). Pour effectuer une telle
RNTI-E-19 - 590 -
S. Bringay et al
s√©lection, nous nous appuyons sur la mesure TF -IDF que nous adaptons √† notre probl√©ma-
tique. Traditionnellement, la mesure TF -IDF donne un poids plus important aux mots carac-
t√©ristiques d‚Äôun document (Salton et al. (1975)). Ainsi, pour attribuer un poids de TF -IDF , il
est n√©cessaire, dans un premier temps, de calculer la fr√©quence d‚Äôun terme (Term Frequency).
Celle-ci correspond au nombre d‚Äôoccurrences de ce terme dans le document consid√©r√©. Ainsi,
pour le document dj et le terme ti, la fr√©quence du terme dans le document est donn√©e par
l‚Äô√©quation suivante :
TFi,j =
ni,j‚àë
k nk,j
o√π ni,j est le nombre d‚Äôoccurrences du terme ti dans dj . Le d√©nominateur correspond au
nombre d‚Äôoccurrences de tous les termes dans le document dj . La fr√©quence inverse de docu-
ment (Inverse Document Frequency) mesure l‚Äôimportance du terme dans l‚Äôensemble du corpus.
Elle consiste √† calculer le logarithme de l‚Äôinverse de la proportion de documents du corpus qui
contiennent le terme et est d√©finie de la mani√®re suivante :
IDFi = log2
|D|
|{dj : ti ‚àà dj}|
o√π |D| repr√©sente le nombre total de documents dans le corpus et |{dj : ti ‚àà dj}| repr√©sente
le nombre de documents o√π le terme ti appara√Æt (c.√†-d. ni,j = 0). Enfin, le poids s‚Äôobtient en
multipliant les deux mesures :
TF ‚àí IDFi,j = TFi,j √ó IDFi
Dans notre cas, nous ne calculons pas les termes repr√©sentatifs par rapport au nombre de
documents mais plut√¥t par rapport au niveau de granularit√© souhait√©. Ainsi, dans notre cas, la
formule repr√©sentant un IDF adaptatif est donn√©e ci-dessous :
IDF ki = log2
|Ek|
|{ekj : ti ‚àà ej}|
o√π |Ek| repr√©sente le nombre total d‚Äô√©l√©ments de type k (dans notre exemple, k = {Enseignant,
Composante, Universit√©}) qui correspond au niveau de la hi√©rarchie que le d√©cideur souhaite
agr√©ger. |{ej : ti ‚àà ej}| est relatif au nombre d‚Äô√©l√©ments de type k dans lequel le terme ti
appara√Æt. Cette mesure permet d‚Äôattribuer un poids adapt√© au niveau d‚Äôagr√©gation d√©cid√© par
l‚Äôutilisateur. Ainsi, nous calculons ce poids TF -IDF ki pour chacun des mots ti. Nous pouvons
ainsi conserver les n mots ayant les poids les plus √©lev√©s.
Exemple 1 Nous donnons dans la table 3 l‚ÄôIDF des mots au regard du niveau trait√© (Com-
posante, Enseignant) illustr√© en section 2. Ceci permet de mettre en relief, dans la table 4, les
mots caract√©ristiques de chaque niveau. Par exemple, le mot m10 est assez caract√©ristique de
la composante 1 (il ne repr√©sente jamais un mot-cl√© de la composante 2). Cependant, un tel
mot-cl√© est utilis√© par de nombreux enseignants (e2, e3, e4), il n‚Äôest donc pas caract√©ristique
pour d√©crire l‚Äôenseignement effectu√© par les enseignants de l‚ÄôUniversit√©. Enfin, pour chaque
niveau, nous pouvons calculer le TF-IDF de chacun des mots. Le r√©sultat d‚Äôun tel calcul est
donn√© dans la table 5. Pour simplifier la pr√©sentation des r√©sultats, nous appliquons une fr√©-
quence (TF) de 1 aux mots-cl√©s pr√©sents ce qui revient √† utiliser une repr√©sentation bool√©enne.
RNTI-E-19- 591 -
Bien cube, les donn√©es textuelles peuvent s‚Äôagr√©ger !
Mot Valeur IDF enseignant
m1 log2(6/1) = 2.58
m2 log2(6/1) = 2.58
... ...
m6 log2(6/4) = 0.58
m7 log2(6/3) = 1.00
... ...
m11 log2(6/3) = 1.00
m12 log2(6/2) = 1.58
... ...
Mot Valeur IDF composante
m1 log2(2/1) = 1
m2 log2(2/1) = 1
... ...
m6 log2(2/2) = 0
m7 log2(2/2) = 0
... ...
m11 log2(2/2) = 0
m12 log2(2/2) = 0
... ...
TAB. 3 ‚Äì Exemple de calcul de l‚ÄôIDF √† diff√©rents niveaux (enseignant, composante)
IDF
enseignant Mots
2.58 m1,m2, ...
1.58 m12, ...
1.00 m7,m11, ...
0.58 m6, ...
IDF
composante Mots
1
m1,m2, ..
0
m6,m7,m11,m12, ...
TAB. 4 ‚Äì Mots discriminants tri√©s au niveau "Enseignant" (gauche) - Mots discriminants tri√©s
au niveau "Composante" (droite)
4.3 Agr√©gation Dynamique
4.3.1 Pr√©sentation g√©n√©rale
Dans cette section, nous proposons de mettre en place une mesure dynamique afin d‚Äôagr√©-
ger les √©l√©ments. Ce probl√®me d‚Äôagr√©gation dynamique est par exemple √©tudi√© dans le contexte
des taxonomies dynamiques (e.g., Sacco (2000)). Le fait de nous appuyer sur les seules connais-
sances de la hi√©rarchie ne permet pas toujours une agr√©gation de qualit√© (repr√©sentant une si-
tuation r√©elle). Par exemple, dans le cadre d‚Äôune Universit√©, un enseignant peut enseigner des
cours tr√®s diff√©rents de la th√©matique de sa propre composante. A contrario, les enseignants
de deux composantes diff√©rentes peuvent se r√©v√©ler extr√™mement proches. Dans ce cas, nous
proposons d‚Äôeffectuer un regroupement sur la base des donn√©es textuelles qui permettent de
mieux d√©crire les √©l√©ments √† agr√©ger.
Enseignant TF -IDFEnseignant
e1
P (m1) = 1√ó 2.58 = 2.58
P (m2) = 1√ó 2.58 = 2.58
...
e2
P (m6) = 1√ó 0.58 = 0.58
P (m7) = 1√ó 1.00 = 1.00
...
e3
P (m6) = 1√ó 0.58 = 0.58
P (m7) = 1√ó 1.00 = 1.00
...
e4 ...
Composante TF -IDFComposante
composante1
P (m1) = 1√ó 1 = 1
P (m2) = 1
...
P (m6) = 0
P (m7) = 0
...
composante2
P (m6) = 1√ó 0 = 0
P (m7) = 0
...
P (m12) = 0
...
TAB. 5 ‚Äì TF-IDF au niveau "Enseignant" et "Composante".
RNTI-E-19 - 592 -
S. Bringay et al
4.3.2 M√©thode mise en ≈ìuvre
De la m√™me mani√®re que l‚Äôagr√©gation adaptative (section 4.2), la premi√®re √©tape consiste
√† fusionner les termes des feuilles (c‚Äôest-√†-dire les documents). Ceci permet de constituer des
vecteurs de mots-cl√©s pour chaque niveau (Enseignant, Composante, Universit√©) en appliquant
une repr√©sentation de type Salton (Salton et al. (1975)). Notons que nous pouvons s√©lection-
ner un nombre donn√© de mots-cl√©s (les plus fr√©quents) pour limiter les informations contenues
dans l‚Äôentrep√¥t. Par la suite, nous appliquons une m√©thode de clustering (Jain et al. (1999))
pour rassembler les √©l√©ments qui partagent les m√™mes mots. Bien entendu, le r√©sultat d‚Äôagr√©-
gation obtenu peut diff√©rer du regroupement fond√© sur une hi√©rarchie statique comme nous
le montrerons dans nos exp√©rimentations (section 5). Les m√©thodes de clustering que nous
utilisons (k-means dans nos exp√©rimentations) s‚Äôappuient sur des mesures classiques afin de
calculer la proximit√© entre deux vecteurs : Jaccard (repr√©sentation bool√©enne), cosinus, dis-
tance euclidienne (repr√©sentation fr√©quentielle), etc.
Avec les approches de clustering utilis√©es, pour chaque regroupement form√©, nous obtenons
un vecteur moyen. Nous s√©lectionnons alors les mots caract√©ristiques (c‚Äôest-√†-dire ayant le
poids le plus √©lev√©) de ces vecteurs moyens. Notons que pour cette repr√©sentation dynamique,
nous pouvons bien s√ªr accorder des poids bool√©ens, fr√©quentiels ou de type TF -IDF pour
construire nos vecteurs.
Notons que l‚Äôagr√©gation/d√©sagr√©gation des √©l√©ments pour effectuer une analyse de type
OLAP peut s‚Äôeffectuer par la variation du param√®tre k de l‚Äôalgorithme de clustering appli-
qu√© (ici k-means). En effet, le fait de choisir le nombre de groupes √† obtenir permet d‚Äôagr√©-
ger/d√©sagr√©ger (Drill-down et Roll-up) les √©l√©ments pour une meilleure analyse.
Exemple 2 En consid√©rant l‚Äôexemple pr√©c√©dent, nous effectuons un regroupement fond√© sur
un algorithme de type k-means en appliquant diff√©rentes valeurs de k (nombre de regrou-
pements diff√©rent). Les r√©sultats des regroupements avec les vecteurs moyens associ√©s sont
donn√©s dans les tableaux 6 et 7. Lorsque nous utilisons le m√™me nombre de groupes que la hi√©-
rarchie statique (deux composantes), nous remarquons que le regroupement propos√© par notre
algorithme est diff√©rent (cf tableau 6). Ce regroupement refl√®te davantage la r√©alit√© propre aux
cours donn√©s par les enseignants. Avec la hi√©rarchie statique nous avons : Classe 1 = {e1, e2,
e3, e4}, Classe 2 = {e5, e6} alors que pour la hi√©rarchie dynamique : Classe 1 = {e1}, Classe
2 = {e2, e3, e4, e5, e6}. En effet, le regroupement form√© met en exergue le fait que l‚Äôenseignant
e1 est isol√© par rapport √† sa propre composante. Les vecteurs moyens des groupes sont donn√©s
dans le tableau 6. Pour chaque regroupement form√©, nous retenons n mots-cl√©s repr√©sentatifs
(c‚Äôest-√†-dire, ayant le score le plus √©lev√©). √Ä titre d‚Äôexemple, le mot le plus repr√©sentatif du
groupe form√© des enseignants {e2, e3, e4, e5, e6} est le mot-cl√© m6. Ce dernier a un poids de
0.8 (le mot m6 est utilis√© pour d√©crire les cours de 4 enseignants sur les 5 du groupe form√©
dynamiquement).
5 Exp√©rimentations
De mani√®re √† √©valuer notre proposition, diff√©rentes exp√©rimentations ont √©t√© r√©alis√©es. Les
donn√©es utilis√©es correspondent √† des articles publi√©s dans un laboratoire (LIRMM) sur l‚Äôan-
n√©e 2009 (305 articles) et r√©f√©renc√©s dans la base de donn√©es HAL (archive ouverte pluridis-
ciplinaire). Dans ce contexte, nous utilisons une hi√©rarchie dont l‚Äô√©l√©ment le plus √©lev√© est le
RNTI-E-19- 593 -
Bien cube, les donn√©es textuelles peuvent s‚Äôagr√©ger !
Mots 0 1
m1 0 1
m2 0 1
m3 0 1
m4 0 1
m5 0 1
m6 0.8 0
m7 0.6 0
m8 0.6 0
m9 0.4 0
m10 0.6 0
m11 0.6 0
m12 0.4 0
m13 0.4 0
m14 0.4 0
m15 0.4 0
m16 0.4 0
m17 0.4 0
m18 0.4 0
m19 0.4 0
Mots 0 1 2 3
m1 0 1 0 0
m2 0 1 0 0
m3 0 1 0 0
m4 0 1 0 0
m5 0 1 0 0
m6 1 0 1 0.5
m7 0 0 1 0.5
m8 0 0 1 0.5
m9 0 0 1 0
m10 1 0 1 0
m11 1 0 0.5 0.5
m12 0 0 0.5 0.5
m13 1 0 0.5 0
m14 1 0 0.5 0
m15 0 0 0 1
m16 0 0 0 1
m17 0 0 0 1
m18 0 0 0 1
m19 0 0 0 1
Mots 0 1 2 3 4
m1 0 1 0 0 0
m2 0 1 0 0 0
m3 0 1 0 0 0
m4 0 1 0 0 0
m5 0 1 0 0 0
m6 1 0 1 0.5 1
m7 0 0 1 0.5 1
m8 0 0 1 0.5 1
m9 0 0 1 0 1
m10 1 0 1 0 1
m11 1 0 1 0.5 0
m12 0 0 1 0.5 0
m13 1 0 1 0 0
m14 1 0 1 0 0
m15 0 0 0 1 0
m16 0 0 0 1 0
m17 0 0 0 1 0
m18 0 0 0 1 0
m19 0 0 0 1 0
TAB. 6 ‚Äì Utilisation de l‚Äôalgorithme k-means deWeka pour diff√©rentes valeurs de k : 2 groupes
(gauche), 4 groupes (centre), 5 groupes (droite)
N. Instances
0 5 ( 83%)
1 1 ( 17%)
N. Instances
0 1 ( 17%)
1 1 ( 17%)
2 2 ( 33%)
3 2 ( 33%)
N. Instances
0 1 ( 17%)
1 1 ( 17%)
2 1 ( 17%)
3 2 ( 33%)
4 1 ( 17%)
TAB. 7 ‚Äì Les diff√©rents regroupements obtenus pour : 2 groupes (gauche), 4 groupes (centre),
5 groupes (droite). Les instances correspondent au nombre d‚Äô√©l√©ments (enseignants) pr√©sents
dans chaque groupe.
laboratoire qui poss√®de plusieurs √©quipes. Ces derni√®res sont compos√©es de chercheurs. Les
documents trait√©s correspondent aux r√©sum√©s d‚Äôarticles. Le but de nos exp√©rimentations est
de comparer les agr√©gations effectu√©es en utilisant une hi√©rarchie statique (section 4.2) ou dy-
namique (section 4.3). Par manque de place, nous ne nous focalisons ici que sur l‚Äôagr√©gation
dynamique. Dans un premier temps, nous appliquons l‚Äô√©tiqueteur grammatical TreeTagger1
sur notre corpus afin de ne retenir que les noms extraits √† partir des r√©sum√©s d‚Äôarticles. Pour
chaque document, nous retenons lesm (m = 10, 20, 30) mots-cl√©s ayant le plus grand nombre
d‚Äôoccurrences et constituons des vecteurs associ√©s √† chaque document.
Les r√©sultats report√©s ici concernent un sous-ensemble du laboratoire : 3 √©quipes repr√©-
sentant 84 chercheurs. Ce sous-ensemble nous permet d‚Äôanalyser manuellement les r√©sultats
obtenus qui sont synth√©tis√©s dans le tableau 8. Nous pouvons alors comparer le regroupement
dynamique par rapport √† un rassemblement fix√© par une hi√©rarchie existante. Nous avons men√©
nos exp√©rimentations en faisant varier le nombre m de mots s√©lectionn√©s pour caract√©riser
un chercheur. Par ailleurs, nous faisons varier le nombre de clusters form√©s. Les r√©sultats du
1http ://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/
RNTI-E-19 - 594 -
S. Bringay et al
m 10 20 30
k=2 1 NSG (11 instances) 1 NSG (11 instances) 1 NSG (11 instances)
1 RG (73 instances) 1 RG (73 instances) 1 RG (73 instances)
k=3 2 NSG (11 et 7 instances) 2 NSG (11 et 3 instances) 2 NSG (11 et 3 instances)
1 RG (66 instances) 1 RG (70 instances) 1 RG (70 instances)
k=4 3 NSG (11, 7, 1 instances) 4 NSG 3 NSG (11, 8, 2 instances)
1 RG (65 instances) (42, 28, 11, 3 instances) 1 RG (63 instances)
k=5 4 NSG (11, 7, 3, 1 instances) 5 NSG 4 NSG (11, 8, 7, 2 instances)
1 RG (62 instances) (34, 28, 11, 8, 3 instances) 1 RG (56 instances)
TAB. 8 ‚Äì Modification des groupes propos√©s par l‚Äôagr√©gation dynamique (algorithme k-
means selon diff√©rentes valeurs de k). NSG form√© = Nouveau Sous-Groupe form√©. RG = Ras-
semblement de groupes.
tableau 8 montrent que les groupes form√©s automatiquement sont assez diff√©rents de la r√©-
partition r√©elle des chercheurs dans diff√©rentes √©quipes. L‚Äôanalyse manuelle montre que de
nombreux sous-groupes sp√©cifiques sont form√©s ; ces derniers repr√©sentent des ensembles de
chercheurs travaillant sur un sous-th√®me des trois √©quipes de recherche. √Ä titre d‚Äôexemple, avec
k = 3 et un nombre m = 20 de mots s√©lectionn√©s, un cluster de 3 individus est cr√©√©. Celui-ci
correspond √† trois chercheurs qui travaillent sur une th√©matique de "fouille de textes" dans une
√©quipe ayant un axe de recherche plus g√©n√©ral. Les autres exp√©rimentions men√©es avec l‚Äôen-
semble des 511 chercheurs r√©pertori√©s dans les archives HAL 2009 du laboratoire confirment
ces observations. Ainsi, l‚Äôapplication d‚Äôune agr√©gation dynamique en fixant par exemple la di-
mension propre √† l‚Äôann√©e permet de mettre en relief des informations nouvelles et int√©ressantes
pour les d√©cideurs.
Comparativement √† une repr√©sentation classique, notre entrep√¥t de donn√©es textuelles n√©-
cessite de stocker m mots par document. Ce choix du param√®tre m exp√©riment√© dans cette
section aura une influence importante quant √† la taille finale de notre entrep√¥t de textes. No-
tons qu‚Äôapr√®s avoir effectu√© les agr√©gations, un sous-ensemble de ces mots sera retourn√© √†
l‚Äôutilisateur.
6 Conclusion
Dans cet article, nous avons propos√© deux nouvelles fonctions afin d‚Äôagr√©ger des donn√©es
textuelles d‚Äôun entrep√¥t. Nos fonctions permettent de proposer au d√©cideur les mots les plus
significatifs issus de ces agr√©gations. La premi√®re fonction s‚Äôappuie sur une mesure issue de la
Recherche d‚ÄôInformation que nous avons √©tendue afin de prendre en compte les informations
d‚Äôune hi√©rarchie existante. La seconde fonction propos√©e effectue une agr√©gation dynamique
sur la base d‚Äôalgorithmes de clustering. Nos exp√©rimentations ont montr√© que les agr√©gations
effectu√©es en utilisant ces deux types de fonctions se r√©v√®lent diff√©rentes ce qui permet d‚Äôap-
porter des informations originales √† partir des donn√©es textuelles de notre entrep√¥t. Dans nos
futurs travaux, nous souhaitons appliquer et exp√©rimenter ces m√©thodes d‚Äôagr√©gation pour des
donn√©es particuli√®res telles que les donn√©es d‚Äôopinions. Ceci demandera une recherche de des-
cripteurs linguistiques plus pr√©cis (syntagmes adjectivaux par exemple) pour caract√©riser les
donn√©es textuelles.
RNTI-E-19- 595 -
Bien cube, les donn√©es textuelles peuvent s‚Äôagr√©ger !
R√©f√©rences
Chang, C.-H., M. Kayed, M. R. Girgis, et K. F. Shaalan (2006). A survey of web information
extraction systems. IEEE Trans. Knowl. Data Eng. 18(10), 1411‚Äì1428.
Codd, E., S. Codd, et C. Salley (1993). Providing olap (on-line analytical processing) to user-
analysts : An it mandate. InWhite Paper.
Hofmann, T. (1999). Probabilistic latent semantic analysis. In In Proc. of Uncertainty in
Artificial Intelligence, UAI‚Äô99, pp. 289‚Äì296.
Jain, A. K., M. N. Murty, et P. J. Flynn (1999). Data clustering : A review. ACM Comput.
Surv. 31(3), 264‚Äì323.
Keith, S., O. Kaser, et D. Lemire (2005). Analyzing large collections of electronic text using
olap. Technical Report TR-05-001, UNBSJ CSAS.
Lin, C. X., B. Ding, J. Han, F. Zhu, et B. Zhao (2008). Text Cube : Computing IR Measures
for Multidimensional Text Database Analysis. In In Proc. of Int. Conf. on Data Mining
(ICDM‚Äô08), pp. 905‚Äì910.
P√©rez-Mart√≠nez, J. M., R. B. Llavori, M. J. A. Cabo, et T. B. Pedersen (2008). Contextualizing
data warehouses with documents. Decision Support Systems 45(1), 77‚Äì94.
Pujolle, G., F. Ravat, O. Teste, et R. Tournier (2008). Fonctions d‚Äôagr√©gation pour l‚Äôanalyse
en ligne (olap) de donn√©es textuelles. fonctions top_kwk et avg_kw op√©rant sur des termes.
Ing√©nierie des Syst√®mes d‚ÄôInformation 13(6), 61‚Äì84.
Sacco, G. (2000). Dynamic taxonomies : A model for large information bases. IEEE Transac-
tions on Knowledge and Data Engineering 12(3), 468‚Äì479.
Saga, R., H. Tsuji, et K. Tabata (2009). Loopo : Integrated text miner for fact-graph-based
trend analysis. In HCI (9), pp. 192‚Äì200.
Salton, G., A. Wong, et C. S. Yang (1975). A vector space model for automatic indexing.
Commun. ACM 18(11), 613‚Äì620.
Sebastiani, F. (2002). Machine learning in automated text categorization. ACM Comput.
Surv. 34(1), 1‚Äì47.
Zhang, D., C. Zhai, et J. Han (2009). Topic cube : Topic modeling for olap on multidimensional
text databases. In In Proc. of the SIAM Int. Conference on Data Mining, pp. 1123‚Äì1134.
Summary
With the development of the Internet, the amount of textual information grows explosively
and it is more and more desirable to provide the end user with new tools for analysing and
extracting knowledge from such amount of data. Recently, new approaches have been defined
in order to enhance tradionnal Datawarehouse and OLAP technologies by handling text doc-
uments. In this paper, we focus on two new aggregative functions. The former is based on
an extension of the classical TF -IDF measure to take into account existing hierarchies. The
latter proposes to dynamically define a hierarchy in order to emphasize real situation extracted
from texts. Experiments conducted on articles stored in the HAL repository show the efficiency
of our proposals.
RNTI-E-19 - 596 -
