Clustering incre´mental pour un apprentissage
distribue´ et robuste: vers un syste`me e´volutif. . .
Yann Prudent, Abdel Ennaji
PSI - FRE CNRS 2645 - Universite´ de Rouen
{yann.prudent, abdel.ennaji}@univ-rouen.fr
Re´sume´. Ce papier pre´sente un syste`me d’apprentissage multi-
classifieurs dont la conception est pilote´e par la topologie des donne´es
d’apprentissage. Il pre´sente un nouvel algorithme d’apprentissage de carte
neuronale auto-organise´e incre´mentale en donne´es. Cette carte est utilise´e
pour distribuer les taˆches de classification sur un ensemble de classifieurs.
Seuls certains classifieurs sont active´s en fonction de l’activite´ des neurones
de la carte pour une donne´e. De plus, le syste`me propose´ permet d’e´tablir
un crite`re de confiance s’affranchissant totalement du type de classifieurs
utilise´s. Ce coefficient permet de controˆler efficacement le compromis Er-
reur/Rejet. Des re´sultats comparatifs de cette architecture sont donne´s
sur la base de segmentation d’images de l’UCI et en reconnaissance de
chiffres manuscrits.
1 Introduction
En reconnaissance de formes, les phases d’apprentissage et de classification consti-
tuent des e´tapes fondamentales qui conditionnent en grande partie les performances.
Les techniques d’apprentissage artificiel ont connu ces dernie`res de´cennies des avance´es
fondamentales a` travers des mode`les tels que les re´seaux de neurones et les SVM (Sup-
port Vector Machines ou Se´parateurs a` Vaste Marge) [Vapnik, 1995], qui montrent
globalement de bonnes performances. Ces me´thodes, base´es sur diffe´rentes the´ories et
me´thodologies, ont e´te´ conside´re´es comme autant de solutions possibles a` un meˆme
proble`me. Cependant, leur de´veloppement n’a pas permis de mettre en e´vidence la
supe´riorite´ incontestable d’une me´thode sur une autre face aux contraintes et a` la com-
plexite´ des applications pratiques. De plus, peu de mode`les permettent de fournir une
estimation de la fiabilite´ de la de´cision ou un coefficient de confiance qui ne soit pas sim-
plement une probabilite´ a posteriori comme c’est souvent le cas. Une solution admise
dans la communaute´ pour re´soudre ce type de proble`mes consiste a` adopter une concep-
tion modulaire et distribue´e du syste`me de classification [Duin, 2002] [Kuncheva, 2002]
[Gori et Scarselli, 1998].
Dans ce contexte, ce papier pre´sente un syste`me d’apprentissage multi-classifieurs dont
la conception est pilote´e par la topologie des donne´es d’apprentissage. Plusieurs contri-
butions sont a` noter dans le domaine de la de´composition de taˆches de classification.
Nous pouvons distinguer les approches purement supervise´es des approches hybrides
combinant a` la fois des algorithmes supervise´s et non supervise´s.
Dans [Jacobs et al., 1991], les auteurs proposent une approche qui de´compose l’en-
semble d’apprentissage en plusieurs sous-ensembles puis entraˆıne plusieurs re´seaux sur
Clustering incre´mental pour un apprentissage distribue´
ces sous-ensembles. L’approche pre´sente´e dans [Gori et Scarselli, 1998] proce`de par une
phase d’apprentissage non supervise´ (clustering) par cartes auto-organisatrices qui sup-
pose de connaˆıtre a priori le nombre de clusters. Cette carte permet de spe´cialiser des
groupes de neurones d’un Perceptron Multi-couches (PMC) en fonction des clusters
de´tecte´s. Ces deux me´thodes fondent la distribution du proble`me de classification soit
sur des informations strictement supervise´es soit des informations a priori difficiles a`
estimer pour un proble`me re´el. Elles ne prennent pas en compte la distribution re´elle
des donne´es dans l’espace de repre´sentation.
Pour effectuer la distribution, certaines me´thodes hybrides re´alisent une premie`re e´tape
qui consiste a` capturer la topologie des donne´es dans l’espace de description. Ceci re-
vient a` un proble`me de classification automatique et implique donc de de´terminer
le nombre et la constitution des groupes (clusters) dans l’ensemble d’apprentissage.
Les techniques les plus ge´ne´ralement utilise´es dans ce domaine sont certainement les
cartes Auto-Organisatrices de Kohonen [Kohonen, 1982] et les me´thodes de regroupe-
ment par partitionnement. Dans la pratique, le principal inconve´nient de ces me´thodes
est la ne´cessite´ de fournir le nombre de groupes a` l’avance pour obtenir une bonne
repre´sentation des donne´es. [Ribert, 1998] se sert d’une e´tude non supervise´e par Clas-
sification Ascendante Hie´rarchique (CAH) du proble`me pour le distribuer sur plusieurs
PMCs (un PMC sur par cluster). Il obtient des re´sultats e´quivalents a` un classifieur
global (KPPV) pour les taux d’erreur maximaux, mais de bien meilleures performances
quand il s’agit de minimiser le taux d’erreur. Toutefois la CAH, bien que tre`s efficace
sur les proble`mes de clustering et ne ne´cessitant pas de connaˆıtre le nombre de clusters
a priori, reste tre`s couˆteuse en temps et en espace. Dans [He´bert et al., 1999], l’auteur
reprend les travaux de [Gori et Scarselli, 1998] et tente de palier ces inconve´nients en se
servant d’un algorithme d’apprentissage non supervise´ qui n’a besoin d’aucune connais-
sance pre´alable du proble`me: le re´seau Growing Neural Gas (GNG) [Fritzke, 1995].
Nous proposons dans ce papier une extension du re´seau GNG, le re´seau Long Life
Growing Neural Gas (LLGNG), qui a la proprie´te´ d’eˆtre incre´mental en donne´es. La
notion d’apprentissage incre´mental e´voque´e ici se de´finit comme la proprie´te´ de pouvoir
adapter un re´seau de´ja` entraˆıne´ pour apprendre de nouvelles donne´es sans ne´cessiter
de disposer des donne´es de´ja` apprises. Autrement dit, cette notion traduit les capacite´s
d’un mode`le a` re´pondre au dilemme stabilite´/plasticite´. L’algorithme mis au point est
ensuite utilise´ pour distribuer un proble`me de classification sur plusieurs classifieurs
diffe´rents. La section suivante est consacre´e a` la pre´sentation de notre algorithme de
clustering, le re´seau LLGNG. La de´marche globale de conception modulaire de notre
syste`me et le facteur de confiance associe´ aux diffe´rents modules sont pre´sente´s dans
la section 3. Des re´sultats pre´liminaires sont pre´sente´s dans la section 4 avant une
conclusion et des perspectives de ce travail en dernie`re section.
2 Long Life Growing Neural Gas
Un des objectifs possibles de l’apprentissage non supervise´ est d’effectuer un ap-
prentissage qui peut eˆtre qualifie´ d’ “apprentissage topologique”. Dans ce but, les
cartes de Kohonen [Kohonen, 1982] et le Growing Cell Structure (GCS) [Fritzke, 1994]
effectuent une projection non line´aire des donne´es d’apprentissage dans un sous-
RNTI - C - 1
Prudent et Ennaji
espace discret de dimension choisie a priori. Pour la carte de Kohonen, la taille
du re´seau doit eˆtre fixe´e au pre´alable, a` l’inverse du re´seau GCS qui ajoute
des neurones et des connexions au fur et a` mesure de son apprentissage. Dans
[Martinetz et Schulten, 1994] les auteurs proposent d’allier deux me´thodes, l’algo-
rithme Neural Gas(NG) [Martinetz et Schulten, 1991] et le Competitive Hebbian Lear-
ning(CHL) [Martinetz, 1993]. L’algorithme NG permet de de´placer les centres des
classes en suivant la distribution des donne´es. Le CHL permet d’e´tablir des relations
topologiques en induisant un sous-graphe de la triangulation de Delaunay (Triangula-
tion de Delaunay induite). Dans ce type de re´seau (NG/CHL), la dimension n’est pas
fixe (Rectangle pour Kohonen, Hyperte´trahe`dre pour GCS), mais varie d’une re´gion
de l’espace a` l’autre. De plus, celle-ci n’est pas fixe´e a priori. Malgre´ ces avantages,
la taille de ce re´seau reste constante et fixe´e a` l’avance. Dans [Fritzke, 1995], l’auteur
propose le re´seau Growing Neural Gas qui combine les avantages des re´seaux GCS et
NG/CHL. Il n’y a ni taille ni dimension a` fixer a priori, et cette approche est pre´sente´e
comme e´tant incre´mentale en donne´es.
Nous introduisons dans la suite et discuterons le principe de l’algorithme GNG. Un
exemple synthe´tique nous permettra d’e´valuer les capacite´s re´ellement incre´mentales
du GNG. Nous proposerons ensuite un nouvel algorithme s’inspirant du GNG mais
qui se caracte´rise par de ve´ritables capacite´s d’apprentissage incre´mental ve´rifiant le
dilemme plasticite´/stabilite´.
2.1 Growing Neural Gas
L’ide´e principale de cette me´thode est d’ajouter progressivement de nouveaux neu-
rones a` un re´seau compose´ initialement de seulement deux neurones connecte´s, et ceci
graˆce a` une analyse locale de l’erreur quadratique engendre´e par les donne´es pre´sente´es.
Les connexions qui relient les neurones n’ont pas de poids, elles n’ont pour but que de
de´finir la structure topologique des donne´es (voisinage). Ce re´seau se caracte´rise par
une gestion dynamique du nombre de neurones base´e sur un principe compe´titif pour
ajouter ou supprimer des neurones et des connexions.
Chaque neurone ni du re´seau GNG posse`de un vecteur de re´fe´rence wi qui correspond
a` ses coordonne´es dans l’espace de description. A chaque e´tape le re´seau tente de mini-
miser l’erreur quadratique engendre´e par le nouvel exemple en de´plac¸ant les neurones
les plus proches de cette nouvelle donne´e de la meˆme manie`re que dans l’algorithme
de notre re´seau (alg. 1). Dans cet algorithme, le coefficient b (n) correspond au pas
d’adaptation du neurone gagnant (de ces voisins). Ces connexions ont un aˆge, et chaque
connexion ayant un aˆge trop e´leve´ est supprime´e. Ainsi, chaque donne´e pre´sente´e au
re´seau active la connexion qui relie les deux neurones qui sont situe´s le plus pre`s d’elle
dans l’espace de description. Si la connexion existe, son aˆge est re´initialise´ a` 0, sinon,
elle est cre´e´e avec un aˆge initial nul. Des neurones sont rajoute´s au re´seau apre`s un
nombre constant d’e´tapes (λ). L’erreur quadratique accumule´e par les diffe´rents neu-
rones permet de de´finir le vecteur de re´fe´rence et les connexions du nouveau neurone.
Ceci est fait de la meˆme manie`re que dans l’algorithme 1. Cette erreur est diminue´e a`
chaque e´tape en la multipliant par un coefficient d.
Fritzke de´crit ce re´seau comme un re´seau incre´mental en donne´es puisqu’il traite les
donne´es une par une et qu’il a une architecture constructive. Toutefois aucun re´sultat
RNTI - C - 1
Clustering incre´mental pour un apprentissage distribue´
sur un apprentissage incre´mental tel que de´fini pre´ce´demment n’est pre´sente´. Un re´seau
GNG peut-il apprendre re´ellement de nouvelles donne´es sans utiliser celles de´ja` apprises
et sans de´te´riorer le re´seau de´ja` entraˆıne´ ? En d’autres termes, le re´seau GNG est il
apte a` re´pondre correctement au dilemme stabilite´/plasticite´.
La figure 1-a illustre un re´seau GNG qui a e´te´ entraˆıne´ sur une distribution de donne´es
de forme cubique. Dans la figure 1-b, la distribution des donne´es a e´volue´ et seules
les nouvelles donne´es situe´es a` droite ont servi a` poursuivre l’apprentissage du re´seau.
Il en re´sulte, comme le montre la fig. 1-c, une de´formation du motif initial tradui-
sant un manque de stabilite´ du re´seau malgre´ de bonnes proprie´te´s en plasticite´. Ce
proble`me synthe´tique montre bien l’e´chec du mode`le GNG en apprentissage re´ellement
incre´mental.
(a) Le re´seau GNG
entraˆıne´ avec les
donne´es de gauche,
(b) E´volution de
la distribution des
donne´es
(c) Adaptation du
re´seau aux nouvelles
donne´es.
Fig. 1 – Apprentissage incre´mental du re´seau GNG
2.2 Notre contribution: Long Life Growing Neural Gas (LL-
GNG)
L’algorithme du LLGNG propose´ reprend les principes ge´ne´raux du re´seau GNG
mais introduit de nouvelles proprie´te´s qui lui sont propres pour re´pondre au proble`me
de l’apprentissage incre´mental. Le re´seau LLGNG posse`de deux types de neurones:
– des neurones embryons,
– des neurones matures.
Le re´seau n’est constitue´ en re´alite´ que de neurones matures, les neurones embryons
ne servant que pour l’apprentissage (de´taille´ dans l’algorithme 1). Une donne´e d’ap-
prentissage x active un neurone ni si ‖x− wi‖2 < σ2. σ de´finit une re´gion d’influence
autour de chaque neurone de la carte. Ce parame`tre est encore fixe´ a priori, mais de-
vrait faire l’objet d’une estimation automatique durant l’apprentissage.
Quand une nouvelle donne´e est pre´sente´e au re´seau, l’adaptation du re´seau se fait en
distinguant trois cas de figure:
– Si la donne´e n’active aucun neurone, un nouveau neurone embryon est cre´e´ avec
un vecteur de re´fe´rence w = x.
– Si la donne´e active un seul neurone, un nouveau neurone embryon est e´galement
cre´e´ avec un vecteur de re´fe´rence w = x, mais l’apprentissage continue de la
meˆme manie`re que pour le re´seau GNG.
– Enfin si la donne´e active plusieurs neurones, l’apprentissage de cette donne´e est
identique a` celui du re´seau GNG.
RNTI - C - 1
Prudent et Ennaji
Chaque neurone posse`de en plus du vecteur de re´fe´rence, un aˆge qui vaut initiale-
ment ze´ro pour un neurone embryon, et majorite pour un neurone mature (majorite
e´tant un parame`tre fixe´ a priori). Lorsqu’un neurone est le plus proche de la nouvelle
donne´e, son aˆge est incre´mente´ ainsi que celui de tous ses voisins directs. Si durant
cette phase, un neurone embryon atteint un aˆge supe´rieur a` majorite, il passe alors a`
l’e´tat mature.
La distribution des figures 2-a et 2-b a e´te´ propose´e dans
[Martinetz et Schulten, 1991] pour tester le re´seau NG, puis re´utilise´e dans
[Fritzke, 1995] pour le GNG. Cette distribution posse`de des dimensions diffe´rentes
dans diffe´rentes re´gions de l’espace de description. Ces deux figures donnent les
re´sultats obtenus avec le GNG et le LLGNG, et montrent clairement les meˆmes
performances des 2 mode`les dans le cas d’un apprentissage passif.
(a) Mode´lisation du GNG (b) Mode´lisation du LLGNG
Fig. 2 – Apprentissage de la Distribution de Martinetz dans le cas d’un apprentissage
passif
Les figures 3(a) et 3(b) pre´sentent le re´seau LLGNG entraˆıne´ sur les meˆmes donne´es
et dans les meˆmes conditions que pour la figure 1. Et contrairement au GNG, notre
mode`le est capable d’apprendre les nouvelles donne´es tout en pre´servant les connais-
sances de´ja` apprises.
(a) Le re´seau LLGNG est
entraˆıne´ avec les donne´es
de gauche ...
(b) ... puis uniquement
avec les donne´es de droite
Fig. 3 – Apprentissage incre´mental du re´seau LLGNG
Dans toutes les validations propose´es dans cet article, nous avons fixe´ σ = 1 et
majorite = 50. Ces deux parame`tres sont fixe´s a priori mais cette taˆche ne de-
mande que peu de connaissances du proble`me a` traiter. Notons que si l’on de´finit
σ = ∞ et majorite = 0, le re´seau est identique au re´seau GNG. Le re´seau LL-
RNTI - C - 1
Clustering incre´mental pour un apprentissage distribue´
de´but
tant que Le crite`re d’arreˆt n’est pas satisfait faire
Choisir une donne´e x ∈ S;
si n1 le neurone le plus pre`s de l’entre´e x n’est pas active´ alors
cre´er un nouveau neurone embryon de coordonne´es x;
retourner ;
si n2 le deuxie`me neurone le plus pre`s de l’entre´e n’est pas active´ alors
cre´er un nouveau neurone embryon de coordone´es x;
e(n1)+=‖x− wn1‖ 2; ( e(n1) : erreur du neurone n1
wn1+ = b(x− wn1); wn+ = n(x− wn); //(n : voisins directs de n1)
si n1 et n2 sont connecte´s alors
agen1→n2 = 0;
sinon
cre´er une connexion entre n1 et n2;
Supprimer les connexions avec un aˆge supe´rieur a` amax;
si un neurone se trouve isole´ alors
supprimer ce neurone;
si le nombre d’ite´rations k est un multiple de λ alors
Trouver le neurone q qui a la plus importante erreur accumule´e;
Trouver son voisin p qui a le plus d’erreur accumule´e;
Inse´rer le nouveau neurone mature r entre q et p (wr = 0.5(wq+wp));
Cre´er les connexions q → r et r → p;
Supprimer la connexion q → p;
e(q) = α× e(q); e(p) = α× e(p); e(r) = e(q);
pour Chaque neurone n faire
e(n)=d×e(n);
Incre´menter l’aˆge des neurones e´manants de n1;
pour Chaque neurone embryon n faire
si age(n)≥majorite alors
n devient mature
fin
Algorithme 1: Algorithme d’apprentissage du re´seau LLGNG
RNTI - C - 1
Prudent et Ennaji
GNG est donc capable de rendre compte des relations topologiques d’une distribu-
tion quelconque de donne´es. Ce mode`le est capable en outre de reprendre un ap-
prentissage sans tenir compte des donne´es pre´ce´demment apprises. Il re´pond donc
de manie`re satisfaisante au dilemme stabilite´/plasticite´ contrairement aux autres tech-
niques de clustering. Cette notion d’apprentissage incre´mental, valide´e par ailleurs dans
[Prudent et Ennaji, 2004], est fondamentale a` notre sens dans la mesure ou` elle permet
de re´pondre aux besoins grandissants en fouille de donne´es et de´couverte de connais-
sances dans les proble`mes actuels. Il devient donc possible de traiter de manie`re pro-
gressive et continue des proble`mes complexes avec des bases d’apprentissage trop volu-
mineuses et/ou en e´volution continue. Cette limitation lie´e e´galement a` la complexite´
des algorithmes de clustering a e´te´ de´montre´e dans [Ribert, 1998] pour la CAH. De
plus le re´seau LLGNG posse`de tous les avantages requis pour traiter de tels proble`mes.
En effet, il n’est pas ne´cessaire de fixer a priori des parame`tres tels que le nombre de
clusters, la dimension de la carte ou la nature de la distribution des donne´es. En outre,
les parame`tres utilise´s sont constants dans le temps contrairement aux re´seaux NG et
aux cartes de Kohonen. Enfin le re´seau LLGNG converge plus vite que le GNG vers
une bonne repre´sentation de la topologie des donne´es. Ceci a e´te´ confirme´ sur plusieurs
proble`mes et en particulier un proble`me de clustering a` densite´ de points tre`s variable
propose´ dans [Ribert, 1998] et qui met en e´chec la plupart des me´thodes de clustering
classiques. Tout ceci fait du re´seau LLGNG une alternative aux approches classiques.
3 Conception du syste`me de de´cision distribue´
La structure topologique mode´lise´e par le re´seau Long Life Growing Neural Gas
est exploite´e pour la conception d’un syste`me de de´cision distribue´ multi-classifieurs.
En effet, ce re´seau est utilise´ dans un premier temps pour partitionner l’ensemble
d’apprentissage initial en plusieurs sous-ensembles. Ce partitionnement est re´alise´
simplement en identifiant tous les e´le´ments d’apprentissage ayant active´ un neurone
donne´ de la carte comme un sous-ensemble particulier. Chaque sous-ensemble est
ensuite associe´ a` un ou plusieurs classifieurs qui seront charge´s de l’identifier. Ainsi,
chacune des re´gions de´finies par le LLGNG est traite´e de manie`re inde´pendante par un
ou plusieurs classifieurs supervise´s. Cette conception pilote´e par la carte topologique
nous offre la possibilite´ d’entraˆıner plusieurs classifieurs de diffe´rents types (PMC,
SVM, KPPV, · · ·), ou aux parame`tres d’apprentissage diffe´rents (noyaux, nombre de
neurones, · · ·) pour chaque sous-ensemble. Il est ensuite possible de se´lectionner le
ou les classifieurs ade´quats au proble`me par les me´thodes de se´lection de classifieurs
propose´es dans la litte´rature [Roli et Giacinto, 2002] [Kuncheva, 2002]. La diminution
de la complexite´ du proble`me engendre´e par ce partitionnement permet aussi d’envi-
sager plus aise´ment de mettre en place des re`gles de combinaison des classifieurs pour
ame´liorer la robustesse du processus de de´cision.
Ainsi, a` chaque neurone ni du LLGNG sont associe´es les donne´es d’apprentissage
telles que:
si = {x ∈ S/d(x,wi) ≤ σi}
σi est fixe´ a priori ou peut eˆtre calcule´ pendant la phase d’apprentissage du re´seau
RNTI - C - 1
Clustering incre´mental pour un apprentissage distribue´
LLGNG. Comme nous le montre la figure 4, chaque neurone est donc associe´ a` une
zone d’influence hypersphe´rique de rayon σi.
Une fois la base d’apprentissage de´compose´e, un ou plusieurs classifieurs super-
vise´s sont associe´s a` chaque sous-ensemble d’apprentissage de´fini pour chaque neurone
du LLGNG. Nous appelons par la suite cette association (neurone, classifieurs, sous-
ensemble) un GNeurone. La de´cision prise par un GNeurone en phase de test concerne
uniquement les e´le´ments qui ont active´ son neurone de la carte LLGNG et sera celle
du ou des classifieurs qui lui sont associe´s.
Fig. 4 – Distribution de l’ensemble d’apprentissage S en plusieurs sous-ensembles si
Cette technique de conception distribue´e de classifieurs a pour autre avantage d’en-
gendrer au niveau des classifieurs des frontie`res de de´cision ferme´es (fig.5).
(a) donne´es d’ap-
prentissage
(b) Frontie`re
ge´ne´re´e par un
SVM
(c) frontie`re
ge´ne´re´e par notre
approche
Fig. 5 – Fermeture des frontie`res de de´cisions
En effet, la ge´ne´ration de frontie`res de de´cisions ouvertes est un des prin-
cipaux de´fauts de beaucoup de classifieurs tels que les PMCs ou les SVMs
[Gori et Scarselli, 1998]. Ainsi, bien que reconnus comme performants, ils ne peuvent
rejeter de manie`re efficace les donne´es n’appartenant a` aucune classe.
Par ailleurs, l’union de tous les sous-ensembles si ge´ne´re´s par le LLGNG n’est pas
force´ment e´quivalente a` l’ensemble d’apprentissage total S. Les donne´es n’appartenant
pas a` cette union ne sont donc pas apprises et seront rejete´es par notre syste`me. Ce
RNTI - C - 1
Prudent et Ennaji
deuxie`me pouvoir de rejet, en plus de celui pouvant eˆtre pris localement par la fonction
de de´cision de chaque GNeurone, est un autre avantage inde´niable de cette approche
vis-a`-vis de la fiabilite´ du processus de de´cision dans de grandes masses de donne´es.
Lorsqu’une nouvelle donne´e x a` classifier est pre´sente´e au syste`me, tous les Gneu-
rones re´pondant a` la condition d(x−wi) ≤ σi sont se´lectionne´s pour la de´cision. Nous
choisissons alors au plus les K plus proches GNeurones de la nouvelle donne´e (K est
fixe´ a priori). A chaque GNeurone se´lectionne´ on associe un coefficient de confiance v
donne´ par:
v =
|si|
d(x,wi)β
Ce coefficient tient compte de deux facteurs importants pour la fiabilite´ d’une de´cision:
– le nombre de donne´es d’apprentissage du GNeurone (|si|),
– la distance de celui-ci avec la donne´e a` classifier.
β est une constante permettant de de´finir un compromis distance/taille de la base
d’apprentissage. Ce coefficient de confiance permet de ponde´rer le vote de chaque
GNeurone, et par la meˆme occasion, de rejeter des donne´es lorsque la de´cision prise
par l’ensemble des K GNeurones est juge´e peu fiable. Il est a` noter que le coefficient de
confiance de chaque GNeurone s’affranchit totalement du ou des classifieurs associe´s
a` celui-ci. Ce crite`re permet a` l’utilisateur de controˆler le compromis Erreur/Rejet. Il
introduit donc un troisie`me niveau possible de rejet qui permet en particulier de prendre
en compte des informations lie´es a` la nature et les contraintes du proble`me traite´, la
qualite´ des donne´es d’apprentissage et leur distribution dans l’espace de repre´sentation.
4 Re´sultats
La validation de notre approche a e´te´ effectue´e a` travers plusieurs expe´rimentations
pour mettre en e´vidence les performances en classification inde´pendamment de la per-
tinence des caracte´ristiques. Nous n’avons utilise´ dans cette e´tude pre´liminaire que des
SVM comme classifieurs pour les GNeurones. Notre syste`me appele´ KPPG (K plus
proches GNeurones) a e´te´ compare´ a` des classifieurs bien connus, le KPPV (k plus
proches voisins) et les SVM. Le noyau utilise´ pour les SVM a e´te´ de´termine´ par un
proce´de´ d’essai/erreur. La premie`re expe´rimentation a e´te´ effectue´e avec la base de
segmentation d’images de l’UCI [Murphy et Aha, 1992] appele´e Image. Les donne´es en
dimension 19 de ce proble`me a` 7 classes se re´partissent en 210 exemples pour l’appren-
tissage et 2100 exemples en test. Le tableau 1 pre´sente les re´sultats obtenus sur la base
Image de l’UCI.
Nous avons ensuite valide´ notre approche sur le proble`me de reconnaissance de
chiffres manuscrits de la base NIST. Le vecteur de caracte´ristiques conside´re´ est constitue´
par les 85 caracte´ristiques (niveaux de gris) issues d’une pyramide de re´solution a` 4 ni-
veaux(1+4+16+64) [Ballard et Brown, 1982]. La figure 6 donne un exemple de chiffres
de la base NIST et la repre´sentation retenue sur l’exemple d’un chiffre 2. Les bases
d’apprentissage et de test contiennent respectivement 2626 et 2621 exemples.
RNTI - C - 1
Clustering incre´mental pour un apprentissage distribue´
(a) Exemple de chiffre de la base NIST (b) Pyramide de re´solution a` 4 niveaux
(chiffres 2)
Fig. 6 – exemples et repre´sentation de chiffres de de la base NIST
classifieur reco(%) erreur(%)
KPPV 87.57 12.43
SVM 93.95 6,05
KPPG 94.34 5.66
Tab. 1 – Re´sultats sur Image
KPPV SVM KPPG
Max 96.83 97.90% 97.90%
≤ 1.2% 93.5% - 96.06%
≤0.4% 81.59% - 90,34%
≤ 0.2% 73.73% - 81.6%
Tab. 2 – Re´sultats sur NIST
Les deux courbes de la figure 7 donnent le taux de classification (taux d’erreur en
fonction du taux de reconnaissance) pour chaque classifieur conside´re´ a` l’exception des
SVM pour lesquels le taux d’erreur ne peut eˆtre parame´tre´. La courbe du KPPV a e´te´
obtenue en diminuant k, tout en ve´rifiant que tous les voisins soient de la meˆme classe
(le taux maximum d’identification est obtenu quand k=1). La courbe du KPPG a e´te´
obtenue de la meˆme manie`re.
70 75 80 85 90 95 100
0
0.5
1
1.5
2
2.5
3
3.5
Reconnaissance (%)
Err
eu
r (%
)
KPPV
KPPG
Fig. 7 – Erreur/Reconnaissance pour le KPPV et le KPPG sur la base NIST(85)
Les re´sultats pre´liminaires obtenus avec notre approche sont prometteurs. Le choix
des 2 proble`mes conside´re´s ici a e´te´ motive´ par la volonte´ d’e´valuer les capacite´s de
RNTI - C - 1
Prudent et Ennaji
ge´ne´ralisation des mode`les a` partir de bases d’apprentissage re´duites. Le proble`me de la
reconnaissance de chiffres manuscrits confirme ces capacite´s en e´vitant le risque de sur-
apprentissage susceptible de se produire pour les bases bien connues de l’UCI a` cause du
de´se´quilibre des bases d’apprentissage et de test. Les performances sont e´quivalentes
aux autres classifieurs pour un taux d’erreur maximal, mais se re´ve`lent supe´rieures
quand des taux d’erreurs faibles sont recherche´s. En effet, les re´sultats obtenus jusqu’a`
pre´sent montrent que dans le cas ou` un taux de reconnaissance maximal est ne´cessaire,
le syste`me propose´ est au moins aussi performant qu’un SVM. De plus, dans le cas
ou` le taux d’erreur doit eˆtre faible, le KPPG obtient de bien meilleurs re´sultats que
le KPPV. Quand aux SVMs, ils ne sont pas, a` notre connaissance, capables de rejeter
efficacement des donne´es (sauf pour des donne´es se projetant dans la marge). Notre
me´thode permet donc d’allier les performances en reconnaissance de certains classifieurs
comme les SVMs et un rejet efficace.
Le choix du re´seau LLGNG, et la liberte´ totale du choix de classifieurs nous per-
mettent de voir ce syste`me comme un nouvel outil pour la conception d’un syste`me
d’apprentissage incre´mental. Enfin, seul un classifieur de type SVM a e´te´ associe´ a`
chaque neurone du re´seau. Le fait de multiplier les classifieurs a` ce niveau permettra
probablement d’ame´liorer les re´sultats obtenus.
5 Conclusion
Une nouvelle approche de conception de syste`me de de´cision distribue´ et modu-
laire est pre´sente´e dans ce papier. Le principe de base est fonde´ sur l’exploitation
de la topologie des donne´es dans l’espace de repre´sentation. Une telle conception est
rendue possible graˆce a` l’utilisation combine´e d’outils de clustering et d’apprentissage
supervise´. Deux objectifs majeurs ont e´te´ recherche´s dans cette e´tude. D’une part, la
ne´cessite´ de disposer d’un syste`me e´volutif/incre´mental a conduit a` la mise au point
d’un algorithme de clustering incre´mental en donne´es, performant et ne ne´cessitant
que peu de parame´trages a priori contrairement aux approches classiques. La capacite´
d’apprentissage re´ellement incre´mental en donne´es ne pourra eˆtre atteinte qui si l’on
dispose de classifieurs supervise´s ayant cette proprie´te´. Ce dernier point est l’une des
principales perspectives de ce travail. Le deuxie`me objectif poursuivi concerne la fia-
bilite´ et la robustesse dans le processus de de´cision. Cette caracte´ristique est devenue
actuellement un enjeu majeur dans les nouvelles applications de fouille et d’exploration
de grandes masses de donne´es et d’aide a` la de´cision. Nous avons ainsi introduit dans
notre syste`me plusieurs niveaux de rejet. Le premier est relatif a` la carte topologique
et peut eˆtre qualifie´ de rejet par distance. Il permet en outre de fermer les frontie`res
de de´cision engendre´es par les classifieurs pilote´s par la carte. Le deuxie`me niveau
de rejet est associe´ aux diffe´rents classifieurs supervise´s utilise´s dans le syste`me. La
multiplication de ces classifieurs et l’introduction de re`gles de combinaison ade´quates
permettront de mieux exploiter cet aspect. Enfin, le dernier niveau de rejet est introduit
pour mieux prendre en compte des e´le´ments du contexte du proble`me inde´pendamment
du comportement intrinse`que des outils d’apprentissage et de clustering. Le facteur de
rejet propose´ a` cette fin conside`re ainsi des parame`tres tels que l’effectif de la base
d’apprentissage et permet par ailleurs a` l’utilisateur de mieux intervenir sur le controˆle
RNTI - C - 1
Clustering incre´mental pour un apprentissage distribue´
du processus de de´cision.
Re´fe´rences
[Ballard et Brown, 1982] D.H. Ballard et C. M. Brown. Computer Vision. Prentice
Hall, 1982.
[Duin, 2002] R.P.W Duin. The combining classifier: to train or not to train. In
IEEE Computer Society, editor, ICPR, pages 765–771, Quebec, 2002.
[Fritzke, 1994] B. Fritzke. Growing cell structures — A self-organizing network for
unsupervised and supervised learning. Neural Networks, 7(9):1441–1460, 1994.
[Fritzke, 1995] B. Fritzke. A growing neural gas network learns topologies. In NIPS,
pages 625–632. MIT Press, 1995.
[Gori et Scarselli, 1998] M. Gori et F. Scarselli. A multilayer perceptron adequate for
pattern recogition and verification. IEE TPAMI, 20:1121–1132, 1998.
[He´bert et al., 1999] Jean-Franc¸ois He´bert, Marc Parizeau, et Nadia Ghazzali. An hy-
brid architecture for active and incremental learning: The self-oganizing perceptron
(sop) network. In IJCNN99, Washington, DC, USA, July 1999.
[Jacobs et al., 1991] R.A. Jacobs, M.J. Jordan, S.J. Nowlan, et G.E. Hinton. Adaptive
mixtures of local experts. Neural Computation, 3(1):79–87, 1991.
[Kohonen, 1982] T. Kohonen. Self-organized formation of topologically correct feature
maps. Biological Cybernetics, 43:59–69, 1982.
[Kuncheva, 2002] L. I. Kuncheva. A theorical study on six classifier fusion strategies.
In IEEE Trans. Pattern Analysis and Machine Intelligence, volume 24, Feb 2002.
[Martinetz et Schulten, 1991] T. Martinetz et K. Schulten. A ”Neural-Gas” network
learns topologies. In T. Kohonen, K. Ma¨kisara, O. Simula, et J. Kangas, editors,
Proc. International Conference on Artificial Neural Networks (Espoo, Finland), vo-
lume I, pages 397–402, Amsterdam, Netherlands, 1991. North-Holland.
[Martinetz et Schulten, 1994] T. Martinetz et K. Schulten. Topology representing net-
works. Neural Networks, 7(2), 1994.
[Martinetz, 1993] T. Martinetz. Competitive Hebbian learning rule forms perfectly
topology preserving maps. In Stan Gielen et Bert Kappen, editors, Proc. ICANN’93,
pages 427–434, London, UK, 1993. Springer.
[Murphy et Aha, 1992] P. M. Murphy et D. W. Aha. UCI repository of machine lear-
ning databases. Machine-readable data repository, University of California, Depart-
ment of Information and Computer Science, Irvine, CA, 1992.
[Prudent et Ennaji, 2004] Y. Prudent et A. Ennaji. Extraction incre´mentale de la
topologie des donne´es. A paraˆıtre dans les Actes de SFC’04, 2004.
[Ribert, 1998] A. Ribert. Structuration Evolutive de donne´es: Application a` la
construction de classifieurs distribue´s. PhD thesis, Universite´ de Rouen, 1998.
[Roli et Giacinto, 2002] Fabio Roli et Gorgio Giacinto. design of multiple classifier
systems. Hybrid Methods in Pattern Recognition, pages 199–226, April 2002.
[Vapnik, 1995] V.N Vapnik. The nature of statistical theory. Springer, 1995.
RNTI - C - 1
