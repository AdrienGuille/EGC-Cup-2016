ModÃ¨les de mÃ©langes topologiques pour la classification de
donnÃ©es catÃ©gorielles et mixtes
Nicoleta Rogovschiâˆ—,Mustapha Lebbahâˆ—âˆ—, YounÃ¨s Bennaniâˆ—âˆ—
âˆ—LIPADE, UniversitÃ© Paris Descartes
45 rue des Saints PÃ¨res
75270 Paris Cedex 06
France
âˆ—âˆ—LIPN-UMR 7030 UniversitÃ© Paris 13 - CNRS
99, av. J-B ClÃ©ment - F-93430 Villetaneuse France.
prÃ©nom.nom@lipn.univ-paris13.fr
RÃ©sumÃ©. Cet article prÃ©sente une mÃ©thode basÃ©e sur les cartes auto-organisatrices
probabilistes dÃ©diÃ©es Ã  la classification non supervisÃ©e et la visualisation de don-
nÃ©es catÃ©gorielles et des donnÃ©es mixtes contenant des composantes quantita-
tives et binaires. Pour chacun de ces types de donnÃ©es, nous proposons un for-
malisme probabiliste dans lequel les unitÃ©s de la carte topologique sont reprÃ©-
sentÃ©es par un modÃ¨le de mÃ©langes de loi de Bernoulli, dans le cas des donnÃ©es
binaires et par un modÃ¨le de mÃ©langes de lois de Bernoulli et Gaussienne dans le
cas des donnÃ©es mixtes. Dans cette Ã©tude, la carte topologique est vue comme un
modÃ¨le gÃ©nÃ©ratif et est revisitÃ©e dans un formalisme probabiliste de modÃ¨les de
mÃ©langes. Lâ€™idÃ©e de base de ce travail repose sur le principe de la conservation
de la structure initiale des donnÃ©es en utilisant le formalisme probabiliste. Les
modÃ¨les de mÃ©langes proposÃ©s ici vÃ©rifient ce principe et fournissent des rÃ©sul-
tats directement interprÃ©tables par rapport aux donnÃ©es initiales, quâ€™elles soient
simplement binaires ou mixtes. Lâ€™apprentissage consiste alors Ã  estimer les para-
mÃ¨tres du modÃ¨le en maximisant la vraisemblance des donnÃ©es dâ€™apprentissage.
Lâ€™algorithme dâ€™apprentissage (PrMTM :Probabilistic Mixed Topological Map)
que nous proposons est basÃ© sur lâ€™algorithme EM (Estimation-Maximisation).
Nous avons montrÃ© que lâ€™algorithme Ã  base de modÃ¨les de mÃ©langes fournit
diffÃ©rentes informations pertinentes qui peuvent Ãªtre utilisÃ©es dans des applica-
tions pratiques. Nos approches ont Ã©tÃ© validÃ©es sur diffÃ©rentes bases de donnÃ©es
rÃ©elles et fournissent des rÃ©sultats prometteurs.
1 Introduction
Lâ€™apprentissage non supervisÃ© consiste Ã  construire des reprÃ©sentations simplifiÃ©es de donnÃ©es,
pour mettre en Ã©vidence les relations existantes entre les caractÃ©ristiques relevÃ©es sur des don-
nÃ©es et les ressemblances ou dissemblances de ces derniÃ¨res, sans avoir aucune connaissance
sur les classes. On peut distinguer deux grandes familles : les mÃ©thodes probabilistes et les mÃ©-
thodes dÃ©terministes ou tout simplement les mÃ©thodes de quantification. Ce travail concerne le
Classification probabilistes des donnÃ©es catÃ©gorielles et mixtes
traitement des donnÃ©es qualitatives et mixtes Ã  lâ€™aide des cartes auto-organisatrices, (Kohonen,
2001; Anouar, 1996; Thiria et al., 1997) dans le cadre du formalisme des modÃ¨les de mÃ©langes.
Les cartes topologiques utilisent un algorithme dâ€™auto-organisation (Self-Organizing Map,
SOM) qui permet dâ€™une part de quantifier de grandes quantitÃ©s de donnÃ©es en regroupant les
observations similaires en groupes ou clusters et dâ€™autre part de projeter les groupes obtenus de
faÃ§on non-linÃ©aire sur une carte, permettant ainsi de visualiser la structure du jeu de donnÃ©es en
deux dimensions, tout en respectant la topologie initiale des donnÃ©es. La mise en oeuvre de lâ€™al-
gorithme sur des donnÃ©es qualitatives et mixtes suppose toujours une phase de prÃ©traitement
permettant dâ€™extraire une information numÃ©rique des observations pour la partie qualitative.
Des travaux antÃ©rieurs (Lebbah et al., 2005; Lebbah, 2003) ont permis de proposer un modÃ¨le
de cartes topologiques dÃ©terministes pour les donnÃ©es binaires et un autre modÃ¨le probabi-
liste dÃ©diÃ© aux donnÃ©es catÃ©gorielles. DiffÃ©rentes approches ont Ã©tÃ© envisagÃ©es, pour diffÃ©rents
types de donnÃ©es, reposant sur des formalismes probabilistes. Dans (Verbeek et al., 2005), les
auteurs proposent une gÃ©nÃ©ralisation probabiliste des cartes auto-organisatrices qui maximise
lâ€™Ã©nergie variationnelle et qui additionne la log-vraisemblance des donnÃ©es et la divergence
de Kullback-Leibler entre une fonction de voisinage normalisÃ©e et la distribution postÃ©rieure
sur les donnÃ©es pour les composants. Nous avons Ã©galement STVQ (Soft topographic vector
quantization), qui emploie une certaine mesure de divergence entre les donnÃ©es Ã©lÃ©mentaires
et les rÃ©fÃ©rents afin de minimiser une nouvelle fonction dâ€™erreur (Heskes, 2001; Graepel et al.,
1998). Il existe aussi un modÃ¨le original qui permet de crÃ©er un graphe entre les prototypes en
se basant sur les modÃ¨les de mÃ©langes et les graphes de Delaunay (Aupetit, 2005). Un autre mo-
dÃ¨le, souvent prÃ©sentÃ© comme la version probabiliste des cartes auto-organisatrices, est GTM
(Generative Topographic Map) (Bishop et al., 1998; Kaban et Girolami, 2001). Cependant, la
faÃ§on dont GTM atteint lâ€™organisation topologique est trÃ¨s diffÃ©rente de celle utilisÃ©e dans les
modÃ¨les des cartes topologiques traditionnelles. Dans GTM le mÃ©lange est paramÃ©trÃ© par une
combinaison linÃ©aire de fonctions non linÃ©aires des positions des cellules de la carte (GTM Ã 
lâ€™origine a Ã©tÃ© conÃ§u pour les donnÃ©es quantitatives). Des extensions de ce modÃ¨le Ã  un modÃ¨le
dÃ©diÃ© aux donnÃ©es discrÃ¨tes et binaires ont Ã©tÃ© proposÃ©es (Girolami, 2001; Priam et Nadif,
2006; Priam et al., 2008).
La difficultÃ© principale en ce qui concerne lâ€™application des modÃ¨les de mÃ©langes de dis-
tributions multivariables pour le partitionnement "clustering" est quâ€™ils sont liÃ©s Ã  un type de
donnÃ©es : les distributions normales pour les donnÃ©es quantitatives, la distribution de Bernoulli
pour les donnÃ©es binaires, et le modÃ¨le des classes latentes pour les variables catÃ©gorielles.
Ceci est limitatif puisque la plupart des ensembles de donnÃ©es sont mixtes et impliquent diffÃ©-
rents types dâ€™informations : quantitatifs, catÃ©goriels, binaires.
Lâ€™idÃ©e de base de ce travail repose sur le principe de la conservation de la structure ini-
tiale des donnÃ©es en utilisant le formalisme probabiliste. Les modÃ¨les de mÃ©langes proposÃ©s
ici vÃ©rifient ce principe et fournissent des rÃ©sultats directement interprÃ©tables par rapport aux
donnÃ©es initiales, quâ€™elles soient simplement binaires ou mixtes.
2 ModÃ¨le de mÃ©lange topologique
Pour dÃ©finir le modÃ¨le des cartes topologiques Ã  base de modÃ¨le de mÃ©lange on associe Ã 
chaque cellule c de la carte C une fonction densitÃ© fc(x) = p(x/Î¸c) dont les paramÃ¨tres se-
ront notÃ©s Î¸. Pour dÃ©finir le mÃ©lange de densitÃ©s des cartes topologiques, nous utiliserons le
Rogovschi et al.
formalisme bayÃ©sien introduit par Luttrel (Luttrel, 1994). Ce formalisme suppose que les ob-
servations x sont gÃ©nÃ©rÃ©es de la maniÃ¨re suivante : on commence par choisir une cellule câˆ— de C
qui permet de dÃ©terminer un voisinage de cellule suivant la probabilitÃ© conditionnelle p(c/câˆ—)
qui est supposÃ©e connue. Ainsi lâ€™observation x est gÃ©nÃ©rÃ©e suivant la probabilitÃ© p(x/c). Ce
processus permet de modÃ©liser les diffÃ©rentes Ã©tapes de propagation de lâ€™information entre les
diffÃ©rentes cellules c âˆˆ C et câˆ— âˆˆ C.
La premiÃ¨re Ã©tape de propagation attribue Ã  une observation x une cellule c de C avec la
probabilitÃ© p(c/x). La seconde Ã©tape attribue Ã  toute cellule c de C une cellule câˆ— de C avec la
probabilitÃ© p(câˆ—/c). Afin de simplifier le calcul des probabilitÃ©s on suppose que le processus
de propagation vÃ©rifie la propriÃ©tÃ© de Markov :
p(x/c, câˆ—) = p(x/c)
et
p(câˆ—/c,x) = p(câˆ—/c)
Ce formalisme nous amÃ¨ne Ã  dÃ©finir le gÃ©nÃ©rateur des donnÃ©es p(x) par un mÃ©lange de proba-
bilitÃ©s dÃ©fini comme suit :
p(x) =
âˆ‘
c,câˆ—âˆˆC
p(c, câˆ—,x)
=
âˆ‘
c,câˆ—âˆˆC
p(x/c)p(c/câˆ—)p(câˆ—)
=
âˆ‘
câˆ—âˆˆC
p(câˆ—)pcâˆ—(x) (1)
avec
pcâˆ—(x) = p(x/câˆ—) =
âˆ‘
câˆˆC
p(c/câˆ—)p(x/c). (2)
Ainsi, p(x) apparaÃ®t comme un mÃ©lange des probabilitÃ©s pcâˆ—(x). Lâ€™observation x sâ€™obtient
premiÃ¨rement par la sÃ©lection de câˆ— puis de c de C, ensuite par la sÃ©lection de x Ã  lâ€™intÃ©rieur du
sous-Ã©chantillon avec la probabilitÃ© p(x/c).
Les coefficients du mÃ©lange sont les probabilitÃ©s p(câˆ—) a priori et les fonctions densitÃ©s rela-
tives Ã  chaque Ã©lÃ©ment du mÃ©lange qui sont donnÃ©es par pcâˆ—(x) (eq.(2)). Ce formalisme montre
quâ€™on peut calculer p(x) Ã  condition de connaÃ®tre pour chaque cellule c la fonction de densitÃ©
p(x/c) et la probabilitÃ© p(c/câˆ—) dâ€™activation de la cellule c connaissant câˆ—.
Afin dâ€™introduire la notion de voisinage dans le formalisme probabiliste, nous supposons que
chaque cellule c de la carte C est dâ€™autant plus active quâ€™elle est proche de la cellule choisie câˆ—,
(eq.(1), eq.(2)). Ceci nous permet de dÃ©finir la probabilitÃ© p(c/câˆ—) en fonction de la fonction
de voisinage KT (.) :
Classification probabilistes des donnÃ©es catÃ©gorielles et mixtes
p(c/câˆ—) =
KT (Î´(c, câˆ—))
Tcâˆ—
(3)
oÃ¹ Tcâˆ— =
âˆ‘
râˆˆC
KT (Î´(r, câˆ—)), est un terme normalisant pour obtenir des probabilitÃ©s.
Pour dÃ©finir complÃ¨tement p(x) il reste Ã  dÃ©finir les coefficients du mÃ©lange p(câˆ—) et les pa-
ramÃ¨tres de la densitÃ© p(x/c). Ce formalisme a dÃ©jÃ  Ã©tÃ© utilisÃ© dans (Anouar et al., 1997) et a
permis de dÃ©finir le modÃ¨le PrSOM dÃ©diÃ© aux donnÃ©es continues (Anouar, 1996; Thiria et al.,
1997). Ce modÃ¨le qui gÃ©nÃ©ralise le modÃ¨le classique des cartes topologiques introduit par Ko-
honen permet dâ€™obtenir une quantification de lâ€™espace des donnÃ©es, mais aussi une estimation
des densitÃ©s locales.
3 Algorithme EM
Lâ€™algorithme EM (Bishop, 1995; Dempster et al., 1977; McLachlan et Krishman, 1997) est un
algorithme itÃ©ratif qui permet de trouver un maximum local de la fonction de vraisemblance
des observations, lorsque chaque observation contient une partie cachÃ©e (ou non observÃ©e).
Ainsi, on suppose que chaque donnÃ©e est un couple de types (x, z) oÃ¹ x est sa partie ob-
servable et z sa partie cachÃ©e (non observable). Nous supposons connus dâ€™une maniÃ¨re ex-
plicite la forme de la fonction densitÃ© jointe p(x, z; Î¸) oÃ¹ Î¸ est lâ€™ensemble des paramÃ¨tres
du modÃ¨le Ã  estimer. On suppose que lâ€™on dispose dâ€™une sÃ©rie de donnÃ©es indÃ©pendantes :
(x1, z1), (x2, z2), ..., (xN , zN ), pour lesquelles xi sont les parties quâ€™on a rÃ©ellement obser-
vÃ©es et les zi sont les parties cachÃ©es (donc inconnues).
Nous souhaitons par la suite maximiser le logarithme de la vraisemblance des parties, des
donnÃ©es rÃ©ellement observÃ©es A = {x1,x2, ...,xN} dÃ©fini comme suit :
lnV (A; Î¸) = lnV (x1,x2, ...,xN ; Î¸) =
Nâˆ‘
i=1
ln p(xi; Î¸) (4)
oÃ¹ p(x; Î¸) est la fonction densitÃ© de la partie observÃ©e x. En pratique p(x; Î¸) est calculable en
marginalisant la fonction densitÃ© p(x, z; Î¸) (p(x; Î¸) =
âˆ«
p(x, z; Î¸)dz), ce qui donne souvent
une fonction log-vraisemblance lnV (x1,x2, ...,xN ; Î¸) qui nâ€™est pas simple Ã  optimiser.
Lâ€™algorithme EM proposÃ© par Dempster et al (Dempster et al., 1977) maximise lâ€™expression
(4) en utilisant la log-vraisemblance des donnÃ©es entiÃ¨res lnV (x1,x2, ...,xN , z1, ..., zN ; Î¸).
On dÃ©signe par Z = {z1, ..., zN} lâ€™ensemble des parties correspondantes et non observÃ©es.
Chaque itÃ©ration de lâ€™algorithme EM comporte deux Ã©tapes :
â€“ Lâ€™Ã©tape dâ€™Estimation (Expectation step) ; dite aussi Ã©tape â€Eâ€
â€“ Lâ€™Ã©tape de Maximisation (Maximization step) ; dite Ã©tape â€Mâ€
Ainsi Ã  lâ€™itÃ©ration t ces deux Ã©tapes se prÃ©sentent de la maniÃ¨re suivante :
Rogovschi et al.
â€“ Etape E (Expectation step)
On suppose Ã  cette Ã©tape, que la fonction densitÃ© de la partie cachÃ©e conditionnÃ©e par
la partie observÃ©e (z/x) correspond Ã  la valeur du paramÃ¨tre Î¸tâˆ’1 calculÃ©e Ã  lâ€™itÃ©ration
prÃ©cÃ©dente (ou Ã©gale Ã  lâ€™initialisation Î¸0 si t = 1) ; cette fonction densitÃ© sâ€™Ã©crit donc
(p(z/x, Î¸tâˆ’1)). On calcule alors lâ€™espÃ©rance :
Q(Î¸, Î¸tâˆ’1) = E
[
lnV (A,Z/Î¸)/A, Î¸tâˆ’1
]
=
âˆ«
lnV (A,Z/Î¸)p(Z/A, Î¸tâˆ’1)
=
âˆ«
lnV (A,Z/Î¸)
Nâˆ
i=1
p(zi/xi, Î¸tâˆ’1) dzi (5)
Cette expression qui est parfois appelÃ©e â€la vraisemblance relativeâ€ se justifie â€intuiti-
vementâ€. En effet, Ã©tant donnÃ© quâ€™on ne connait pas les valeurs des variables cachÃ©es
zi associÃ©es aux observations xi âˆˆ A, on calcule lâ€™espÃ©rance de la log-vraisemblance
relativement aux variables cachÃ©es.
â€“ Etape de maximisation (Maximization step)
Ayant calculÃ© Q(Î¸, Î¸tâˆ’1) Ã  lâ€™Ã©tape E, il sâ€™agit dans cette Ã©tape de maximiser cette ex-
pression par rapport Ã  Î¸. On prend alors :
Î¸
â€²
= argmax
Î¸
Q(Î¸, Î¸tâˆ’1)
Il est dÃ©montrÃ© alors que chaque itÃ©ration (E-M) fait croÃ®tre la fonction log-vraisemblance (4)
(lnV (A, Î¸t) â‰¥ lnV (A, Î¸tâˆ’1)) (Dempster et al., 1977). Ainsi, lâ€™algorithme E-M se prÃ©sente
de la maniÃ¨re suivante :
1. Initialisation : Choisir des paramÃ¨tres initiaux Î¸0 et Niter (le nombre dâ€™itÃ©rations).
2. ItÃ©ration de Base (t â‰¥ 1)
â€“ Etape E : Estimer lâ€™expression Q(Î¸, Î¸tâˆ’1) dÃ©finie par lâ€™expression 5.
â€“ EtapeM : Maximiser Q(Î¸, Î¸tâˆ’1) par rapport Ã  Î¸, prendre Î¸t = argmaxÎ¸ Q(Î¸, Î¸tâˆ’1)
3. RÃ©pÃ©ter lâ€™itÃ©ration de base, jusquâ€™Ã  stabilisation de Î¸t ou jusquâ€™Ã  t â‰¥ Niter
Remarque : Lâ€™algorithme EM est largement utilisÃ© en classification pour bÃ¢tir de faÃ§on itÃ©ra-
tive, Ã  partir dâ€™un nombre dâ€™observations donnÃ©es, des modÃ¨les de mÃ©langes paramÃ©triques.
4 ModÃ¨le de mÃ©langes pour des donnÃ©es binaires et mixtes
Nous supposons par la suite que les donnÃ©es x sont des vecteurs Ã  d composantes composÃ©es
de deux parties : une partie quantitative xr[.]i = (x
r[1]
i , x
r[2]
i , ..., x
r[n]
i ) (x
r[.]
i âˆˆ Rn) et dâ€™une
Classification probabilistes des donnÃ©es catÃ©gorielles et mixtes
partie qualitative codÃ©e en binaire xb[.]i = (x
b[1]
i , x
b[2]
i , ..., x
b[k]
i , ..., x
b[m]
i ) oÃ¹ la kiÃ¨me compo-
sante xb[k]i est une variable binaire (x
b[k]
i âˆˆ Î² = {0, 1}). Chaque observation xi est ainsi la
rÃ©alisation dâ€™une variable alÃ©atoire appartenant Ã  RnÃ—Î²m. Avec ces notations une observation
particuliÃ¨re xi = (x
r[.]
i ,x
b[.]
i ) est un vecteur composÃ© dâ€™une partie quantitative et une binaire
avec la dimension d = n +m. Nous rappelons que A reprÃ©sente lâ€™ensemble des observations
de taille N .
Afin de simplifier ce modÃ¨le, nous supposons que la composante quantitative est indÃ©pendante
de la composante binaire. Cette hypothÃ¨se est appliquÃ©e pour la majoritÃ© des algorithmes pro-
babilistes de partitionnement. Ainsi la probabilitÃ© conditionnelle peut Ãªtre rÃ©Ã©crite comme le
produit de deux termes :
p(x/c) = p(xr[.]/c)Ã— p(xb[.]/c)
Nous prenons aussi une hypothÃ¨se forte qui est de considÃ©rer que les n composantes quantita-
tives et lesm binaires sont indÃ©pendantes sachant une cellule c :
p(xb[.]/c) =
mâˆ
k=1
p(xb[k]/c)
p(xr[.]/c) =
nâˆ
k=1
p(xr[k]/c)
Nous associons dans la suite Ã  chaque cellule c âˆˆ C de la carte une probabilitÃ© conditionnelle
qui dÃ©crit la gÃ©nÃ©ration dâ€™observation par une cellule c avec les deux parties :
â€“ La fonction densitÃ© de la partie quantitative qui est une gaussienne sphÃ©rique
p(xr[.]/c) = N(xr[.],wr[.], Ïƒ2cI), dÃ©finie par "la moyenne" (vecteur rÃ©fÃ©rent w
r[.] =
(wr[1], ..., wr[k], wr[n])), la matrice covariance, dÃ©finie par Ïƒ2cI oÃ¹ Ïƒc est lâ€™Ã©cart type et
I la matrice identitÃ©,
N(xr[.],wr[.], Ïƒ2cI) =
1
(2piÏƒc)
n
2
exp
[
||wr[.]c âˆ’ xr[.]i ||2
2Ïƒ2c
]
(6)
â€“ La fonction densitÃ© de la partie binaire qui est la distribution de Bernoulli
p(xb[.]/c) = p(xb[.]/Îµc,w
b[.]
c ) = fc(xb[.],w
b[.]
c , Îµc) avec les paramÃ¨tres w
b[.]
c =
(wb[1]c , w
b[2]
c , ..., w
b[k]
c , ..., w
b[m]
c ) âˆˆ Î²m avec la probabilitÃ© Îµc âˆˆ]0, 12 [ associÃ©e Ã  wb[.]c âˆˆ
{0, 1}m. Le paramÃ¨tre Îµc dÃ©finit la probabilitÃ© dâ€™Ãªtre diffÃ©rent du prototype wb[.]c . La
distribution associÃ©e Ã  chaque cellule c âˆˆ C est dÃ©finie comme suit :
fc(xb[.],wb[.]c , Îµc) = Îµ
H(xb[.],wb[.]c )
c (1âˆ’ Îµc)mâˆ’H(xb[.],wb[.]c ) (7)
H est la distance de Hamming qui permet la comparaison de deux vecteurs binaires.
Cette distance mesure le nombre de composantes binaires diffÃ©rentes entre xb[.]i et x
b[.]
j :
H(xb[.]i ,x
b[.]
j ) =
mâˆ‘
k=1
|xb[k]i âˆ’ xb[k]j |
Rogovschi et al.
Les paramÃ¨tres Î¸ = Î¸C âˆª Î¸Câˆ— qui dÃ©finissent le modÃ¨le gÃ©nÃ©rateur de mÃ©lange sont consti-
tuÃ©s Ã  la fois des paramÃ¨tres de la distribution Gaussienne et Bernoulli (Î¸C = {Î¸c, c = 1..K},
oÃ¹ Î¸c = (wc = (w
r[.]
c ,w
b[.]
c ), Ïƒ2c , Îµc)), et de la probabilitÃ© a priori aussi appellÃ©e coefficient
de la mixture (Î¸C
âˆ—
= {Î¸câˆ— , câˆ— = 1..K}, oÃ¹ Î¸câˆ— = p(câˆ—)). Lâ€™objectif maintenant est de dÃ©fi-
nir la fonction de coÃ»t ainsi que lâ€™algorithme dâ€™apprentissage associÃ© qui permettra dâ€™estimer
ces paramÃ¨tres. Cet algorithme sera notÃ© par la suite PrMTM :Probabilistic Mixed Topological
Map.
4.1 Algorithme dâ€™apprentissage
Lâ€™algorithme dâ€™apprentissage consiste Ã  maximiser la vraisemblance des observations en appli-
quant lâ€™algorithme EM. Lâ€™usage de lâ€™algorithme EM sâ€™explique par lâ€™existence dâ€™une variable
cachÃ©e notÃ©e z, constituÃ©e par le couple de cellule c et câˆ—, z = (c, câˆ—), impliquÃ©es dans la gÃ©-
nÃ©ration dâ€™une donnÃ©e observÃ©e x. En effet, la variable cachÃ©e z = (c, câˆ—) apparaÃ®t lorsquâ€™on
Ã©crit :
p(x) =
âˆ‘
zâˆˆCÃ—C
p(x, z)
=
âˆ‘
c,câˆ—âˆˆC
p(x/c)p(câˆ—)p(c/câˆ—)N(xr[.],wr[.], Ïƒ2cI)Ã— fc(xb[.],wb[.]c , Îµc) (8)
A chaque donnÃ©e mixte rÃ©ellement observÃ©e x, correspond une variable indicatrice non obser-
vÃ©e z qui appartient Ã  C Ã— C et qui permet dâ€™identifier le couple de cellules responsables de
la gÃ©nÃ©ration de lâ€™observation xi. On note par Z = {z1, ..., zN} lâ€™ensemble des variables non
observÃ©es.
z
(c,câˆ—)
i =
{
1 pour zi = (c, câˆ—)
0 sinon (9)
Donc, nous pouvons dÃ©finir la vraisemblance des donnÃ©es de la faÃ§on suivante :
V T (A,Z; Î¸) =
Kâˆ
i=1
âˆ
câˆ—âˆˆC
âˆ
câˆˆC
[
p(câˆ—)p(c/câˆ—)N(xr[.]i ,w
r[.], Ïƒ2c1I)Ã— fc(xb[.]i ,wb[.]c , Îµc)
]z(c,câˆ—)i
(10)
Lâ€™application de lâ€™algorithme EM pour la maximisation de la vraisemblance des donnÃ©es ob-
servÃ©es nÃ©cessite dâ€™une part lâ€™estimation de
QT (Î¸, Î¸t) = E
[
lnV T (A,Z; Î¸)/A, Î¸t
]
,
oÃ¹ Î¸t est lâ€™ensemble des paramÃ¨tres estimÃ©s Ã  la tÃ¨me itÃ©ration de lâ€™algorithme, et Î¸ lâ€™ensemble
des paramÃ¨tres recherchÃ©s.
Lâ€™Ã©tape "E (Estimation)" calcule lâ€™espÃ©rance de la log-vraisemblance par rapport aux variables
cachÃ©es en prenant en considÃ©ration les paramÃ©tres Î¸tâˆ’1. A lâ€™issue de lâ€™Ã©tape "M (Maximisa-
tion)", la fonctionQT (Î¸t, Î¸tâˆ’1) est maximisÃ©e par rapport Î¸t, (Î¸t = argmaxÎ¸(QT (Î¸, Î¸tâˆ’1))).
Ces deux Ã©tapes maximisent la fonction objective QT (Î¸t, Î¸tâˆ’1) oÃ¹ lnV T (A, Î¸t) â‰¥
Classification probabilistes des donnÃ©es catÃ©gorielles et mixtes
lnV T (A, Î¸tâˆ’1). Ainsi, la fonction QT (Î¸t, Î¸tâˆ’1) est dÃ©finie de la maniÃ¨re suivante :
QT (Î¸t, Î¸tâˆ’1) =
âˆ‘
xiâˆˆA
âˆ‘
câˆ—âˆˆC
âˆ‘
câˆˆC
E(z(c,c
âˆ—)
i /xi, Î¸
tâˆ’1)
(
ln(Î¸c
âˆ—
) + ln
(
KT (Î´(câˆ—, c))
Tcâˆ—
)
+ ln
(
N(xr[.],wr[.]c , Ïƒ
2
cI)Ã— fc(xb[.],wb[.]c , Îµc)
))
(11)
oÃ¹ Tcâˆ— =
âˆ‘
râˆˆCK
T (Î´(r, câˆ—)) et la variable z(c,c
âˆ—)
i est une variable de Bernoulli.
Ainsi, lâ€™espÃ©rance est dÃ©finie comme suit :
E(z(c,c
âˆ—)
i /xi, Î¸
tâˆ’1) = p(z(c,c
âˆ—)
i = 1/xi, Î¸
tâˆ’1) = p(c, câˆ—/xi, Î¸tâˆ’1)
oÃ¹
p(c, câˆ—/xi, Î¸tâˆ’1) =
p(câˆ—)p(c/câˆ—)p(x/c)
p(x)
Ainsi la fonction QT (Î¸t, Î¸tâˆ’1) sâ€™Ã©crit :
QT (Î¸t, Î¸tâˆ’1) =
âˆ‘
xiâˆˆA
âˆ‘
câˆˆC
âˆ‘
câˆ—âˆˆC
p(c, câˆ—/xi, Î¸tâˆ’1) ln(N(xr[.],wr[.]c , Ïƒ
2
cI))
+
âˆ‘
xiâˆˆA
âˆ‘
câˆˆC
âˆ‘
câˆ—âˆˆC
p(c, câˆ—/xi, Î¸tâˆ’1) ln(fc(xb[.],wb[.]c , Îµc))
+
âˆ‘
xiâˆˆA
âˆ‘
câˆ—âˆˆC
âˆ‘
câˆˆC
p(c, câˆ—/xi, Î¸tâˆ’1) ln(Î¸c
âˆ—
)
+
âˆ‘
xiâˆˆA
âˆ‘
câˆ—âˆˆC
âˆ‘
câˆˆC
p(c, câˆ—/xi, Î¸tâˆ’1) ln
(
KT (Î´(câˆ—, c))
Tcâˆ—
)
Les variables Î¸c et Î¸c
âˆ—
indiquent les paramÃ¨tres estimÃ©s Ã  lâ€™itÃ©ration t. Nous observons que la
fonction objectiveQT (Î¸t, Î¸tâˆ’1) (12) est dÃ©finie comme une somme de trois termes principaux.
Le premier termeQT1 (Î¸
C, Î¸tâˆ’1) est composÃ© de deux parties qui dÃ©pendent respectivement des
paramÃ¨tres (wr[.]c , Ïƒc) et (w
b[.]
c , Îµc) ; le second termeQT2 (Î¸
Câˆ— , Î¸tâˆ’1) dÃ©pend du paramÃ¨tre Î¸c
âˆ—
,
et le troisiÃ¨me terme est constant. La maximisation de la fonction QT (Î¸t, Î¸tâˆ’1) par rapport Ã 
Î¸c
âˆ—
et Î¸c est rÃ©alisÃ©e sÃ©parÃ©ment. Ainsi,
QT (Î¸t, Î¸tâˆ’1) = QT1 (Î¸
C, Î¸tâˆ’1) +QT2 (Î¸
Câˆ— , Î¸tâˆ’1) +QT3 (Î¸
tâˆ’1)
(12)
oÃ¹
QT2 (Î¸
Câˆ— , Î¸tâˆ’1) =
âˆ‘
xiâˆˆA
âˆ‘
câˆ—âˆˆC
âˆ‘
câˆˆC
p(c, câˆ—/xi, Î¸tâˆ’1) ln(Î¸c
âˆ—
)
et
QT1 (Î¸
C, Î¸tâˆ’1) = Qr[.],T1 (w
r[.], Ïƒc, Î¸
tâˆ’1) +Qb[.],T1 (w
b[.], Îµc, Î¸
tâˆ’1)
Rogovschi et al.
Q
r[.],T
1 (w
r[.], Ïƒc, Î¸
tâˆ’1) =
âˆ‘
xiâˆˆA
âˆ‘
câˆˆC
âˆ‘
câˆ—âˆˆC
p(c, câˆ—/xi, Î¸tâˆ’1) ln(N(xr[.],wr[.]c , Ïƒ
2
cI))
Q
b[.],T
1 (w
b[.], Îµc, Î¸
tâˆ’1) =
âˆ‘
xiâˆˆA
âˆ‘
câˆˆC
âˆ‘
câˆ—âˆˆC
p(c, câˆ—/xi, Î¸tâˆ’1) ln(fc(xb[.],wb[.]c , Îµc))
Maximisation de la fonction QT (Î¸t, Î¸tâˆ’1)
Maximiser la fonction (12) revient Ã  maximiser les deux premiers termes sÃ©parÃ©ment. Notons
que la maximisation du premier terme QT1 (Î¸
C, Î¸tâˆ’1) nÃ©cessite aussi la maximisation de deux
autres termes. Finalement, maximiser la fonction (12) revient Ã  maximiser trois termes. Le
terme Qr[.],T1 (w
r[.], Ïƒc, Î¸
tâˆ’1) par rapport Ã  wr[.] et Ïƒc, la fonction Q
b[.],T
1 (w
b[.], Îµc, Î¸
tâˆ’1) par
rapport Ã  Îµc et Î¸tâˆ’1, et le terme QT2 (Î¸
Câˆ— , Î¸tâˆ’1) par rapport Ã  Î¸C
âˆ—
.
â€“ Maximiser QT2 (Î¸C
âˆ—
, Î¸tâˆ’1) :
QT2 (Î¸
Câˆ— , Î¸tâˆ’1) =
âˆ‘
xiâˆˆA
âˆ‘
câˆ—âˆˆC
âˆ‘
câˆˆC
p(c, câˆ—/xi, Î¸tâˆ’1) ln(Î¸c
âˆ—
)
Afin dâ€™estimer les paramÃ¨tres Î¸C
âˆ—
qui est lâ€™ensemble des probabilitÃ©s a priori, on donne
une forme explicite aux probabilitÃ©s a priori. Ainsi la probabilitÃ© a priori est estimÃ©e
avec lâ€™Ã©quation suivante :
Î¸c
âˆ—
= p(câˆ—) =
âˆ‘
xiâˆˆA p(c
âˆ—/xi, Î¸tâˆ’1)
K
(13)
â€“ Maximiser Qr[.],T1 (wr[.], Ïƒc, Î¸tâˆ’1) :
Q
r[.],T
1 (w
r[.], Ïƒc, Î¸
tâˆ’1) =
âˆ‘
xiâˆˆA
âˆ‘
câˆˆC
âˆ‘
câˆ—âˆˆC
p(c, câˆ—/xi, Î¸tâˆ’1) ln(N(xr[.],wr[.]c , Ïƒ
2
cI))
La maximisation de cette fonction nÃ©cessite une maximisation en deux Ã©tapes. La pre-
miÃ¨re consiste Ã  fixer le paramÃ¨trewr[.]c et Ã  maximiser la fonctionQ
r[.],T
1 (w
r[.], Îµc, Î¸
tâˆ’1)
en dÃ©rivant la fonction par rapport Ã  Ïƒc. Et la deuxiÃ¨me consiste Ã  fixer lâ€™Ã©cart Ïƒc et Ã 
dÃ©river par rapport Ã  wr[.]c :
wr[.]c =
âˆ‘
xiâˆˆA x
r[.]
i p(c/xi)âˆ‘
xiâˆˆA p(c/xi)
(14)
Ïƒ2c =
âˆ‘
xiâˆˆA ||w
r[.]
c âˆ’ xr[.]i ||2p(c/xi)
n
âˆ‘
xâˆˆA p(c/xi)
(15)
â€“ Maximiser Qb[.],T1 (wb[.], Îµc, Î¸tâˆ’1)
Q
b[.],T
1 (w
b[.], Îµc, Î¸
tâˆ’1) =
âˆ‘
xiâˆˆA
âˆ‘
câˆˆC
âˆ‘
câˆ—âˆˆC
p(c, câˆ—/xi, Î¸tâˆ’1) ln(fc(xb[.],wb[.]c , Îµc))
Classification probabilistes des donnÃ©es catÃ©gorielles et mixtes
Dans ce cas le paramÃ¨tre  dÃ©pend seulement de la cellule c. La maximisation de la
fonction est aussi rÃ©alisÃ©e en deux Ã©tapes. Une premiÃ¨re maximisation par rapport Ã 
w
b[k]
c . Celle-ci correspond au calcul du centre mÃ©dian. Puis on effectue une maximisation
par rapport Ã  Îµc en rÃ©solvant lâ€™Ã©quation
âˆ‚Q
b[.],T
1 (w
b[.],Îµc,Î¸
tâˆ’1)
âˆ‚Îµc
= 0 . Ainsi les expressions
qui permettent de maximiser cette partie de la fonction, connaissant les paramÃ¨tres Ã 
lâ€™instant tâˆ’ 1 sont dÃ©finies par :
wb[k]c =
ï£±ï£´ï£´ï£²ï£´ï£´ï£³
0 si
[âˆ‘
xiâˆˆA p(c/xi, Î¸
tâˆ’1)(1âˆ’ xb[k]i )
]
â‰¥[âˆ‘
xiâˆˆA p(c/xi, Î¸
tâˆ’1)xb[k]i
]
1 sinon
(16)
Îµc =
âˆ‘
xiâˆˆA p(c/xi, Î¸
tâˆ’1)H(xb[.]i ,w
b[.]
c )âˆ‘
xiâˆˆAmp(c/xi, Î¸
tâˆ’1)
(17)
oÃ¹
p(câˆ—/xi, Î¸tâˆ’1) =
âˆ‘
câˆˆC p(c, c
âˆ—/xi, Î¸tâˆ’1)
et
p(c/xi, Î¸tâˆ’1) =
âˆ‘
câˆ—âˆˆC p(c, c
âˆ—/xi, Î¸tâˆ’1).
Lâ€™algorithme dâ€™apprentissage PrMTM est une autre application de lâ€™algorithme EM aux mo-
dÃ¨les des cartes auto-organisatrices probabilistes. En supposant que les probabilitÃ©s condition-
nelles p(câˆ—/c) sont fixÃ©es pour une valeur donnÃ©e de T , lâ€™algorithme est dÃ©fini dâ€™une maniÃ¨re
itÃ©rative oÃ¹ les paramÃ¨tres Ã  lâ€™itÃ©ration t+1 sont calculÃ©s en fonction des paramÃ¨tres estimÃ©s Ã 
lâ€™itÃ©ration t. Lâ€™algorithme PrMTM pour un paramÃ¨tre T fixÃ© se prÃ©sente de la maniÃ¨re suivante :
1. Initialisation (t = 0)
â€“ dÃ©termination de lâ€™ensemble des paramÃ¨tres initiaux (Î¸0) et du nombre dâ€™itÃ©rations
iter.
2. ItÃ©ration de base Ã  T constant (t â‰¥ 1)
â€“ Calcul de lâ€™ensemble des paramÃ¨tres Î¸t+1 Ã  partir de lâ€™ensemble des paramÃ¨tres dÃ©jÃ 
calculÃ©s Î¸t en appliquant les formules (13),(14), (15),(16) et (17).
3. RÃ©pÃ©ter lâ€™itÃ©ration de base tant que t < iter.
Nous avons prÃ©sentÃ© le principe de lâ€™algorithme dâ€™apprentissage PrMTM permettant dâ€™estimer
les paramÃ¨tres maximisant la fonction vraisemblance pour un paramÃ¨tre T fixÃ©. Le paramÃ¨tre
T permet de contrÃ´ler la taille du voisinage dâ€™influence dâ€™une cellule sur la carte, qui dÃ©croÃ®t
avec le paramÃ¨tre T . De la mÃªme maniÃ¨re et par analogie avec lâ€™algorithme des cartes topolo-
giques, on peut faire dÃ©croÃ®tre la valeur de T entre deux valeurs Tmax et Tmin. Pour chaque
valeur de T , on obtient une fonction de vraisemblance V T qui varie avec T . Nous pouvons
Rogovschi et al.
observer deux Ã©tapes dans le fonctionnement de lâ€™algorithme.
â€“ La premiÃ¨re Ã©tape correspond aux grandes valeurs de T . Dans ce cas, le voisinage dâ€™in-
fluence dâ€™une cellule c de la carte est grand et correspond aux valeurs "significatives" de
KT (Î´(c, r)). Les formules, (13),(14), (15),(16) et (17) ont tendance, dans ce cas, Ã  faire
participer un trÃ¨s grand nombre dâ€™observations Ã  lâ€™estimation des paramÃ¨tres du modÃ¨le
PrMTM.
â€“ La deuxiÃ¨me Ã©tape correspond aux petites valeurs de T . Le nombre dâ€™observations in-
tervenant dans les formules (13),(14), (15),(16) et (17) est alors restreint. Lâ€™adaptation
est trÃ¨s locale.
Si on utilise cette dÃ©croissance de T , lâ€™algorithme dâ€™apprentissage de PrMTM se prÃ©sente de
la maniÃ¨re suivante :
1. Phase dâ€™initialisation (t = 0)
â€“ Choisir Tmax, Tmin et Niter. Effectuer lâ€™algorithme dâ€™apprentissage PrMTM pour la
valeur de T constante Ã©gale Ã  Tmax.
2. Etape itÃ©rative
â€“ Lâ€™ensemble des paramÃ¨tres Î¸t de lâ€™Ã©tape prÃ©cÃ©dente est connu. Calculer la nouvelle
valeur de T en appliquant la formule suivante :
T = Tmax
(
Tmin
Tmax
) t
iterâˆ’1
â€“ Pour cette valeur du paramÃ¨tre T , calculer lâ€™itÃ©ration de base dÃ©finie dans lâ€™algorithme
indiquÃ© prÃ©cÃ©demment pour un paramÃ¨tre fixe T .
3. RÃ©pÃ©ter lâ€™Ã©tape itÃ©rative tant que t â‰¤ Niter
Par la suite nous dÃ©velopperons trois versions de PrMTM (tableau 1). La premiÃ¨re est dÃ©-
veloppÃ©e sous lâ€™hypothÃ¨se que le paramÃ¨tre de probabilitÃ©  dÃ©pend uniquement de la cellule
( = Îµc). La deuxiÃ¨me est le cas gÃ©nÃ©ral oÃ¹ le paramÃ¨tre de probabilitÃ© dÃ©pend de la cellule
et de la variable c = (Îµ1c , ..., Îµ
k
c , ..., Îµ
n
c ). La troisiÃ¨me version estime un paramÃ¨tre qui dÃ©pend
seulement de la carte ( = Îµ).
PrMTM-Îµc  = Îµc wc = (w1c , ..., w
k
c , ..., w
n
c )
PrMTM-c c = (Îµ1c , ..., Îµ
k
c , ..., Îµ
n
c ) wc = (w
1
c , ..., w
k
c , ..., w
n
c )
PrMTM-Îµ  = Îµ wc = (w1c , ..., w
k
c , ..., w
n
c )
TAB. 1 â€“ Les paramÃ¨tres des trois versions PrMTM :Probabilistic Mixed Topological Map
Classification probabilistes des donnÃ©es catÃ©gorielles et mixtes
4.2 PrMTM et lâ€™algorithme traditionnel des cartes topologiques
Il existe dans la littÃ©rature un modÃ¨le dÃ©terministe Ã  base de cartes topologiques dÃ©diÃ© aux
donnÃ©es binaires et mixtes utilisant une fonction de coÃ»t similaire Ã  lâ€™algorithme traditionnel de
Kohonen (MTM :Mixed Topological Map), (Kohonen, 2001; Lebbah et al., 2005). Etant donnÃ©
que pour des vecteurs Ã  composantes binaires la distance Euclidienne nâ€™est que la distance de
Hamming H, alors la distance Euclidienne pour les donnÃ©es mixtes peut-Ãªtre rÃ©Ã©crite comme
suit :
||xâˆ’wc||2 = ||xr[.] âˆ’wr[.]c ||2 +H(xb[.],wb[.]c ).
Utilisant cette expression, la fonction de coÃ»t de lâ€™algorithme classique de Kohonen peut Ãªtre
exprimÃ©e comme suit :
G(Ï†,W) =
âˆ‘
xiâˆˆA
âˆ‘
râˆˆC
KT (Î´(r, Ï†(xi)))||xr[.]i âˆ’wr[.]r ||2
+
âˆ‘
xiâˆˆA
âˆ‘
râˆˆC
KT (Î´(r, Ï†(xi)))H(x
b[.]
i ,w
b[.]
r )
(18)
oÃ¹ Ï† affecte chaque observation x Ã  une seule cellule de C. Le premier terme correspond Ã  la
fonction de coÃ»t classique utilisÃ©e par lâ€™algorithme batch de Kohonen, et le deuxiÃ¨me terme
reprÃ©sente la fonction de coÃ»t utilisÃ©e dans le modÃ¨le Binbatch dÃ©diÃ© uniquement aux donnÃ©es
binaires (Lebbah et al., 2000). La fonction de coÃ»t (18), est minimisÃ©e en utilisant un processus
itÃ©ratif Ã  deux Ã©tapes.
1. Lâ€™Ã©tape dâ€™affectation qui utilise la fonction suivante :
âˆ€x, Ï†(x) = argmin
c
(
||xr[.] âˆ’wr[.]c ||2 +H(xb[.],wb[.]c )
)
2. Lâ€™Ã©tape de quantification. Il est facile dâ€™observer que la minimisation de ces deux
termes sÃ©parÃ©ment nous permet de dÃ©finir :
â€“ La partie quantitative wr[.]c du vecteur rÃ©fÃ©rent wc qui est calculÃ©e comme suit :
wr[.]c =
âˆ‘
xiâˆˆA
K(Î´(c, Ï†(xi)))x
r[.]
iâˆ‘
xiâˆˆA
K(Î´(c, Ï†(xi)))
,
â€“ La partie binaire wb[.]c du vecteur rÃ©fÃ©rent wc qui est dÃ©finie comme le centre mÃ©dian
de la partie binaire des observations xb[.]i âˆˆ A pondÃ©rÃ©es par K(Î´(c, Ï†(xi))). Chaque
composante du vecteur wb[.]c = (w
b[1]
c , ..., w
b[k]
c , ..., w
b[m]
c ) est calculÃ©e de la maniÃ¨re
suivante :
wb[k]c =
ï£±ï£´ï£´ï£²ï£´ï£´ï£³
0 si
[âˆ‘
xiâˆˆAK(Î´(c, Ï†(xi)))(1âˆ’ x
b[k]
i )
]
â‰¥[âˆ‘
xiâˆˆAK(Î´(c, Ï†(xi)))x
b[k]
i
]
1 sinon
,
Rogovschi et al.
Lâ€™analyse de ces formules indique que la mise Ã  jour pour le centre mÃ©dian wb[.]c et la partie
rÃ©elle wr[.]c de notre modÃ¨le PrMTM coÃ¯ncide avec le modÃ¨le BinBatch (Lebbah et al., 2000)
et le modÃ¨le batch de Kohonen pour lesquels chaque observation x est pondÃ©rÃ©e proportion-
nellement par la fonction de voisinage ou une probabilitÃ© centrÃ©e sur le prototype gagnant.
Dans les deux modÃ¨les (PrMTM et MTM) nous minimisons lâ€™inertie des observations x dans
lâ€™espace rÃ©el et binaire (Rn Ã— Î²m). Dans le modÃ¨le probabiliste PrMTM, la dÃ©finition du ga-
gnant est diffÃ©rente de celle du modÃ¨le dÃ©terministe MTM. Lâ€™affectation est effectuÃ©e Ã  la fin
de lâ€™algorithme dâ€™apprentissage. Notons Ã©galement quâ€™il existe un lien fort entre le modÃ¨le
dÃ©terministe des cartes topologiques dÃ©diÃ©es aux donnÃ©es mixtes (MTM : Mixed Topologi-
cal Map), et le modÃ¨le de mÃ©lange PrMTM. A chaque pas dâ€™apprentissage nous calculons la
probabilitÃ© a posteriori p(c/x) qui est utilisÃ©e pour pondÃ©rer lâ€™observation x. Dans le modÃ¨le
MTM, lâ€™affectation est simplifiÃ©e en minimisant ||xr[.] âˆ’wr[.]c ||2 +H(xb[.],wb[.]c ).
Ainsi, si nous supposons que Îµ et Ïƒ reprÃ©sentent le mÃªme paramÃ¨tre pour toutes les cellules
et pour toutes les variables (binaires et quantitatives), et si les probabilitÃ©s a priori p(câˆ—) = 1K
sont Ã©gales, alors une distance faible implique une probabilitÃ© p(x/c) = p(xr[.]/c)Ã—p(xb[.]/c)
Ã©levÃ©e. Nous dÃ©duisons donc, que les probabilitÃ©s a posteriori p(c/x) et p(câˆ—/x) deviennent
Ã©levÃ©es elles aussi. Celles-ci sont Ã©crites de la maniÃ¨re suivante :
p(c/x) =
p(xr[.]/c)Ã— p(xb[.]/c)âˆ‘câˆ—âˆˆC KT (Î´(c, câˆ—))
KTcâˆ—p(x)
,
p(câˆ—/x) =
âˆ‘
câˆˆC K
T (Î´(c, câˆ—))p(xr[.]/c)Ã— p(xb[.]/c)
KTcâˆ—p(x)
,
Dans ces conditions, la maximisation de la fonction de coÃ»t QT (Î¸t, Î¸tâˆ’1) est la mÃªme que la
maximisation de la fonction de coÃ»t QT1 (Î¸
C, Î¸tâˆ’1) qui est dÃ©composÃ©e en deux termes (12)
et qui dÃ©pendent seulement de Î¸c = (wc, Îµ, Ïƒ), oÃ¹ la probabilitÃ© Îµ et lâ€™Ã©cart Ïƒ dÃ©pendent
seulement de la carte. Par consÃ©quent, maximiser QT1 (Î¸
C, Î¸tâˆ’1) par rapport Ã  Îµ et Ïƒ nÃ©cessite
le calcul de la dÃ©rivÃ©e simple duQb[.],T1 (w
b[.], Îµ, Î¸tâˆ’1) par rapport Ã  Îµ etQr[.],T1 (w
r[.], Ïƒc, Î¸
tâˆ’1)
par rapport Ã  Ïƒ. Par contre, maximiserQT1 (Î¸
C, Î¸tâˆ’1) par rapport Ã wc nÃ©cessite la minimisation
de la fonction de coÃ»t simplifiÃ©e G(w) qui est dÃ©finie par :
G(w) =
âˆ‘
câˆˆC
âˆ‘
xiâˆˆA
p(c/xi, Î¸tâˆ’1)H(x
b[.]
i ,w
b[.]
c )
+
âˆ‘
câˆˆC
âˆ‘
xiâˆˆA
p(c/xi, Î¸tâˆ’1)||xr[.]i âˆ’wr[.]c ||2
(19)
On en dÃ©duit ainsi que le modÃ¨le MTM a tendance Ã  rendre toutes les cellules Ã©quivalentes.
La dÃ©termination de la cellule responsable de la gÃ©nÃ©ration câˆ— avec une fonction dâ€™affectation,
nous permet de dÃ©duire que la fonction de coÃ»t G(Ï†,w) (18) nâ€™est quâ€™une simplification de
la fonction de coÃ»t G(w) (19). Il est clair que le modÃ¨le PrMTM probabiliste fournit plus
dâ€™information que le modÃ¨le dÃ©terministe MTM.
Classification probabilistes des donnÃ©es catÃ©gorielles et mixtes
5 ExpÃ©rimentations
Pour Ã©valuer la qualitÃ© de la classification, on adopte une approche dâ€™Ã©valuation qui utilise
des Ã©tiquettes externes. Ainsi, on utilise la puretÃ© de la classification pour mesurer les rÃ©sul-
tats de la classification. Câ€™est une approche frÃ©quente dans le domaine de la classification des
donnÃ©es. En gÃ©nÃ©ral, les rÃ©sultats de la classification sont Ã©valuÃ©s en se basant sur des connais-
sances externes sur la faÃ§on dont les classes doivent Ãªtre structurÃ©es. Cela peut impliquer de
calculer des critÃ¨res comme : la sÃ©paration, la densitÃ©, la connectivitÃ©, etc. La seule maniÃ¨re de
juger lâ€™utilitÃ© du rÃ©sultat du clustering est la validation indirecte, par laquelle les classes sont
appliquÃ©es Ã  la solution dâ€™un problÃ¨me et lâ€™exactitude est Ã©valuÃ©e par rapport Ã  lâ€™objectif des
connaissances externes. Cette procÃ©dure est dÃ©finie par (Jain et Dubes, 1988) comme "valida-
tion du clustering par des variables externes", et a Ã©tÃ© utilisÃ©e dans plusieurs travaux (Khan
et Kant, 2007; Andreopoulos et al., 2006). Nous pensons que cette approche est raisonnable,
si on ne veut pas juger les rÃ©sultats de la classification par certains indices de validitÃ© de la
classe, qui ne sont quâ€™un choix parmi certaines propriÃ©tÃ©s prÃ©fÃ©rÃ©es des classes (par exemple :
compact, ou bien sÃ©parÃ©s, ou connectÃ©s). Par consÃ©quent, pour adopter cette approche on a
besoin des jeux de donnÃ©es Ã©tiquetÃ©es, oÃ¹ la connaissance externe reprÃ©sente lâ€™information sur
la classe fournit par les Ã©tiquettes. Ainsi, si lâ€™algorithme PrMTM trouve des classes pertinentes
dans les donnÃ©es, cela sera reflÃ©tÃ© par la distribution des classes. Donc on utilise un vote ma-
joritaire pour les clusters et on les compare au comportement des mÃ©thodes dans la littÃ©rature.
La technique du vote majoritaire contient les Ã©tapes suivantes. Pour chaque cluster c âˆˆ C :
â€“ On compte le nombre dâ€™observations de chaque classe l (appelÃ© Ncl).
â€“ On compte le nombre total dâ€™observations affectÃ©es Ã  la cellule c (appelÃ© Nc).
â€“ On calcule la proportion dâ€™observation de chaque classe (appelÃ©e Scl = Ncl/Nc).
â€“ On attribue au cluster lâ€™Ã©tiquette de la classe la plus reprÃ©sentÃ©e (l = argmaxl(Scl).
Une cellule c pour laquelle Scl = 1 pour certaine classe Ã©tiquettÃ©e l est dâ€™habitude appelÃ©e un
cluster "pure", et une mesure de puretÃ© peut Ãªtre exprimÃ©e comme le pourcentge dâ€™Ã©lÃ©ments
de la classe affectÃ©e au cluster. Les rÃ©sultats expÃ©rimentaux sont ensuite exprimÃ©s comme une
fraction des observations qui interviennent dans les clusters et qui sont Ã©tiquetÃ©es avec une
classe diffÃ©rente de celle de lâ€™observation. Cette quantitÃ© est exprimÃ©e sous forme de pour-
centage et est appelÃ©e â€erreur de classificationâ€œ (indiquÃ©e comme Err% dans les rÃ©sultats).
Concernant les dimensions des cartes topologiques, nous avons utilisÃ© la dimension fournie
dâ€™une maniÃ¨re heuristique Ã  lâ€™aide de la "SOM toolbox".
5.1 Application aux bases binaires et catÃ©gorielles
5.1.1 La base Zoo
Câ€™est une base de donnÃ©es extraite du rÃ©pertoire UCI (Blake et Merz, 1998). On utilise ce
simple jeu de donnÃ©es pour montrer les bonnes performances de notre algorithme PrMTM. Ce
jeu de donnÃ©es contient lâ€™information sur 101 animaux dÃ©crits par 16 variables qualitatives :
dont 15 variables sont binaires et une est catÃ©gorielle avec 6 modalitÃ©s. Chaque animal est Ã©ti-
quettÃ© de 1 Ã  7 conformÃ©ment Ã  sa classe (son espÃ¨ce). Utilisant le codage disjonctif pour les
variables qualitatives avec 6 valeurs possibles, dÃ©finit dans le tableau 2, on obtient une matrice
binaire 101Ã— 21 (individusÃ— variables).
Rogovschi et al.
Afin de montrer lâ€™apport du modÃ¨le appliquÃ© aux donnÃ©es binaires, nous avons appris le
modÃ¨le globale sur une carte de dimensions 5 Ã— 5 cellules. Lâ€™algorithme dâ€™apprentissage
nous fournit dans ce cas les paramÃ¨tres de la distribution de Bernoulli pour chaque cellule,
wc = (w1c , w
2
c , ..., w
k
c , ..., w
21
c ) âˆˆ Î²n et un vecteur de probabilitÃ© c = (Îµ1c , Îµ2c , ..., Îµkc , ..., Îµ21c ).
ModalitÃ© Codage binaire
1 1 0 0 0 0 0
2 0 1 0 0 0 0
3 0 0 1 0 0 0
4 0 0 0 1 0 0
5 0 0 0 0 1 0
6 0 0 0 0 0 1
TAB. 2 â€“ Variable catÃ©gorielle avec 6 valeurs possibles. Chaque modalitÃ© est codÃ©e de la
mÃªme maniÃ¨re utilisant le codage disjonctif complet.
A la fin de la phase dâ€™apprentissage, chaque observation, qui correspond Ã  un animal, est affec-
tÃ©e Ã  la cellule avec la plus grande probabilitÃ© a posteriori p(c/x). Pour visualiser la cohÃ©rence
de la carte avec les Ã©tiquettes des animaux, la figure 1 nous montre le numÃ©ro de la classe qui
correspond Ã  chaque cellule aprÃ¨s lâ€™application du vote majoritaire pour chaque cellule. On
observe que les cellules qui ont la mÃªme classe sont proches lâ€™une de lâ€™autre sur la carte. On
voit aussi que les insectes qui ont lâ€™Ã©tiquette "6" sont affectÃ©s vers la partie droite en bas de la
carte. On peut faire la mÃªme analyse pour le reste des â€groupesâ€.
La figure 2 nous montre lâ€™Ã©volution de la fonction objective QT (Î¸t, Î¸tâˆ’1) sans calculer le
terme constant QT3 (Î¸
tâˆ’1) et variant T de Tmax = 2 Ã  Tmin = 0.5. On visualise aussi les
termesQT1 (Î¸
C, Î¸tâˆ’1) etQT2 (Î¸
Câˆ— , Î¸tâˆ’1). La maximisation de la fonction objective est Ã©vidente.
5.1.2 La base de donnÃ©es des chiffres manuscrits
Cette expÃ©rience concerne une base de donnÃ©es composÃ©es de chiffres manuscrits ("0"âˆ’"9")
extraits Ã  partir dâ€™une collection de cartes des services hollandais (Blake et Merz, 1998).
On a 200 exemples pour chaque caractÃ¨re, ainsi on a au total 2000 exemples. Chaque
exemple est une imagette binaire (pixel â€œnoirâ€œ ou â€blancâ€) de dimension 15 Ã— 16.
Lâ€™ensemble de donnÃ©es forme une matrice binaire de dimension 2000 Ã— 240. Chaque
variable qualitative est un pixel Ã  deux valeurs possibles "On=1" et "Off=0". Lâ€™algorithme
PrMTMâˆ’ associe Ã  chaque cellule uniquement une distribution de Bernoulli avec un
vecteur rÃ©fÃ©rent wc = (w1c , w
2
c , ..., w
k
c , ..., w
240
c ) âˆˆ Î²n et un vecteur de probabilitÃ©s
c = (Îµ1c , Îµ
2
c , ..., Îµ
k
c , ..., Îµ
240
c ).
La figure 3 nous montre les paramÃ¨tres estimÃ©s par notre modÃ¨le PrMTM. La figure 3.(a) nous
montre le vecteur prototype wc âˆˆ Î²n qui est reprÃ©sentÃ© comme une imagette de dimension
15Ã— 16. La figure 3.(b) nous montre le vecteur paramÃ¨tre c comme une imagette de la mÃªme
dimension 15 Ã— 16. Ainsi, chaque pixel dÃ©finit la probabilitÃ© Îµkc dâ€™Ãªtre diffÃ©rent de la variable
binaire wkc associÃ©e au vecteur prototype binaire wc reprÃ©sentÃ© dans la figure 3.(a). La nuance
Classification probabilistes des donnÃ©es catÃ©gorielles et mixtes
FIG. 1 â€“ 5Ã— 5 La carte PrMTMâˆ’. On montre les animaux associÃ©s Ã  la plus grande proba-
bilitÃ©. Le numÃ©ro entre parenthÃ¨ses indique lâ€™Ã©tiquette de la classe pour chaque cellule aprÃ¨s
lâ€™application de la rÃ¨gle du vote majoritaire
Rogovschi et al.
FIG. 2 â€“ Lâ€™Ã©volution de la fonction de coÃ»t QT (Î¸t, Î¸tâˆ’1) au cours de lâ€™apprentissage pour
le jeu de donnÃ©es Zoo. La ligne en pointillÃ©e reprÃ©sente la fonction QT1 (Î¸
C, Î¸tâˆ’1). La ligne
tiret-point reprÃ©sente la fonction QT2 (Î¸
Câˆ— , Î¸tâˆ’1)
de gris de chaque pixel est proportionnelle Ã  la probabilitÃ© dâ€™Ãªtre diffÃ©rent du prototype estimÃ©
wc. On constate que les composantes ou les probabilitÃ©s Îµkc , qui correspondent au contour de
lâ€™image, sont Ã©levÃ©es. En observant les deux figures Ã  la fois, on observe une organisation to-
pologique des prototypes assez claire sur toute la carte.
Pour Ã©tudier lâ€™influence du choix de la loi de Bernoulli, nous avons rÃ©alisÃ© un apprentissage
de lâ€™algorithme PrMTM-Îµc qui suppose que le paramÃ¨tre Îµc dÃ©pend uniquement dâ€™une cellule
c âˆˆ C. Au lieu dâ€™estimer le vecteur de probabilitÃ©s c, le modÃ¨le PrMTM calcule une proba-
bilitÃ© scalaire Îµc pour chaque cellule. La figure 4 nous montre les paramÃ¨tres estimÃ©s par le
modÃ¨le PrMTM-Îµ. La figure 4.(a) montre le vecteur prototype wc âˆˆ Î²n qui est reprÃ©sentÃ©
comme une imagette de dimension 15 Ã— 16. On observe une organisation topologique des
prototypes assez nette. La figure 4.(b) reprÃ©sente le paramÃ¨tre Îµc estimÃ© pour chaque cellule
c âˆˆ C. Ainsi, la nuance de gris de chaque cellule est proportionnelle Ã  la probabilitÃ© Îµc dâ€™Ãªtre
diffÃ©rente du vecteur prototype binaire wc reprÃ©sentÃ© dans la figure 4.(a).
Evidemment, on constate que le modÃ¨le gÃ©nÃ©ral PrMTMâˆ’ prÃ©sentÃ© dans la figure 3 fournit
plus dâ€™informations que le modÃ¨le rÃ©duit PrMTM-Îµc (figure 4). Le modÃ¨le PrMTM-Îµc est in-
tÃ©ressant quand on manipule de grandes bases de donnÃ©es.
Classification probabilistes des donnÃ©es catÃ©gorielles et mixtes
(a)
(b)
FIG. 3 â€“ La carte PrMTMâˆ’ de dimension 16Ã—16. (a). Chaque image est le vecteur prototype
wc = (w1c , w
2
c , ...w
k
c , ..., w
240
c ) qui est un vecteur binaire. Les images des prototypes sont bien
organisÃ©es. Le pixel blanc indique "0" et le pixel noir indique "1". (b).Chaque image reprÃ©sente
un vecteur de probabilitÃ© c = (Îµ1c , Îµ
2
c , ..., Îµ
k
c , ..., Îµ
240
c ).
Rogovschi et al.
(a)
(b)
FIG. 4 â€“ La carte de PrMTM-Îµ de dimension 16 Ã— 16 . Dans la figure (a) chaque image
reprÃ©sentÃ©e est le vecteur prototype wc = (w1c , w
2
c , ...w
k
c , ..., w
240
c ) qui est un vecteur binaire.
Les prototypes des images sont bien organisÃ©s. Le pixel blanc indique "0" et le pixel noir
indique "1". Dans la figure (b) chaque image reprÃ©sentÃ©e est la probabilitÃ© Îµc. Le niveau de
gris de chaque cellule est proportionnel Ã  la probabilitÃ© dâ€™Ãªtre diffÃ©rent du prototype estimÃ©
wc (figure(b))
Classification probabilistes des donnÃ©es catÃ©gorielles et mixtes
5.1.3 Discussions
Avec le modÃ¨le que lâ€™on propose, on peut obtenir diffÃ©rents niveaux de pertinences. En
fonction de lâ€™hypothÃ¨se sur la probabilitÃ© Îµ on peut avoir trois cas :
1. La probabilitÃ© Îµ dÃ©pend de la cellule c et de la variable j : c = (Îµ1c , Îµ
2
c , ..., Îµ
j
c, ..., Îµ
n
c )
figure 5(a)(cas gÃ©nÃ©ral)
2. La probabilitÃ©  dÃ©pend dâ€™une cellule seulement  = Îµc, figure 5(b)
3. La probabilitÃ© Îµ dÃ©pend seulement de la carte C (une seule valeur pour toute la carte),
figure 5(c)
Nous observons que les valeurs des probabilitÃ©s permettent de dÃ©tecter les variables perti-
nentes. On arrive visuellement Ã  reconnaÃ®tre les chiffres. Par consÃ©quent, il est possible dâ€™uti-
liser ces valeurs pour caractÃ©riser les groupes. Dans le deuxiÃ¨me cas, il nâ€™est pas possible de
caractÃ©riser la forme des chiffres, mais nous pouvons caractÃ©riser les groupes. Ainsi, il est pos-
sible de sÃ©lectionner des groupes dâ€™individus et de rÃ©aliser un Ã©chantillonnage optimisÃ©.
Dans le troisiÃ¨me cas, une seule valeur rÃ©elle est estimÃ©e pour toute la carte. Afin de mon-
trer lâ€™intÃ©rÃªt de ce type de modÃ¨le nous avons appris plusieurs cartes avec des initialisations
diffÃ©rentes et par la suite nous avons calculÃ© la puretÃ© associÃ©e Ã  chacune de ces cartes. La
figure 5(c) indique la variation de la puretÃ© selon la probabilitÃ© Îµ estimÃ©e par le modÃ¨le. Plus
la probabilitÃ© est faible plus le modÃ¨le est bon. Nous observons que les modÃ¨les estimant des
probabilitÃ©s supÃ©rieures Ã  0.5 fournissent des puretÃ©s faibles. A lâ€™opposÃ©, ceux estimant des
probabilitÃ©s infÃ©rieures Ã  0.5 correspondent Ã  des puretÃ©s fortes. Il convient donc de choisir
comme meilleur modÃ¨le celui qui est associÃ© Ã  la valeur de probabilitÃ© la plus faible. Ce type
dâ€™application montre quâ€™il est possible dâ€™utiliser ce principe pour faire de la sÃ©lection de mo-
dÃ¨les.
5.1.4 Autres bases de donnÃ©es
Nous avons comparÃ© notre modÃ¨le PrMTM avec la version classique des cartes topologiques
binaires. Nous avons utilisÃ© deux autres bases :
La maladie du cancer du sein (Wisconsin Breast Cancer Data)
Ce jeu de donnÃ©es contient 699 observations avec 9 variables. Chaque observation est Ã©tiquetÃ©e
bÃ©nigne (458 ou 65.5%) ou maligne (241 ou 34.5%). Dans notre cas, toutes les variables sont
considÃ©rÃ©es catÃ©gorielles avec valeurs entre 1, 2, ..., 10 et codÃ©es en binaire (Annexe A).
La base de donnÃ©es â€œVoteâ€œ (Congressional Vote Data)
Câ€™est un jeu de donnÃ©es qui contient 435 observations, dont 168 appartiennent Ã  une classe et
267 appartiennent Ã  la deuxiÃ¨me classe.
Le tableau 3 indique le taux de lâ€™erreur de classification obtenu avec les deux mÃ©thodes. Nous
pouvons observer que les rÃ©sultats utilisant le modÃ¨le BinBatch et PrMTMâˆ’ sont gÃ©nÃ©ra-
lement similaires, bien quâ€™ils soient meilleurs avec PrMTMâˆ’. Comme nous lâ€™avons signalÃ©
Rogovschi et al.
(a)
(b)
(c)
FIG. 5 â€“ Dans la figure (a) chaque image reprÃ©sente un vecteur de probabilitÃ©. Dans la figure
(b) on voit la probabilitÃ© par cellule, sur la figure (c) on voit la probabilitÃ© pour toute la carte.
Classification probabilistes des donnÃ©es catÃ©gorielles et mixtes
dans les sections prÃ©cÃ©dentes le modÃ¨le PrMTM fournit plus dâ€™informations que le modÃ¨le
dÃ©terministe BinBatch (qui reprÃ©sente les cartes classiques utilisant la distance de Hamming).
Le jeu de donnÃ©es / Err BinBatch PrMTMâˆ’
Wisconsin-B-C 3.87% 2.43%
Zoo 2.97% 1.98%
Congressional vote 5.91% 5.77%
TAB. 3 â€“ La comparaison des perfomances de classification de PrMTMâˆ’, et BinBatch.
5.2 Application aux donnÃ©es mixtes
5.2.1 La base de donnÃ©es "Cleve"
Dans cette partie, nous illustrons la convergence de lâ€™algorithme PrMTM sur la base mÃ©dicale
cleve. Cette base a Ã©tÃ© fournie par le Dr. Detrano en 1988. Elle dÃ©crit la maladie du coeur trai-
tÃ©e dans la clinique de Cleveland. Lâ€™ensemble des donnÃ©es contient 303 patients oÃ¹ chacun est
dÃ©crit par 6 variables quantitatives et 7 qualitatives. Les patients sont classÃ©s en deux classes,
reprÃ©sentant la prÃ©sence de la maladie ou son absence. En utilisant un codage disjonctif binaire
on obtient 17 variables binaires.
Lâ€™apprentissage dâ€™une carte de dimension 13Ã— 7, fournit pour chaque cellule des vecteurs rÃ©-
fÃ©rents avec deux parties (wr[.]c ,w
b[.]
c ) associÃ©es respectivement Ã  lâ€™Ã©cart-type Ïƒc pour la partie
quantitative, et la probabilitÃ© Îµc dâ€™Ãªtre diffÃ©rent du prototype pour la partie binaire. Notre mo-
dÃ¨le PrMTM nous a permis de disposer des mÃªmes visualisations que les cartes topologiques
traditionnelles. Nous rappelons que le modÃ¨le PrMTM utilise une affectation probabiliste pour
projeter les observations sur la carte. La figure 6 illustre la variation de la partie quantitative
correspondant Ã  toutes les observations xr[.] captÃ©es par chaque cellule. On observe une auto-
organisation de la partie quantitative malgrÃ© la prÃ©sence de la partie binaire lors de la phase
dâ€™apprentissage.
La figure 7 affiche la probabilitÃ© Îµc dâ€™Ãªtre diffÃ©rent de la partie binaire wb[.] indiquÃ©e par
la partie binaire (figure 8). La nuance de gris de chaque prototype est proportionnelle Ã  la
probabilitÃ© dâ€™Ãªtre diffÃ©rent du prototype binaire estimÃ©. Cette information est trÃ¨s importante
pour lâ€™interprÃ©tation des rÃ©sultats. La probabilitÃ© Îµ indique la confiance quâ€™on peut faire aux
variables binaires et par consÃ©quent aux variables qualitatives. Lorsque la probabilitÃ© est trÃ¨s
forte, lâ€™expert peut dÃ©cider dâ€™ignorer lâ€™interprÃ©tation des variables binaires correspondantes.
5.2.2 Autres donnÃ©es rÃ©elles
Dans cette section nous montrons les apports de notre modÃ¨le relativement Ã  lâ€™algorithme
dÃ©terministe de classification topologique MTM. Pour la suite on utilise deux autres bases
obtenues du rÃ©pertoire UCI (Blake et Merz, 1998). Le tableau 4, fournit une courte description
des bases de donnÃ©es utilisÃ©es.
Rogovschi et al.
FIG. 6 â€“ La carte PrMTM pour la base de donnÃ©es Cleve. Chaque cellule indique la partie
quantitative des observations captÃ©es par chaque cellule.
Base de donnÃ©es dim. qualit dim. quantitative # obs # classes
Cleve 7 6 303 2
Credit 6 9 666 2
Thyroid 12 7 3163 2
TAB. 4 â€“ Jeux de donnÃ©es utilisÃ©es pour lâ€™Ã©valuation. # obs : nombre dâ€™observation ; #
classes : nombre de classes.
Nous avons comparÃ© notre modÃ¨le PrMTM avec lâ€™algorithme classique dÃ©terministe MTM.
Dans ces expÃ©rimentations, la comparaison des diffÃ©rents rÃ©sultats est mesurÃ©e Ã  lâ€™aide du taux
de puretÃ© en utilisant lâ€™Ã©tiquette connue de chaque observation. La comparaison est rÃ©alisÃ©e
en calculant la moyenne des puretÃ©s sur 50 expÃ©riences. Le tableau 5 montre les performances
atteintes par notre modÃ¨le PrMTM et part le modÃ¨le MTM. Nous observons une amÃ©lioration
des puretÃ©s sur toutes les bases.
En examinant le tableau 5, nous observons par exemple, pour la base Cleve une amÃ©lioration
de la puretÃ© de 86.78% Ã  87.25% en rÃ©duisant lâ€™Ã©cart-type de 2.62 Ã  1.95. Pour la base de don-
nÃ©es Credit nous observons des rÃ©sultats Ã©quivalents, mais en rÃ©duisant lâ€™Ã©cart-type de 2.46 Ã 
1.96. En ce qui concerne la base de donnÃ©es Thyroid on observe une amÃ©lioration de puretÃ©
avec une lÃ©gÃ¨re augmentation de lâ€™Ã©cart-type.
Classification probabilistes des donnÃ©es catÃ©gorielles et mixtes
FIG. 7 â€“ La carte PrMTM pour les donnÃ©es Cleve de dimension 13 Ã— 7. La carte indique la
probabilitÃ© Îµc (valeur par cellule). Le niveau de gris de chaque cellule est proportionnel Ã  la
probabilitÃ© dâ€™Ãªtre diffÃ©rent du prototype binaire estimÃ© wb[.]c .
PuretÃ© : % MTM PrMTM
Cleve (13Ã— 7) 86.78Â± 2.62 87.25Â± 1.95
Credit (13Ã— 10) 81.60Â± 2.46 81.93Â± 1.96
Thyroid (21Ã— 14) 95.85Â± 1.06 96.22Â± 1.09
TAB. 5 â€“ Comparaison entre MTM et PrMTM utilisant lâ€™indice de puretÃ© (moyenneÂ± Ã©cart-
type sur 50 expÃ©rimentations). MTM : Carte topologique classique dÃ©diÃ©es aux donnÃ©es mixtes.
PrMTM : carte topologique utilisant la loi Gaussienne et de Bernoulli
Pour valider notre approche, nous avons utilisÃ© la validation croisÃ©e. Par consÃ©quent, nous
avons divisÃ© les bases en 3 sous-ensembles (un tiers de la base est utilisÃ© pour la validation
et deux tiers pour lâ€™apprentissage). Ainsi, 15 expÃ©riences sont rÃ©alisÃ©es pour chaque base. Le
tableau 6 indique la moyenne calculÃ©e avec 15 expÃ©riences. Pour le mÃªme objectif de compa-
raison, nous avons enrichi le modÃ¨le PrMTM avec lâ€™estimation dâ€™un vecteur de probabilitÃ©s par
cellule au lieu dâ€™une valeur par cellule. Ce modÃ¨le fait rÃ©fÃ©rence au modÃ¨le modÃ¨le PrMTM-c
dÃ©diÃ© aux donnÃ©es binaires oÃ¹ la probabilitÃ© dÃ©pend Ã  la fois de la cellule et de la variable,
c = (Îµ1c , ..., Îµ
k
c , ..., Îµ
n
c ). Nous appelons par la suite ce modÃ¨le PrMTM-c.
Nous observons clairement que le modÃ¨le PrMTM fournit de meilleurs rÃ©sultats que le modÃ¨le
Rogovschi et al.
FIG. 8 â€“ La carte PrMTM pour les donnÃ©es Cleve de dimension 13 Ã— 7. La carte indique les
profils de la partie binaire ("1/0"qualitative).
Taux de classification : % MTM PrMTM-c PrMTM
Cleve (13Ã— 7) 72.78 75.26 74.93
Credit (13Ã— 10) 62.76 64.58 63.34
Thyroid (21Ã— 14) 82.75 85.41 84.69
TAB. 6 â€“ Comparaison entre MTM, PrMTM et PrMTM-c utilisant la technique de la valida-
tion croisÃ©e. On indique le taux de classification pour chaque base. MTM : Carte topologique
classique dÃ©diÃ©es aux donnÃ©es mixtes. PrMTM : carte topologique utilisant la loi Gaussienne
et de Bernoulli (oÃ¹ la probabilitÃ© est calculÃ©e pour chaque cellule de la carte). PrMTM-c :
carte topologique utilisant la loi Gaussienne et de Bernoulli (oÃ¹ le vecteur probabilitÃ© c dÃ©-
pend de la cellule c et de la variable, c = (Îµ1c , ..., Îµ
k
c , ..., Îµ
n
c ))
dÃ©terministe. Ceci est rassurant puisque le modÃ¨le PrMTM est plus riche en information. Il est
clair aussi que lorsquâ€™on estime un vecteur de probabilitÃ© pour la partie binaire "PrMTM-c",
les performances augmentent. Comme nous lâ€™avons signalÃ© dans les sections prÃ©cÃ©dentes, le
modÃ¨le PrMTM fournit plus dâ€™informations que le modÃ¨le dÃ©terministe MTM. Pour le modÃ¨le
proposÃ©, la probabilitÃ© Îµc et lâ€™Ã©cart-type Ïƒc peuvent Ãªtre utilisÃ©s pour la sÃ©lection des modÃ¨les.
Supposant que la probabilitÃ© et lâ€™Ã©cart-type dÃ©pendent des prototypes et des variables, on es-
time pour les deux distributions, le vecteur dâ€™Ã©cart-type Ïƒc = (Ïƒ1c , Ïƒ
2
c , ..., Ïƒ
n
c ) et le vecteur
de probabilitÃ©s c = (Îµ1c , Îµ
2
c , ..., Îµ
m
c ). Ainsi ce modÃ¨le peut-Ãªtre utilisÃ© pour la sÃ©lection non-
Classification probabilistes des donnÃ©es catÃ©gorielles et mixtes
supervisÃ©e des variables. Il nâ€™est pas Ã©vident de comparer notre modÃ¨le avec un algorithme qui
nâ€™utilise pas une architecture similaire. Nous rappelons que le modÃ¨le PrMTM, basÃ© sur lâ€™ar-
chitecture SOM, fournit plus de clusters que les modÃ¨les hiÃ©rarchiques ou le K-means dÃ©diÃ©
aux donnÃ©es mixtes (Ahmad et Dey, 2007).
6 Conclusion
Les travaux prÃ©sentÃ©s dans cet article nous ont permis dâ€™analyser les propriÃ©tÃ©s mathÃ©ma-
tiques de lâ€™algorithme des cartes auto-organisatrices dans un cadre probabiliste. Tenir compte
de la distribution des donnÃ©es implique lâ€™intÃ©gration de plus dâ€™informations dans le modÃ¨le des
cartes topologiques selon le type de donnÃ©es et donc lâ€™amÃ©lioration des performances. Nous
avons proposÃ© un nouveau modÃ¨le dâ€™apprentissage qui tient compte de la distribution locale
des donnÃ©es. Le modÃ¨le, PrMTM (Probabilistic Mixed Topological Map) dÃ©diÃ© aux donnÃ©es
mixtes, utilise le formalisme probabiliste des cartes topologiques et associe simultanÃ©ment Ã 
chaque cellule de la carte la distribution Gaussienne et la distribution de Bernoulli. Dans le cas
de la distribution de Bernoulli, chaque cellule est caractÃ©risÃ©e par un prototype avec le mÃªme
codage binaire de lâ€™espace dâ€™entrÃ©e et par la probabilitÃ© dâ€™Ãªtre diffÃ©rent de ce prototype. Cette
approche PrMTM dÃ©diÃ©e aux donnÃ©es catÃ©gorielles et mixtes (quantitatives et binaires) utilise
lâ€™algorithme EM pour maximiser la vraisemblance de donnÃ©es afin dâ€™estimer les paramÃ¨tres
dâ€™un modÃ¨le de mÃ©lange des lois de Bernoulli et Gausiennes. Cet algorithme a lâ€™avantage de
fournir des prototypes qui sont de mÃªme nature que les donnÃ©es initiales. Nous avons montrÃ©
que lâ€™algorithme PrMTM nous fournit diffÃ©rentes informations qui peuvent Ãªtre utilisÃ©es dans
des applications pratiques. La complexitÃ© de notre algorithme dâ€™apprentissage est deO(NK2).
Il est K fois plus lent que lâ€™algorithme MTM et peut-Ãªtre plus lent pour de grandes bases de
donnÃ©es. Toutefois, en limitant le voisinage au cours de lâ€™apprentissage, nous pouvons obtenir
un faible coÃ»t de calcul. Une autre faÃ§on de rÃ©duire le coÃ»t de calcul est dâ€™introduire une Ã©tape
dâ€™affectation au lieu dâ€™attribuer les observations Ã  la fin de lâ€™apprentissage (Celeux et Govaert,
1992).
Plusieurs perspectives de dÃ©veloppement peuvent Ãªtre envisagÃ©es comme Ã©ventuellement
lâ€™extension du modÃ¨le PrMTM Ã  la classification croisÃ©e en utilisant le formalisme probabi-
liste des cartes topologiques. Nous pouvons envisager un critÃ¨re entre groupes dâ€™observations
et groupes de variables qui dÃ©coule de la fonction de vraisemblance.
RÃ©fÃ©rences
Ahmad, A. et L. Dey (2007). A k-mean clustering algorithm for mixed numeric and categorical
data. Data Knowl. Eng. 63(2), 503â€“527.
Andreopoulos, B., A. An, et X. Wang (2006). Bi-level clustering of mixed categorical and
numerical biomedical data. International Journal of Data Mining and Bioinformatics 1(1),
19 â€“ 56.
Anouar, F. (1996). ModÃ©lisation probabiliste des auto-organisÃ©es : Application en classification
et en rÃ©gression. thÃ¨se de doctorat soutenue au conservatoires national des arts et mÃ©tiers.
Rogovschi et al.
Anouar, F., F. Badran, et S. Thiria (1997). Self-organizing map, a probabilistic approach. In
Proceedings of WSOMâ€™97-Workshop on Self-Organizing Maps, Espoo, Finland June 4-6,
pp. 339â€“344.
Aupetit, M. (2005). Learning topology with the generative gaussian graph and the em algo-
rithm. In NIPS, pp. 592â€“598.
Bishop, C. M. (1995). Neural networks for pattern recognition. Clarrendon Press, Oxford.
Bishop, C. M., M. SvensÃ©n, et C. K. I.Williams (1998). Gtm : The generative topographic
mapping. Neural Comput 10(1), 215â€“234.
Blake, C. et C. Merz (1998). Uci repository of machine learning databases. technical report.
Celeux, G. et G. Govaert (1992). A classification em algorithm for clustering and two stochas-
tic versions. Comput. Stat. Data Anal. 14(3), 315â€“332.
Dempster, A., N. Laird, et D. Rubin (1977). Maximum likelihood from incomplete data via
the em algorithm. Roy. Statist. Soc 39(1), 1â€“38.
Girolami, M. (2001). The topographic organisation and visualisation of binary data
using mutivariate-bernoulli latent variable models. I.E.E.E Transactions on Neural Net-
works 12(6), 1367â€“1374.
Graepel, T., M. Burger, et K. Obermayer (1998). Self-organizing maps : generalizations and
new optimization techniques. Neurocomputing 21, 173â€“190.
Heskes, T. (2001). Self-organizing maps, vector quantization, and mixture modeling. IEEE
Trans. Neural Networks 12, 1299â€“1305.
Jain, A. K. et R. C. Dubes (1988). Algorithms for clustering data. Upper Saddle River, NJ,
USA : Prentice-Hall, Inc.
Kaban, A. et M. Girolami (2001). A combined latent class and trait model for the analysis and
visualization of discrete data. IEEE Trans. Pattern Anal. Mach. Intell 23, 859â€“872.
Khan, S. S. et S. Kant (2007). Computation of initial modes for k-modes clustering algorithm
using evidence accumulation. In IJCAI, pp. 2784â€“2789.
Kohonen, T. (2001). Self-organizing Maps. Springer Berlin.
Lebbah, M. (2003). Carte topologique pour donnÃ©es qualitatives : application Ã  la recon-
naissance automatique de la densitÃ© du trafic routier. ThÃ©se de doctorat en Informatique,
UniversitÃ© de Versailles Saint-Quentin en Yvelines.
Lebbah, M., A. Chazottes, F. Badran, et S. Thiria (2005). Mixed topological map. In ESANN,
pp. 357â€“362.
Lebbah, M., S. Thiria, et F. Badran (2000). Topological map for binary data. In Proceedings
European Symposium on Artificial Neural Networks-ESANN 2000, Bruges, April 26-27-28,
pp. 267â€“272.
Luttrel, S. P. (1994). A bayesian ananlysis of self-organizing maps. Neural Computing 6, 767
â€“ 794.
McLachlan, G. et T. Krishman (1997). The EM algorithm and Extensions. Wiley, New York.
Priam, R. et M. Nadif (2006). Carte auto-organisatrice probabiliste sur donnÃ©es binaires. In
EGC, pp. 445â€“456.
Classification probabilistes des donnÃ©es catÃ©gorielles et mixtes
Priam, R., M. Nadif, et G. Govaert (2008). Binary block gtm : Carte auto-organisatrice pro-
babiliste pour les grands tableaux binaires. In Extraction et gestion des connaissances
(EGCâ€™2008), Actes des 8Ã¨mes journÃ©es Extraction et Gestion des Connaissances, Re-
vue des Nouvelles Technologies de lâ€™Information, Sophia-Antipolis, Franceâ€ pp. 265â€“272.
CÃ©paduÃ¨s-Ã‰ditions.
Thiria, S., Y. Lechevallier, O. Gascuel, et S. Canu (1997). Statistique et mÃ©thodes neuronales.
Verbeek, J., N. Vlassis, et B. KrÃ¶se (2005). Self-organizing mixture models. Neurocompu-
ting 63, 99â€“123.
Summary
This paper introduces a method based on probabilistic self-organizing maps dedicated for to-
pographic clustering, analysis and visualization of categorical and mixed data. For each kind
of data we propose a probabilistic formalism in which cells are represented by a mixture model
of Bernoulli distribution in the case of binary data and by a mixture model of Bernoulli and
Gaussian laws in the case of mixed data. Each cell is characterized by a prototype with the
same binary coding as used in the data space and the probability of being different from this
prototype. The learning algorithm, PrMTM, that we propose is an application of the EM stan-
dard algorithm. We illustrate the power of this method with several binary and mixed data sets
taken from a public data set repository. The results show a good quality of the topological
ordering and homogenous clustering.
