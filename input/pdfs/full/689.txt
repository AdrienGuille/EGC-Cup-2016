Mod√®le de Langue √† base de Concepts pour la Recherche 
d‚ÄôInformation
 
Lynda SAID L‚ÄôHADJ*, Mohand BOUGHANEM** 
 
*Ecole Doctorale STIC, Ecole nationale Sup√©rieure d‚ÄôInformatique ESI, Alg√©rie  
l_said_lhadj@esi.dz 
**Laboratoire IRIT, Universit√© Paul Sabatier 
118 route de Narbonne 31062 Toulouse Cedex 09, France 
bougha@irit.fr  
 
R√©sum√©. La majorit√© des mod√®les de langue appliqu√©s √† la recherche 
d‚Äôinformation repose sur l‚Äôhypoth√®se d‚Äôind√©pendance des mots.                              
Plus pr√©cis√©ment, ces mod√®les sont estim√©s √† partir des mots simples 
apparaissant dans les documents sans consid√©rer les √©ventuelles relations 
s√©mantiques et conceptuelles. Pour pallier ce probl√®me, deux grandes 
approches ont √©t√© explor√©es : la premi√®re int√®gre des d√©pendances d‚Äôordre 
surfacique entre les mots, et la seconde repose sur l‚Äôutilisation des ressources 
s√©mantiques pour capturer les d√©pendances entre les mots. Le mod√®le de 
langue que nous pr√©sentons dans cet article s‚Äôinscrit dans la seconde approche. 
Nous proposons d‚Äôint√©grer les d√©pendances entre les mots en repr√©sentant les  
documents et les requ√™tes par les concepts. 
1 Introduction
Les mod√®les de langue ont acquis une grande popularit√© en Recherche d‚ÄôInformation (RI) 
√©tant donn√© la solidit√© de leur fondement math√©matique Ponte et Croft (1998). Ces mod√®les 
ne mod√©lisent pas directement la notion de pertinence. Cette derni√®re est vue comme                      
la probabilit√© conditionnelle (P(QD)) que la requ√™te Q soit g√©n√©r√©e par le mod√®le de langue 
du document (D). P(QD) est  estim√©e sous l‚Äôhypoth√®se d‚Äôind√©pendance des mots qui 
simplifie le calcul math√©matique. Cependant, elle pose un probl√®me majeur li√©                      
√† la repr√©sentation  des documents (requ√™tes) comme des sacs de mots d√©nu√©s de s√©mantique.  
Pour pallier ce probl√®me, une nouvelle g√©n√©ration de mod√®les de langue qui s‚Äôinscrit                
√† l‚Äôintersection des mod√®les de langue et de la recherche s√©mantique d‚Äôinformation a √©t√© 
d√©velopp√©e Cao et al. (2005), Srikanth et Srihari (2002, 2003). Dans cette intersection, deux 
grandes approches peuvent √™tre distingu√©es : l‚Äôapproche statistique surfacique qui prend en 
compte des d√©pendances surfaciques entre les mots et l‚Äôapproche s√©mantique bas√©e sur des 
ressources s√©mantiques (ontologies, th√©saurus) pour identifier les sens des mots. 
Le mod√®le de langue pr√©sent√© dans cet article s‚Äôinscrit dans la seconde approche. Nous 
proposons de capturer les d√©pendances entre les mots par l‚Äôidentification des concepts 
auxquels renvoient ces mots. M√™me si l‚Äôapproche conceptuelle souffre du probl√®me                      
de silence1, nous pensons que la d√©finition d‚Äôun mod√®le de langue mixte combinant                     
les concepts identifi√©s dans l‚Äôontologie et les concepts non identifi√©s permet de r√©soudre             
ce probl√®me.  
                                                          
1 d√ª √† la non disponibilit√© de ressources conceptuelles compl√®tes et g√©n√©rales. 
RNTI-E-19- 91 -
Mod√®le de langue √† base de concepts pour la recherche d‚Äôinformation 
Le reste du papier est organis√© comme suit : Nous pr√©sentons un bref √©tat de l‚Äôart sur                   
les mod√®les de langue s√©mantiques dans la section 2. La section 3 est consacr√©e √† la 
pr√©sentation du mod√®le propos√©. Puis, nous d√©roulons un exemple dans la section 4. Enfin, 
dans la section 5, nous terminons ce papier avec une synth√®se du travail pr√©sent√©.    
2 Etat de l‚Äôart 
La pertinence d‚Äôun document face √† une requ√™te est en rapport avec la probabilit√© que             
la requ√™te Q, vue comme une suite de mots t1t2‚Ä¶tn, puisse √™tre g√©n√©r√©e par le mod√®le de 
langue du document. Le score de pertinence est alors donn√© par : 
Score(Q,D)=P(Q|MD)2=P(t1t2‚Ä¶tnMD)                                                                                 (1) 
Pour estimer la probabilit√© de (1), il faut que les ti soient ind√©pendants, ainsi :    	 
    )                                                                                                      (2)                      
L‚Äôhypoth√®se d‚Äôind√©pendance des mots pose deux probl√®mes majeurs : le premier est celui 
des donn√©es √©parses, c‚Äôest-√†-dire, si un mot ti est absent dans le document, P(QD) est alors 
nulle m√™me si les autres tj,ji sont pr√©sents. Ce probl√®me a √©t√© r√©solu par les techniques                 
de lissage3 Zhai et al. (2001). Le second probl√®me est la repr√©sentation en sac de mots  qui 
ne permet pas la prise en compte de deux ph√©nom√®nes tr√®s importants en RI √† savoir                      
la polys√©mie et la synonymie. Pour le r√©soudre, la plupart des travaux propos√©s jusque                   
l√† a utilis√© les techniques de lissage (le lissage s√©mantique) afin d‚Äôincorporer les sens                  
des mots ainsi que les liens entre ces mots dans les mod√®les de langue. Ces travaux sont 
class√©s en deux cat√©gories d‚Äôapproches Cao et al. (2005): L‚Äôapproche statistique ou 
surfacique  et l‚Äôapproche guid√©e par les ressources s√©mantiques.
L‚Äôapproche surfacique tente d‚Äôint√©grer les relations entre les mots selon des 
consid√©rations statistiques, par exemple les cooccurrences. Le mod√®le de translation 
statistique de Berger et Lafferty (1999) fut l‚Äôun des premiers travaux dans cette direction. 
Gao et al. (2004), de leur cot√©, consid√®rent les d√©pendances entre les mots comme une 
variable cach√©e L, repr√©sent√©e par un graphe acyclique non orient√©, pour mod√©liser                      
les d√©pendances entre les mots. Srikanth et Srihari (2002) ont propos√© un mod√®le bi-termes 
o√π ils ignorent la contrainte d‚Äôadjacence et de l‚Äôordre des mots impos√©e dans les mod√®les            
bi-grammes. Enfin, Srikanth et Srihari (2003) pr√©sentent un mod√®le uni-gramme de concepts 
(des s√©quences de mots) identifi√©s avec un parseur syntaxique.                         
L‚Äôapproche guid√©e par les ressources s√©mantiques se base sur des liens s√©mantiques 
extraits de ressources s√©mantiques comme les ontologies. Cao et al. (2005) ont propos√© une  
approche qui combine le mod√®le d‚Äôind√©pendance (uni-gramme) avec le mod√®le                      
de d√©pendance des mots en exploitant les techniques de lissage. Ces d√©pendances sont                     
de deux  types: statistique (cooccurrence) et s√©mantique (relations entre mots simples                  
de WordNet). Dans la m√™me direction, Bao et al. (2006) ont propos√© un mod√®le de langue 
uni-gramme liss√© avec un mod√®le uni-gramme de sens de ces mots identifi√©s par un syst√®me                  
de d√©sambigu√Øsation bas√© sur WordNet.  
Les r√©sultats des deux approches sont meilleurs que le mod√®le de langue uni-gramme. 
Cependant, l‚Äôapproche surfacique engendre beaucoup de bruit et donc elle n√©cessite un 
filtrage linguistique voire s√©mantique. Nous pensons √©galement que l‚Äôint√©gration de relations 
                                                          
2 On √©crit P(Q|D) pour repr√©senter la probabilit√©  P(Q|MD) o√π MD est le mod√®le de document. 
3 Attribuer une probabilit√© non nulle aux mots de la requ√™te absents dans le document.   
RNTI-E-19 - 92 -
L. SaidL‚Äôhadj et M. Boughanem 
(surfaciques ou s√©mantiques) entre mots simples ou la simple d√©sambig√ºisation de ces mots 
ne suffit pas pour capturer le contenu s√©mantique implicite des documents et des requ√™tes. 
Nous pensons de ce fait qu‚Äôun concept, correspondant par exemple √† une entr√©e d‚Äôune 
ontologie, est plus pr√©cis qu‚Äôun mot isol√© ou un sens isol√©.  
3 Mod√®le propos√© 
Le mod√®le que nous proposons se base sur les concepts. Plus pr√©cis√©ment, tout 
document (respectivement requ√™te) est projet√© sur une ontologie par exemple WordNet, 
Nous utilisons √† cet effet l‚Äôalgorithme de Baziz (2005)4 pour la d√©tection des concepts. Ainsi, 
les termes  ayant une entr√©e dans l‚Äôontologie sont pris comme √©l√©ments du document qui 
permettent la construction de l‚Äôarborescence du document (de la requ√™te). Mais, 
contrairement √† Baziz (2005), nous proposons de garder les termes non reconnus dans 
l‚Äôontologie dans le descripteur, car il peut arriver que ces termes renvoient √† des concepts 
importants (cas des noms propres ou des n√©ologismes).  
Nous consid√©rons la requ√™te (Document) comme des  sacs de concepts. Ainsi:                      
Q= c1c2‚Ä¶cn. Le score de pertinence est donn√© par P(QD) estim√©e comme suit:  	 
                                                                                                         (4)                       
Nous distinguons deux cas : Si ci ne correspond √† aucune entr√©e de WordNet, 
l‚Äôappariement est strict. Sinon, on exploite la hi√©rarchie de la requ√™te et du document pour 
chercher non seulement ci mais aussi les concepts qui lui sont proches. Le lissage par 
interpolation lin√©aire permet de tenir compte de ce fait, ainsi :    	                                                                              (5)                : est la probabilit√© que ci non candidat √† l‚Äôexpansion soit g√©n√©r√© par D.     : est la probabilit√© que le concept ci identifi√© dans WordNet soit g√©n√©r√© par D. 
Estimation de  !"#$%&' . Quand le concept ci correspond √† une entr√©e de l‚Äôontologie, on 
peut non seulement retrouver les documents o√π il figure effectivement (appariement direct) 
mais aussi les documents o√π figurent les concepts qui lui sont li√©s par des relations 
s√©mantiques de l‚Äôontologie (subsomption) (appariement indirect). Ces deux cas sont 
combin√©s par un lissage par interpolation lin√©aire.    	 (   )  (*                                                               (6)                 est la probabilit√© que le concept ci soit g√©n√©r√© directement par D, et *    est 
la probabilit√© que le concept ci soit g√©n√©r√© indirectement par D.  
Estimation des probabilit√©s !$%& '  et !"#$%& ' . Elles sont estim√©es en utilisant                 
la formule de pond√©ration de concepts CF (Concept Frequency) propos√©e dans Baziz (2005). 
    	 +  , 	 -./0 -1/213                                                                                     (7)                     4+/ , 	 5678+/ ,  0 9:;<=>:;<)+.,=?@ABC;. )5678)D)                                                               
O√π Count (cpi, D) retourne la fr√©quence d‚Äôapparition de cpi, Length(cpi) repr√©sente le 
nombre de mots dans le concept cpi et sub_concept (cpi) le nombre de tous les sous-concepts                 
                                                          
4  Cet algorithme comprend  d√©tection des groupes de mots, d√©sambig√ºisation et pond√©ration. 
RNTI-E-19- 93 -
Mod√®le de langue √† base de concepts pour la recherche d‚Äôinformation 
(des concepts de l‚Äôontologie) d√©riv√©s de cpi. Quand ci ne correspond √† aucune entr√©e                      
de WordNet, nous annulons le deuxi√®me terme de 4+/ ,. 4+E/ , 	 5678E/    
Quand ci (identifi√© ou non dans WordNet) est absent dans le document, alors P(QD) est 
nulle. C‚Äôest pourquoi nous lissons  et  en utilisant la m√©thode ‚ÄúAbsolute 
Discount‚Äù appliqu√©e aux concepts Zhai et al. (2001).  FB@+, 	 GHI)-/JK/L  K M>N5                                                                 
O√π 	 0 41 O/  et )M>N5 	 -/?0 -/?2P )(C est le mod√®le de la collection).  
Estimation de !$Q%&'. Pour int√©grer les relations entre les concepts, nous utilisons                  
le mod√®le de  Berger et  Lafferty (1999).  * 	 0 *.QN *R)                                                                                (8) 
O√π E : est l‚Äôensemble de tous les concepts * li√©s √† ceux de la requ√™te.
Les approches conceptuelles propos√©es jusque l√†, m√©langent les concepts sp√©cifiques avec 
les concepts g√©n√©riques. Or, il a √©t√© constat√© que les concepts g√©n√©riques am√©liorent le rappel 
et que les concepts sp√©cifiques am√©liorent la pr√©cision Baziz (2005), Zakos, J. (2005).               
Le mod√®le (8) est s√©par√© pour tenir compte de ce fait par le lissage par interpolation lin√©aire:  
)Q  	 S T0 UNUV :):)W    S X0 YNYV @)@)Z)))                     (9) 
O√π : : (respectivement)@)  est la probabilit√© conditionnelle que ci soit g√©n√©r√© 
par un concept plus g√©n√©rique cg (respectivement cs). Nous avons pos√©  les contraintes  cgV Q 
et cs V Q  pour ne tenir qu‚Äôune seule fois de cg et cs  quand ils existent d√©j√† dans la requ√™te.  
Estimation de !%&%[ et de !%&%\. Ces probabilit√©s interpr√®tent la distance 
s√©mantique entre ci et cg (ou cs). Elles sont  estim√©es en utilisant une mesure de similarit√© 
bas√©e sur la distance s√©mantique entre ces concepts. Nous avons choisi la mesure de Wu et 
Palmer (1994) car elle est simple √† mettre en ≈ìuvre, de plus, elle est bas√©e sur le principe de 
la distance s√©mantique suivant : Soient X et Y  deux √©l√©ments d‚Äôune ontologie. La similarit√© 
entre eux est bas√©e sur les distances N1 et N2 qui les s√©parent du n≈ìud racine et la distance 
N qui s√©pare le concept subsumant (CS) X et Y du n≈ìud racine. D]^)_A`/ a 	 bccdcb  , alors : + : , 	 =e)fgU/)0 =e)fg/h2hi                                                                                                     (10) 
De la m√™me mani√®re on estime la probabilit√© @ 
Apr√®s remplacement des diff√©rentes probabilit√©s dans  [5], le mod√®le propos√© est donn√© par : 
+, 	 

jkk
kl       m (      (TS 0 UNUV :):))   S0 YNYV @)@Wnop
ppq                  (11)  
                                                          
5 Il s‚Äôagit du mod√®le de l‚Äôexpansion des concepts √† proprement parler  
RNTI-E-19 - 94 -
L. SaidL‚Äôhadj et M. Boughanem 
4 Exemple
Soient: D1={Natural (4), Science(6), Geology(10), Geography(5), Geophysics(8), Globe(3), 
aeroelastic (10) }. 
D2={Earth (7), Natural (3), Science (6), Anatomy (4), Regional (5)} 
Q= {earth, science, geography, aeroelastic} 
4.1 Application du mod√®le uni-gramme mixte 
Le mod√®le de langue mixte est donn√© par :  	 
 r    5st u 
Sachant que les ti..k correspondent aux mots de la requ√™te et  est fix√© √† 0.5, l‚Äôapplication 
num√©rique du mod√®le  retourne les scores de pertinences suivants : P(QD2)=  0.00225                      
et P(QD1) = 0.00125. On remarque ainsi que D2 est plus pertinent que D1 par rapport √† Q. 
4.2 Application du mod√®le √† base de concepts  propos√©
La projection de D1 et de D2  sur la hi√©rarchie de WordNet retourne les 
repr√©sentations conceptuelles : D1 = {Natural Science (9), Geology (10), Geography (5), 
Geophysics (8), Globe (3), aeroelastic (10),  
D2= {Earth (7), Natural Science (7.5), Regional anatomy (8.5)}  
Q {earth science, geography, aeroelastic} 
 
 
FIG. 1-Repr√©sentations hi√©rarchiques des concepts de D1 et D2. 
La figure 1 permet de distinguer les niveaux de concepts que voici :   ={aeroelastic},  
Cp= {earth science, geography}, Cg (earth science)={natural science, science }, Cs (earth 
science)={geology, geography, oceanography, geology, geophysics}, Cg (geography) = { }.  
Apr√®s application du mod√®le propos√©6, les scores de pertinence sont :                      
P(QD1) = 0,000003726 et P(QD2) = 0,000001481040. Nous remarquons alors que D1 est 
plus pertinent que D2 par rapport √† Q. Ce r√©sultat diff√®re du premier. Il est justifi√© par                   
la fr√©quence √©lev√©e de ¬´ Earth ¬ª  de D2  (dont le sens est loin de celui de la requ√™te) qui                  
a influenc√© le r√©sultat retourn√© par le mod√®le uni-gramme.   
                                                          
6 Les param√®tres  (, , ) =   (0.3, 0.5, 0.5). Nous avons donn√© un poids plus important (0.5) au 
mod√®le d‚Äôexpansion car il capture effectivement la s√©mantique de la requ√™te et du document.  
 
RNTI-E-19- 95 -
Mod√®le de langue √† base de concepts pour la recherche d‚Äôinformation 
5 Conclusion
Dans ce papier nous avons propos√© un mod√®le de langue bas√© sur les concepts. Le choix 
d‚Äôint√©grer les concepts dans les mod√®les de langue se justifie aussi bien par les r√©sultats 
prometteurs de la recherche conceptuelle d‚Äôinformation que par la performance et la 
flexibilit√© des mod√®les de langue √† int√©grer plusieurs sources de connaissances. En effet, 
cette flexibilit√© nous a permis de tenir compte non seulement des concepts de l‚Äôontologie 
ainsi que de leurs liens mais aussi des concepts qui n‚Äôapparaissent pas dans l‚Äôontologie. Ce 
mod√®le est en cours d‚Äôexp√©rimentation. Les r√©sultats nous permettront d‚Äôapprofondir  et de 
consolider nos hypoth√®ses sur la combinaison mots simples-concepts ainsi que de la 
s√©paration des deux niveaux de concepts g√©n√©riques et concepts sp√©cifiques.  
6 R√©f√©rences bibliographiques
Shenghua Bao, Lei Zhang, Erdong Chen, Min Long, Rui Li, and Yong Yu (2006). LSM: 
Language Sense Model for Information Retrieval,  WAIM,  pp. 97‚Äì108. 
M. Baziz (2005). Indexation  Conceptuelle Guid√©e par Ontologie pour la  Recherche 
d‚ÄôInformation, th√®se de doctorat de l‚Äôuniversit√© de Paul Sabatier.  
Berger, A. and Lafferty, J., (1999). Information retrieval as statistical translation, In Proc. of 
the 1999 ACM SIGIR, pp. 222-229. 
Guihong Cao, Jian-Yun Nie, Jing Bai (2005). Integrating Word Relationships into Language 
Models,. SIGIR‚Äô05, Salvador, Brazil, August 15‚Äì19. 
Jianfeng Gao, Jian-Yun Nie, Guangyuan Wu, Guihong Cao (2004). Dependance Language 
model for information retrieval,  SIGIR‚Äô04. 
Jay M. Ponte and W. Bruce Croft (1998). A Language Modeling Approach to Information 
Retrieval, Proc. of ACM-SIGIR, pp. 275-281. 
Munirathnam Srikanth et Rohini Srihari (2002). Biterm Language Models for Document 
Retrieval, ACM SIGIR‚Äô02, Tampere, Finland.  
Munirathnam Srikanth, Rohini Srihari (2003). Incorporating Query Term Dependencies in 
Language Models for Document Retrieval, In SIGIR‚Äô03, Canada. 
John Zakos (2005). A Novel Concept and Context based Approach for Web Information 
Retrieval, Doctorate thesis, Griffith University, 2005. 
Wu Z. & Palmer M., (1994). Verb Semantics and Lexical Selection. In Proc. of the 32nd 
Annual Meeting of the Associations for Computational Linguistics, pp. 133-138, 1994 .   
Zhai C and Lafferty J (2001). A Study of Smoothing Methods for Language Models Applied 
to Information Retrieval, In Proc. of the 2001 ACM SIGIR. pp. 334-342. 
RNTI-E-19 - 96 -
