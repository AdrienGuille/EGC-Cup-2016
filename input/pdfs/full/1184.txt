Relaxations de la régression logistique : modèles pour
l’apprentissage sur une sous-population
et la prédiction sur une autre
Farid Beninel∗, Christophe Biernacki∗∗
∗CREST ENSAI
rue Blaise Pascal, Campus de Ker Lann
35170 Bruz, France
Farid.Beninel@ensai.fr
∗∗Université Lille1, UFR de mathématiques, UMR 6524
59655 Villeneuve d’Ascq, France
Christophe.Biernacki@math.univ-lille1.fr
Résumé. Habituellement en analyse discriminante on a à prédire le groupe d’ap-
partenance à partir des variables de description ou covariables. La règle de pré-
diction est élaborée en utilisant un échantillon d’apprentissage soumis aux mêmes
conditions externes que les individus à prédire. Dans ce travail, on s’intéresse à
la prédiction d’individus d’une certaine sous-population utilisant un échantillon
d’apprentissage d’une autre sous-population. En assurance-finance, le problème
apparaît quand il faut inférer le groupe d’appartenance de sociétaires-clients sou-
mis à certaines conditions externes et que la règle est élaborée à partir d’indivi-
dus soumis à d’autres. On propose différents modèles étendant la discrimination
logistique classique. Ces modèles se fondent sur des relations acceptables entre
les fonctions scores que l’on associerait à chacune des sous-populations en pré-
sence.
1 Introduction
Traditionnellement, l’analyse discriminante procède de la façon suivante (McLachlan 1992) :
un échantillon provient d’une population et une partition en plusieurs groupes de cet échan-
tillon est connue. À partir des variables disponibles, une règle de classement est alors établie
dans le but de classer tout nouvel élément non étiqueté. Néanmoins, une hypothèse sous jacente
à cette procédure est que ces nouveaux individus et les individus constituant l’échantillon d’ap-
prentissage proviennent de la même population. L’analyse discriminante généralisée consiste à
étendre le problème de l’analyse discriminante classique lorsque cette hypothèse fondamentale
est relaxée.
Dans Biernacki et al. (2002) on considère cette extension dans le cas de la discrimination
gaussienne multivariée. À partir d’hypothèses simples et raisonnables sur la nature du lien sto-
chastique entre les deux sous-populations d’où proviennent respectivement l’échantillon d’ap-
- 213 - RNTI-A-1
Relaxations de la régression logistique
prentissage et l’échantillon de prédiction, il a été établi que cette liaison était nécessairement
affine. Un certain nombre de modèles de contraintes sur les paramètres affines de cette liaison
ont ensuite été proposés, permettant ainsi d’obtenir des modèles parcimonieux, généralement
faciles à interpréter par le praticien et enfin retrouvant puis généralisant des travaux précurseurs
en discrimination généralisée (Van Franecker & Ter Brack 1993).
La méthode proposée a été testée sur des données issues de la biologie. Les sous-populations de
prédiction et d’apprentissage correspondaient à deux espèces similaires d’oiseaux de mer dif-
férant de par leur localisation géographique (Bretagnolle et al. 1998). L’objectif était d’estimer
ou de prédire le sexe d’oiseaux de la seconde espèce à partir des seules variables biométriques.
La règle de prédiction utilisée est construite à partir des données relatives aux individus de la
première espèce renseignés, eux, pour la biométrie et le sexe. Les résultats se sont alors révélés
très concluants sur cet exemple.
On comprend aisément que le potentiel d’évolution du concept d’analyse discriminante gé-
néralisée soit fort puisqu’il concerne naturellement l’ensemble des méthodes et des types de
données considérées en analyse discriminante classique. Dans ce travail, nous focalisons notre
attention sur la discrimination ou régression logistique, méthode employée dans de nombreux
domaines (dont les assurances) et permettant de traiter des données de différentes natures
(continues et/ou catégorielles).
L’idée initiale consiste à utiliser les résultats établis dans le modèle gaussien multivarié et
à les transposer au modèle logistique. Afin d’exprimer simplement et avec parcimonie une
relation entre les paramètres de la discrimination logistique des deux sous-populations (celle
d’apprentissage et celle de prédiction), un certain nombre de modèles de liaison vont être
identifiés et explicités. Dans un premier temps, il est donc utile de rappeler succinctement les
résultats disponibles dans le cas gaussien.
2 Discrimination gaussienne généralisée
2.1 Problématique
En discrimination généralisée (gaussienne ou non), les données consistent en deux échan-
tillons : un échantillon d’apprentissage, (i.e. un échantillon avec labels) S provenant d’une
sous-population Ω et un échantillon de prédiction, (i.e. un échantillon sans labels) S∗ pro-
venant d’une sous-population Ω∗. La problématique fondamentale repose sur le fait que les
sous-populations Ω et Ω∗ peuvent être différentes.
Dans le contexte de la discrimination gaussienne multivariée, l’échantillon d’apprentissage S
est composé de n couples (x1, z1), . . ., (xn, zn) où xi est un vecteur de Rd représentant les
caractéristiques numériques décrivant l’individu numéro i (i = 1, . . . , n) et où zi est le numéro
de son groupe d’appartenance. Ainsi, zi = k avec k = 1, . . . ,K si cet individu appartient au
groupe k parmiK groupes possibles. Les n couples (xi, zi) sont supposés être des réalisations
i.i.d. du couple aléatoire (X, Z) défini sur Ω de distribution jointe
X|Z=k ∼ Nd(µk,Σk), k = 1, . . . ,K et Z ∼MK(1, pi1, . . . , piK) (1)
où Nd(µk,Σk) correspond à la distribution gaussienne d dimensionnelle de moyenne µk ∈
Rd et de matrice de variance Σk ∈ Rd×d et MK(1, pi1, . . . , piK) correspond à la loi de
- 214 -RNTI-A-1
F. Beninel et C. Biernacki
l’indice non nul d’un vecteur aléatoire issu d’une loi multinomiale d’ordre 1 et de para-
mètres pi1, . . . , piK . Ainsi, le paramètre pik représente la proportion du groupe k dans la sous-
population Ω et par suite
∑K
k=1 pik = 1.
L’échantillon de prédiction S∗ est composé de n∗ individus desquels seules les caractéristiques
numériques x∗1,, . . ., x
∗
n∗ sont connues (ces caractéristiques sont les mêmes que pour S), les
labels correspondant z∗1 , . . ., z
∗
n∗ étant inconnus. Les n
∗ couples (x∗i , z
∗
i ) sont supposés être
des réalisations i.i.d. du couple aléatoire (X∗, Z∗) défini sur l’espace Ω∗ de distribution jointe
X∗|Z∗=k ∼ Nd(µ∗k,Σ∗k), k = 1, . . . ,K et Z∗ ∼MK(1, pi∗1 , . . . , pi∗K). (2)
L’objectif étant d’estimer les n∗ labels inconnus z∗1 , . . ., z
∗
n∗ en utilisant l’information prove-
nant des deux échantillons S et S∗, le principal enjeu est alors d’identifier une relation liant les
sous-populations Ω et Ω∗.
2.2 Liaison affine entre sous-populations
L’approche proposée pour la discrimination généralisée consiste à établir une application
φk de Rd dans Rd liant en loi les vecteurs aléatoires du groupe k (k = 1, . . . ,K) des sous-
populations Ω et Ω∗. Ainsi
X∗|Z∗=k ∼ φk(X|Z=k) = [φk1(X|Z=k), . . . , φkd(X|Z=k)]T, (3)
avec φkj une application de Rd dans R (j = 1, . . . , d). Deux hypothèses essentielles sont alors
faites sur l’application φk. Tout d’abord, il est supposé que la jème composante φkj(X|Z=k)
de φk(X|Z=k) ne dépend que de la jème composante Xj|Z=k de X|Z=k. Cela revient à ad-
mettre que φkj est une application de R dans R (par simplicité, la notation φkj est conservée),
ce qui s’écrit aussi
φk(X|Z=k) = [φk1(X1|Z=k), . . . , φkd(Xd|Z=k))]T. (4)
En second lieu, cette application φkj est supposée être de classe C1. Ces deux hypothèses
suffisent à établir que la fonction φkj est nécessairement affine (résultat provenant de DeMeyer
et al. 2000), ce qui conduit auxK relations suivantes
X∗|Z∗=k ∼ DkX|Z=k + bk, k = 1, . . . ,K (5)
avecDk une matrice diagonale de Rd×d et bk un vecteur de Rd. Comme conséquence immé-
diate, les paramètres des deux sous-populations Ω et Ω∗ sont liés de la façon suivante :
pour k = 1, . . . ,K, µ∗k = Dkµk + bk et Σ
∗
k = DkΣkDk. (6)
3 La discrimination logistique classique
3.1 Le modèle logistique
Par commodité le label Z denotera dorénavant une variable binaire dont la valeur 1 corres-
pond au groupe 1 et la valeur 0 correspond au groupe 2. Les n paires (x1, z1), . . . , (xn, zn) de
- 215 - RNTI-A-1
Relaxations de la régression logistique
l’échantillon d’apprentissage sont des réalisations indépendantes du couple aléatoire (X, Z)
dont la loi jointe est définie parX|Z=k ∼ fk(k = 0, 1) et Z ∼ B(1, pi). Dans le cadre de cette
hypothèse sur les données, le modèle logistique porte sur la distribution conditionnelle, i.e.
P(Z = 1|X = x) = exp(β0 + β
Tx)
1 + exp(β0 + βTx)
. (7)
Etant donné un nouvel individu (x∗, z∗) ∼ (X, Z) soumis aux mêmes conditions que ceux de
l’échantillon S et pour lequel seul x∗ est connu, il s’agit de prédire la valeur z∗.
Cette prédicion se base sur la seule information liant variables explicatives et à expliquer que
recèle l’échantillon d’apprentissage S. L’affectation au groupe {Z = 1} ou {Z = 0} se fait
selon la vraisemblance de l’une ou l’autre des deux alternatives, eu égard à la donnée x∗ ; cette
vraisemblance est mesurée par la probabilité pix∗ = P(Z = 1|x∗). On affecte au groupe 1
(z∗ = 1) si pix∗ > 12 et au groupe 2 (z
∗ = 0) si x∗ < 12 ; l’indétermination pix∗ =
1
2 , a priori
rare, sera gérée selon le niveau de sévérité que l’on impose quant à admettre au groupe 1 resp.
au groupe 2.
L’hypothèse sous jacente au modèle logistique, est que
log
(
f1(x∗)
f0(x∗)
)
= β˜0 + βTx∗, (8)
avec β˜0 ∈ R, β = (β1, . . . , βd)T ∈ Rd. En effet, par la formule de Bayes, on a pix∗ =
pif1(x∗)/[pif1(x∗) + (1− pi)f0(x∗)] et par suite,
log
(
f1(x∗)
f0(x∗)
)
= log
(
(1− pi)pix∗
pi(1− pix∗)
)
= log
(
1− pi
pi
)
+ β0 + βTx∗. (9)
Ainsi, le modèle logistique vaut pour les situations où le rapport des lois marginales f1 et f0
peut être considéré à logarithme linéaire, comme cela est le cas par exemple lorsque f1 et f0
sont des distributions gaussiennes homoscédatiques. Plus généralement, cela est vérifié pour
une large famille de distributions multivariées continues et discrètes (Anderson 1982).
3.2 Estimation des paramètres
Ici, le problème est restreint a l’estimation des paramètres β0 et β du modèle donné en (7),
étant donné l’échantillon S = {(x1, z1), . . . , (xn, zn)}.
La log-vraisemblance, associée aux données, est
l(β0,β) =
1∑
k=0
∑
i:zi=k
zi log(pif1(xi)) + (1− zi) log((1− pi)f2(xi)). (10)
On décompose en resp. une partie conditionnelle et une partie marginale.
l(β0,β) =
1∑
k=0
∑
i:zi=k
log(P(Zi = k|xi)) +
n∑
i=1
log(pif1(xi) + (1− pi)f2(xi)). (11)
- 216 -RNTI-A-1
F. Beninel et C. Biernacki
En réalité, du fait que les modèles (inconnus) de lois auxquels s’apparentent f1 et f2 peuvent
être considérés comme indépendantes de (β0,β), on maximise la seule log-vraiemblance
conditionnelle, i.e.
lcond(β0,β) =
1∑
k=0
∑
i:zi=k
log(P(Zi = k|xi)) =
n∑
i=1
zi log(pixi)+(1−zi) log(1−pixi). (12)
On trouve dans (Govaert 2003) une justification de cette démarche.
La recherche de (β0,β) maximisant lcond(β0,β) consiste en la résolution du système non
linéaire (S1) suivant obtenu par annulation des dérivées partielles :
(S1) :

∂lcond(β0,β)
∂β0
=
∑n
i=1(zi − pi(xi, β0,β)) = 0,
lcond(β0,β)
∂βj
=
∑n
i=1 xi,j(zi − pi(xi, β0,β)) = 0. j = 1, . . . , d.
Dans le cas général, le système (S1) admet une unique solution correspondant au maximum.
Le cas dégénéré (non unicité) correspond a un modèle surparamétré. Du point de vue compu-
tationnel, la résolution du système (S1) se fait par l’usage de l’algorithme de Newton-Raphson
ou ses variantes.
4 La discrimination logistique étendue à unmélange de deux
sous-populations
4.1 Les données
On dispose des deux échantillons S = {(xi, zi) : i = 1, . . . , n} et S∗ = {(x∗i , z∗i ) : i =
1, . . . , n∗} ; les tailles respectives sont n et n∗. Les paires (xi, zi) sont des réalisations indé-
pendantes du couple aléatoire (X, Z) restreint à la sous-population Ω ; les paires (x∗i , z
∗
i ) sont,
elles, des réalisations indépendantes du couple (X, Z) restreint a une autre sous-population
Ω∗.
4.2 La problèmatique
Il s’agit de mettre en évidence une fonction d’affectation aux groupes pour les individus de
Ω∗ en utilisant les échantillons d’apprentissage S et S∗ ; ce deuxième échantillon est supposé
de petite taille.
L’utilisation (comme données complémentaires) de l’échantillon S ⊂ Ω pour prédire dans Ω∗
est pour pallier à l’insuffisance en nombre des observations constituant S∗ et se fonde sur un
lien supposé entre les restrictions (aux deux sous-populations) du vecteur de covariables, i.e.
X|Ω etX|Ω∗ .
Le lien entre restrictions du vecteur de covariables implique un lien entre fonctions scores.
Ainsi, l’utilisation d’un lien acceptable entre les fonctions scores des deux sous-populations
permet de se servir de l’information que recèlent les échantillons S et S∗ pour affecter, aux
- 217 - RNTI-A-1
Relaxations de la régression logistique
groupes, des individus de Ω∗. Soient Ψ (Ω→ {0, 1}) et Ψ∗(Ω∗ → {0, 1}) les deux fonctions
score. On fait l’hypothèse que les deux fonctions font intervenir « les mêmes covariables», i.e.
Ψ(x) = log
(
pix
1− pix
)
= β0 + βTx et Ψ∗(x∗) = log
(
pix∗
1− pix∗
)
= β∗0 + β
∗Tx∗.
4.3 L’héritage gaussien
Dans le cas où les populations Ω et Ω∗ sont gaussiennes homoscédatiques condition-
nellement aux groupes et notant les matrices de variances communes Σ = Σ1 = Σ2 et
Σ∗ = Σ∗1 = Σ
∗
2, on obtient aisément le lien suivant entre les paramètres logistiques et les
paramètres gaussiens des deux sous-populations :
Ω : β0 =
1
2
(µT2Σ
−1µ2 − µT1Σ−1µ1) et β = Σ−1(µ1 − µ2),
Ω∗ : β∗0 =
1
2
(µ∗T2 Σ
∗−1µ∗2 − µ∗T1 Σ∗−1µ∗1) et β∗ = Σ∗−1(µ∗1 − µ∗2).
En fonction des hypothèses sur les paramètres de liaison entre les deux gaussiennes, il est
possible d’exhiber des relations entre β∗0 et β0 d’une part, et β
∗ et β d’autre part, liaisons
où l’hypothèse gaussienne n’apparaît plus explicitement. C’est ce genre de modèles que nous
allons maintenant décrire ci-dessous.
4.4 Les modèles de liaison entre fonctions scores
Les modèles de liaisons sont donnés par c ∈ R et Λ une matrice diagonale d’ordre d tels
que β∗0 = β0 + c et β
∗ = Λβ. Comme évoqué ci-dessus, les modèles de liaisons retenus sont
ceux faisant intervenir les mêmes variables dans chacun des deux modèles et ces modèles ont
été inspirés par le cas gaussien homoscédatique décrit précédement.
– (M.1) : β∗0 = β0 et β
∗ = β ; la discrimination logistique est identique pour les popula-
tions Ω et Ω∗.
– (M.2) : β∗0 = β0 et β
∗ = λβ ; les discriminations logistiques des populations Ω et Ω∗
diffèrent uniquement au travers du paramètre scalaire λ.
– (M.3) : β∗0 libre et β
∗ = β ; les discriminations logistiques des populations Ω et Ω∗
diffèrent uniquement au travers du paramètre scalaire β∗0 .
– (M.4) : β∗0 libre et β
∗ = λβ ; les discriminations logistiques des populations Ω et Ω∗
diffèrent cette fois au travers du couple de paramètres scalaires β∗0 et λ.
– (M.5) : β∗0 = β0 et β
∗ libre ; les discriminations logistiques des populations Ω et Ω∗
diffèrent seulement au travers du paramètre vectoriel β∗.
– (M.6) : β∗0 libre et β
∗ libre ; il y a donc autant de paramètres libres (d + 1) dans la
régression logistique associée à Ω et à celle associée à Ω∗. Dans ce cas limite, il n’existe
plus de lien stochastique entre les discriminations logistiques des deux populations.
4.5 Estimation des paramètres
L’estimation des paramètres β0 et β associés à la régression logistique de la population
Ω se fait tout d’abord de façon standard et ne nécessite alors aucune explication spécifique.
- 218 -RNTI-A-1
F. Beninel et C. Biernacki
Dans un second temps, et conditionnellement à la connaissance des paramètres de Ω, les pa-
ramètres de transition entre les fonctions scores de Ω et de Ω∗ doivent être estimés. En notant
θ ce ou ces paramètres, l’estimation peut se réaliser par maximisation de la log-vraisemblance
conditionnelle qui est donnée par :
lcond(θ) =
n∗∑
i=1
z∗i log(pi(x
∗
i ,θ)) + (1− z∗i ) log(1− pi(x∗i ,θ)). (13)
On peut interpréter les z∗1 , . . . , z
∗
n∗ comme des réalisations des variables de Bernoulli indé-
pendantes Z∗1 , . . . , Z
∗
n∗ telles que Z
∗
i ∼ B(pix∗1 ), ceci conditionnellement aux réalisations
x∗1, . . . , x
∗
n∗ .
On donne, pour l’ensemble des modèles, le système d’équations non linéaires (en les compo-
santes de θ) correspondant et une condition nécessaire et suffisante d’unicité de la solution.
Le modèle (M.1) Il n’y a aucun paramètre à estimer car on utilise simplement les estima-
tions associées au score de Ω∗.
Le modèle (M.2) Le paramètre θ = λ ∈ R est estimé par la solution de l’équation non
linéaire à l’inconnue λ
∂lcond(λ)
∂λ
=
n∗∑
i=1
βTx∗i (z
∗
i − pi(x∗i , λ)) = 0. (14)
L’expression de la dérivée seconde est donnée par
∂2lcond(λ)
∂λ2
= −
n∗∑
i=1
(βTx∗i )
2pi(x∗i , λ)(1− pi(x∗i ), λ). (15)
On établit aisément que ∂
2lcond(λ)
∂λ2 ≤ 0, i.e. que lcond(λ) est concave. Considérons la condition
(16) ci après :
∃i ∈ S∗ : βTx∗i 6= 0. (16)
Sous cette condition lcond(λ) est strictement concave, d’où l’unicité de solution de l’equation
(14), i.e. unicité de l’estimation du seul paramètre intervenant dans le modèle. La non vérifica-
tion de la condition (16) entraine que la fonction lcond(λ) est indépendante des observations x∗i
et de λ d’où la non unicité. En conséquence toutes les estimations (i.e., choix) de λ génèreront
des modèles qui affecteront les observations x∗i au même groupe d’appartenance.
La condition (16) est peu restrictive ; elle est vérifiée notamment lorsque les observations
{x∗i : i = 1, . . . , n∗} engendrent un espace de dimension supérieure ou égale au nombre
de covariables d.
Le modèle (M.3) On estime θ = β∗0 ∈ R solution de l’équation non linéaire à l’inconnue
β∗0
∂lcond(β∗0)
∂β∗0
=
n∗∑
i=1
(z∗i − pi(x∗i , β∗0)) = 0. (17)
- 219 - RNTI-A-1
Relaxations de la régression logistique
Ce modèle, s’apparente à ce qui se pratique habituellement, i.e. ayant obtenu l’estimation d’un
modèle logistique, on essaie de décaler le seuil d’affectation à la réponse positive {Z = 1}, ce
qui revient à substituer à l’intercept β0 la valeur β∗0 .
L’expression de la dérivée seconde est donnée par
∂2lcond(β∗0)
∂β∗20
= −
n∗∑
i=1
pi(x∗i , β
∗
0)(1− pi(x∗i , β∗0)). (18)
On vérifie donc, sans peine, que lcond(β∗0) est strictement concave et que par conséquent l’es-
timation β̂∗0 est unique.
Le modèle (M.4) On estime θ = (β∗0 , λ) ∈ R2 par maximisation de lcond. Cela revient à
résoudre le système non linéaire
(S.4) :
{
∂lcond(β
∗
0 ,λ)
∂β∗0
=
∑n∗
i=1(z
∗
i − pi(x∗i , β∗0 , λ)) = 0,
∂lcond(β
∗
0 ,λ)
∂λ =
∑n∗
i=1 β
Tx∗i (z
∗
i − pi(x∗i , β∗0 , λ)) = 0.
SoitH le hessien associé à la log-vraisemblance, en posantH11 =
∂2l(β∗0 ,λ)
∂β0∗2
,H22 =
∂2l(β∗0 ,λ)
∂λ2
et H12 =
∂2l(β∗0 ,λ)
∂β∗0∂λ
, on établit que
H11 = −
n∗∑
i=1
pi(x∗i , β
∗
0 , λ)(1− pi(x∗i , β∗0 , λ)), (19)
H22 = −
n∗∑
i=1
(βTx∗i )
2pi(x∗i , β
∗
0 , λ)(1− pi(x∗i , β∗0 , λ)), (20)
H12 = −
∑
i=1
βTx∗i pi(x
∗
i , β
∗
0 , λ)(1− pi(x∗i , β∗0 , λ)). (21)
On montre que le hessien H est semi défini négatif d’où la concavité de lcond(β∗0 , λ) et donc
l’existence de solution du système (S. 4).
Considérons la condition (22) ci après :
∃i, i′ ∈ {1, . . . , n∗} : βT(x∗i′ − x∗i ) 6= 0. (22)
Sous cette condition la concavité est stricte et par conséquent la solution du système (S. 4) est
unique. Là aussi, la non vérification de la condition d’unicité du maximum entraine, pour tout
choix de (β∗0 , λ), l’affectation de toutes les observations à un même groupe d’appartenance.
Le modèle (M.5) On estime θ = β∗ en résolvant le système
(S.5) : ∂lcond(Λ)∂β∗j =
∑n∗
i=1 x
∗
i,j (z
∗
i − pi(x∗i ,β∗)) = 0, j = 1, . . . , d.
Le hessien H est défini par son terme générique
Hj,l = −
n∗∑
i=1
x∗i,j x
∗
i,l pi(x
∗
i ,β
∗) (1− pi(x∗i ,β∗)) j, l ∈ {1, . . . , d} (23)
- 220 -RNTI-A-1
F. Beninel et C. Biernacki
La matriceH est semi définie négative (i.e. lcond(θ) est concave) quelles que soient les données
x∗1, . . . ,x
∗
n∗ ; ce qui garantit l’existence de l’estimation.
Convenons que dim désigne la dimension et E l’éspace engendré et considérons la condition
(24) ci après :
dim(E(x∗1, . . . ,x∗n∗)) = d. (24)
Sous cette condition, on a unicité de solution du système (S.5).
Le modèle (M.6) Il s’agit simplement d’une estimation standard des paramètres logistiques
θ = (β∗0 ,β
∗) à partir de S∗.
4.6 L’algorithmique
Rappelons tout d’abord que l’estimation des paramètres logistiques associés à Ω sont réa-
lisés de façon classique. Du point de vue computationnel, l’estimation du paramètre θ liant
Ω à Ω∗ peut s’obtenir pour l’ensemble des modèles étudiés par l’usage de l’algorithme de
Newton-Raphson ou ses variantes. De façon équivalente, on peut procéder à une régression lo-
gistique sous contrainte, la contrainte dépendant du modèle considéré. Cette variante peut être
intéressante pour l’utilisateur disposant d’un logiciel de régression logistique. Nous décrivons
maintenant cette seconde option.
L’estimation se fait avec les estimations βˆ0 et βˆ ainsi que le deuxième échantillon d’appren-
tissage S
∗
= {(x∗i , z∗i ) : i = 1, . . . , n∗}. La procédure logistique est mise en œuvre avec
des options variables selon le modèle étudié. Considérons la matrice diagonale construite à
partir de β̂, i.e. diag(β̂) = diag(β̂1, . . . , β̂d) et les observations transformées x˜∗i = diag(β̂)x
∗
i
i = 1, . . . , n∗. Notons aussi la variable somme (des covariables) Y = 1X˜ et y∗i = 1
Tx˜∗i
(i = 1, . . . , n∗) ses réalisations sur le deuxième échantillon d’apprentissage. La notation 1
représente un vecteur colonne unitaire de Rd.
Modèle (M.2) Il s’agit de l’estimation du paramètre λ ∈ R intervenant dans le modèle
logit(P(Z∗ = 1|y∗)) = β̂0 + λy∗, (25)
à partir des données {(y∗i , z∗i ) : i = 1, . . . , n∗}. La procédure logistique appliquée ici,
contraint l’intercept d’être égal à β̂0.
Modèle (M.3) On estime β∗0 ∈ R intervenant dans le modèle
logit(P(Z∗ = 1|y∗)) = β∗0 + y∗. (26)
La procédure logistique appliquée ici contraint le coefficient associé à « la covariable » y∗
d’être égal à l’unité.
Modèle (M.4) On estime (β∗0 , λ) ∈ R2 intervenant dans le modèle
logit(P(Z∗ = 1|y∗)) = β∗0 + λy∗. (27)
Il s’agit là de mettre en oeuvre la procédure logistique sans poser de contraintes sur les para-
mètres du modèle.
- 221 - RNTI-A-1
Relaxations de la régression logistique
Modèle (M.5) On estime β∗ ∈ Rd intervenant dans le modèle
logit(P(Z∗ = 1|x˜∗)) = β̂0 + β∗Tx˜∗, (28)
à partir de l’échantillon transformé {(x˜∗, z∗i ) : i = 1, . . . , n∗}. La procédure de régression
logistique contraint l’intercept d’être égal à l’estimation (ou intercept) βˆ0.
4.7 Applications et perspectives d’applications
La mise en oeuvre des modèles d’extension de la régression logistique étudiés, dans les
domaines de l’assurance, la banque et le marketing constitue une perspective à court terme. On
s’intéresse, notamment à l’actualisation de fonctions scores.
Ainsi le début d’application, présentée ici, se basera sur les données biologiques traités dans
(Biernacki et al. 2002) par l’analyse discriminante généralisée. Le choix de ces données per-
met la comparaison des résultats obtenus à ceux obtenus et connus par ailleurs.
Les données considérées consistent en trois échantillons d’oiseaux de mer, provenant de trois
sous espèces de l’espèce Calanectris Diomedea :
– Le premier est constitué d’oiseaux Borealis composé de 93 femelles (SEX = 2) et 113
mâles (SEX = 1) ;
– le second est constitué d’oiseaux Diomedea composé de 22 femelles et 16 mâles ;
– le troisième est constitué d’oiseaux de l’espèce Edwards composé de 44 mâles et 48
femelles.
Les trois sous espèces se distinguent par leur répartition géographique (Thibault et al. (1997))
Le problème est de prédire le sexe (Variable SEX) à partir de cinq variables consistant en des
mesures biométriques :
– BECH et BECL : deux mesures relatives au bec ;
– TARSE : longueur du tarse ;
– AILE : envergure des ailes ;
– QUEUE : longueur de la queue.
Dans un premier temps, on s’intéresse à la prédiction du sexe d’oiseaux Diomedea en consi-
dérant l’échantillon des Borealis. L’echantillon S∗ est donc constitué d’une partie d’oiseaux
Diomedea (l’autre partie étant réservée aux tests) et l’échantillon S est constitué de l’ensemble
des oiseaux Borealis.
Le tableau 1 récapitule les résultats des simulations consistant pour chaque taille n, à tirer au
hasard 100 sous-échantillons Diomedea et à estimer les six modèles à partir de chacun de ces
échantillons, combiné avec l’échantillon Borealis. Pour ces simulations, on restreint l’évalua-
tion de la qualité d’un modèle à la seule utilisation du pourcentage de bien classés, calculé sur
les échantillons tests.
Dans un deuxième temps, le même type de simulations est réalisé pour la prédiction du sexe
d’individus de la sous espèce Edwards à partir d’oiseaux Borealis (échantillon S) et d’oiseaux
Edwards (échantillon S∗). Les résultats sont donnés par le tableau 2.
- 222 -RNTI-A-1
F. Beninel et C. Biernacki
Les résultats donnés dans les deux tableaux montrent la supériorité manifeste des modèles fai-
sant intervenir les deux échantillons en présence.
Par ailleurs, les résultats obtenus ici et dans le cadre de la «régression logistique générali-
sée»confirment ceux obtenus sur les mêmes données dans le cadre de la discrimination gaus-
siènne généralisée (Biernacki et al. (2002)).
Modèle M1 M2 M3 M4 M5 M6
n = 10 58.27 82.71 87.96 80.45 65.60 53.94
n = 20 54.59 86.20 85.82 84.28 71.61 52.67
n = 30 58.75 90.37 87.91 90.37 77.53 57.91
TAB. 1 – Tableau donnant le pourcentage moyen d’individus Diomedea bien classés, pour les
valeurs 10, 20, 30 de la taille n de S∗ et comme taille d’échantillon test (38− n).
Modèle M1 M2 M3 M4 M5 M6
n = 10 51.76 85.27 90.01 83.73 70.09 51.35
n = 20 51.73 86.85 86.93 86.75 78.57 49.70
n = 30 51.85 89.06 90.44 88.82 83.33 53.76
n = 50 52.01 88.91 89.84 89.01 85.07 52.47
TAB. 2 – Tableau donnant le pourcentage moyen d’individus Edwards bien classés, pour les
valeurs 10, 20, 30, 50 de la taille n de S∗ et comme taille d’échantillon test (92− n).
5 Conclusion
Les premières expériences numériques montrent l’utilité de modèles étendant la régression
logistique et permettant de considérer l’information de présence d’un mélange de populations.
Des expériences mumériques plus ambitieuses sont envisagées, notamment l’étude de l’évolu-
tion des critères de choix de modèles (BIC, AIC, . . .) en fonction des modèles et des tailles des
échantillons S∗ et S.
Ici, l’estimation des paramètres de transition θ (i.e. (β∗0 , λ) ou (β
∗
0 ,β
∗), selon le modèle) se fait
conditionnellement aux paramètres associés à la sous-population Ω (i.e. β0 et β) ; on envisage
comme perspective, l’estimation jointe des paramètres de Ω et ceux de transition.
Remerciements : Les auteurs remercient Madame Valérie Molina (attachée de l’INSEE au-
prés de l’ENSAI, Bruz) pour ses remarques et suggestions concernant l’optimisation du temps
de simulation.
- 223 - RNTI-A-1
Relaxations de la régression logistique
6 Références
Anderson, J.A. (1982). Logistic discrimination. In Handbook of Statistics (Vol. 2), P.R. Krish-
naiah and L. Kanal (Eds.). Amsterdam : North-Holland, pp. 169–191.
Biernacki, C., Beninel, F. & Bretagnolle, V. (2002). A Generalized Discriminante Rule when
Training Population and Test Population Differ on their Descriptive Parameters, Biometrics,
58, 2, 387–397.
Bretagnolle, V., Genevois, F. & Mougeot, F. (1998). Intra and Intersexual Function in the Call
of a non Passerine Bird, Behaviour, 135 : 1161-502.
De Meyer, B., Roynette, B., Vallois, P. & Yor, M. (2000). On independent times and positions
for Brownian motion. Technical Report 1, Les prépublications de l’Institut Élie Cartan, Institut
Élie Cartan, Vandœuvre lès Nancy, France.
Govaert, G. (2003). Analyse des données. Lavoisier serie "traitement du signal et de l’image",
Paris, pp.362.
McLachlan, G.J. (1992). Discriminant Analysis and Statistical Pattern Recognition, Wiley,
New York.
Thibault,J.-C., Bretagnolle,V., Rabouam,C. (1997). Cory’s shearwater calonectris diomedia.
Birds of Western Paleartic Update, 1, 75-98.
Van Franecker, J.A. & Ter Brack, C.J.F. (1993). A Generalized Discriminant for Sexing Ful-
marine Petrels from External Measurements, Auk, 110 : 492-502.
Summary
Usually in discriminant analysis we are faced with the prediction of labels of individuals
from a population given their descriptive parameters and using a unique learning sample. In-
dividuals to predict and individuals of the learning sample are submitted to the same external
conditions. The problem here, is to predict labels of individuals from a subpopulation using a
learning sample from another one. In insurance and finance, this problem occurs in the predic-
tion of the risk groups using characteristic parameters. Individuals to predict and the learning
ones come respectively from two subpopulations of member-cum-consumers corresponding to
geographical areas . . . In this work we extend the idea used in generalized discriminant analy-
sis (consisting of the use of the two learning samples to predict) to logistic discrimination, less
restrictive concerning the type of descriptive variables. We propose different models of gener-
alized logistic discrimination based on acceptable relations between the score function on the
first population and the score function of the second one.
- 224 -RNTI-A-1
